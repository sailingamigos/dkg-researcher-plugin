[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09526v1",
            "title": "DFIL: Deepfake Incremental Learning by Exploiting Domain-invariant\n  Forgery Clues",
            "updated": "2023-09-18T07:02:26Z",
            "published": "2023-09-18T07:02:26Z",
            "summary": "The malicious use and widespread dissemination of deepfake pose a significant\ncrisis of trust. Current deepfake detection models can generally recognize\nforgery images by training on a large dataset. However, the accuracy of\ndetection models degrades significantly on images generated by new deepfake\nmethods due to the difference in data distribution. To tackle this issue, we\npresent a novel incremental learning framework that improves the generalization\nof deepfake detection models by continual learning from a small number of new\nsamples. To cope with different data distributions, we propose to learn a\ndomain-invariant representation based on supervised contrastive learning,\npreventing overfit to the insufficient new data. To mitigate catastrophic\nforgetting, we regularize our model in both feature-level and label-level based\non a multi-perspective knowledge distillation approach. Finally, we propose to\nselect both central and hard representative samples to update the replay set,\nwhich is beneficial for both domain-invariant representation learning and\nrehearsal-based knowledge preserving. We conduct extensive experiments on four\nbenchmark datasets, obtaining the new state-of-the-art average forgetting rate\nof 7.01 and average accuracy of 85.49 on FF++, DFDC-P, DFD, and CDF2. Our code\nis released at https://github.com/DeepFakeIL/DFIL.",
            "author": [
                "Kun Pan",
                "Yin Yifang",
                "Yao Wei",
                "Feng Lin",
                "Zhongjie Ba",
                "Zhenguang Liu",
                "ZhiBo Wang",
                "Lorenzo Cavallaro",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09526v1",
                "http://arxiv.org/pdf/2309.09526v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09517v3",
            "title": "FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural\n  Networks",
            "updated": "2023-09-21T08:37:22Z",
            "published": "2023-09-18T06:55:14Z",
            "summary": "Federated training of Graph Neural Networks (GNN) has become popular in\nrecent years due to its ability to perform graph-related tasks under data\nisolation scenarios while preserving data privacy. However, graph heterogeneity\nissues in federated GNN systems continue to pose challenges. Existing\nframeworks address the problem by representing local tasks using different\nstatistics and relating them through a simple aggregation mechanism. However,\nthese approaches suffer from limited efficiency from two aspects: low quality\nof task-relatedness quantification and inefficacy of exploiting the\ncollaboration structure. To address these issues, we propose FedGKD, a novel\nfederated GNN framework that utilizes a novel client-side graph dataset\ndistillation method to extract task features that better describe\ntask-relatedness, and introduces a novel server-side aggregation mechanism that\nis aware of the global collaboration structure. We conduct extensive\nexperiments on six real-world datasets of different scales, demonstrating our\nframework's outperformance.",
            "author": [
                "Qiying Pan",
                "Ruofan Wu",
                "Tengfei Liu",
                "Tianyi Zhang",
                "Yifei Zhu",
                "Weiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09517v3",
                "http://arxiv.org/pdf/2309.09517v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09516v2",
            "title": "On the gamma difference distribution",
            "updated": "2023-09-24T23:31:13Z",
            "published": "2023-09-18T06:54:44Z",
            "summary": "The gamma difference distribution is defined as the difference of two gamma\ndistributions, with in general different shape and rate parameters. Starting\nwith knowledge of the corresponding characteristic function, a second order\nlinear differential equation characterisation of the probability density\nfunction is given. This is used to derive a Stein-type differential identity\nrelating to the expectation with respect to the gamma difference distribution\nof a general twice differentiable function $g(x)$. Choosing $g(x) = x^k$ gives\na second order recurrence for the positive integer moments, which are also\nshown to permit evaluations in terms of ${}_2 F_1$ hypergeometric polynomials.\nA hypergeometric function evaluation is given for the absolute continuous\nmoments. Specialising the gamma difference distribution gives the variance\ngamma distribution. Results of the type obtained herein have previously been\nobtained for this distribution, allowing for comparisons to be made.",
            "author": [
                "Peter J. Forrester"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09516v2",
                "http://arxiv.org/pdf/2309.09516v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "math.PR",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09506v2",
            "title": "LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language\n  Models",
            "updated": "2023-09-19T07:47:52Z",
            "published": "2023-09-18T06:35:10Z",
            "summary": "Graphic layout generation, a growing research field, plays a significant role\nin user engagement and information perception. Existing methods primarily treat\nlayout generation as a numerical optimization task, focusing on quantitative\naspects while overlooking the semantic information of layout, such as the\nrelationship between each layout element. In this paper, we propose LayoutNUWA,\nthe first model that treats layout generation as a code generation task to\nenhance semantic information and harness the hidden layout expertise of large\nlanguage models~(LLMs). More concretely, we develop a Code Instruct Tuning\n(CIT) approach comprising three interconnected modules: 1) the Code\nInitialization (CI) module quantifies the numerical conditions and initializes\nthem as HTML code with strategically placed masks; 2) the Code Completion (CC)\nmodule employs the formatting knowledge of LLMs to fill in the masked portions\nwithin the HTML code; 3) the Code Rendering (CR) module transforms the\ncompleted code into the final layout output, ensuring a highly interpretable\nand transparent layout generation procedure that directly maps code to a\nvisualized layout. We attain significant state-of-the-art performance (even\nover 50\\% improvements) on multiple datasets, showcasing the strong\ncapabilities of LayoutNUWA. Our code is available at\nhttps://github.com/ProjectNUWA/LayoutNUWA.",
            "author": [
                "Zecheng Tang",
                "Chenfei Wu",
                "Juntao Li",
                "Nan Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09506v2",
                "http://arxiv.org/pdf/2309.09506v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09502v1",
            "title": "RenderOcc: Vision-Centric 3D Occupancy Prediction with 2D Rendering\n  Supervision",
            "updated": "2023-09-18T06:08:15Z",
            "published": "2023-09-18T06:08:15Z",
            "summary": "3D occupancy prediction holds significant promise in the fields of robot\nperception and autonomous driving, which quantifies 3D scenes into grid cells\nwith semantic labels. Recent works mainly utilize complete occupancy labels in\n3D voxel space for supervision. However, the expensive annotation process and\nsometimes ambiguous labels have severely constrained the usability and\nscalability of 3D occupancy models. To address this, we present RenderOcc, a\nnovel paradigm for training 3D occupancy models only using 2D labels.\nSpecifically, we extract a NeRF-style 3D volume representation from multi-view\nimages, and employ volume rendering techniques to establish 2D renderings, thus\nenabling direct 3D supervision from 2D semantics and depth labels.\nAdditionally, we introduce an Auxiliary Ray method to tackle the issue of\nsparse viewpoints in autonomous driving scenarios, which leverages sequential\nframes to construct comprehensive 2D rendering for each object. To our best\nknowledge, RenderOcc is the first attempt to train multi-view 3D occupancy\nmodels only using 2D labels, reducing the dependence on costly 3D occupancy\nannotations. Extensive experiments demonstrate that RenderOcc achieves\ncomparable performance to models fully supervised with 3D labels, underscoring\nthe significance of this approach in real-world applications.",
            "author": [
                "Mingjie Pan",
                "Jiaming Liu",
                "Renrui Zhang",
                "Peixiang Huang",
                "Xiaoqi Li",
                "Li Liu",
                "Shanghang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09502v1",
                "http://arxiv.org/pdf/2309.09502v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09500v1",
            "title": "PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction",
            "updated": "2023-09-18T05:57:12Z",
            "published": "2023-09-18T05:57:12Z",
            "summary": "In the era of information explosion, spatio-temporal data mining serves as a\ncritical part of urban management. Considering the various fields demanding\nattention, e.g., traffic state, human activity, and social event, predicting\nmultiple spatio-temporal attributes simultaneously can alleviate regulatory\npressure and foster smart city construction. However, current research can not\nhandle the spatio-temporal multi-attribute prediction well due to the complex\nrelationships between diverse attributes. The key challenge lies in how to\naddress the common spatio-temporal patterns while tackling their distinctions.\nIn this paper, we propose an effective solution for spatio-temporal\nmulti-attribute prediction, PromptST. We devise a spatio-temporal transformer\nand a parameter-sharing training scheme to address the common knowledge among\ndifferent spatio-temporal attributes. Then, we elaborate a spatio-temporal\nprompt tuning strategy to fit the specific attributes in a lightweight manner.\nThrough the pretrain and prompt tuning phases, our PromptST is able to enhance\nthe specific spatio-temoral characteristic capture by prompting the backbone\nmodel to fit the specific target attribute while maintaining the learned common\nknowledge. Extensive experiments on real-world datasets verify that our\nPromptST attains state-of-the-art performance. Furthermore, we also prove\nPromptST owns good transferability on unseen spatio-temporal attributes, which\nbrings promising application potential in urban computing. The implementation\ncode is available to ease reproducibility.",
            "author": [
                "Zijian Zhang",
                "Xiangyu Zhao",
                "Qidong Liu",
                "Chunxu Zhang",
                "Qian Ma",
                "Wanyu Wang",
                "Hongwei Zhao",
                "Yiqi Wang",
                "Zitao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09500v1",
                "http://arxiv.org/pdf/2309.09500v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09498v1",
            "title": "Combating Advanced Persistent Threats: Challenges and Solutions",
            "updated": "2023-09-18T05:46:11Z",
            "published": "2023-09-18T05:46:11Z",
            "summary": "The rise of advanced persistent threats (APTs) has marked a significant\ncybersecurity challenge, characterized by sophisticated orchestration, stealthy\nexecution, extended persistence, and targeting valuable assets across diverse\nsectors. Provenance graph-based kernel-level auditing has emerged as a\npromising approach to enhance visibility and traceability within intricate\nnetwork environments. However, it still faces challenges including\nreconstructing complex lateral attack chains, detecting dynamic evasion\nbehaviors, and defending smart adversarial subgraphs. To bridge the research\ngap, this paper proposes an efficient and robust APT defense scheme leveraging\nprovenance graphs, including a network-level distributed audit model for\ncost-effective lateral attack reconstruction, a trust-oriented APT evasion\nbehavior detection strategy, and a hidden Markov model based adversarial\nsubgraph defense approach. Through prototype implementation and extensive\nexperiments, we validate the effectiveness of our system. Lastly, crucial open\nresearch directions are outlined in this emerging field.",
            "author": [
                "Yuntao Wang",
                "Han Liu",
                "Zhou Su"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09498v1",
                "http://arxiv.org/pdf/2309.09498v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09496v1",
            "title": "CLIP-based Synergistic Knowledge Transfer for Text-based Person\n  Retrieval",
            "updated": "2023-09-18T05:38:49Z",
            "published": "2023-09-18T05:38:49Z",
            "summary": "Text-based Person Retrieval aims to retrieve the target person images given a\ntextual query. The primary challenge lies in bridging the substantial gap\nbetween vision and language modalities, especially when dealing with limited\nlarge-scale datasets. In this paper, we introduce a CLIP-based Synergistic\nKnowledge Transfer(CSKT) approach for TBPR. Specifically, to explore the CLIP's\nknowledge on input side, we first propose a Bidirectional Prompts Transferring\n(BPT) module constructed by text-to-image and image-to-text bidirectional\nprompts and coupling projections. Secondly, Dual Adapters Transferring (DAT) is\ndesigned to transfer knowledge on output side of Multi-Head Self-Attention\n(MHSA) in vision and language. This synergistic two-way collaborative mechanism\npromotes the early-stage feature fusion and efficiently exploits the existing\nknowledge of CLIP. CSKT outperforms the state-of-the-art approaches across\nthree benchmark datasets when the training parameters merely account for 7.4%\nof the entire model, demonstrating its remarkable efficiency, effectiveness and\ngeneralization.",
            "author": [
                "Yating liu",
                "Yaowei Li",
                "Zimo Liu",
                "Wenming Yang",
                "Yaowei Wang",
                "Qingmin Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09496v1",
                "http://arxiv.org/pdf/2309.09496v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09470v1",
            "title": "Face-Driven Zero-Shot Voice Conversion with Memory-based Face-Voice\n  Alignment",
            "updated": "2023-09-18T04:08:02Z",
            "published": "2023-09-18T04:08:02Z",
            "summary": "This paper presents a novel task, zero-shot voice conversion based on face\nimages (zero-shot FaceVC), which aims at converting the voice characteristics\nof an utterance from any source speaker to a newly coming target speaker,\nsolely relying on a single face image of the target speaker. To address this\ntask, we propose a face-voice memory-based zero-shot FaceVC method. This method\nleverages a memory-based face-voice alignment module, in which slots act as the\nbridge to align these two modalities, allowing for the capture of voice\ncharacteristics from face images. A mixed supervision strategy is also\nintroduced to mitigate the long-standing issue of the inconsistency between\ntraining and inference phases for voice conversion tasks. To obtain\nspeaker-independent content-related representations, we transfer the knowledge\nfrom a pretrained zero-shot voice conversion model to our zero-shot FaceVC\nmodel. Considering the differences between FaceVC and traditional voice\nconversion tasks, systematic subjective and objective metrics are designed to\nthoroughly evaluate the homogeneity, diversity and consistency of voice\ncharacteristics controlled by face images. Through extensive experiments, we\ndemonstrate the superiority of our proposed method on the zero-shot FaceVC\ntask. Samples are presented on our demo website.",
            "author": [
                "Zheng-Yan Sheng",
                "Yang Ai",
                "Yan-Nian Chen",
                "Zhen-Hua Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09470v1",
                "http://arxiv.org/pdf/2309.09470v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09468v1",
            "title": "Thermodynamics of imbibition in capillaries of double conical\n  structures-Hourglass, diamond, and sawtooth shaped capillaries-",
            "updated": "2023-09-18T04:02:06Z",
            "published": "2023-09-18T04:02:06Z",
            "summary": "Thermodynamics of imbibition (intrusion and extrusion) in capillaries of\ndouble conical structures is theoretically studied using the classical\ncapillary model. By extending the knowledge of the thermodynamics of a single\nconical capillary, not only the nature of spontaneous imbibition but that of\nforced imbibition under applied external pressure are clarified. Spontaneous\nimbibition in capillaries of double conical structure can be predicted from the\nLaplace pressure in a single conical capillary. To understand the forced\nimbibition process, the free energy landscape along the imbibition pathway is\ncalculated. This landscape shows either a maximum or a minimum. The former acts\nas the energy barrier and the latter acts as the trap for the liquid-vapor\nmeniscus so that the imbibition process can be either abrupt with a pressure\nhysteresis or gradual and continuous. The landscape also predicts a completely\nfilled, a half-filled and a completely empty state as the thermodynamically\nstable state. Furthermore, it also predicts a completely filled and a\nhalf-filled state of metastable liquid which can be prepared by the combination\nof the intrusion and the extrusion process. Our study could be useful for\nunderstanding various natural fluidic systems and for designing functional\nfluidic devices such as a diode, a switch etc.",
            "author": [
                "Masao Iwamatsu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09468v1",
                "http://arxiv.org/pdf/2309.09468v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09467v2",
            "title": "A model of stochastic memoization and name generation in probabilistic\n  programming: categorical semantics via monads on presheaf categories",
            "updated": "2023-11-21T14:28:35Z",
            "published": "2023-09-18T04:02:03Z",
            "summary": "Stochastic memoization is a higher-order construct of probabilistic\nprogramming languages that is key in Bayesian nonparametrics, a modular\napproach that allows us to extend models beyond their parametric limitations\nand compose them in an elegant and principled manner. Stochastic memoization is\nsimple and useful in practice, but semantically elusive, particularly regarding\ndataflow transformations. As the naive implementation resorts to the state\nmonad, which is not commutative, it is not clear if stochastic memoization\npreserves the dataflow property -- i.e., whether we can reorder the lines of a\nprogram without changing its semantics, provided the dataflow graph is\npreserved. In this paper, we give an operational and categorical semantics to\nstochastic memoization and name generation in the context of a minimal\nprobabilistic programming language, for a restricted class of functions. Our\ncontribution is a first model of stochastic memoization of constant Bernoulli\nfunctions with a non-enumerable type, which validates data flow\ntransformations, bridging the gap between traditional probability theory and\nhigher-order probability models. Our model uses a presheaf category and a novel\nprobability monad on it.",
            "author": [
                "Younesse Kaddar",
                "Sam Staton"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09467v2",
                "http://arxiv.org/pdf/2309.09467v2"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09457v2",
            "title": "Exploring and Learning in Sparse Linear MDPs without Computationally\n  Intractable Oracles",
            "updated": "2023-09-19T01:56:24Z",
            "published": "2023-09-18T03:35:48Z",
            "summary": "The key assumption underlying linear Markov Decision Processes (MDPs) is that\nthe learner has access to a known feature map $\\phi(x, a)$ that maps\nstate-action pairs to $d$-dimensional vectors, and that the rewards and\ntransitions are linear functions in this representation. But where do these\nfeatures come from? In the absence of expert domain knowledge, a tempting\nstrategy is to use the ``kitchen sink\" approach and hope that the true features\nare included in a much larger set of potential features. In this paper we\nrevisit linear MDPs from the perspective of feature selection. In a $k$-sparse\nlinear MDP, there is an unknown subset $S \\subset [d]$ of size $k$ containing\nall the relevant features, and the goal is to learn a near-optimal policy in\nonly poly$(k,\\log d)$ interactions with the environment. Our main result is the\nfirst polynomial-time algorithm for this problem. In contrast, earlier works\neither made prohibitively strong assumptions that obviated the need for\nexploration, or required solving computationally intractable optimization\nproblems.\n  Along the way we introduce the notion of an emulator: a succinct approximate\nrepresentation of the transitions that suffices for computing certain Bellman\nbackups. Since linear MDPs are a non-parametric model, it is not even obvious\nwhether polynomial-sized emulators exist. We show that they do exist and can be\ncomputed efficiently via convex programming.\n  As a corollary of our main result, we give an algorithm for learning a\nnear-optimal policy in block MDPs whose decoding function is a low-depth\ndecision tree; the algorithm runs in quasi-polynomial time and takes a\npolynomial number of samples. This can be seen as a reinforcement learning\nanalogue of classic results in computational learning theory. Furthermore, it\ngives a natural model where improving the sample complexity via representation\nlearning is computationally feasible.",
            "author": [
                "Noah Golowich",
                "Ankur Moitra",
                "Dhruv Rohatgi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09457v2",
                "http://arxiv.org/pdf/2309.09457v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DS",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09455v2",
            "title": "CaT: Balanced Continual Graph Learning with Graph Condensation",
            "updated": "2023-09-19T01:00:15Z",
            "published": "2023-09-18T03:28:49Z",
            "summary": "Continual graph learning (CGL) is purposed to continuously update a graph\nmodel with graph data being fed in a streaming manner. Since the model easily\nforgets previously learned knowledge when training with new-coming data, the\ncatastrophic forgetting problem has been the major focus in CGL. Recent\nreplay-based methods intend to solve this problem by updating the model using\nboth (1) the entire new-coming data and (2) a sampling-based memory bank that\nstores replayed graphs to approximate the distribution of historical data.\nAfter updating the model, a new replayed graph sampled from the incoming graph\nwill be added to the existing memory bank. Despite these methods are intuitive\nand effective for the CGL, two issues are identified in this paper. Firstly,\nmost sampling-based methods struggle to fully capture the historical\ndistribution when the storage budget is tight. Secondly, a significant data\nimbalance exists in terms of the scales of the complex new-coming graph data\nand the lightweight memory bank, resulting in unbalanced training. To solve\nthese issues, a Condense and Train (CaT) framework is proposed in this paper.\nPrior to each model update, the new-coming graph is condensed to a small yet\ninformative synthesised replayed graph, which is then stored in a Condensed\nGraph Memory with historical replay graphs. In the continual learning phase, a\nTraining in Memory scheme is used to update the model directly with the\nCondensed Graph Memory rather than the whole new-coming graph, which alleviates\nthe data imbalance problem. Extensive experiments conducted on four benchmark\ndatasets successfully demonstrate superior performances of the proposed CaT\nframework in terms of effectiveness and efficiency. The code has been released\non https://github.com/superallen13/CaT-CGL.",
            "author": [
                "Yilun Liu",
                "Ruihong Qiu",
                "Zi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09455v2",
                "http://arxiv.org/pdf/2309.09455v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09444v1",
            "title": "Investigating Zero- and Few-shot Generalization in Fact Verification",
            "updated": "2023-09-18T02:53:12Z",
            "published": "2023-09-18T02:53:12Z",
            "summary": "In this paper, we explore zero- and few-shot generalization for fact\nverification (FV), which aims to generalize the FV model trained on\nwell-resourced domains (e.g., Wikipedia) to low-resourced domains that lack\nhuman annotations. To this end, we first construct a benchmark dataset\ncollection which contains 11 FV datasets representing 6 domains. We conduct an\nempirical analysis of generalization across these FV datasets, finding that\ncurrent models generalize poorly. Our analysis reveals that several factors\naffect generalization, including dataset size, length of evidence, and the type\nof claims. Finally, we show that two directions of work improve generalization:\n1) incorporating domain knowledge via pretraining on specialized domains, and\n2) automatically generating training data via claim generation.",
            "author": [
                "Liangming Pan",
                "Yunxiang Zhang",
                "Min-Yen Kan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09444v1",
                "http://arxiv.org/pdf/2309.09444v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.10008v1",
            "title": "DeepHEN: quantitative prediction essential lncRNA genes and rethinking\n  essentialities of lncRNA genes",
            "updated": "2023-09-18T02:46:33Z",
            "published": "2023-09-18T02:46:33Z",
            "summary": "Gene essentiality refers to the degree to which a gene is necessary for the\nsurvival and reproductive efficacy of a living organism. Although the\nessentiality of non-coding genes has been documented, there are still aspects\nof non-coding genes' essentiality that are unknown to us. For example, We do\nnot know the contribution of sequence features and network spatial features to\nessentiality. As a consequence, in this work, we propose DeepHEN that could\nanswer the above question. By buidling a new lncRNA-proteion-protein network\nand utilizing both representation learning and graph neural network, we\nsuccessfully build our DeepHEN models that could predict the essentiality of\nlncRNA genes. Compared to other methods for predicting the essentiality of\nlncRNA genes, our DeepHEN model not only tells whether sequence features or\nnetwork spatial features have a greater influence on essentiality but also\naddresses the overfitting issue of those methods caused by the low number of\nessential lncRNA genes, as evidenced by the results of enrichment analysis.",
            "author": [
                "Hanlin Zhang",
                "Wenzheng Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.10008v1",
                "http://arxiv.org/pdf/2309.10008v1"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09432v1",
            "title": "Entire solutions of two-convex Lagrangian mean curvature flows",
            "updated": "2023-09-18T02:20:09Z",
            "published": "2023-09-18T02:20:09Z",
            "summary": "Given an entire $C^2$ function $u$ on $\\mathbb{R}^n$, we consider the graph\nof $D u$ as a Lagrangian submanifold of $\\mathbb{R}^{2n}$, and deform it by the\nmean curvature flow in $\\mathbb{R}^{2n}$. This leads to the special Lagrangian\nevolution equation, a fully nonlinear Hessian type PDE. We prove long-time\nexistence and convergence results under a 2-positivity assumption of $(I+(D^2\nu)^2)^{-1}D^2 u$. Such results were previously known only under the stronger\nassumption of positivity of $D^2 u$.",
            "author": [
                "Chung-Jun Tsai",
                "Mao-Pei Tsui",
                "Mu-Tao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09432v1",
                "http://arxiv.org/pdf/2309.09432v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "53C44"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09422v1",
            "title": "Desensitization and Deception in Differential Games with Asymmetric\n  Information",
            "updated": "2023-09-18T01:43:27Z",
            "published": "2023-09-18T01:43:27Z",
            "summary": "Desensitization addresses safe optimal planning under parametric\nuncertainties by providing sensitivity function-based risk measures. This paper\nexpands upon the existing work on desensitization to address safe planning for\na class of two-player differential games. In the proposed game, parametric\nuncertainties correspond to variations in a vector of model parameters about\nits nominal value. The two players in the proposed formulation are assumed to\nhave information about the nominal value of the parameter vector. However, only\none of the players is assumed to have complete knowledge of parametric\nvariation, creating a form of information asymmetry in the proposed game. The\nlack of knowledge regarding the parametric variations is expected to result in\nstate constraint violations for the player with an information disadvantage. In\nthis regard, a desensitized feedback strategy that provides safe trajectories\nis proposed for the player with incomplete information. The proposed feedback\nstrategy is evaluated in instances involving one pursuer and one evader with an\nuncertain dynamic obstacle, where the pursuer is assumed to know only the\nnominal value of the obstacle's speed. At the same time, the evader knows the\nobstacle's true speed, and also the fact that the pursuer possesses only the\nnominal value. Subsequently, deceptive strategies are proposed for the evader,\nwho has an information advantage, and these strategies are assessed against the\npursuer's desensitized strategy.",
            "author": [
                "Vinodhini Comandur",
                "Tulasi Ram Vechalapu",
                "Venkata Ramana Makkapati",
                "Seth Hutchinson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09422v1",
                "http://arxiv.org/pdf/2309.09422v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.RO",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09421v1",
            "title": "Unified Pretraining Target Based Video-music Retrieval With Music Rhythm\n  And Video Optical Flow Information",
            "updated": "2023-09-18T01:42:48Z",
            "published": "2023-09-18T01:42:48Z",
            "summary": "Background music (BGM) can enhance the video's emotion. However, selecting an\nappropriate BGM often requires domain knowledge. This has led to the\ndevelopment of video-music retrieval techniques. Most existing approaches\nutilize pretrained video/music feature extractors trained with different target\nsets to obtain average video/music-level embeddings. The drawbacks are\ntwo-fold. One is that different target sets for video/music pretraining may\ncause the generated embeddings difficult to match. The second is that the\nunderlying temporal correlation between video and music is ignored. In this\npaper, our proposed approach leverages a unified target set to perform\nvideo/music pretraining and produces clip-level embeddings to preserve temporal\ninformation. The downstream cross-modal matching is based on the clip-level\nfeatures with embedded music rhythm and optical flow information. Experiments\ndemonstrate that our proposed method can achieve superior performance over the\nstate-of-the-art methods by a significant margin.",
            "author": [
                "Tianjun Mao",
                "Shansong Liu",
                "Yunxuan Zhang",
                "Dian Li",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09421v1",
                "http://arxiv.org/pdf/2309.09421v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09420v1",
            "title": "Discovery and inference of a causal network with hidden confounding",
            "updated": "2023-09-18T01:42:06Z",
            "published": "2023-09-18T01:42:06Z",
            "summary": "This article proposes a novel causal discovery and inference method called\nGrIVET for a Gaussian directed acyclic graph with unmeasured confounders.\nGrIVET consists of an order-based causal discovery method and a\nlikelihood-based inferential procedure. For causal discovery, we generalize the\nexisting peeling algorithm to estimate the ancestral relations and candidate\ninstruments in the presence of hidden confounders. Based on this, we propose a\nnew procedure for instrumental variable estimation of each direct effect by\nseparating it from any mediation effects. For inference, we develop a new\nlikelihood ratio test of multiple causal effects that is able to account for\nthe unmeasured confounders. Theoretically, we prove that the proposed method\nhas desirable guarantees, including robustness to invalid instruments and\nuncertain interventions, estimation consistency, low-order polynomial time\ncomplexity, and validity of asymptotic inference. Numerically, GrIVET performs\nwell and compares favorably against state-of-the-art competitors. Furthermore,\nwe demonstrate the utility and effectiveness of the proposed method through an\napplication inferring regulatory pathways from Alzheimer's disease gene\nexpression data.",
            "author": [
                "Li Chen",
                "Chunlin Li",
                "Xiaotong Shen",
                "Wei Pan"
            ],
            "link": [
                "http://dx.doi.org/10.1080/01621459.2023.2261658",
                "http://arxiv.org/abs/2309.09420v1",
                "http://arxiv.org/pdf/2309.09420v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09416v1",
            "title": "Causal Discovery and Prediction: Methods and Algorithms",
            "updated": "2023-09-18T01:19:37Z",
            "published": "2023-09-18T01:19:37Z",
            "summary": "We are not only observers but also actors of reality. Our capability to\nintervene and alter the course of some events in the space and time surrounding\nus is an essential component of how we build our model of the world. In this\ndoctoral thesis we introduce a generic a-priori assessment of each possible\nintervention, in order to select the most cost-effective interventions only,\nand avoid unnecessary systematic experimentation on the real world. Based on\nthis a-priori assessment, we propose an active learning algorithm that\nidentifies the causal relations in any given causal model, using a least cost\nsequence of interventions. There are several novel aspects introduced by our\nalgorithm. It is, in most case scenarios, able to discard many causal model\ncandidates using relatively inexpensive interventions that only test one value\nof the intervened variables. Also, the number of interventions performed by the\nalgorithm can be bounded by the number of causal model candidates. Hence, fewer\ninitial candidates (or equivalently, more prior knowledge) lead to fewer\ninterventions for causal discovery.\n  Causality is intimately related to time, as causes appear to precede their\neffects. Cyclical causal processes are a very interesting case of causality in\nrelation to time. In this doctoral thesis we introduce a formal analysis of\ntime cyclical causal settings by defining a causal analog to the purely\nobservational Dynamic Bayesian Networks, and provide a sound and complete\nalgorithm for the identification of causal effects in the cyclic setting. We\nintroduce the existence of two types of hidden confounder variables in this\nframework, which affect in substantially different ways the identification\nprocedures, a distinction with no analog in either Dynamic Bayesian Networks or\nstandard causal graphs.",
            "author": [
                "Gilles Blondel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09416v1",
                "http://arxiv.org/pdf/2309.09416v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09410v1",
            "title": "BRONCO: Automated modelling of the bronchovascular bundle using the\n  Computed Tomography Images",
            "updated": "2023-09-18T00:38:25Z",
            "published": "2023-09-18T00:38:25Z",
            "summary": "Segmentation of the bronchovascular bundle within the lung parenchyma is a\nkey step for the proper analysis and planning of many pulmonary diseases. It\nmight also be considered the preprocessing step when the goal is to segment the\nnodules from the lung parenchyma. We propose a segmentation pipeline for the\nbronchovascular bundle based on the Computed Tomography images, returning\neither binary or labelled masks of vessels and bronchi situated in the lung\nparenchyma. The method consists of two modules, modeling of the bronchial tree\nand vessels. The core revolves around a similar pipeline, the determination of\nthe initial perimeter by the GMM method, skeletonization, and hierarchical\nanalysis of the created graph. We tested our method on both low-dose CT and\nstandard-dose CT, with various pathologies, reconstructed with various slice\nthicknesses, and acquired from various machines. We conclude that the method is\ninvariant with respect to the origin and parameters of the CT series. Our\npipeline is best suited for studies with healthy patients, patients with lung\nnodules, and patients with emphysema.",
            "author": [
                "Wojciech Pra\u017cuch",
                "Marek Socha",
                "Anna Mrukwa",
                "Aleksandra Suwalska",
                "Agata Durawa",
                "Malgorzata Jelitto-G\u00f3rska",
                "Katarzyna Dziadziuszko",
                "Edyta Szurowska",
                "Pawel Bo\u017cek",
                "Michal Marczyk",
                "Witold Rzyman",
                "Joanna Polanska"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09410v1",
                "http://arxiv.org/pdf/2309.09410v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09401v1",
            "title": "ChatGPT Hallucinates when Attributing Answers",
            "updated": "2023-09-17T23:49:12Z",
            "published": "2023-09-17T23:49:12Z",
            "summary": "Can ChatGPT provide evidence to support its answers? Does the evidence it\nsuggests actually exist and does it really support its answer? We investigate\nthese questions using a collection of domain-specific knowledge-based\nquestions, specifically prompting ChatGPT to provide both an answer and\nsupporting evidence in the form of references to external sources. We also\ninvestigate how different prompts impact answers and evidence. We find that\nChatGPT provides correct or partially correct answers in about half of the\ncases (50.6% of the times), but its suggested references only exist 14% of the\ntimes. We further provide insights on the generated references that reveal\ncommon traits among the references that ChatGPT generates, and show how even if\na reference provided by the model does exist, this reference often does not\nsupport the claims ChatGPT attributes to it. Our findings are important because\n(1) they are the first systematic analysis of the references created by ChatGPT\nin its answers; (2) they suggest that the model may leverage good quality\ninformation in producing correct answers, but is unable to attribute real\nevidence to support its answers. Prompts, raw result files and manual analysis\nare made publicly available.",
            "author": [
                "Guido Zuccon",
                "Bevan Koopman",
                "Razia Shaik"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09401v1",
                "http://arxiv.org/pdf/2309.09401v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09386v1",
            "title": "Axioms for Distanceless Graph Partitioning",
            "updated": "2023-09-17T21:52:30Z",
            "published": "2023-09-17T21:52:30Z",
            "summary": "In 2002, Kleinberg proposed three axioms for distance-based clustering, and\nproved that it was impossible for a clustering method to satisfy all three.\nWhile there has been much subsequent work examining and modifying these axioms\nfor distance-based clustering, little work has been done to explore axioms\nrelevant to the graph partitioning problem, i.e., when the graph is given\nwithout a distance matrix. Here, we propose and explore axioms for graph\npartitioning when given graphs without distance matrices, including\nmodifications of Kleinberg's axioms for the distanceless case and two others\n(one axiom relevant to the ''Resolution Limit'' and one addressing\nwell-connectedness). We prove that clustering under the Constant Potts Model\nsatisfies all the axioms, while Modularity clustering and Iterative k-core both\nfail many axioms we pose. These theoretical properties of the clustering\nmethods are relevant both for theoretical investigation as well as to\npractitioners considering which methods to use for their domain science\nstudies.",
            "author": [
                "James Willson",
                "Tandy Warnow"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09386v1",
                "http://arxiv.org/pdf/2309.09386v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09384v2",
            "title": "Mitigating Over-Smoothing and Over-Squashing using Augmentations of\n  Forman-Ricci Curvature",
            "updated": "2023-11-24T00:25:38Z",
            "published": "2023-09-17T21:43:18Z",
            "summary": "While Graph Neural Networks (GNNs) have been successfully leveraged for\nlearning on graph-structured data across domains, several potential pitfalls\nhave been described recently. Those include the inability to accurately\nleverage information encoded in long-range connections (over-squashing), as\nwell as difficulties distinguishing the learned representations of nearby nodes\nwith growing network depth (over-smoothing). An effective way to characterize\nboth effects is discrete curvature: Long-range connections that underlie\nover-squashing effects have low curvature, whereas edges that contribute to\nover-smoothing have high curvature. This observation has given rise to rewiring\ntechniques, which add or remove edges to mitigate over-smoothing and\nover-squashing. Several rewiring approaches utilizing graph characteristics,\nsuch as curvature or the spectrum of the graph Laplacian, have been proposed.\nHowever, existing methods, especially those based on curvature, often require\nexpensive subroutines and careful hyperparameter tuning, which limits their\napplicability to large-scale graphs. Here we propose a rewiring technique based\non Augmented Forman-Ricci curvature (AFRC), a scalable curvature notation,\nwhich can be computed in linear time. We prove that AFRC effectively\ncharacterizes over-smoothing and over-squashing effects in message-passing\nGNNs. We complement our theoretical results with experiments, which demonstrate\nthat the proposed approach achieves state-of-the-art performance while\nsignificantly reducing the computational cost in comparison with other methods.\nUtilizing fundamental properties of discrete curvature, we propose effective\nheuristics for hyperparameters in curvature-based rewiring, which avoids\nexpensive hyperparameter searches, further improving the scalability of the\nproposed approach.",
            "author": [
                "Lukas Fesser",
                "Melanie Weber"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09384v2",
                "http://arxiv.org/pdf/2309.09384v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09377v1",
            "title": "Frequency-Domain Detection for Molecular Communication with\n  Cross-Reactive Receptors",
            "updated": "2023-09-17T20:53:42Z",
            "published": "2023-09-17T20:53:42Z",
            "summary": "Molecular Communications (MC) is a bio-inspired communication paradigm that\nuses molecules as information carriers, requiring unconventional transceivers\nand modulation/detection techniques. Practical MC receivers (MC-Rxs) can be\nimplemented using field-effect transistor biosensor (bioFET) architectures,\nwhere surface receptors reversibly react with ligands. The time-varying\nconcentration of ligand-bound receptors is translated into electrical signals\nvia field effect, which is used to decode the transmitted information. However,\nligand-receptor interactions do not provide an ideal molecular selectivity, as\nsimilar ligand types, i.e., interferers, co-existing in the MC channel, can\ninteract with the same type of receptors. Overcoming this molecular cross-talk\nin the time domain can be challenging, especially when Rx has no knowledge of\nthe interferer statistics or operates near saturation. Therefore, we propose a\nfrequency-domain detection (FDD) technique for bioFET-based MC-Rxs that\nexploits the difference in binding reaction rates of different ligand types\nreflected in the power spectrum of the ligand-receptor binding noise. We derive\nthe bit error probability (BEP) of the FDD technique and demonstrate its\neffectiveness in decoding transmitted concentration signals under stochastic\nmolecular interference compared to a widely used time-domain detection (TDD)\ntechnique. We then verified the analytical performance bounds of the FDD\nthrough a particle-based spatial stochastic simulator simulating reactions on\nthe MC-Rx in microfluidic channels.",
            "author": [
                "Meltem Civas",
                "Murat Kuscu",
                "Ozgur B. Akan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09377v1",
                "http://arxiv.org/pdf/2309.09377v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09369v1",
            "title": "Embrace Divergence for Richer Insights: A Multi-document Summarization\n  Benchmark and a Case Study on Summarizing Diverse Information from News\n  Articles",
            "updated": "2023-09-17T20:28:17Z",
            "published": "2023-09-17T20:28:17Z",
            "summary": "Previous research in multi-document news summarization has typically\nconcentrated on collating information that all sources agree upon. However, to\nour knowledge, the summarization of diverse information dispersed across\nmultiple articles about an event has not been previously investigated. The\nlatter imposes a different set of challenges for a summarization model. In this\npaper, we propose a new task of summarizing diverse information encountered in\nmultiple news articles encompassing the same event. To facilitate this task, we\noutlined a data collection schema for identifying diverse information and\ncurated a dataset named DiverseSumm. The dataset includes 245 news stories,\nwith each story comprising 10 news articles and paired with a human-validated\nreference. Moreover, we conducted a comprehensive analysis to pinpoint the\nposition and verbosity biases when utilizing Large Language Model (LLM)-based\nmetrics for evaluating the coverage and faithfulness of the summaries, as well\nas their correlation with human assessments. We applied our findings to study\nhow LLMs summarize multiple news articles by analyzing which type of diverse\ninformation LLMs are capable of identifying. Our analyses suggest that despite\nthe extraordinary capabilities of LLMs in single-document summarization, the\nproposed task remains a complex challenge for them mainly due to their limited\ncoverage, with GPT-4 only able to cover less than 40% of the diverse\ninformation on average.",
            "author": [
                "Kung-Hsiang Huang",
                "Philippe Laban",
                "Alexander R. Fabbri",
                "Prafulla Kumar Choubey",
                "Shafiq Joty",
                "Caiming Xiong",
                "Chien-Sheng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09369v1",
                "http://arxiv.org/pdf/2309.09369v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09360v1",
            "title": "Non-negative Matrix Factorization using Partial Prior Knowledge for\n  Radiation Dosimetry",
            "updated": "2023-09-17T19:50:52Z",
            "published": "2023-09-17T19:50:52Z",
            "summary": "Hyperspectral unmixing aims at decomposing a given signal into its spectral\nsignatures and its associated fractional abundances. To improve the accuracy of\nthis decomposition, algorithms have included different assumptions depending on\nthe application. The goal of this study is to develop a new unmixing algorithm\nthat can be applied for the calibration of multi-point scintillation dosimeters\nused in the field of radiation therapy. This new algorithm is based on a\nnon-negative matrix factorization. It incorporates a partial prior knowledge on\nboth the abundances and the endmembers of a given signal. It is shown herein\nthat, following a precise calibration routine, it is possible to use partial\nprior information about the fractional abundances, as well as on the\nendmembers, in order to perform a simplified yet precise calibration of these\ndosimeters. Validation and characterization of this algorithm is made using\nboth simulations and experiments. The experimental validation shows an\nimprovement in accuracy compared to previous algorithms with a mean spectral\nangle distance (SAD) on the estimated endmembers of 0.0766, leading to an\naverage error of $(0.25 \\pm 0.73)$ % on dose measurements.",
            "author": [
                "Boby Lessard",
                "Fr\u00e9d\u00e9ric Marcotte",
                "Arthur Lalonde",
                "Fran\u00e7ois Therriault-Proulx",
                "Simon Lambert-Girard",
                "Luc Beaulieu",
                "Louis Archambault"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09360v1",
                "http://arxiv.org/pdf/2309.09360v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09345v1",
            "title": "On the structure of a smallest counterexample and a new class verifying\n  the 2-Decomposition Conjecture",
            "updated": "2023-09-17T18:39:11Z",
            "published": "2023-09-17T18:39:11Z",
            "summary": "The 2-Decomposition Conjecture, equivalent to the 3-Decomposition Conjecture\nstated in 2011 by Hoffmann-Ostenhof, claims that every connected graph $G$ with\nvertices of degree 2 and 3, for which $G \\setminus E(C)$ is disconnected for\nevery cycle $C$, admits a decomposition into a spanning tree and a matching. In\nthis work we present two main results focused on developing a strategy to prove\nthe 2-Decomposition Conjecture. One of them is a list of structural properties\nof a minimum counterexample for this conjecture. Among those properties, we\nprove that a minimum counterexample has girth at least 5 and its vertices of\ndegree 2 are at distance at least 3. Motivated by the class of smallest\ncounterexamples, we show that the 2-Decomposition Conjecture holds for graphs\nwhose vertices of degree 3 induce a collection of cacti in which each vertex\nbelongs to a cycle. The core of the proof of this result may possibly be used\nin an inductive proof of the 2-Decomposition Conjecture based on a parameter\nthat relates the number of vertices of degree 2 and 3 in a minimum\ncounterexample.",
            "author": [
                "F. Botler",
                "A. Jim\u00e9nez",
                "M. Sambinelli",
                "Y. Wakabayashi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09345v1",
                "http://arxiv.org/pdf/2309.09345v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09344v1",
            "title": "Efficient Belief Road Map for Planning Under Uncertainty",
            "updated": "2023-09-17T18:22:46Z",
            "published": "2023-09-17T18:22:46Z",
            "summary": "Robotic systems, particularly in demanding environments like narrow corridors\nor disaster zones, often grapple with imperfect state estimation. Addressing\nthis challenge requires a trajectory plan that not only navigates these\nrestrictive spaces but also manages the inherent uncertainty of the system. We\npresent a novel approach for graph-based belief space planning via the use of\nan efficient covariance control algorithm. By adaptively steering state\nstatistics via output state feedback, we efficiently craft a belief roadmap\ncharacterized by nodes with controlled uncertainty and edges representing\ncollision-free mean trajectories. The roadmap's structured design then paves\nthe way for precise path searches that balance control costs and uncertainty\nconsiderations. Our numerical experiments affirm the efficacy and advantage of\nour method in different motion planning tasks. Our open-source implementation\ncan be found at https://github.com/hzyu17/VIMP/tree/BRM.",
            "author": [
                "Zhenyang Chen",
                "Hongzhe Yu",
                "Yongxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09344v1",
                "http://arxiv.org/pdf/2309.09344v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09334v1",
            "title": "Off the Beaten Track: Laterally Weighted Motion Planning for Local\n  Obstacle Avoidance",
            "updated": "2023-09-17T17:48:27Z",
            "published": "2023-09-17T17:48:27Z",
            "summary": "We extend the behaviour of generic sample-based motion planners to support\nobstacle avoidance during long-range path following by introducing a new\nedge-cost metric paired with a curvilinear planning space. The resulting\nplanner generates naturally smooth paths that avoid local obstacles while\nminimizing lateral path deviation to best exploit prior terrain knowledge from\nthe reference path. In this adaptation, we explore the nuances of planning in\nthe curvilinear configuration space and describe a mechanism for natural\nsingularity handling to improve generality. We then shift our focus to the\ntrajectory generation problem, proposing a novel Model Predictive Control (MPC)\narchitecture to best exploit our path planner for improved obstacle avoidance.\nThrough rigorous field robotics trials over 5 km, we compare our approach to\nthe more common direct path-tracking MPC method and discuss the promise of\nthese techniques for reliable long-term autonomous operations.",
            "author": [
                "Jordy Sehn",
                "Jack Collier",
                "Timothy D. Barfoot"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09334v1",
                "http://arxiv.org/pdf/2309.09334v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09326v1",
            "title": "Experiential-Informed Data Reconstruction for Fishery Sustainability and\n  Policies in the Azores",
            "updated": "2023-09-17T17:17:38Z",
            "published": "2023-09-17T17:17:38Z",
            "summary": "Fishery analysis is critical in maintaining the long-term sustainability of\nspecies and the livelihoods of millions of people who depend on fishing for\nfood and income. The fishing gear, or metier, is a key factor significantly\nimpacting marine habitats, selectively targeting species and fish sizes.\nAnalysis of commercial catches or landings by metier in fishery stock\nassessment and management is crucial, providing robust estimates of fishing\nefforts and their impact on marine ecosystems. In this paper, we focus on a\nunique data set from the Azores' fishing data collection programs between 2010\nand 2017, where little information on metiers is available and sparse\nthroughout our timeline. Our main objective is to tackle the task of data set\nreconstruction, leveraging domain knowledge and machine learning methods to\nretrieve or associate metier-related information to each fish landing. We\nempirically validate the feasibility of this task using a diverse set of\nmodeling approaches and demonstrate how it provides new insights into different\nfisheries' behavior and the impact of metiers over time, which are essential\nfor future fish population assessments, management, and conservation efforts.",
            "author": [
                "Brenda Nogueira",
                "Gui M. Menezes",
                "Nuno Moniz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09326v1",
                "http://arxiv.org/pdf/2309.09326v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09323v2",
            "title": "Answering Layer 3 queries with DiscoSCMs",
            "updated": "2023-10-13T08:58:46Z",
            "published": "2023-09-17T17:01:05Z",
            "summary": "Addressing causal queries across the Pearl Causal Hierarchy (PCH) (i.e.,\nassociational, interventional and counterfactual), which is formalized as\n\\Layer{} Valuations, is a central task in contemporary causal inference\nresearch. Counterfactual questions, in particular, pose a significant challenge\nas they often necessitate a complete knowledge of structural equations. This\npaper identifies \\textbf{the degeneracy problem} caused by the consistency\nrule. To tackle this, the \\textit{Distribution-consistency Structural Causal\nModels} (DiscoSCMs) is introduced, which extends both the structural causal\nmodels (SCM) and the potential outcome framework. The correlation pattern of\npotential outcomes in personalized incentive scenarios, described by $P(y_x,\ny'_{x'})$, is used as a case study for elucidation. Although counterfactuals\nare no longer degenerate, they remain indeterminable. As a result, the\ncondition of independent potential noise is incorporated into DiscoSCM. It is\nfound that by adeptly using homogeneity, counterfactuals can be identified.\nFurthermore, more refined results are achieved in the unit problem scenario. In\nsimpler terms, when modeling counterfactuals, one should contemplate: \"Consider\na person with average ability who takes a test and, due to good luck, achieves\nan exceptionally high score. If this person were to retake the test under\nidentical external conditions, what score will he obtain? An exceptionally high\nscore or an average score?\" If your choose is predicting an average score, then\nyou are essentially choosing DiscoSCM over the traditional frameworks based on\nthe consistency rule.",
            "author": [
                "Heyang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09323v2",
                "http://arxiv.org/pdf/2309.09323v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09317v1",
            "title": "Kinematics-aware Trajectory Generation and Prediction with Latent\n  Stochastic Differential Modeling",
            "updated": "2023-09-17T16:06:38Z",
            "published": "2023-09-17T16:06:38Z",
            "summary": "Trajectory generation and trajectory prediction are two critical tasks for\nautonomous vehicles, which generate various trajectories during development and\npredict the trajectories of surrounding vehicles during operation,\nrespectively. However, despite significant advances in improving their\nperformance, it remains a challenging problem to ensure that the\ngenerated/predicted trajectories are realistic, explainable, and physically\nfeasible. Existing model-based methods provide explainable results, but are\nconstrained by predefined model structures, limiting their capabilities to\naddress complex scenarios. Conversely, existing deep learning-based methods\nhave shown great promise in learning various traffic scenarios and improving\noverall performance, but they often act as opaque black boxes and lack\nexplainability. In this work, we integrate kinematic knowledge with neural\nstochastic differential equations (SDE) and develop a variational autoencoder\nbased on a novel latent kinematics-aware SDE (LK-SDE) to generate vehicle\nmotions. Our approach combines the advantages of both model-based and deep\nlearning-based techniques. Experimental results demonstrate that our method\nsignificantly outperforms baseline approaches in producing realistic,\nphysically-feasible, and precisely-controllable vehicle trajectories,\nbenefiting both generation and prediction tasks.",
            "author": [
                "Ruochen Jiao",
                "Yixuan Wang",
                "Xiangguo Liu",
                "Chao Huang",
                "Qi Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09317v1",
                "http://arxiv.org/pdf/2309.09317v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09315v1",
            "title": "Privacy-Preserving Polynomial Computing Over Distributed Data",
            "updated": "2023-09-17T16:04:28Z",
            "published": "2023-09-17T16:04:28Z",
            "summary": "In this letter, we delve into a scenario where a user aims to compute\npolynomial functions using their own data as well as data obtained from\ndistributed sources. To accomplish this, the user enlists the assistance of $N$\ndistributed workers, thereby defining a problem we refer to as\nprivacy-preserving polynomial computing over distributed data. To address this\nchallenge, we propose an approach founded upon Lagrange encoding. Our method\nnot only possesses the ability to withstand the presence of stragglers and\nbyzantine workers but also ensures the preservation of security. Specifically,\neven if a coalition of $X$ workers collude, they are unable to acquire any\nknowledge pertaining to the data originating from the distributed sources or\nthe user.",
            "author": [
                "Zhiquan Tan",
                "Dingli Yuan",
                "Zhongyi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09315v1",
                "http://arxiv.org/pdf/2309.09315v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09313v1",
            "title": "Transportation cost spaces and their embeddings into $L_1$, a Survey",
            "updated": "2023-09-17T16:00:30Z",
            "published": "2023-09-17T16:00:30Z",
            "summary": "These notes present a basic survey on Transportation cost spaces (aka\nLipschitzfree spaces, Wasserstein spaces) and their bi-Lipschitz and linear\nembeddings into $L_1$ spaces. To make these notes as self-contained as\npossible, we added the proofs of several relevant results from computational\ngraph theory in the appendix.",
            "author": [
                "Thomas Schlumprecht"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09313v1",
                "http://arxiv.org/pdf/2309.09313v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "46B85, 68R12, 46B20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09311v1",
            "title": "Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal\n  Intervention",
            "updated": "2023-09-17T15:58:27Z",
            "published": "2023-09-17T15:58:27Z",
            "summary": "Many studies focus on improving pretraining or developing new backbones in\ntext-video retrieval. However, existing methods may suffer from the learning\nand inference bias issue, as recent research suggests in other\ntext-video-related tasks. For instance, spatial appearance features on action\nrecognition or temporal object co-occurrences on video scene graph generation\ncould induce spurious correlations. In this work, we present a unique and\nsystematic study of a temporal bias due to frame length discrepancy between\ntraining and test sets of trimmed video clips, which is the first such attempt\nfor a text-video retrieval task, to the best of our knowledge. We first\nhypothesise and verify the bias on how it would affect the model illustrated\nwith a baseline study. Then, we propose a causal debiasing approach and perform\nextensive experiments and ablation studies on the Epic-Kitchens-100, YouCook2,\nand MSR-VTT datasets. Our model overpasses the baseline and SOTA on nDCG, a\nsemantic-relevancy-focused evaluation metric which proves the bias is\nmitigated, as well as on the other conventional metrics.",
            "author": [
                "Burak Satar",
                "Hongyuan Zhu",
                "Hanwang Zhang",
                "Joo Hwee Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09311v1",
                "http://arxiv.org/pdf/2309.09311v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09305v1",
            "title": "Connectivity of Random Geometric Hypergraphs",
            "updated": "2023-09-17T15:39:10Z",
            "published": "2023-09-17T15:39:10Z",
            "summary": "We consider a random geometric hypergraph model based on an underlying\nbipartite graph. Nodes and hyperedges are sampled uniformly in a domain, and a\nnode is assigned to those hyperedges that lie with a certain radius. From a\nmodelling perspective, we explain how the model captures higher order\nconnections that arise in real data sets. Our main contribution is to study the\nconnectivity properties of the model. In an asymptotic limit where the number\nof nodes and hyperedges grow in tandem we give a condition on the radius that\nguarantees connectivity.",
            "author": [
                "Henry-Louis de Kergorlay",
                "Desmond J. Higham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09305v1",
                "http://arxiv.org/pdf/2309.09305v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.NA",
                "math.NA",
                "05C80",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09296v1",
            "title": "Model-based Subsampling for Knowledge Graph Completion",
            "updated": "2023-09-17T15:12:50Z",
            "published": "2023-09-17T15:12:50Z",
            "summary": "Subsampling is effective in Knowledge Graph Embedding (KGE) for reducing\noverfitting caused by the sparsity in Knowledge Graph (KG) datasets. However,\ncurrent subsampling approaches consider only frequencies of queries that\nconsist of entities and their relations. Thus, the existing subsampling\npotentially underestimates the appearance probabilities of infrequent queries\neven if the frequencies of their entities or relations are high. To address\nthis problem, we propose Model-based Subsampling (MBS) and Mixed Subsampling\n(MIX) to estimate their appearance probabilities through predictions of KGE\nmodels. Evaluation results on datasets FB15k-237, WN18RR, and YAGO3-10 showed\nthat our proposed subsampling methods actually improved the KG completion\nperformances for popular KGE models, RotatE, TransE, HAKE, ComplEx, and\nDistMult.",
            "author": [
                "Xincan Feng",
                "Hidetaka Kamigaito",
                "Katsuhiko Hayashi",
                "Taro Watanabe"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09296v1",
                "http://arxiv.org/pdf/2309.09296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09279v1",
            "title": "Sufficient conditions for fractional [a,b]-deleted graphs",
            "updated": "2023-09-17T14:07:23Z",
            "published": "2023-09-17T14:07:23Z",
            "summary": "Let $a$ and $b$ be two positive integers with $a\\leq b$, and let $G$ be a\ngraph with vertex set $V(G)$ and edge set $E(G)$. Let $h:E(G)\\rightarrow[0,1]$\nbe a function. If $a\\leq\\sum\\limits_{e\\in E_G(v)}{h(e)}\\leq b$ holds for every\n$v\\in V(G)$, then the subgraph of $G$ with vertex set $V(G)$ and edge set\n$F_h$, denoted by $G[F_h]$, is called a fractional $[a,b]$-factor of $G$ with\nindicator function $h$, where $E_G(v)$ denotes the set of edges incident with\n$v$ in $G$ and $F_h=\\{e\\in E(G):h(e)>0\\}$. A graph $G$ is defined as a\nfractional $[a,b]$-deleted graph if for any $e\\in E(G)$, $G-e$ contains a\nfractional $[a,b]$-factor. The size, spectral radius and signless Laplacian\nspectral radius of $G$ are denoted by $e(G)$, $\\rho(G)$ and $q(G)$,\nrespectively. In this paper, we establish a lower bound on the size, spectral\nradius and signless Laplacian spectral radius of a graph $G$ to guarantee that\n$G$ is a fractional $[a,b]$-deleted graph.",
            "author": [
                "Sizhong Zhou",
                "Yuli Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09279v1",
                "http://arxiv.org/pdf/2309.09279v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C70, 05C72"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09228v1",
            "title": "Hamiltonian path and Hamiltonian cycle are solvable in polynomial time\n  in graphs of bounded independence number",
            "updated": "2023-09-17T09:59:47Z",
            "published": "2023-09-17T09:59:47Z",
            "summary": "A Hamiltonian path (a Hamiltonian cycle) in a graph is a path (a cycle,\nrespectively) that traverses all of its vertices. The problems of deciding\ntheir existence in an input graph are well-known to be NP-complete, in fact,\nthey belong to the first problems shown to be computationally hard when the\ntheory of NP-completeness was being developed. A lot of research has been\ndevoted to the complexity of Hamiltonian path and Hamiltonian cycle problems\nfor special graph classes, yet only a handful of positive results are known.\nThe complexities of both of these problems have been open even for $4K_1$-free\ngraphs, i.e., graphs of independence number at most $3$. We answer this\nquestion in the general setting of graphs of bounded independence number.\n  We also consider a newly introduced problem called\n\\emph{Hamiltonian-$\\ell$-Linkage} which is related to the notions of a path\ncover and of a linkage in a graph. This problem asks if given $\\ell$ pairs of\nvertices in an input graph can be connected by disjoint paths that altogether\ntraverse all vertices of the graph. For $\\ell=1$, Hamiltonian-1-Linkage asks\nfor existence of a Hamiltonian path connecting a given pair of vertices. Our\nmain result reads that for every pair of integers $k$ and $\\ell$, the\nHamiltonian-$\\ell$-Linkage problem is polynomial time solvable for graphs of\nindependence number not exceeding $k$. We further complement this general\npolynomial time algorithm by a structural description of obstacles to\nHamiltonicity in graphs of independence number at most $k$ for small values of\n$k$.",
            "author": [
                "Nikola Jedli\u010dkov\u00e1",
                "Jan Kratochv\u00edl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09228v1",
                "http://arxiv.org/pdf/2309.09228v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09214v2",
            "title": "Logic of Awareness in Agent's Reasoning",
            "updated": "2023-09-21T07:18:51Z",
            "published": "2023-09-17T08:50:35Z",
            "summary": "The aim of this study is to formally express awareness for modeling practical\nagent communication. The notion of awareness has been proposed as a set of\npropositions for each agent, to which he/she pays attention, and has\ncontributed to avoiding \\textit{logical omniscience}. However, when an agent\nguesses another agent's knowledge states, what matters are not propositions but\nare accessible possible worlds. Therefore, we introduce a partition of possible\nworlds connected to awareness, that is an equivalence relation, to denote\n\\textit{indistinguishable} worlds. Our logic is called Awareness Logic with\nPartition ($\\mathcal{ALP}$). In this paper, we first show a running example to\nillustrate a practical social game. Thereafter, we introduce syntax and Kripke\nsemantics of the logic and prove its completeness. Finally, we outline an idea\nto incorporate some epistemic actions with dynamic operators that change the\nstate of awareness.",
            "author": [
                "Yudai Kubono",
                "Teeradaj Racharak",
                "Satoshi Tojo"
            ],
            "link": [
                "http://dx.doi.org/10.5220/0011630300003393",
                "http://arxiv.org/abs/2309.09214v2",
                "http://arxiv.org/pdf/2309.09214v2"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09212v1",
            "title": "RobotPerf: An Open-Source, Vendor-Agnostic, Benchmarking Suite for\n  Evaluating Robotics Computing System Performance",
            "updated": "2023-09-17T08:41:11Z",
            "published": "2023-09-17T08:41:11Z",
            "summary": "We introduce RobotPerf, a vendor-agnostic benchmarking suite designed to\nevaluate robotics computing performance across a diverse range of hardware\nplatforms using ROS 2 as its common baseline. The suite encompasses ROS 2\npackages covering the full robotics pipeline and integrates two distinct\nbenchmarking approaches: black-box testing, which measures performance by\neliminating upper layers and replacing them with a test application, and\ngrey-box testing, an application-specific measure that observes internal system\nstates with minimal interference. Our benchmarking framework provides\nready-to-use tools and is easily adaptable for the assessment of custom ROS 2\ncomputational graphs. Drawing from the knowledge of leading robot architects\nand system architecture experts, RobotPerf establishes a standardized approach\nto robotics benchmarking. As an open-source initiative, RobotPerf remains\ncommitted to evolving with community input to advance the future of\nhardware-accelerated robotics.",
            "author": [
                "V\u00edctor Mayoral-Vilches",
                "Jason Jabbour",
                "Yu-Shun Hsiao",
                "Zishen Wan",
                "Alejandra Mart\u00ednez-Fari\u00f1a",
                "Marti\u00f1o Crespo-\u00c1lvarez",
                "Matthew Stewart",
                "Juan Manuel Reina-Mu\u00f1oz",
                "Prateek Nagras",
                "Gaurav Vikhe",
                "Mohammad Bakhshalipour",
                "Martin Pinzger",
                "Stefan Rass",
                "Smruti Panigrahi",
                "Giulio Corradi",
                "Niladri Roy",
                "Phillip B. Gibbons",
                "Sabrina M. Neuman",
                "Brian Plancher",
                "Vijay Janapa Reddi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09212v1",
                "http://arxiv.org/pdf/2309.09212v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09206v1",
            "title": "Differentiable SLAM Helps Deep Learning-based LiDAR Perception Tasks",
            "updated": "2023-09-17T08:24:16Z",
            "published": "2023-09-17T08:24:16Z",
            "summary": "We investigate a new paradigm that uses differentiable SLAM architectures in\na self-supervised manner to train end-to-end deep learning models in various\nLiDAR based applications. To the best of our knowledge there does not exist any\nwork that leverages SLAM as a training signal for deep learning based models.\nWe explore new ways to improve the efficiency, robustness, and adaptability of\nLiDAR systems with deep learning techniques. We focus on the potential benefits\nof differentiable SLAM architectures for improving performance of deep learning\ntasks such as classification, regression as well as SLAM. Our experimental\nresults demonstrate a non-trivial increase in the performance of two deep\nlearning applications - Ground Level Estimation and Dynamic to Static LiDAR\nTranslation, when used with differentiable SLAM architectures. Overall, our\nfindings provide important insights that enhance the performance of LiDAR based\nnavigation systems. We demonstrate that this new paradigm of using SLAM Loss\nsignal while training LiDAR based models can be easily adopted by the\ncommunity.",
            "author": [
                "Prashant Kumar",
                "Dheeraj Vattikonda",
                "Vedang Bhupesh Shenvi Nadkarni",
                "Erqun Dong",
                "Sabyasachi Sahoo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09206v1",
                "http://arxiv.org/pdf/2309.09206v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09199v1",
            "title": "Matroid, Ideal, Ultrafilter, Tangle, and so on: Reconsideration of\n  Obstruction to linear decomposition",
            "updated": "2023-09-17T07:57:11Z",
            "published": "2023-09-17T07:57:11Z",
            "summary": "The investigation of width parameters in both graph and algebraic contexts\nhas attracted considerable interest. Among these parameters, the linear branch\nwidth has emerged as a crucial measure. In this concise paper, we explore the\nconcept of linear decomposition, specifically focusing on the single filter in\na connectivity system. Additionally, we examine the relevance of matroids,\nantimatroids, and greedoids in the context of connectivity systems. Our primary\nobjective in this study is to shed light on the impediments to linear\ndecomposition from multiple perspectives.",
            "author": [
                "Takaaki Fujita"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09199v1",
                "http://arxiv.org/pdf/2309.09199v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09194v1",
            "title": "Understanding Representations by Exploring Galaxies in Chemical Space",
            "updated": "2023-09-17T07:37:19Z",
            "published": "2023-09-17T07:37:19Z",
            "summary": "We present a Monte Carlo approach for studying chemical feature distributions\nof molecules without training a machine learning model or performing exhaustive\nenumeration. The algorithm generates molecules with predefined similarity to a\ngiven one for any representation. It serves as a diagnostic tool to understand\nwhich molecules are grouped in feature space and to identify shortcomings of\nrepresentations and embeddings from unsupervised learning. In this work, we\nfirst study clusters surrounding chosen molecules and demonstrate that common\nrepresentations do not yield a constant density of molecules in feature space,\nwith possible implications for learning behavior. Next, we observe a connection\nbetween representations and properties: a linear correlation between the\nproperty value of a central molecule and the average radial slope of that\nproperty in chemical space. Molecules with extremal property values have the\nlargest property derivative values in chemical space, which provides a route to\nimprove the data efficiency of a representation by tailoring it towards a given\nproperty. Finally, we demonstrate applications for sampling molecules with\nspecified metric-dependent distributions to generate molecules biased toward\ngraph spaces of interest.",
            "author": [
                "Jan Weinreich",
                "Konstantin Karandashev",
                "Guido Falk von Rudorff"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09194v1",
                "http://arxiv.org/pdf/2309.09194v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09182v1",
            "title": "Optimal Scene Graph Planning with Large Language Model Guidance",
            "updated": "2023-09-17T07:09:46Z",
            "published": "2023-09-17T07:09:46Z",
            "summary": "Recent advances in metric, semantic, and topological mapping have equipped\nautonomous robots with semantic concept grounding capabilities to interpret\nnatural language tasks. This work aims to leverage these new capabilities with\nan efficient task planning algorithm for hierarchical metric-semantic models.\nWe consider a scene graph representation of the environment and utilize a large\nlanguage model (LLM) to convert a natural language task into a linear temporal\nlogic (LTL) automaton. Our main contribution is to enable optimal hierarchical\nLTL planning with LLM guidance over scene graphs. To achieve efficiency, we\nconstruct a hierarchical planning domain that captures the attributes and\nconnectivity of the scene graph and the task automaton, and provide semantic\nguidance via an LLM heuristic function. To guarantee optimality, we design an\nLTL heuristic function that is provably consistent and supplements the\npotentially inadmissible LLM guidance in multi-heuristic planning. We\ndemonstrate efficient planning of complex natural language tasks in scene\ngraphs of virtualized real environments.",
            "author": [
                "Zhirui Dai",
                "Arash Asgharivaskasi",
                "Thai Duong",
                "Shusen Lin",
                "Maria-Elizabeth Tzes",
                "George Pappas",
                "Nikolay Atanasov"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09182v1",
                "http://arxiv.org/pdf/2309.09182v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09181v1",
            "title": "From Cooking Recipes to Robot Task Trees -- Improving Planning\n  Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network",
            "updated": "2023-09-17T07:09:16Z",
            "published": "2023-09-17T07:09:16Z",
            "summary": "Task planning for robotic cooking involves generating a sequence of actions\nfor a robot to prepare a meal successfully. This paper introduces a novel task\ntree generation pipeline producing correct planning and efficient execution for\ncooking tasks. Our method first uses a large language model (LLM) to retrieve\nrecipe instructions and then utilizes a fine-tuned GPT-3 to convert them into a\ntask tree, capturing sequential and parallel dependencies among subtasks. The\npipeline then mitigates the uncertainty and unreliable features of LLM outputs\nusing task tree retrieval. We combine multiple LLM task tree outputs into a\ngraph and perform a task tree retrieval to avoid questionable nodes and\nhigh-cost nodes to improve planning correctness and improve execution\nefficiency. Our evaluation results show its superior performance compared to\nprevious works in task planning accuracy and efficiency.",
            "author": [
                "Md Sadman Sakib",
                "Yu Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09181v1",
                "http://arxiv.org/pdf/2309.09181v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09179v1",
            "title": "Syntax Tree Constrained Graph Network for Visual Question Answering",
            "updated": "2023-09-17T07:03:54Z",
            "published": "2023-09-17T07:03:54Z",
            "summary": "Visual Question Answering (VQA) aims to automatically answer natural language\nquestions related to given image content. Existing VQA methods integrate vision\nmodeling and language understanding to explore the deep semantics of the\nquestion. However, these methods ignore the significant syntax information of\nthe question, which plays a vital role in understanding the essential semantics\nof the question and guiding the visual feature refinement. To fill the gap, we\nsuggested a novel Syntax Tree Constrained Graph Network (STCGN) for VQA based\non entity message passing and syntax tree. This model is able to extract a\nsyntax tree from questions and obtain more precise syntax information.\nSpecifically, we parse questions and obtain the question syntax tree using the\nStanford syntax parsing tool. From the word level and phrase level, syntactic\nphrase features and question features are extracted using a hierarchical tree\nconvolutional network. We then design a message-passing mechanism for\nphrase-aware visual entities and capture entity features according to a given\nvisual context. Extensive experiments on VQA2.0 datasets demonstrate the\nsuperiority of our proposed model.",
            "author": [
                "Xiangrui Su",
                "Qi Zhang",
                "Chongyang Shi",
                "Jiachang Liu",
                "Liang Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09179v1",
                "http://arxiv.org/pdf/2309.09179v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09999v1",
            "title": "A renewal approach to prove the Four Color Theorem unplugged, Part II:\n  R/G/B Kempe chains in an extremum non-4-colorable MPG",
            "updated": "2023-09-17T05:20:05Z",
            "published": "2023-09-17T05:20:05Z",
            "summary": "This is the second part of three episodes to demonstrate a renewal approach\nfor proving the Four Color Theorem without checking by a computer. The first\nand the third episodes have subtitles: ``RGB-tilings on maximal planar graphs''\nand ``Diamond routes, canal lines and $\\Sigma$-adjustments,'' where R/G/B stand\nfor red, green and blue colors to paint on edges and an MPG stands for a\nmaximal planar graph. We focus on an extremum non-4-colorable MPG $EP$ in the\nwhole paper. In this second part, we refresh the false proof on $EP$ by Kempe\nfor the Four Color Theorem. And then using single color tilings or RGB-tilings\non $EP$, we offer a renewal point of view through R/G/B Kempe chains to enhance\nour coloring skill, either in vertex-colorings or in edge-colorings. We\ndiscover many fundamental theorems associated with R-/RGB-tilings and\n4-colorability; an adventure study on One Piece, which is either an MPG or an\n$n$-semi-MPG; many if-and-only-if statements for $EP-\\{e\\}$ by using Type A or\nType B $e$-diamond and Kempe chains. This work started on May 31, 2018 and was\nfirst announced by the author~\\cite{Liu2020} on Jan.\\ 22, 2020, when the\npandemic just occurred.",
            "author": [
                "Shu-Chung Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09999v1",
                "http://arxiv.org/pdf/2309.09999v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C10, 05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09998v1",
            "title": "A renewal approach to prove the Four Color Theorem unplugged, Part III:\n  Diamond routes, canal lines and $\u03a3$-adjustments",
            "updated": "2023-09-17T05:19:12Z",
            "published": "2023-09-17T05:19:12Z",
            "summary": "This is the last part of three episodes to demonstrate a renewal approach for\nproving the Four Color Theorem without checking by a computer. The first and\nthe second episodes have subtitles: ``RGB-tilings on maximal planar graphs''\nand ``R/G/B Kempe chains in an extremum non-4-colorable MPG,'' where R/G/B\nstand for red, green and blue colors to paint on edges and an MPG stands for a\nmaximal planar graph. We focus on an extremum non-4-colorable MPG $EP$ in the\nwhole paper. In this part we introduce three tools based on RGB-tilings. They\nare diamond routes, normal and generalized canal lines or rings and\n$\\Sigma$-adjustments. Using these tools, we show a major result of this paper:\nno four vertices of degree 5 form a diamond in any extremum $EP$.",
            "author": [
                "Shu-Chung Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09998v1",
                "http://arxiv.org/pdf/2309.09998v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C10, 05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09156v1",
            "title": "Consensus-Based Leader-Follower Formation Tracking for Control-Affine\n  Nonlinear Multiagent Systems",
            "updated": "2023-09-17T04:44:47Z",
            "published": "2023-09-17T04:44:47Z",
            "summary": "In the typical multiagent formation tracking problem centered on consensus,\nthe prevailing assumption in the literature is that the agents' nonlinear\nmodels can be approximated by integrator systems, by their feedback-linearized\nequivalents, or by dynamics composed of deterministic linear and nonlinear\nterms. The resulting approaches associated with such assumptions, however, are\nhardly applicable to general nonlinear systems. To this end, we present\nconsensus-based control laws for multiagent formation tracking in\nfinite-dimensional state space, with the agents represented by a more general\nclass of dynamics: control-affine nonlinear systems. The agents also exchange\ninformation via a leader-follower communication topology modeled as an\nundirected and connected graph with a single leader node. By leveraging\nstandard tools from algebraic graph theory and Lyapunov analysis, we first\nderive a locally asymptotically stabilizing formation tracking law. Next, to\ndemonstrate the effectiveness of our approach, we present results from\nnumerical simulations of an example in robotics. These results -- together with\na comparison of the formation errors obtained with our approach and those\nrealized via an optimization-based method -- further validate our theoretical\npropositions.",
            "author": [
                "Clinton Enwerem",
                "John S. Baras"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09156v1",
                "http://arxiv.org/pdf/2309.09156v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.11515v1",
            "title": "Towards Differential Privacy in Sequential Recommendation: A Noisy Graph\n  Neural Network Approach",
            "updated": "2023-09-17T03:12:33Z",
            "published": "2023-09-17T03:12:33Z",
            "summary": "With increasing frequency of high-profile privacy breaches in various online\nplatforms, users are becoming more concerned about their privacy. And\nrecommender system is the core component of online platforms for providing\npersonalized service, consequently, its privacy preservation has attracted\ngreat attention. As the gold standard of privacy protection, differential\nprivacy has been widely adopted to preserve privacy in recommender systems.\nHowever, existing differentially private recommender systems only consider\nstatic and independent interactions, so they cannot apply to sequential\nrecommendation where behaviors are dynamic and dependent. Meanwhile, little\nattention has been paid on the privacy risk of sensitive user features, most of\nthem only protect user feedbacks. In this work, we propose a novel\nDIfferentially Private Sequential recommendation framework with a noisy Graph\nNeural Network approach (denoted as DIPSGNN) to address these limitations. To\nthe best of our knowledge, we are the first to achieve differential privacy in\nsequential recommendation with dependent interactions. Specifically, in\nDIPSGNN, we first leverage piecewise mechanism to protect sensitive user\nfeatures. Then, we innovatively add calibrated noise into aggregation step of\ngraph neural network based on aggregation perturbation mechanism. And this\nnoisy graph neural network can protect sequentially dependent interactions and\ncapture user preferences simultaneously. Extensive experiments demonstrate the\nsuperiority of our method over state-of-the-art differentially private\nrecommender systems in terms of better balance between privacy and accuracy.",
            "author": [
                "Wentao Hu",
                "Hui Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.11515v1",
                "http://arxiv.org/pdf/2309.11515v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09142v1",
            "title": "Performance of Graph Neural Networks for Point Cloud Applications",
            "updated": "2023-09-17T03:05:13Z",
            "published": "2023-09-17T03:05:13Z",
            "summary": "Graph Neural Networks (GNNs) have gained significant momentum recently due to\ntheir capability to learn on unstructured graph data. Dynamic GNNs (DGNNs) are\nthe current state-of-the-art for point cloud applications; such applications\n(viz. autonomous driving) require real-time processing at the edge with tight\nlatency and memory constraints. Conducting performance analysis on such DGNNs,\nthus, becomes a crucial task to evaluate network suitability.\n  This paper presents a profiling analysis of EdgeConv-based DGNNs applied to\npoint cloud inputs. We assess their inference performance in terms of\nend-to-end latency and memory consumption on state-of-the-art CPU and GPU\nplatforms. The EdgeConv layer has two stages: (1) dynamic graph generation\nusing k-Nearest Neighbors (kNN) and, (2) node feature updation. The addition of\ndynamic graph generation via kNN in each (EdgeConv) layer enhances network\nperformance compared to networks that work with the same static graph in each\nlayer; such performance enhancement comes, however, at the added computational\ncost associated with the dynamic graph generation stage (via kNN algorithm).\nUnderstanding its costs is essential for identifying the performance bottleneck\nand exploring potential avenues for hardware acceleration. To this end, this\npaper aims to shed light on the performance characteristics of EdgeConv-based\nDGNNs for point cloud inputs. Our performance analysis on a state-of-the-art\nEdgeConv network for classification shows that the dynamic graph construction\nvia kNN takes up upwards of 95% of network latency on the GPU and almost 90% on\nthe CPU. Moreover, we propose a quasi-Dynamic Graph Neural Network (qDGNN) that\nhalts dynamic graph updates after a specific depth within the network to\nsignificantly reduce the latency on both CPU and GPU whilst matching the\noriginal networks inference accuracy.",
            "author": [
                "Dhruv Parikh",
                "Bingyi Zhang",
                "Rajgopal Kannan",
                "Viktor Prasanna",
                "Carl Busart"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09142v1",
                "http://arxiv.org/pdf/2309.09142v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09128v1",
            "title": "ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis\n  Testing",
            "updated": "2023-09-17T01:42:30Z",
            "published": "2023-09-17T01:42:30Z",
            "summary": "Evaluating outputs of large language models (LLMs) is challenging, requiring\nmaking -- and making sense of -- many responses. Yet tools that go beyond basic\nprompting tend to require knowledge of programming APIs, focus on narrow\ndomains, or are closed-source. We present ChainForge, an open-source visual\ntoolkit for prompt engineering and on-demand hypothesis testing of text\ngeneration LLMs. ChainForge provides a graphical interface for comparison of\nresponses across models and prompt variations. Our system was designed to\nsupport three tasks: model selection, prompt template design, and hypothesis\ntesting (e.g., auditing). We released ChainForge early in its development and\niterated on its design with academics and online users. Through in-lab and\ninterview studies, we find that a range of people could use ChainForge to\ninvestigate hypotheses that matter to them, including in real-world settings.\nWe identify three modes of prompt engineering and LLM hypothesis testing:\nopportunistic exploration, limited evaluation, and iterative refinement.",
            "author": [
                "Ian Arawjo",
                "Chelse Swoopes",
                "Priyan Vaithilingam",
                "Martin Wattenberg",
                "Elena Glassman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09128v1",
                "http://arxiv.org/pdf/2309.09128v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "H.5.2; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09122v1",
            "title": "FDCNet: Feature Drift Compensation Network for Class-Incremental Weakly\n  Supervised Object Localization",
            "updated": "2023-09-17T01:10:45Z",
            "published": "2023-09-17T01:10:45Z",
            "summary": "This work addresses the task of class-incremental weakly supervised object\nlocalization (CI-WSOL). The goal is to incrementally learn object localization\nfor novel classes using only image-level annotations while retaining the\nability to localize previously learned classes. This task is important because\nannotating bounding boxes for every new incoming data is expensive, although\nobject localization is crucial in various applications. To the best of our\nknowledge, we are the first to address this task. Thus, we first present a\nstrong baseline method for CI-WSOL by adapting the strategies of\nclass-incremental classifiers to mitigate catastrophic forgetting. These\nstrategies include applying knowledge distillation, maintaining a small data\nset from previous tasks, and using cosine normalization. We then propose the\nfeature drift compensation network to compensate for the effects of feature\ndrifts on class scores and localization maps. Since updating network parameters\nto learn new tasks causes feature drifts, compensating for the final outputs is\nnecessary. Finally, we evaluate our proposed method by conducting experiments\non two publicly available datasets (ImageNet-100 and CUB-200). The experimental\nresults demonstrate that the proposed method outperforms other baseline\nmethods.",
            "author": [
                "Sejin Park",
                "Taehyung Lee",
                "Yeejin Lee",
                "Byeongkeun Kang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612450",
                "http://arxiv.org/abs/2309.09122v1",
                "http://arxiv.org/pdf/2309.09122v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.04425v1",
            "title": "Red Teaming Generative AI/NLP, the BB84 quantum cryptography protocol\n  and the NIST-approved Quantum-Resistant Cryptographic Algorithms",
            "updated": "2023-09-17T00:59:14Z",
            "published": "2023-09-17T00:59:14Z",
            "summary": "In the contemporary digital age, Quantum Computing and Artificial\nIntelligence (AI) convergence is reshaping the cyber landscape, introducing\nunprecedented opportunities and potential vulnerabilities.This research,\nconducted over five years, delves into the cybersecurity implications of this\nconvergence, with a particular focus on AI/Natural Language Processing (NLP)\nmodels and quantum cryptographic protocols, notably the BB84 method and\nspecific NIST-approved algorithms. Utilising Python and C++ as primary\ncomputational tools, the study employs a \"red teaming\" approach, simulating\npotential cyber-attacks to assess the robustness of quantum security measures.\nPreliminary research over 12 months laid the groundwork, which this study seeks\nto expand upon, aiming to translate theoretical insights into actionable,\nreal-world cybersecurity solutions. Located at the University of Oxford's\ntechnology precinct, the research benefits from state-of-the-art infrastructure\nand a rich collaborative environment. The study's overarching goal is to ensure\nthat as the digital world transitions to quantum-enhanced operations, it\nremains resilient against AI-driven cyber threats. The research aims to foster\na safer, quantum-ready digital future through iterative testing, feedback\nintegration, and continuous improvement. The findings are intended for broad\ndissemination, ensuring that the knowledge benefits academia and the global\ncommunity, emphasising the responsible and secure harnessing of quantum\ntechnology.",
            "author": [
                "Petar Radanliev",
                "David De Roure",
                "Omar Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.04425v1",
                "http://arxiv.org/pdf/2310.04425v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR",
                "cs.ET",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09113v1",
            "title": "On generalized Tur\u00e1n problems with bounded matching number",
            "updated": "2023-09-17T00:12:01Z",
            "published": "2023-09-17T00:12:01Z",
            "summary": "Given a graph $H$ and a family of graphs $\\mathcal{F}$, the generalized\nTur\\'an number $\\mathrm{ex}(n,H,\\mathcal{F})$ is the maximum number of copies\nof $H$ in an $n$-vertex graphs that do not contain any member of $\\mathcal{F}$\nas a subgraph. Recently there has been interest in studying the case\n$\\mathcal{F}=\\{F,M_{s+1}\\}$ for arbitrary $F$ and $H=K_r$. We extend these\ninvestigations to the case $H$ is arbitrary as well.",
            "author": [
                "D\u00e1niel Gerbner"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09113v1",
                "http://arxiv.org/pdf/2309.09113v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09108v1",
            "title": "Neural Network-based Fault Detection and Identification for Quadrotors\n  using Dynamic Symmetry",
            "updated": "2023-09-16T22:59:09Z",
            "published": "2023-09-16T22:59:09Z",
            "summary": "Autonomous robotic systems, such as quadrotors, are susceptible to actuator\nfaults, and for the safe operation of such systems, timely detection and\nisolation of these faults is essential. Neural networks can be used for\nverification of actuator performance via online actuator fault detection with\nhigh accuracy. In this paper, we develop a novel model-free fault detection and\nisolation (FDI) framework for quadrotor systems using long-short-term memory\n(LSTM) neural network architecture. The proposed framework only uses system\noutput data and the commanded control input and requires no knowledge of the\nsystem model. Utilizing the symmetry in quadrotor dynamics, we train the FDI\nfor fault in just one of the motors (e.g., motor $\\# 2$), and the trained FDI\ncan predict faults in any of the motors. This reduction in search space enables\nus to design an FDI for partial fault as well as complete fault scenarios.\nNumerical experiments illustrate that the proposed NN-FDI correctly verifies\nthe actuator performance and identifies partial as well as complete faults with\nover $90\\%$ prediction accuracy. We also illustrate that model-free NN-FDI\nperforms at par with model-based FDI, and is robust to model uncertainties as\nwell as distribution shifts in input data.",
            "author": [
                "Kunal Garg",
                "Chuchu Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09108v1",
                "http://arxiv.org/pdf/2309.09108v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09082v1",
            "title": "A construction of a graphical model",
            "updated": "2023-09-16T19:26:42Z",
            "published": "2023-09-16T19:26:42Z",
            "summary": "We present a nonparametric graphical model. Our model uses an undirected\ngraph that represents conditional independence for general random variables\ndefined by the conditional dependence coefficient (Azadkia and Chatterjee\n(2021)). The set of edges of the graph are defined as\n  $E=\\{(i,j):R_{i,j}\\neq 0\\}$, where $R_{i,j}$ is the conditional dependence\ncoefficient for $X_i$ and $X_j$ given $(X_1,\\ldots,X_p) \\backslash\n\\{X_{i},X_{j}\\}$.\n  We propose a graph structure learning by two steps selection procedure:\nfirst, we compute the matrix of sample version of the conditional dependence\ncoefficient $\\widehat{R_{i,j}}$; next, for some prespecificated threshold\n$\\lambda>0$ we choose an edge $\\{i,j\\}$ if\n  $ \\left|\\widehat{R_{i,j}} \\right| \\geq \\lambda.$ The graph recovery structure\nhas been evaluated on artificial and real datasets. We also applied a slight\nmodification of our graph recovery procedure for learning partial correlation\ngraphs for the elliptical distribution.",
            "author": [
                "Konrad Furma\u0144czyk"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09082v1",
                "http://arxiv.org/pdf/2309.09082v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09069v1",
            "title": "Constructing a Knowledge Graph for Vietnamese Legal Cases with\n  Heterogeneous Graphs",
            "updated": "2023-09-16T18:31:47Z",
            "published": "2023-09-16T18:31:47Z",
            "summary": "This paper presents a knowledge graph construction method for legal case\ndocuments and related laws, aiming to organize legal information efficiently\nand enhance various downstream tasks. Our approach consists of three main\nsteps: data crawling, information extraction, and knowledge graph deployment.\nFirst, the data crawler collects a large corpus of legal case documents and\nrelated laws from various sources, providing a rich database for further\nprocessing. Next, the information extraction step employs natural language\nprocessing techniques to extract entities such as courts, cases, domains, and\nlaws, as well as their relationships from the unstructured text. Finally, the\nknowledge graph is deployed, connecting these entities based on their extracted\nrelationships, creating a heterogeneous graph that effectively represents legal\ninformation and caters to users such as lawyers, judges, and scholars. The\nestablished baseline model leverages unsupervised learning methods, and by\nincorporating the knowledge graph, it demonstrates the ability to identify\nrelevant laws for a given legal case. This approach opens up opportunities for\nvarious applications in the legal domain, such as legal case analysis, legal\nrecommendation, and decision support.",
            "author": [
                "Thi-Hai-Yen Vuong",
                "Minh-Quan Hoang",
                "Tan-Minh Nguyen",
                "Hoang-Trung Nguyen",
                "Ha-Thanh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09069v1",
                "http://arxiv.org/pdf/2309.09069v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09068v1",
            "title": "Recovering Missing Node Features with Local Structure-based Embeddings",
            "updated": "2023-09-16T18:23:14Z",
            "published": "2023-09-16T18:23:14Z",
            "summary": "Node features bolster graph-based learning when exploited jointly with\nnetwork structure. However, a lack of nodal attributes is prevalent in graph\ndata. We present a framework to recover completely missing node features for a\nset of graphs, where we only know the signals of a subset of graphs. Our\napproach incorporates prior information from both graph topology and existing\nnodal values. We demonstrate an example implementation of our framework where\nwe assume that node features depend on local graph structure. Missing nodal\nvalues are estimated by aggregating known features from the most similar nodes.\nSimilarity is measured through a node embedding space that preserves local\ntopological features, which we train using a Graph AutoEncoder. We empirically\nshow not only the accuracy of our feature estimation approach but also its\nvalue for downstream graph classification. Our success embarks on and implies\nthe need to emphasize the relationship between node features and graph\nstructure in graph-based learning.",
            "author": [
                "Victor M. Tenorio",
                "Madeline Navarro",
                "Santiago Segarra",
                "Antonio G. Marques"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09068v1",
                "http://arxiv.org/pdf/2309.09068v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09064v2",
            "title": "Fast Triangle Counting",
            "updated": "2023-09-20T17:48:37Z",
            "published": "2023-09-16T18:18:50Z",
            "summary": "Listing and counting triangles in graphs is a key algorithmic kernel for\nnetwork analyses including community detection, clustering coefficients,\nk-trusses, and triangle centrality. We design and implement a new serial\nalgorithm for triangle counting that performs competitively with the fastest\nprevious approaches on both real and synthetic graphs, such as those from the\nGraph500 Benchmark and the MIT/Amazon/IEEE Graph Challenge. The experimental\nresults use the recently-launched Intel Xeon Platinum 8480+ and CPU Max 9480\nprocessors.",
            "author": [
                "David A. Bader"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09064v2",
                "http://arxiv.org/pdf/2309.09064v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09063v1",
            "title": "Blind Deconvolution of Sparse Graph Signals in the Presence of\n  Perturbations",
            "updated": "2023-09-16T18:07:16Z",
            "published": "2023-09-16T18:07:16Z",
            "summary": "Blind deconvolution over graphs involves using (observed) output graph\nsignals to obtain both the inputs (sources) as well as the filter that drives\n(models) the graph diffusion process. This is an ill-posed problem that\nrequires additional assumptions, such as the sources being sparse, to be\nsolvable. This paper addresses the blind deconvolution problem in the presence\nof imperfect graph information, where the observed graph is a perturbed version\nof the (unknown) true graph. While not having perfect knowledge of the graph is\narguably more the norm than the exception, the body of literature on this topic\nis relatively small. This is partly due to the fact that translating the\nuncertainty about the graph topology to standard graph signal processing tools\n(e.g. eigenvectors or polynomials of the graph) is a challenging endeavor. To\naddress this limitation, we propose an optimization-based estimator that solves\nthe blind identification in the vertex domain, aims at estimating the inverse\nof the generating filter, and accounts explicitly for additive graph\nperturbations. Preliminary numerical experiments showcase the effectiveness and\npotential of the proposed algorithm.",
            "author": [
                "Victor M. Tenorio",
                "Samuel Rey",
                "Antonio G. Marques"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09063v1",
                "http://arxiv.org/pdf/2309.09063v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12367v1",
            "title": "Examining the Influence of Varied Levels of Domain Knowledge Base\n  Inclusion in GPT-based Intelligent Tutors",
            "updated": "2023-09-16T17:12:05Z",
            "published": "2023-09-16T17:12:05Z",
            "summary": "Recent advancements in large language models (LLMs) have facilitated the\ndevelopment of chatbots with sophisticated conversational capabilities.\nHowever, LLMs exhibit frequent inaccurate responses to queries, hindering\napplications in educational settings. In this paper, we investigate the\neffectiveness of integrating a knowledge base (KB) with LLM intelligent tutors\nto increase response reliability. To achieve this, we design a scaleable KB\nthat affords educational supervisors seamless integration of lesson curricula,\nwhich is automatically processed by the intelligent tutoring system. We then\ndetail an evaluation, where student participants were presented with questions\nabout the artificial intelligence curriculum to respond to. GPT-4 intelligent\ntutors with varying hierarchies of KB access and human domain experts then\nassessed these responses. Lastly, students cross-examined the intelligent\ntutors' responses to the domain experts' and ranked their various pedagogical\nabilities. Results suggest that, although these intelligent tutors still\ndemonstrate a lower accuracy compared to domain experts, the accuracy of the\nintelligent tutors increases when access to a KB is granted. We also observe\nthat the intelligent tutors with KB access exhibit better pedagogical abilities\nto speak like a teacher and understand students than those of domain experts,\nwhile their ability to help students remains lagging behind domain experts.",
            "author": [
                "Blake Castleman",
                "Mehmet Kerem Turkcan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12367v1",
                "http://arxiv.org/pdf/2309.12367v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09047v1",
            "title": "CNS: Correspondence Encoded Neural Image Servo Policy",
            "updated": "2023-09-16T17:09:13Z",
            "published": "2023-09-16T17:09:13Z",
            "summary": "Image servo is an indispensable technique in robotic applications that helps\nto achieve high precision positioning. The intermediate representation of image\nservo policy is important to sensor input abstraction and policy output\nguidance. Classical approaches achieve high precision but require clean\nkeypoint correspondence, and suffer from limited convergence basin or weak\nfeature error robustness. Recent learning-based methods achieve moderate\nprecision and large convergence basin on specific scenes but face issues when\ngeneralizing to novel environments. In this paper, we encode keypoints and\ncorrespondence into a graph and use graph neural network as architecture of\ncontroller. This design utilizes both advantages: generalizable intermediate\nrepresentation from keypoint correspondence and strong modeling ability from\nneural network. Other techniques including realistic data generation, feature\nclustering and distance decoupling are proposed to further improve efficiency,\nprecision and generalization. Experiments in simulation and real-world verify\nthe effectiveness of our method in speed (maximum 40fps along with observer),\nprecision (<0.3{\\deg} and sub-millimeter accuracy) and generalization\n(sim-to-real without fine-tuning). Project homepage (full paper with\nsupplementary text, video and code): https://hhcaz.github.io/CNS-home",
            "author": [
                "Anzhe Chen",
                "Hongxiang Yu",
                "Yue Wang",
                "Rong Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09047v1",
                "http://arxiv.org/pdf/2309.09047v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09045v1",
            "title": "Temporal Smoothness Regularisers for Neural Link Predictors",
            "updated": "2023-09-16T16:52:49Z",
            "published": "2023-09-16T16:52:49Z",
            "summary": "Most algorithms for representation learning and link prediction on relational\ndata are designed for static data. However, the data to which they are applied\ntypically evolves over time, including online social networks or interactions\nbetween users and items in recommender systems. This is also the case for\ngraph-structured knowledge bases -- knowledge graphs -- which contain facts\nthat are valid only for specific points in time. In such contexts, it becomes\ncrucial to correctly identify missing links at a precise time point, i.e. the\ntemporal prediction link task. Recently, Lacroix et al. and Sadeghian et al.\nproposed a solution to the problem of link prediction for knowledge graphs\nunder temporal constraints inspired by the canonical decomposition of 4-order\ntensors, where they regularise the representations of time steps by enforcing\ntemporal smoothing, i.e. by learning similar transformation for adjacent\ntimestamps. However, the impact of the choice of temporal regularisation terms\nis still poorly understood. In this work, we systematically analyse several\nchoices of temporal smoothing regularisers using linear functions and recurrent\narchitectures. In our experiments, we show that by carefully selecting the\ntemporal smoothing regulariser and regularisation weight, a simple method like\nTNTComplEx can produce significantly more accurate results than\nstate-of-the-art methods on three widely used temporal link prediction\ndatasets. Furthermore, we evaluate the impact of a wide range of temporal\nsmoothing regularisers on two state-of-the-art temporal link prediction models.\nOur work shows that simple tensor factorisation models can produce new\nstate-of-the-art results using newly proposed temporal regularisers,\nhighlighting a promising avenue for future research.",
            "author": [
                "Manuel Dileo",
                "Pasquale Minervini",
                "Matteo Zignani",
                "Sabrina Gaito"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09045v1",
                "http://arxiv.org/pdf/2309.09045v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09041v1",
            "title": "Some bounds on the Laplacian eigenvalues of token graphs",
            "updated": "2023-09-16T16:43:14Z",
            "published": "2023-09-16T16:43:14Z",
            "summary": "The $k$-token graph $F_k(G)$ of a graph $G$ on $n$ vertices is the graph\nwhose vertices are the ${n\\choose k}$ $k$-subsets of vertices from $G$, two of\nwhich being adjacent whenever their symmetric difference is a pair of adjacent\nvertices in $G$.\n  It is known that the algebraic connectivity (or second Laplacian eigenvalue)\nof $F_k(G)$ equals the algebraic connectivity $\\alpha(G)$ of $G$.\n  In this paper, we give some bounds on the (Laplacian) eigenvalues of a\n$k$-token graph (including the algebraic connectivity) in terms of the\n$h$-token graph, with $h\\leq k$. For instance, we prove that if $\\lambda$ is an\neigenvalue of $F_k(G)$, but not of $G$, then $$ \\lambda\\ge k\\alpha(G)-k+1. $$\nAs a consequence, we conclude that if $\\alpha(G)\\geq k$, then\n$\\alpha(F_h(G))=\\alpha(G)$ for every $h\\le k$.",
            "author": [
                "Cristina Dalf\u00f3",
                "Miquel \u00c0ngel Fiol",
                "Arnau Messegu\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09041v1",
                "http://arxiv.org/pdf/2309.09041v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09032v1",
            "title": "Solving Quadratic Systems with Full-Rank Matrices Using Sparse or\n  Generative Priors",
            "updated": "2023-09-16T16:00:07Z",
            "published": "2023-09-16T16:00:07Z",
            "summary": "The problem of recovering a signal $\\boldsymbol{x} \\in \\mathbb{R}^n$ from a\nquadratic system $\\{y_i=\\boldsymbol{x}^\\top\\boldsymbol{A}_i\\boldsymbol{x},\\\ni=1,\\ldots,m\\}$ with full-rank matrices $\\boldsymbol{A}_i$ frequently arises in\napplications such as unassigned distance geometry and sub-wavelength imaging.\nWith i.i.d. standard Gaussian matrices $\\boldsymbol{A}_i$, this paper addresses\nthe high-dimensional case where $m\\ll n$ by incorporating prior knowledge of\n$\\boldsymbol{x}$. First, we consider a $k$-sparse $\\boldsymbol{x}$ and\nintroduce the thresholded Wirtinger flow (TWF) algorithm that does not require\nthe sparsity level $k$. TWF comprises two steps: the spectral initialization\nthat identifies a point sufficiently close to $\\boldsymbol{x}$ (up to a sign\nflip) when $m=O(k^2\\log n)$, and the thresholded gradient descent (with a good\ninitialization) that produces a sequence linearly converging to\n$\\boldsymbol{x}$ with $m=O(k\\log n)$ measurements. Second, we explore the\ngenerative prior, assuming that $\\boldsymbol{x}$ lies in the range of an\n$L$-Lipschitz continuous generative model with $k$-dimensional inputs in an\n$\\ell_2$-ball of radius $r$. We develop the projected gradient descent (PGD)\nalgorithm that also comprises two steps: the projected power method that\nprovides an initial vector with $O\\big(\\sqrt{\\frac{k \\log L}{m}}\\big)$\n$\\ell_2$-error given $m=O(k\\log(Lnr))$ measurements, and the projected gradient\ndescent that refines the $\\ell_2$-error to $O(\\delta)$ at a geometric rate when\n$m=O(k\\log\\frac{Lrn}{\\delta^2})$. Experimental results corroborate our\ntheoretical findings and show that: (i) our approach for the sparse case\nnotably outperforms the existing provable algorithm sparse power factorization;\n(ii) leveraging the generative prior allows for precise image recovery in the\nMNIST dataset from a small number of quadratic measurements.",
            "author": [
                "Junren Chen",
                "Shuai Huang",
                "Michael K. Ng",
                "Zhaoqiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09032v1",
                "http://arxiv.org/pdf/2309.09032v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "eess.SP",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09021v1",
            "title": "Pedestrian Trajectory Prediction Using Dynamics-based Deep Learning",
            "updated": "2023-09-16T15:25:03Z",
            "published": "2023-09-16T15:25:03Z",
            "summary": "Pedestrian trajectory prediction plays an important role in autonomous\ndriving systems and robotics. Recent work utilising prominent deep learning\nmodels for pedestrian motion prediction makes limited a priori assumptions\nabout human movements, resulting in a lack of explainability and explicit\nconstraints enforced on predicted trajectories. This paper presents a\ndynamics-based deep learning framework where a novel asymptotically stable\ndynamical system is integrated into a deep learning model. Our novel\nasymptotically stable dynamical system is used to model human goal-targeted\nmotion by enforcing the human walking trajectory converges to a predicted goal\nposition and provides a deep learning model with prior knowledge and\nexplainability. Our deep learning model utilises recent innovations from\ntransformer networks and is used to learn some features of human motion, such\nas collision avoidance, for our proposed dynamical system. The experimental\nresults show that our framework outperforms recent prominent models in\npedestrian trajectory prediction on five benchmark human motion datasets.",
            "author": [
                "Honghui Wang",
                "Weiming Zhi",
                "Gustavo Batista",
                "Rohitash Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09021v1",
                "http://arxiv.org/pdf/2309.09021v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08993v1",
            "title": "Fast laser field reconstruction method based on a Gerchberg-Saxton\n  algorithm with mode decomposition",
            "updated": "2023-09-16T13:19:05Z",
            "published": "2023-09-16T13:19:05Z",
            "summary": "Knowledge of the electric field of femtosecond, high intensity laser pulses\nis of paramount importance to study the interaction of this class of lasers\nwith matter. A novel, hybrid method to reconstruct the laser field from fluence\nmeasurements in the transverse plane at multiple positions along the\npropagation axis is presented, combining a Hermite-Gauss modes decomposition\nand elements of the Gerchberg-Saxton algorithm. The proposed Gerchberg-Saxton\nalgorithm with modes decomposition (GSA-MD) takes into account the pointing\ninstabilities of high intensity laser systems by tuning the centers of the HG\nmodes. Furthermore, it quickly builds a field description by progressively\nincreasing the number of modes and thus the accuracy of the field\nreconstruction. The results of field reconstruction using the GSA-MD are shown\nto be in excellent agreement with experimental measurements from two different\nhigh-peak power laser facilities.",
            "author": [
                "Ioaquin Moulanier",
                "Lewis Thomas Dickson",
                "Francesco Massimo",
                "Brigitte Cros"
            ],
            "link": [
                "http://dx.doi.org/10.1364/JOSAB.489884",
                "http://arxiv.org/abs/2309.08993v1",
                "http://arxiv.org/pdf/2309.08993v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08972v2",
            "title": "Architecture-Aware Synthesis of Stabilizer Circuits from Clifford\n  Tableaus",
            "updated": "2023-09-19T06:12:49Z",
            "published": "2023-09-16T12:11:56Z",
            "summary": "Since quantum computing is currently in the NISQ-Era, compilation strategies\nto reduce the number of gates executed on specific hardware are required. In\nthis work, we utilize the concept of synthesis of a data structure called\nClifford tableaus, focusing on applying CNOTs within the respective\nconnectivity graph of the quantum device. We hence contribute to the field of\ncompilation or, more precisely, synthesis by reducing the number of CNOTs in\nthe synthesized quantum circuit. Upon convergence, our method shows to\noutperform other state-of-the-art synthesis techniques, when executed with\nrespect to a specific hardware. Upon executing the resulting circuits on real\nhardware, our synthesized circuits tend to increase the final fidelity and\nreduce the overall execution times.",
            "author": [
                "David Winderl",
                "Qunsheng Huang",
                "Arianne Meijer-van de Griend",
                "Richie Yeung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08972v2",
                "http://arxiv.org/pdf/2309.08972v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.10829v2",
            "title": "Comparative study of Deep Learning Models for Binary Classification on\n  Combined Pulmonary Chest X-ray Dataset",
            "updated": "2023-10-03T21:45:52Z",
            "published": "2023-09-16T11:58:04Z",
            "summary": "CNN-based deep learning models for disease detection have become popular\nrecently. We compared the binary classification performance of eight prominent\ndeep learning models: DenseNet 121, DenseNet 169, DenseNet 201, EffecientNet\nb0, EffecientNet lite4, GoogleNet, MobileNet, and ResNet18 for their binary\nclassification performance on combined Pulmonary Chest Xrays dataset. Despite\nthe widespread application in different fields in medical images, there remains\na knowledge gap in determining their relative performance when applied to the\nsame dataset, a gap this study aimed to address. The dataset combined Shenzhen,\nChina (CH) and Montgomery, USA (MC) data. We trained our model for binary\nclassification, calculated different parameters of the mentioned models, and\ncompared them. The models were trained to keep in mind all following the same\ntraining parameters to maintain a controlled comparison environment. End of the\nstudy, we found a distinct difference in performance among the other models\nwhen applied to the pulmonary chest Xray image dataset, where DenseNet169\nperformed with 89.38 percent and MobileNet with 92.2 percent precision.\n  Keywords: Pulmonary, Deep Learning, Tuberculosis, Disease detection, Xray",
            "author": [
                "Shabbir Ahmed Shuvo",
                "Md Aminul Islam",
                "Md. Mozammel Hoque",
                "Rejwan Bin Sulaiman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.10829v2",
                "http://arxiv.org/pdf/2309.10829v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08961v1",
            "title": "UNIDEAL: Curriculum Knowledge Distillation Federated Learning",
            "updated": "2023-09-16T11:30:29Z",
            "published": "2023-09-16T11:30:29Z",
            "summary": "Federated Learning (FL) has emerged as a promising approach to enable\ncollaborative learning among multiple clients while preserving data privacy.\nHowever, cross-domain FL tasks, where clients possess data from different\ndomains or distributions, remain a challenging problem due to the inherent\nheterogeneity. In this paper, we present UNIDEAL, a novel FL algorithm\nspecifically designed to tackle the challenges of cross-domain scenarios and\nheterogeneous model architectures. The proposed method introduces Adjustable\nTeacher-Student Mutual Evaluation Curriculum Learning, which significantly\nenhances the effectiveness of knowledge distillation in FL settings. We conduct\nextensive experiments on various datasets, comparing UNIDEAL with\nstate-of-the-art baselines. Our results demonstrate that UNIDEAL achieves\nsuperior performance in terms of both model accuracy and communication\nefficiency. Additionally, we provide a convergence analysis of the algorithm,\nshowing a convergence rate of O(1/T) under non-convex conditions.",
            "author": [
                "Yuwen Yang",
                "Chang Liu",
                "Xun Cai",
                "Suizhi Huang",
                "Hongtao Lu",
                "Yue Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08961v1",
                "http://arxiv.org/pdf/2309.08961v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08952v1",
            "title": "Cross-Lingual Knowledge Editing in Large Language Models",
            "updated": "2023-09-16T11:07:52Z",
            "published": "2023-09-16T11:07:52Z",
            "summary": "Knowledge editing aims to change language models' performance on several\nspecial cases (i.e., editing scope) by infusing the corresponding expected\nknowledge into them. With the recent advancements in large language models\n(LLMs), knowledge editing has been shown as a promising technique to adapt LLMs\nto new knowledge without retraining from scratch. However, most of the previous\nstudies neglect the multi-lingual nature of some main-stream LLMs (e.g., LLaMA,\nChatGPT and GPT-4), and typically focus on monolingual scenarios, where LLMs\nare edited and evaluated in the same language. As a result, it is still unknown\nthe effect of source language editing on a different target language. In this\npaper, we aim to figure out this cross-lingual effect in knowledge editing.\nSpecifically, we first collect a large-scale cross-lingual synthetic dataset by\ntranslating ZsRE from English to Chinese. Then, we conduct English editing on\nvarious knowledge editing methods covering different paradigms, and evaluate\ntheir performance in Chinese, and vice versa. To give deeper analyses of the\ncross-lingual effect, the evaluation includes four aspects, i.e., reliability,\ngenerality, locality and portability. Furthermore, we analyze the inconsistent\nbehaviors of the edited models and discuss their specific challenges.",
            "author": [
                "Jiaan Wang",
                "Yunlong Liang",
                "Zengkui Sun",
                "Yuxuan Cao",
                "Jiarong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08952v1",
                "http://arxiv.org/pdf/2309.08952v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08944v1",
            "title": "Universal Metric Learning with Parameter-Efficient Transfer Learning",
            "updated": "2023-09-16T10:34:01Z",
            "published": "2023-09-16T10:34:01Z",
            "summary": "A common practice in metric learning is to train and test an embedding model\nfor each dataset. This dataset-specific approach fails to simulate real-world\nscenarios that involve multiple heterogeneous distributions of data. In this\nregard, we introduce a novel metric learning paradigm, called Universal Metric\nLearning (UML), which learns a unified distance metric capable of capturing\nrelations across multiple data distributions. UML presents new challenges, such\nas imbalanced data distribution and bias towards dominant distributions. To\naddress these challenges, we propose Parameter-efficient Universal Metric\nleArning (PUMA), which consists of a pre-trained frozen model and two\nadditional modules, stochastic adapter and prompt pool. These modules enable to\ncapture dataset-specific knowledge while avoiding bias towards dominant\ndistributions. Additionally, we compile a new universal metric learning\nbenchmark with a total of 8 different datasets. PUMA outperformed the\nstate-of-the-art dataset-specific models while using about 69 times fewer\ntrainable parameters.",
            "author": [
                "Sungyeon Kim",
                "Donghyun Kim",
                "Suha Kwak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08944v1",
                "http://arxiv.org/pdf/2309.08944v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08933v1",
            "title": "Is This a New Class of Matrices?",
            "updated": "2023-09-16T09:28:11Z",
            "published": "2023-09-16T09:28:11Z",
            "summary": "We consider a new class of matrices associated to a real square matrix $A$\nand to a vector $\\vec{c} \\in \\{-1,1\\}^n$ such that $c_1=1$ by using a map\n$\\varphi_{\\vec{c}}$ which turns out to be a conjugation of a matrix $A$ by a\nsignature matrix. It is shown that every such matrix is similar and congruent\nto a matrix $A$ and that they have same permanental polynomials. There are\n$2^{n-1}$ maps $\\varphi_{\\vec{c}}$ and they form an abelian group under the\ncomposition of maps isomorphic to the group $({\\mathbb{Z}_2}^{n-1}, +)$. A\ndecomposition of matrices, on a symmetric and antisymmetric matrix under a map\n$\\varphi_{\\vec{c}}$, is considered. Particularly, it is shown that sum of all\nprincipal minors of the order two of a matrix $A$ is equal to the sum of all\nprincipal minors of the order two of their symmetric and antisymmetric parts.\nIt is shown that any symmetric matrix and any antisymmetric matrix under the\nmap $\\varphi_{\\vec{c}}$ are simultaneously permutation similar to certain block\nmatrices which have two blocks. Finally, for a fixed matrix $A$, it is proved\nthat the number of different matrices $\\varphi_{\\vec{c}}(A)$ is $2^{n-t}$,\nwhere $t$ is the number of connected components of the graph $G$ whose\nadjacency matrix is $A$.",
            "author": [
                "Jovan Miki\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08933v1",
                "http://arxiv.org/pdf/2309.08933v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA",
                "15B35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08919v1",
            "title": "Pixel Adapter: A Graph-Based Post-Processing Approach for Scene Text\n  Image Super-Resolution",
            "updated": "2023-09-16T08:12:12Z",
            "published": "2023-09-16T08:12:12Z",
            "summary": "Current Scene text image super-resolution approaches primarily focus on\nextracting robust features, acquiring text information, and complex training\nstrategies to generate super-resolution images. However, the upsampling module,\nwhich is crucial in the process of converting low-resolution images to\nhigh-resolution ones, has received little attention in existing works. To\naddress this issue, we propose the Pixel Adapter Module (PAM) based on graph\nattention to address pixel distortion caused by upsampling. The PAM effectively\ncaptures local structural information by allowing each pixel to interact with\nits neighbors and update features. Unlike previous graph attention mechanisms,\nour approach achieves 2-3 orders of magnitude improvement in efficiency and\nmemory utilization by eliminating the dependency on sparse adjacency matrices\nand introducing a sliding window approach for efficient parallel computation.\nAdditionally, we introduce the MLP-based Sequential Residual Block (MSRB) for\nrobust feature extraction from text images, and a Local Contour Awareness loss\n($\\mathcal{L}_{lca}$) to enhance the model's perception of details.\nComprehensive experiments on TextZoom demonstrate that our proposed method\ngenerates high-quality super-resolution images, surpassing existing methods in\nrecognition accuracy. For single-stage and multi-stage strategies, we achieved\nimprovements of 0.7\\% and 2.6\\%, respectively, increasing the performance from\n52.6\\% and 53.7\\% to 53.3\\% and 56.3\\%. The code is available at\nhttps://github.com/wenyu1009/RTSRN.",
            "author": [
                "Wenyu Zhang",
                "Xin Deng",
                "Baojun Jia",
                "Xingtong Yu",
                "Yifan Chen",
                "jin Ma",
                "Qing Ding",
                "Xinming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08919v1",
                "http://arxiv.org/pdf/2309.08919v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08916v2",
            "title": "BGGAN: Generative AI Enables Representing Brain Structure-Function\n  Connections for Alzheimer's Disease",
            "updated": "2023-10-05T08:46:01Z",
            "published": "2023-09-16T07:49:54Z",
            "summary": "The relationship between brain structure and function is critical for\nrevealing the pathogenesis of brain disease, including Alzheimer's disease\n(AD). However, it is a great challenge to map brain structure-function\nconnections due to various reasons. In this work, a bidirectional graph\ngenerative adversarial networks (BGGAN) is proposed to represent brain\nstructure-function connections. Specifically, by designing a module\nincorporating inner graph convolution network (InnerGCN), the generators of\nBGGAN can employ features of direct and indirect brain regions to learn the\nmapping function between structural domain and functional domain. Besides, a\nnew module named Balancer is designed to counterpoise the optimization between\ngenerators and discriminators. By introducing the Balancer into BGGAN, both the\nstructural generator and functional generator can not only alleviate the issue\nof mode collapse but also learn complementarity of structural and functional\nfeatures. Experimental results using ADNI datasets show that the both the\ngenerated structure connections and generated function connections can improve\nthe identification accuracy of AD. More importantly, based the proposed model,\nit is found that the relationship between brain structure and function is not a\ncomplete one-to-one correspondence. Brain structure is the basis of brain\nfunction. The strong structural connections are almost accompanied by strong\nfunctional connections.",
            "author": [
                "Chen Ding",
                "Shuqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08916v2",
                "http://arxiv.org/pdf/2309.08916v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "eess.IV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08914v1",
            "title": "Outram: One-shot Global Localization via Triangulated Scene Graph and\n  Global Outlier Pruning",
            "updated": "2023-09-16T07:39:00Z",
            "published": "2023-09-16T07:39:00Z",
            "summary": "One-shot LiDAR localization refers to the ability to estimate the robot pose\nfrom one single point cloud, which yields significant advantages in\ninitialization and relocalization processes. In the point cloud domain, the\ntopic has been extensively studied as a global descriptor retrieval (i.e., loop\nclosure detection) and pose refinement (i.e., point cloud registration) problem\nboth in isolation or combined. However, few have explicitly considered the\nrelationship between candidate retrieval and correspondence generation in pose\nestimation, leaving them brittle to substructure ambiguities. To this end, we\npropose a hierarchical one-shot localization algorithm called Outram that\nleverages substructures of 3D scene graphs for locally consistent\ncorrespondence searching and global substructure-wise outlier pruning. Such a\nhierarchical process couples the feature retrieval and the correspondence\nextraction to resolve the substructure ambiguities by conducting a\nlocal-to-global consistency refinement. We demonstrate the capability of Outram\nin a variety of scenarios in multiple large-scale outdoor datasets. Our\nimplementation is open-sourced: https://github.com/Pamphlett/Outram.",
            "author": [
                "Pengyu Yin",
                "Haozhi Cao",
                "Thien-Minh Nguyen",
                "Shenghai Yuan",
                "Shuyang Zhang",
                "Kangcheng Liu",
                "Lihua Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08914v1",
                "http://arxiv.org/pdf/2309.08914v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08896v1",
            "title": "Graph-based Decentralized Task Allocation for Multi-Robot Target\n  Localization",
            "updated": "2023-09-16T06:33:12Z",
            "published": "2023-09-16T06:33:12Z",
            "summary": "We introduce a new approach to address the task allocation problem in a\nsystem of heterogeneous robots comprising of Unmanned Ground Vehicles (UGVs)\nand Unmanned Aerial Vehicles (UAVs). The proposed model, \\texttt{\\method}, or\n\\textbf{G}raph \\textbf{A}ttention \\textbf{T}ask \\textbf{A}llocato\\textbf{R}\naggregates information from neighbors in the multi-robot system, with the aim\nof achieving joint optimality in the target localization efficiency.Being\ndecentralized, our method is highly robust and adaptable to situations where\ncollaborators may change over time, ensuring the continuity of the mission. We\nalso proposed heterogeneity-aware preprocessing to let all the different types\nof robots collaborate with a uniform model.The experimental results demonstrate\nthe effectiveness and scalability of the proposed approach in a range of\nsimulated scenarios. The model can allocate targets' positions close to the\nexpert algorithm's result, with a median spatial gap less than a unit length.\nThis approach can be used in multi-robot systems deployed in search and rescue\nmissions, environmental monitoring, and disaster response.",
            "author": [
                "Juntong Peng",
                "Hrishikesh Viswanath",
                "Kshitij Tiwari",
                "Aniket Bera"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08896v1",
                "http://arxiv.org/pdf/2309.08896v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08895v1",
            "title": "CDDM: Channel Denoising Diffusion Models for Wireless Semantic\n  Communications",
            "updated": "2023-09-16T06:32:13Z",
            "published": "2023-09-16T06:32:13Z",
            "summary": "Diffusion models (DM) can gradually learn to remove noise, which have been\nwidely used in artificial intelligence generated content (AIGC) in recent\nyears. The property of DM for eliminating noise leads us to wonder whether DM\ncan be applied to wireless communications to help the receiver mitigate the\nchannel noise. To address this, we propose channel denoising diffusion models\n(CDDM) for semantic communications over wireless channels in this paper. CDDM\ncan be applied as a new physical layer module after the channel equalization to\nlearn the distribution of the channel input signal, and then utilizes this\nlearned knowledge to remove the channel noise. We derive corresponding training\nand sampling algorithms of CDDM according to the forward diffusion process\nspecially designed to adapt the channel models and theoretically prove that the\nwell-trained CDDM can effectively reduce the conditional entropy of the\nreceived signal under small sampling steps. Moreover, we apply CDDM to a\nsemantic communications system based on joint source-channel coding (JSCC) for\nimage transmission. Extensive experimental results demonstrate that CDDM can\nfurther reduce the mean square error (MSE) after minimum mean square error\n(MMSE) equalizer, and the joint CDDM and JSCC system achieves better\nperformance than the JSCC system and the traditional JPEG2000 with low-density\nparity-check (LDPC) code approach.",
            "author": [
                "Tong Wu",
                "Zhiyong Chen",
                "Dazhi He",
                "Liang Qian",
                "Yin Xu",
                "Meixia Tao",
                "Wenjun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08895v1",
                "http://arxiv.org/pdf/2309.08895v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08885v1",
            "title": "Single-frequency lasers' linewidth elegantly characterized with Sigmoid\n  functions of observation time",
            "updated": "2023-09-16T05:37:59Z",
            "published": "2023-09-16T05:37:59Z",
            "summary": "Linewidth is the most important parameter for characterizing the coherence\nproperties of a single-frequency laser, but unfortunately only the natural\nlinewidth representing the contributions of the spontaneous emission or quantum\nnoise can be described with an analytical expression known as the\nSchawlow-Townes-Henry formula. To the best of authors' knowledge, no analytical\nexpression is formulized after 63 years since laser's invention for\ncharacterizing the effective linewidth of a single-frequency laser including\nthe linewidth broadening caused by the flicker noises, which strongly depends\non the measurement duration and is much larger than the natural linewidth. By\ncarefully measuring the instantaneous frequency fluctuations of multiple\ncommercial single-frequency lasers using a self-built optical frequency\nanalyzer with ultra-high resolution and speed to obtain their linewidths with\nour time domain statistical analysis method, we discover and validate that the\nlaser linewidths can be expressed as one or more Sigmoid functions of\nobservation time. Not only the simple Sigmoid linewidth expression provides\nclear linewidth information of the laser, but also better understanding of the\nphysical origins affecting the laser linewidths, which will benefit a large\nnumber of applications ranging from coherent distributed sensing to\ngravitational wave detection and therefore is worthy to be widely adopted to\nfully and elegantly characterize the linewidths of single-frequency lasers.",
            "author": [
                "Xiaosong Ma",
                "X. Steve Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08885v1",
                "http://arxiv.org/pdf/2309.08885v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08880v1",
            "title": "Data-Driven H-infinity Control with a Real-Time and Efficient\n  Reinforcement Learning Algorithm: An Application to Autonomous\n  Mobility-on-Demand Systems",
            "updated": "2023-09-16T05:02:41Z",
            "published": "2023-09-16T05:02:41Z",
            "summary": "Reinforcement learning (RL) is a class of artificial intelligence algorithms\nbeing used to design adaptive optimal controllers through online learning. This\npaper presents a model-free, real-time, data-efficient Q-learning-based\nalgorithm to solve the H$_{\\infty}$ control of linear discrete-time systems.\nThe computational complexity is shown to reduce from\n$\\mathcal{O}(\\underline{q}^3)$ in the literature to\n$\\mathcal{O}(\\underline{q}^2)$ in the proposed algorithm, where $\\underline{q}$\nis quadratic in the sum of the size of state variables, control inputs, and\ndisturbance. An adaptive optimal controller is designed and the parameters of\nthe action and critic networks are learned online without the knowledge of the\nsystem dynamics, making the proposed algorithm completely model-free. Also, a\nsufficient probing noise is only needed in the first iteration and does not\naffect the proposed algorithm. With no need for an initial stabilizing policy,\nthe algorithm converges to the closed-form solution obtained by solving the\nRiccati equation. A simulation study is performed by applying the proposed\nalgorithm to real-time control of an autonomous mobility-on-demand (AMoD)\nsystem for a real-world case study to evaluate the effectiveness of the\nproposed algorithm.",
            "author": [
                "Ali Aalipour",
                "Alireza Khani"
            ],
            "link": [
                "http://dx.doi.org/10.48550/arXiv.2309.08880",
                "http://arxiv.org/abs/2309.08880v1",
                "http://arxiv.org/pdf/2309.08880v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08879v1",
            "title": "Semantic Information Extraction for Text Data with Probability Graph",
            "updated": "2023-09-16T05:01:20Z",
            "published": "2023-09-16T05:01:20Z",
            "summary": "In this paper, the problem of semantic information extraction for resource\nconstrained text data transmission is studied. In the considered model, a\nsequence of text data need to be transmitted within a communication\nresource-constrained network, which only allows limited data transmission.\nThus, at the transmitter, the original text data is extracted with natural\nlanguage processing techniques. Then, the extracted semantic information is\ncaptured in a knowledge graph. An additional probability dimension is\nintroduced in this graph to capture the importance of each information. This\nsemantic information extraction problem is posed as an optimization framework\nwhose goal is to extract most important semantic information for transmission.\nTo find an optimal solution for this problem, a Floyd's algorithm based\nsolution coupled with an efficient sorting mechanism is proposed. Numerical\nresults testify the effectiveness of the proposed algorithm with regards to two\nnovel performance metrics including semantic uncertainty and semantic\nsimilarity.",
            "author": [
                "Zhouxiang Zhao",
                "Zhaohui Yang",
                "Ye Hu",
                "Licheng Lin",
                "Zhaoyang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08879v1",
                "http://arxiv.org/pdf/2309.08879v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.00015v2",
            "title": "Semantic Communication with Probability Graph: A Joint Communication and\n  Computation Design",
            "updated": "2023-10-05T09:46:35Z",
            "published": "2023-09-16T04:54:23Z",
            "summary": "In this paper, we present a probability graph-based semantic information\ncompression system for scenarios where the base station (BS) and the user share\ncommon background knowledge. We employ probability graphs to represent the\nshared knowledge between the communicating parties. During the transmission of\nspecific text data, the BS first extracts semantic information from the text,\nwhich is represented by a knowledge graph. Subsequently, the BS omits certain\nrelational information based on the shared probability graph to reduce the data\nsize. Upon receiving the compressed semantic data, the user can automatically\nrestore missing information using the shared probability graph and predefined\nrules. This approach brings additional computational resource consumption while\neffectively reducing communication resource consumption. Considering the\nlimitations of wireless resources, we address the problem of joint\ncommunication and computation resource allocation design, aiming at minimizing\nthe total communication and computation energy consumption of the network while\nadhering to latency, transmit power, and semantic constraints. Simulation\nresults demonstrate the effectiveness of the proposed system.",
            "author": [
                "Zhouxiang Zhao",
                "Zhaohui Yang",
                "Quoc-Viet Pham",
                "Qianqian Yang",
                "Zhaoyang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.00015v2",
                "http://arxiv.org/pdf/2310.00015v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08866v1",
            "title": "Measuring COVID-19 Related Media Consumption on Twitter",
            "updated": "2023-09-16T04:01:45Z",
            "published": "2023-09-16T04:01:45Z",
            "summary": "The COVID-19 pandemic has been affecting the world dramatically ever since\n2020. The minimum availability of physical interactions during the lockdown has\ncaused more and more people to turn to online activities on social media\nplatforms. These platforms have provided essential updates regarding the\npandemic, serving as bridges for communications. Research on studying these\ncommunications on different platforms emerges during the meantime. Prior\nstudies focus on areas such as topic modeling, sentiment analysis and\nprediction tasks such as predicting COVID-19 positive cases, misinformation\nspread, etc. However, online communications with media outlets remain\nunexplored on an international scale. We have little knowledge about the\npatterns of the media consumption geographically and their association with\noffline political preference. We believe addressing these questions could help\ngovernments and researchers better understand human behaviors during the\npandemic. In this thesis, we specifically investigate the online consumption of\nmedia outlets on Twitter through a set of quantitative analyses. We make use of\nseveral public media outlet datasets to extract media consumption from tweets\ncollected based on COVID-19 keyword matching. We make use of a metric\n\"interaction\" to quantify media consumption through weighted Twitter\nactivities. We further construct a matrix based on it which could be directly\nused to measure user-media consumption in different granularities. We then\nconduct analyses on the United States level and global level. To the best of\nour knowledge, this thesis presents the first-of-its-kind study on media\nconsumption on COVID-19 across countries, it sheds light on understanding how\npeople consume media outlets during the pandemic and provides potential\ninsights for peer researchers.",
            "author": [
                "Cai Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08866v1",
                "http://arxiv.org/pdf/2309.08866v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08845v1",
            "title": "Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis\n  Using U.S. College Subreddit Data from 2019 to 2022",
            "updated": "2023-09-16T02:57:30Z",
            "published": "2023-09-16T02:57:30Z",
            "summary": "As impact of COVID-19 pandemic winds down, both individuals and society\ngradually return to pre-pandemic activities. This study aims to explore how\npeople's emotions have changed from the pre-pandemic during the pandemic to\npost-emergency period and whether it has returned to pre-pandemic level. We\ncollected Reddit data in 2019 (pre-pandemic), 2020 (peak pandemic), 2021, and\n2022 (late stages of pandemic, transitioning period to post-emergency period)\nfrom subreddits in 128 universities/colleges in the U.S., and a set of\nschool-level characteristics. We predicted two sets of sentiments from a\npre-trained Robustly Optimized BERT pre-training approach (RoBERTa) and graph\nattention network (GAT) that leverages both rich semantic and relational\ninformation among posted messages and then applied a logistic stacking method\nto obtain the final sentiment classification. After obtaining sentiment label\nfor each message, we used a generalized linear mixed-effects model to estimate\ntemporal trend in sentiment from 2019 to 2022 and how school-level factors may\naffect sentiment. Compared to the year 2019, the odds of negative sentiment in\nyears 2020, 2021, and 2022 are 24%, 4.3%, and 10.3% higher, respectively, which\nare all statistically significant(adjusted $p$<0.05). Our study findings\nsuggest a partial recovery in the sentiment composition in the\npost-pandemic-emergency era. The results align with common expectations and\nprovide a detailed quantification of how sentiments have evolved from 2019 to\n2022.",
            "author": [
                "Tian Yan",
                "Fang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08845v1",
                "http://arxiv.org/pdf/2309.08845v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08842v1",
            "title": "MA-SAM: Modality-agnostic SAM Adaptation for 3D Medical Image\n  Segmentation",
            "updated": "2023-09-16T02:41:53Z",
            "published": "2023-09-16T02:41:53Z",
            "summary": "The Segment Anything Model (SAM), a foundation model for general image\nsegmentation, has demonstrated impressive zero-shot performance across numerous\nnatural image segmentation tasks. However, SAM's performance significantly\ndeclines when applied to medical images, primarily due to the substantial\ndisparity between natural and medical image domains. To effectively adapt SAM\nto medical images, it is important to incorporate critical third-dimensional\ninformation, i.e., volumetric or temporal knowledge, during fine-tuning.\nSimultaneously, we aim to harness SAM's pre-trained weights within its original\n2D backbone to the fullest extent. In this paper, we introduce a\nmodality-agnostic SAM adaptation framework, named as MA-SAM, that is applicable\nto various volumetric and video medical data. Our method roots in the\nparameter-efficient fine-tuning strategy to update only a small portion of\nweight increments while preserving the majority of SAM's pre-trained weights.\nBy injecting a series of 3D adapters into the transformer blocks of the image\nencoder, our method enables the pre-trained 2D backbone to extract\nthird-dimensional information from input data. The effectiveness of our method\nhas been comprehensively evaluated on four medical image segmentation tasks, by\nusing 10 public datasets across CT, MRI, and surgical video data. Remarkably,\nwithout using any prompt, our method consistently outperforms various\nstate-of-the-art 3D approaches, surpassing nnU-Net by 0.9%, 2.6%, and 9.9% in\nDice for CT multi-organ segmentation, MRI prostate segmentation, and surgical\nscene segmentation respectively. Our model also demonstrates strong\ngeneralization, and excels in challenging tumor segmentation when prompts are\nused. Our code is available at: https://github.com/cchen-cc/MA-SAM.",
            "author": [
                "Cheng Chen",
                "Juzheng Miao",
                "Dufan Wu",
                "Zhiling Yan",
                "Sekeun Kim",
                "Jiang Hu",
                "Aoxiao Zhong",
                "Zhengliang Liu",
                "Lichao Sun",
                "Xiang Li",
                "Tianming Liu",
                "Pheng-Ann Heng",
                "Quanzheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08842v1",
                "http://arxiv.org/pdf/2309.08842v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08838v1",
            "title": "AOSR-Net: All-in-One Sandstorm Removal Network",
            "updated": "2023-09-16T02:11:24Z",
            "published": "2023-09-16T02:11:24Z",
            "summary": "Most existing sandstorm image enhancement methods are based on traditional\ntheory and prior knowledge, which often restrict their applicability in\nreal-world scenarios. In addition, these approaches often adopt a strategy of\ncolor correction followed by dust removal, which makes the algorithm structure\ntoo complex. To solve the issue, we introduce a novel image restoration model,\nnamed all-in-one sandstorm removal network (AOSR-Net). This model is developed\nbased on a re-formulated sandstorm scattering model, which directly establishes\nthe image mapping relationship by integrating intermediate parameters. Such\nintegration scheme effectively addresses the problems of over-enhancement and\nweak generalization in the field of sand dust image enhancement. Experimental\nresults on synthetic and real-world sandstorm images demonstrate the\nsuperiority of the proposed AOSR-Net over state-of-the-art (SOTA) algorithms.",
            "author": [
                "Yazhong Si",
                "Xulong Zhang",
                "Fan Yang",
                "Jianzong Wang",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08838v1",
                "http://arxiv.org/pdf/2309.08838v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08837v1",
            "title": "FastGraphTTS: An Ultrafast Syntax-Aware Speech Synthesis Framework",
            "updated": "2023-09-16T02:10:16Z",
            "published": "2023-09-16T02:10:16Z",
            "summary": "This paper integrates graph-to-sequence into an end-to-end text-to-speech\nframework for syntax-aware modelling with syntactic information of input text.\nSpecifically, the input text is parsed by a dependency parsing module to form a\nsyntactic graph. The syntactic graph is then encoded by a graph encoder to\nextract the syntactic hidden information, which is concatenated with phoneme\nembedding and input to the alignment and flow-based decoding modules to\ngenerate the raw audio waveform. The model is experimented on two languages,\nEnglish and Mandarin, using single-speaker, few samples of target speakers, and\nmulti-speaker datasets, respectively. Experimental results show better prosodic\nconsistency performance between input text and generated audio, and also get\nhigher scores in the subjective prosodic evaluation, and show the ability of\nvoice conversion. Besides, the efficiency of the model is largely boosted\nthrough the design of the AI chip operator with 5x acceleration.",
            "author": [
                "Jianzong Wang",
                "Xulong Zhang",
                "Aolan Sun",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08837v1",
                "http://arxiv.org/pdf/2309.08837v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08834v1",
            "title": "Random Maps with Sociological Flavor",
            "updated": "2023-09-16T01:38:36Z",
            "published": "2023-09-16T01:38:36Z",
            "summary": "A map of a set to itself admits a representation by a directed graph with\nvertices being the elements of the set and directed edges from vertexes to\ntheir images. Disregarding directionality, one defines communities as the\nmaximal connected components and notices that each community is uni-cyclic. The\ndistributions of the sizes of communities and lengths of cycles in graphs\nrepresenting unconstrained random maps is a classical subject. We define\nexperts as images, followers as vertexes that are not experts, and further\nnotions including prophets, founders, egocentrics, introverts, etc. We\nintroduce and analyze classes of random maps with sociological flavor.",
            "author": [
                "P. L. Krapivsky"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08834v1",
                "http://arxiv.org/pdf/2309.08834v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cond-mat.stat-mech",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08829v1",
            "title": "Exact description of limiting SIR and SEIR dynamics on locally tree-like\n  graphs",
            "updated": "2023-09-16T01:12:53Z",
            "published": "2023-09-16T01:12:53Z",
            "summary": "We study the Susceptible-Infected-Recovered (SIR) and the\nSusceptible-Exposed-Infected-Recovered (SEIR) models of epidemics, with\npossibly time-varying rates, on a class of networks that are locally tree-like,\nwhich includes sparse Erd\\H{o}s-R\\`enyi random graphs, random regular graphs,\nand other configuration models. We identify tractable systems of ODEs that\nexactly describe the dynamics of the SIR and SEIR processes in a suitable\nasymptotic regime in which the population size goes to infinity. Moreover, in\nthe case of constant recovery and infection rates, we characterize the outbreak\nsize as the unique zero of an explicit functional. We use this to show that a\n(suitably defined) mean-field prediction always overestimates the outbreak\nsize, and that the outbreak sizes for SIR and SEIR processes with the same\ninitial condition and constant infection and recovery rates coincide. In\ncontrast, we show that the outbreak sizes for SIR and SEIR processes with the\nsame time-varying infection and recovery rates can in general be quite\ndifferent. We also demonstrate via simulations the efficacy of our\napproximations for populations of moderate size.",
            "author": [
                "Juniper Cocomello",
                "Kavita Ramanan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08829v1",
                "http://arxiv.org/pdf/2309.08829v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.DS",
                "q-bio.PE",
                "60K35, 60F17 (Primary), 60G60, 60J2 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08828v1",
            "title": "Boosting End-to-End Multilingual Phoneme Recognition through Exploiting\n  Universal Speech Attributes Constraints",
            "updated": "2023-09-16T01:08:22Z",
            "published": "2023-09-16T01:08:22Z",
            "summary": "We propose a first step toward multilingual end-to-end automatic speech\nrecognition (ASR) by integrating knowledge about speech articulators. The key\nidea is to leverage a rich set of fundamental units that can be defined\n\"universally\" across all spoken languages, referred to as speech attributes,\nnamely manner and place of articulation. Specifically, several deterministic\nattribute-to-phoneme mapping matrices are constructed based on the predefined\nset of universal attribute inventory, which projects the knowledge-rich\narticulatory attribute logits, into output phoneme logits. The mapping puts\nknowledge-based constraints to limit inconsistency with acoustic-phonetic\nevidence in the integrated prediction. Combined with phoneme recognition, our\nphone recognizer is able to infer from both attribute and phoneme information.\nThe proposed joint multilingual model is evaluated through phoneme recognition.\nIn multilingual experiments over 6 languages on benchmark datasets LibriSpeech\nand CommonVoice, we find that our proposed solution outperforms conventional\nmultilingual approaches with a relative improvement of 6.85% on average, and it\nalso demonstrates a much better performance compared to monolingual model.\nFurther analysis conclusively demonstrates that the proposed solution\neliminates phoneme predictions that are inconsistent with attributes.",
            "author": [
                "Hao Yen",
                "Sabato Marco Siniscalchi",
                "Chin-Hui Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08828v1",
                "http://arxiv.org/pdf/2309.08828v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08819v1",
            "title": "The Cohen-Macaulay type of edge-weighted r-path ideals",
            "updated": "2023-09-16T00:31:40Z",
            "published": "2023-09-16T00:31:40Z",
            "summary": "We describe combinatorially the Cohen-Macaulay type of edge-weighted r-path\nsuspensions of edge-weighted graphs for an arbitrary positive integer r. The\ncomputation of the Cohen-Macaulay type of edge-weighted suspensions of\nedge-weighted graphs becomes a special case of r = 1.",
            "author": [
                "Shuai Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08819v1",
                "http://arxiv.org/pdf/2309.08819v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08815v1",
            "title": "Hybrid Quantum-Classical Multilevel Approach for Maximum Cuts on Graphs",
            "updated": "2023-09-15T23:54:46Z",
            "published": "2023-09-15T23:54:46Z",
            "summary": "Combinatorial optimization is one of the fields where near term quantum\ndevices are being utilized with hybrid quantum-classical algorithms to\ndemonstrate potentially practical applications of quantum computing. One of the\nmost well studied problems in combinatorial optimization is the Max-Cut\nproblem. The problem is also highly relevant to quantum and other types of\n\"post Moore\" architectures due to its similarity with the Ising model and other\nreasons. In this paper, we introduce a scalable hybrid multilevel approach to\nsolve large instances of Max-Cut using both classical only solvers and quantum\napproximate optimization algorithm (QAOA). We compare the results of our solver\nto existing state of the art large-scale Max-Cut solvers. We demonstrate\nexcellent performance of both classical and hybrid quantum-classical approaches\nand show that using QAOA within our framework is comparable to classical\napproaches.",
            "author": [
                "Anthony Angone",
                "Xioayuan Liu",
                "Ruslan Shaydulin",
                "Ilya Safro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08815v1",
                "http://arxiv.org/pdf/2309.08815v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08810v1",
            "title": "Global trends of the electric dipole polarizability from shell-model\n  calculations",
            "updated": "2023-09-15T23:27:59Z",
            "published": "2023-09-15T23:27:59Z",
            "summary": "Shell-model calculations of the electric dipole (E1) polarizability have been\nperformed for the ground state of selected p- and sd-shell nuclei,\nsubstantially advancing previous knowledge. Our results are slightly larger\ncompared with the somewhat more scattered photo-absorption cross-section data,\nalbeit agreeing with ab initio calculations at shell closures and presenting a\nsmooth trend that follows the leptodermus approximation provided by the\nfinite-range droplet model (FRDM). The total E1 strengths also show an\nincreasing trend proportional to the mass number which follows from the\nclassical oscillator strength (TRK) sum rule for the E1 operator. The\nenhancement of the energy-weighted sum over E1 excitations with respect to the\nTRK sum rule arises from the use of experimental single-particle energies and\nthe residual particle-hole interaction.",
            "author": [
                "Jos\u00e9 Nicol\u00e1s Orce",
                "Cebo Ngwetsheni",
                "B. Alex Brown"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08810v1",
                "http://arxiv.org/pdf/2309.08810v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08797v1",
            "title": "On the Asymptotics of Graph Cut Objectives for Experimental Designs of\n  Network A/B Testing",
            "updated": "2023-09-15T22:43:20Z",
            "published": "2023-09-15T22:43:20Z",
            "summary": "A/B testing is an effective way to assess the potential impacts of two\ntreatments. For A/B tests conducted by IT companies, the test users of A/B\ntesting are often connected and form a social network. The responses of A/B\ntesting can be related to the network connection of test users. This paper\ndiscusses the relationship between the design criteria of network A/B testing\nand graph cut objectives. We develop asymptotic distributions of graph cut\nobjectives to enable rerandomization algorithms for the design of network A/B\ntesting under two scenarios.",
            "author": [
                "Qiong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08797v1",
                "http://arxiv.org/pdf/2309.08797v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08794v1",
            "title": "Privacy-preserving Early Detection of Epileptic Seizures in Videos",
            "updated": "2023-09-15T22:29:07Z",
            "published": "2023-09-15T22:29:07Z",
            "summary": "In this work, we contribute towards the development of video-based epileptic\nseizure classification by introducing a novel framework (SETR-PKD), which could\nachieve privacy-preserved early detection of seizures in videos. Specifically,\nour framework has two significant components - (1) It is built upon optical\nflow features extracted from the video of a seizure, which encodes the seizure\nmotion semiotics while preserving the privacy of the patient; (2) It utilizes a\ntransformer based progressive knowledge distillation, where the knowledge is\ngradually distilled from networks trained on a longer portion of video samples\nto the ones which will operate on shorter portions. Thus, our proposed\nframework addresses the limitations of the current approaches which compromise\nthe privacy of the patients by directly operating on the RGB video of a seizure\nas well as impede real-time detection of a seizure by utilizing the full video\nsample to make a prediction. Our SETR-PKD framework could detect tonic-clonic\nseizures (TCSs) in a privacy-preserving manner with an accuracy of 83.9% while\nthey are only half-way into their progression. Our data and code is available\nat https://github.com/DevD1092/seizure-detection",
            "author": [
                "Deval Mehta",
                "Shobi Sivathamboo",
                "Hugh Simpson",
                "Patrick Kwan",
                "Terence O`Brien",
                "Zongyuan Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08794v1",
                "http://arxiv.org/pdf/2309.08794v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08788v1",
            "title": "BioinspiredLLM: Conversational Large Language Model for the Mechanics of\n  Biological and Bio-inspired Materials",
            "updated": "2023-09-15T22:12:44Z",
            "published": "2023-09-15T22:12:44Z",
            "summary": "The study of biological materials and bio-inspired materials science is well\nestablished; however, surprisingly little knowledge has been systematically\ntranslated to engineering solutions. To accelerate discovery and guide\ninsights, an open-source autoregressive transformer large language model,\nBioinspiredLLM, is reported. The model was finetuned with a corpus of over a\nthousand peer-reviewed articles in the field of structural biological and\nbio-inspired materials and can be prompted to actively and interactively recall\ninformation, assist with research tasks, and function as an engine for\ncreativity. The model has proven by example that it is not only able to\naccurately recall information about biological materials when queried but also\nformulate biomaterials questions and answers that can evaluate its own\nperformance. BioinspiredLLM also has been shown to develop sound hypotheses\nregarding biological materials design and remarkably so for materials that have\nnever been explicitly studied before. Lastly, the model showed impressive\npromise in collaborating with other generative artificial intelligence models\nin a workflow that can reshape the traditional materials design process. This\ncollaborative generative artificial intelligence method can stimulate and\nenhance bio-inspired materials design workflows. Biological materials is at a\ncritical intersection of multiple scientific fields and models like\nBioinspiredLLM help to connect knowledge domains.",
            "author": [
                "Rachel K. Luu",
                "Markus J. Buehler"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08788v1",
                "http://arxiv.org/pdf/2309.08788v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.dis-nn",
                "cond-mat.soft",
                "cs.LG",
                "nlin.AO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08780v1",
            "title": "Simultaneous Trajectory Estimation and Mapping for Autonomous Underwater\n  Proximity Operations",
            "updated": "2023-09-15T21:58:07Z",
            "published": "2023-09-15T21:58:07Z",
            "summary": "Due to the challenges regarding the limits of their endurance and autonomous\ncapabilities, underwater docking for autonomous underwater vehicles (AUVs) has\nbecome a topic of interest for many academic and commercial applications.\nHerein, we take on the problem of state estimation during an autonomous\nunderwater docking mission. Docking operations typically involve only two\nactors, a chaser and a target. We leverage the similarities to proximity\noperations (prox-ops) from spacecraft robotic missions to frame the diverse\ndocking scenarios with a set of phases the chaser undergoes on the way to its\ntarget. We use factor graphs to generalize the underlying estimation problem\nfor arbitrary underwater prox-ops. To showcase our framework, we use this\nfactor graph approach to model an underwater homing scenario with an active\ntarget as a Simultaneous Localization and Mapping problem. Using basic AUV\nnavigation sensors, relative Ultra-short Baseline measurements, and the\nassumption of constant dynamics for the target, we derive factors that\nconstrain the chaser's state and the position and trajectory of the target. We\ndetail our front- and back-end software implementation using open-source\nsoftware and libraries, and verify its performance with both simulated and\nfield experiments. Obtained results show an overall increase in performance\nagainst the unprocessed measurements, regardless of the presence of an\nadversarial target whose dynamics void the modeled assumptions. However,\nchallenges with unmodeled noise parameters and stringent target motion\nassumptions shed light on limitations that must be addressed to enhance the\naccuracy and consistency of the proposed approach.",
            "author": [
                "Aldo Ter\u00e1n Espinoza",
                "Antonio Ter\u00e1n Espinoza",
                "John Folkesson",
                "Niklas Rolleberg",
                "Peter Sigray",
                "Jakob Kuttenkeuler"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08780v1",
                "http://arxiv.org/pdf/2309.08780v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08765v1",
            "title": "Mining Patents with Large Language Models Demonstrates Congruence of\n  Functional Labels and Chemical Structures",
            "updated": "2023-09-15T21:08:41Z",
            "published": "2023-09-15T21:08:41Z",
            "summary": "Predicting chemical function from structure is a major goal of the chemical\nsciences, from the discovery and repurposing of novel drugs to the creation of\nnew materials. Recently, new machine learning algorithms are opening up the\npossibility of general predictive models spanning many different chemical\nfunctions. Here, we consider the challenge of applying large language models to\nchemical patents in order to consolidate and leverage the information about\nchemical functionality captured by these resources. Chemical patents contain\nvast knowledge on chemical function, but their usefulness as a dataset has\nhistorically been neglected due to the impracticality of extracting\nhigh-quality functional labels. Using a scalable ChatGPT-assisted patent\nsummarization and word-embedding label cleaning pipeline, we derive a Chemical\nFunction (CheF) dataset, containing 100K molecules and their patent-derived\nfunctional labels. The functional labels were validated to be of high quality,\nallowing us to detect a strong relationship between functional label and\nchemical structural spaces. Further, we find that the co-occurrence graph of\nthe functional labels contains a robust semantic structure, which allowed us in\nturn to examine functional relatedness among the compounds. We then trained a\nmodel on the CheF dataset, allowing us to assign new functional labels to\ncompounds. Using this model, we were able to retrodict approved Hepatitis C\nantivirals, uncover an antiviral mechanism undisclosed in the patent, and\nidentify plausible serotonin-related drugs. The CheF dataset and associated\nmodel offers a promising new approach to predict chemical functionality.",
            "author": [
                "Clayton W. Kosonocky",
                "Claus O. Wilke",
                "Edward M. Marcotte",
                "Andrew D. Ellington"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08765v1",
                "http://arxiv.org/pdf/2309.08765v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08754v1",
            "title": "Reproducible Domain-Specific Knowledge Graphs in the Life Sciences: a\n  Systematic Literature Review",
            "updated": "2023-09-15T20:40:59Z",
            "published": "2023-09-15T20:40:59Z",
            "summary": "Knowledge graphs (KGs) are widely used for representing and organizing\nstructured knowledge in diverse domains. However, the creation and upkeep of\nKGs pose substantial challenges. Developing a KG demands extensive expertise in\ndata modeling, ontology design, and data curation. Furthermore, KGs are\ndynamic, requiring continuous updates and quality control to ensure accuracy\nand relevance. These intricacies contribute to the considerable effort required\nfor their development and maintenance. One critical dimension of KGs that\nwarrants attention is reproducibility. The ability to replicate and validate\nKGs is fundamental for ensuring the trustworthiness and sustainability of the\nknowledge they represent. Reproducible KGs not only support open science by\nallowing others to build upon existing knowledge but also enhance transparency\nand reliability in disseminating information. Despite the growing number of\ndomain-specific KGs, a comprehensive analysis concerning their reproducibility\nhas been lacking. This paper addresses this gap by offering a general overview\nof domain-specific KGs and comparing them based on various reproducibility\ncriteria. Our study over 19 different domains shows only eight out of 250\ndomain-specific KGs (3.2%) provide publicly available source code. Among these,\nonly one system could successfully pass our reproducibility assessment (14.3%).\nThese findings highlight the challenges and gaps in achieving reproducibility\nacross domain-specific KGs. Our finding that only 0.4% of published\ndomain-specific KGs are reproducible shows a clear need for further research\nand a shift in cultural practices.",
            "author": [
                "Samira Babalou",
                "Sheeba Samuel",
                "Birgitta K\u00f6nig-Ries"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08754v1",
                "http://arxiv.org/pdf/2309.08754v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08751v1",
            "title": "Diverse Neural Audio Embeddings -- Bringing Features back !",
            "updated": "2023-09-15T20:27:47Z",
            "published": "2023-09-15T20:27:47Z",
            "summary": "With the advent of modern AI architectures, a shift has happened towards\nend-to-end architectures. This pivot has led to neural architectures being\ntrained without domain-specific biases/knowledge, optimized according to the\ntask. We in this paper, learn audio embeddings via diverse feature\nrepresentations, in this case, domain-specific. For the case of audio\nclassification over hundreds of categories of sound, we learn robust separate\nembeddings for diverse audio properties such as pitch, timbre, and neural\nrepresentation, along with also learning it via an end-to-end architecture. We\nobserve handcrafted embeddings, e.g., pitch and timbre-based, although on their\nown, are not able to beat a fully end-to-end representation, yet adding these\ntogether with end-to-end embedding helps us, significantly improve performance.\nThis work would pave the way to bring some domain expertise with end-to-end\nmodels to learn robust, diverse representations, surpassing the performance of\njust training end-to-end models.",
            "author": [
                "Prateek Verma"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08751v1",
                "http://arxiv.org/pdf/2309.08751v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08739v1",
            "title": "Concept explainability for plant diseases classification",
            "updated": "2023-09-15T19:57:50Z",
            "published": "2023-09-15T19:57:50Z",
            "summary": "Plant diseases remain a considerable threat to food security and agricultural\nsustainability. Rapid and early identification of these diseases has become a\nsignificant concern motivating several studies to rely on the increasing global\ndigitalization and the recent advances in computer vision based on deep\nlearning. In fact, plant disease classification based on deep convolutional\nneural networks has shown impressive performance. However, these methods have\nyet to be adopted globally due to concerns regarding their robustness,\ntransparency, and the lack of explainability compared with their human experts\ncounterparts. Methods such as saliency-based approaches associating the network\noutput to perturbations of the input pixels have been proposed to give insights\ninto these algorithms. Still, they are not easily comprehensible and not\nintuitive for human users and are threatened by bias. In this work, we deploy a\nmethod called Testing with Concept Activation Vectors (TCAV) that shifts the\nfocus from pixels to user-defined concepts. To the best of our knowledge, our\npaper is the first to employ this method in the field of plant disease\nclassification. Important concepts such as color, texture and disease related\nconcepts were analyzed. The results suggest that concept-based explanation\nmethods can significantly benefit automated plant disease identification.",
            "author": [
                "Jihen Amara",
                "Birgitta K\u00f6nig-Ries",
                "Sheeba Samuel"
            ],
            "link": [
                "http://dx.doi.org/10.5220/0011667900003417",
                "http://arxiv.org/abs/2309.08739v1",
                "http://arxiv.org/pdf/2309.08739v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08735v1",
            "title": "On groups with Schottky set boundary",
            "updated": "2023-09-15T19:52:52Z",
            "published": "2023-09-15T19:52:52Z",
            "summary": "We study relatively hyperbolic group pairs whose boundaries are Schottky\nsets. We characterize the groups that have boundaries where the Schottky sets\nhave incidence graphs with 1 or 2 components.",
            "author": [
                "Peter Ha\u00efssinsky",
                "Luisa Paoluzzi",
                "Genevieve Walsh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08735v1",
                "http://arxiv.org/pdf/2309.08735v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.GR",
                "20F67, Secondary 20F65, 20H10, 20E99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08721v1",
            "title": "Relative $h$-principles for closed stable forms",
            "updated": "2023-09-15T19:14:25Z",
            "published": "2023-09-15T19:14:25Z",
            "summary": "This paper uses convex integration to develop a new, general method for\nproving relative $h$-principles for closed, stable, exterior forms on\nmanifolds. This method is applied to prove the relative $h$-principle for 4\nclasses of closed stable forms which were previously not known to satisfy the\n$h$-principle, $\\textit{viz.}$ stable $(2k-2)$-forms in $2k$ dimensions, stable\n$(2k-1)$-forms in $2k+1$ dimensions, $\\widetilde{\\mathrm{G}}_2$ 3-forms and\n$\\widetilde{\\mathrm{G}}_2$ 4-forms. The method is also used to produce new,\nunified proofs of all three previously established $h$-principles for closed,\nstable forms, $\\textit{viz.}$ the $h$-principles for closed stable 2-forms in\n$2k+1$ dimensions, closed $\\mathrm{G}_2$ 4-forms and closed\n$\\mathrm{SL}(3;\\mathbb{C})$ 3-forms. In addition, it is shown that if a class\nof closed stable forms satisfies the relative $h$-principle, then the\ncorresponding Hitchin functional (whenever defined) is necessarily unbounded\nabove.\n  Due to the general nature of the $h$-principles considered in this paper, the\napplication of convex integration requires an analogue of Hodge decomposition\non arbitrary $n$-manifolds (possibly non-compact, or with boundary) which\ncannot, to the author's knowledge, be found elsewhere in the literature. Such a\ndecomposition is proven in Appendix A.",
            "author": [
                "Laurence H. Mayther"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08721v1",
                "http://arxiv.org/pdf/2309.08721v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "math.AT",
                "math.FA",
                "math.GT",
                "53C10, 53D15, 15A69, 15A72, 55P10, 35R45 (Primary) 15A75, 58A20,\n  46A04, 46A11, 58A12, 57R05 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08714v1",
            "title": "Generating Semantic Graph Corpora with Graph Expansion Grammar",
            "updated": "2023-09-15T19:10:19Z",
            "published": "2023-09-15T19:10:19Z",
            "summary": "We introduce Lovelace, a tool for creating corpora of semantic graphs. The\nsystem uses graph expansion grammar as a representational language, thus\nallowing users to craft a grammar that describes a corpus with desired\nproperties. When given such grammar as input, the system generates a set of\noutput graphs that are well-formed according to the grammar, i.e., a graph\nbank. The generation process can be controlled via a number of configurable\nparameters that allow the user to, for example, specify a range of desired\noutput graph sizes. Central use cases are the creation of synthetic data to\naugment existing corpora, and as a pedagogical tool for teaching formal\nlanguage theory.",
            "author": [
                "Eric Andersson",
                "Johanna Bj\u00f6rklund",
                "Frank Drewes",
                "Anna Jonsson"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.388.3",
                "http://arxiv.org/abs/2309.08714v1",
                "http://arxiv.org/pdf/2309.08714v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.CL",
                "F.4.3; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08713v3",
            "title": "How does international guidance for statistical practice align with the\n  ASA Ethical Guidelines?",
            "updated": "2023-10-31T16:57:36Z",
            "published": "2023-09-15T19:05:28Z",
            "summary": "Gillikin (2017) defines a 'practice standard' as a document to 'define the\nway the profession's body of knowledge is ethically translated into day-to-day\nactivities' (Gillikin 2017, p. 1). Such documents fulfill three objectives:\nthey 1) define the profession; 2) communicate uniform standards to\nstakeholders; and 3) reduce conflicts between personal and professional conduct\n(Gillikin, 2017 p. 2). However, there are many guidelines - this is due to\ndifferent purposes that guidance writers may have, as well as to the fact that\nthere are different audiences for the many guidance documents. The existence of\ndiverse statements do not necessarily make it clear that there are\ncommonalities; and while some statements are explicitly aspirational,\nprofessionals as well as the public need to know that ethically-trained\npractitioners follow accepted practice standards. This paper applies the\nmethodological approach described in Tractenberg (2023) and demonstrated in\nPark and Tractenberg (2023) to study alignment among international guidance for\nofficial statistics, and between these guidance documents and the ASA Ethical\nGuidelines for Statistical Practice functioning as an ethical practice standard\n(Tractenberg, 2022-A, 2022-B; after Gillikin 2017). In the spirit of exchanging\nexperiences and lessons learned, we discuss how our findings could inform\ncloser examination, clarification, and, if beneficial, possible revision of\nguidance in the future.",
            "author": [
                "Rochelle E. Tractenberg",
                "Jennifer Park"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08713v3",
                "http://arxiv.org/pdf/2309.08713v3"
            ],
            "primary_category": "stat.OT",
            "category": [
                "stat.OT",
                "62-00, 62-40J, 62-P99",
                "A.2; E.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08709v1",
            "title": "Price of Safety in Linear Best Arm Identification",
            "updated": "2023-09-15T19:01:21Z",
            "published": "2023-09-15T19:01:21Z",
            "summary": "We introduce the safe best-arm identification framework with linear feedback,\nwhere the agent is subject to some stage-wise safety constraint that linearly\ndepends on an unknown parameter vector. The agent must take actions in a\nconservative way so as to ensure that the safety constraint is not violated\nwith high probability at each round. Ways of leveraging the linear structure\nfor ensuring safety has been studied for regret minimization, but not for\nbest-arm identification to the best our knowledge. We propose a gap-based\nalgorithm that achieves meaningful sample complexity while ensuring the\nstage-wise safety. We show that we pay an extra term in the sample complexity\ndue to the forced exploration phase incurred by the additional safety\nconstraint. Experimental illustrations are provided to justify the design of\nour algorithm.",
            "author": [
                "Xuedong Shang",
                "Igor Colin",
                "Merwan Barlier",
                "Hamza Cherkaoui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08709v1",
                "http://arxiv.org/pdf/2309.08709v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08691v1",
            "title": "The additive-multiplicative distance matrix of a graph, and a novel\n  third invariant",
            "updated": "2023-09-15T18:31:38Z",
            "published": "2023-09-15T18:31:38Z",
            "summary": "Graham showed with Pollak and Hoffman-Hosoya that for any directed graph $G$\nwith strong blocks $G_e$, the determinant $\\det(D_G)$ and cofactor-sum\n$cof(D_G)$ of the distance matrix $D_G$ can be computed from the same\nquantities for the blocks $G_e$. This was extended to trees - and in our recent\nwork to any graph - with multiplicative and $q$-distance matrices. For trees,\nwe went further and unified all previous variants with weights in a unital\ncommutative ring, into a distance matrix with additive and multiplicative\nedge-data.\n  In this work: (1) We introduce the additive-multiplicative distance matrix\n$D_G$ of every strongly connected graph $G$, using what we term the\nadditive-multiplicative block-datum $\\mathcal{G}$. This subsumes the previously\nstudied additive, multiplicative, and $q$-distances for all graphs. (2) We\nintroduce an invariant $\\kappa(D_G)$ that seems novel to date, and use it to\nshow \"master\" Graham-Hoffman-Hosoya (GHH) identities, which express $\\det(D_G),\ncof(D_G)$ in terms of the blocks $G_e$. We show how these imply all previous\nvariants. (3) We show $\\det(.), cof(.), \\kappa(.)$ depend only on the\nblock-data for not just $D_G$, but also several minors of $D_G$. This was not\nstudied in any setting to date; we show it in the \"most general\"\nadditive-multiplicative setting, hence in all known settings. (4) We compute\n$D_G^{-1}$ in closed-form; this specializes to all known variants. In\nparticular, we recover our previous formula for $D_T^{-1}$ for\nadditive-multiplicative trees (which itself specializes to a result of\nGraham-Lovasz and answers a 2006 question of Bapat-Lal-Pati.) (5) We also show\nthat not the Laplacian, but a closely related matrix is the \"correct\" one to\nuse in $D_G^{-1}$ - for the most general additive-multiplicative matrix $D_G$\nof each $G$. As examples, we compute in closed form $\\det(D_G), cof(D_G),\n\\kappa(D_G), D_G^{-1}$ for hypertrees.",
            "author": [
                "Projesh Nath Choudhury",
                "Apoorva Khare"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08691v1",
                "http://arxiv.org/pdf/2309.08691v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C12 (primary), 05C20, 05C22, 05C25, 05C50, 05C83, 15A15\n  (secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18315v1",
            "title": "Systematic Analysis of COVID-19 Ontologies",
            "updated": "2023-09-15T18:17:01Z",
            "published": "2023-09-15T18:17:01Z",
            "summary": "This comprehensive study conducts an in-depth analysis of existing COVID-19\nontologies, scrutinizing their objectives, classifications, design\nmethodologies, and domain focal points. The study is conducted through a\ndual-stage approach, commencing with a systematic review of relevant literature\nand followed by an ontological assessment utilizing a parametric methodology.\nThrough this meticulous process, twenty-four COVID-19 Ontologies (CovOs) are\nselected and examined. The findings highlight the scope, intended purpose,\ngranularity of ontology, modularity, formalism, vocabulary reuse, and extent of\ndomain coverage. The analysis reveals varying levels of formality in ontology\ndevelopment, a prevalent preference for utilizing OWL as the representational\nlanguage, and diverse approaches to constructing class hierarchies within the\nmodels. Noteworthy is the recurrent reuse of ontologies like OBO models (CIDO,\nGO, etc.) alongside CODO. The METHONTOLOGY approach emerges as a favored design\nmethodology, often coupled with application-based or data-centric evaluation\nmethods. Our study provides valuable insights for the scientific community and\nCOVID-19 ontology developers, supplemented by comprehensive ontology metrics.\nBy meticulously evaluating and documenting COVID-19 information-driven\nontological models, this research offers a comparative cross-domain\nperspective, shedding light on knowledge representation variations. The present\nstudy significantly enhances understanding of CovOs, serving as a consolidated\nresource for comparative analysis and future development, while also\npinpointing research gaps and domain emphases, thereby guiding the trajectory\nof future ontological advancements.",
            "author": [
                "Debanjali Bain",
                "Biswanath Dutta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18315v1",
                "http://arxiv.org/pdf/2310.18315v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08596v1",
            "title": "Robust e-NeRF: NeRF from Sparse & Noisy Events under Non-Uniform Motion",
            "updated": "2023-09-15T17:52:08Z",
            "published": "2023-09-15T17:52:08Z",
            "summary": "Event cameras offer many advantages over standard cameras due to their\ndistinctive principle of operation: low power, low latency, high temporal\nresolution and high dynamic range. Nonetheless, the success of many downstream\nvisual applications also hinges on an efficient and effective scene\nrepresentation, where Neural Radiance Field (NeRF) is seen as the leading\ncandidate. Such promise and potential of event cameras and NeRF inspired recent\nworks to investigate on the reconstruction of NeRF from moving event cameras.\nHowever, these works are mainly limited in terms of the dependence on dense and\nlow-noise event streams, as well as generalization to arbitrary contrast\nthreshold values and camera speed profiles. In this work, we propose Robust\ne-NeRF, a novel method to directly and robustly reconstruct NeRFs from moving\nevent cameras under various real-world conditions, especially from sparse and\nnoisy events generated under non-uniform motion. It consists of two key\ncomponents: a realistic event generation model that accounts for various\nintrinsic parameters (e.g. time-independent, asymmetric threshold and\nrefractory period) and non-idealities (e.g. pixel-to-pixel threshold\nvariation), as well as a complementary pair of normalized reconstruction losses\nthat can effectively generalize to arbitrary speed profiles and intrinsic\nparameter values without such prior knowledge. Experiments on real and novel\nrealistically simulated sequences verify our effectiveness. Our code, synthetic\ndataset and improved event simulator are public.",
            "author": [
                "Weng Fei Low",
                "Gim Hee Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08596v1",
                "http://arxiv.org/pdf/2309.08596v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08594v1",
            "title": "\"Merge Conflicts!\" Exploring the Impacts of External Distractors to\n  Parametric Knowledge Graphs",
            "updated": "2023-09-15T17:47:59Z",
            "published": "2023-09-15T17:47:59Z",
            "summary": "Large language models (LLMs) acquire extensive knowledge during pre-training,\nknown as their parametric knowledge. However, in order to remain up-to-date and\nalign with human instructions, LLMs inevitably require external knowledge\nduring their interactions with users. This raises a crucial question: How will\nLLMs respond when external knowledge interferes with their parametric\nknowledge? To investigate this question, we propose a framework that\nsystematically elicits LLM parametric knowledge and introduces external\nknowledge. Specifically, we uncover the impacts by constructing a parametric\nknowledge graph to reveal the different knowledge structures of LLMs, and\nintroduce external knowledge through distractors of varying degrees, methods,\npositions, and formats. Our experiments on both black-box and open-source\nmodels demonstrate that LLMs tend to produce responses that deviate from their\nparametric knowledge, particularly when they encounter direct conflicts or\nconfounding changes of information within detailed contexts. We also find that\nwhile LLMs are sensitive to the veracity of external knowledge, they can still\nbe distracted by unrelated information. These findings highlight the risk of\nhallucination when integrating external knowledge, even indirectly, during\ninteractions with current LLMs. All the data and results are publicly\navailable.",
            "author": [
                "Cheng Qian",
                "Xinran Zhao",
                "Sherry Tongshuang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08594v1",
                "http://arxiv.org/pdf/2309.08594v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08569v1",
            "title": "Local Differential Privacy in Graph Neural Networks: a Reconstruction\n  Approach",
            "updated": "2023-09-15T17:35:51Z",
            "published": "2023-09-15T17:35:51Z",
            "summary": "Graph Neural Networks have achieved tremendous success in modeling complex\ngraph data in a variety of applications. However, there are limited studies\ninvestigating privacy protection in GNNs. In this work, we propose a learning\nframework that can provide node privacy at the user level, while incurring low\nutility loss. We focus on a decentralized notion of Differential Privacy,\nnamely Local Differential Privacy, and apply randomization mechanisms to\nperturb both feature and label data at the node level before the data is\ncollected by a central server for model training. Specifically, we investigate\nthe application of randomization mechanisms in high-dimensional feature\nsettings and propose an LDP protocol with strict privacy guarantees. Based on\nfrequency estimation in statistical analysis of randomized data, we develop\nreconstruction methods to approximate features and labels from perturbed data.\nWe also formulate this learning framework to utilize frequency estimates of\ngraph clusters to supervise the training procedure at a sub-graph level.\nExtensive experiments on real-world and semi-synthetic datasets demonstrate the\nvalidity of our proposed model.",
            "author": [
                "Karuna Bhaila",
                "Wen Huang",
                "Yongkai Wu",
                "Xintao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08569v1",
                "http://arxiv.org/pdf/2309.08569v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08550v1",
            "title": "Variational and stability properties of coupled NLS equations on the\n  star graph",
            "updated": "2023-09-15T17:13:01Z",
            "published": "2023-09-15T17:13:01Z",
            "summary": "We consider variational and stability properties of a system of two coupled\nnonlinear Schr\\\"{o}dinger equations on the star graph $\\Gamma$ with the\n$\\delta$ coupling at the vertex of $\\Gamma$. The first part is devoted to the\nproof of an existence of the ground state as the minimizer of the constrained\nenergy in the cubic case. This result extends the one obtained recently for the\ncoupled NLS equations on the line.\n  In the second part, we study stability properties of several families of\nstanding waves in the case of a general power nonlinearity. In particular, we\nstudy one-component standing waves $e^{i\\omega t}(\\Phi_1(x), 0)$ and\n$e^{i\\omega t}(0, \\Phi_2(x))$. Moreover, we study two-component standing waves\n$e^{i\\omega t}(\\Phi(x), \\Phi(x))$ for the case of power nonlinearity depending\non a unique power parameter $p$.\n  To our knowledge, these are the first results on variational and stability\nproperties of coupled NLS equations on graphs.",
            "author": [
                "Liliana Cely",
                "Nataliia Goloshchapova"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.na.2022.113056",
                "http://arxiv.org/abs/2309.08550v1",
                "http://arxiv.org/pdf/2309.08550v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math.FA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08548v1",
            "title": "On the maximum second eigenvalue of outerplanar graphs",
            "updated": "2023-09-15T17:12:02Z",
            "published": "2023-09-15T17:12:02Z",
            "summary": "For a fixed integer $k$ and a graph $G$, let $\\lambda_k(G)$ denote the $k$-th\nlargest eigenvalue of the adjacency matrix of $G$. In 2017, Tait and Tobin\nproved that the maximum $\\lambda_1(G)$ among all connected outerplanar graphs\non $n$ vertices is achieved by the fan graph $K_1\\vee P_{n-1}$. In this paper,\nwe consider a similar problem of determining the maximum $\\lambda_2$ among all\nconnected outerplanar graphs on $n$ vertices. For $n$ even and sufficiently\nlarge, we prove that the maximum $\\lambda_2$ is uniquely achieved by the graph\n$(K_1\\vee P_{n/2-1})\\!\\!-\\!\\!(K_1\\vee P_{n/2-1})$, which is obtained by\nconnecting two disjoint copies of $(K_1\\vee P_{n/2-1})$ through a new edge at\ntheir ends. When $n$ is odd and sufficiently large, the extremal graphs are not\nunique. The extremal graphs are those graphs $G$ that contains a cut vertex $u$\nsuch that $G\\setminus \\{u\\}$ is isomorphic to $2(K_1\\vee P_{n/2-1})$. We also\ndetermine the maximum $\\lambda_2$ among all 2-connected outerplanar graphs and\nasymptotically determine the maximum of $\\lambda_k(G)$ among all connected\nouterplanar graphs for general $k$.",
            "author": [
                "George Brooks",
                "Maggie Gu",
                "Jack Hyatt",
                "William Linz",
                "Linyuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08548v1",
                "http://arxiv.org/pdf/2309.08548v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08535v1",
            "title": "Visual Speech Recognition for Low-resource Languages with Automatic\n  Labels From Whisper Model",
            "updated": "2023-09-15T16:53:01Z",
            "published": "2023-09-15T16:53:01Z",
            "summary": "This paper proposes a powerful Visual Speech Recognition (VSR) method for\nmultiple languages, especially for low-resource languages that have a limited\nnumber of labeled data. Different from previous methods that tried to improve\nthe VSR performance for the target language by using knowledge learned from\nother languages, we explore whether we can increase the amount of training data\nitself for the different languages without human intervention. To this end, we\nemploy a Whisper model which can conduct both language identification and\naudio-based speech recognition. It serves to filter data of the desired\nlanguages and transcribe labels from the unannotated, multilingual audio-visual\ndata pool. By comparing the performances of VSR models trained on automatic\nlabels and the human-annotated labels, we show that we can achieve similar VSR\nperformance to that of human-annotated labels even without utilizing human\nannotations. Through the automated labeling process, we label large-scale\nunlabeled multilingual databases, VoxCeleb2 and AVSpeech, producing 1,002 hours\nof data for four low VSR resource languages, French, Italian, Spanish, and\nPortuguese. With the automatic labels, we achieve new state-of-the-art\nperformance on mTEDx in four languages, significantly surpassing the previous\nmethods. The automatic labels are available online:\nhttps://github.com/JeongHun0716/Visual-Speech-Recognition-for-Low-Resource-Languages",
            "author": [
                "Jeong Hun Yeo",
                "Minsu Kim",
                "Shinji Watanabe",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08535v1",
                "http://arxiv.org/pdf/2309.08535v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08533v1",
            "title": "Automated dermatoscopic pattern discovery by clustering neural network\n  output for human-computer interaction",
            "updated": "2023-09-15T16:50:47Z",
            "published": "2023-09-15T16:50:47Z",
            "summary": "Background: As available medical image datasets increase in size, it becomes\ninfeasible for clinicians to review content manually for knowledge extraction.\nThe objective of this study was to create an automated clustering resulting in\nhuman-interpretable pattern discovery.\n  Methods: Images from the public HAM10000 dataset, including 7 common\npigmented skin lesion diagnoses, were tiled into 29420 tiles and clustered via\nk-means using neural network-extracted image features. The final number of\nclusters per diagnosis was chosen by either the elbow method or a compactness\nmetric balancing intra-lesion variance and cluster numbers. The amount of\nresulting non-informative clusters, defined as those containing less than six\nimage tiles, was compared between the two methods.\n  Results: Applying k-means, the optimal elbow cutoff resulted in a mean of\n24.7 (95%-CI: 16.4-33) clusters for every included diagnosis, including 14.9%\n(95% CI: 0.8-29.0) non-informative clusters. The optimal cutoff, as estimated\nby the compactness metric, resulted in significantly fewer clusters (13.4;\n95%-CI 11.8-15.1; p=0.03) and less non-informative ones (7.5%; 95% CI: 0-19.5;\np=0.017). The majority of clusters (93.6%) from the compactness metric could be\nmanually mapped to previously described dermatoscopic diagnostic patterns.\n  Conclusions: Automatically constraining unsupervised clustering can produce\nan automated extraction of diagnostically relevant and human-interpretable\nclusters of visual patterns from a large image dataset.",
            "author": [
                "Lidia Talavera-Martinez",
                "Philipp Tschandl"
            ],
            "link": [
                "http://dx.doi.org/10.1111/jdv.19234",
                "http://arxiv.org/abs/2309.08533v1",
                "http://arxiv.org/pdf/2309.08533v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC",
                "I.2.0; I.4.0; I.5.4; J.3; H.1.2; H.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08531v1",
            "title": "Towards Practical and Efficient Image-to-Speech Captioning with\n  Vision-Language Pre-training and Multi-modal Tokens",
            "updated": "2023-09-15T16:48:34Z",
            "published": "2023-09-15T16:48:34Z",
            "summary": "In this paper, we propose methods to build a powerful and efficient\nImage-to-Speech captioning (Im2Sp) model. To this end, we start with importing\nthe rich knowledge related to image comprehension and language modeling from a\nlarge-scale pre-trained vision-language model into Im2Sp. We set the output of\nthe proposed Im2Sp as discretized speech units, i.e., the quantized speech\nfeatures of a self-supervised speech model. The speech units mainly contain\nlinguistic information while suppressing other characteristics of speech. This\nallows us to incorporate the language modeling capability of the pre-trained\nvision-language model into the spoken language modeling of Im2Sp. With the\nvision-language pre-training strategy, we set new state-of-the-art Im2Sp\nperformances on two widely used benchmark databases, COCO and Flickr8k. Then,\nwe further improve the efficiency of the Im2Sp model. Similar to the speech\nunit case, we convert the original image into image units, which are derived\nthrough vector quantization of the raw image. With these image units, we can\ndrastically reduce the required data storage for saving image data to just 0.8%\nwhen compared to the original image data in terms of bits. Demo page:\nhttps://ms-dot-k.github.io/Image-to-Speech-Captioning.",
            "author": [
                "Minsu Kim",
                "Jeongsoo Choi",
                "Soumi Maiti",
                "Jeong Hun Yeo",
                "Shinji Watanabe",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08531v1",
                "http://arxiv.org/pdf/2309.08531v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "eess.AS",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08514v1",
            "title": "On the rna number of powers of cycles",
            "updated": "2023-09-15T16:19:33Z",
            "published": "2023-09-15T16:19:33Z",
            "summary": "A signed graph $(G,\\sigma)$ on $n$ vertices is called a \\textit{parity signed\ngraph} if there is a bijective mapping $f \\colon V(G) \\rightarrow\n\\{1,\\ldots,n\\}$ such that $f(u)$ and $f(v)$ have same parity if $\\sigma(uv)=1$,\nand opposite parities if $\\sigma(uv)=-1$ for each edge $uv$ in $G$. The\n\\emph{rna} number $\\sigma^{-}(G)$ of $G$ is the least number of negative edges\namong all possible parity signed graphs over $G$. In other words,\n$\\sigma^{-}(G)$ is the smallest size of an edge-cut of $G$ such that the sizes\nof two sides differ at most one.\n  Let $C_n^{d}$ be the $d\\text{th}$ power of a cycle of order $n$. Recently,\nAcharya, Kureethara and Zaslavsky proved that the \\emph{rna} number of a cycle\n$C_n$ on $n$ vertices is $2$. In this paper, we show for $2 \\leq d < \\lfloor\n\\frac{n}{2} \\rfloor$ that $2d \\leq \\sigma^{-}(C_n^{d}) \\leq d(d+1)$. Moreover,\nwe prove that the graphs $C_n^{2}$ and $C_n^{3}$ achieve the upper bound of\n$d(d+1)$.",
            "author": [
                "Deepak Sehrawat",
                "Anil Kumar",
                "Sweta Ahlawat"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08514v1",
                "http://arxiv.org/pdf/2309.08514v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C22, 05C38, 05C40, 05C78"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08508v1",
            "title": "MOSAIC: Learning Unified Multi-Sensory Object Property Representations\n  for Robot Perception",
            "updated": "2023-09-15T16:11:46Z",
            "published": "2023-09-15T16:11:46Z",
            "summary": "A holistic understanding of object properties across diverse sensory\nmodalities (e.g., visual, audio, and haptic) is essential for tasks ranging\nfrom object categorization to complex manipulation. Drawing inspiration from\ncognitive science studies that emphasize the significance of multi-sensory\nintegration in human perception, we introduce MOSAIC (Multi-modal Object\nproperty learning with Self-Attention and Integrated Comprehension), a novel\nframework designed to facilitate the learning of unified multi-sensory object\nproperty representations. While it is undeniable that visual information plays\na prominent role, we acknowledge that many fundamental object properties extend\nbeyond the visual domain to encompass attributes like texture, mass\ndistribution, or sounds, which significantly influence how we interact with\nobjects. In MOSAIC, we leverage this profound insight by distilling knowledge\nfrom the extensive pre-trained Contrastive Language-Image Pre-training (CLIP)\nmodel, aligning these representations not only across vision but also haptic\nand auditory sensory modalities. Through extensive experiments on a dataset\nwhere a humanoid robot interacts with 100 objects across 10 exploratory\nbehaviors, we demonstrate the versatility of MOSAIC in two task families:\nobject categorization and object-fetching tasks. Our results underscore the\nefficacy of MOSAIC's unified representations, showing competitive performance\nin category recognition through a simple linear probe setup and excelling in\nthe fetch object task under zero-shot transfer conditions. This work pioneers\nthe application of CLIP-based sensory grounding in robotics, promising a\nsignificant leap in multi-sensory perception capabilities for autonomous\nsystems. We have released the code, datasets, and additional results:\nhttps://github.com/gtatiya/MOSAIC.",
            "author": [
                "Gyan Tatiya",
                "Jonathan Francis",
                "Ho-Hsiang Wu",
                "Yonatan Bisk",
                "Jivko Sinapov"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08508v1",
                "http://arxiv.org/pdf/2309.08508v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08503v1",
            "title": "HealthFC: A Dataset of Health Claims for Evidence-Based Medical\n  Fact-Checking",
            "updated": "2023-09-15T16:05:48Z",
            "published": "2023-09-15T16:05:48Z",
            "summary": "Seeking health-related advice on the internet has become a common practice in\nthe digital era. Determining the trustworthiness of medical claims found online\nand finding appropriate evidence for this information is increasingly\nchallenging. Fact-checking has emerged as an approach to assess the veracity of\nfactual claims using evidence from credible knowledge sources. To help advance\nthe automation of this task, in this paper, we introduce a novel dataset of 750\nhealth-related claims, labeled for veracity by medical experts and backed with\nevidence from appropriate clinical studies. We provide an analysis of the\ndataset, highlighting its characteristics and challenges. The dataset can be\nused for Machine Learning tasks related to automated fact-checking such as\nevidence retrieval, veracity prediction, and explanation generation. For this\npurpose, we provide baseline models based on different approaches, examine\ntheir performance, and discuss the findings.",
            "author": [
                "Juraj Vladika",
                "Phillip Schneider",
                "Florian Matthes"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08503v1",
                "http://arxiv.org/pdf/2309.08503v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08491v1",
            "title": "Using Large Language Models for Knowledge Engineering (LLMKE): A Case\n  Study on Wikidata",
            "updated": "2023-09-15T15:51:14Z",
            "published": "2023-09-15T15:51:14Z",
            "summary": "In this work, we explore the use of Large Language Models (LLMs) for\nknowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge.\nFor this task, given subject and relation pairs sourced from Wikidata, we\nutilize pre-trained LLMs to produce the relevant objects in string format and\nlink them to their respective Wikidata QIDs. We developed a pipeline using LLMs\nfor Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata\nentity mapping. The method achieved a macro-averaged F1-score of 0.701 across\nthe properties, with the scores varying from 1.00 to 0.328. These results\ndemonstrate that the knowledge of LLMs varies significantly depending on the\ndomain and that further experimentation is required to determine the\ncircumstances under which LLMs can be used for automatic Knowledge Base (e.g.,\nWikidata) completion and correction. The investigation of the results also\nsuggests the promising contribution of LLMs in collaborative knowledge\nengineering. LLMKE won Track 2 of the challenge. The implementation is\navailable at https://github.com/bohuizhang/LLMKE.",
            "author": [
                "Bohui Zhang",
                "Ioannis Reklos",
                "Nitisha Jain",
                "Albert Mero\u00f1o Pe\u00f1uela",
                "Elena Simperl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08491v1",
                "http://arxiv.org/pdf/2309.08491v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08488v1",
            "title": "A Random Graph-based Autoregressive Model for Networked Time Series",
            "updated": "2023-09-15T15:47:08Z",
            "published": "2023-09-15T15:47:08Z",
            "summary": "Contemporary time series data often feature objects connected by a social\nnetwork that naturally induces temporal dependence involving connected\nneighbours. The network vector autoregressive model is useful for describing\nthe influence of linked neighbours, while recent generalizations aim to\nseparate influence and homophily. Existing approaches, however, require either\ncorrect specification of a time series model or accurate estimation of a\nnetwork model or both, and rely exclusively on least-squares for parameter\nestimation. This paper proposes a new autoregressive model incorporating a\nflexible form for latent variables used to depict homophily. We develop a\nfirst-order differencing method for the estimation of influence requiring only\nthe influence part of the model to be correctly specified. When the part\nincluding homophily is correctly specified admitting a semiparametric form, we\nleverage and generalize the recent notion of neighbour smoothing for parameter\nestimation, bypassing the need to specify the generative mechanism of the\nnetwork. We develop new theory to show that all the estimated parameters are\nconsistent and asymptotically normal. The efficacy of our approach is confirmed\nvia extensive simulations and an analysis of a social media dataset.",
            "author": [
                "Weichi Wu",
                "Chenlei Leng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08488v1",
                "http://arxiv.org/pdf/2309.08488v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08485v1",
            "title": "XFedHunter: An Explainable Federated Learning Framework for Advanced\n  Persistent Threat Detection in SDN",
            "updated": "2023-09-15T15:44:09Z",
            "published": "2023-09-15T15:44:09Z",
            "summary": "Advanced Persistent Threat (APT) attacks are highly sophisticated and employ\na multitude of advanced methods and techniques to target organizations and\nsteal sensitive and confidential information. APT attacks consist of multiple\nstages and have a defined strategy, utilizing new and innovative techniques and\ntechnologies developed by hackers to evade security software monitoring. To\neffectively protect against APTs, detecting and predicting APT indicators with\nan explanation from Machine Learning (ML) prediction is crucial to reveal the\ncharacteristics of attackers lurking in the network system. Meanwhile,\nFederated Learning (FL) has emerged as a promising approach for building\nintelligent applications without compromising privacy. This is particularly\nimportant in cybersecurity, where sensitive data and high-quality labeling play\na critical role in constructing effective machine learning models for detecting\ncyber threats. Therefore, this work proposes XFedHunter, an explainable\nfederated learning framework for APT detection in Software-Defined Networking\n(SDN) leveraging local cyber threat knowledge from many training collaborators.\nIn XFedHunter, Graph Neural Network (GNN) and Deep Learning model are utilized\nto reveal the malicious events effectively in the large number of normal ones\nin the network system. The experimental results on NF-ToN-IoT and DARPA TCE3\ndatasets indicate that our framework can enhance the trust and accountability\nof ML-based systems utilized for cybersecurity purposes without privacy\nleakage.",
            "author": [
                "Huynh Thai Thi",
                "Ngo Duc Hoang Son",
                "Phan The Duy",
                "Nghi Hoang Khoa",
                "Khoa Ngo-Khanh",
                "Van-Hau Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08485v1",
                "http://arxiv.org/pdf/2309.08485v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08474v1",
            "title": "VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts\n  by Multimodal Learning with Graph Neural Network and Language Model",
            "updated": "2023-09-15T15:26:44Z",
            "published": "2023-09-15T15:26:44Z",
            "summary": "This paper presents VulnSense framework, a comprehensive approach to\nefficiently detect vulnerabilities in Ethereum smart contracts using a\nmultimodal learning approach on graph-based and natural language processing\n(NLP) models. Our proposed framework combines three types of features from\nsmart contracts comprising source code, opcode sequences, and control flow\ngraph (CFG) extracted from bytecode. We employ Bidirectional Encoder\nRepresentations from Transformers (BERT), Bidirectional Long Short-Term Memory\n(BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these\nfeatures. The final layer of our multimodal approach consists of a fully\nconnected layer used to predict vulnerabilities in Ethereum smart contracts.\nAddressing limitations of existing vulnerability detection methods relying on\nsingle-feature or single-model deep learning techniques, our method surpasses\naccuracy and effectiveness constraints. We assess VulnSense using a collection\nof 1.769 smart contracts derived from the combination of three datasets:\nCurated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with\nvarious unimodal and multimodal learning techniques contributed by GNN, BiLSTM\nand BERT architectures. The experimental outcomes demonstrate the superior\nperformance of our proposed approach, achieving an average accuracy of 77.96\\%\nacross all three categories of vulnerable smart contracts.",
            "author": [
                "Phan The Duy",
                "Nghi Hoang Khoa",
                "Nguyen Huu Quyen",
                "Le Cong Trinh",
                "Vu Trung Kien",
                "Trinh Minh Hoang",
                "Van-Hau Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08474v1",
                "http://arxiv.org/pdf/2309.08474v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08470v1",
            "title": "Crossing estimates on general s-embeddings",
            "updated": "2023-09-15T15:20:00Z",
            "published": "2023-09-15T15:20:00Z",
            "summary": "We prove Russo-Seymour-Welsh type crossing estimates for the FK-Ising model\non general s-embeddings whose origami map has an asymptotic Lipschitz constant\nstrictly smaller than $1$, provided a mild non-degeneracy assumption is\nsatisfied. This result extends the original work of Chelkak and provides a\ngeneral framework to prove that connection probabilities between boundaries of\nboxes remain bounded away from $0$ and $1$. It is explained that one cannot\nprove similar estimates without a similar assumption on the origami map, and\nallows to propose some notion of critical model for generic planar graphs, that\ncan be rephrased from the perspective of the associated propagator operator.\nThis paper reproves along the way corresponding results in almost all already\nknown setups and also treats new ones of interest.",
            "author": [
                "R\u00e9my Mahfouf"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08470v1",
                "http://arxiv.org/pdf/2309.08470v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08429v1",
            "title": "IHT-Inspired Neural Network for Single-Snapshot DOA Estimation with\n  Sparse Linear Arrays",
            "updated": "2023-09-15T14:30:38Z",
            "published": "2023-09-15T14:30:38Z",
            "summary": "Single-snapshot direction-of-arrival (DOA) estimation using sparse linear\narrays (SLAs) has gained significant attention in the field of automotive MIMO\nradars. This is due to the dynamic nature of automotive settings, where\nmultiple snapshots aren't accessible, and the importance of minimizing hardware\ncosts. Low-rank Hankel matrix completion has been proposed to interpolate the\nmissing elements in SLAs. However, the solvers of matrix completion, such as\niterative hard thresholding (IHT), heavily rely on expert knowledge of\nhyperparameter tuning and lack task-specificity. Besides, IHT involves\ntruncated-singular value decomposition (t-SVD), which has high computational\ncost in each iteration. In this paper, we propose an IHT-inspired neural\nnetwork for single-snapshot DOA estimation with SLAs, termed IHT-Net. We\nutilize a recurrent neural network structure to parameterize the IHT algorithm.\nAdditionally, we integrate shallow-layer autoencoders to replace t-SVD,\nreducing computational overhead while generating a novel optimizer through\nsupervised learning. IHT-Net maintains strong interpretability as its network\nlayer operations align with the iterations of the IHT algorithm. The learned\noptimizer exhibits fast convergence and higher accuracy in the full array\nsignal reconstruction followed by single-snapshot DOA estimation. Numerical\nresults validate the effectiveness of the proposed method.",
            "author": [
                "Yunqiao Hu",
                "Shunqiao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08429v1",
                "http://arxiv.org/pdf/2309.08429v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08420v4",
            "title": "FedDCSR: Federated Cross-domain Sequential Recommendation via\n  Disentangled Representation Learning",
            "updated": "2023-12-02T10:52:48Z",
            "published": "2023-09-15T14:23:20Z",
            "summary": "Cross-domain Sequential Recommendation (CSR) which leverages user sequence\ndata from multiple domains has received extensive attention in recent years.\nHowever, the existing CSR methods require sharing origin user data across\ndomains, which violates the General Data Protection Regulation (GDPR). Thus, it\nis necessary to combine federated learning (FL) and CSR to fully utilize\nknowledge from different domains while preserving data privacy. Nonetheless,\nthe sequence feature heterogeneity across different domains significantly\nimpacts the overall performance of FL. In this paper, we propose FedDCSR, a\nnovel federated cross-domain sequential recommendation framework via\ndisentangled representation learning. Specifically, to address the sequence\nfeature heterogeneity across domains, we introduce an approach called\ninter-intra domain sequence representation disentanglement (SRD) to disentangle\nthe user sequence features into domain-shared and domain-exclusive features. In\naddition, we design an intra domain contrastive infomax (CIM) strategy to learn\nricher domain-exclusive features of users by performing data augmentation on\nuser sequences. Extensive experiments on three real-world scenarios demonstrate\nthat FedDCSR achieves significant improvements over existing baselines.",
            "author": [
                "Hongyu Zhang",
                "Dongyi Zheng",
                "Xu Yang",
                "Jiyuan Feng",
                "Qing Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08420v4",
                "http://arxiv.org/pdf/2309.08420v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08413v1",
            "title": "Ab initio quantum scattering calculations and a new potential energy\n  surface for the HCl($X^1\u03a3^+$)-O$_{2}$($X^3\u03a3^-_g$) system:\n  collision-induced line-shape parameters for O$_{2}$-perturbed R(0) 0-0 line\n  in H$^{35}$Cl",
            "updated": "2023-09-15T14:18:01Z",
            "published": "2023-09-15T14:18:01Z",
            "summary": "The remote sensing of abundance and properties of HCl -- the main atmospheric\nreservoir of Cl atoms which directly participate in ozone depletion -- are\nimportant for monitoring the partitioning of chlorine between \"ozone-depleting\"\nand \"reservoir\" species. Such remote studies require knowledge of the shapes of\nmolecular resonances of HCl, which are perturbed by collisions with the\nmolecules of the surrounding air. In this work, we report the first fully\nquantum calculations of collisional perturbations of the shape of a pure\nrotational line in H$^{35}$Cl perturbed by an air-relevant molecule (as the\nfirst model system we choose the R(0) line in HCl perturbed by O$_2$). The\ncalculations are performed on our new highly-accurate\nHCl($X^1\\Sigma^+$)-O$_2$($X^3\\Sigma^-_g$) potential energy surface. In addition\nto pressure broadening and shift, we determine also their speed dependencies\nand the complex Dicke parameter. This gives important input to the community\ndiscussion on the physical meaning of the complex Dicke parameter and its\nrelevance for atmospheric spectra (previously, the complex Dicke parameter for\nsuch systems was mainly determined from phenomenological fits to experimental\nspectra and the physical meaning of its value in that context is questionable).\nWe also calculate the temperature dependence of the line-shape parameters and\nobtain agreement with the available experimental data. We estimate the total\ncombined uncertainties of our calculations at 2% relative RMSE residuals in the\nsimulated line shape at 296~K. This result constitutes an important step\ntowards computational population of spectroscopic databases with accurate ab\ninitio line-shape parameters for molecular systems of terrestrial atmospheric\nimportance.",
            "author": [
                "Artur Olejnik",
                "Hubert J\u00f3\u017awiak",
                "Maciej Gancewski",
                "Ernesto Quintas-S\u00e1nchez",
                "Richard Dawes",
                "Piotr Wcis\u0142o"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08413v1",
                "http://arxiv.org/pdf/2309.08413v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.ao-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08406v1",
            "title": "Constraint-Free Structure Learning with Smooth Acyclic Orientations",
            "updated": "2023-09-15T14:08:09Z",
            "published": "2023-09-15T14:08:09Z",
            "summary": "The structure learning problem consists of fitting data generated by a\nDirected Acyclic Graph (DAG) to correctly reconstruct its arcs. In this\ncontext, differentiable approaches constrain or regularize the optimization\nproblem using a continuous relaxation of the acyclicity property. The\ncomputational cost of evaluating graph acyclicity is cubic on the number of\nnodes and significantly affects scalability. In this paper we introduce COSMO,\na constraint-free continuous optimization scheme for acyclic structure\nlearning. At the core of our method, we define a differentiable approximation\nof an orientation matrix parameterized by a single priority vector. Differently\nfrom previous work, our parameterization fits a smooth orientation matrix and\nthe resulting acyclic adjacency matrix without evaluating acyclicity at any\nstep. Despite the absence of explicit constraints, we prove that COSMO always\nconverges to an acyclic solution. In addition to being asymptotically faster,\nour empirical analysis highlights how COSMO performance on graph reconstruction\ncompares favorably with competing structure learning methods.",
            "author": [
                "Riccardo Massidda",
                "Francesco Landolfi",
                "Martina Cinquini",
                "Davide Bacciu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08406v1",
                "http://arxiv.org/pdf/2309.08406v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08401v1",
            "title": "A new upper bound for angular resolution",
            "updated": "2023-09-15T13:53:29Z",
            "published": "2023-09-15T13:53:29Z",
            "summary": "The angular resolution of a planar straight-line drawing of a graph is the\nsmallest angle formed by two edges incident to the same vertex. Garg and\nTamassia (ESA '94) constructed a family of planar graphs with maximum degree\n$d$ that have angular resolution $O((\\log d)^{\\frac{1}{2}}/d^{\\frac{3}{2}})$ in\nany planar straight-line drawing. This upper bound has been the best known\nupper bound on angular resolution for a long time. In this paper, we improve\nthis upper bound. For an arbitrarily small positive constant $\\varepsilon$, we\nconstruct a family of planar graphs with maximum degree $d$ that have angular\nresolution $O((\\log d)^\\varepsilon/d^{\\frac{3}{2}})$ in any planar\nstraight-line drawing.",
            "author": [
                "Hiroyuki Miyata"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08401v1",
                "http://arxiv.org/pdf/2309.08401v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08380v1",
            "title": "Unleashing Potential of Evidence in Knowledge-Intensive Dialogue\n  Generation",
            "updated": "2023-09-15T13:13:30Z",
            "published": "2023-09-15T13:13:30Z",
            "summary": "Incorporating external knowledge into dialogue generation (KIDG) is crucial\nfor improving the correctness of response, where evidence fragments serve as\nknowledgeable snippets supporting the factual dialogue replies. However,\nintroducing irrelevant content often adversely impacts reply quality and easily\nleads to hallucinated responses. Prior work on evidence retrieval and\nintegration in dialogue systems falls short of fully leveraging existing\nevidence since the model fails to locate useful fragments accurately and\noverlooks hidden evidence labels within the KIDG dataset. To fully Unleash the\npotential of evidence, we propose a framework to effectively incorporate\nEvidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we\nintroduce an automatic evidence generation framework that harnesses the power\nof Large Language Models (LLMs) to mine reliable evidence veracity labels from\nunlabeled data. By utilizing these evidence labels, we train a reliable\nevidence indicator to effectively identify relevant evidence from retrieved\npassages. Furthermore, we propose an evidence-augmented generator with an\nevidence-focused attention mechanism, which allows the model to concentrate on\nevidenced segments. Experimental results on MultiDoc2Dial demonstrate the\nefficacy of evidential label augmentation and refined attention mechanisms in\nimproving model performance. Further analysis confirms that the proposed method\noutperforms other baselines (+3~+5 points) regarding coherence and factual\nconsistency.",
            "author": [
                "Xianjie Wu",
                "Jian Yang",
                "Tongliang Li",
                "Di Liang",
                "Shiwei Zhang",
                "Yiyang Du",
                "Zhoujun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08380v1",
                "http://arxiv.org/pdf/2309.08380v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08370v1",
            "title": "Gallai-Ramsey multiplicity for rainbow small trees",
            "updated": "2023-09-15T12:51:32Z",
            "published": "2023-09-15T12:51:32Z",
            "summary": "Let $G, H$ be two non-empty graphs and $k$ be a positive integer. The\nGallai-Ramsey number $\\operatorname{gr}_k(G:H)$ is defined as the minimum\npositive integer $N$ such that for all $n\\geq N$, every $k$-edge-coloring of\n$K_n$ contains either a rainbow subgraph $G$ or a monochromatic subgraph $H$.\nThe Gallai-Ramsey multiplicity $\\operatorname{GM}_k(G:H)$ is defined as the\nminimum total number of rainbow subgraphs $G$ and monochromatic subgraphs $H$\nfor all $k$-edge-colored $K_{\\operatorname{gr}_k(G:H)}$. In this paper, we get\nsome exact values of the Gallai-Ramsey multiplicity for rainbow small trees\nversus general monochromatic graphs under a sufficiently large number of\ncolors. We also discuss the bipartite Gallai-Ramsey multiplicity.",
            "author": [
                "Xueliang Li",
                "Yuan Si"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08370v1",
                "http://arxiv.org/pdf/2309.08370v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08349v1",
            "title": "Fermionic Gaussian free field structure in the Abelian sandpile model\n  and uniform spanning tree",
            "updated": "2023-09-15T12:16:50Z",
            "published": "2023-09-15T12:16:50Z",
            "summary": "In this paper we rigorously construct a finite volume representation for the\nheight-one field of the Abelian sandpile model and the degree field of the\nuniform spanning tree in terms of the fermionic Gaussian free field. This\nrepresentation can be seen as the lattice representation of a free symplectic\nfermion field. It allows us to compute cumulants of those fields, both in\nfinite volume and in the scaling limit, including determining the explicit\nnormalizing constants for fields in the corresponding logarithmic field theory.\nFurthermore, our results point towards universality of the height-one and\ndegree fields, as we prove that the scaling limits of the cumulants agree (up\nto constants) in the square and triangular lattice. We also recover the\nequivalent scaling limits for the hypercubic lattice in higher dimensions, and\ndiscuss how to adapt the proofs of our results to general graphs.",
            "author": [
                "Leandro Chiarini",
                "Alessandra Cipriani",
                "Alan Rapoport",
                "Wioletta Ruszel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08349v1",
                "http://arxiv.org/pdf/2309.08349v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP",
                "60K35, 39A12, 60G15, 81V74"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08345v1",
            "title": "Data Distribution Bottlenecks in Grounding Language Models to Knowledge\n  Bases",
            "updated": "2023-09-15T12:06:45Z",
            "published": "2023-09-15T12:06:45Z",
            "summary": "Language models (LMs) have already demonstrated remarkable abilities in\nunderstanding and generating both natural and formal language. Despite these\nadvances, their integration with real-world environments such as large-scale\nknowledge bases (KBs) remains an underdeveloped area, affecting applications\nsuch as semantic parsing and indulging in \"hallucinated\" information. This\npaper is an experimental investigation aimed at uncovering the robustness\nchallenges that LMs encounter when tasked with knowledge base question\nanswering (KBQA). The investigation covers scenarios with inconsistent data\ndistribution between training and inference, such as generalization to unseen\ndomains, adaptation to various language variations, and transferability across\ndifferent datasets. Our comprehensive experiments reveal that even when\nemployed with our proposed data augmentation techniques, advanced small and\nlarge language models exhibit poor performance in various dimensions. While the\nLM is a promising technology, the robustness of the current form in dealing\nwith complex environments is fragile and of limited practicality because of the\ndata distribution issue. This calls for future research on data collection and\nLM learning paradims.",
            "author": [
                "Yiheng Shu",
                "Zhiwei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08345v1",
                "http://arxiv.org/pdf/2309.08345v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08344v1",
            "title": "Constant Mean Curvature surfaces with prescribed finite topologies",
            "updated": "2023-09-15T12:01:55Z",
            "published": "2023-09-15T12:01:55Z",
            "summary": "In this article, we construct complete embedded constant mean curvature\nsurfaces in $\\mb{R}^3$ with freely prescribed genus and any number of ends\ngreater than or equal to four. Heuristically, the surfaces are obtained by\nresolving finitely many points of tangency between collections of spheres. The\nconstruction relies a family of constant mean curvature surfaces constructed in\n\\cite{Kleene}, constructed as graphs over catenoidal necks of small scale.",
            "author": [
                "Stephen. J. Kleene"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08344v1",
                "http://arxiv.org/pdf/2309.08344v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08327v1",
            "title": "Forbidden Tournaments and the Orientation Completion Problem",
            "updated": "2023-09-15T11:32:05Z",
            "published": "2023-09-15T11:32:05Z",
            "summary": "For a fixed finite set of finite tournaments ${\\mathcal F}$, the ${\\mathcal\nF}$-free orientation problem asks whether a given finite undirected graph $G$\nhas an $\\mathcal F$-free orientation, i.e., whether the edges of $G$ can be\noriented so that the resulting digraph does not embed any of the tournaments\nfrom ${\\mathcal F}$. We prove that for every ${\\mathcal F}$, this problem is in\nP or NP-complete. Our proof reduces the classification task to a complete\ncomplexity classification of the orientation completion problem for ${\\mathcal\nF}$, which is the variant of the problem above where the input is a directed\ngraph instead of an undirected graph, introduced by Bang-Jensen, Huang, and Zhu\n(2017). Our proof uses results from the theory of constraint satisfaction, and\na result of Agarwal and Kompatscher (2018) about infinite permutation groups\nand transformation monoids.",
            "author": [
                "Manuel Bodirsky",
                "Santiago Guzm\u00e1n-Pro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08327v1",
                "http://arxiv.org/pdf/2309.08327v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.CC",
                "math.LO",
                "05C60 (Primary) 03C98 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08304v1",
            "title": "Lattice attack on group ring NTRU: The case of the dihedral group",
            "updated": "2023-09-15T10:50:46Z",
            "published": "2023-09-15T10:50:46Z",
            "summary": "Group ring NTRU (GR-NTRU) provides a general structure to design different\nvariants of NTRU-like schemes by employing different groups. Although, most of\nthe schemes in literature are built over cyclic groups, nonabelian groups can\nalso be used. Coppersmith and Shamir in 1997 have suggested that\nnoncommutativity may result in better security against some lattice attacks for\nsome groups. Lattice attacks on the public key of NTRU-like cryptosystems try\nto retrieve the private key by solving the shortest vector problem (SVP) or its\napproximation in a lattice of a certain dimension, assuming the knowledge of\nthe public key only. This paper shows that dihedral groups do not guarantee\nbetter security against this class of attacks. We prove that retrieving the\nprivate key is possible by solving the SVP in two lattices with half the\ndimension of the original lattice generated for GR-NTRU based on dihedral\ngroups. The possibility of such an attack was mentioned by Yasuda et\nal.(IACR/2015/1170). In contrast to their proposed approach, we explicitly\nprovide the lattice reduction without any structure theorem from the\nrepresentation theory for finite groups. Furthermore, we demonstrate the\neffectiveness of our technique with experimental results.",
            "author": [
                "Vikas Kumar",
                "Ali Raya",
                "Sugata Gangopadhyay",
                "Aditi Kar Gangopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08304v1",
                "http://arxiv.org/pdf/2309.08304v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08286v1",
            "title": "Quartz as an Accurate High-Field Low-Cost THz Helicity Detector",
            "updated": "2023-09-15T09:59:16Z",
            "published": "2023-09-15T09:59:16Z",
            "summary": "The advent of high-field THz sources has opened the field of nonlinear THz\nphysics and unlocked access to fundamental low energy excitations for ultrafast\nmaterial control. Recent advances towards controlling and employing chiral\nexcitations, or generally angular momentum of light, not only rely on the\nmeasurement of undistorted intense THz fields, but also on the precise\nknowledge about sophisticated THz helicity states. A recently reported and\npromising detector material is $\\alpha$-quartz. However, its electrooptic\nresponse function and contributing nonlinear effects have remained elusive.\nHere, we establish z-cut $\\alpha$-quartz as a precise electrooptic THz detector\nfor full amplitude, phase and polarization measurement of intense THz fields,\nall at a fraction of costs of conventional THz detectors. We experimentally\ndetermine its complex detector response function, which is in good agreement\nwith our model based on predominantly known literature values. It also explains\npreviously observed thickness-dependent waveforms. These insights allow us to\ndevelop a swift and reliable protocol to precisely measure arbitrary THz\npolarization and helicity states. This two-dimensional electrooptic sampling\n(2D-EOS) in $\\alpha$-quartz fosters rapid and cost-efficient THz time-domain\nellipsometry, and enables the characterization of polarization-tailored fields\nfor driving chiral or other helicity-sensitive quasiparticles and topologies.",
            "author": [
                "Maximilian Frenzel",
                "Joanna M. Urban",
                "Leona Nest",
                "Tobias Kampfrath",
                "Michael S. Spencer",
                "Sebastian F. Maehrlein"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08286v1",
                "http://arxiv.org/pdf/2309.08286v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cond-mat.mtrl-sci",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08285v1",
            "title": "One-Class Knowledge Distillation for Spoofing Speech Detection",
            "updated": "2023-09-15T09:59:06Z",
            "published": "2023-09-15T09:59:06Z",
            "summary": "The detection of spoofing speech generated by unseen algorithms remains an\nunresolved challenge. One reason for the lack of generalization ability is\ntraditional detecting systems follow the binary classification paradigm, which\ninherently assumes the possession of prior knowledge of spoofing speech.\nOne-class methods attempt to learn the distribution of bonafide speech and are\ninherently suited to the task where spoofing speech exhibits significant\ndifferences. However, training a one-class system using only bonafide speech is\nchallenging. In this paper, we introduce a teacher-student framework to provide\nguidance for the training of a one-class model. The proposed one-class\nknowledge distillation method outperforms other state-of-the-art methods on the\nASVspoof 21DF dataset and InTheWild dataset, which demonstrates its superior\ngeneralization ability.",
            "author": [
                "Jingze Lu",
                "Yuxiang Zhang",
                "Wenchao Wang",
                "Zengqiang Shang",
                "Pengyuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08285v1",
                "http://arxiv.org/pdf/2309.08285v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08284v1",
            "title": "Towards an Interoperability Roadmap for the Energy Transition",
            "updated": "2023-09-15T09:55:31Z",
            "published": "2023-09-15T09:55:31Z",
            "summary": "Smart grid interoperability is the means to achieve the twin green and\ndigital transition but re-mains heterogeneous and fragmented to date. This work\npresents the first ideas and corner-stones of an Interoperability Roadmap for\nthe Energy Transition that is being developed by the Horizon Europe int:net\nproject. This roadmap builds on four cornerstones that address open\ninteroperability issues. These are a knowledge base to address the lack of\nconvergence among existing initiatives, a maturity model and a network of\ntesting and certification facilities to ad-dress the lack of practical tools\nfor the industry, and a governance process to address the gap between\nstandards-related approaches of Standards Development Organisations and\nResearch and Innovation projects. A community of practice will be set up to\nensure the continuity of the ongoing activities related to smart grid\ninteroperability. To outlive the duration of the int:net project, the aim is to\nformalise the community of practice as a legal entity.",
            "author": [
                "Valerie Reif",
                "Thomas I. Strasser",
                "Joseba Jimeno",
                "Marjolaine Farre",
                "Oliver Genest",
                "Am\u00e9lie Gyrard",
                "Mark McGranaghan",
                "Gianluca Lipari",
                "Johann Sch\u00fctz",
                "Mathias Uslar",
                "Sebastian Vogel",
                "Arsim Bytyqi",
                "Rita Dornmair",
                "Andreas Corusa",
                "Gaurav Roy",
                "Ferdinanda Ponci",
                "Alberto Dognini",
                "Antonello Monti"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08284v1",
                "http://arxiv.org/pdf/2309.08284v1"
            ],
            "primary_category": "cs.OH",
            "category": [
                "cs.OH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08279v1",
            "title": "Improving Short Utterance Anti-Spoofing with AASIST2",
            "updated": "2023-09-15T09:45:00Z",
            "published": "2023-09-15T09:45:00Z",
            "summary": "The wav2vec 2.0 and integrated spectro-temporal graph attention network\n(AASIST) based countermeasure achieves great performance in speech\nanti-spoofing. However, current spoof speech detection systems have fixed\ntraining and evaluation durations, while the performance degrades significantly\nduring short utterance evaluation. To solve this problem, AASIST can be\nimproved to AASIST2 by modifying the residual blocks to Res2Net blocks. The\nmodified Res2Net blocks can extract multi-scale features and improve the\ndetection performance for speech of different durations, thus improving the\nshort utterance evaluation performance. On the other hand, adaptive large\nmargin fine-tuning (ALMFT) has achieved performance improvement in short\nutterance speaker verification. Therefore, we apply Dynamic Chunk Size (DCS)\nand ALMFT training strategies in speech anti-spoofing to further improve the\nperformance of short utterance evaluation. Experiments demonstrate that the\nproposed AASIST2 improves the performance of short utterance evaluation while\nmaintaining the performance of regular evaluation on different datasets.",
            "author": [
                "Yuxiang Zhang",
                "Jingze Lu",
                "Zengqiang Shang",
                "Wenchao Wang",
                "Pengyuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08279v1",
                "http://arxiv.org/pdf/2309.08279v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08275v1",
            "title": "User Power Measurement Based IRS Channel Estimation via Single-Layer\n  Neural Network",
            "updated": "2023-09-15T09:36:22Z",
            "published": "2023-09-15T09:36:22Z",
            "summary": "One main challenge for implementing intelligent reflecting surface (IRS)\naided communications lies in the difficulty to obtain the channel knowledge for\nthe base station (BS)-IRS-user cascaded links, which is needed to design\nhigh-performance IRS reflection in practice. Traditional methods for estimating\nIRS cascaded channels are usually based on the additional pilot signals\nreceived at the BS/users, which increase the system training overhead and also\nmay not be compatible with the current communication protocols. To tackle this\nchallenge, we propose in this paper a new single-layer neural network\n(NN)-enabled IRS channel estimation method based on only the knowledge of\nusers' individual received signal power measurements corresponding to different\nIRS random training reflections, which are easily accessible in current\nwireless systems. To evaluate the effectiveness of the proposed channel\nestimation method, we design the IRS reflection for data transmission based on\nthe estimated cascaded channels in an IRS-aided multiuser communication system.\nNumerical results show that the proposed IRS channel estimation and reflection\ndesign can significantly improve the minimum received signal-to-noise ratio\n(SNR) among all users, as compared to existing power measurement based designs.",
            "author": [
                "He Sun",
                "Weidong Mei",
                "Lipeng Zhu",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08275v1",
                "http://arxiv.org/pdf/2309.08275v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08271v1",
            "title": "Greedy Optimization of Resistance-based Graph Robustness with Global and\n  Local Edge Insertions",
            "updated": "2023-09-15T09:28:53Z",
            "published": "2023-09-15T09:28:53Z",
            "summary": "The total effective resistance, also called the Kirchhoff index, provides a\nrobustness measure for a graph $G$. We consider two optimization problems of\nadding $k$ new edges to $G$ such that the resulting graph has minimal total\neffective resistance (i.e., is most robust) -- one where the new edges can be\nanywhere in the graph and one where the new edges need to be incident to a\nspecified focus node. The total effective resistance and effective resistances\nbetween nodes can be computed using the pseudoinverse of the graph Laplacian.\nThe pseudoinverse may be computed explicitly via pseudoinversion; yet, this\ntakes cubic time in practice and quadratic space. We instead exploit\ncombinatorial and algebraic connections to speed up gain computations in an\nestablished generic greedy heuristic. Moreover, we leverage existing randomized\ntechniques to boost the performance of our approaches by introducing a\nsub-sampling step. Our different graph- and matrix-based approaches are indeed\nsignificantly faster than the state-of-the-art greedy algorithm, while their\nquality remains reasonably high and is often quite close. Our experiments show\nthat we can now process larger graphs for which the application of the\nstate-of-the-art greedy approach was impractical before.",
            "author": [
                "Maria Predari",
                "Lukas Berner",
                "Robert Kooij",
                "Henning Meyerhenke"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08271v1",
                "http://arxiv.org/pdf/2309.08271v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08260v1",
            "title": "Using photon-hadron production to impose restrictions on heavy-hadrons\n  fragmentation functions",
            "updated": "2023-09-15T09:14:13Z",
            "published": "2023-09-15T09:14:13Z",
            "summary": "Fragmentation Functions (FF) are universal non-perturbative objects that\nmodel hadronization in some general kind of processes. They are mainly\nextracted from experimental data, hence constraining the parameters of the\ncorresponding fits is crucial for achieving reliable results. As expected, the\nproduction of lighter hadrons is favoured w.r.t. heavy ones, thus we would like\nto exploit the precise knowledge of pion FFs to constraint the shape of kaon\n(or heavier) FFs. In this talk, we show how imposing specific cuts on\nphoton-hadron production leads to relations between the $u$-started FFs. For\ndoing so, we exploit the reconstruction of momentum fractions in terms of\nexperimentally-accessible quantities and introduce NLO QCD + LO QED corrections\nto reduce the theoretical uncertainties.",
            "author": [
                "German F. R. Sborlini",
                "Roger Hern\u00e1ndez-Pinto",
                "Salvador Ochoa-Oregon",
                "David F. Renter\u00eda-Estrada"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08260v1",
                "http://arxiv.org/pdf/2309.08260v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08255v1",
            "title": "Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for\n  Robust Polyglot Text-To-Speech",
            "updated": "2023-09-15T09:03:14Z",
            "published": "2023-09-15T09:03:14Z",
            "summary": "In this work, we introduce a framework for cross-lingual speech synthesis,\nwhich involves an upstream Voice Conversion (VC) model and a downstream\nText-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the\nfirst two stages, we use a VC model to convert utterances in the target locale\nto the voice of the target speaker. In the third stage, the converted data is\ncombined with the linguistic features and durations from recordings in the\ntarget language, which are then used to train a single-speaker acoustic model.\nFinally, the last stage entails the training of a locale-independent vocoder.\nOur evaluations show that the proposed paradigm outperforms state-of-the-art\napproaches which are based on training a large multilingual TTS model. In\naddition, our experiments demonstrate the robustness of our approach with\ndifferent model architectures, languages, speakers and amounts of data.\nMoreover, our solution is especially beneficial in low-resource settings.",
            "author": [
                "Dariusz Piotrowski",
                "Renard Korzeniowski",
                "Alessio Falai",
                "Sebastian Cygert",
                "Kamil Pokora",
                "Georgi Tinchev",
                "Ziyao Zhang",
                "Kayoko Yanagisawa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08255v1",
                "http://arxiv.org/pdf/2309.08255v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08248v2",
            "title": "Verifiable Privacy-Preserving Computing",
            "updated": "2023-12-04T08:04:30Z",
            "published": "2023-09-15T08:44:13Z",
            "summary": "Privacy-preserving computation (PPC) methods, such as secure multiparty\ncomputation (MPC) and homomorphic encryption (HE), are deployed increasingly\noften to guarantee data confidentiality in computations over private,\ndistributed data. Similarly, we observe a steep increase in the adoption of\nzero-knowledge proofs (ZKPs) to guarantee (public) verifiability of locally\nexecuted computations. We project that applications that are data intensive and\nrequire strong privacy guarantees, are also likely to require correctness\nguarantees, especially when outsourced. While the combination of methods for\nverifiability and privacy protection has clear benefits, certain challenges\nstand before their widespread practical adoption.\n  In this work, we analyze existing solutions that combine verifiability with\nprivacy-preserving computations over distributed data, in order to preserve\nconfidentiality and guarantee correctness at the same time.We classify and\ncompare 32 different schemes, regarding solution approach, security,\nefficiency, and practicality. Lastly, we discuss some of the most promising\nsolutions in this regard, and present various open challenges and directions\nfor future research.",
            "author": [
                "Tariq Bontekoe",
                "Dimka Karastoyanova",
                "Fatih Turkmen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08248v2",
                "http://arxiv.org/pdf/2309.08248v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08241v1",
            "title": "Topological Node2vec: Enhanced Graph Embedding via Persistent Homology",
            "updated": "2023-09-15T08:31:26Z",
            "published": "2023-09-15T08:31:26Z",
            "summary": "Node2vec is a graph embedding method that learns a vector representation for\neach node of a weighted graph while seeking to preserve relative proximity and\nglobal structure. Numerical experiments suggest Node2vec struggles to recreate\nthe topology of the input graph. To resolve this we introduce a topological\nloss term to be added to the training loss of Node2vec which tries to align the\npersistence diagram (PD) of the resulting embedding as closely as possible to\nthat of the input graph. Following results in computational optimal transport,\nwe carefully adapt entropic regularization to PD metrics, allowing us to\nmeasure the discrepancy between PDs in a differentiable way. Our modified loss\nfunction can then be minimized through gradient descent to reconstruct both the\ngeometry and the topology of the input graph. We showcase the benefits of this\napproach using demonstrative synthetic examples.",
            "author": [
                "Yasuaki Hiraoka",
                "Yusuke Imoto",
                "Killian Meehan",
                "Th\u00e9o Lacombe",
                "Toshiaki Yachimura"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08241v1",
                "http://arxiv.org/pdf/2309.08241v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.AT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08240v1",
            "title": "Understanding ice and water film formation on soil particles by\n  combining DFT and Casimir-Lifshitz forces",
            "updated": "2023-09-15T08:30:18Z",
            "published": "2023-09-15T08:30:18Z",
            "summary": "Thin films of ice and water on soil particles play crucial roles in\nenvironmental and technological processes. Understanding the fundamental\nphysical mechanisms underlying their formation is essential for advancing\nscientific knowledge and engineering practices. Herein, we focus on the role of\nthe Casimir-Lifshitz force, also referred to as dispersion force, in the\nformation and behavior of thin films of ice and water on soil particles at\n273.16 K, arising from quantum fluctuations of the electromagnetic field and\ndepending on the dielectric properties of interacting materials. We employ the\nfirst-principles density functional theory (DFT) to compute the dielectric\nfunctions for two model materials, CaCO$_3$ and Al$_2$O$_3$, essential\nconstituents in various soils. These dielectric functions are used with the\nKramers-Kronig relationship and different extrapolations to calculate the\nfrequency-dependent quantities required for determining forces and free\nenergies. Moreover, we assess the accuracy of the optical data based on the DFT\nto model dispersion forces effectively, such as those between soil particles.\nOur findings reveal that moisture can accumulate into almost micron-sized water\nlayers on the surface of calcite (soil) particles, significantly impacting the\naverage dielectric properties of soil particles. This research highlights the\nrelevance of DFT-based data for understanding thin film formation in soil\nparticles and offers valuable insights for environmental and engineering\napplications.",
            "author": [
                "M. Bostr\u00f6m",
                "S. Kuthe",
                "S. Carretero-Palacios",
                "V. Esteso",
                "Y. Li",
                "I. Brevik",
                "H. R. Gopidi",
                "O. I. Malyi",
                "B. Glaser",
                "C. Persson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08240v1",
                "http://arxiv.org/pdf/2309.08240v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08227v1",
            "title": "VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime\n  Inference",
            "updated": "2023-09-15T07:54:49Z",
            "published": "2023-09-15T07:54:49Z",
            "summary": "Lifelong learning, also referred to as continual learning, is the problem of\ntraining an AI agent continuously while also preventing it from forgetting its\npreviously acquired knowledge. Most of the existing methods primarily focus on\nlifelong learning within a static environment and lack the ability to mitigate\nforgetting in a quickly-changing dynamic environment. Streaming lifelong\nlearning is a challenging setting of lifelong learning with the goal of\ncontinuous learning in a dynamic non-stationary environment without forgetting.\nWe introduce a novel approach to lifelong learning, which is streaming,\nrequires a single pass over the data, can learn in a class-incremental manner,\nand can be evaluated on-the-fly (anytime inference). To accomplish these, we\npropose virtual gradients for continual representation learning to prevent\ncatastrophic forgetting and leverage an exponential-moving-average-based\nsemantic memory to further enhance performance. Extensive experiments on\ndiverse datasets demonstrate our method's efficacy and superior performance\nover existing methods.",
            "author": [
                "Soumya Banerjee",
                "Vinay K. Verma",
                "Avideep Mukherjee",
                "Deepak Gupta",
                "Vinay P. Namboodiri",
                "Piyush Rai"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08227v1",
                "http://arxiv.org/pdf/2309.08227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08225v1",
            "title": "Silent Vulnerability-fixing Commit Identification Based on Graph Neural\n  Networks",
            "updated": "2023-09-15T07:51:39Z",
            "published": "2023-09-15T07:51:39Z",
            "summary": "The growing dependence of software projects on external libraries has\ngenerated apprehensions regarding the security of these libraries because of\nconcealed vulnerabilities. Handling these vulnerabilities presents difficulties\ndue to the temporal delay between remediation and public exposure. Furthermore,\na substantial fraction of open-source projects covertly address vulnerabilities\nwithout any formal notification, influencing vulnerability management.\nEstablished solutions like OWASP predominantly hinge on public announcements,\nlimiting their efficacy in uncovering undisclosed vulnerabilities. To address\nthis challenge, the automated identification of vulnerability-fixing commits\nhas come to the forefront. In this paper, we present VFFINDER, a novel\ngraph-based approach for automated silent vulnerability fix identification.\nVFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and\nrepresents them in annotated ASTs. To precisely capture the meaning of code\nchanges, the changed code is represented in connection with the related\nunchanged code. In VFFINDER, the structure of the changed code and related\nunchanged code are captured and the structural changes are represented in\nannotated Abstract Syntax Trees (aAST). VFFINDER distinguishes\nvulnerability-fixing commits from non-fixing ones using attention-based graph\nneural network models to extract structural features expressed in aASTs. We\nconducted experiments to evaluate VFFINDER on a dataset of 11K+ vulnerability\nfixing commits in 507 real-world C/C++ projects. Our results show that VFFINDER\nsignificantly improves the state-of-the-art methods by 272-420% in Precision,\n22-70% in Recall, and 3.2X-8.2X in F1. Especially, VFFINDER speeds up the\nsilent fix identification process by up to 121% with the same effort reviewing\n50K LOC compared to the existing approaches.",
            "author": [
                "Hieu Dinh Vo",
                "Thanh Trong Vu",
                "Son Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08225v1",
                "http://arxiv.org/pdf/2309.08225v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08220v1",
            "title": "UniST: Towards Unifying Saliency Transformer for Video Saliency\n  Prediction and Detection",
            "updated": "2023-09-15T07:39:53Z",
            "published": "2023-09-15T07:39:53Z",
            "summary": "Video saliency prediction and detection are thriving research domains that\nenable computers to simulate the distribution of visual attention akin to how\nhumans perceiving dynamic scenes. While many approaches have crafted\ntask-specific training paradigms for either video saliency prediction or video\nsalient object detection tasks, few attention has been devoted to devising a\ngeneralized saliency modeling framework that seamlessly bridges both these\ndistinct tasks. In this study, we introduce the Unified Saliency Transformer\n(UniST) framework, which comprehensively utilizes the essential attributes of\nvideo saliency prediction and video salient object detection. In addition to\nextracting representations of frame sequences, a saliency-aware transformer is\ndesigned to learn the spatio-temporal representations at progressively\nincreased resolutions, while incorporating effective cross-scale saliency\ninformation to produce a robust representation. Furthermore, a task-specific\ndecoder is proposed to perform the final prediction for each task. To the best\nof our knowledge, this is the first work that explores designing a transformer\nstructure for both saliency modeling tasks. Convincible experiments demonstrate\nthat the proposed UniST achieves superior performance across seven challenging\nbenchmarks for two tasks, and significantly outperforms the other\nstate-of-the-art methods.",
            "author": [
                "Junwen Xiong",
                "Peng Zhang",
                "Chuanyue Li",
                "Wei Huang",
                "Yufei Zha",
                "Tao You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08220v1",
                "http://arxiv.org/pdf/2309.08220v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08216v1",
            "title": "Unified Risk Analysis for Weakly Supervised Learning",
            "updated": "2023-09-15T07:30:15Z",
            "published": "2023-09-15T07:30:15Z",
            "summary": "Among the flourishing research of weakly supervised learning (WSL), we\nrecognize the lack of a unified interpretation of the mechanism behind the\nweakly supervised scenarios, let alone a systematic treatment of the risk\nrewrite problem, a crucial step in the empirical risk minimization approach. In\nthis paper, we introduce a framework providing a comprehensive understanding\nand a unified methodology for WSL. The formulation component of the framework,\nleveraging a contamination perspective, provides a unified interpretation of\nhow weak supervision is formed and subsumes fifteen existing WSL settings. The\ninduced reduction graphs offer comprehensive connections over WSLs. The\nanalysis component of the framework, viewed as a decontamination process,\nprovides a systematic method of conducting risk rewrite. In addition to the\nconventional inverse matrix approach, we devise a novel strategy called\nmarginal chain aiming to decontaminate distributions. We justify the\nfeasibility of the proposed framework by recovering existing rewrites reported\nin the literature.",
            "author": [
                "Chao-Kai Chiang",
                "Masashi Sugiyama"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08216v1",
                "http://arxiv.org/pdf/2309.08216v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08211v1",
            "title": "Practical Program Repair via Preference-based Ensemble Strategy",
            "updated": "2023-09-15T07:23:04Z",
            "published": "2023-09-15T07:23:04Z",
            "summary": "To date, over 40 Automated Program Repair (APR) tools have been designed with\nvarying bug-fixing strategies, which have been demonstrated to have\ncomplementary performance in terms of being effective for different bug\nclasses. Intuitively, it should be feasible to improve the overall bug-fixing\nperformance of APR via assembling existing tools. Unfortunately, simply\ninvoking all available APR tools for a given bug can result in unacceptable\ncosts on APR execution as well as on patch validation (via expensive testing).\nTherefore, while assembling existing tools is appealing, it requires an\nefficient strategy to reconcile the need to fix more bugs and the requirements\nfor practicality. In light of this problem, we propose a Preference-based\nEnsemble Program Repair framework (P-EPR), which seeks to effectively rank APR\ntools for repairing different bugs. P-EPR is the first non-learning-based APR\nensemble method that is novel in its exploitation of repair patterns as a major\nsource of knowledge for ranking APR tools and its reliance on a dynamic update\nstrategy that enables it to immediately exploit and benefit from newly derived\nrepair results. Experimental results show that P-EPR outperforms existing\nstrategies significantly both in flexibility and effectiveness.",
            "author": [
                "Wenkang Zhong",
                "Chuanyi Li",
                "Kui Liu",
                "Tongtong Xu",
                "Tegawend\u00e9 F. Bissyand\u00e9",
                "Jidong Ge",
                "Bin Luo",
                "Vincent Ng"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3597503.3623310",
                "http://arxiv.org/abs/2309.08211v1",
                "http://arxiv.org/pdf/2309.08211v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08206v1",
            "title": "Salient Object Detection in Optical Remote Sensing Images Driven by\n  Transformer",
            "updated": "2023-09-15T07:14:43Z",
            "published": "2023-09-15T07:14:43Z",
            "summary": "Existing methods for Salient Object Detection in Optical Remote Sensing\nImages (ORSI-SOD) mainly adopt Convolutional Neural Networks (CNNs) as the\nbackbone, such as VGG and ResNet. Since CNNs can only extract features within\ncertain receptive fields, most ORSI-SOD methods generally follow the\nlocal-to-contextual paradigm. In this paper, we propose a novel Global\nExtraction Local Exploration Network (GeleNet) for ORSI-SOD following the\nglobal-to-local paradigm. Specifically, GeleNet first adopts a transformer\nbackbone to generate four-level feature embeddings with global long-range\ndependencies. Then, GeleNet employs a Direction-aware Shuffle Weighted Spatial\nAttention Module (D-SWSAM) and its simplified version (SWSAM) to enhance local\ninteractions, and a Knowledge Transfer Module (KTM) to further enhance\ncross-level contextual interactions. D-SWSAM comprehensively perceives the\norientation information in the lowest-level features through directional\nconvolutions to adapt to various orientations of salient objects in ORSIs, and\neffectively enhances the details of salient objects with an improved attention\nmechanism. SWSAM discards the direction-aware part of D-SWSAM to focus on\nlocalizing salient objects in the highest-level features. KTM models the\ncontextual correlation knowledge of two middle-level features of different\nscales based on the self-attention mechanism, and transfers the knowledge to\nthe raw features to generate more discriminative features. Finally, a saliency\npredictor is used to generate the saliency map based on the outputs of the\nabove three modules. Extensive experiments on three public datasets demonstrate\nthat the proposed GeleNet outperforms relevant state-of-the-art methods. The\ncode and results of our method are available at\nhttps://github.com/MathLee/GeleNet.",
            "author": [
                "Gongyang Li",
                "Zhen Bai",
                "Zhi Liu",
                "Xinpeng Zhang",
                "Haibin Ling"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIP.2023.3314285",
                "http://arxiv.org/abs/2309.08206v1",
                "http://arxiv.org/pdf/2309.08206v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08204v1",
            "title": "One-stage Modality Distillation for Incomplete Multimodal Learning",
            "updated": "2023-09-15T07:12:27Z",
            "published": "2023-09-15T07:12:27Z",
            "summary": "Learning based on multimodal data has attracted increasing interest recently.\nWhile a variety of sensory modalities can be collected for training, not all of\nthem are always available in development scenarios, which raises the challenge\nto infer with incomplete modality. To address this issue, this paper presents a\none-stage modality distillation framework that unifies the privileged knowledge\ntransfer and modality information fusion into a single optimization procedure\nvia multi-task learning. Compared with the conventional modality distillation\nthat performs them independently, this helps to capture the valuable\nrepresentation that can assist the final model inference directly.\nSpecifically, we propose the joint adaptation network for the modality transfer\ntask to preserve the privileged information. This addresses the representation\nheterogeneity caused by input discrepancy via the joint distribution\nadaptation. Then, we introduce the cross translation network for the modality\nfusion task to aggregate the restored and available modality features. It\nleverages the parameters-sharing strategy to capture the cross-modal cues\nexplicitly. Extensive experiments on RGB-D classification and segmentation\ntasks demonstrate the proposed multimodal inheritance framework can overcome\nthe problem of incomplete modality input in various scenes and achieve\nstate-of-the-art performance.",
            "author": [
                "Shicai Wei",
                "Yang Luo",
                "Chunbo Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08204v1",
                "http://arxiv.org/pdf/2309.08204v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08196v1",
            "title": "ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection",
            "updated": "2023-09-15T06:55:43Z",
            "published": "2023-09-15T06:55:43Z",
            "summary": "Few-shot object detection (FSOD) identifies objects from extremely few\nannotated samples. Most existing FSOD methods, recently, apply the two-stage\nlearning paradigm, which transfers the knowledge learned from abundant base\nclasses to assist the few-shot detectors by learning the global features.\nHowever, such existing FSOD approaches seldom consider the localization of\nobjects from local to global. Limited by the scarce training data in FSOD, the\ntraining samples of novel classes typically capture part of objects, resulting\nin such FSOD methods cannot detect the completely unseen object during testing.\nTo tackle this problem, we propose an Extensible Co-Existing Attention (ECEA)\nmodule to enable the model to infer the global object according to the local\nparts. Essentially, the proposed module continuously learns the extensible\nability on the base stage with abundant samples and transfers it to the novel\nstage, which can assist the few-shot model to quickly adapt in extending local\nregions to co-existing regions. Specifically, we first devise an extensible\nattention mechanism that starts with a local region and extends attention to\nco-existing regions that are similar and adjacent to the given local region. We\nthen implement the extensible attention mechanism in different feature scales\nto progressively discover the full object in various receptive fields.\nExtensive experiments on the PASCAL VOC and COCO datasets show that our ECEA\nmodule can assist the few-shot detector to completely predict the object\ndespite some regions failing to appear in the training samples and achieve the\nnew state of the art compared with existing FSOD methods.",
            "author": [
                "Zhimeng Xin",
                "Tianxu Wu",
                "Shiming Chen",
                "Yixiong Zou",
                "Ling Shao",
                "Xinge You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08196v1",
                "http://arxiv.org/pdf/2309.08196v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08192v1",
            "title": "A Cross Entropy Approach to the Domination Problem and its Variants",
            "updated": "2023-09-15T06:50:10Z",
            "published": "2023-09-15T06:50:10Z",
            "summary": "The domination problem and several of its variants (total domination,\n2-domination and secure domination) are considered. These problems have various\nreal-world applications, but are NP-hard to solve to provable optimality,\nmaking fast heuristics for these problems desirable. There is a wealth of\nhighly-developed heuristics and approximation algorithms for the domination\nproblem, however such heuristics are much less common for variants of the\ndomination problem. We redress this by proposing an implementation of the cross\nentropy method that can be applied to any sensible variant of domination. We\npresent results from experiments which demonstrate that this approach can\nproduce good results in an efficient manner even for larger graphs, and that it\nworks roughly as well for any of the domination variants considered.",
            "author": [
                "Ryan Burdett",
                "Michael Haythorpe",
                "Alex Newcombe"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08192v1",
                "http://arxiv.org/pdf/2309.08192v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08185v1",
            "title": "Multilingual Sentence-Level Semantic Search using Meta-Distillation\n  Learning",
            "updated": "2023-09-15T06:22:37Z",
            "published": "2023-09-15T06:22:37Z",
            "summary": "Multilingual semantic search is the task of retrieving relevant contents to a\nquery expressed in different language combinations. This requires a better\nsemantic understanding of the user's intent and its contextual meaning.\nMultilingual semantic search is less explored and more challenging than its\nmonolingual or bilingual counterparts, due to the lack of multilingual parallel\nresources for this task and the need to circumvent \"language bias\". In this\nwork, we propose an alignment approach: MAML-Align, specifically for\nlow-resource scenarios. Our approach leverages meta-distillation learning based\non MAML, an optimization-based Model-Agnostic Meta-Learner. MAML-Align distills\nknowledge from a Teacher meta-transfer model T-MAML, specialized in\ntransferring from monolingual to bilingual semantic search, to a Student model\nS-MAML, which meta-transfers from bilingual to multilingual semantic search. To\nthe best of our knowledge, we are the first to extend meta-distillation to a\nmultilingual search application. Our empirical results show that on top of a\nstrong baseline based on sentence transformers, our meta-distillation approach\nboosts the gains provided by MAML and significantly outperforms naive\nfine-tuning methods. Furthermore, multilingual meta-distillation learning\nimproves generalization even to unseen languages.",
            "author": [
                "Meryem M'hamdi",
                "Jonathan May",
                "Franck Dernoncourt",
                "Trung Bui",
                "Seunghyun Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08185v1",
                "http://arxiv.org/pdf/2309.08185v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08184v2",
            "title": "On the first two eigenvalues of regular graphs",
            "updated": "2023-09-27T07:04:36Z",
            "published": "2023-09-15T06:19:49Z",
            "summary": "Let $G$ be a regular graph with $m$ edges, and let $\\mu_1, \\mu_2$ denote the\ntwo largest eigenvalues of $A_G$, the adjacency matrix of $G$. We show that\n$$\\mu_1^2 + \\mu_2^2 \\leq \\frac{2(\\omega - 1)}{\\omega} m$$ where $\\omega$ is the\nclique number of $G$. This confirms a conjecture of Bollob\\'{a}s and Nikiforov\nfor regular graphs.",
            "author": [
                "Shengtong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08184v2",
                "http://arxiv.org/pdf/2309.08184v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08183v1",
            "title": "Spectral Properties and Weak Detection in Stochastic Block Models",
            "updated": "2023-09-15T06:13:53Z",
            "published": "2023-09-15T06:13:53Z",
            "summary": "We consider the spectral properties of balanced stochastic block models of\nwhich the average degree grows slower than the number of nodes (sparse regime)\nor proportional to it (dense regime). For both regimes, we prove a phase\ntransition of the extreme eigenvalues of SBM at the Kesten--Stigum threshold.\nWe also prove the central limit theorem for the linear spectral statistics for\nboth regimes. We propose a hypothesis test for determining the presence of\ncommunities of the graph, based on the central limit theorem for the linear\nspectral statistics.",
            "author": [
                "Yoochan Han",
                "Ji Oon Lee",
                "Wooseok Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08183v1",
                "http://arxiv.org/pdf/2309.08183v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08182v2",
            "title": "Using Large Language Model to Solve and Explain Physics Word Problems\n  Approaching Human Level",
            "updated": "2023-09-20T07:08:53Z",
            "published": "2023-09-15T06:13:06Z",
            "summary": "Our work demonstrates that large language model (LLM) pre-trained on texts\ncan not only solve pure math word problems, but also physics word problems,\nwhose solution requires calculation and inference based on prior physical\nknowledge. We collect and annotate the first physics word problem\ndataset-PhysQA, which contains over 1000 junior high school physics word\nproblems (covering Kinematics, Mass&Density, Mechanics, Heat, Electricity).\nThen we use OpenAI' s GPT3.5 to generate the answer of these problems and found\nthat GPT3.5 could automatically solve 49.3% of the problems through zero-shot\nlearning and 73.2% through few-shot learning. This result demonstrates that by\nusing similar problems and their answers as prompt, LLM could solve elementary\nphysics word problems approaching human level performance. In addition to\nsolving problems, GPT3.5 can also summarize the knowledge or topics covered by\nthe problems, provide relevant explanations, and generate new physics word\nproblems based on the input. Our work is the first research to focus on the\nautomatic solving, explanation, and generation of physics word problems across\nvarious types and scenarios, and we achieve an acceptable and state-of-the-art\naccuracy. This underscores the potential of LLMs for further applications in\nsecondary education.",
            "author": [
                "Jingzhe Ding",
                "Yan Cen",
                "Xinyuan Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08182v2",
                "http://arxiv.org/pdf/2309.08182v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08179v1",
            "title": "STDG: Semi-Teacher-Student Training Paradigram for Depth-guided\n  One-stage Scene Graph Generation",
            "updated": "2023-09-15T06:06:33Z",
            "published": "2023-09-15T06:06:33Z",
            "summary": "Scene Graph Generation is a critical enabler of environmental comprehension\nfor autonomous robotic systems. Most of existing methods, however, are often\nthwarted by the intricate dynamics of background complexity, which limits their\nability to fully decode the inherent topological information of the\nenvironment. Additionally, the wealth of contextual information encapsulated\nwithin depth cues is often left untapped, rendering existing approaches less\neffective. To address these shortcomings, we present STDG, an avant-garde\nDepth-Guided One-Stage Scene Graph Generation methodology. The innovative\narchitecture of STDG is a triad of custom-built modules: The Depth Guided HHA\nRepresentation Generation Module, the Depth Guided Semi-Teaching Network\nLearning Module, and the Depth Guided Scene Graph Generation Module. This\ntrifecta of modules synergistically harnesses depth information, covering all\naspects from depth signal generation and depth feature utilization, to the\nfinal scene graph prediction. Importantly, this is achieved without imposing\nadditional computational burden during the inference phase. Experimental\nresults confirm that our method significantly enhances the performance of\none-stage scene graph generation baselines.",
            "author": [
                "Xukun Zhou",
                "Zhenbo Song",
                "Jun He",
                "Hongyan Liu",
                "Zhaoxin Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08179v1",
                "http://arxiv.org/pdf/2309.08179v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08169v1",
            "title": "On Induced Versions of Menger's Theorem on Sparse Graphs",
            "updated": "2023-09-15T05:34:53Z",
            "published": "2023-09-15T05:34:53Z",
            "summary": "Let $A$ and $B$ be sets of vertices in a graph $G$. Menger's theorem states\nthat for every positive integer $k$, either there exists a collection of $k$\nvertex-disjoint paths between $A$ and $B$, or $A$ can be separated from $B$ by\na set of at most $k-1$ vertices. Let $\\Delta$ be the maximum degree of $G$. We\nshow that there exists a function $f(\\Delta) = (\\Delta+1)^{\\Delta^2+1}$, so\nthat for every positive integer $k$, either there exists a collection of $k$\nvertex-disjoint and pairwise anticomplete paths between $A$ and $B$, or $A$ can\nbe separated from $B$ by a set of at most $k \\cdot f(\\Delta)$ vertices. We also\nshow that the result can be generalized from bounded-degree graphs to graphs\nexcluding a topological minor. On the negative side, we show that no such\nrelation holds on graphs that have degeneracy 2 and arbitrarily large girth,\neven when $k = 2$. Similar results were obtained independently and concurrently\nby Hendrey, Norin, Steiner, and Turcotte [arXiv:2309.07905].",
            "author": [
                "Peter Gartland",
                "Tuukka Korhonen",
                "Daniel Lokshtanov"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08169v1",
                "http://arxiv.org/pdf/2309.08169v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08165v1",
            "title": "To Predict or to Reject: Causal Effect Estimation with Uncertainty on\n  Networked Data",
            "updated": "2023-09-15T05:25:43Z",
            "published": "2023-09-15T05:25:43Z",
            "summary": "Due to the imbalanced nature of networked observational data, the causal\neffect predictions for some individuals can severely violate the\npositivity/overlap assumption, rendering unreliable estimations. Nevertheless,\nthis potential risk of individual-level treatment effect estimation on\nnetworked data has been largely under-explored. To create a more trustworthy\ncausal effect estimator, we propose the uncertainty-aware graph deep kernel\nlearning (GraphDKL) framework with Lipschitz constraint to model the prediction\nuncertainty with Gaussian process and identify unreliable estimations. To the\nbest of our knowledge, GraphDKL is the first framework to tackle the violation\nof positivity assumption when performing causal effect estimation with graphs.\nWith extensive experiments, we demonstrate the superiority of our proposed\nmethod in uncertainty-aware causal effect estimation on networked data.",
            "author": [
                "Hechuan Wen",
                "Tong Chen",
                "Li Kheng Chai",
                "Shazia Sadiq",
                "Kai Zheng",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08165v1",
                "http://arxiv.org/pdf/2309.08165v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.10662v2",
            "title": "Assessing the Influence of Different Types of Probing on Adversarial\n  Decision-Making in a Deception Game",
            "updated": "2023-10-22T14:53:12Z",
            "published": "2023-09-15T04:31:11Z",
            "summary": "Deception, which includes leading cyber-attackers astray with false\ninformation, has shown to be an effective method of thwarting cyber-attacks.\nThere has been little investigation of the effect of probing action costs on\nadversarial decision-making, despite earlier studies on deception in\ncybersecurity focusing primarily on variables like network size and the\npercentage of honeypots utilized in games. Understanding human decision-making\nwhen prompted with choices of various costs is essential in many areas such as\nin cyber security. In this paper, we will use a deception game (DG) to examine\ndifferent costs of probing on adversarial decisions. To achieve this we\nutilized an IBLT model and a delayed feedback mechanism to mimic knowledge of\nhuman actions. Our results were taken from an even split of deception and no\ndeception to compare each influence. It was concluded that probing was slightly\ntaken less as the cost of probing increased. The proportion of attacks stayed\nrelatively the same as the cost of probing increased. Although a constant cost\nled to a slight decrease in attacks. Overall, our results concluded that the\ndifferent probing costs do not have an impact on the proportion of attacks\nwhereas it had a slightly noticeable impact on the proportion of probing.",
            "author": [
                "Md Abu Sayed",
                "Mohammad Ariful Islam Khan",
                "Bryant A Allsup",
                "Joshua Zamora",
                "Palvi Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10662v2",
                "http://arxiv.org/pdf/2310.10662v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08144v1",
            "title": "Two-Step Knowledge Distillation for Tiny Speech Enhancement",
            "updated": "2023-09-15T04:19:38Z",
            "published": "2023-09-15T04:19:38Z",
            "summary": "Tiny, causal models are crucial for embedded audio machine learning\napplications. Model compression can be achieved via distilling knowledge from a\nlarge teacher into a smaller student model. In this work, we propose a novel\ntwo-step approach for tiny speech enhancement model distillation. In contrast\nto the standard approach of a weighted mixture of distillation and supervised\nlosses, we firstly pre-train the student using only the knowledge distillation\n(KD) objective, after which we switch to a fully supervised training regime. We\nalso propose a novel fine-grained similarity-preserving KD loss, which aims to\nmatch the student's intra-activation Gram matrices to that of the teacher. Our\nmethod demonstrates broad improvements, but particularly shines in adverse\nconditions including high compression and low signal to noise ratios (SNR),\nyielding signal to distortion ratio gains of 0.9 dB and 1.1 dB, respectively,\nat -5 dB input SNR and 63x compression compared to baseline.",
            "author": [
                "Rayan Daod Nathoo",
                "Mikolaj Kegler",
                "Marko Stamenovic"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08144v1",
                "http://arxiv.org/pdf/2309.08144v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08138v3",
            "title": "Find What You Want: Learning Demand-conditioned Object Attribute Space\n  for Demand-driven Navigation",
            "updated": "2023-11-06T11:02:58Z",
            "published": "2023-09-15T04:07:57Z",
            "summary": "The task of Visual Object Navigation (VON) involves an agent's ability to\nlocate a particular object within a given scene. In order to successfully\naccomplish the VON task, two essential conditions must be fulfilled:1) the user\nmust know the name of the desired object; and 2) the user-specified object must\nactually be present within the scene. To meet these conditions, a simulator can\nincorporate pre-defined object names and positions into the metadata of the\nscene. However, in real-world scenarios, it is often challenging to ensure that\nthese conditions are always met. Human in an unfamiliar environment may not\nknow which objects are present in the scene, or they may mistakenly specify an\nobject that is not actually present. Nevertheless, despite these challenges,\nhuman may still have a demand for an object, which could potentially be\nfulfilled by other objects present within the scene in an equivalent manner.\nHence, we propose Demand-driven Navigation (DDN), which leverages the user's\ndemand as the task instruction and prompts the agent to find the object matches\nthe specified demand. DDN aims to relax the stringent conditions of VON by\nfocusing on fulfilling the user's demand rather than relying solely on\npredefined object categories or names. We propose a method first acquire\ntextual attribute features of objects by extracting common knowledge from a\nlarge language model. These textual attribute features are subsequently aligned\nwith visual attribute features using Contrastive Language-Image Pre-training\n(CLIP). By incorporating the visual attribute features as prior knowledge, we\nenhance the navigation process. Experiments on AI2Thor with the ProcThor\ndataset demonstrate the visual attribute features improve the agent's\nnavigation performance and outperform the baseline methods commonly used in\nVON.",
            "author": [
                "Hongcheng Wang",
                "Andy Guan Hong Chen",
                "Xiaoqi Li",
                "Mingdong Wu",
                "Hao Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08138v3",
                "http://arxiv.org/pdf/2309.08138v3"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08134v1",
            "title": "AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with\n  Pretrained ViT",
            "updated": "2023-09-15T04:05:01Z",
            "published": "2023-09-15T04:05:01Z",
            "summary": "Towards flexible object-centric visual perception, we propose a one-shot\ninstance-aware object keypoint (OKP) extraction approach, AnyOKP, which\nleverages the powerful representation ability of pretrained vision transformer\n(ViT), and can obtain keypoints on multiple object instances of arbitrary\ncategory after learning from a support image. An off-the-shelf petrained ViT is\ndirectly deployed for generalizable and transferable feature extraction, which\nis followed by training-free feature enhancement. The best-prototype pairs\n(BPPs) are searched for in support and query images based on appearance\nsimilarity, to yield instance-unaware candidate keypoints.Then, the entire\ngraph with all candidate keypoints as vertices are divided to sub-graphs\naccording to the feature distributions on the graph edges. Finally, each\nsub-graph represents an object instance. AnyOKP is evaluated on real object\nimages collected with the cameras of a robot arm, a mobile robot, and a\nsurgical robot, which not only demonstrates the cross-category flexibility and\ninstance awareness, but also show remarkable robustness to domain shift and\nviewpoint change.",
            "author": [
                "Fangbo Qin",
                "Taogang Hou",
                "Shan Lin",
                "Kaiyuan Wang",
                "Michael C. Yip",
                "Shan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08134v1",
                "http://arxiv.org/pdf/2309.08134v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.00013v2",
            "title": "Adaptive Communications in Collaborative Perception with Domain\n  Alignment for Autonomous Driving",
            "updated": "2023-10-24T12:51:49Z",
            "published": "2023-09-15T03:53:35Z",
            "summary": "Collaborative perception among multiple connected and autonomous vehicles can\ngreatly enhance perceptive capabilities by allowing vehicles to exchange\nsupplementary information via communications. Despite advances in previous\napproaches, challenges still remain due to channel variations and data\nheterogeneity among collaborative vehicles. To address these issues, we propose\nACC-DA, a channel-aware collaborative perception framework to dynamically\nadjust the communication graph and minimize the average transmission delay\nwhile mitigating the side effects from the data heterogeneity. Our novelties\nlie in three aspects. We first design a transmission delay minimization method,\nwhich can construct the communication graph and minimize the transmission delay\naccording to different channel information state. We then propose an adaptive\ndata reconstruction mechanism, which can dynamically adjust the rate-distortion\ntrade-off to enhance perception efficiency. Moreover, it minimizes the temporal\nredundancy during data transmissions. Finally, we conceive a domain alignment\nscheme to align the data distribution from different vehicles, which can\nmitigate the domain gap between different vehicles and improve the performance\nof the target task. Comprehensive experiments demonstrate the effectiveness of\nour method in comparison to the existing state-of-the-art works.",
            "author": [
                "Senkang Hu",
                "Zhengru Fang",
                "Haonan An",
                "Guowen Xu",
                "Yuan Zhou",
                "Xianhao Chen",
                "Yuguang Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.00013v2",
                "http://arxiv.org/pdf/2310.00013v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08121v1",
            "title": "\"I'm Not Confident in Debiasing AI Systems Since I Know Too Little\":\n  Teaching AI Creators About Gender Bias Through Hands-on Tutorials",
            "updated": "2023-09-15T03:09:36Z",
            "published": "2023-09-15T03:09:36Z",
            "summary": "Gender bias is rampant in AI systems, causing bad user experience,\ninjustices, and mental harm to women. School curricula fail to educate AI\ncreators on this topic, leaving them unprepared to mitigate gender bias in AI.\nIn this paper, we designed hands-on tutorials to raise AI creators' awareness\nof gender bias in AI and enhance their knowledge of sources of gender bias and\ndebiasing techniques. The tutorials were evaluated with 18 AI creators,\nincluding AI researchers, AI industrial practitioners (i.e., developers and\nproduct managers), and students who had learned AI. Their improved awareness\nand knowledge demonstrated the effectiveness of our tutorials, which have the\npotential to complement the insufficient AI gender bias education in CS/AI\ncourses. Based on the findings, we synthesize design implications and a rubric\nto guide future research, education, and design efforts.",
            "author": [
                "Kyrie Zhixuan Zhou",
                "Jiaxun Cao",
                "Xiaowen Yuan",
                "Daniel E. Weissglass",
                "Zachary Kilhoffer",
                "Madelyn Rose Sanfilippo",
                "Xin Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08121v1",
                "http://arxiv.org/pdf/2309.08121v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08120v1",
            "title": "Post-processing variational quantum algorithm for constrained\n  combinatorial optimization problems",
            "updated": "2023-09-15T03:09:16Z",
            "published": "2023-09-15T03:09:16Z",
            "summary": "We propose post-processing variational quantum algorithm (pVQA) for solving\nconstrained combinatorial optimization problems (COPs). COPs are typically\ntransformed into ground-state search problems of the Ising model on a quantum\nannealer or gate-type quantum device. Variational quantum algorithms are used\nto find an annealing path that leads to the grand state in a short amount of\ntime. Post-processing techniques convert the output solutions of the quantum\ndevices to satisfy the constraints of the COPs. pVQA combines the variational\nquantum algorithm and the post-processing technique. We apply it to two\nconstrained NP-hard COPs: the graph partitioning problem and the quadratic\nknapsack problem. pVQA on a simulator shows that a small number of variational\nparameters is sufficient to achieve an optimal performance within a\npredetermined operation time. Then building upon the simulator results, we\nimplement pVQA on a quantum annealer and a gate-type quantum device. pVQA\nexhibits a superior performance compared with conventional quantum algorithms.",
            "author": [
                "Tatsuhiko Shirai",
                "Nozomu Togawa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08120v1",
                "http://arxiv.org/pdf/2309.08120v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08118v1",
            "title": "Graph IRs for Impure Higher-Order Languages (Technical Report)",
            "updated": "2023-09-15T02:51:31Z",
            "published": "2023-09-15T02:51:31Z",
            "summary": "This is a companion report for the OOPSLA 2023 paper of the same title,\npresenting a detailed end-to-end account of the $\\lambda^*_{\\mathsf{G}}$ graph\nIR, at a level of detail beyond a regular conference paper. Our first concern\nis adequacy and soundness of $\\lambda^*_{\\mathsf{G}}$, which we derive from a\ndirect-style imperative functional language (a variant of Bao et al.'s\n$\\lambda^*$-calculus with reachability types and a simple effect system) by a\nseries of type-preserving translations into a calculus in monadic normalform\n(MNF). Static reachability types and effects entirely inform\n$\\lambda^*_{\\mathsf{G}}$'s dependency synthesis. We argue for its adequacy by\nproving its functional properties along with dependency safety via progress and\npreservation lemmas with respect to a notion of call-by-value (CBV) reduction\nthat checks the observed order of effects.\n  Our second concern is establishing the correctness of\n$\\lambda^*_{\\mathsf{G}}$'s equational rules that drive compiler optimizations\n(e.g., DCE, $\\lambda$-hoisting, etc.), by proving contextual equivalence using\nlogical relations. A key insight is that the functional properties of\ndependency synthesis permit a logical relation on $\\lambda^*_{\\mathsf{G}}$ in\nMNF in terms of previously developed logical relations for the direct-style\n$\\lambda^*$-calculus.\n  Finally, we also include a longer version of the conference paper's section\non code generation and code motion for $\\lambda^*_{\\mathsf{G}}$ as implemented\nin Scala~LMS.",
            "author": [
                "Oliver Bra\u010devac",
                "Guannan Wei",
                "Songlin Jia",
                "Supun Abeysinghe",
                "Yuxuan Jiang",
                "Yuyan Bao",
                "Tiark Rompf"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08118v1",
                "http://arxiv.org/pdf/2309.08118v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08105v1",
            "title": "Libriheavy: a 50,000 hours ASR corpus with punctuation casing and\n  context",
            "updated": "2023-09-15T01:59:21Z",
            "published": "2023-09-15T01:59:21Z",
            "summary": "In this paper, we introduce Libriheavy, a large-scale ASR corpus consisting\nof 50,000 hours of read English speech derived from LibriVox. To the best of\nour knowledge, Libriheavy is the largest freely-available corpus of speech with\nsupervisions. Different from other open-sourced datasets that only provide\nnormalized transcriptions, Libriheavy contains richer information such as\npunctuation, casing and text context, which brings more flexibility for system\nbuilding. Specifically, we propose a general and efficient pipeline to locate,\nalign and segment the audios in previously published Librilight to its\ncorresponding texts. The same as Librilight, Libriheavy also has three training\nsubsets small, medium, large of the sizes 500h, 5000h, 50000h respectively. We\nalso extract the dev and test evaluation sets from the aligned audios and\nguarantee there is no overlapping speakers and books in training sets. Baseline\nsystems are built on the popular CTC-Attention and transducer models.\nAdditionally, we open-source our dataset creatation pipeline which can also be\nused to other audio alignment tasks.",
            "author": [
                "Wei Kang",
                "Xiaoyu Yang",
                "Zengwei Yao",
                "Fangjun Kuang",
                "Yifan Yang",
                "Liyong Guo",
                "Long Lin",
                "Daniel Povey"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08105v1",
                "http://arxiv.org/pdf/2309.08105v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08100v1",
            "title": "Research on Joint Representation Learning Methods for Entity\n  Neighborhood Information and Description Information",
            "updated": "2023-09-15T01:38:07Z",
            "published": "2023-09-15T01:38:07Z",
            "summary": "To address the issue of poor embedding performance in the knowledge graph of\na programming design course, a joint represen-tation learning model that\ncombines entity neighborhood infor-mation and description information is\nproposed. Firstly, a graph at-tention network is employed to obtain the\nfeatures of entity neigh-boring nodes, incorporating relationship features to\nenrich the structural information. Next, the BERT-WWM model is utilized in\nconjunction with attention mechanisms to obtain the representation of entity\ndescription information. Finally, the final entity vector representation is\nobtained by combining the vector representations of entity neighborhood\ninformation and description information. Experimental results demonstrate that\nthe proposed model achieves favorable performance on the knowledge graph\ndataset of the pro-gramming design course, outperforming other baseline models.",
            "author": [
                "Le Xiao",
                "Xin Shan",
                "Yuhua Wang",
                "Miaolei Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08100v1",
                "http://arxiv.org/pdf/2309.08100v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08097v1",
            "title": "Detail Reinforcement Diffusion Model: Augmentation Fine-Grained Visual\n  Categorization in Few-Shot Conditions",
            "updated": "2023-09-15T01:28:59Z",
            "published": "2023-09-15T01:28:59Z",
            "summary": "The challenge in fine-grained visual categorization lies in how to explore\nthe subtle differences between different subclasses and achieve accurate\ndiscrimination. Previous research has relied on large-scale annotated data and\npre-trained deep models to achieve the objective. However, when only a limited\namount of samples is available, similar methods may become less effective.\nDiffusion models have been widely adopted in data augmentation due to their\noutstanding diversity in data generation. However, the high level of detail\nrequired for fine-grained images makes it challenging for existing methods to\nbe directly employed. To address this issue, we propose a novel approach termed\nthe detail reinforcement diffusion model~(DRDM), which leverages the rich\nknowledge of large models for fine-grained data augmentation and comprises two\nkey components including discriminative semantic recombination (DSR) and\nspatial knowledge reference~(SKR). Specifically, DSR is designed to extract\nimplicit similarity relationships from the labels and reconstruct the semantic\nmapping between labels and instances, which enables better discrimination of\nsubtle differences between different subclasses. Furthermore, we introduce the\nSKR module, which incorporates the distributions of different datasets as\nreferences in the feature space. This allows the SKR to aggregate the\nhigh-dimensional distribution of subclass features in few-shot FGVC tasks, thus\nexpanding the decision boundary. Through these two critical components, we\neffectively utilize the knowledge from large models to address the issue of\ndata scarcity, resulting in improved performance for fine-grained visual\nrecognition tasks. Extensive experiments demonstrate the consistent performance\ngain offered by our DRDM.",
            "author": [
                "Tianxu Wu",
                "Shuo Ye",
                "Shuhuang Chen",
                "Qinmu Peng",
                "Xinge You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08097v1",
                "http://arxiv.org/pdf/2309.08097v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08086v1",
            "title": "Fast and Accurate Deep Loop Closing and Relocalization for Reliable\n  LiDAR SLAM",
            "updated": "2023-09-15T00:59:31Z",
            "published": "2023-09-15T00:59:31Z",
            "summary": "Loop closing and relocalization are crucial techniques to establish reliable\nand robust long-term SLAM by addressing pose estimation drift and degeneration.\nThis article begins by formulating loop closing and relocalization within a\nunified framework. Then, we propose a novel multi-head network LCR-Net to\ntackle both tasks effectively. It exploits novel feature extraction and\npose-aware attention mechanism to precisely estimate similarities and 6-DoF\nposes between pairs of LiDAR scans. In the end, we integrate our LCR-Net into a\nSLAM system and achieve robust and accurate online LiDAR SLAM in outdoor\ndriving environments. We thoroughly evaluate our LCR-Net through three setups\nderived from loop closing and relocalization, including candidate retrieval,\nclosed-loop point cloud registration, and continuous relocalization using\nmultiple datasets. The results demonstrate that LCR-Net excels in all three\ntasks, surpassing the state-of-the-art methods and exhibiting a remarkable\ngeneralization ability. Notably, our LCR-Net outperforms baseline methods\nwithout using a time-consuming robust pose estimator, rendering it suitable for\nonline SLAM applications. To our best knowledge, the integration of LCR-Net\nyields the first LiDAR SLAM with the capability of deep loop closing and\nrelocalization. The implementation of our methods will be made open-source.",
            "author": [
                "Chenghao Shi",
                "Xieyuanli Chen",
                "Junhao Xiao",
                "Bin Dai",
                "Huimin Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08086v1",
                "http://arxiv.org/pdf/2309.08086v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08008v1",
            "title": "An Empirical Evaluation of Prompting Strategies for Large Language\n  Models in Zero-Shot Clinical Natural Language Processing",
            "updated": "2023-09-14T19:35:00Z",
            "published": "2023-09-14T19:35:00Z",
            "summary": "Large language models (LLMs) have shown remarkable capabilities in Natural\nLanguage Processing (NLP), especially in domains where labeled data is scarce\nor expensive, such as clinical domain. However, to unlock the clinical\nknowledge hidden in these LLMs, we need to design effective prompts that can\nguide them to perform specific clinical NLP tasks without any task-specific\ntraining data. This is known as in-context learning, which is an art and\nscience that requires understanding the strengths and weaknesses of different\nLLMs and prompt engineering approaches. In this paper, we present a\ncomprehensive and systematic experimental study on prompt engineering for five\nclinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence\nExtraction, Coreference Resolution, Medication Status Extraction, and\nMedication Attribute Extraction. We assessed the prompts proposed in recent\nliterature, including simple prefix, simple cloze, chain of thought, and\nanticipatory prompts, and introduced two new types of prompts, namely heuristic\nprompting and ensemble prompting. We evaluated the performance of these prompts\non three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted\nzero-shot prompting with few-shot prompting, and provide novel insights and\nguidelines for prompt engineering for LLMs in clinical NLP. To the best of our\nknowledge, this is one of the first works on the empirical evaluation of\ndifferent prompt engineering approaches for clinical NLP in this era of\ngenerative AI, and we hope that it will inspire and inform future research in\nthis area.",
            "author": [
                "Sonish Sivarajkumar",
                "Mark Kelley",
                "Alyssa Samolyk-Mazzanti",
                "Shyam Visweswaran",
                "Yanshan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08008v1",
                "http://arxiv.org/pdf/2309.08008v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09987v1",
            "title": "TCGF: A unified tensorized consensus graph framework for multi-view\n  representation learning",
            "updated": "2023-09-14T19:29:14Z",
            "published": "2023-09-14T19:29:14Z",
            "summary": "Multi-view learning techniques have recently gained significant attention in\nthe machine learning domain for their ability to leverage consistency and\ncomplementary information across multiple views. However, there remains a lack\nof sufficient research on generalized multi-view frameworks that unify existing\nworks into a scalable and robust learning framework, as most current works\nfocus on specific styles of multi-view models. Additionally, most multi-view\nlearning works rely heavily on specific-scale scenarios and fail to effectively\ncomprehend multiple scales holistically. These limitations hinder the effective\nfusion of essential information from multiple views, resulting in poor\ngeneralization. To address these limitations, this paper proposes a universal\nmulti-view representation learning framework named Tensorized Consensus Graph\nFramework (TCGF). Specifically, it first provides a unified framework for\nexisting multi-view works to exploit the representations for individual view,\nwhich aims to be suitable for arbitrary assumptions and different-scales\ndatasets. Then, stacks them into a tensor under alignment basics as a\nhigh-order representation, allowing for the smooth propagation of consistency\nand complementary information across all views. Moreover, TCGF proposes\nlearning a consensus embedding shared by adaptively collaborating all views to\nuncover the essential structure of the multi-view data, which utilizes\nview-consensus grouping effect to regularize the view-consensus representation.\nTo further facilitate related research, we provide a specific implementation of\nTCGF for large-scale datasets, which can be efficiently solved by applying the\nalternating optimization strategy. Experimental results conducted on seven\ndifferent-scales datasets indicate the superiority of the proposed TCGF against\nexisting state-of-the-art multi-view learning methods.",
            "author": [
                "Xiangzhu Meng",
                "Wei Wei",
                "Qiang Liu",
                "Shu Wu",
                "Liang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09987v1",
                "http://arxiv.org/pdf/2309.09987v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07986v1",
            "title": "Viewpoint Textual Inversion: Unleashing Novel View Synthesis with\n  Pretrained 2D Diffusion Models",
            "updated": "2023-09-14T18:52:16Z",
            "published": "2023-09-14T18:52:16Z",
            "summary": "Text-to-image diffusion models understand spatial relationship between\nobjects, but do they represent the true 3D structure of the world from only 2D\nsupervision? We demonstrate that yes, 3D knowledge is encoded in 2D image\ndiffusion models like Stable Diffusion, and we show that this structure can be\nexploited for 3D vision tasks. Our method, Viewpoint Neural Textual Inversion\n(ViewNeTI), controls the 3D viewpoint of objects in generated images from\nfrozen diffusion models. We train a small neural mapper to take camera\nviewpoint parameters and predict text encoder latents; the latents then\ncondition the diffusion generation process to produce images with the desired\ncamera viewpoint.\n  ViewNeTI naturally addresses Novel View Synthesis (NVS). By leveraging the\nfrozen diffusion model as a prior, we can solve NVS with very few input views;\nwe can even do single-view novel view synthesis. Our single-view NVS\npredictions have good semantic details and photorealism compared to prior\nmethods. Our approach is well suited for modeling the uncertainty inherent in\nsparse 3D vision problems because it can efficiently generate diverse samples.\nOur view-control mechanism is general, and can even change the camera view in\nimages generated by user-defined prompts.",
            "author": [
                "James Burgess",
                "Kuan-Chieh Wang",
                "Serena Yeung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07986v1",
                "http://arxiv.org/pdf/2309.07986v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07982v1",
            "title": "Uncertainty quantification for learned ISTA",
            "updated": "2023-09-14T18:39:07Z",
            "published": "2023-09-14T18:39:07Z",
            "summary": "Model-based deep learning solutions to inverse problems have attracted\nincreasing attention in recent years as they bridge state-of-the-art numerical\nperformance with interpretability. In addition, the incorporated prior domain\nknowledge can make the training more efficient as the smaller number of\nparameters allows the training step to be executed with smaller datasets.\nAlgorithm unrolling schemes stand out among these model-based learning\ntechniques. Despite their rapid advancement and their close connection to\ntraditional high-dimensional statistical methods, they lack certainty estimates\nand a theory for uncertainty quantification is still elusive. This work\nprovides a step towards closing this gap proposing a rigorous way to obtain\nconfidence intervals for the LISTA estimator.",
            "author": [
                "Frederik Hoppe",
                "Claudio Mayrink Verdun",
                "Felix Krahmer",
                "Hannah Laus",
                "Holger Rauhut"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07982v1",
                "http://arxiv.org/pdf/2309.07982v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "eess.IV",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07981v1",
            "title": "Efficiently Identifying Hotspots in a Spatially Varying Field with\n  Multiple Robots",
            "updated": "2023-09-14T18:33:11Z",
            "published": "2023-09-14T18:33:11Z",
            "summary": "In this paper, we present algorithms to identify environmental hotspots using\nmobile sensors. We examine two approaches: one involving a single robot and\nanother using multiple robots coordinated through a decentralized robot system.\nWe introduce an adaptive algorithm that does not require precise knowledge of\nGaussian Processes (GPs) hyperparameters, making the modeling process more\nflexible. The robots operate for a pre-defined time in the environment. The\nmulti-robot system uses Voronoi partitioning to divide tasks and a Monte Carlo\nTree Search for optimal path planning. Our tests on synthetic and a real-world\ndataset of Chlorophyll density from a Pacific Ocean sub-region suggest that\naccurate estimation of GP hyperparameters may not be essential for hotspot\ndetection, potentially simplifying environmental monitoring tasks.",
            "author": [
                "Varun Suryan",
                "Pratap Tokekar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07981v1",
                "http://arxiv.org/pdf/2309.07981v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07979v1",
            "title": "Fast Safe Rectangular Corridor-based Online AGV Trajectory Optimization\n  with Obstacle Avoidance",
            "updated": "2023-09-14T18:30:53Z",
            "published": "2023-09-14T18:30:53Z",
            "summary": "Automated Guided Vehicles (AGVs) are widely adopted in various industries due\nto their efficiency and adaptability. However, safely deploying AGVs in dynamic\nenvironments remains a significant challenge. This paper introduces an online\ntrajectory optimization framework, the Fast Safe Rectangular Corridor (FSRC),\ndesigned for AGVs in obstacle-rich settings. The primary challenge is\nefficiently planning trajectories that prioritize safety and collision\navoidance. To tackle this challenge, the FSRC algorithm constructs convex\nregions, represented as rectangular corridors, to address obstacle avoidance\nconstraints within an optimal control problem. This conversion from non-convex\nto box constraints improves the collision avoidance efficiency and quality.\nAdditionally, the Modified Visibility Graph algorithm speeds up path planning,\nand a boundary discretization strategy expedites FSRC construction. The\nframework also includes a dynamic obstacle avoidance strategy for real-time\nadaptability. Our framework's effectiveness and superiority have been\ndemonstrated in experiments, particularly in computational efficiency (see Fig.\n\\ref{fig:case1} and \\ref{fig:case23}). Compared to state-of-the-art frameworks,\nour trajectory planning framework significantly enhances computational\nefficiency, ranging from 1 to 2 orders of magnitude (see Table \\ref{tab:res}).\nNotably, the FSRC algorithm outperforms other safe convex corridor-based\nmethods, substantially improving computational efficiency by 1 to 2 orders of\nmagnitude (see Table \\ref{tab:FRSC}).",
            "author": [
                "Shaoqiang Liang",
                "Songyuan Fa",
                "Zong Chen",
                "Yiqun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07979v1",
                "http://arxiv.org/pdf/2309.07979v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07974v1",
            "title": "A Data Source for Reasoning Embodied Agents",
            "updated": "2023-09-14T18:17:16Z",
            "published": "2023-09-14T18:17:16Z",
            "summary": "Recent progress in using machine learning models for reasoning tasks has been\ndriven by novel model architectures, large-scale pre-training protocols, and\ndedicated reasoning datasets for fine-tuning. In this work, to further pursue\nthese advances, we introduce a new data generator for machine reasoning that\nintegrates with an embodied agent. The generated data consists of templated\ntext queries and answers, matched with world-states encoded into a database.\nThe world-states are a result of both world dynamics and the actions of the\nagent. We show the results of several baseline models on instantiations of\ntrain sets. These include pre-trained language models fine-tuned on a\ntext-formatted representation of the database, and graph-structured\nTransformers operating on a knowledge-graph representation of the database. We\nfind that these models can answer some questions about the world-state, but\nstruggle with others. These results hint at new research directions in\ndesigning neural reasoning models and database representations. Code to\ngenerate the data will be released at github.com/facebookresearch/neuralmemory",
            "author": [
                "Jack Lanchantin",
                "Sainbayar Sukhbaatar",
                "Gabriel Synnaeve",
                "Yuxuan Sun",
                "Kavya Srinet",
                "Arthur Szlam"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07974v1",
                "http://arxiv.org/pdf/2309.07974v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07964v1",
            "title": "Improved Shortest Path Restoration Lemmas for Multiple Edge Failures:\n  Trade-offs Between Fault-tolerance and Subpaths",
            "updated": "2023-09-14T18:01:00Z",
            "published": "2023-09-14T18:01:00Z",
            "summary": "The restoration lemma is a classic result by Afek, Bremler-Barr, Kaplan,\nCohen, and Merritt [PODC '01], which relates the structure of shortest paths in\na graph $G$ before and after some edges in the graph fail. Their work shows\nthat, after one edge failure, any replacement shortest path avoiding this\nfailing edge can be partitioned into two pre-failure shortest paths. More\ngenerally, this implies an additive tradeoff between fault tolerance and\nsubpath count: for any $f, k$, we can partition any $f$-edge-failure\nreplacement shortest path into $k+1$ subpaths which are each an\n$(f-k)$-edge-failure replacement shortest path. This generalized result has\nfound applications in routing, graph algorithms, fault tolerant network design,\nand more.\n  Our main result improves this to a multiplicative tradeoff between fault\ntolerance and subpath count. We show that for all $f, k$, any $f$-edge-failure\nreplacement path can be partitioned into $O(k)$ subpaths that are each an\n$(f/k)$-edge-failure replacement path. We also show an asymptotically matching\nlower bound. In particular, our results imply that the original restoration\nlemma is exactly tight in the case $k=1$, but can be significantly improved for\nlarger $k$. We also show an extension of this result to weighted input graphs,\nand we give efficient algorithms that compute path decompositions satisfying\nour improved restoration lemmas.",
            "author": [
                "Greg Bodwin",
                "Lily Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07964v1",
                "http://arxiv.org/pdf/2309.07964v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07920v2",
            "title": "Large-Vocabulary 3D Diffusion Model with Transformer",
            "updated": "2023-09-15T07:56:34Z",
            "published": "2023-09-14T17:59:53Z",
            "summary": "Creating diverse and high-quality 3D assets with an automatic generative\nmodel is highly desirable. Despite extensive efforts on 3D generation, most\nexisting works focus on the generation of a single category or a few\ncategories. In this paper, we introduce a diffusion-based feed-forward\nframework for synthesizing massive categories of real-world 3D objects with a\nsingle generative model. Notably, there are three major challenges for this\nlarge-vocabulary 3D generation: a) the need for expressive yet efficient 3D\nrepresentation; b) large diversity in geometry and texture across categories;\nc) complexity in the appearances of real-world objects. To this end, we propose\na novel triplane-based 3D-aware Diffusion model with TransFormer, DiffTF, for\nhandling challenges via three aspects. 1) Considering efficiency and\nrobustness, we adopt a revised triplane representation and improve the fitting\nspeed and accuracy. 2) To handle the drastic variations in geometry and\ntexture, we regard the features of all 3D objects as a combination of\ngeneralized 3D knowledge and specialized 3D features. To extract generalized 3D\nknowledge from diverse categories, we propose a novel 3D-aware transformer with\nshared cross-plane attention. It learns the cross-plane relations across\ndifferent planes and aggregates the generalized 3D knowledge with specialized\n3D features. 3) In addition, we devise the 3D-aware encoder/decoder to enhance\nthe generalized 3D knowledge in the encoded triplanes for handling categories\nwith complex appearances. Extensive experiments on ShapeNet and OmniObject3D\n(over 200 diverse real-world categories) convincingly demonstrate that a single\nDiffTF model achieves state-of-the-art large-vocabulary 3D object generation\nperformance with large diversity, rich semantics, and high quality.",
            "author": [
                "Ziang Cao",
                "Fangzhou Hong",
                "Tong Wu",
                "Liang Pan",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07920v2",
                "http://arxiv.org/pdf/2309.07920v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07915v2",
            "title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context\n  Learning",
            "updated": "2023-10-02T14:46:01Z",
            "published": "2023-09-14T17:59:17Z",
            "summary": "Since the resurgence of deep learning, vision-language models (VLMs) enhanced\nby large language models (LLMs) have grown exponentially in popularity.\nHowever, while LLMs can utilize extensive background knowledge and task\ninformation with in-context learning, most VLMs still struggle with\nunderstanding complex multi-modal prompts with multiple images, making VLMs\nless effective in downstream vision-language tasks. In this paper, we address\nthe limitation above by 1) introducing MMICL, a new approach to allow the VLM\nto deal with multi-modal inputs efficiently; 2) proposing a novel context\nscheme to augment the in-context learning ability of the VLM; 3) constructing\nthe Multi-modal In-Context Learning (MIC) dataset, designed to enhance the\nVLM's ability to understand complex multi-modal prompts. Our experiments\nconfirm that MMICL achieves new state-of-the-art zero-shot performance on a\nwide range of general vision-language tasks, especially for complex benchmarks,\nincluding MME and MMBench. Our analysis demonstrates that MMICL effectively\ntackles the challenge of complex multi-modal prompt understanding and emerges\nthe impressive ICL ability. Furthermore, we observe that MMICL successfully\nalleviates language bias in VLMs, a common issue for VLMs that often leads to\nhallucination when faced with extensive textual context.",
            "author": [
                "Haozhe Zhao",
                "Zefan Cai",
                "Shuzheng Si",
                "Xiaojian Ma",
                "Kaikai An",
                "Liang Chen",
                "Zixuan Liu",
                "Sheng Wang",
                "Wenjuan Han",
                "Baobao Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07915v2",
                "http://arxiv.org/pdf/2309.07915v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07950v1",
            "title": "Topological and geometric analysis of cell states in single-cell\n  transcriptomic data",
            "updated": "2023-09-14T17:58:58Z",
            "published": "2023-09-14T17:58:58Z",
            "summary": "Single-cell RNA sequencing (scRNA-seq) enables dissecting cellular\nheterogeneity in tissues, resulting in numerous biological discoveries. Various\ncomputational methods have been devised to delineate cell types by clustering\nscRNA-seq data where the clusters are often annotated using prior knowledge of\nmarker genes. In addition to identifying pure cell types, several methods have\nbeen developed to identify cells undergoing state transitions which often rely\non prior clustering results. Present computational approaches predominantly\ninvestigate the local and first-order structures of scRNA-seq data using graph\nrepresentations, while scRNA-seq data frequently displays complex\nhigh-dimensional structures. Here, we present a tool, scGeom for exploiting the\nmultiscale and multidimensional structures in scRNA-seq data by inspecting the\ngeometry via graph curvature and topology via persistent homology of both cell\nnetworks and gene networks. We demonstrate the utility of these structural\nfeatures for reflecting biological properties and functions in several\napplications where we show that curvatures and topological signatures of cell\nand gene networks can help indicate transition cells and developmental potency\nof cells. We additionally illustrate that the structural characteristics can\nimprove the classification of cell types.",
            "author": [
                "Tram Huynh",
                "Zixuan Cang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07950v1",
                "http://arxiv.org/pdf/2309.07950v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "q-bio.GN",
                "92B05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07905v1",
            "title": "On an induced version of Menger's theorem",
            "updated": "2023-09-14T17:53:46Z",
            "published": "2023-09-14T17:53:46Z",
            "summary": "We prove Menger-type results in which the obtained paths are pairwise\nnon-adjacent, both for graphs of bounded maximum degree and, more generally,\nfor graphs excluding a topological minor. We further show better bounds in the\nsubcubic case, and in particular obtain a tight result for two paths using a\ncomputer-assisted proof.",
            "author": [
                "Kevin Hendrey",
                "Sergey Norin",
                "Raphael Steiner",
                "J\u00e9r\u00e9mie Turcotte"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07905v1",
                "http://arxiv.org/pdf/2309.07905v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C38 (Primary) 05C15, 05C40, 05C83 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07900v1",
            "title": "Ambiguity-Aware In-Context Learning with Large Language Models",
            "updated": "2023-09-14T17:48:34Z",
            "published": "2023-09-14T17:48:34Z",
            "summary": "In-context learning (ICL) i.e. showing LLMs only a few task-specific\ndemonstrations has led to downstream gains with no task-specific fine-tuning\nrequired. However, LLMs are sensitive to the choice of prompts, and therefore a\ncrucial research question is how to select good demonstrations for ICL. One\neffective strategy is leveraging semantic similarity between the ICL\ndemonstrations and test inputs by using a text retriever, which however is\nsub-optimal as that does not consider the LLM's existing knowledge about that\ntask. From prior work (Min et al., 2022), we already know that labels paired\nwith the demonstrations bias the model predictions. This leads us to our\nhypothesis whether considering LLM's existing knowledge about the task,\nespecially with respect to the output label space can help in a better\ndemonstration selection strategy. Through extensive experimentation on three\ntext classification tasks, we find that it is beneficial to not only choose\nsemantically similar ICL demonstrations but also to choose those demonstrations\nthat help resolve the inherent label ambiguity surrounding the test example.\nInterestingly, we find that including demonstrations that the LLM previously\nmis-classified and also fall on the test example's decision boundary, brings\nthe most performance gain.",
            "author": [
                "Lingyu Gao",
                "Aditi Chaudhary",
                "Krishna Srinivasan",
                "Kazuma Hashimoto",
                "Karthik Raman",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07900v1",
                "http://arxiv.org/pdf/2309.07900v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07888v1",
            "title": "A Novel Local-Global Feature Fusion Framework for Body-weight Exercise\n  Recognition with Pressure Mapping Sensors",
            "updated": "2023-09-14T17:40:44Z",
            "published": "2023-09-14T17:40:44Z",
            "summary": "We present a novel local-global feature fusion framework for body-weight\nexercise recognition with floor-based dynamic pressure maps. One step further\nfrom the existing studies using deep neural networks mainly focusing on global\nfeature extraction, the proposed framework aims to combine local and global\nfeatures using image processing techniques and the YOLO object detection to\nlocalize pressure profiles from different body parts and consider physical\nconstraints. The proposed local feature extraction method generates two sets of\nhigh-level local features consisting of cropped pressure mapping and numerical\nfeatures such as angular orientation, location on the mat, and pressure area.\nIn addition, we adopt a knowledge distillation for regularization to preserve\nthe knowledge of the global feature extraction and improve the performance of\nthe exercise recognition. Our experimental results demonstrate a notable 11\npercent improvement in F1 score for exercise recognition while preserving\nlabel-specific features.",
            "author": [
                "Davinder Pal Singh",
                "Lala Shakti Swarup Ray",
                "Bo Zhou",
                "Sungho Suh",
                "Paul Lukowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07888v1",
                "http://arxiv.org/pdf/2309.07888v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07885v1",
            "title": "Generating Sets and Algebraic Properties of Pure Mapping Class Groups of\n  Infinite Graphs",
            "updated": "2023-09-14T17:31:35Z",
            "published": "2023-09-14T17:31:35Z",
            "summary": "We completely classify the locally finite, infinite graphs with pure mapping\nclass groups admitting a coarsely bounded generating set. We also study\nalgebraic properties of the pure mapping class group: We establish a semidirect\nproduct decomposition, compute first integral cohomology, and classify when\nthey satisfy residual finiteness and the Tits alternative. These results\nprovide a framework and some initial steps towards quasi-isometric and\nalgebraic rigidity of these groups.",
            "author": [
                "George Domat",
                "Hannah Hoganson",
                "Sanghoon Kwak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07885v1",
                "http://arxiv.org/pdf/2309.07885v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.GT",
                "57S05, 37E25, 57M07, 20E08, 20F65, 54H05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07859v1",
            "title": "Improved Distributed Algorithms for Random Colorings",
            "updated": "2023-09-14T17:02:18Z",
            "published": "2023-09-14T17:02:18Z",
            "summary": "Markov Chain Monte Carlo (MCMC) algorithms are a widely-used algorithmic tool\nfor sampling from high-dimensional distributions, a notable example is the\nequilibirum distribution of graphical models. The Glauber dynamics, also known\nas the Gibbs sampler, is the simplest example of an MCMC algorithm; the\ntransitions of the chain update the configuration at a randomly chosen\ncoordinate at each step. Several works have studied distributed versions of the\nGlauber dynamics and we extend these efforts to a more general family of Markov\nchains. An important combinatorial problem in the study of MCMC algorithms is\nrandom colorings. Given a graph $G$ of maximum degree $\\Delta$ and an integer\n$k\\geq\\Delta+1$, the goal is to generate a random proper vertex $k$-coloring of\n$G$.\n  Jerrum (1995) proved that the Glauber dynamics has $O(n\\log{n})$ mixing time\nwhen $k>2\\Delta$. Fischer and Ghaffari (2018), and independently Feng, Hayes,\nand Yin (2018), presented a parallel and distributed version of the Glauber\ndynamics which converges in $O(\\log{n})$ rounds for $k>(2+\\varepsilon)\\Delta$\nfor any $\\varepsilon>0$. We improve this result to $k>(11/6-\\delta)\\Delta$ for\na fixed $\\delta>0$. This matches the state of the art for randomly sampling\ncolorings of general graphs in the sequential setting. Whereas previous works\nfocused on distributed variants of the Glauber dynamics, our work presents a\nparallel and distributed version of the more general flip dynamics presented by\nVigoda (2000) (and refined by Chen, Delcourt, Moitra, Perarnau, and Postle\n(2019)), which recolors local maximal two-colored components in each step.",
            "author": [
                "Charlie Carlson",
                "Daniel Frishberg",
                "Eric Vigoda"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07859v1",
                "http://arxiv.org/pdf/2309.07859v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07856v1",
            "title": "SMARTFEAT: Efficient Feature Construction through Feature-Level\n  Foundation Model Interactions",
            "updated": "2023-09-14T17:00:53Z",
            "published": "2023-09-14T17:00:53Z",
            "summary": "Before applying data analytics or machine learning to a data set, a vital\nstep is usually the construction of an informative set of features from the\ndata. In this paper, we present SMARTFEAT, an efficient automated feature\nengineering tool to assist data users, even non-experts, in constructing useful\nfeatures. Leveraging the power of Foundation Models (FMs), our approach enables\nthe creation of new features from the data, based on contextual information and\nopen-world knowledge. To achieve this, our method incorporates an intelligent\noperator selector that discerns a subset of operators, effectively avoiding\nexhaustive combinations of original features, as is typically observed in\ntraditional automated feature engineering tools. Moreover, we address the\nlimitations of performing data tasks through row-level interactions with FMs,\nwhich could lead to significant delays and costs due to excessive API calls. To\ntackle this, we introduce a function generator that facilitates the acquisition\nof efficient data transformations, such as dataframe built-in methods or lambda\nfunctions, ensuring the applicability of SMARTFEAT to generate new features for\nlarge datasets. With SMARTFEAT, dataset users can efficiently search for and\napply transformations to obtain new features, leading to improvements in the\nAUC of downstream ML classification by up to 29.8%.",
            "author": [
                "Yin Lin",
                "Bolin Ding",
                "H. V. Jagadish",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07856v1",
                "http://arxiv.org/pdf/2309.07856v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07851v3",
            "title": "The mass of simple and higher-order networks",
            "updated": "2023-11-22T17:08:40Z",
            "published": "2023-09-14T16:52:01Z",
            "summary": "We propose a theoretical framework that explains how the mass of simple and\nhigher-order networks emerges from their topology and geometry. We use the\ndiscrete topological Dirac operator to define an action for a massless\nself-interacting topological Dirac field inspired by the Nambu-Jona Lasinio\nmodel. The mass of the network is strictly speaking the mass of this\ntopological Dirac field defined on the network; it results from the chiral\nsymmetry breaking of the model and satisfies a self-consistent gap equation.\nInterestingly, it is shown that the mass of a network depends on its spectral\nproperties, topology, and geometry. Due to the breaking of the\nmatter-antimatter symmetry observed for the harmonic modes of the discrete\ntopological Dirac operator, two possible definitions of the network mass can be\ngiven. For both possible definitions, the mass of the network comes from a gap\nequation with the difference among the two definitions encoded in the value of\nthe bare mass. Indeed, the bare mass can be determined either by the Betti\nnumber $\\beta_0$ or by the Betti number $\\beta_1$ of the network. We provide\nnumerical results on the mass of different networks, including random graphs,\nscale-free, and real weighted collaboration networks. We also discuss the\ngeneralization of these results to higher-order networks, defining the mass of\nsimplicial complexes. The observed dependence of the mass of the considered\ntopological Dirac field with the topology and geometry of the network could\nlead to interesting physics in the scenario in which the considered Dirac field\nis coupled with a dynamical evolution of the underlying network structure.",
            "author": [
                "Ginestra Bianconi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07851v3",
                "http://arxiv.org/pdf/2309.07851v3"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "gr-qc",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07813v1",
            "title": "Directed Scattering for Knowledge Graph-based Cellular Signaling\n  Analysis",
            "updated": "2023-09-14T15:59:23Z",
            "published": "2023-09-14T15:59:23Z",
            "summary": "Directed graphs are a natural model for many phenomena, in particular\nscientific knowledge graphs such as molecular interaction or chemical reaction\nnetworks that define cellular signaling relationships. In these situations,\nsource nodes typically have distinct biophysical properties from sinks. Due to\ntheir ordered and unidirectional relationships, many such networks also have\nhierarchical and multiscale structure. However, the majority of methods\nperforming node- and edge-level tasks in machine learning do not take these\nproperties into account, and thus have not been leveraged effectively for\nscientific tasks such as cellular signaling network inference. We propose a new\nframework called Directed Scattering Autoencoder (DSAE) which uses a directed\nversion of a geometric scattering transform, combined with the non-linear\ndimensionality reduction properties of an autoencoder and the geometric\nproperties of the hyperbolic space to learn latent hierarchies. We show this\nmethod outperforms numerous others on tasks such as embedding directed graphs\nand learning cellular signaling networks.",
            "author": [
                "Aarthi Venkat",
                "Joyce Chew",
                "Ferran Cardoso Rodriguez",
                "Christopher J. Tape",
                "Michael Perlmutter",
                "Smita Krishnaswamy"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07813v1",
                "http://arxiv.org/pdf/2309.07813v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.CB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07804v1",
            "title": "Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API\n  Names?",
            "updated": "2023-09-14T15:46:41Z",
            "published": "2023-09-14T15:46:41Z",
            "summary": "Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex,\nhave shown their superior performance in various downstream tasks. The\ncorrectness and unambiguity of API usage among these code models are crucial\nfor achieving desirable program functionalities, requiring them to learn\nvarious API fully qualified names structurally and semantically. Recent studies\nreveal that even state-of-the-art pre-trained code models struggle with\nsuggesting the correct APIs during code generation. However, the reasons for\nsuch poor API usage performance are barely investigated. To address this\nchallenge, we propose using knowledge probing as a means of interpreting code\nmodels, which uses cloze-style tests to measure the knowledge stored in models.\nOur comprehensive study examines a code model's capability of understanding API\nfully qualified names from two different perspectives: API call and API import.\nSpecifically, we reveal that current code models struggle with understanding\nAPI names, with pre-training strategies significantly affecting the quality of\nAPI name learning. We demonstrate that natural language context can assist code\nmodels in locating Python API names and generalize Python API name knowledge to\nunseen data. Our findings provide insights into the limitations and\ncapabilities of current pre-trained code models, and suggest that incorporating\nAPI structure into the pre-training process can improve automated API usage and\ncode representations. This work provides significance for advancing code\nintelligence practices and direction for future studies. All experiment\nresults, data and source code used in this work are available at\n\\url{https://doi.org/10.5281/zenodo.7902072}.",
            "author": [
                "Terry Yue Zhuo",
                "Xiaoning Du",
                "Zhenchang Xing",
                "Jiamou Sun",
                "Haowei Quan",
                "Li Li",
                "Liming Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07804v1",
                "http://arxiv.org/pdf/2309.07804v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07803v1",
            "title": "SnakeGAN: A Universal Vocoder Leveraging DDSP Prior Knowledge and\n  Periodic Inductive Bias",
            "updated": "2023-09-14T15:46:39Z",
            "published": "2023-09-14T15:46:39Z",
            "summary": "Generative adversarial network (GAN)-based neural vocoders have been widely\nused in audio synthesis tasks due to their high generation quality, efficient\ninference, and small computation footprint. However, it is still challenging to\ntrain a universal vocoder which can generalize well to out-of-domain (OOD)\nscenarios, such as unseen speaking styles, non-speech vocalization, singing,\nand musical pieces. In this work, we propose SnakeGAN, a GAN-based universal\nvocoder, which can synthesize high-fidelity audio in various OOD scenarios.\nSnakeGAN takes a coarse-grained signal generated by a differentiable digital\nsignal processing (DDSP) model as prior knowledge, aiming at recovering\nhigh-fidelity waveform from a Mel-spectrogram. We introduce periodic\nnonlinearities through the Snake activation function and anti-aliased\nrepresentation into the generator, which further brings the desired inductive\nbias for audio synthesis and significantly improves the extrapolation capacity\nfor universal vocoding in unseen scenarios. To validate the effectiveness of\nour proposed method, we train SnakeGAN with only speech data and evaluate its\nperformance for various OOD distributions with both subjective and objective\nmetrics. Experimental results show that SnakeGAN significantly outperforms the\ncompared approaches and can generate high-fidelity audio samples including\nunseen speakers with unseen styles, singing voices, instrumental pieces, and\nnonverbal vocalization.",
            "author": [
                "Sipan Li",
                "Songxiang Liu",
                "Luwen Zhang",
                "Xiang Li",
                "Yanyao Bian",
                "Chao Weng",
                "Zhiyong Wu",
                "Helen Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07803v1",
                "http://arxiv.org/pdf/2309.07803v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07947v1",
            "title": "TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging\n  Analysis",
            "updated": "2023-09-14T15:17:42Z",
            "published": "2023-09-14T15:17:42Z",
            "summary": "In recent years, functional magnetic resonance imaging has emerged as a\npowerful tool for investigating the human brain's functional connectivity\nnetworks. Related studies demonstrate that functional connectivity networks in\nthe human brain can help to improve the efficiency of diagnosing neurological\ndisorders. However, there still exist two challenges that limit the progress of\nfunctional neuroimaging. Firstly, there exists an abundance of noise and\nredundant information in functional connectivity data, resulting in poor\nperformance. Secondly, existing brain network models have tended to prioritize\neither classification performance or the interpretation of neuroscience\nfindings behind the learned models. To deal with these challenges, this paper\nproposes a novel brain graph learning framework called Template-induced Brain\nGraph Learning (TiBGL), which has both discriminative and interpretable\nabilities. Motivated by the related medical findings on functional\nconnectivites, TiBGL proposes template-induced brain graph learning to extract\ntemplate brain graphs for all groups. The template graph can be regarded as an\naugmentation process on brain networks that removes noise information and\nhighlights important connectivity patterns. To simultaneously support the tasks\nof discrimination and interpretation, TiBGL further develops template-induced\nconvolutional neural network and template-induced brain interpretation\nanalysis. Especially, the former fuses rich information from brain graphs and\ntemplate brain graphs for brain disorder tasks, and the latter can provide\ninsightful connectivity patterns related to brain disorders based on template\nbrain graphs. Experimental results on three real-world datasets show that the\nproposed TiBGL can achieve superior performance compared with nine\nstate-of-the-art methods and keep coherent with neuroscience findings in recent\nliteratures.",
            "author": [
                "Xiangzhu Meng",
                "Wei Wei",
                "Qiang Liu",
                "Shu Wu",
                "Liang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07947v1",
                "http://arxiv.org/pdf/2309.07947v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07783v2",
            "title": "On the Assouad spectrum of H\u00f6lder and Sobolev graphs",
            "updated": "2023-10-02T00:11:34Z",
            "published": "2023-09-14T15:16:50Z",
            "summary": "We provide upper bounds for the Assouad spectrum\n$\\dim_A^\\theta(\\text{Gr}(f))$ of the graph of a real-valued H\\\"older or Sobolev\nfunction $f$ defined on an interval $I \\subset \\mathbb{R}$. We demonstrate via\nexamples that all of our bounds are sharp. In the setting of H\\\"older graphs,\nwe further provide a geometric algorithm which takes as input the graph of an\n$\\alpha$-H\\\"older continuous function satisfying a matching lower oscillation\ncondition with exponent $\\alpha$ and returns the graph of a new\n$\\alpha$-H\\\"older continuous function for which the Assouad $\\theta$-spectrum\nrealizes the stated upper bound for all $\\theta\\in (0,1)$. Examples of\nfunctions to which this algorithm applies include the continuous nowhere\ndifferentiable functions of Weierstrass and Takagi.",
            "author": [
                "Efstathios Konstantinos Chrontsios Garitsis",
                "Jeremy T. Tyson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07783v2",
                "http://arxiv.org/pdf/2309.07783v2"
            ],
            "primary_category": "math.CA",
            "category": [
                "math.CA",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07781v2",
            "title": "A Deductive Verification Infrastructure for Probabilistic Programs\n  (Extended Version)",
            "updated": "2023-11-15T12:38:01Z",
            "published": "2023-09-14T15:12:39Z",
            "summary": "This paper presents a quantitative program verification infrastructure for\ndiscrete probabilistic programs. Our infrastructure can be viewed as the\nprobabilistic analogue of Boogie: its central components are an intermediate\nverification language (IVL) together with a real-valued logic. Our IVL provides\na programming-language-style for expressing verification conditions whose\nvalidity implies the correctness of a program under investigation. As our focus\nis on verifying quantitative properties such as bounds on expected outcomes,\nexpected run-times, or termination probabilities, off-the-shelf IVLs based on\nBoolean first-order logic do not suffice. Instead, a paradigm shift from the\nstandard Boolean to a real-valued domain is required.\n  Our IVL features quantitative generalizations of standard verification\nconstructs such as assume- and assert-statements. Verification conditions are\ngenerated by a weakest-precondition-style semantics, based on our real-valued\nlogic. We show that our verification infrastructure supports natural encodings\nof numerous verification techniques from the literature. With our SMT-based\nimplementation, we automatically verify a variety of benchmarks. To the best of\nour knowledge, this establishes the first deductive verification infrastructure\nfor expectation-based reasoning about probabilistic programs.",
            "author": [
                "Philipp Schr\u00f6er",
                "Kevin Batz",
                "Benjamin Lucien Kaminski",
                "Joost-Pieter Katoen",
                "Christoph Matheja"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3622870",
                "http://arxiv.org/abs/2309.07781v2",
                "http://arxiv.org/pdf/2309.07781v2"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07774v2",
            "title": "Almost sure one-endedness of a random graph model of distributed ledgers",
            "updated": "2023-09-18T15:32:56Z",
            "published": "2023-09-14T15:03:50Z",
            "summary": "Blockchain and other decentralized databases, known as distributed ledgers,\nare designed to store information online where all trusted network members can\nupdate the data with transparency. The dynamics of ledger's development can be\nmathematically represented by a directed acyclic graph (DAG). One essential\nproperty of a properly functioning shared ledger is that all network members\nholding a copy of the ledger agree on a sequence of information added to the\nledger, which is referred to as consensus and is known to be related to a\nstructural property of DAG called one-endedness. In this paper, we consider a\nmodel of distributed ledger with sequential stochastic arrivals that mimic\nattachment rules from the IOTA cryptocurrency. We first prove that the number\nof leaves in the random DAG is bounded by a constant infinitely often through\nthe identification of a suitable martingale, and then prove that a sequence of\nspecific events happens infinitely often. Combining those results we establish\nthat, as time goes to infinity, the IOTA DAG is almost surely one-ended.",
            "author": [
                "Jiewei Feng",
                "Christopher King",
                "Ken R. Duffy"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07774v2",
                "http://arxiv.org/pdf/2309.07774v2"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07760v2",
            "title": "PRE: Vision-Language Prompt Learning with Reparameterization Encoder",
            "updated": "2023-11-06T12:18:25Z",
            "published": "2023-09-14T14:48:01Z",
            "summary": "Large pre-trained vision-language models such as CLIP have demonstrated great\npotential in zero-shot transferability to downstream tasks. However, to attain\noptimal performance, the manual selection of prompts is necessary to improve\nalignment between the downstream image distribution and the textual class\ndescriptions. This manual prompt engineering is the major challenge for\ndeploying such models in practice since it requires domain expertise and is\nextremely time-consuming. To avoid non-trivial prompt engineering, recent work\nContext Optimization (CoOp) introduced the concept of prompt learning to the\nvision domain using learnable textual tokens. While CoOp can achieve\nsubstantial improvements over manual prompts, its learned context is worse\ngeneralizable to wider unseen classes within the same dataset. In this work, we\npresent Prompt Learning with Reparameterization Encoder (PRE) - a simple and\nefficient method that enhances the generalization ability of the learnable\nprompt to unseen classes while maintaining the capacity to learn Base classes.\nInstead of directly optimizing the prompts, PRE employs a prompt encoder to\nreparameterize the input prompt embeddings, enhancing the exploration of\ntask-specific knowledge from few-shot samples. Experiments and extensive\nablation studies on 8 benchmarks demonstrate that our approach is an efficient\nmethod for prompt learning. Specifically, PRE achieves a notable enhancement of\n5.60% in average accuracy on New classes and 3% in Harmonic mean compared to\nCoOp in the 16-shot setting, all achieved within a good training time.",
            "author": [
                "Anh Pham Thi Minh",
                "An Duc Nguyen",
                "Georgios Tzimiropoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07760v2",
                "http://arxiv.org/pdf/2309.07760v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.4.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07754v1",
            "title": "Dynamic programming on bipartite tree decompositions",
            "updated": "2023-09-14T14:39:12Z",
            "published": "2023-09-14T14:39:12Z",
            "summary": "We revisit a graph width parameter that we dub bipartite treewidth, along\nwith its associated graph decomposition that we call bipartite tree\ndecomposition. Bipartite treewidth can be seen as a common generalization of\ntreewidth and the odd cycle transversal number. Intuitively, a bipartite tree\ndecomposition is a tree decomposition whose bags induce almost bipartite graphs\nand whose adhesions contain at most one vertex from the bipartite part of any\nother bag, while the width of such decomposition measures how far the bags are\nfrom being bipartite. Adapted from a tree decomposition originally defined by\nDemaine, Hajiaghayi, and Kawarabayashi [SODA 2010] and explicitly defined by\nTazari [Th. Comp. Sci. 2012], bipartite treewidth appears to play a crucial\nrole for solving problems related to odd-minors, which have recently attracted\nconsiderable attention. As a first step toward a theory for solving these\nproblems efficiently, the main goal of this paper is to develop dynamic\nprogramming techniques to solve problems on graphs of small bipartite\ntreewidth. For such graphs, we provide a number of para-NP-completeness\nresults, FPT-algorithms, and XP-algorithms, as well as several open problems.\nIn particular, we show that $K_t$-Subgraph-Cover, Weighted Vertex\nCover/Independent Set, Odd Cycle Transversal, and Maximum Weighted Cut are\n$FPT$ parameterized by bipartite treewidth. We provide the following complexity\ndichotomy when $H$ is a 2-connected graph, for each of $H$-Subgraph-Packing,\n$H$-Induced-Packing, $H$-Scattered-Packing, and $H$-Odd-Minor-Packing problem:\nif $H$ is bipartite, then the problem is para-NP-complete parameterized by\nbipartite treewidth while, if $H$ is non-bipartite, then it is solvable in\nXP-time. We define 1-${\\cal H}$-treewidth by replacing the bipartite graph\nclass by any class ${\\cal H}$. Most of the technology developed here works for\nthis more general parameter.",
            "author": [
                "Lars Jaffke",
                "Laure Morelle",
                "Ignasi Sau",
                "Dimitrios M. Thilikos"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07754v1",
                "http://arxiv.org/pdf/2309.07754v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "05C85, 68R10, 05C75, 05C83, 05C75, 05C69",
                "F.2.2; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07744v1",
            "title": "Random Tur\u00e1n and counting results for general position sets over\n  finite fields",
            "updated": "2023-09-14T14:30:47Z",
            "published": "2023-09-14T14:30:47Z",
            "summary": "Let $\\alpha(\\mathbb{F}_q^d,p)$ denote the maximum size of a general position\nset in a $p$-random subset of $\\mathbb{F}_q^d$. We determine the order of\nmagnitude of $\\alpha(\\mathbb{F}_q^2,p)$ up to polylogarithmic factors for all\npossible values of $p$, improving the previous best upper bounds obtained by\nRoche-Newton--Warren and Bhowmick--Roche-Newton. For $d \\ge 3$ we prove upper\nbounds for $\\alpha(\\mathbb{F}_q^d,p)$ that are essentially tight within certain\nintervals of $p$.\n  We establish the upper bound $2^{(1+o(1))q}$ for the number of general\nposition sets in $\\mathbb{F}_q^d$, which matches the trivial lower bound\n$2^{q}$ asymptotically in exponent. We also refine this counting result by\nproving an asymptotically tight (in exponent) upper bound for the number of\ngeneral position sets with fixed size. The latter result for $d=2$ improves a\nresult of Roche-Newton--Warren.\n  Our proofs are grounded in the hypergraph container method, and additionally,\nfor $d=2$ we also leverage the pseudorandomness of the point-line incidence\nbipartite graph of $\\mathbb{F}_{q}^2$.",
            "author": [
                "Yaobin Chen",
                "Xizhi Liu",
                "Jiaxi Nie",
                "Ji Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07744v1",
                "http://arxiv.org/pdf/2309.07744v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C65, 05D40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08636v3",
            "title": "ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI\n  chatbots at scientific writing?",
            "updated": "2023-10-16T14:24:02Z",
            "published": "2023-09-14T14:04:03Z",
            "summary": "Historical emphasis on writing mastery has shifted with advances in\ngenerative AI, especially in scientific writing. This study analysed six AI\nchatbots for scholarly writing in humanities and archaeology. Using methods\nthat assessed factual correctness and scientific contribution, ChatGPT-4 showed\nthe highest quantitative accuracy, closely followed by ChatGPT-3.5, Bing, and\nBard. However, Claude 2 and Aria scored considerably lower. Qualitatively, all\nAIs exhibited proficiency in merging existing knowledge, but none produced\noriginal scientific content. Inter-estingly, our findings suggest ChatGPT-4\nmight represent a plateau in large language model size. This research\nemphasizes the unique, intricate nature of human research, suggesting that AI's\nemulation of human originality in scientific writing is challenging. As of\n2023, while AI has transformed content generation, it struggles with original\ncontributions in humanities. This may change as AI chatbots continue to evolve\ninto LLM-powered software.",
            "author": [
                "Edisa Lozi\u0107",
                "Benjamin \u0160tular"
            ],
            "link": [
                "http://dx.doi.org/10.3390/fi15100336",
                "http://arxiv.org/abs/2309.08636v3",
                "http://arxiv.org/pdf/2309.08636v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.ET",
                "cs.HC",
                "68T01",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07726v1",
            "title": "GRID: Scene-Graph-based Instruction-driven Robotic Task Planning",
            "updated": "2023-09-14T14:02:56Z",
            "published": "2023-09-14T14:02:56Z",
            "summary": "Recent works have shown that Large Language Models (LLMs) can promote\ngrounding instructions to robotic task planning. Despite the progress, most\nexisting works focused on utilizing raw images to help LLMs understand\nenvironmental information, which not only limits the observation scope but also\ntypically requires massive multimodal data collection and large-scale models.\nIn this paper, we propose a novel approach called Graph-based Robotic\nInstruction Decomposer (GRID), leverages scene graph instead of image to\nperceive global scene information and continuously plans subtask in each stage\nfor a given instruction. Our method encodes object attributes and relationships\nin graphs through an LLM and Graph Attention Networks, integrating instruction\nfeatures to predict subtasks consisting of pre-defined robot actions and target\nobjects in the scene graph. This strategy enables robots to acquire semantic\nknowledge widely observed in the environment from the scene graph. To train and\nevaluate GRID, we build a dataset construction pipeline to generate synthetic\ndatasets in graph-based robotic task planning. Experiments have shown that our\nmethod outperforms GPT-4 by over 25.4% in subtask accuracy and 43.6% in task\naccuracy. Experiments conducted on datasets of unseen scenes and scenes with\ndifferent numbers of objects showed that the task accuracy of GRID declined by\nat most 3.8%, which demonstrates its good cross-scene generalization ability.\nWe validate our method in both physical simulation and the real world.",
            "author": [
                "Zhe Ni",
                "Xiao-Xin Deng",
                "Cong Tai",
                "Xin-Yue Zhu",
                "Xiang Wu",
                "Yong-Jin Liu",
                "Long Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07726v1",
                "http://arxiv.org/pdf/2309.07726v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07708v1",
            "title": "Market-GAN: Adding Control to Financial Market Data Generation with\n  Semantic Context",
            "updated": "2023-09-14T13:42:27Z",
            "published": "2023-09-14T13:42:27Z",
            "summary": "Financial simulators play an important role in enhancing forecasting\naccuracy, managing risks, and fostering strategic financial decision-making.\nDespite the development of financial market simulation methodologies, existing\nframeworks often struggle with adapting to specialized simulation context. We\npinpoint the challenges as i) current financial datasets do not contain context\nlabels; ii) current techniques are not designed to generate financial data with\ncontext as control, which demands greater precision compared to other\nmodalities; iii) the inherent difficulties in generating context-aligned,\nhigh-fidelity data given the non-stationary, noisy nature of financial data. To\naddress these challenges, our contributions are: i) we proposed the Contextual\nMarket Dataset with market dynamics, stock ticker, and history state as\ncontext, leveraging a market dynamics modeling method that combines linear\nregression and Dynamic Time Warping clustering to extract market dynamics; ii)\nwe present Market-GAN, a novel architecture incorporating a Generative\nAdversarial Networks (GAN) for the controllable generation with context, an\nautoencoder for learning low-dimension features, and supervisors for knowledge\ntransfer; iii) we introduce a two-stage training scheme to ensure that\nMarket-GAN captures the intrinsic market distribution with multiple objectives.\nIn the pertaining stage, with the use of the autoencoder and supervisors, we\nprepare the generator with a better initialization for the adversarial training\nstage. We propose a set of holistic evaluation metrics that consider alignment,\nfidelity, data usability on downstream tasks, and market facts. We evaluate\nMarket-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and\nshowcase superior performance in comparison to 4 state-of-the-art time-series\ngenerative models.",
            "author": [
                "Haochong Xia",
                "Shuo Sun",
                "Xinrun Wang",
                "Bo An"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07708v1",
                "http://arxiv.org/pdf/2309.07708v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07707v1",
            "title": "CoLLD: Contrastive Layer-to-layer Distillation for Compressing\n  Multilingual Pre-trained Speech Encoders",
            "updated": "2023-09-14T13:38:02Z",
            "published": "2023-09-14T13:38:02Z",
            "summary": "Large-scale self-supervised pre-trained speech encoders outperform\nconventional approaches in speech recognition and translation tasks. Due to the\nhigh cost of developing these large models, building new encoders for new tasks\nand deploying them to on-device applications are infeasible. Prior studies\npropose model compression methods to address this issue, but those works focus\non smaller models and less realistic tasks. Thus, we propose Contrastive\nLayer-to-layer Distillation (CoLLD), a novel knowledge distillation method to\ncompress pre-trained speech encoders by leveraging masked prediction and\ncontrastive learning to train student models to copy the behavior of a large\nteacher model. CoLLD outperforms prior methods and closes the gap between small\nand large models on multilingual speech-to-text translation and recognition\nbenchmarks.",
            "author": [
                "Heng-Jui Chang",
                "Ning Dong",
                "Ruslan Mavlyutov",
                "Sravya Popuri",
                "Yu-An Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07707v1",
                "http://arxiv.org/pdf/2309.07707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07698v1",
            "title": "Dataset Condensation via Generative Model",
            "updated": "2023-09-14T13:17:02Z",
            "published": "2023-09-14T13:17:02Z",
            "summary": "Dataset condensation aims to condense a large dataset with a lot of training\nsamples into a small set. Previous methods usually condense the dataset into\nthe pixels format. However, it suffers from slow optimization speed and large\nnumber of parameters to be optimized. When increasing image resolutions and\nclasses, the number of learnable parameters grows accordingly, prohibiting\ncondensation methods from scaling up to large datasets with diverse classes.\nMoreover, the relations among condensed samples have been neglected and hence\nthe feature distribution of condensed samples is often not diverse. To solve\nthese problems, we propose to condense the dataset into another format, a\ngenerative model. Such a novel format allows for the condensation of large\ndatasets because the size of the generative model remains relatively stable as\nthe number of classes or image resolution increases. Furthermore, an\nintra-class and an inter-class loss are proposed to model the relation of\ncondensed samples. Intra-class loss aims to create more diverse samples for\neach class by pushing each sample away from the others of the same class.\nMeanwhile, inter-class loss increases the discriminability of samples by\nwidening the gap between the centers of different classes. Extensive\ncomparisons with state-of-the-art methods and our ablation studies confirm the\neffectiveness of our method and its individual component. To our best\nknowledge, we are the first to successfully conduct condensation on\nImageNet-1k.",
            "author": [
                "David Junhao Zhang",
                "Heng Wang",
                "Chuhui Xue",
                "Rui Yan",
                "Wenqing Zhang",
                "Song Bai",
                "Mike Zheng Shou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07698v1",
                "http://arxiv.org/pdf/2309.07698v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07687v1",
            "title": "$\\texttt{ChisholmD.wl}$- Automated rational approximant for bi-variate\n  series",
            "updated": "2023-09-14T13:03:24Z",
            "published": "2023-09-14T13:03:24Z",
            "summary": "The Chisholm rational approximant is a natural generalization to two\nvariables of the well-known single variable Pad\\'e approximant, and has the\nadvantage of reducing to the latter when one of the variables is set equals to\n0. We present, to our knowledge, the first automated Mathematica package to\nevaluate diagonal Chisholm approximants of two variable series. For the moment,\nthe package can only be used to evaluate diagonal approximants i.e. the maximum\npowers of both the variables, in both the numerator and the denominator, is\nequal to some integer $M$. We further modify the original method so as to allow\nus to evaluate the approximants around some general point $(x,y)$ not\nnecessarily $(0,0)$. Using the approximants around general point $(x,y)$,\nallows us to get a better estimate of the result when the point of evaluation\nis far from $(0,0)$. Several examples of the elementary functions have been\nstudied which shows that the approximants can be useful for analytic\ncontinuation and convergence acceleration purposes. We continue our study using\nvarious examples of two variable hypergeometric series,\n$\\mathrm{Li}_{2,2}(x,y)$ etc that arise in particle physics and in the study of\ncritical phenomena in condensed matter physics. The demonstration of the\npackage is discussed in detail and the Mathematica package is provided as an\nancillary file.",
            "author": [
                "Souvik Bera",
                "Tanay Pathak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07687v1",
                "http://arxiv.org/pdf/2309.07687v1"
            ],
            "primary_category": "cs.MS",
            "category": [
                "cs.MS",
                "cs.NA",
                "hep-ph",
                "math-ph",
                "math.MP",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07682v1",
            "title": "A Conversation is Worth A Thousand Recommendations: A Survey of Holistic\n  Conversational Recommender Systems",
            "updated": "2023-09-14T12:55:23Z",
            "published": "2023-09-14T12:55:23Z",
            "summary": "Conversational recommender systems (CRS) generate recommendations through an\ninteractive process. However, not all CRS approaches use human conversations as\ntheir source of interaction data; the majority of prior CRS work simulates\ninteractions by exchanging entity-level information. As a result, claims of\nprior CRS work do not generalise to real-world settings where conversations\ntake unexpected turns, or where conversational and intent understanding is not\nperfect. To tackle this challenge, the research community has started to\nexamine holistic CRS, which are trained using conversational data collected\nfrom real-world scenarios. Despite their emergence, such holistic approaches\nare under-explored.\n  We present a comprehensive survey of holistic CRS methods by summarizing the\nliterature in a structured manner. Our survey recognises holistic CRS\napproaches as having three components: 1) a backbone language model, the\noptional use of 2) external knowledge, and/or 3) external guidance. We also\ngive a detailed analysis of CRS datasets and evaluation methods in real\napplication scenarios. We offer our insight as to the current challenges of\nholistic CRS and possible future trends.",
            "author": [
                "Chuang Li",
                "Hengchang Hu",
                "Yan Zhang",
                "Min-Yen Kan",
                "Haizhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07682v1",
                "http://arxiv.org/pdf/2309.07682v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07681v1",
            "title": "A review of the degradation mechanisms of NCM cathodes and corresponding\n  mitigation strategies",
            "updated": "2023-09-14T12:48:25Z",
            "published": "2023-09-14T12:48:25Z",
            "summary": "Li-ion batteries (LIBs) are the most widely used form of energy storage in\nmobile electronic devices and electric vehicles. Li-ion battery cathodes with\nthe composition LiNixMnyCozO2 (NCMs) currently display some of the most\npromising electrochemical characteristics for high performance LIBs. NCM\ncompositions with high nickel content (x > 0.8) exhibit the largest specific\ncapacity while undergoing fast degradation and presenting safety issues. As the\nmain degradation mechanisms of NCM materials and the mitigation of their\ndegradation, are still subjects of many ongoing studies, this work summarizes\nthe current knowledge on the subject. Here, the existing literature is reviewed\nto present the structural and electrochemical degradation of NCM with varying\nNi stoichiometries (NCM111, NCM622, NCM811, and beyond). Routes for hindering\nthe degradation of NCM are discussed as a function of Ni content in NCM and\ninclude doping, application of protective coatings, and engineering of the\nmicrostructure. A comprehensive understanding of the main degradation pathways\nof NCM is key to applying the most appropriate mitigation strategies and keep\nadvancing towards higher energy NCM materials with longer cycle-life.",
            "author": [
                "Liga Britala",
                "Mario Marinaro",
                "Gints Kucinskis"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.est.2023.108875",
                "http://arxiv.org/abs/2309.07681v1",
                "http://arxiv.org/pdf/2309.07681v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07680v2",
            "title": "Inhomogeneous order 1 iterative functional equations with applications\n  to combinatorics",
            "updated": "2023-11-30T20:16:20Z",
            "published": "2023-09-14T12:46:32Z",
            "summary": "We show that if a Laurent series $f\\in\\mathbb{C}((t))$ satisfies a particular\nkind of linear iterative equation, then $f$ is either a rational function or it\nis differentially transcendental over $\\mathbb{C}(t)$. This condition is more\nprecisely stated as follows: We consider $R,b\\in \\mathbb{C}(t)$ with $R(0)=0$,\nsuch that $f(R(t))=f(t)+b(t)$. If either $R'(0)=0$ or $R'(0)$ is a root of\nunity, then either $f$ is a rational function, or $f$ does not satisfy a\npolynomial differential equation. More generally a solution of a functional\nequation of the form $f(R(t))=a(t)f(t)+b(t)$ will be either differentially\ntrascendental or the solution of an inhomogeneous linear differential equation\nof order $1$ with rational coefficients.\n  We illustrate how to apply these results to deduce the differential\ntranscendence of combinatorial generating functions by considering three\nexamples: the ordinary generating function for a family of complete trees; the\nGreen function for excursions on the Sierpinski graph; and a series related to\nthe enumeration of permutations avoiding the consecutive pattern 1423.\n  The proof strategy is inspired by the Galois theory of functional equations\nand relies on the property of the dynamics of $R$.",
            "author": [
                "Lucia Di Vizio",
                "Gwladys Fernandes",
                "Marni Mishna"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07680v2",
                "http://arxiv.org/pdf/2309.07680v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.NT",
                "12H05, 05A15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07675v2",
            "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via\n  Set-Based Reachability Analysis",
            "updated": "2023-11-22T10:24:26Z",
            "published": "2023-09-14T12:39:26Z",
            "summary": "Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this paper, we propose a\ndevelopmental mechanism for goal discovery via an emergent representation that\nabstracts (i.e., groups together) sets of environment states that have similar\nroles in the task. We introduce a Feudal HRL algorithm that concurrently learns\nboth the goal representation and a hierarchical policy. The algorithm uses\nsymbolic reachability analysis for neural networks to approximate the\ntransition relation among sets of states and to refine the goal representation.\nWe evaluate our approach on complex navigation tasks, showing the learned\nrepresentation is interpretable, transferrable and results in data efficient\nlearning.",
            "author": [
                "Mehdi Zadem",
                "Sergio Mover",
                "Sao Mai Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07675v2",
                "http://arxiv.org/pdf/2309.07675v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "K.3.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07672v1",
            "title": "Physics-constrained robust learning of open-form PDEs from limited and\n  noisy data",
            "updated": "2023-09-14T12:34:42Z",
            "published": "2023-09-14T12:34:42Z",
            "summary": "Unveiling the underlying governing equations of nonlinear dynamic systems\nremains a significant challenge, especially when encountering noisy\nobservations and no prior knowledge available. This study proposes R-DISCOVER,\na framework designed to robustly uncover open-form partial differential\nequations (PDEs) from limited and noisy data. The framework operates through\ntwo alternating update processes: discovering and embedding. The discovering\nphase employs symbolic representation and a reinforcement learning (RL)-guided\nhybrid PDE generator to efficiently produce diverse open-form PDEs with tree\nstructures. A neural network-based predictive model fits the system response\nand serves as the reward evaluator for the generated PDEs. PDEs with superior\nfits are utilized to iteratively optimize the generator via the RL method and\nthe best-performing PDE is selected by a parameter-free stability metric. The\nembedding phase integrates the initially identified PDE from the discovering\nprocess as a physical constraint into the predictive model for robust training.\nThe traversal of PDE trees automates the construction of the computational\ngraph and the embedding process without human intervention. Numerical\nexperiments demonstrate our framework's capability to uncover governing\nequations from nonlinear dynamic systems with limited and highly noisy data and\noutperform other physics-informed neural network-based discovery methods. This\nwork opens new potential for exploring real-world systems with limited\nunderstanding.",
            "author": [
                "Mengge Du",
                "Longfeng Nie",
                "Siyu Lou",
                "Yuntian Chenc",
                "Dongxiao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07672v1",
                "http://arxiv.org/pdf/2309.07672v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07668v1",
            "title": "CoRF : Colorizing Radiance Fields using Knowledge Distillation",
            "updated": "2023-09-14T12:30:48Z",
            "published": "2023-09-14T12:30:48Z",
            "summary": "Neural radiance field (NeRF) based methods enable high-quality novel-view\nsynthesis for multi-view images. This work presents a method for synthesizing\ncolorized novel views from input grey-scale multi-view images. When we apply\nimage or video-based colorization methods on the generated grey-scale novel\nviews, we observe artifacts due to inconsistency across views. Training a\nradiance field network on the colorized grey-scale image sequence also does not\nsolve the 3D consistency issue. We propose a distillation based method to\ntransfer color knowledge from the colorization networks trained on natural\nimages to the radiance field network. Specifically, our method uses the\nradiance field network as a 3D representation and transfers knowledge from\nexisting 2D colorization methods. The experimental results demonstrate that the\nproposed method produces superior colorized novel views for indoor and outdoor\nscenes while maintaining cross-view consistency than baselines. Further, we\nshow the efficacy of our method on applications like colorization of radiance\nfield network trained from 1.) Infra-Red (IR) multi-view images and 2.) Old\ngrey-scale multi-view image sequences.",
            "author": [
                "Ankit Dhiman",
                "R Srinath",
                "Srinjay Sarkar",
                "Lokesh R Boregowda",
                "R Venkatesh Babu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07668v1",
                "http://arxiv.org/pdf/2309.07668v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07623v1",
            "title": "SwitchGPT: Adapting Large Language Models for Non-Text Outputs",
            "updated": "2023-09-14T11:38:23Z",
            "published": "2023-09-14T11:38:23Z",
            "summary": "Large Language Models (LLMs), primarily trained on text-based datasets,\nexhibit exceptional proficiencies in understanding and executing complex\nlinguistic instructions via text outputs. However, they falter when requests to\ngenerate non-text ones. Concurrently, modality conversion models, such as\ntext-to-image, despite generating high-quality images, suffer from a lack of\nextensive textual pretraining. As a result, these models are only capable of\naccommodating specific image descriptions rather than comprehending more\ncomplex instructions. To bridge this gap, we propose a novel approach,\n\\methodname, from a modality conversion perspective that evolves a text-based\nLLM into a multi-modal one. We specifically employ a minimal dataset to\ninstruct LLMs to recognize the intended output modality as directed by the\ninstructions. Consequently, the adapted LLM can effectively summon various\noff-the-shelf modality conversion models from the model zoos to generate\nnon-text responses. This circumvents the necessity for complicated pretraining\nthat typically requires immense quantities of paired multi-modal data, while\nsimultaneously inheriting the extensive knowledge of LLMs and the ability of\nhigh-quality generative models. To evaluate and compare the adapted multi-modal\nLLM with its traditional counterparts, we have constructed a multi-modal\ninstruction benchmark that solicits diverse modality outputs. The experiment\nresults reveal that, with minimal training, LLMs can be conveniently adapted to\ncomprehend requests for non-text responses, thus achieving higher flexibility\nin multi-modal scenarios. Code and data will be made available at\nhttps://github.com/xinke-wang/SwitchGPT.",
            "author": [
                "Xinyu Wang",
                "Bohan Zhuang",
                "Qi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07623v1",
                "http://arxiv.org/pdf/2309.07623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07608v1",
            "title": "Identifying and analysing toxic actors and communities on Facebook by\n  employing network analysis",
            "updated": "2023-09-14T11:16:16Z",
            "published": "2023-09-14T11:16:16Z",
            "summary": "There has been an increasingly widespread agreement among both academic\ncircles and the general public that the Social Media Platforms (SMPs) play a\ncentral role in the dissemination of harmful and negative sentiment content in\na coordinated manner. A substantial body of recent scholarly research has\ndemonstrated the ways in which hateful content, political propaganda, and\ntargeted messaging on SMPs have contributed to serious real-world consequences.\nAdopting inspirations from graph theory, in this paper we apply novel network\nand community finding algorithms over a representative Facebook dataset\n(n=608,417) which we have scrapped through 630 pages. By applying Girvan-Newman\nalgorithm over the historical dataset our analysis finds five communities of\ncoordinated networks of actors, within the contexts of Indian far-right\nHindutva discourse. This work further paves the path for future potentials of\napplying such novel network analysis algorithms to SMPs, in order to\nautomatically identify toxic coordinated communities and sub-communities, and\nto possibly resist real-world threats emerging from information dissemination\nin the SMPs.",
            "author": [
                "Ritumbra Manuvie",
                "Saikat Chatterjee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07608v1",
                "http://arxiv.org/pdf/2309.07608v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07594v1",
            "title": "Neuro-Symbolic Recommendation Model based on Logic Query",
            "updated": "2023-09-14T10:54:48Z",
            "published": "2023-09-14T10:54:48Z",
            "summary": "A recommendation system assists users in finding items that are relevant to\nthem. Existing recommendation models are primarily based on predicting\nrelationships between users and items and use complex matching models or\nincorporate extensive external information to capture association patterns in\ndata. However, recommendation is not only a problem of inductive statistics\nusing data; it is also a cognitive task of reasoning decisions based on\nknowledge extracted from information. Hence, a logic system could naturally be\nincorporated for the reasoning in a recommendation task. However, although\nhard-rule approaches based on logic systems can provide powerful reasoning\nability, they struggle to cope with inconsistent and incomplete knowledge in\nreal-world tasks, especially for complex tasks such as recommendation.\nTherefore, in this paper, we propose a neuro-symbolic recommendation model,\nwhich transforms the user history interactions into a logic expression and then\ntransforms the recommendation prediction into a query task based on this logic\nexpression. The logic expressions are then computed based on the modular logic\noperations of the neural network. We also construct an implicit logic encoder\nto reasonably reduce the complexity of the logic computation. Finally, a user's\ninterest items can be queried in the vector space based on the computation\nresults. Experiments on three well-known datasets verified that our method\nperforms better compared to state of the art shallow, deep, session, and\nreasoning models.",
            "author": [
                "Maonian Wu",
                "Bang Chen",
                "Shaojun Zhu",
                "Bo Zheng",
                "Wei Peng",
                "Mingyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07594v1",
                "http://arxiv.org/pdf/2309.07594v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07587v1",
            "title": "The edge rings of compact graphs",
            "updated": "2023-09-14T10:45:11Z",
            "published": "2023-09-14T10:45:11Z",
            "summary": "We define a simple graph as compact if it lacks even cycles and satisfies the\nodd-cycle condition. Our focus is on classifying all compact graphs and\nexamining the characteristics of their edge rings. Let $G$ be a compact graph\nand $\\mathbb{K}[G]$ be its edge ring. Specifically, we demonstrate that the\nCohen-Macaulay type and the projective dimension of $\\mathbb{K}[G]$ are both\nequal to the number of induced cycles of $G$ minus one, and that the regularity\nof $\\mathbb{K}[G]$ is equal to the matching number of $G_0$. Here, $G_0$ is\nobtained from $G$ by removing the vertices of degree one successively,\nresulting in a graph where every vertex has a degree greater than 1.",
            "author": [
                "Zexin Wang",
                "Dancheng Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07587v1",
                "http://arxiv.org/pdf/2309.07587v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "Primary 05E40, 13A02, Secondary 06D50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07581v1",
            "title": "A Survey of Graph Pre-processing Methods: From Algorithmic to Hardware\n  Perspectives",
            "updated": "2023-09-14T10:26:51Z",
            "published": "2023-09-14T10:26:51Z",
            "summary": "Graph-related applications have experienced significant growth in academia\nand industry, driven by the powerful representation capabilities of graph.\nHowever, efficiently executing these applications faces various challenges,\nsuch as load imbalance, random memory access, etc. To address these challenges,\nresearchers have proposed various acceleration systems, including software\nframeworks and hardware accelerators, all of which incorporate graph\npre-processing (GPP). GPP serves as a preparatory step before the formal\nexecution of applications, involving techniques such as sampling, reorder, etc.\nHowever, GPP execution often remains overlooked, as the primary focus is\ndirected towards enhancing graph applications themselves. This oversight is\nconcerning, especially considering the explosive growth of real-world graph\ndata, where GPP becomes essential and even dominates system running overhead.\nFurthermore, GPP methods exhibit significant variations across devices and\napplications due to high customization. Unfortunately, no comprehensive work\nsystematically summarizes GPP. To address this gap and foster a better\nunderstanding of GPP, we present a comprehensive survey dedicated to this area.\nWe propose a double-level taxonomy of GPP, considering both algorithmic and\nhardware perspectives. Through listing relavent works, we illustrate our\ntaxonomy and conduct a thorough analysis and summary of diverse GPP techniques.\nLastly, we discuss challenges in GPP and potential future directions.",
            "author": [
                "Zhengyang Lv",
                "Mingyu Yan",
                "Xin Liu",
                "Mengyao Dong",
                "Xiaochun Ye",
                "Dongrui Fan",
                "Ninghui Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07581v1",
                "http://arxiv.org/pdf/2309.07581v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07580v1",
            "title": "Combining Multiple View Components for Exploratory Visualization",
            "updated": "2023-09-14T10:26:46Z",
            "published": "2023-09-14T10:26:46Z",
            "summary": "The analysis of structured complex data, such as clustered graph based\ndatasets, usually applies a variety of visual representation techniques and\nformats. The majority of currently available tools and approaches to\nexploratory visualization are built on integrated schemes for simultaneous\ndisplaying of multiple aspects of studying objects and processes. Usually, such\nschemes partition screen space that is composed of multiple views and adopt\ninteraction patterns to focus on data-driven items. Widely known concepts as\noverview plus-detail and focus-plus-context are ambiguous in interpretation by\nmeans of technical terms. Therefore, their implementation by UI design\npractitioners need reviews and a classification of the basic approaches to\nvisual composition of graphical representation modules. We propose a\ndescription of basic components of the view and focus and an overview of their\nmultiple combinations.",
            "author": [
                "Vladimir Guchev",
                "Paolo Buono",
                "Cristina Gena"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07580v1",
                "http://arxiv.org/pdf/2309.07580v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07561v1",
            "title": "Adaptive Prompt Learning with Distilled Connective Knowledge for\n  Implicit Discourse Relation Recognition",
            "updated": "2023-09-14T09:44:46Z",
            "published": "2023-09-14T09:44:46Z",
            "summary": "Implicit discourse relation recognition (IDRR) aims at recognizing the\ndiscourse relation between two text segments without an explicit connective.\nRecently, the prompt learning has just been applied to the IDRR task with great\nperformance improvements over various neural network-based approaches. However,\nthe discrete nature of the state-art-of-art prompting approach requires manual\ndesign of templates and answers, a big hurdle for its practical applications.\nIn this paper, we propose a continuous version of prompt learning together with\nconnective knowledge distillation, called AdaptPrompt, to reduce manual design\nefforts via continuous prompting while further improving performance via\nknowledge transfer. In particular, we design and train a few virtual tokens to\nform continuous templates and automatically select the most suitable one by\ngradient search in the embedding space. We also design an answer-relation\nmapping rule to generate a few virtual answers as the answer space.\nFurthermore, we notice the importance of annotated connectives in the training\ndataset and design a teacher-student architecture for knowledge transfer.\nExperiments on the up-to-date PDTB Corpus V3.0 validate our design objectives\nin terms of the better relation recognition performance over the\nstate-of-the-art competitors.",
            "author": [
                "Bang Wang",
                "Zhenglin Wang",
                "Wei Xiang",
                "Yijun Mo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07561v1",
                "http://arxiv.org/pdf/2309.07561v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07559v2",
            "title": "Spectrum and Local Metric Dimension of Andr\u00e1sfai Graphs",
            "updated": "2023-09-29T10:25:30Z",
            "published": "2023-09-14T09:42:01Z",
            "summary": "The Andr\\'asfai graph $And(k)$ for $k\\geq 1$ is a circulant and triangle-free\ngraph on 3k-1 vertices. In this paper, we have determined the least eigenvalue,\nsecond largest eigenvalue, and the number of distinct eigenvalues of the\nadjacency spectrum of $And(k)$. Also, we have found out the local metric\ndimension of $And(k)$.",
            "author": [
                "K. Bharani Dharan",
                "S. Radha"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07559v2",
                "http://arxiv.org/pdf/2309.07559v2"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math.CO",
                "05C12, 05C25, 05C50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07553v1",
            "title": "Identifying Job Satisfaction Parameters among the Employees in Higher\n  Educational Institutions: A Mathematical Model",
            "updated": "2023-09-14T09:28:28Z",
            "published": "2023-09-14T09:28:28Z",
            "summary": "The study is conducted to evaluate the job satisfaction among the\nadministrative and teaching faculties in higher educational institutions. Many\nresearchers have conducted studies to evaluate differences in job perception\nbetween teaching and non-teaching staff. Despite this, none of the studies have\nexplicitly focused on developing a formal mathematical approach for analysis.\nThus, this paper aims to identify the job satisfaction parameters among staff\nin an educational institution by using Multi Criteria Decision Making (MCDM)\ntools.\n  The factors influencing employee job satisfaction have been ascertained and\nhierarchically organized through the utilization of the standard deviation\nmethodology. Analytical findings reveal that certain variables, including\npromotional opportunities, interpersonal relations with colleagues, managerial\nsupport, and the department of employment, exert a substantial impact on an\nindividual's level of job satisfaction. The research posits that the strategic\nimplementation of these variables and attributes by organizational management\ncan significantly ameliorate challenges related to employee retention, thereby\nenhancing overall workforce efficiency.",
            "author": [
                "Mahak Bhatia",
                "Aled Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07553v1",
                "http://arxiv.org/pdf/2309.07553v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "math.OC",
                "47N10, 65K05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07550v1",
            "title": "Naturalistic Robot Arm Trajectory Generation via Representation Learning",
            "updated": "2023-09-14T09:26:03Z",
            "published": "2023-09-14T09:26:03Z",
            "summary": "The integration of manipulator robots in household environments suggests a\nneed for more predictable and human-like robot motion. This holds especially\ntrue for wheelchair-mounted assistive robots that can support the independence\nof people with paralysis. One method of generating naturalistic motion\ntrajectories is via the imitation of human demonstrators. This paper explores a\nself-supervised imitation learning method using an autoregressive\nspatio-temporal graph neural network for an assistive drinking task. We address\nlearning from diverse human motion trajectory data that were captured via\nwearable IMU sensors on a human arm as the action-free task demonstrations.\nObserved arm motion data from several participants is used to generate natural\nand functional drinking motion trajectories for a UR5e robot arm.",
            "author": [
                "Jayjun Lee",
                "Adam J. Spiers"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07550v1",
                "http://arxiv.org/pdf/2309.07550v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07548v1",
            "title": "Proximal Bellman mappings for reinforcement learning and their\n  application to robust adaptive filtering",
            "updated": "2023-09-14T09:20:21Z",
            "published": "2023-09-14T09:20:21Z",
            "summary": "This paper aims at the algorithmic/theoretical core of reinforcement learning\n(RL) by introducing the novel class of proximal Bellman mappings. These\nmappings are defined in reproducing kernel Hilbert spaces (RKHSs), to benefit\nfrom the rich approximation properties and inner product of RKHSs, they are\nshown to belong to the powerful Hilbertian family of (firmly) nonexpansive\nmappings, regardless of the values of their discount factors, and possess ample\ndegrees of design freedom to even reproduce attributes of the classical Bellman\nmappings and to pave the way for novel RL designs. An approximate\npolicy-iteration scheme is built on the proposed class of mappings to solve the\nproblem of selecting online, at every time instance, the \"optimal\" exponent $p$\nin a $p$-norm loss to combat outliers in linear adaptive filtering, without\ntraining data and any knowledge on the statistical properties of the outliers.\nNumerical tests on synthetic data showcase the superior performance of the\nproposed framework over several non-RL and kernel-based RL schemes.",
            "author": [
                "Yuki Akiyama",
                "Konstantinos Slavakis"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07548v1",
                "http://arxiv.org/pdf/2309.07548v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07545v2",
            "title": "DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph",
            "updated": "2023-09-25T08:44:19Z",
            "published": "2023-09-14T09:15:36Z",
            "summary": "In this work, we present a web application named DBLPLink, which performs\nentity linking over the DBLP scholarly knowledge graph. DBLPLink uses\ntext-to-text pre-trained language models, such as T5, to produce entity label\nspans from an input text question. Entity candidates are fetched from a\ndatabase based on the labels, and an entity re-ranker sorts them based on\nentity embeddings, such as TransE, DistMult and ComplEx. The results are\ndisplayed so that users may compare and contrast the results between T5-small,\nT5-base and the different KG embeddings used. The demo can be accessed at\nhttps://ltdemos.informatik.uni-hamburg.de/dblplink/.",
            "author": [
                "Debayan Banerjee",
                "Arefa",
                "Ricardo Usbeck",
                "Chris Biemann"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07545v2",
                "http://arxiv.org/pdf/2309.07545v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07530v1",
            "title": "Adaptive approximation of monotone functions",
            "updated": "2023-09-14T08:56:31Z",
            "published": "2023-09-14T08:56:31Z",
            "summary": "We study the classical problem of approximating a non-decreasing function $f:\n\\mathcal{X} \\to \\mathcal{Y}$ in $L^p(\\mu)$ norm by sequentially querying its\nvalues, for known compact real intervals $\\mathcal{X}$, $\\mathcal{Y}$ and a\nknown probability measure $\\mu$ on $\\cX$. For any function~$f$ we characterize\nthe minimum number of evaluations of $f$ that algorithms need to guarantee an\napproximation $\\hat{f}$ with an $L^p(\\mu)$ error below $\\epsilon$ after\nstopping. Unlike worst-case results that hold uniformly over all $f$, our\ncomplexity measure is dependent on each specific function $f$. To address this\nproblem, we introduce GreedyBox, a generalization of an algorithm originally\nproposed by Novak (1992) for numerical integration. We prove that GreedyBox\nachieves an optimal sample complexity for any function $f$, up to logarithmic\nfactors. Additionally, we uncover results regarding piecewise-smooth functions.\nPerhaps as expected, the $L^p(\\mu)$ error of GreedyBox decreases much faster\nfor piecewise-$C^2$ functions than predicted by the algorithm (without any\nknowledge on the smoothness of $f$). A simple modification even achieves\noptimal minimax approximation rates for such functions, which we compute\nexplicitly. In particular, our findings highlight multiple performance gaps\nbetween adaptive and non-adaptive algorithms, smooth and piecewise-smooth\nfunctions, as well as monotone or non-monotone functions. Finally, we provide\nnumerical experiments to support our theoretical results.",
            "author": [
                "Pierre Gaillard",
                "S\u00e9bastien Gerchinovitz",
                "\u00c9tienne de Montbrun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07530v1",
                "http://arxiv.org/pdf/2309.07530v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07509v1",
            "title": "DiffTalker: Co-driven audio-image diffusion for talking faces via\n  intermediate landmarks",
            "updated": "2023-09-14T08:22:34Z",
            "published": "2023-09-14T08:22:34Z",
            "summary": "Generating realistic talking faces is a complex and widely discussed task\nwith numerous applications. In this paper, we present DiffTalker, a novel model\ndesigned to generate lifelike talking faces through audio and landmark\nco-driving. DiffTalker addresses the challenges associated with directly\napplying diffusion models to audio control, which are traditionally trained on\ntext-image pairs. DiffTalker consists of two agent networks: a\ntransformer-based landmarks completion network for geometric accuracy and a\ndiffusion-based face generation network for texture details. Landmarks play a\npivotal role in establishing a seamless connection between the audio and image\ndomains, facilitating the incorporation of knowledge from pre-trained diffusion\nmodels. This innovative approach efficiently produces articulate-speaking\nfaces. Experimental results showcase DiffTalker's superior performance in\nproducing clear and geometrically accurate talking faces, all without the need\nfor additional alignment between audio and image features.",
            "author": [
                "Zipeng Qi",
                "Xulong Zhang",
                "Ning Cheng",
                "Jing Xiao",
                "Jianzong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07509v1",
                "http://arxiv.org/pdf/2309.07509v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07499v1",
            "title": "Efficiently Robustify Pre-trained Models",
            "updated": "2023-09-14T08:07:49Z",
            "published": "2023-09-14T08:07:49Z",
            "summary": "A recent trend in deep learning algorithms has been towards training large\nscale models, having high parameter count and trained on big dataset. However,\nrobustness of such large scale models towards real-world settings is still a\nless-explored topic. In this work, we first benchmark the performance of these\nmodels under different perturbations and datasets thereby representing\nreal-world shifts, and highlight their degrading performance under these\nshifts. We then discuss on how complete model fine-tuning based existing\nrobustification schemes might not be a scalable option given very large scale\nnetworks and can also lead them to forget some of the desired characterstics.\nFinally, we propose a simple and cost-effective method to solve this problem,\ninspired by knowledge transfer literature. It involves robustifying smaller\nmodels, at a lower computation cost, and then use them as teachers to tune a\nfraction of these large scale networks, reducing the overall computational\noverhead. We evaluate our proposed method under various vision perturbations\nincluding ImageNet-C,R,S,A datasets and also for transfer learning, zero-shot\nevaluation setups on different datasets. Benchmark results show that our method\nis able to induce robustness to these large scale models efficiently, requiring\nsignificantly lower time and also preserves the transfer learning, zero-shot\nproperties of the original model which none of the existing methods are able to\nachieve.",
            "author": [
                "Nishant Jain",
                "Harkirat Behl",
                "Yogesh Singh Rawat",
                "Vibhav Vineet"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07499v1",
                "http://arxiv.org/pdf/2309.07499v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07486v1",
            "title": "Massively-Parallel Heat Map Sorting and Applications To Explainable\n  Clustering",
            "updated": "2023-09-14T07:53:52Z",
            "published": "2023-09-14T07:53:52Z",
            "summary": "Given a set of points labeled with $k$ labels, we introduce the heat map\nsorting problem as reordering and merging the points and dimensions while\npreserving the clusters (labels). A cluster is preserved if it remains\nconnected, i.e., if it is not split into several clusters and no two clusters\nare merged.\n  We prove the problem is NP-hard and we give a fixed-parameter algorithm with\na constant number of rounds in the massively parallel computation model, where\neach machine has a sublinear memory and the total memory of the machines is\nlinear. We give an approximation algorithm for a NP-hard special case of the\nproblem. We empirically compare our algorithm with k-means and density-based\nclustering (DBSCAN) using a dimensionality reduction via locality-sensitive\nhashing on several directed and undirected graphs of email and computer\nnetworks.",
            "author": [
                "Sepideh Aghamolaei",
                "Mohammad Ghodsi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07486v1",
                "http://arxiv.org/pdf/2309.07486v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07482v1",
            "title": "MuLaN: a MultiLayer Networks Alignment Algorithm",
            "updated": "2023-09-14T07:43:40Z",
            "published": "2023-09-14T07:43:40Z",
            "summary": "A Multilayer Network (MN) is a system consisting of several topological\nlevels (i.e., layers) representing the interactions between the system's\nobjects and the related interdependency. Therefore, it may be represented as a\nset of layers that can be assimilated to a set of networks of its own objects,\nby means inter-layer edges (or inter-edges) linking the nodes of different\nlayers; for instance, a biological MN may allow modeling of inter and intra\ninteractions among diseases, genes, and drugs, only using its own structure.\nThe analysis of MNs may reveal hidden knowledge, as demonstrated by several\nalgorithms for the analysis. Recently, there is a growing interest in comparing\ntwo MNs by revealing local regions of similarity, as a counterpart of Network\nAlignment algorithms (NA) for simple networks. However, classical algorithms\nfor NA such as Local NA (LNA) cannot be applied on multilayer networks, since\nthey are not able to deal with inter-layer edges. Therefore, there is the need\nfor the introduction of novel algorithms. In this paper, we present MuLaN, an\nalgorithm for the local alignment of multilayer networks. We first show as\nproof of concept the performances of MuLaN on a set of synthetic multilayer\nnetworks. Then, we used as a case study a real multilayer network in the\nbiomedical domain. Our results show that MuLaN is able to build high-quality\nalignments and can extract knowledge about the aligned multilayer networks.\nMuLaN is available at https://github.com/pietrocinaglia/mulan.",
            "author": [
                "Marianna Milano",
                "Pietro Cinaglia",
                "Pietro Hiram Guzzi",
                "Mario Cannataro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07482v1",
                "http://arxiv.org/pdf/2309.07482v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07473v1",
            "title": "Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories\n  of Articulated Objects",
            "updated": "2023-09-14T07:11:58Z",
            "published": "2023-09-14T07:11:58Z",
            "summary": "Articulated object manipulation is a fundamental yet challenging task in\nrobotics. Due to significant geometric and semantic variations across object\ncategories, previous manipulation models struggle to generalize to novel\ncategories. Few-shot learning is a promising solution for alleviating this\nissue by allowing robots to perform a few interactions with unseen objects.\nHowever, extant approaches often necessitate costly and inefficient test-time\ninteractions with each unseen instance. Recognizing this limitation, we observe\nthat despite their distinct shapes, different categories often share similar\nlocal geometries essential for manipulation, such as pullable handles and\ngraspable edges - a factor typically underutilized in previous few-shot\nlearning works. To harness this commonality, we introduce 'Where2Explore', an\naffordance learning framework that effectively explores novel categories with\nminimal interactions on a limited number of instances. Our framework explicitly\nestimates the geometric similarity across different categories, identifying\nlocal areas that differ from shapes in the training categories for efficient\nexploration while concurrently transferring affordance knowledge to similar\nparts of the objects. Extensive experiments in simulated and real-world\nenvironments demonstrate our framework's capacity for efficient few-shot\nexploration and generalization.",
            "author": [
                "Chuanruo Ning",
                "Ruihai Wu",
                "Haoran Lu",
                "Kaichun Mo",
                "Hao Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07473v1",
                "http://arxiv.org/pdf/2309.07473v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07470v1",
            "title": "African swine fever in wild boar: investigating model assumptions and\n  structure",
            "updated": "2023-09-14T07:00:31Z",
            "published": "2023-09-14T07:00:31Z",
            "summary": "African swine fever (ASF) is a highly virulent viral disease that affects\nboth domestic pigs and wild boar. Current ASF transmission in Europe is in part\ndriven by wild boar populations, which act as a disease reservoir. Wild boar\nare abundant throughout Europe and are highly social animals with complex\nsocial organisation. Despite the known importance of wild boar in ASF spread\nand persistence, there remain knowledge gaps surrounding wild boar\ntransmission. To investigate the influence of density-contact functions and\nwild boar social structure on disease dynamics, we developed a wild boar\nmodelling framework. The framework included an ordinary differential equation\nmodel, a homogeneous stochastic model, and various network-based stochastic\nmodels that explicitly included wild boar social grouping. We found that power\nlaw functions (transmission $\\propto$ density$^{0.5}$) and frequency-based\ndensity-contact functions were best able to reproduce recent Baltic outbreaks;\nhowever, power law function models predicted considerable carcass transmission,\nwhile frequency-based models had negligible carcass transmission. Furthermore,\nincreased model heterogeneity caused a decrease in the relative importance of\ncarcass-based transmission. The different dominant transmission pathways\npredicted by each model type affected the efficacy of potential interventions,\nwhich highlights the importance of evaluating model type and structure when\nmodelling systems with uncertainties.",
            "author": [
                "Callum Shaw",
                "Angus McLure",
                "Kathryn Glass"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07470v1",
                "http://arxiv.org/pdf/2309.07470v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07460v1",
            "title": "A Tutorial on Environment-Aware Communications via Channel Knowledge Map\n  for 6G",
            "updated": "2023-09-14T06:38:08Z",
            "published": "2023-09-14T06:38:08Z",
            "summary": "Sixth-generation (6G) mobile communication networks are expected to have\ndense infrastructures, large-dimensional channels, cost-effective hardware,\ndiversified positioning methods, and enhanced intelligence. Such trends bring\nboth new challenges and opportunities for the practical design of 6G. On one\nhand, acquiring channel state information (CSI) in real time for all wireless\nlinks becomes quite challenging in 6G. On the other hand, there would be\nnumerous data sources in 6G containing high-quality location-tagged channel\ndata, making it possible to better learn the local wireless environment. By\nexploiting such new opportunities and for tackling the CSI acquisition\nchallenge, there is a promising paradigm shift from the conventional\nenvironment-unaware communications to the new environment-aware communications\nbased on the novel approach of channel knowledge map (CKM). This article aims\nto provide a comprehensive tutorial overview on environment-aware\ncommunications enabled by CKM to fully harness its benefits for 6G. First, the\nbasic concept of CKM is presented, and a comparison of CKM with various\nexisting channel inference techniques is discussed. Next, the main techniques\nfor CKM construction are discussed, including both the model-free and\nmodel-assisted approaches. Furthermore, a general framework is presented for\nthe utilization of CKM to achieve environment-aware communications, followed by\nsome typical CKM-aided communication scenarios. Finally, important open\nproblems in CKM research are highlighted and potential solutions are discussed\nto inspire future work.",
            "author": [
                "Yong Zeng",
                "Junting Chen",
                "Jie Xu",
                "Di Wu",
                "Xiaoli Xu",
                "Shi Jin",
                "Xiqi Gao",
                "David Gesbert",
                "Shuguang Cui",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07460v1",
                "http://arxiv.org/pdf/2309.07460v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07453v1",
            "title": "SC-MAD: Mixtures of Higher-order Networks for Data Augmentation",
            "updated": "2023-09-14T06:25:39Z",
            "published": "2023-09-14T06:25:39Z",
            "summary": "The myriad complex systems with multiway interactions motivate the extension\nof graph-based pairwise connections to higher-order relations. In particular,\nthe simplicial complex has inspired generalizations of graph neural networks\n(GNNs) to simplicial complex-based models. Learning on such systems requires\nlarge amounts of data, which can be expensive or impossible to obtain. We\npropose data augmentation of simplicial complexes through both linear and\nnonlinear mixup mechanisms that return mixtures of existing labeled samples. In\naddition to traditional pairwise mixup, we present a convex clustering mixup\napproach for a data-driven relationship among several simplicial complexes. We\ntheoretically demonstrate that the resultant synthetic simplicial complexes\ninterpolate among existing data with respect to homomorphism densities. Our\nmethod is demonstrated on both synthetic and real-world datasets for simplicial\ncomplex classification.",
            "author": [
                "Madeline Navarro",
                "Santiago Segarra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07453v1",
                "http://arxiv.org/pdf/2309.07453v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07452v1",
            "title": "Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph\n  Neural Network?",
            "updated": "2023-09-14T06:24:33Z",
            "published": "2023-09-14T06:24:33Z",
            "summary": "A rising trend in theoretical deep learning is to understand why deep\nlearning works through Neural Tangent Kernel (NTK) [jgh18], a kernel method\nthat is equivalent to using gradient descent to train a multi-layer\ninfinitely-wide neural network. NTK is a major step forward in the theoretical\ndeep learning because it allows researchers to use traditional mathematical\ntools to analyze properties of deep neural networks and to explain various\nneural network techniques from a theoretical view. A natural extension of NTK\non graph learning is \\textit{Graph Neural Tangent Kernel (GNTK)}, and\nresearchers have already provide GNTK formulation for graph-level regression\nand show empirically that this kernel method can achieve similar accuracy as\nGNNs on various bioinformatics datasets [dhs+19]. The remaining question now is\nwhether solving GNTK regression is equivalent to training an infinite-wide\nmulti-layer GNN using gradient descent. In this paper, we provide three new\ntheoretical results. First, we formally prove this equivalence for graph-level\nregression. Second, we present the first GNTK formulation for node-level\nregression. Finally, we prove the equivalence for node-level regression.",
            "author": [
                "Lianke Qin",
                "Zhao Song",
                "Baocheng Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07452v1",
                "http://arxiv.org/pdf/2309.07452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07449v1",
            "title": "Rate-Induced Transitions in Networked Complex Adaptive Systems:\n  Exploring Dynamics and Management Implications Across Ecological, Social, and\n  Socioecological Systems",
            "updated": "2023-09-14T06:13:53Z",
            "published": "2023-09-14T06:13:53Z",
            "summary": "Complex adaptive systems (CASs), from ecosystems to economies, are open\nsystems and inherently dependent on external conditions. While a system can\ntransition from one state to another based on the magnitude of change in\nexternal conditions, the rate of change -- irrespective of magnitude -- may\nalso lead to system state changes due to a phenomenon known as a rate-induced\ntransition (RIT). This study presents a novel framework that captures RITs in\nCASs through a local model and a network extension where each node contributes\nto the structural adaptability of others. Our findings reveal how RITs occur at\na critical environmental change rate, with lower-degree nodes tipping first due\nto fewer connections and reduced adaptive capacity. High-degree nodes tip later\nas their adaptability sources (lower-degree nodes) collapse. This pattern\npersists across various network structures. Our study calls for an extended\nperspective when managing CASs, emphasizing the need to focus not only on\nthresholds of external conditions but also the rate at which those conditions\nchange, particularly in the context of the collapse of surrounding systems that\ncontribute to the focal system's resilience. Our analytical method opens a path\nto designing management policies that mitigate RIT impacts and enhance\nresilience in ecological, social, and socioecological systems. These policies\ncould include controlling environmental change rates, fostering system\nadaptability, implementing adaptive management strategies, and building\ncapacity and knowledge exchange. Our study contributes to the understanding of\nRIT dynamics and informs effective management strategies for complex adaptive\nsystems in the face of rapid environmental change.",
            "author": [
                "V\u00edtor V. Vasconcelos",
                "Fl\u00e1via M. D. Marquitti",
                "Theresa Ong",
                "Lisa C. McManus",
                "Marcus Aguiar",
                "Amanda B. Campos",
                "Partha S. Dutta",
                "Kristen Jovanelly",
                "Victoria Junquera",
                "Jude Kong",
                "Elisabeth H. Krueger",
                "Simon A. Levin",
                "Wenying Liao",
                "Mingzhen Lu",
                "Dhruv Mittal",
                "Mercedes Pascual",
                "Fl\u00e1vio L. Pinheiro",
                "Juan Rocha",
                "Fernando P. Santos",
                "Peter Sloot",
                "Chenyang",
                "Su",
                "Benton Taylor",
                "Eden Tekwa",
                "Sjoerd Terpstra",
                "Andrew R. Tilman",
                "James R. Watson",
                "Luojun Yang",
                "Senay Yitbarek",
                "Qi Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07449v1",
                "http://arxiv.org/pdf/2309.07449v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.MA",
                "math.DS",
                "nlin.AO",
                "37G, 37N, 91B, 91C, 91D, 91E, 92D, 92D25, 92D40, 92F, 93A, 93A14,\n  93A16",
                "I.6.3; I.6.m; J.3; J.4; J.m; K.4.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07439v1",
            "title": "DePT: Decoupled Prompt Tuning",
            "updated": "2023-09-14T05:45:40Z",
            "published": "2023-09-14T05:45:40Z",
            "summary": "This work breaks through the Base-New Tradeoff (BNT)dilemma in prompt tuning,\ni.e., the better the tuned model generalizes to the base (or target) task, the\nworse it generalizes to new tasks, and vice versa. Specifically, through an\nin-depth analysis of the learned features of the base and new tasks, we observe\nthat the BNT stems from a channel bias issue, i.e., the vast majority of\nfeature channels are occupied by base-specific knowledge, resulting in the\ncollapse of taskshared knowledge important to new tasks. To address this, we\npropose the Decoupled Prompt Tuning (DePT) framework, which decouples\nbase-specific knowledge from feature channels into an isolated feature space\nduring prompt tuning, so as to maximally preserve task-shared knowledge in the\noriginal feature space for achieving better zero-shot generalization on new\ntasks. Importantly, our DePT is orthogonal to existing prompt tuning methods,\nhence it can improve all of them. Extensive experiments on 11 datasets show the\nstrong flexibility and effectiveness of DePT. Our code and pretrained models\nare available at https://github.com/Koorye/DePT.",
            "author": [
                "Ji Zhang",
                "Shihan Wu",
                "Lianli Gao",
                "Hengtao Shen",
                "Jingkuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07439v1",
                "http://arxiv.org/pdf/2309.07439v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07429v1",
            "title": "Semantic Parsing in Limited Resource Conditions",
            "updated": "2023-09-14T05:03:09Z",
            "published": "2023-09-14T05:03:09Z",
            "summary": "This thesis explores challenges in semantic parsing, specifically focusing on\nscenarios with limited data and computational resources. It offers solutions\nusing techniques like automatic data curation, knowledge transfer, active\nlearning, and continual learning.\n  For tasks with no parallel training data, the thesis proposes generating\nsynthetic training examples from structured database schemas. When there is\nabundant data in a source domain but limited parallel data in a target domain,\nknowledge from the source is leveraged to improve parsing in the target domain.\n  For multilingual situations with limited data in the target languages, the\nthesis introduces a method to adapt parsers using a limited human translation\nbudget. Active learning is applied to select source-language samples for manual\ntranslation, maximizing parser performance in the target language. In addition,\nan alternative method is also proposed to utilize machine translation services,\nsupplemented by human-translated data, to train a more effective parser.\n  When computational resources are limited, a continual learning approach is\nintroduced to minimize training time and computational memory. This maintains\nthe parser's efficiency in previously learned tasks while adapting it to new\ntasks, mitigating the problem of catastrophic forgetting.\n  Overall, the thesis provides a comprehensive set of methods to improve\nsemantic parsing in resource-constrained conditions.",
            "author": [
                "Zhuang Li"
            ],
            "link": [
                "http://dx.doi.org/10.26180/24083265.v1",
                "http://arxiv.org/abs/2309.07429v1",
                "http://arxiv.org/pdf/2309.07429v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07415v1",
            "title": "Client-side Gradient Inversion Against Federated Learning from Poisoning",
            "updated": "2023-09-14T03:48:27Z",
            "published": "2023-09-14T03:48:27Z",
            "summary": "Federated Learning (FL) enables distributed participants (e.g., mobile\ndevices) to train a global model without sharing data directly to a central\nserver. Recent studies have revealed that FL is vulnerable to gradient\ninversion attack (GIA), which aims to reconstruct the original training samples\nand poses high risk against the privacy of clients in FL. However, most\nexisting GIAs necessitate control over the server and rely on strong prior\nknowledge including batch normalization and data distribution information. In\nthis work, we propose Client-side poisoning Gradient Inversion (CGI), which is\na novel attack method that can be launched from clients. For the first time, we\nshow the feasibility of a client-side adversary with limited knowledge being\nable to recover the training samples from the aggregated global model. We take\na distinct approach in which the adversary utilizes a malicious model that\namplifies the loss of a specific targeted class of interest. When honest\nclients employ the poisoned global model, the gradients of samples belonging to\nthe targeted class are magnified, making them the dominant factor in the\naggregated update. This enables the adversary to effectively reconstruct the\nprivate input belonging to other clients using the aggregated update. In\naddition, our CGI also features its ability to remain stealthy against\nByzantine-robust aggregation rules (AGRs). By optimizing malicious updates and\nblending benign updates with a malicious replacement vector, our method remains\nundetected by these defense mechanisms. To evaluate the performance of CGI, we\nconduct experiments on various benchmark datasets, considering representative\nByzantine-robust AGRs, and exploring diverse FL settings with different levels\nof adversary knowledge about the data. Our results demonstrate that CGI\nconsistently and successfully extracts training input in all tested scenarios.",
            "author": [
                "Jiaheng Wei",
                "Yanjun Zhang",
                "Leo Yu Zhang",
                "Chao Chen",
                "Shirui Pan",
                "Kok-Leong Ong",
                "Jun Zhang",
                "Yang Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07415v1",
                "http://arxiv.org/pdf/2309.07415v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07402v1",
            "title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning\n  and Minimax Entropy",
            "updated": "2023-09-14T03:15:57Z",
            "published": "2023-09-14T03:15:57Z",
            "summary": "Label scarcity in a graph is frequently encountered in real-world\napplications due to the high cost of data labeling. To this end,\nsemi-supervised domain adaptation (SSDA) on graphs aims to leverage the\nknowledge of a labeled source graph to aid in node classification on a target\ngraph with limited labels. SSDA tasks need to overcome the domain gap between\nthe source and target graphs. However, to date, this challenging research\nproblem has yet to be formally considered by the existing approaches designed\nfor cross-graph node classification. To tackle the SSDA problem on graphs, a\nnovel method called SemiGCL is proposed, which benefits from graph contrastive\nlearning and minimax entropy training. SemiGCL generates informative node\nrepresentations by contrasting the representations learned from a graph's local\nand global views. Additionally, SemiGCL is adversarially optimized with the\nentropy loss of unlabeled target nodes to reduce domain divergence.\nExperimental results on benchmark datasets demonstrate that SemiGCL outperforms\nthe state-of-the-art baselines on the SSDA tasks.",
            "author": [
                "Jiaren Xiao",
                "Quanyu Dai",
                "Xiao Shen",
                "Xiaochen Xie",
                "Jing Dai",
                "James Lam",
                "Ka-Wai Kwok"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07402v1",
                "http://arxiv.org/pdf/2309.07402v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07400v1",
            "title": "HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image\n  Analysis",
            "updated": "2023-09-14T03:04:06Z",
            "published": "2023-09-14T03:04:06Z",
            "summary": "In computation pathology, the pyramid structure of gigapixel Whole Slide\nImages (WSIs) has recently been studied for capturing various information from\nindividual cell interactions to tissue microenvironments. This hierarchical\nstructure is believed to be beneficial for cancer diagnosis and prognosis\ntasks. However, most previous hierarchical WSI analysis works (1) only\ncharacterize local or global correlations within the WSI pyramids and (2) use\nonly unidirectional interaction between different resolutions, leading to an\nincomplete picture of WSI pyramids. To this end, this paper presents a novel\nHierarchical Interaction Graph-Transformer (i.e., HIGT) for WSI analysis. With\nGraph Neural Network and Transformer as the building commons, HIGT can learn\nboth short-range local information and long-range global representation of the\nWSI pyramids. Considering that the information from different resolutions is\ncomplementary and can benefit each other during the learning process, we\nfurther design a novel Bidirectional Interaction block to establish\ncommunication between different levels within the WSI pyramids. Finally, we\naggregate both coarse-grained and fine-grained features learned from different\nlevels together for slide-level prediction. We evaluate our methods on two\npublic WSI datasets from TCGA projects, i.e., kidney carcinoma (KICA) and\nesophageal carcinoma (ESCA). Experimental results show that our HIGT\noutperforms both hierarchical and non-hierarchical state-of-the-art methods on\nboth tumor subtyping and staging tasks.",
            "author": [
                "Ziyu Guo",
                "Weiqin Zhao",
                "Shujun Wang",
                "Lequan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07400v1",
                "http://arxiv.org/pdf/2309.07400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07396v1",
            "title": "DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning\n  in the Debiasing Perspective",
            "updated": "2023-09-14T02:43:34Z",
            "published": "2023-09-14T02:43:34Z",
            "summary": "Several prior studies have suggested that word frequency biases can cause the\nBert model to learn indistinguishable sentence embeddings. Contrastive learning\nschemes such as SimCSE and ConSERT have already been adopted successfully in\nunsupervised sentence embedding to improve the quality of embeddings by\nreducing this bias. However, these methods still introduce new biases such as\nsentence length bias and false negative sample bias, that hinders model's\nability to learn more fine-grained semantics. In this paper, we reexamine the\nchallenges of contrastive sentence embedding learning from a debiasing\nperspective and argue that effectively eliminating the influence of various\nbiases is crucial for learning high-quality sentence embeddings. We think all\nthose biases are introduced by simple rules for constructing training data in\ncontrastive learning and the key for contrastive learning sentence embedding is\nto mimic the distribution of training data in supervised machine learning in\nunsupervised way. We propose a novel contrastive framework for sentence\nembedding, termed DebCSE, which can eliminate the impact of these biases by an\ninverse propensity weighted sampling method to select high-quality positive and\nnegative pairs according to both the surface and semantic similarity between\nsentences. Extensive experiments on semantic textual similarity (STS)\nbenchmarks reveal that DebCSE significantly outperforms the latest\nstate-of-the-art models with an average Spearman's correlation coefficient of\n80.33% on BERTbase.",
            "author": [
                "Pu Miao",
                "Zeyao Du",
                "Junlin Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614833",
                "http://arxiv.org/abs/2309.07396v1",
                "http://arxiv.org/pdf/2309.07396v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07384v1",
            "title": "An Interactive Framework for Profiling News Media Sources",
            "updated": "2023-09-14T02:03:45Z",
            "published": "2023-09-14T02:03:45Z",
            "summary": "The recent rise of social media has led to the spread of large amounts of\nfake and biased news, content published with the intent to sway beliefs. While\ndetecting and profiling the sources that spread this news is important to\nmaintain a healthy society, it is challenging for automated systems.\n  In this paper, we propose an interactive framework for news media profiling.\nIt combines the strengths of graph based news media profiling models,\nPre-trained Large Language Models, and human insight to characterize the social\ncontext on social media. Experimental results show that with as little as 5\nhuman interactions, our framework can rapidly detect fake and biased news\nmedia, even in the most challenging settings of emerging news events, where\ntest data is unseen.",
            "author": [
                "Nikhil Mehta",
                "Dan Goldwasser"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07384v1",
                "http://arxiv.org/pdf/2309.07384v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07381v1",
            "title": "International Competition on Graph Counting Algorithms 2023",
            "updated": "2023-09-14T01:58:45Z",
            "published": "2023-09-14T01:58:45Z",
            "summary": "This paper reports on the details of the International Competition on Graph\nCounting Algorithms (ICGCA) held in 2023. The graph counting problem is to\ncount the subgraphs satisfying specified constraints on a given graph. The\nproblem belongs to #P-complete, a computationally tough class. Since many\nessential systems in modern society, e.g., infrastructure networks, are often\nrepresented as graphs, graph counting algorithms are a key technology to\nefficiently scan all the subgraphs representing the feasible states of the\nsystem. In the ICGCA, contestants were asked to count the paths on a graph\nunder a length constraint. The benchmark set included 150 challenging\ninstances, emphasizing graphs resembling infrastructure networks. Eleven\nsolvers were submitted and ranked by the number of benchmarks correctly solved\nwithin a time limit. The winning solver, TLDC, was designed based on three\nfundamental approaches: backtracking search, dynamic programming, and model\ncounting or #SAT (a counting version of Boolean satisfiability). Detailed\nanalyses show that each approach has its own strengths, and one approach is\nunlikely to dominate the others. The codes and papers of the participating\nsolvers are available: https://afsa.jp/icgca/.",
            "author": [
                "Takeru Inoue",
                "Norihito Yasuda",
                "Hidetomo Nabeshima",
                "Masaaki Nishino",
                "Shuhei Denzumi",
                "Shin-ichi Minato"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07381v1",
                "http://arxiv.org/pdf/2309.07381v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07380v1",
            "title": "Domain-adaptive Graph Attention-supervised Network for Cross-network\n  Edge Classification",
            "updated": "2023-09-14T01:45:41Z",
            "published": "2023-09-14T01:45:41Z",
            "summary": "Graph neural networks (GNNs) have shown great ability in modeling graphs,\nhowever, their performance would significantly degrade when there are noisy\nedges connecting nodes from different classes. To alleviate negative effect of\nnoisy edges on neighborhood aggregation, some recent GNNs propose to predict\nthe label agreement between node pairs within a single network. However,\npredicting the label agreement of edges across different networks has not been\ninvestigated yet. Our work makes the pioneering attempt to study a novel\nproblem of cross-network homophilous and heterophilous edge classification\n(CNHHEC), and proposes a novel domain-adaptive graph attention-supervised\nnetwork (DGASN) to effectively tackle the CNHHEC problem. Firstly, DGASN adopts\nmulti-head GAT as the GNN encoder, which jointly trains node embeddings and\nedge embeddings via the node classification and edge classification losses. As\na result, label-discriminative embeddings can be obtained to distinguish\nhomophilous edges from heterophilous edges. In addition, DGASN applies direct\nsupervision on graph attention learning based on the observed edge labels from\nthe source network, thus lowering the negative effects of heterophilous edges\nwhile enlarging the positive effects of homophilous edges during neighborhood\naggregation. To facilitate knowledge transfer across networks, DGASN employs\nadversarial domain adaptation to mitigate domain divergence. Extensive\nexperiments on real-world benchmark datasets demonstrate that the proposed\nDGASN achieves the state-of-the-art performance in CNHHEC.",
            "author": [
                "Xiao Shen",
                "Mengqiu Shao",
                "Shirui Pan",
                "Laurence T. Yang",
                "Xi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07380v1",
                "http://arxiv.org/pdf/2309.07380v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07363v1",
            "title": "Linking Mechanisms: Limits and Robustness",
            "updated": "2023-09-14T00:37:31Z",
            "published": "2023-09-14T00:37:31Z",
            "summary": "Quota mechanisms are commonly used to elicit private information when agents\nface multiple decisions and monetary transfers are infeasible. As the number of\ndecisions grows large, quotas asymptotically implement the same set of social\nchoice functions as do separate mechanisms with transfers. We analyze the\nrobustness of quota mechanisms. To set the correct quota, the designer must\nhave precise knowledge of the environment. We show that, without transfers,\nonly trivial social choice rules can be implemented in a prior-independent way.\nWe obtain a tight bound on the decision error that results when the quota does\nnot match the true type distribution. Finally, we show that in a multi-agent\nsetting, quotas are robust to agents' beliefs about each other. Crucially,\nquotas make the distribution of reports common knowledge.",
            "author": [
                "Ian Ball",
                "Deniz Kattwinkel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07363v1",
                "http://arxiv.org/pdf/2309.07363v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07347v1",
            "title": "Energy-Constrained Active Exploration Under Incremental-Resolution\n  Symbolic Perception",
            "updated": "2023-09-13T22:55:16Z",
            "published": "2023-09-13T22:55:16Z",
            "summary": "In this work, we consider the problem of autonomous exploration in search of\ntargets while respecting a fixed energy budget. The robot is equipped with an\nincremental-resolution symbolic perception module wherein the perception of\ntargets in the environment improves as the robot's distance from targets\ndecreases. We assume no prior information about the total number of targets,\ntheir locations as well as their possible distribution within the environment.\nThis work proposes a novel decision-making framework for the resulting\nconstrained sequential decision-making problem by first converting it into a\nreward maximization problem on a product graph computed offline. It is then\nsolved online as a Mixed-Integer Linear Program (MILP) where the knowledge\nabout the environment is updated at each step, combining automata-based and\nMILP-based techniques. We demonstrate the efficacy of our approach with the\nhelp of a case study and present empirical evaluation in terms of expected\nregret. Furthermore, the runtime performance shows that online planning can be\nefficiently performed for moderately-sized grid environments.",
            "author": [
                "Disha Kamale",
                "Sofie Haesaert",
                "Cristian-Ioan Vasile"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07347v1",
                "http://arxiv.org/pdf/2309.07347v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12801v1",
            "title": "End-to-end Phase Field Model Discovery Combining Experimentation,\n  Crowdsourcing, Simulation and Learning",
            "updated": "2023-09-13T22:44:04Z",
            "published": "2023-09-13T22:44:04Z",
            "summary": "The availability of tera-byte scale experiment data calls for AI driven\napproaches which automatically discover scientific models from data.\nNonetheless, significant challenges present in AI-driven scientific discovery:\n(i) The annotation of large scale datasets requires fundamental re-thinking in\ndeveloping scalable crowdsourcing tools. (ii) The learning of scientific models\nfrom data calls for innovations beyond black-box neural nets. (iii) Novel\nvisualization and diagnosis tools are needed for the collaboration of\nexperimental and theoretical physicists, and computer scientists. We present\nPhase-Field-Lab platform for end-to-end phase field model discovery, which\nautomatically discovers phase field physics models from experiment data,\nintegrating experimentation, crowdsourcing, simulation and learning.\nPhase-Field-Lab combines (i) a streamlined annotation tool which reduces the\nannotation time (by ~50-75%), while increasing annotation accuracy compared to\nbaseline; (ii) an end-to-end neural model which automatically learns phase\nfield models from data by embedding phase field simulation and existing domain\nknowledge into learning; and (iii) novel interfaces and visualizations to\nintegrate our platform into the scientific discovery cycle of domain\nscientists. Our platform is deployed in the analysis of nano-structure\nevolution in materials under extreme conditions (high temperature and\nirradiation). Our approach reveals new properties of nano-void defects, which\notherwise cannot be detected via manual analysis.",
            "author": [
                "Md Nasim",
                "Anter El-Azab",
                "Xinghang Zhang",
                "Yexiang Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12801v1",
                "http://arxiv.org/pdf/2311.12801v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07338v2",
            "title": "Overcoming near-degeneracy in the autologistic actor attribute model",
            "updated": "2023-09-21T22:32:43Z",
            "published": "2023-09-13T22:14:12Z",
            "summary": "The autologistic actor attribute model, or ALAAM, is the social influence\ncounterpart of the better-known exponential-family random graph model (ERGM)\nfor social selection. Extensive experience with ERGMs has shown that the\nproblem of near-degeneracy which often occurs with simple models can be\novercome by using \"geometrically weighted\" or \"alternating\" statistics. In the\nmuch more limited empirical applications of ALAAMs to date, the problem of\nnear-degeneracy, although theoretically expected, appears to have been less of\nan issue. In this work I present a comprehensive survey of ALAAM applications,\nshowing that this model has to date only been used with relatively small\nnetworks, in which near-degeneracy does not appear to be a problem. I show\nnear-degeneracy does occur in simple ALAAM models of larger empirical networks,\ndefine some geometrically weighted ALAAM statistics analogous to those for\nERGM, and demonstrate that models with these statistics do not suffer from\nnear-degeneracy and hence can be estimated where they could not be with the\nsimple statistics.",
            "author": [
                "Alex Stivala"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07338v2",
                "http://arxiv.org/pdf/2309.07338v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07330v1",
            "title": "Automated Assessment of Critical View of Safety in Laparoscopic\n  Cholecystectomy",
            "updated": "2023-09-13T22:01:36Z",
            "published": "2023-09-13T22:01:36Z",
            "summary": "Cholecystectomy (gallbladder removal) is one of the most common procedures in\nthe US, with more than 1.2M procedures annually. Compared with classical open\ncholecystectomy, laparoscopic cholecystectomy (LC) is associated with\nsignificantly shorter recovery period, and hence is the preferred method.\nHowever, LC is also associated with an increase in bile duct injuries (BDIs),\nresulting in significant morbidity and mortality. The primary cause of BDIs\nfrom LCs is misidentification of the cystic duct with the bile duct. Critical\nview of safety (CVS) is the most effective of safety protocols, which is said\nto be achieved during the surgery if certain criteria are met. However, due to\nsuboptimal understanding and implementation of CVS, the BDI rates have remained\nstable over the last three decades. In this paper, we develop deep-learning\ntechniques to automate the assessment of CVS in LCs. An innovative aspect of\nour research is on developing specialized learning techniques by incorporating\ndomain knowledge to compensate for the limited training data available in\npractice. In particular, our CVS assessment process involves a fusion of two\nsegmentation maps followed by an estimation of a certain region of interest\nbased on anatomical structures close to the gallbladder, and then finally\ndetermination of each of the three CVS criteria via rule-based assessment of\nstructural information. We achieved a gain of over 11.8% in mIoU on relevant\nclasses with our two-stream semantic segmentation approach when compared to a\nsingle-model baseline, and 1.84% in mIoU with our proposed Sobel loss function\nwhen compared to a Transformer-based baseline model. For CVS criteria, we\nachieved up to 16% improvement and, for the overall CVS assessment, we achieved\n5% improvement in balanced accuracy compared to DeepCVS under the same\nexperiment settings.",
            "author": [
                "Yunfan Li",
                "Himanshu Gupta",
                "Haibin Ling",
                "IV Ramakrishnan",
                "Prateek Prasanna",
                "Georgios Georgakis",
                "Aaron Sasson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07330v1",
                "http://arxiv.org/pdf/2309.07330v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07932v1",
            "title": "Flat origami is Turing Complete",
            "updated": "2023-09-13T20:15:49Z",
            "published": "2023-09-13T20:15:49Z",
            "summary": "Flat origami refers to the folding of flat, zero-curvature paper such that\nthe finished object lies in a plane. Mathematically, flat origami consists of a\ncontinuous, piecewise isometric map $f:P\\subseteq\\mathbb{R}^2\\to\\mathbb{R}^2$\nalong with a layer ordering $\\lambda_f:P\\times P\\to \\{-1,1\\}$ that tracks which\npoints of $P$ are above/below others when folded. The set of crease lines that\na flat origami makes (i.e., the set on which the mapping $f$ is\nnon-differentiable) is called its \\textit{crease pattern}. Flat origami\nmappings and their layer orderings can possess surprisingly intricate\nstructure. For instance, determining whether or not a given straight-line\nplanar graph drawn on $P$ is the crease pattern for some flat origami has been\nshown to be an NP-complete problem, and this result from 1996 led to numerous\nexplorations in computational aspects of flat origami. In this paper we prove\nthat flat origami, when viewed as a computational device, is Turing complete.\nWe do this by showing that flat origami crease patterns with \\textit{optional\ncreases} (creases that might be folded or remain unfolded depending on\nconstraints imposed by other creases or inputs) can be constructed to simulate\nRule 110, a one-dimensional cellular automaton that was proven to be Turing\ncomplete by Matthew Cook in 2004.",
            "author": [
                "Thomas C. Hull",
                "Inna Zakharevich"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07932v1",
                "http://arxiv.org/pdf/2309.07932v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07286v1",
            "title": "Initially Regular Sequences on Cycles and Depth of Unicyclic Graphs",
            "updated": "2023-09-13T20:12:38Z",
            "published": "2023-09-13T20:12:38Z",
            "summary": "In this article, we establish initially regular sequences on cycles of the\nform $C_{3n+2}$ for $n\\ge 1$, in the sense of \\cite{FHM-ini}. These sequences\naccurately compute the depth of these cycles, completing the case of finding\neffective initially regular sequences on cycles. Our approach involves a\ncareful analysis of associated primes of initial ideals of the form\n$\\rm{ini}_>(I,f)$ for arbitrary monomial ideals $I$ and $f$ linear sums. We\ndescribe the minimal associated primes of these ideals in terms of the minimal\nprimes of $I$. Moreover, we obtain a description of the embedded associated\nprimes of arbitrary monomial ideals. Finally, we accurately compute the depth\nof certain types of unicyclic graphs.",
            "author": [
                "Le Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07286v1",
                "http://arxiv.org/pdf/2309.07286v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "13C15, 13D05, 05E40, 13F20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07240v2",
            "title": "Eulerian Polynomials for Digraphs",
            "updated": "2023-09-18T21:04:39Z",
            "published": "2023-09-13T18:27:30Z",
            "summary": "Given an $n$-vertex digraph $D$ and a labeling $\\sigma:V(D)\\to [n]$, we say\nthat an arc $u\\to v$ of $D$ is a descent of $\\sigma$ if $\\sigma(u)>\\sigma(v)$.\nFoata and Zeilberger introduced a generating function $A_D(t)$ for labelings of\n$D$ weighted by descents, which simultaneously generalizes both Eulerian\npolynomials and Mahonian polynomials. Motivated by work of Kalai, we look at\nproblems related to $-1$ evaluations of $A_D(t)$. In particular, we give a\ncombinatorial interpretation of $|A_D(-1)|$ in terms of \"generalized\nalternating permutations\" whenever the underlying graph of $D$ is bipartite.",
            "author": [
                "Kyle Celano",
                "Nicholas Sieger",
                "Sam Spiro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07240v2",
                "http://arxiv.org/pdf/2309.07240v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C20 (Primary) 05A05, 05C31 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07230v1",
            "title": "ESRO: Experience Assisted Service Reliability against Outages",
            "updated": "2023-09-13T18:04:52Z",
            "published": "2023-09-13T18:04:52Z",
            "summary": "Modern cloud services are prone to failures due to their complex\narchitecture, making diagnosis a critical process. Site Reliability Engineers\n(SREs) spend hours leveraging multiple sources of data, including the alerts,\nerror logs, and domain expertise through past experiences to locate the root\ncause(s). These experiences are documented as natural language text in outage\nreports for previous outages. However, utilizing the raw yet rich\nsemi-structured information in the reports systematically is time-consuming.\nStructured information, on the other hand, such as alerts that are often used\nduring fault diagnosis, is voluminous and requires expert knowledge to discern.\nSeveral strategies have been proposed to use each source of data separately for\nroot cause analysis. In this work, we build a diagnostic service called ESRO\nthat recommends root causes and remediation for failures by utilizing\nstructured as well as semi-structured sources of data systematically. ESRO\nconstructs a causal graph using alerts and a knowledge graph using outage\nreports, and merges them in a novel way to form a unified graph during\ntraining. A retrieval-based mechanism is then used to search the unified graph\nand rank the likely root causes and remediation techniques based on the alerts\nfired during an outage at inference time. Not only the individual alerts, but\ntheir respective importance in predicting an outage group is taken into account\nduring recommendation. We evaluated our model on several cloud service outages\nof a large SaaS enterprise over the course of ~2 years, and obtained an average\nimprovement of 27% in rouge scores after comparing the likely root causes\nagainst the ground truth over state-of-the-art baselines. We further establish\nthe effectiveness of ESRO through qualitative analysis on multiple real outage\nexamples.",
            "author": [
                "Sarthak Chakraborty",
                "Shubham Agarwal",
                "Shaddy Garg",
                "Abhimanyu Sethia",
                "Udit Narayan Pandey",
                "Videh Aggarwal",
                "Shiv Saini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07230v1",
                "http://arxiv.org/pdf/2309.07230v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07115v1",
            "title": "Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker\n  Verification",
            "updated": "2023-09-13T17:45:41Z",
            "published": "2023-09-13T17:45:41Z",
            "summary": "In this paper, we present a methodology for achieving robust multimodal\nperson representations optimized for open-set audio-visual speaker\nverification. Distance Metric Learning (DML) approaches have typically\ndominated this problem space, owing to strong performance on new and unseen\nclasses. In our work, we explored multitask learning techniques to further\nboost performance of the DML approach and show that an auxiliary task with weak\nlabels can increase the compactness of the learned speaker representation. We\nalso extend the Generalized end-to-end loss (GE2E) to multimodal inputs and\ndemonstrate that it can achieve competitive performance in an audio-visual\nspace. Finally, we introduce a non-synchronous audio-visual sampling random\nstrategy during training time that has shown to improve generalization. Our\nnetwork achieves state of the art performance for speaker verification,\nreporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official\ntrial lists of VoxCeleb1-O/E/H, which is to our knowledge, the best published\nresults on VoxCeleb1-E and VoxCeleb1-H.",
            "author": [
                "Anith Selvakumar",
                "Homa Fashandi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07115v1",
                "http://arxiv.org/pdf/2309.07115v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07112v1",
            "title": "A statistical mechanics framework for constructing non-equilibrium\n  thermodynamic models",
            "updated": "2023-09-13T17:34:58Z",
            "published": "2023-09-13T17:34:58Z",
            "summary": "Far-from-equilibrium phenomena are critical to all natural and engineered\nsystems, and essential to biological processes responsible for life. For over a\ncentury and a half, since Carnot, Clausius, Maxwell, Boltzmann, and Gibbs,\namong many others, laid the foundation for our understanding of equilibrium\nprocesses, scientists and engineers have dreamed of an analogous treatment of\nnon-equilibrium systems. But despite tremendous efforts, a universal theory of\nnon-equilibrium behavior akin to equilibrium statistical mechanics and\nthermodynamics has evaded description. Several methodologies have proved their\nability to accurately describe complex non-equilibrium systems at the\nmacroscopic scale, but their accuracy and predictive capacity is predicated on\neither phenomenological kinetic equations fit to microscopic data, or on\nrunning concurrent simulations at the particle level. Instead, we provide a\nframework for deriving stand-alone macroscopic thermodynamics models directly\nfrom microscopic physics without fitting in overdamped Langevin systems. The\nonly necessary ingredient is a functional form for a parameterized, approximate\ndensity of states, in analogy to the assumption of a uniform density of states\nin the equilibrium microcanonical ensemble. We highlight this framework's\neffectiveness by deriving analytical approximations for evolving mechanical and\nthermodynamic quantities in a model of coiled-coil proteins and double stranded\nDNA, thus producing, to the authors' knowledge, the first derivation of the\ngoverning equations for a phase propagating system under general loading\nconditions without appeal to phenomenology. The generality of our treatment\nallows for application to any system described by Langevin dynamics with\narbitrary interaction energies and external driving, including colloidal\nmacromolecules, hydrogels, and biopolymers.",
            "author": [
                "Travis Leadbetter",
                "Prashant K. Purohit",
                "Celia Reina"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07112v1",
                "http://arxiv.org/pdf/2309.07112v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07089v1",
            "title": "On the spectra of token graphs of cycles and other graphs",
            "updated": "2023-09-13T17:04:53Z",
            "published": "2023-09-13T17:04:53Z",
            "summary": "The $k$-token graph $F_k(G)$ of a graph $G$ is the graph whose vertices are\nthe $k$-subsets of vertices from $G$, two of which being adjacent whenever\ntheir symmetric difference is a pair of adjacent vertices in $G$. It is a known\nresult that the algebraic connectivity (or second Laplacian eigenvalue) of\n$F_k(G)$ equals the algebraic connectivity of $G$.\n  In this paper, we first give results that relate the algebraic connectivities\nof a token graph and the same graph after removing a vertex. Then, we prove the\nresult on the algebraic connectivity of 2-token graphs for two infinite\nfamilies: the odd graphs $O_r$ for all $r$, and the multipartite complete\ngraphs $K_{n_1,n_2,\\ldots,n_r}$ for all $n_1,n_2,\\ldots,n_r$ In the case of\ncycles, we present a new method that allows us to compute the whole spectrum of\n$F_2(C_n)$. This method also allows us to obtain closed formulas that give\nasymptotically exact approximations for most of the eigenvalues of\n$F_2(\\textit{}C_n)$.",
            "author": [
                "M\u00f3nica. A. Reyes",
                "Cristina Dalf\u00f3",
                "Miquel \u00c0ngel Fiol",
                "Arnau Messegu\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07089v1",
                "http://arxiv.org/pdf/2309.07089v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07201v1",
            "title": "Digital 3D Smocking Design",
            "updated": "2023-09-13T16:23:52Z",
            "published": "2023-09-13T16:23:52Z",
            "summary": "We develop an optimization-based method to model smocking, a surface\nembroidery technique that provides decorative geometric texturing while\nmaintaining stretch properties of the fabric. During smocking, multiple pairs\nof points on the fabric are stitched together, creating non-manifold geometric\nfeatures and visually pleasing textures. Designing smocking patterns is\nchallenging, because the outcome of stitching is unpredictable: the final\ntexture is often revealed only when the whole smocking process is completed,\nnecessitating painstaking physical fabrication and time consuming\ntrial-and-error experimentation. This motivates us to seek a digital smocking\ndesign method. Straightforward attempts to compute smocked fabric geometry\nusing surface deformation or cloth simulation methods fail to produce realistic\nresults, likely due to the intricate structure of the designs, the large number\nof contacts and high-curvature folds. We instead formulate smocking as a graph\nembedding and shape deformation problem. We extract a coarse graph representing\nthe fabric and the stitching constraints, and then derive the graph structure\nof the smocked result. We solve for the 3D embedding of this graph, which in\nturn reliably guides the deformation of the high-resolution fabric mesh. Our\noptimization based method is simple, efficient, and flexible, which allows us\nto build an interactive system for smocking pattern exploration. To demonstrate\nthe accuracy of our method, we compare our results to real fabrications on a\nlarge set of smocking patterns",
            "author": [
                "Jing Ren",
                "Aviv Segall",
                "Olga Sorkine-Hornung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07201v1",
                "http://arxiv.org/pdf/2309.07201v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07056v2",
            "title": "Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into\n  Quantum Experiments",
            "updated": "2023-10-04T18:57:50Z",
            "published": "2023-09-13T16:13:54Z",
            "summary": "Despite their promise to facilitate new scientific discoveries, the\nopaqueness of neural networks presents a challenge in interpreting the logic\nbehind their findings. Here, we use a eXplainable-AI (XAI) technique called\n$inception$ or $deep$ $dreaming$, which has been invented in machine learning\nfor computer vision. We use this technique to explore what neural networks\nlearn about quantum optics experiments. Our story begins by training deep\nneural networks on the properties of quantum systems. Once trained, we \"invert\"\nthe neural network -- effectively asking how it imagines a quantum system with\na specific property, and how it would continuously modify the quantum system to\nchange a property. We find that the network can shift the initial distribution\nof properties of the quantum system, and we can conceptualize the learned\nstrategies of the neural network. Interestingly, we find that, in the first\nlayers, the neural network identifies simple properties, while in the deeper\nones, it can identify complex quantum structures and even quantum entanglement.\nThis is in reminiscence of long-understood properties known in computer vision,\nwhich we now identify in a complex natural science task. Our approach could be\nuseful in a more interpretable way to develop new advanced AI-based scientific\ndiscovery techniques in quantum physics.",
            "author": [
                "Tareq Jaouni",
                "S\u00f6ren Arlt",
                "Carlos Ruiz-Gonzalez",
                "Ebrahim Karimi",
                "Xuemei Gu",
                "Mario Krenn"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07056v2",
                "http://arxiv.org/pdf/2309.07056v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07051v1",
            "title": "UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons",
            "updated": "2023-09-13T16:07:25Z",
            "published": "2023-09-13T16:07:25Z",
            "summary": "The automatic co-speech gesture generation draws much attention in computer\nanimation. Previous works designed network structures on individual datasets,\nwhich resulted in a lack of data volume and generalizability across different\nmotion capture standards. In addition, it is a challenging task due to the weak\ncorrelation between speech and gestures. To address these problems, we present\nUnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis\napproach, trained on multiple gesture datasets with different skeletons.\nSpecifically, we first present a retargeting network to learn latent\nhomeomorphic graphs for different motion capture standards, unifying the\nrepresentations of various gestures while extending the dataset. We then\ncapture the correlation between speech and gestures based on a diffusion model\narchitecture using cross-local attention and self-attention to generate better\nspeech-matched and realistic gestures. To further align speech and gesture and\nincrease diversity, we incorporate reinforcement learning on the discrete\ngesture units with a learned reward function. Extensive experiments show that\nUnifiedGesture outperforms recent approaches on speech-driven gesture\ngeneration in terms of CCA, FGD, and human-likeness. All code, pre-trained\nmodels, databases, and demos are available to the public at\nhttps://github.com/YoungSeng/UnifiedGesture.",
            "author": [
                "Sicheng Yang",
                "Zilin Wang",
                "Zhiyong Wu",
                "Minglei Li",
                "Zhensong Zhang",
                "Qiaochu Huang",
                "Lei Hao",
                "Songcen Xu",
                "Xiaofei Wu",
                "changpeng yang",
                "Zonghong Dai"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612503",
                "http://arxiv.org/abs/2309.07051v1",
                "http://arxiv.org/pdf/2309.07051v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07038v4",
            "title": "Efficient Reinforcement Learning for Jumping Monopods",
            "updated": "2023-10-13T07:54:55Z",
            "published": "2023-09-13T15:46:40Z",
            "summary": "In this work, we consider the complex control problem of making a monopod\nreach a target with a jump. The monopod can jump in any direction and the\nterrain underneath its foot can be uneven. This is a template of a much larger\nclass of problems, which are extremely challenging and computationally\nexpensive to solve using standard optimisation-based techniques. Reinforcement\nLearning (RL) could be an interesting alternative, but the application of an\nend-to-end approach in which the controller must learn everything from scratch,\nis impractical. The solution advocated in this paper is to guide the learning\nprocess within an RL framework by injecting physical knowledge. This expedient\nbrings to widespread benefits, such as a drastic reduction of the learning\ntime, and the ability to learn and compensate for possible errors in the\nlow-level controller executing the motion. We demonstrate the advantage of our\napproach with respect to both optimization-based and end-to-end RL approaches.",
            "author": [
                "Riccardo Bussola",
                "Michele Focchi",
                "Andrea Del Prete",
                "Daniele Fontanelli",
                "Luigi Palopoli"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07038v4",
                "http://arxiv.org/pdf/2309.07038v4"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07030v2",
            "title": "Optimal transport distances for directed, weighted graphs: a case study\n  with cell-cell communication networks",
            "updated": "2023-09-14T09:07:44Z",
            "published": "2023-09-13T15:36:39Z",
            "summary": "Comparing graphs by means of optimal transport has recently gained\nsignificant attention, as the distances induced by optimal transport provide\nboth a principled metric between graphs as well as an interpretable description\nof the associated changes between graphs in terms of a transport plan. As the\nlack of symmetry introduces challenges in the typically considered\nformulations, optimal transport distances for graphs have mostly been developed\nfor undirected graphs. Here, we propose two distance measures to compare\ndirected graphs based on variants of optimal transport: (i) an earth movers\ndistance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance. We evaluate\nthese two distances and discuss their relative performance for both simulated\ngraph data and real-world directed cell-cell communication graphs, inferred\nfrom single-cell RNA-seq data.",
            "author": [
                "James S. Nagai",
                "Ivan G. Costa",
                "Michael T. Schaub"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07030v2",
                "http://arxiv.org/pdf/2309.07030v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "cs.SY",
                "eess.SY",
                "q-bio.GN",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07018v1",
            "title": "Perfect Roman Domination and Unique Response Roman Domination",
            "updated": "2023-09-13T15:19:03Z",
            "published": "2023-09-13T15:19:03Z",
            "summary": "The idea of enumeration algorithms with polynomial delay is to polynomially\nbound the running time between any two subsequent solutions output by the\nenumeration algorithm. While it is open for more than four decades if all\nminimal dominating sets of a graph can be enumerated in output-polynomial time,\nit has recently been proven that pointwise-minimal Roman dominating functions\ncan be enumerated even with polynomial delay. The idea of the enumeration\nalgorithm was to use polynomial-time solvable extension problems. We use this\nas a motivation to prove that also two variants of Roman dominating functions\nstudied in the literature, named perfect and unique response, can be enumerated\nwith polynomial delay. This is interesting since Extension Perfect Roman\nDomination is W[1]-complete if parameterized by the weight of the given\nfunction and even W[2]-complete if parameterized by the number vertices\nassigned 0 in the pre-solution, as we prove. Otherwise, efficient solvability\nof extension problems and enumerability with polynomial delay tend to go\nhand-in-hand. We achieve our enumeration result by constructing a bijection to\nRoman dominating functions, where the corresponding extension problem is\npolynomimaltime solvable. Furthermore, we show that Unique Response Roman\nDomination is solvable in polynomial time on split graphs, while Perfect Roman\nDomination is NP-complete on this graph class, which proves that both\nvariations, albeit coming with a very similar definition, do differ in some\ncomplexity aspects. This way, we also solve an open problem from the\nliterature.",
            "author": [
                "Henning Fernau",
                "Kevin Mann"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07018v1",
                "http://arxiv.org/pdf/2309.07018v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.CC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06998v1",
            "title": "Data-Driven Synthesis of Configuration-Constrained Robust Invariant Sets\n  for Linear Parameter-Varying Systems",
            "updated": "2023-09-13T14:47:07Z",
            "published": "2023-09-13T14:47:07Z",
            "summary": "We present a data-driven method to synthesize robust control invariant (RCI)\nsets for linear parameter-varying (LPV) systems subject to unknown but bounded\ndisturbances. A finite-length data set consisting of state, input, and\nscheduling signal measurements is used to compute an RCI set and\ninvariance-inducing controller, without identifying an LPV model of the system.\nWe parameterize the RCI set as a configuration-constrained polytope whose\nfacets have a fixed orientation and variable offset. This allows us to define\nthe vertices of the polytopic set in terms of its offset. By exploiting this\nproperty, an RCI set and associated vertex control inputs are computed by\nsolving a single linear programming (LP) problem, formulated based on a\ndata-based invariance condition and system constraints. We illustrate the\neffectiveness of our approach via two numerical examples. The proposed method\ncan generate RCI sets that are of comparable size to those obtained by a\nmodel-based method in which exact knowledge of the system matrices is assumed.\nWe show that RCI sets can be synthesized even with a relatively small number of\ndata samples, if the gathered data satisfy certain excitation conditions.",
            "author": [
                "Manas Mejari",
                "Sampath Kumar Mulagaleti",
                "Alberto Bemporad"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06998v1",
                "http://arxiv.org/pdf/2309.06998v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06991v1",
            "title": "Unsupervised Contrast-Consistent Ranking with Language Models",
            "updated": "2023-09-13T14:36:26Z",
            "published": "2023-09-13T14:36:26Z",
            "summary": "Language models contain ranking-based knowledge and are powerful solvers of\nin-context ranking tasks. For instance, they may have parametric knowledge\nabout the ordering of countries by size or may be able to rank reviews by\nsentiment. Recent work focuses on pairwise, pointwise, and listwise prompting\ntechniques to elicit a language model's ranking knowledge. However, we find\nthat even with careful calibration and constrained decoding, prompting-based\ntechniques may not always be self-consistent in the rankings they produce. This\nmotivates us to explore an alternative approach that is inspired by an\nunsupervised probing method called Contrast-Consistent Search (CCS). The idea\nis to train a probing model guided by a logical constraint: a model's\nrepresentation of a statement and its negation must be mapped to contrastive\ntrue-false poles consistently across multiple statements. We hypothesize that\nsimilar constraints apply to ranking tasks where all items are related via\nconsistent pairwise or listwise comparisons. To this end, we extend the binary\nCCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking\nmethods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression\nobjective. Our results confirm that, for the same language model, CCR probing\noutperforms prompting and even performs on a par with prompting much larger\nlanguage models.",
            "author": [
                "Niklas Stoehr",
                "Pengxiang Cheng",
                "Jing Wang",
                "Daniel Preotiuc-Pietro",
                "Rajarshi Bhowmik"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06991v1",
                "http://arxiv.org/pdf/2309.06991v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07197v1",
            "title": "Mitigating Adversarial Attacks in Federated Learning with Trusted\n  Execution Environments",
            "updated": "2023-09-13T14:19:29Z",
            "published": "2023-09-13T14:19:29Z",
            "summary": "The main premise of federated learning (FL) is that machine learning model\nupdates are computed locally to preserve user data privacy. This approach\navoids by design user data to ever leave the perimeter of their device. Once\nthe updates aggregated, the model is broadcast to all nodes in the federation.\nHowever, without proper defenses, compromised nodes can probe the model inside\ntheir local memory in search for adversarial examples, which can lead to\ndangerous real-world scenarios. For instance, in image-based applications,\nadversarial examples consist of images slightly perturbed to the human eye\ngetting misclassified by the local model. These adversarial images are then\nlater presented to a victim node's counterpart model to replay the attack.\nTypical examples harness dissemination strategies such as altered traffic signs\n(patch attacks) no longer recognized by autonomous vehicles or seemingly\nunaltered samples that poison the local dataset of the FL scheme to undermine\nits robustness. Pelta is a novel shielding mechanism leveraging Trusted\nExecution Environments (TEEs) that reduce the ability of attackers to craft\nadversarial samples. Pelta masks inside the TEE the first part of the\nback-propagation chain rule, typically exploited by attackers to craft the\nmalicious samples. We evaluate Pelta on state-of-the-art accurate models using\nthree well-established datasets: CIFAR-10, CIFAR-100 and ImageNet. We show the\neffectiveness of Pelta in mitigating six white-box state-of-the-art adversarial\nattacks, such as Projected Gradient Descent, Momentum Iterative Method, Auto\nProjected Gradient Descent, the Carlini & Wagner attack. In particular, Pelta\nconstitutes the first attempt at defending an ensemble model against the\nSelf-Attention Gradient attack to the best of our knowledge. Our code is\navailable to the research community at https://github.com/queyrusi/Pelta.",
            "author": [
                "Simon Queyrut",
                "Valerio Schiavoni",
                "Pascal Felber"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07197v1",
                "http://arxiv.org/pdf/2309.07197v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06981v1",
            "title": "MASTERKEY: Practical Backdoor Attack Against Speaker Verification\n  Systems",
            "updated": "2023-09-13T14:15:54Z",
            "published": "2023-09-13T14:15:54Z",
            "summary": "Speaker Verification (SV) is widely deployed in mobile systems to\nauthenticate legitimate users by using their voice traits. In this work, we\npropose a backdoor attack MASTERKEY, to compromise the SV models. Different\nfrom previous attacks, we focus on a real-world practical setting where the\nattacker possesses no knowledge of the intended victim. To design MASTERKEY, we\ninvestigate the limitation of existing poisoning attacks against unseen\ntargets. Then, we optimize a universal backdoor that is capable of attacking\narbitrary targets. Next, we embed the speaker's characteristics and semantics\ninformation into the backdoor, making it imperceptible. Finally, we estimate\nthe channel distortion and integrate it into the backdoor. We validate our\nattack on 6 popular SV models. Specifically, we poison a total of 53 models and\nuse our trigger to attack 16,430 enrolled speakers, composed of 310 target\nspeakers enrolled in 53 poisoned models. Our attack achieves 100% attack\nsuccess rate with a 15% poison rate. By decreasing the poison rate to 3%, the\nattack success rate remains around 50%. We validate our attack in 3 real-world\nscenarios and successfully demonstrate the attack through both over-the-air and\nover-the-telephony-line scenarios.",
            "author": [
                "Hanqing Guo",
                "Xun Chen",
                "Junfeng Guo",
                "Li Xiao",
                "Qiben Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06981v1",
                "http://arxiv.org/pdf/2309.06981v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06975v1",
            "title": "Predicting Expressibility of Parameterized Quantum Circuits using Graph\n  Neural Network",
            "updated": "2023-09-13T14:08:01Z",
            "published": "2023-09-13T14:08:01Z",
            "summary": "Parameterized Quantum Circuits (PQCs) are essential to quantum machine\nlearning and optimization algorithms. The expressibility of PQCs, which\nmeasures their ability to represent a wide range of quantum states, is a\ncritical factor influencing their efficacy in solving quantum problems.\nHowever, the existing technique for computing expressibility relies on\nstatistically estimating it through classical simulations, which requires many\nsamples. In this work, we propose a novel method based on Graph Neural Networks\n(GNNs) for predicting the expressibility of PQCs. By leveraging the graph-based\nrepresentation of PQCs, our GNN-based model captures intricate relationships\nbetween circuit parameters and their resulting expressibility. We train the GNN\nmodel on a comprehensive dataset of PQCs annotated with their expressibility\nvalues. Experimental evaluation on a four thousand random PQC dataset and IBM\nQiskit's hardware efficient ansatz sets demonstrates the superior performance\nof our approach, achieving a root mean square error (RMSE) of 0.03 and 0.06,\nrespectively.",
            "author": [
                "Shamminuj Aktar",
                "Andreas B\u00e4rtschi",
                "Abdel-Hameed A. Badawy",
                "Diane Oyen",
                "Stephan Eidenbenz"
            ],
            "link": [
                "http://dx.doi.org/10.1109/QCE57702.2023.10302",
                "http://arxiv.org/abs/2309.06975v1",
                "http://arxiv.org/pdf/2309.06975v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07196v1",
            "title": "Attention-based Dynamic Graph Convolutional Recurrent Neural Network for\n  Traffic Flow Prediction in Highway Transportation",
            "updated": "2023-09-13T13:57:21Z",
            "published": "2023-09-13T13:57:21Z",
            "summary": "As one of the important tools for spatial feature extraction, graph\nconvolution has been applied in a wide range of fields such as traffic flow\nprediction. However, current popular works of graph convolution cannot\nguarantee spatio-temporal consistency in a long period. The ignorance of\ncorrelational dynamics, convolutional locality and temporal comprehensiveness\nwould limit predictive accuracy. In this paper, a novel Attention-based Dynamic\nGraph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve\ntraffic flow prediction in highway transportation. Three temporal resolutions\nof data sequence are effectively integrated by self-attention to extract\ncharacteristics; multi-dynamic graphs and their weights are dynamically created\nto compliantly combine the varying characteristics; a dedicated gated kernel\nemphasizing highly relative nodes is introduced on these complete graphs to\nreduce overfitting for graph convolution operations. Experiments on two public\ndatasets show our work better than state-of-the-art baselines, and case studies\nof a real Web system prove practical benefit in highway transportation.",
            "author": [
                "Tianpu Zhang",
                "Weilong Ding",
                "Mengda Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07196v1",
                "http://arxiv.org/pdf/2309.07196v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06959v1",
            "title": "Tur\u00e1n Colourings in Off-Diagonal Ramsey Multiplicity",
            "updated": "2023-09-13T13:49:22Z",
            "published": "2023-09-13T13:49:22Z",
            "summary": "The Ramsey multiplicity constant of a graph $H$ is the limit as $n$ tends to\ninfinity of the minimum density of monochromatic labelled copies of $H$ in a\ncolouring of the edges of $K_n$ with two colours. Fox and Wigderson recently\nidentified a large family of graphs whose Ramsey multiplicity constants are\nattained by sequences of \"Tur\\'an colourings;\" i.e. colourings in which one of\nthe colour classes forms the edge set of a balanced complete multipartite\ngraph. The graphs in their family come from taking a connected non-3-colourable\ngraph with a critical edge and adding many pendant edges. We extend their\nresult to an off-diagonal variant of the Ramsey multiplicity constant which\ninvolves minimizing a weighted sum of red copies of one graph and blue copies\nof another. We also apply the flag algebra method to investigate the minimum\nnumber of pendant edges required for Tur\\'an colourings to become optimal when\nthe underlying graphs are small cliques.",
            "author": [
                "Joseph Hyde",
                "Jae-baek Lee",
                "Jonathan A. Noel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06959v1",
                "http://arxiv.org/pdf/2309.06959v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35, 05D10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06957v1",
            "title": "Harvesting Brownian Motion: Zero Energy Computational Sampling",
            "updated": "2023-09-13T13:43:36Z",
            "published": "2023-09-13T13:43:36Z",
            "summary": "The key factor currently limiting the advancement of computational power of\nelectronic computation is no longer the manufacturing density and speed of\ncomponents, but rather their high energy consumption. While it has been widely\nargued that reversible computation can escape the fundamental Landauer limit of\n$k_B T\\ln(2)$ Joules per irreversible computational step, there is disagreement\naround whether indefinitely reusable computation can be achieved without energy\ndissipation. Here we focus on the relatively simpler context of sampling\nproblems, which take no input, so avoids modeling the energy costs of the\nobserver perturbing the machine to change its input. Given an algorithm $A$ for\ngenerating samples from a distribution, we desire a device that can perpetually\ngenerate samples from that distribution driven entirely by Brownian motion. We\nshow that such a device can efficiently execute algorithm $A$ in the sense that\nwe must wait only $O(\\text{time}(A)^2)$ between samples. We consider two output\nmodels: Las Vegas, which samples from the exact probability distribution every\n$4$ tries in expectation, and Monte Carlo, in which every try succeeds but the\ndistribution is only approximated. We base our model on continuous-time random\nwalks over the state space graph of a general computational machine, with a\nspace-bounded Turing machine as one instantiation. The problem of sampling a\ncomputationally complex probability distribution with no energy dissipation\ninforms our understanding of the energy requirements of computation, and may\nlead to more energy efficient randomized algorithms.",
            "author": [
                "David Doty",
                "Niels Kornerup",
                "Austin Luchsinger",
                "Leo Orshansky",
                "David Soloveichik",
                "Damien Woods"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06957v1",
                "http://arxiv.org/pdf/2309.06957v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.ET",
                "60J28",
                "G.3; F.1.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06954v1",
            "title": "Limit-closed Profiles",
            "updated": "2023-09-13T13:41:07Z",
            "published": "2023-09-13T13:41:07Z",
            "summary": "Tangle-tree theorems are an important tool in structural graph theory, and\nabstract separation systems are a very general setting in which tangle-tree\ntheorems can still be formulated and proven. For infinite abstract separation\nsystems, so far tangle-tree theorems have only been shown for special cases of\nseparation systems, in particular when the separation system arises from a\n(locally finite) infinite graph. We present a tangle-tree theorem for infinite\nseparation systems where we do not place restrictions on the separation system\nitself but on the tangles to be arranged in a tree.",
            "author": [
                "Ann-Kathrin Elm",
                "Hendrik Heine"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06954v1",
                "http://arxiv.org/pdf/2309.06954v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "06-XX (Primary) 05C63, 05C05 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06952v1",
            "title": "Anisotropic Viscosities Estimation for the Stochastic Primitive\n  Equations",
            "updated": "2023-09-13T13:35:03Z",
            "published": "2023-09-13T13:35:03Z",
            "summary": "The viscosity parameters plays a fundamental role in applications involving\nstochastic primitive equations (SPE), such as accurate weather predictions,\nclimate modeling, and ocean current simulations. In this paper, we develop\nseveral novel estimators for the anisotropic viscosities in the SPE, using\nfinite number of Fourier modes of a single sample path observed within a finite\ntime interval. The focus is on analyzing the consistency and asymptotic\nnormality of these estimators. We consider a torus domain and treat strong,\npathwise solutions in the presence of additive white noise (in time). Notably,\nthe analysis for estimating horizontal and vertical viscosities differs due to\nthe unique structure of the SPE, as well as the fact that both parameters of\ninterest are next to the highest order derivative. To the best of our\nknowledge, this is the first work addressing the estimation of anisotropic\nviscosities, with potential applicability of the methodology to other modeling.",
            "author": [
                "Igor Cialenco",
                "Ruimeng Hu",
                "Quyuan Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06952v1",
                "http://arxiv.org/pdf/2309.06952v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06944v1",
            "title": "Three-cuts are a charm: acyclicity in 3-connected cubic graphs",
            "updated": "2023-09-13T13:28:15Z",
            "published": "2023-09-13T13:28:15Z",
            "summary": "Let $G$ be a bridgeless cubic graph. In 2023, the three authors solved a\nconjecture (also known as the $S_4$-Conjecture) made by Mazzuoccolo in 2013:\nthere exist two perfect matchings of $G$ such that the complement of their\nunion is a bipartite subgraph of $G$. They actually show that given any\n$1^+$-factor $F$ (a spanning subgraph of $G$ such that its vertices have degree\nat least 1) and an arbitrary edge $e$ of $G$, there exists a perfect matching\n$M$ of $G$ containing $e$ such that $G\\setminus (F\\cup M)$ is bipartite. This\nis a step closer to comprehend better the Fan--Raspaud Conjecture and\neventually the Berge--Fulkerson Conjecture. The $S_4$-Conjecture, now a\ntheorem, is also the weakest assertion in a series of three conjectures made by\nMazzuoccolo in 2013, with the next stronger statement being: there exist two\nperfect matchings of $G$ such that the complement of their union is an acyclic\nsubgraph of $G$. Unfortunately, this conjecture is not true: Jin, Steffen, and\nMazzuoccolo later showed that there exists a counterexample admitting 2-cuts.\nHere we show that, despite of this, every cyclically 3-edge-connected cubic\ngraph satisfies this second conjecture.",
            "author": [
                "Franti\u0161ek Kardo\u0161",
                "Edita M\u00e1\u010dajov\u00e1",
                "Jean Paul Zerafa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06944v1",
                "http://arxiv.org/pdf/2309.06944v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15, 05C70"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06930v1",
            "title": "Modeling Dislocation Dynamics Data Using Semantic Web Technologies",
            "updated": "2023-09-13T13:03:44Z",
            "published": "2023-09-13T13:03:44Z",
            "summary": "Research in the field of Materials Science and Engineering focuses on the\ndesign, synthesis, properties, and performance of materials. An important class\nof materials that is widely investigated are crystalline materials, including\nmetals and semiconductors. Crystalline material typically contains a distinct\ntype of defect called \"dislocation\". This defect significantly affects various\nmaterial properties, including strength, fracture toughness, and ductility.\nResearchers have devoted a significant effort in recent years to understanding\ndislocation behavior through experimental characterization techniques and\nsimulations, e.g., dislocation dynamics simulations. This paper presents how\ndata from dislocation dynamics simulations can be modeled using semantic web\ntechnologies through annotating data with ontologies. We extend the already\nexisting Dislocation Ontology by adding missing concepts and aligning it with\ntwo other domain-related ontologies (i.e., the Elementary Multi-perspective\nMaterial Ontology and the Materials Design Ontology) allowing for representing\nthe dislocation simulation data efficiently. Moreover, we show a real-world use\ncase by representing the discrete dislocation dynamics data as a knowledge\ngraph (DisLocKG) that illustrates the relationship between them. We also\ndeveloped a SPARQL endpoint that brings extensive flexibility to query\nDisLocKG.",
            "author": [
                "Ahmad Zainul Ihsan",
                "Said Fathalla",
                "Stefan Sandfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06930v1",
                "http://arxiv.org/pdf/2309.06930v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06928v1",
            "title": "Dynamic Causal Disentanglement Model for Dialogue Emotion Detection",
            "updated": "2023-09-13T12:58:09Z",
            "published": "2023-09-13T12:58:09Z",
            "summary": "Emotion detection is a critical technology extensively employed in diverse\nfields. While the incorporation of commonsense knowledge has proven beneficial\nfor existing emotion detection methods, dialogue-based emotion detection\nencounters numerous difficulties and challenges due to human agency and the\nvariability of dialogue content.In dialogues, human emotions tend to accumulate\nin bursts. However, they are often implicitly expressed. This implies that many\ngenuine emotions remain concealed within a plethora of unrelated words and\ndialogues.In this paper, we propose a Dynamic Causal Disentanglement Model\nbased on hidden variable separation, which is founded on the separation of\nhidden variables. This model effectively decomposes the content of dialogues\nand investigates the temporal accumulation of emotions, thereby enabling more\nprecise emotion recognition. First, we introduce a novel Causal Directed\nAcyclic Graph (DAG) to establish the correlation between hidden emotional\ninformation and other observed elements. Subsequently, our approach utilizes\npre-extracted personal attributes and utterance topics as guiding factors for\nthe distribution of hidden variables, aiming to separate irrelevant ones.\nSpecifically, we propose a dynamic temporal disentanglement model to infer the\npropagation of utterances and hidden variables, enabling the accumulation of\nemotion-related information throughout the conversation. To guide this\ndisentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to\nextract utterance topics and personal attributes as observed\ninformation.Finally, we test our approach on two popular datasets in dialogue\nemotion detection and relevant experimental results verified the model's\nsuperiority.",
            "author": [
                "Yuting Su",
                "Yichen Wei",
                "Weizhi Nie",
                "Sicheng Zhao",
                "Anan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06928v1",
                "http://arxiv.org/pdf/2309.06928v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06924v1",
            "title": "Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote\n  Physiological Measurement via Spatiotemporal Contrast",
            "updated": "2023-09-13T12:50:21Z",
            "published": "2023-09-13T12:50:21Z",
            "summary": "Video-based remote physiological measurement utilizes facial videos to\nmeasure the blood volume change signal, which is also called remote\nphotoplethysmography (rPPG). Supervised methods for rPPG measurements have been\nshown to achieve good performance. However, the drawback of these methods is\nthat they require facial videos with ground truth (GT) physiological signals,\nwhich are often costly and difficult to obtain. In this paper, we propose\nContrast-Phys+, a method that can be trained in both unsupervised and\nweakly-supervised settings. We employ a 3DCNN model to generate multiple\nspatiotemporal rPPG signals and incorporate prior knowledge of rPPG into a\ncontrastive loss function. We further incorporate the GT signals into\ncontrastive learning to adapt to partial or misaligned labels. The contrastive\nloss encourages rPPG/GT signals from the same video to be grouped together,\nwhile pushing those from different videos apart. We evaluate our methods on\nfive publicly available datasets that include both RGB and Near-infrared\nvideos. Contrast-Phys+ outperforms the state-of-the-art supervised methods,\neven when using partially available or misaligned GT signals, or no labels at\nall. Additionally, we highlight the advantages of our methods in terms of\ncomputational efficiency, noise robustness, and generalization.",
            "author": [
                "Zhaodong Sun",
                "Xiaobai Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06924v1",
                "http://arxiv.org/pdf/2309.06924v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06918v1",
            "title": "Lotaru: Locally Predicting Workflow Task Runtimes for Resource\n  Management on Heterogeneous Infrastructures",
            "updated": "2023-09-13T12:30:27Z",
            "published": "2023-09-13T12:30:27Z",
            "summary": "Many resource management techniques for task scheduling, energy and carbon\nefficiency, and cost optimization in workflows rely on a-priori task runtime\nknowledge. Building runtime prediction models on historical data is often not\nfeasible in practice as workflows, their input data, and the cluster\ninfrastructure change. Online methods, on the other hand, which estimate task\nruntimes on specific machines while the workflow is running, have to cope with\na lack of measurements during start-up. Frequently, scientific workflows are\nexecuted on heterogeneous infrastructures consisting of machines with different\nCPU, I/O, and memory configurations, further complicating predicting runtimes\ndue to different task runtimes on different machine types.\n  This paper presents Lotaru, a method for locally predicting the runtimes of\nscientific workflow tasks before they are executed on heterogeneous compute\nclusters. Crucially, our approach does not rely on historical data and copes\nwith a lack of training data during the start-up. To this end, we use\nmicrobenchmarks, reduce the input data to quickly profile the workflow locally,\nand predict a task's runtime with a Bayesian linear regression based on the\ngathered data points from the local workflow execution and the microbenchmarks.\nDue to its Bayesian approach, Lotaru provides uncertainty estimates that can be\nused for advanced scheduling methods on distributed cluster infrastructures.\n  In our evaluation with five real-world scientific workflows, our method\noutperforms two state-of-the-art runtime prediction baselines and decreases the\nabsolute prediction error by more than 12.5%. In a second set of experiments,\nthe prediction performance of our method, using the predicted runtimes for\nstate-of-the-art scheduling, carbon reduction, and cost prediction, enables\nresults close to those achieved with perfect prior knowledge of runtimes.",
            "author": [
                "Jonathan Bader",
                "Fabian Lehmann",
                "Lauritz Thamsen",
                "Ulf Leser",
                "Odej Kao"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.future.2023.08.022",
                "http://arxiv.org/abs/2309.06918v1",
                "http://arxiv.org/pdf/2309.06918v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06917v1",
            "title": "Continual Learning with Dirichlet Generative-based Rehearsal",
            "updated": "2023-09-13T12:30:03Z",
            "published": "2023-09-13T12:30:03Z",
            "summary": "Recent advancements in data-driven task-oriented dialogue systems (ToDs)\nstruggle with incremental learning due to computational constraints and\ntime-consuming issues. Continual Learning (CL) attempts to solve this by\navoiding intensive pre-training, but it faces the problem of catastrophic\nforgetting (CF). While generative-based rehearsal CL methods have made\nsignificant strides, generating pseudo samples that accurately reflect the\nunderlying task-specific distribution is still a challenge. In this paper, we\npresent Dirichlet Continual Learning (DCL), a novel generative-based rehearsal\nstrategy for CL. Unlike the traditionally used Gaussian latent variable in the\nConditional Variational Autoencoder (CVAE), DCL leverages the flexibility and\nversatility of the Dirichlet distribution to model the latent prior variable.\nThis enables it to efficiently capture sentence-level features of previous\ntasks and effectively guide the generation of pseudo samples. In addition, we\nintroduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based\nknowledge distillation method that enhances knowledge transfer during pseudo\nsample generation. Our experiments confirm the efficacy of our approach in both\nintent detection and slot-filling tasks, outperforming state-of-the-art\nmethods.",
            "author": [
                "Min Zeng",
                "Wei Xue",
                "Qifeng Liu",
                "Yike Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06917v1",
                "http://arxiv.org/pdf/2309.06917v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06912v1",
            "title": "Multi-behavior Recommendation with SVD Graph Neural Networks",
            "updated": "2023-09-13T12:22:14Z",
            "published": "2023-09-13T12:22:14Z",
            "summary": "Graph Neural Networks (GNNs) has been extensively employed in the field of\nrecommender systems, offering users personalized recommendations and yielding\nremarkable outcomes. Recently, GNNs incorporating contrastive learning have\ndemonstrated promising performance in handling sparse data problem of\nrecommendation system. However, existing contrastive learning methods still\nhave limitations in addressing the cold-start problem and resisting noise\ninterference especially for multi-behavior recommendation. To mitigate the\naforementioned issues, the present research posits a GNNs based multi-behavior\nrecommendation model MB-SVD that utilizes Singular Value Decomposition (SVD)\ngraphs to enhance model performance. In particular, MB-SVD considers user\npreferences under different behaviors, improving recommendation effectiveness\nwhile better addressing the cold-start problem. Our model introduces an\ninnovative methodology, which subsume multi-behavior contrastive learning\nparadigm to proficiently discern the intricate interconnections among\nheterogeneous manifestations of user behavior and generates SVD graphs to\nautomate the distillation of crucial multi-behavior self-supervised information\nfor robust graph augmentation. Furthermore, the SVD based framework reduces the\nembedding dimensions and computational load. Thorough experimentation showcases\nthe remarkable performance of our proposed MB-SVD approach in multi-behavior\nrecommendation endeavors across diverse real-world datasets.",
            "author": [
                "Shengxi Fu",
                "Qianqian Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06912v1",
                "http://arxiv.org/pdf/2309.06912v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06904v1",
            "title": "Strong arc decompositions of split digraphs",
            "updated": "2023-09-13T12:05:23Z",
            "published": "2023-09-13T12:05:23Z",
            "summary": "A {\\bf strong arc decomposition} of a digraph $D=(V,A)$ is a partition of its\narc set $A$ into two sets $A_1,A_2$ such that the digraph $D_i=(V,A_i)$ is\nstrong for $i=1,2$. Bang-Jensen and Yeo (2004) conjectured that there is some\n$K$ such that every $K$-arc-strong digraph has a strong arc decomposition. They\nalso proved that with one exception on 4 vertices every 2-arc-strong\nsemicomplete digraph has a strong arc decomposition. Bang-Jensen and Huang\n(2010) extended this result to locally semicomplete digraphs by proving that\nevery 2-arc-strong locally semicomplete digraph which is not the square of an\neven cycle has a strong arc decomposition. This implies that every 3-arc-strong\nlocally semicomplete digraph has a strong arc decomposition. A {\\bf split\ndigraph} is a digraph whose underlying undirected graph is a split graph,\nmeaning that its vertices can be partioned into a clique and an independent\nset. Equivalently, a split digraph is any digraph which can be obtained from a\nsemicomplete digraph $D=(V,A)$ by adding a new set $V'$ of vertices and some\narcs between $V'$ and $V$. In this paper we prove that every 3-arc-strong split\ndigraph has a strong arc decomposition which can be found in polynomial time\nand we provide infinite classes of 2-strong split digraphs with no strong arc\ndecomposition. We also pose a number of open problems on split digraphs.",
            "author": [
                "Joergen Bang-Jensen",
                "Yun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06904v1",
                "http://arxiv.org/pdf/2309.06904v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C20, 05C40, 05C85"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06896v1",
            "title": "Domain-Aware Augmentations for Unsupervised Online General Continual\n  Learning",
            "updated": "2023-09-13T11:45:21Z",
            "published": "2023-09-13T11:45:21Z",
            "summary": "Continual Learning has been challenging, especially when dealing with\nunsupervised scenarios such as Unsupervised Online General Continual Learning\n(UOGCL), where the learning agent has no prior knowledge of class boundaries or\ntask change information. While previous research has focused on reducing\nforgetting in supervised setups, recent studies have shown that self-supervised\nlearners are more resilient to forgetting. This paper proposes a novel approach\nthat enhances memory usage for contrastive learning in UOGCL by defining and\nusing stream-dependent data augmentations together with some implementation\ntricks. Our proposed method is simple yet effective, achieves state-of-the-art\nresults compared to other unsupervised approaches in all considered setups, and\nreduces the gap between supervised and unsupervised continual learning. Our\ndomain-aware augmentation procedure can be adapted to other replay-based\nmethods, making it a promising strategy for continual learning.",
            "author": [
                "Nicolas Michel",
                "Romain Negrel",
                "Giovanni Chierchia",
                "Jean-Fran\u00e7ois Bercher"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06896v1",
                "http://arxiv.org/pdf/2309.06896v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06891v1",
            "title": "Keep It SimPool: Who Said Supervised Transformers Suffer from Attention\n  Deficit?",
            "updated": "2023-09-13T11:28:27Z",
            "published": "2023-09-13T11:28:27Z",
            "summary": "Convolutional networks and vision transformers have different forms of\npairwise interactions, pooling across layers and pooling at the end of the\nnetwork. Does the latter really need to be different? As a by-product of\npooling, vision transformers provide spatial attention for free, but this is\nmost often of low quality unless self-supervised, which is not well studied. Is\nsupervision really the problem?\n  In this work, we develop a generic pooling framework and then we formulate a\nnumber of existing methods as instantiations. By discussing the properties of\neach group of methods, we derive SimPool, a simple attention-based pooling\nmechanism as a replacement of the default one for both convolutional and\ntransformer encoders. We find that, whether supervised or self-supervised, this\nimproves performance on pre-training and downstream tasks and provides\nattention maps delineating object boundaries in all cases. One could thus call\nSimPool universal. To our knowledge, we are the first to obtain attention maps\nin supervised transformers of at least as good quality as self-supervised,\nwithout explicit losses or modifying the architecture. Code at:\nhttps://github.com/billpsomas/simpool.",
            "author": [
                "Bill Psomas",
                "Ioannis Kakogeorgiou",
                "Konstantinos Karantzalos",
                "Yannis Avrithis"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06891v1",
                "http://arxiv.org/pdf/2309.06891v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06888v1",
            "title": "OWL Reasoners still useable in 2023",
            "updated": "2023-09-13T11:22:42Z",
            "published": "2023-09-13T11:22:42Z",
            "summary": "In a systematic literature and software review over 100 OWL reasoners/systems\nwere analyzed to see if they would still be usable in 2023. This has never been\ndone in this capacity. OWL reasoners still play an important role in knowledge\norganisation and management, but the last comprehensive surveys/studies are\nmore than 8 years old. The result of this work is a comprehensive list of 95\nstandalone OWL reasoners and systems using an OWL reasoner. For each item,\ninformation on project pages, source code repositories and related\ndocumentation was gathered. The raw research data is provided in a Github\nrepository for anyone to use.",
            "author": [
                "Konrad Abicht"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06888v1",
                "http://arxiv.org/pdf/2309.06888v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06887v1",
            "title": "Utilizing Hybrid Trajectory Prediction Models to Recognize Highly\n  Interactive Traffic Scenarios",
            "updated": "2023-09-13T11:22:31Z",
            "published": "2023-09-13T11:22:31Z",
            "summary": "Autonomous vehicles hold great promise in improving the future of\ntransportation. The driving models used in these vehicles are based on neural\nnetworks, which can be difficult to validate. However, ensuring the safety of\nthese models is crucial. Traditional field tests can be costly, time-consuming,\nand dangerous. To address these issues, scenario-based closed-loop simulations\ncan simulate many hours of vehicle operation in a shorter amount of time and\nallow for specific investigation of important situations. Nonetheless, the\ndetection of relevant traffic scenarios that also offer substantial testing\nbenefits remains a significant challenge. To address this need, in this paper\nwe build an imitation learning based trajectory prediction for traffic\nparticipants. We combine an image-based (CNN) approach to represent spatial\nenvironmental factors and a graph-based (GNN) approach to specifically\nrepresent relations between traffic participants. In our understanding, traffic\nscenes that are highly interactive due to the network's significant utilization\nof the social component are more pertinent for a validation process. Therefore,\nwe propose to use the activity of such sub networks as a measure of\ninteractivity of a traffic scene. We evaluate our model using a motion dataset\nand discuss the value of the relationship information with respect to different\ntraffic situations.",
            "author": [
                "Maximilian Zipfl",
                "Sven Spickermann",
                "J. Marius Z\u00f6llner"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06887v1",
                "http://arxiv.org/pdf/2309.06887v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06867v1",
            "title": "Robustness for Spectral Clustering of General Graphs under Local\n  Differential Privacy",
            "updated": "2023-09-13T10:23:29Z",
            "published": "2023-09-13T10:23:29Z",
            "summary": "Spectral clustering is a widely used algorithm to find clusters in networks.\nSeveral researchers have studied the stability of spectral clustering under\nlocal differential privacy with the additional assumption that the underlying\nnetworks are generated from the stochastic block model (SBM). However, we argue\nthat this assumption is too restrictive since social networks do not originate\nfrom the SBM. Thus, delve into an analysis for general graphs in this work. Our\nprimary focus is the edge flipping method -- a common technique for protecting\nlocal differential privacy. On a positive side, our findings suggest that even\nwhen the edges of an $n$-vertex graph satisfying some reasonable\nwell-clustering assumptions are flipped with a probability of $O(\\log n/n)$,\nthe clustering outcomes are largely consistent. Empirical tests further\ncorroborate these theoretical findings. Conversely, although clustering\noutcomes have been stable for dense and well-clustered graphs produced from the\nSBM, we show that in general, spectral clustering may yield highly erratic\nresults on certain dense and well-clustered graphs when the flipping\nprobability is $\\omega(\\log n/n)$. This indicates that the best privacy budget\nobtainable for general graphs is $\\Theta(\\log n)$.",
            "author": [
                "Sayan Mukherjee",
                "Vorapong Suppakitpaisarn"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06867v1",
                "http://arxiv.org/pdf/2309.06867v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SI",
                "68P27"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06854v1",
            "title": "Nonlinear network identifiability: The static case",
            "updated": "2023-09-13T10:01:25Z",
            "published": "2023-09-13T10:01:25Z",
            "summary": "We analyze the problem of network identifiability with nonlinear functions\nassociated with the edges. We consider a static model for the output of each\nnode and by assuming a perfect identification of the function associated with\nthe measurement of a node, we provide conditions for the identifiability of the\nedges in a specific class of functions. First, we analyze the identifiability\nconditions in the class of all nonlinear functions and show that even for a\npath graph, it is necessary to measure all the nodes except by the source.\nThen, we consider analytic functions satisfying $f(0)=0$ and we provide\nconditions for the identifiability of paths and trees. Finally, by restricting\nthe problem to a smaller class of functions where none of the functions is\nlinear, we derive conditions for the identifiability of directed acyclic\ngraphs. Some examples are presented to illustrate the results.",
            "author": [
                "Renato Vizuete",
                "Julien M. Hendrickx"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06854v1",
                "http://arxiv.org/pdf/2309.06854v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06843v1",
            "title": "Stepwise Model Reconstruction of Robotic Manipulator Based on\n  Data-Driven Method",
            "updated": "2023-09-13T09:48:33Z",
            "published": "2023-09-13T09:48:33Z",
            "summary": "Research on dynamics of robotic manipulators provides promising support for\nmodel-based control. In general, rigorous first-principles-based dynamics\nmodeling and accurate identification of mechanism parameters are critical to\nachieving high precision in model-based control, while data-driven model\nreconstruction provides alternative approaches of the above process. Taking the\nlevel of activation of data as an indicator, this paper classifies the\ncollected robotic manipulator data by means of K-means clustering algorithm.\nWith the fundamental prior knowledge, we find the corresponding dynamical\nproperties behind the classified data separately. Afterwards, the sparse\nidentification of nonlinear dynamics (SINDy) method is used to reconstruct the\ndynamics model of the robotic manipulator step by step according to the\nactivation level of the classified data. The simulation results show that the\nproposed method not only reduces the complexity of the basis function library,\nenabling the application of SINDy method to multi-degree-of-freedom robotic\nmanipulators, but also decreases the influence of data noise on the regression\nresults. Finally, the dynamic control based on the reconfigured model is\ndeployed on the experimental platform, and the experimental results prove the\neffectiveness of the proposed method.",
            "author": [
                "Dingxu Guo",
                "Jian xu",
                "Shu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06843v1",
                "http://arxiv.org/pdf/2309.06843v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06833v1",
            "title": "Agnostic detection of large-scale weather patterns in the northern\n  hemisphere: from blockings to teleconnections",
            "updated": "2023-09-13T09:32:55Z",
            "published": "2023-09-13T09:32:55Z",
            "summary": "Detecting recurrent weather patterns and understanding the transitions\nbetween such regimes are key to advancing our knowledge on the low-frequency\nvariability of the atmosphere and have important implications in terms of\nweather and climate-related risks. We adapt an analysis pipeline inspired by\nMarkov State Modelling and detect in an unsupervised manner the dominant winter\nmid-latitude Northern Hemisphere weather patterns in the Atlantic and Pacific\nsectors, defined by the slowest decaying modes of a suitable projection on a\ndiscrete basis of the weather dynamics. When focusing on a longitudinal window\nof 60$^\\circ$, we recognise, first and foremost, a longitude-dependent estimate\nof the slowest relaxation times, which are often related with transitions\nbetween blocked regimes and zonal flow. We analyze in detail the Atlantic and\nPacific sectors, finding, additionally, clear evidence of the strong connection\nbetween blockings in the two regions. When the analysis is performed in a\nbroader geographical region of the Atlantic sector, we detect teleconnection\npatterns like the North Atlantic Oscillation and a large-scale mode of\nvariability alternating between Scandinavian and Greenland blocking. The\napproach proposed here has great potential for intercomparing climate models\nand for assessing the impact of climate change on the low-frequency variability\nof the atmosphere.",
            "author": [
                "Sebastian Springer",
                "Vera Melinda Galfi",
                "Alessandro Laio",
                "Valerio Lucarini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06833v1",
                "http://arxiv.org/pdf/2309.06833v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cond-mat.stat-mech",
                "physics.data-an",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06829v1",
            "title": "Sparse graphs and the fixed points on type spaces property",
            "updated": "2023-09-13T09:26:11Z",
            "published": "2023-09-13T09:26:11Z",
            "summary": "We examine the topological dynamics of the automorphism groups of\nomega-categorical sparse graphs resulting from Hrushovski constructions.\nSpecifically, we consider the fixed points on type spaces property, which a\nstructure M has if, for each positive integer n, every Aut(M)-subflow of the\nspace of n-types has a fixed point. Extending a result of Evans, Hubicka and\nNesetril, we show that there exists an omega-categorical structure M, resulting\nfrom a Hrushovski construction, such that no omega-categorical expansion of M\nhas the fixed points on type spaces property.",
            "author": [
                "Rob Sullivan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06829v1",
                "http://arxiv.org/pdf/2309.06829v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "03C15, 37B05, 20B27, 05C55, 05D10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06828v1",
            "title": "UniBrain: Universal Brain MRI Diagnosis with Hierarchical\n  Knowledge-enhanced Pre-training",
            "updated": "2023-09-13T09:22:49Z",
            "published": "2023-09-13T09:22:49Z",
            "summary": "Magnetic resonance imaging~(MRI) have played a crucial role in brain disease\ndiagnosis, with which a range of computer-aided artificial intelligence methods\nhave been proposed. However, the early explorations usually focus on the\nlimited types of brain diseases in one study and train the model on the data in\na small scale, yielding the bottleneck of generalization. Towards a more\neffective and scalable paradigm, we propose a hierarchical knowledge-enhanced\npre-training framework for the universal brain MRI diagnosis, termed as\nUniBrain. Specifically, UniBrain leverages a large-scale dataset of 24,770\nimaging-report pairs from routine diagnostics. Different from previous\npre-training techniques for the unitary vision or textual feature, or with the\nbrute-force alignment between vision and language information, we leverage the\nunique characteristic of report information in different granularity to build a\nhierarchical alignment mechanism, which strengthens the efficiency in feature\nlearning. Our UniBrain is validated on three real world datasets with severe\nclass imbalance and the public BraTS2019 dataset. It not only consistently\noutperforms all state-of-the-art diagnostic methods by a large margin and\nprovides a superior grounding performance but also shows comparable performance\ncompared to expert radiologists on certain disease types.",
            "author": [
                "Jiayu Lei",
                "Lisong Dai",
                "Haoyun Jiang",
                "Chaoyi Wu",
                "Xiaoman Zhang",
                "Yao Zhang",
                "Jiangchao Yao",
                "Weidi Xie",
                "Yanyong Zhang",
                "Yuehua Li",
                "Ya Zhang",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06828v1",
                "http://arxiv.org/pdf/2309.06828v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06814v1",
            "title": "Comparative Analysis of Contextual Relation Extraction based on Deep\n  Learning Models",
            "updated": "2023-09-13T09:05:09Z",
            "published": "2023-09-13T09:05:09Z",
            "summary": "Contextual Relation Extraction (CRE) is mainly used for constructing a\nknowledge graph with a help of ontology. It performs various tasks such as\nsemantic search, query answering, and textual entailment. Relation extraction\nidentifies the entities from raw texts and the relations among them. An\nefficient and accurate CRE system is essential for creating domain knowledge in\nthe biomedical industry. Existing Machine Learning and Natural Language\nProcessing (NLP) techniques are not suitable to predict complex relations from\nsentences that consist of more than two relations and unspecified entities\nefficiently. In this work, deep learning techniques have been used to identify\nthe appropriate semantic relation based on the context from multiple sentences.\nEven though various machine learning models have been used for relation\nextraction, they provide better results only for binary relations, i.e.,\nrelations occurred exactly between the two entities in a sentence. Machine\nlearning models are not suited for complex sentences that consist of the words\nthat have various meanings. To address these issues, hybrid deep learning\nmodels have been used to extract the relations from complex sentence\neffectively. This paper explores the analysis of various deep learning models\nthat are used for relation extraction.",
            "author": [
                "R. Priyadharshini",
                "G. Jeyakodi",
                "P. Shanthi Bala"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06814v1",
                "http://arxiv.org/pdf/2309.06814v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06804v1",
            "title": "Block-and-hole graphs: Constructibility and $(3,0)$-sparsity",
            "updated": "2023-09-13T08:50:50Z",
            "published": "2023-09-13T08:50:50Z",
            "summary": "We show that minimally 3-rigid block-and-hole graphs, with one block or one\nhole, are characterised as those which are constructible from $K_3$ by vertex\nsplitting, and also, as those having associated looped face graphs which are\n$(3,0)$-tight. This latter property can be verified in polynomial time by a\nform of pebble game algorithm. We also indicate connections to the rigidity\nproperties of polyhedral surfaces known as origami and to graph rigidity in\n$\\ell_p^3$ for $p\\not=2$.",
            "author": [
                "Bryan Gin-ge Chen",
                "James Cruickshank",
                "Derek Kitson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06804v1",
                "http://arxiv.org/pdf/2309.06804v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "52C25 (Primary) 05C10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06801v1",
            "title": "Defensive Alliances in Signed Networks",
            "updated": "2023-09-13T08:49:02Z",
            "published": "2023-09-13T08:49:02Z",
            "summary": "The analysis of (social) networks and multi-agent systems is a central theme\nin Artificial Intelligence. Some line of research deals with finding groups of\nagents that could work together to achieve a certain goal. To this end,\ndifferent notions of so-called clusters or communities have been introduced in\nthe literature of graphs and networks. Among these, defensive alliance is a\nkind of quantitative group structure. However, all studies on the alliance so\nfor have ignored one aspect that is central to the formation of alliances on a\nvery intuitive level, assuming that the agents are preconditioned concerning\ntheir attitude towards other agents: they prefer to be in some group (alliance)\ntogether with the agents they like, so that they are happy to help each other\ntowards their common aim, possibly then working against the agents outside of\ntheir group that they dislike. Signed networks were introduced in the\npsychology literature to model liking and disliking between agents,\ngeneralizing graphs in a natural way. Hence, we propose the novel notion of a\ndefensive alliance in the context of signed networks. We then investigate\nseveral natural algorithmic questions related to this notion. These, and also\ncombinatorial findings, connect our notion to that of correlation clustering,\nwhich is a well-established idea of finding groups of agents within a signed\nnetwork. Also, we introduce a new structural parameter for signed graphs,\nsigned neighborhood diversity snd, and exhibit a parameterized algorithm that\nfinds a smallest defensive alliance in a signed graph.",
            "author": [
                "Emmanuel Arrighi",
                "Zhidan Feng",
                "Henning Fernau",
                "Kevin Mann",
                "Xingqin Qi",
                "Petra Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06801v1",
                "http://arxiv.org/pdf/2309.06801v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06800v5",
            "title": "Uncertainty-aware Traffic Prediction under Missing Data",
            "updated": "2023-11-29T18:38:49Z",
            "published": "2023-09-13T08:48:00Z",
            "summary": "Traffic prediction is a crucial topic because of its broad scope of\napplications in the transportation domain. Recently, various studies have\nachieved promising results. However, most studies assume the prediction\nlocations have complete or at least partial historical records and cannot be\nextended to non-historical recorded locations. In real-life scenarios, the\ndeployment of sensors could be limited due to budget limitations and\ninstallation availability, which makes most current models not applicable.\nThough few pieces of literature tried to impute traffic states at the missing\nlocations, these methods need the data simultaneously observed at the locations\nwith sensors, making them not applicable to prediction tasks. Another drawback\nis the lack of measurement of uncertainty in prediction, making prior works\nunsuitable for risk-sensitive tasks or involving decision-making. To fill the\ngap, inspired by the previous inductive graph neural network, this work\nproposed an uncertainty-aware framework with the ability to 1) extend\nprediction to missing locations with no historical records and significantly\nextend spatial coverage of prediction locations while reducing deployment of\nsensors and 2) generate probabilistic prediction with uncertainty\nquantification to help the management of risk and decision making in the\ndown-stream tasks. Through extensive experiments on real-life datasets, the\nresult shows our method achieved promising results on prediction tasks, and the\nuncertainty quantification gives consistent results which highly correlated\nwith the locations with and without historical data. We also show that our\nmodel could help support sensor deployment tasks in the transportation field to\nachieve higher accuracy with a limited sensor deployment budget.",
            "author": [
                "Hao Mei",
                "Junxian Li",
                "Zhiming Liang",
                "Guanjie Zheng",
                "Bin Shi",
                "Hua Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06800v5",
                "http://arxiv.org/pdf/2309.06800v5"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06799v2",
            "title": "When Geoscience Meets Foundation Models: Towards General Geoscience\n  Artificial Intelligence System",
            "updated": "2023-10-04T08:52:08Z",
            "published": "2023-09-13T08:44:09Z",
            "summary": "Geoscience foundation models represent a revolutionary approach in the field\nof Earth sciences by integrating massive cross-disciplinary data to simulate\nand understand the Earth systems dynamics. As a data-centric artificial\nintelligence (AI) paradigm, they uncover insights from petabytes of structured\nand unstructured data. Flexible task specification, diverse inputs and outputs\nand multi-modal knowledge representation enable comprehensive analysis\ninfeasible with individual data sources. Critically, the scalability and\ngeneralizability of geoscience models allow for tackling diverse prediction,\nsimulation, and decision challenges related to Earth systems interactions.\nCollaboration between domain experts and computer scientists leads to\ninnovations in these invaluable tools for understanding the past, present, and\nfuture of our planet. However, challenges remain in validation and\nverification, scale, interpretability, knowledge representation, and social\nbias. Going forward, enhancing model integration, resolution, accuracy, and\nequity through cross-disciplinary teamwork is key. Despite current limitations,\ngeoscience foundation models show promise for providing critical insights into\npressing issues including climate change, natural hazards, and sustainability\nthrough their ability to probe scenarios and quantify uncertainties. Their\ncontinued evolution toward integrated, data-driven modeling holds\nparadigm-shifting potential for Earth science.",
            "author": [
                "Hao Zhang",
                "Jin-Jian Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06799v2",
                "http://arxiv.org/pdf/2309.06799v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06782v3",
            "title": "Improved particle-flow event reconstruction with scalable neural\n  networks for current and future particle detectors",
            "updated": "2023-11-07T14:34:31Z",
            "published": "2023-09-13T08:16:15Z",
            "summary": "We study scalable machine learning models for full event reconstruction in\nhigh-energy electron-positron collisions based on a highly granular detector\nsimulation. Particle-flow reconstruction can be formulated as a supervised\nlearning task using tracks and calorimeter clusters or hits. We compare a graph\nneural network and kernel-based transformer and demonstrate that both avoid\nquadratic memory allocation and computational cost while achieving realistic\nreconstruction. We show that hyperparameter tuning on a supercomputer\nsignificantly enhances the physics performance of the models, improving the jet\ntransverse momentum resolution by up to 50% compared to the baseline. The\nresulting model is highly portable across hardware processors. Finally, we\ndemonstrate that the model can be trained on highly granular inputs consisting\nof tracks and calorimeter hits, resulting in a competitive physics performance\nwith the baseline. Datasets and software to reproduce the studies are published\nfollowing the findable, accessible, interoperable, and reusable principles.",
            "author": [
                "Joosep Pata",
                "Eric Wulff",
                "Farouk Mokhtar",
                "David Southwick",
                "Mengke Zhang",
                "Maria Girone",
                "Javier Duarte"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06782v3",
                "http://arxiv.org/pdf/2309.06782v3"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an",
                "cs.LG",
                "hep-ex",
                "physics.ins-det",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06779v1",
            "title": "ZKROWNN: Zero Knowledge Right of Ownership for Neural Networks",
            "updated": "2023-09-13T08:06:13Z",
            "published": "2023-09-13T08:06:13Z",
            "summary": "Training contemporary AI models requires investment in procuring learning\ndata and computing resources, making the models intellectual property of the\nowners. Popular model watermarking solutions rely on key input triggers for\ndetection; the keys have to be kept private to prevent discovery, forging, and\nremoval of the hidden signatures. We present ZKROWNN, the first automated\nend-to-end framework utilizing Zero-Knowledge Proofs (ZKP) that enable an\nentity to validate their ownership of a model, while preserving the privacy of\nthe watermarks. ZKROWNN permits a third party client to verify model ownership\nin less than a second, requiring as little as a few KBs of communication.",
            "author": [
                "Nojan Sheybani",
                "Zahra Ghodsi",
                "Ritvik Kapila",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06779v1",
                "http://arxiv.org/pdf/2309.06779v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06777v1",
            "title": "Quantum Optical Induced-Coherence Tomography by a Hybrid Interferometer",
            "updated": "2023-09-13T07:54:31Z",
            "published": "2023-09-13T07:54:31Z",
            "summary": "Quantum interferometry based on induced-coherence phenomena has demonstrated\nthe possibility of undetected-photon measurements. Perturbation in the optical\npath of probe photons can be detected by interference signals generated by\nquantum mechanically correlated twin photons propagating through a different\npath, possibly at a different wavelength. To the best of our knowledge, this\nwork demonstrates for the first time a hybrid-type induced-coherence\ninterferometer that incorporates a Mach-Zehnder-type interferometer for visible\nphotons and a Michelson-type interferometer for infrared photons, based on\ndouble-pass pumped spontaneous parametric down-conversion. This configuration\nenables infrared optical measurements via the detection of near-visible photons\nand provides methods for characterizing the quality of measurements by\nidentifying photon pairs of different origins. The results verify that the\ninduced-coherence interference visibility is approximately the same as the\nheralding efficiencies between twin photons along the relevant spatial modes.\nApplications to both time-domain and frequency-domain quantum-optical\ninduced-coherence tomography for three-dimensional test structures are\ndemonstrated. The results prove the feasibility of practical undetected-photon\nsensing and imaging techniques based on the presented structure.",
            "author": [
                "Eun Mi Kim",
                "Sun Kyung Lee",
                "Sang Min Lee",
                "Myeong Soo Kang",
                "Hee Su Park"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06777v1",
                "http://arxiv.org/pdf/2309.06777v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06768v1",
            "title": "Hierarchical Time-Optimal Planning for Multi-Vehicle Racing",
            "updated": "2023-09-13T07:40:05Z",
            "published": "2023-09-13T07:40:05Z",
            "summary": "This paper presents a hierarchical planning algorithm for racing with\nmultiple opponents. The two-stage approach consists of a high-level behavioral\nplanning step and a low-level optimization step. By combining discrete and\ncontinuous planning methods, our algorithm encourages global time optimality\nwithout being limited by coarse discretization. In the behavioral planning\nstep, the fastest behavior is determined with a low-resolution spatio-temporal\nvisibility graph. Based on the selected behavior, we calculate maneuver\nenvelopes that are subsequently applied as constraints in a time-optimal\ncontrol problem. The performance of our method is comparable to a parallel\napproach that selects the fastest trajectory from multiple optimizations with\ndifferent behavior classes. However, our algorithm can be executed on a single\ncore. This significantly reduces computational requirements, especially when\nmultiple opponents are involved. Therefore, the proposed method is an efficient\nand practical solution for real-time multi-vehicle racing scenarios.",
            "author": [
                "Georg Jank",
                "Matthias Rowold",
                "Boris Lohmann"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06768v1",
                "http://arxiv.org/pdf/2309.06768v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06739v1",
            "title": "MCNS: Mining Causal Natural Structures Inside Time Series via A Novel\n  Internal Causality Scheme",
            "updated": "2023-09-13T06:15:37Z",
            "published": "2023-09-13T06:15:37Z",
            "summary": "Causal inference permits us to discover covert relationships of various\nvariables in time series. However, in most existing works, the variables\nmentioned above are the dimensions. The causality between dimensions could be\ncursory, which hinders the comprehension of the internal relationship and the\nbenefit of the causal graph to the neural networks (NNs). In this paper, we\nfind that causality exists not only outside but also inside the time series\nbecause it reflects a succession of events in the real world. It inspires us to\nseek the relationship between internal subsequences. However, the challenges\nare the hardship of discovering causality from subsequences and utilizing the\ncausal natural structures to improve NNs. To address these challenges, we\npropose a novel framework called Mining Causal Natural Structure (MCNS), which\nis automatic and domain-agnostic and helps to find the causal natural\nstructures inside time series via the internal causality scheme. We evaluate\nthe MCNS framework and impregnation NN with MCNS on time series classification\ntasks. Experimental results illustrate that our impregnation, by refining\nattention, shape selection classification, and pruning datasets, drives NN,\neven the data itself preferable accuracy and interpretability. Besides, MCNS\nprovides an in-depth, solid summary of the time series and datasets.",
            "author": [
                "Yuanhao Liu",
                "Dehui Du",
                "Zihan Jiang",
                "Anyan Huang",
                "Yiyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06739v1",
                "http://arxiv.org/pdf/2309.06739v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06735v1",
            "title": "GelFlow: Self-supervised Learning of Optical Flow for Vision-Based\n  Tactile Sensor Displacement Measurement",
            "updated": "2023-09-13T05:48:35Z",
            "published": "2023-09-13T05:48:35Z",
            "summary": "High-resolution multi-modality information acquired by vision-based tactile\nsensors can support more dexterous manipulations for robot fingers. Optical\nflow is low-level information directly obtained by vision-based tactile\nsensors, which can be transformed into other modalities like force, geometry\nand depth. Current vision-tactile sensors employ optical flow methods from\nOpenCV to estimate the deformation of markers in gels. However, these methods\nneed to be more precise for accurately measuring the displacement of markers\nduring large elastic deformation of the gel, as this can significantly impact\nthe accuracy of downstream tasks. This study proposes a self-supervised optical\nflow method based on deep learning to achieve high accuracy in displacement\nmeasurement for vision-based tactile sensors. The proposed method employs a\ncoarse-to-fine strategy to handle large deformations by constructing a\nmulti-scale feature pyramid from the input image. To better deal with the\nelastic deformation caused by the gel, the Helmholtz velocity decomposition\nconstraint combined with the elastic deformation constraint are adopted to\naddress the distortion rate and area change rate, respectively. A local flow\nfusion module is designed to smooth the optical flow, taking into account the\nprior knowledge of the blurred effect of gel deformation. We trained the\nproposed self-supervised network using an open-source dataset and compared it\nwith traditional and deep learning-based optical flow methods. The results show\nthat the proposed method achieved the highest displacement measurement\naccuracy, thereby demonstrating its potential for enabling more precise\nmeasurement of downstream tasks using vision-based tactile sensors.",
            "author": [
                "Zhiyuan Zhang",
                "Hua Yang",
                "Zhouping Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06735v1",
                "http://arxiv.org/pdf/2309.06735v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07929v2",
            "title": "Prompting Segmentation with Sound is Generalizable Audio-Visual Source\n  Localizer",
            "updated": "2023-09-18T02:04:59Z",
            "published": "2023-09-13T05:43:35Z",
            "summary": "Never having seen an object and heard its sound simultaneously, can the model\nstill accurately localize its visual position from the input audio? In this\nwork, we concentrate on the Audio-Visual Localization and Segmentation tasks\nbut under the demanding zero-shot and few-shot scenarios. To achieve this goal,\ndifferent from existing approaches that mostly employ the\nencoder-fusion-decoder paradigm to decode localization information from the\nfused audio-visual feature, we introduce the encoder-prompt-decoder paradigm,\naiming to better fit the data scarcity and varying data distribution dilemmas\nwith the help of abundant knowledge from pre-trained models. Specifically, we\nfirst propose to construct Semantic-aware Audio Prompt (SAP) to help the visual\nfoundation model focus on sounding objects, meanwhile, the semantic gap between\nthe visual and audio modalities is also encouraged to shrink. Then, we develop\na Correlation Adapter (ColA) to keep minimal training efforts as well as\nmaintain adequate knowledge of the visual foundation model. By equipping with\nthese means, extensive experiments demonstrate that this new paradigm\noutperforms other fusion-based methods in both the unseen class and\ncross-dataset settings. We hope that our work can further promote the\ngeneralization study of Audio-Visual Localization and Segmentation in practical\napplication scenarios.",
            "author": [
                "Yaoting Wang",
                "Weisong Liu",
                "Guangyao Li",
                "Jian Ding",
                "Di Hu",
                "Xi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07929v2",
                "http://arxiv.org/pdf/2309.07929v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06709v1",
            "title": "Development of helium turbine loss model based on knowledge transfer\n  with Neural Network and its application on aerodynamic design",
            "updated": "2023-09-13T04:14:15Z",
            "published": "2023-09-13T04:14:15Z",
            "summary": "Helium turbines are widely used in the Closed Brayton Cycle for power\ngeneration and aerospace applications. The primary concerns of designing highly\nloaded helium turbines include choosing between conventional and\ncontra-rotating designs and the guidelines for selecting design parameters. A\nloss model serving as an evaluation means is the key to addressing this issue.\nDue to the property disparities between helium and air, turbines utilizing\neither as working fluid experience distinct loss mechanisms. Consequently,\ndirectly applying gas turbine experience to the design of helium turbines leads\nto inherent inaccuracies. A helium turbine loss model is developed by combining\nknowledge transfer and the Neural Network method to accurately predict\nperformance at design and off-design points. By utilizing the loss model,\ndesign parameter selection guidelines for helium turbines are obtained. A\ncomparative analysis is conducted of conventional and contra-rotating helium\nturbine designs. Results show that the prediction errors of the loss model are\nbelow 0.5% at over 90% of test samples, surpassing the accuracy achieved by the\ngas turbine loss model. Design parameter selection guidelines for helium\nturbines differ significantly from those based on gas turbine experience. The\ncontra-rotating helium turbine design exhibits advantages in size, weight, and\naerodynamic performance.",
            "author": [
                "Changxing Liu",
                "Zhengping Zou",
                "Pengcheng Xu",
                "Yifan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06709v1",
                "http://arxiv.org/pdf/2309.06709v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06696v1",
            "title": "Fault-Tolerant Spanners against Bounded-Degree Edge Failures: Linearly\n  More Faults, Almost For Free",
            "updated": "2023-09-13T03:38:55Z",
            "published": "2023-09-13T03:38:55Z",
            "summary": "We study a new and stronger notion of fault-tolerant graph structures whose\nsize bounds depend on the degree of the failing edge set, rather than the total\nnumber of faults. For a subset of faulty edges $F \\subseteq G$, the\nfaulty-degree $\\deg(F)$ is the largest number of faults in $F$ incident to any\ngiven vertex. We design new fault-tolerant structures with size comparable to\nprevious constructions, but which tolerate every fault set of small\nfaulty-degree $\\deg(F)$, rather than only fault sets of small size $|F|$. Our\nmain results are:\n  - New FT-Certificates: For every $n$-vertex graph $G$ and degree threshold\n$f$, one can compute a connectivity certificate $H \\subseteq G$ with $|E(H)| =\n\\widetilde{O}(fn)$ edges that has the following guarantee: for any edge set $F$\nwith faulty-degree $\\deg(F)\\leq f$ and every vertex pair $u,v$, it holds that\n$u$ and $v$ are connected in $H \\setminus F$ iff they are connected in $G\n\\setminus F$. This bound on $|E(H)|$ is nearly tight. Since our certificates\nhandle some fault sets of size up to $|F|=O(fn)$, prior work did not imply any\nnontrivial upper bound for this problem, even when $f=1$.\n  - New FT-Spanners: We show that every $n$-vertex graph $G$ admits a\n$(2k-1)$-spanner $H$ with $|E(H)| = O_k(f^{1-1/k} n^{1+1/k})$ edges, which\ntolerates any fault set $F$ of faulty-degree at most $f$. This bound on\n$|E(H)|$ optimal up to its hidden dependence on $k$, and it is close to the\nbound of $O_k(|F|^{1/2} n^{1+1/k} + |F|n)$ that is known for the case where the\ntotal number of faults is $|F|$ [Bodwin, Dinitz, Robelle SODA '22]. Our proof\nof this theorem is non-constructive, but by following a proof strategy of\nDinitz and Robelle [PODC '20], we show that the runtime can be made polynomial\nby paying an additional $\\text{polylog } n$ factor in spanner size.",
            "author": [
                "Greg Bodwin",
                "Bernhard Haeupler",
                "Merav Parter"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06696v1",
                "http://arxiv.org/pdf/2309.06696v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06690v1",
            "title": "Scalable Scheduling for Industrial Time-Sensitive Networking: A\n  Hyper-flow Graph Based Scheme",
            "updated": "2023-09-13T03:07:21Z",
            "published": "2023-09-13T03:07:21Z",
            "summary": "Industrial Time-Sensitive Networking (TSN) provides deterministic mechanisms\nfor real-time and reliable flow transmission. Increasing attention has been\npaid to efficient scheduling for time-sensitive flows with stringent\nrequirements such as ultra-low latency and jitter. In TSN, the fine-grained\ntraffic shaping protocol, cyclic queuing and forwarding (CQF), eliminates\nuncertain delay and frame loss by cyclic traffic forwarding and queuing.\nHowever, it inevitably causes high scheduling complexity. Moreover, complexity\nis quite sensitive to flow attributes and network scale. The problem stems in\npart from the lack of an attribute mining mechanism in existing frame-based\nscheduling. For time-critical industrial networks with large-scale complex\nflows, a so-called hyper-flow graph based scheduling scheme is proposed to\nimprove the scheduling scalability in terms of schedulability, scheduling\nefficiency and latency & jitter. The hyper-flow graph is built by aggregating\nsimilar flow sets as hyper-flow nodes and designing a hierarchical scheduling\nframework. The flow attribute-sensitive scheduling information is embedded into\nthe condensed maximal cliques, and reverse maps them precisely to congestion\nflow portions for re-scheduling. Its parallel scheduling reduces network scale\ninduced complexity. Further, this scheme is designed in its entirety as a\ncomprehensive scheduling algorithm GH^2. It improves the three criteria of\nscalability along a Pareto front. Extensive simulation studies demonstrate its\nsuperiority. Notably, GH^2 is verified its scheduling stability with a runtime\nof less than 100 ms for 1000 flows and near 1/430 of the SOTA FITS method for\n2000 flows.",
            "author": [
                "Yanzhou Zhang",
                "Cailian Chen",
                "Qimin Xu",
                "Shouliang Wang",
                "Lei Xu",
                "Xinping Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06690v1",
                "http://arxiv.org/pdf/2309.06690v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06687v2",
            "title": "Self-Refined Large Language Model as Automated Reward Function Designer\n  for Deep Reinforcement Learning in Robotics",
            "updated": "2023-10-02T17:20:21Z",
            "published": "2023-09-13T02:56:56Z",
            "summary": "Although Deep Reinforcement Learning (DRL) has achieved notable success in\nnumerous robotic applications, designing a high-performing reward function\nremains a challenging task that often requires substantial manual input.\nRecently, Large Language Models (LLMs) have been extensively adopted to address\ntasks demanding in-depth common-sense knowledge, such as reasoning and\nplanning. Recognizing that reward function design is also inherently linked to\nsuch knowledge, LLM offers a promising potential in this context. Motivated by\nthis, we propose in this work a novel LLM framework with a self-refinement\nmechanism for automated reward function design. The framework commences with\nthe LLM formulating an initial reward function based on natural language\ninputs. Then, the performance of the reward function is assessed, and the\nresults are presented back to the LLM for guiding its self-refinement process.\nWe examine the performance of our proposed framework through a variety of\ncontinuous robotic control tasks across three diverse robotic systems. The\nresults indicate that our LLM-designed reward functions are able to rival or\neven surpass manually designed reward functions, highlighting the efficacy and\napplicability of our approach.",
            "author": [
                "Jiayang Song",
                "Zhehua Zhou",
                "Jiawei Liu",
                "Chunrong Fang",
                "Zhan Shu",
                "Lei Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06687v2",
                "http://arxiv.org/pdf/2309.06687v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06684v2",
            "title": "Attention Loss Adjusted Prioritized Experience Replay",
            "updated": "2023-10-09T03:12:03Z",
            "published": "2023-09-13T02:49:32Z",
            "summary": "Prioritized Experience Replay (PER) is a technical means of deep\nreinforcement learning by selecting experience samples with more knowledge\nquantity to improve the training rate of neural network. However, the\nnon-uniform sampling used in PER inevitably shifts the state-action space\ndistribution and brings the estimation error of Q-value function. In this\npaper, an Attention Loss Adjusted Prioritized (ALAP) Experience Replay\nalgorithm is proposed, which integrates the improved Self-Attention network\nwith Double-Sampling mechanism to fit the hyperparameter that can regulate the\nimportance sampling weights to eliminate the estimation error caused by PER. In\norder to verify the effectiveness and generality of the algorithm, the ALAP is\ntested with value-function based, policy-gradient based and multi-agent\nreinforcement learning algorithms in OPENAI gym, and comparison studies verify\nthe advantage and efficiency of the proposed training framework.",
            "author": [
                "Zhuoying Chen",
                "Huiping Li",
                "Rizhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06684v2",
                "http://arxiv.org/pdf/2309.06684v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06683v1",
            "title": "Federated PAC-Bayesian Learning on Non-IID data",
            "updated": "2023-09-13T02:44:01Z",
            "published": "2023-09-13T02:44:01Z",
            "summary": "Existing research has either adapted the Probably Approximately Correct (PAC)\nBayesian framework for federated learning (FL) or used information-theoretic\nPAC-Bayesian bounds while introducing their theorems, but few considering the\nnon-IID challenges in FL. Our work presents the first non-vacuous federated\nPAC-Bayesian bound tailored for non-IID local data. This bound assumes unique\nprior knowledge for each client and variable aggregation weights. We also\nintroduce an objective function and an innovative Gibbs-based algorithm for the\noptimization of the derived bound. The results are validated on real-world\ndatasets.",
            "author": [
                "Zihao Zhao",
                "Yang Liu",
                "Wenbo Ding",
                "Xiao-Ping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06683v1",
                "http://arxiv.org/pdf/2309.06683v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06680v1",
            "title": "STUPD: A Synthetic Dataset for Spatial and Temporal Relation Reasoning",
            "updated": "2023-09-13T02:35:59Z",
            "published": "2023-09-13T02:35:59Z",
            "summary": "Understanding relations between objects is crucial for understanding the\nsemantics of a visual scene. It is also an essential step in order to bridge\nvisual and language models. However, current state-of-the-art computer vision\nmodels still lack the ability to perform spatial reasoning well. Existing\ndatasets mostly cover a relatively small number of spatial relations, all of\nwhich are static relations that do not intrinsically involve motion. In this\npaper, we propose the Spatial and Temporal Understanding of Prepositions\nDataset (STUPD) -- a large-scale video dataset for understanding static and\ndynamic spatial relationships derived from prepositions of the English\nlanguage. The dataset contains 150K visual depictions (videos and images),\nconsisting of 30 distinct spatial prepositional senses, in the form of object\ninteraction simulations generated synthetically using Unity3D. In addition to\nspatial relations, we also propose 50K visual depictions across 10 temporal\nrelations, consisting of videos depicting event/time-point interactions. To our\nknowledge, no dataset exists that represents temporal relations through visual\nsettings. In this dataset, we also provide 3D information about object\ninteractions such as frame-wise coordinates, and descriptions of the objects\nused. The goal of this synthetic dataset is to help models perform better in\nvisual relationship detection in real-world settings. We demonstrate an\nincrease in the performance of various models over 2 real-world datasets\n(ImageNet-VidVRD and Spatial Senses) when pretrained on the STUPD dataset, in\ncomparison to other pretraining datasets.",
            "author": [
                "Palaash Agrawal",
                "Haidi Azaman",
                "Cheston Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06680v1",
                "http://arxiv.org/pdf/2309.06680v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07187v1",
            "title": "Multi-step prediction of chlorophyll concentration based on Adaptive\n  Graph-Temporal Convolutional Network with Series Decomposition",
            "updated": "2023-09-13T02:15:02Z",
            "published": "2023-09-13T02:15:02Z",
            "summary": "Chlorophyll concentration can well reflect the nutritional status and algal\nblooms of water bodies, and is an important indicator for evaluating water\nquality. The prediction of chlorophyll concentration change trend is of great\nsignificance to environmental protection and aquaculture. However, there is a\ncomplex and indistinguishable nonlinear relationship between many factors\naffecting chlorophyll concentration. In order to effectively mine the nonlinear\nfeatures contained in the data. This paper proposes a time-series decomposition\nadaptive graph-time convolutional network ( AGTCNSD ) prediction model.\nFirstly, the original sequence is decomposed into trend component and periodic\ncomponent by moving average method. Secondly, based on the graph convolutional\nneural network, the water quality parameter data is modeled, and a parameter\nembedding matrix is defined. The idea of matrix decomposition is used to assign\nweight parameters to each node. The adaptive graph convolution learns the\nrelationship between different water quality parameters, updates the state\ninformation of each parameter, and improves the learning ability of the update\nrelationship between nodes. Finally, time dependence is captured by time\nconvolution to achieve multi-step prediction of chlorophyll concentration. The\nvalidity of the model is verified by the water quality data of the coastal city\nBeihai. The results show that the prediction effect of this method is better\nthan other methods. It can be used as a scientific resource for environmental\nmanagement decision-making.",
            "author": [
                "Ying Chen",
                "Xiao Li",
                "Hongbo Zhang",
                "Wenyang Song",
                "Chongxuan Xv"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07187v1",
                "http://arxiv.org/pdf/2309.07187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06669v1",
            "title": "A short proof of the existence of a minor-universal countable planar\n  graph",
            "updated": "2023-09-13T02:08:59Z",
            "published": "2023-09-13T02:08:59Z",
            "summary": "We produce a new, shorter construction of a minor-universal planar graph.",
            "author": [
                "George Kontogeorgiou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06669v1",
                "http://arxiv.org/pdf/2309.06669v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C10 (Primary), 05C63 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06658v1",
            "title": "Dissipative Imitation Learning for Discrete Dynamic Output Feedback\n  Control with Sparse Data Sets",
            "updated": "2023-09-13T01:13:33Z",
            "published": "2023-09-13T01:13:33Z",
            "summary": "Imitation learning enables the synthesis of controllers for complex\nobjectives and highly uncertain plant models. However, methods to provide\nstability guarantees to imitation learned controllers often rely on large\namounts of data and/or known plant models. In this paper, we explore an\ninput-output (IO) stability approach to dissipative imitation learning, which\nachieves stability with sparse data sets and with little known about the plant\nmodel. A closed-loop stable dynamic output feedback controller is learned using\nexpert data, a coarse IO plant model, and a new constraint to enforce\ndissipativity on the learned controller. While the learning objective is\nnonconvex, iterative convex overbounding (ICO) and projected gradient descent\n(PGD) are explored as methods to successfully learn the controller. This new\nimitation learning method is applied to two unknown plants and compared to\ntraditionally learned dynamic output feedback controller and neural network\ncontroller. With little knowledge of the plant model and a small data set, the\ndissipativity constrained learned controller achieves closed loop stability and\nsuccessfully mimics the behavior of the expert controller, while other methods\noften fail to maintain stability and achieve good performance.",
            "author": [
                "Amy K. Strong",
                "Ethan J. LoCicero",
                "Leila J. Bridgeman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06658v1",
                "http://arxiv.org/pdf/2309.06658v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06655v2",
            "title": "Out of Distribution Detection via Domain-Informed Gaussian Process State\n  Space Models",
            "updated": "2023-09-15T21:20:20Z",
            "published": "2023-09-13T01:02:42Z",
            "summary": "In order for robots to safely navigate in unseen scenarios using\nlearning-based methods, it is important to accurately detect\nout-of-training-distribution (OoD) situations online. Recently, Gaussian\nprocess state-space models (GPSSMs) have proven useful to discriminate\nunexpected observations by comparing them against probabilistic predictions.\nHowever, the capability for the model to correctly distinguish between in- and\nout-of-training distribution observations hinges on the accuracy of these\npredictions, primarily affected by the class of functions the GPSSM kernel can\nrepresent. In this paper, we propose (i) a novel approach to embed existing\ndomain knowledge in the kernel and (ii) an OoD online runtime monitor, based on\nreceding-horizon predictions. Domain knowledge is provided in the form of a\ndataset, collected either in simulation or by using a nominal model. Numerical\nresults show that the informed kernel yields better regression quality with\nsmaller datasets, as compared to standard kernel choices. We demonstrate the\neffectiveness of the OoD monitor on a real quadruped navigating an indoor\nsetting, which reliably classifies previously unseen terrains.",
            "author": [
                "Alonso Marco",
                "Elias Morley",
                "Claire J. Tomlin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06655v2",
                "http://arxiv.org/pdf/2309.06655v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06652v1",
            "title": "Event-Driven Imaging in Turbid Media: A Confluence of Optoelectronics\n  and Neuromorphic Computation",
            "updated": "2023-09-13T00:38:59Z",
            "published": "2023-09-13T00:38:59Z",
            "summary": "In this paper a new optical-computational method is introduced to unveil\nimages of targets whose visibility is severely obscured by light scattering in\ndense, turbid media. The targets of interest are taken to be dynamic in that\ntheir optical properties are time-varying whether stationary in space or\nmoving. The scheme, to our knowledge the first of its kind, is human vision\ninspired whereby diffuse photons collected from the turbid medium are first\ntransformed to spike trains by a dynamic vision sensor as in the retina, and\nimage reconstruction is then performed by a neuromorphic computing approach\nmimicking the brain. We combine benchtop experimental data in both reflection\n(backscattering) and transmission geometries with support from physics-based\nsimulations to develop a neuromorphic computational model and then apply this\nfor image reconstruction of different MNIST characters and image sets by a\ndedicated deep spiking neural network algorithm. Image reconstruction is\nachieved under conditions of turbidity where an original image is\nunintelligible to the human eye or a digital video camera, yet clearly and\nquantifiable identifiable when using the new neuromorphic computational\napproach.",
            "author": [
                "Ning Zhang",
                "Timothy Shea",
                "Arto Nurmikko"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06652v1",
                "http://arxiv.org/pdf/2309.06652v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06648v1",
            "title": "Exp[licit]-A Robot modeling Software based on Exponential Maps",
            "updated": "2023-09-13T00:06:33Z",
            "published": "2023-09-13T00:06:33Z",
            "summary": "$ $Deriving a robot's equation of motion typically requires placing multiple\ncoordinate frames, commonly using the Denavit-Hartenberg convention to express\nthe kinematic and dynamic relationships between segments. This paper presents\nan alternative using the differential geometric method of Exponential Maps,\nwhich reduces the number of coordinate frame choices to two. The traditional\nand differential geometric methods are compared, and the conceptual and\npractical differences are detailed. The open-source software, Exp[licit], based\non the differential geometric method, is introduced. It is intended for use by\nresearchers and engineers with basic knowledge of geometry and robotics. Code\nsnippets and an example application are provided to demonstrate the benefits of\nthe differential geometric method and assist users to get started with the\nsoftware.",
            "author": [
                "Johannes Lachner",
                "Moses C. Nah",
                "Stefano Stramigioli",
                "Neville Hogan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06648v1",
                "http://arxiv.org/pdf/2309.06648v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06645v1",
            "title": "Bregman Graph Neural Network",
            "updated": "2023-09-12T23:54:24Z",
            "published": "2023-09-12T23:54:24Z",
            "summary": "Numerous recent research on graph neural networks (GNNs) has focused on\nformulating GNN architectures as an optimization problem with the smoothness\nassumption. However, in node classification tasks, the smoothing effect induced\nby GNNs tends to assimilate representations and over-homogenize labels of\nconnected nodes, leading to adverse effects such as over-smoothing and\nmisclassification. In this paper, we propose a novel bilevel optimization\nframework for GNNs inspired by the notion of Bregman distance. We demonstrate\nthat the GNN layer proposed accordingly can effectively mitigate the\nover-smoothing issue by introducing a mechanism reminiscent of the \"skip\nconnection\". We validate our theoretical results through comprehensive\nempirical studies in which Bregman-enhanced GNNs outperform their original\ncounterparts in both homophilic and heterophilic graphs. Furthermore, our\nexperiments also show that Bregman GNNs can produce more robust learning\naccuracy even when the number of layers is high, suggesting the effectiveness\nof the proposed method in alleviating the over-smoothing issue.",
            "author": [
                "Jiayu Zhai",
                "Lequan Lin",
                "Dai Shi",
                "Junbin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06645v1",
                "http://arxiv.org/pdf/2309.06645v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08630v1",
            "title": "PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph\n  Construction Methods and Chebyshev Graph Convolutions",
            "updated": "2023-09-12T23:20:19Z",
            "published": "2023-09-12T23:20:19Z",
            "summary": "Jet tagging is a classification problem in high-energy physics experiments\nthat aims to identify the collimated sprays of subatomic particles, jets, from\nparticle collisions and tag them to their emitter particle. Advances in jet\ntagging present opportunities for searches of new physics beyond the Standard\nModel. Current approaches use deep learning to uncover hidden patterns in\ncomplex collision data. However, the representation of jets as inputs to a deep\nlearning model have been varied, and often, informative features are withheld\nfrom models. In this study, we propose a graph-based representation of a jet\nthat encodes the most information possible. To learn best from this\nrepresentation, we design Particle Chebyshev Network (PCN), a graph neural\nnetwork (GNN) using Chebyshev graph convolutions (ChebConv). ChebConv has been\ndemonstrated as an effective alternative to classical graph convolutions in\nGNNs and has yet to be explored in jet tagging. PCN achieves a substantial\nimprovement in accuracy over existing taggers and opens the door to future\nstudies into graph-based representations of jets and ChebConv layers in\nhigh-energy physics experiments. Code is available at\nhttps://github.com/YVSemlani/PCN-Jet-Tagging.",
            "author": [
                "Yash Semlani",
                "Mihir Relan",
                "Krithik Ramesh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08630v1",
                "http://arxiv.org/pdf/2309.08630v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06635v2",
            "title": "Collaborative Dynamic 3D Scene Graphs for Automated Driving",
            "updated": "2023-09-19T21:29:32Z",
            "published": "2023-09-12T22:54:30Z",
            "summary": "Maps have played an indispensable role in enabling safe and automated\ndriving. Although there have been many advances on different fronts ranging\nfrom SLAM to semantics, building an actionable hierarchical semantic\nrepresentation of urban dynamic scenes from multiple agents is still a\nchallenging problem. In this work, we present Collaborative URBan Scene Graphs\n(CURB-SG) that enable higher-order reasoning and efficient querying for many\nfunctions of automated driving. CURB-SG leverages panoptic LiDAR data from\nmultiple agents to build large-scale maps using an effective graph-based\ncollaborative SLAM approach that detects inter-agent loop closures. To\nsemantically decompose the obtained 3D map, we build a lane graph from the\npaths of ego agents and their panoptic observations of other vehicles. Based on\nthe connectivity of the lane graph, we segregate the environment into\nintersecting and non-intersecting road areas. Subsequently, we construct a\nmulti-layered scene graph that includes lane information, the position of\nstatic landmarks and their assignment to certain map sections, other vehicles\nobserved by the ego agents, and the pose graph from SLAM including 3D panoptic\npoint clouds. We extensively evaluate CURB-SG in urban scenarios using a\nphotorealistic simulator. We release our code at\nhttp://curb.cs.uni-freiburg.de.",
            "author": [
                "Elias Greve",
                "Martin B\u00fcchner",
                "Niclas V\u00f6disch",
                "Wolfram Burgard",
                "Abhinav Valada"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06635v2",
                "http://arxiv.org/pdf/2309.06635v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06634v1",
            "title": "$G$-Mapper: Learning a Cover in the Mapper Construction",
            "updated": "2023-09-12T22:51:16Z",
            "published": "2023-09-12T22:51:16Z",
            "summary": "The Mapper algorithm is a visualization technique in topological data\nanalysis (TDA) that outputs a graph reflecting the structure of a given\ndataset. The Mapper algorithm requires tuning several parameters in order to\ngenerate a \"nice\" Mapper graph. The paper focuses on selecting the cover\nparameter. We present an algorithm that optimizes the cover of a Mapper graph\nby splitting a cover repeatedly according to a statistical test for normality.\nOur algorithm is based on $G$-means clustering which searches for the optimal\nnumber of clusters in $k$-means by conducting iteratively the Anderson-Darling\ntest. Our splitting procedure employs a Gaussian mixture model in order to\nchoose carefully the cover based on the distribution of a given data.\nExperiments for synthetic and real-world datasets demonstrate that our\nalgorithm generates covers so that the Mapper graphs retain the essence of the\ndatasets.",
            "author": [
                "Enrique Alvarado",
                "Robin Belton",
                "Emily Fischer",
                "Kang-Ju Lee",
                "Sourabh Palande",
                "Sarah Percival",
                "Emilie Purvine"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06634v1",
                "http://arxiv.org/pdf/2309.06634v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06620v1",
            "title": "Games and Argumentation: Time for a Family Reunion!",
            "updated": "2023-09-12T22:22:15Z",
            "published": "2023-09-12T22:22:15Z",
            "summary": "The rule \"defeated(X) $\\leftarrow$ attacks(Y,X), $\\neg$ defeated(Y)\" states\nthat an argument is defeated if it is attacked by an argument that is not\ndefeated. The rule \"win(X) $\\leftarrow$ move(X,Y), $\\neg$ win(Y)\" states that\nin a game a position is won if there is a move to a position that is not won.\nBoth logic rules can be seen as close relatives (even identical twins) and both\nrules have been at the center of attention at various times in different\ncommunities: The first rule lies at the core of argumentation frameworks and\nhas spawned a large family of models and semantics of abstract argumentation.\nThe second rule has played a key role in the quest to find the \"right\"\nsemantics for logic programs with recursion through negation, and has given\nrise to the stable and well-founded semantics. Both semantics have been widely\nstudied by the logic programming and nonmonotonic reasoning community. The\nsecond rule has also received much attention by the database and finite model\ntheory community, e.g., when studying the expressive power of query languages\nand fixpoint logics. Although close connections between argumentation\nframeworks, logic programming, and dialogue games have been known for a long\ntime, the overlap and cross-fertilization between the communities appears to be\nsmaller than one might expect. To this end, we recall some of the key results\nfrom database theory in which the win-move query has played a central role,\ne.g., on normal forms and expressive power of query languages. We introduce\nsome notions that naturally emerge from games and that may provide new\nperspectives and research opportunities for argumentation frameworks. We\ndiscuss how solved query evaluation games reveal how- and why-not provenance of\nquery answers. These techniques can be used to explain how results were derived\nvia the given query, game, or argumentation framework.",
            "author": [
                "Bertram Lud\u00e4scher",
                "Yilin Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06620v1",
                "http://arxiv.org/pdf/2309.06620v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06617v1",
            "title": "Accelerating model evaluations in uncertainty propagation on tensor\n  grids using computational graph transformations",
            "updated": "2023-09-12T22:20:15Z",
            "published": "2023-09-12T22:20:15Z",
            "summary": "Methods such as non-intrusive polynomial chaos (NIPC), and stochastic\ncollocation are frequently used for uncertainty propagation problems.\nParticularly for low-dimensional problems, these methods often use a\ntensor-product grid for sampling the space of uncertain inputs. A limitation of\nthis approach is that it encounters a significant challenge: the number of\nsample points grows exponentially with the increase of uncertain inputs.\nCurrent strategies to mitigate computational costs abandon the tensor structure\nof sampling points, with the aim of reducing their overall count.\nContrastingly, our investigation reveals that preserving the tensor structure\nof sample points can offer distinct advantages in specific scenarios. Notably,\nby manipulating the computational graph of the targeted model, it is feasible\nto avoid redundant evaluations at the operation level to significantly reduce\nthe model evaluation cost on tensor-grid inputs. This paper presents a\npioneering method: Accelerated Model Evaluations on Tensor grids using\nComputational graph transformations (AMTC). The core premise of AMTC lies in\nthe strategic modification of the computational graph of the target model to\nalgorithmically remove the repeated evaluations on the operation level. We\nimplemented the AMTC method within the compiler of a new modeling language\ncalled the Computational System Design Language (CSDL). We demonstrate the\neffectiveness of AMTC by using it with the full-grid NIPC method to solve three\nlow-dimensional UQ problems involving an analytical piston model, a\nmultidisciplinary unmanned aerial vehicle design model, and a multi-point air\ntaxi mission analysis model, respectively. For all of the test problems, AMTC\nreduces the model evaluation cost by between 50% and 90%, making the full-grid\nNIPC the most efficacious method to use among the UQ methods implemented.",
            "author": [
                "Bingran Wang",
                "Mark Sperry",
                "Victor E. Gandarillas",
                "John T. Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06617v1",
                "http://arxiv.org/pdf/2309.06617v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07181v1",
            "title": "The Grand Illusion: The Myth of Software Portability and Implications\n  for ML Progress",
            "updated": "2023-09-12T22:11:55Z",
            "published": "2023-09-12T22:11:55Z",
            "summary": "Pushing the boundaries of machine learning often requires exploring different\nhardware and software combinations. However, the freedom to experiment across\ndifferent tooling stacks can be at odds with the drive for efficiency, which\nhas produced increasingly specialized AI hardware and incentivized\nconsolidation around a narrow set of ML frameworks. Exploratory research can be\nrestricted if software and hardware are co-evolving, making it even harder to\nstray away from mainstream ideas that work well with popular tooling stacks.\nWhile this friction increasingly impacts the rate of innovation in machine\nlearning, to our knowledge the lack of portability in tooling has not been\nquantified. In this work, we ask: How portable are popular ML software\nframeworks? We conduct a large-scale study of the portability of mainstream ML\nframeworks across different hardware types. Our findings paint an uncomfortable\npicture -- frameworks can lose more than 40% of their key functions when ported\nto other hardware. Worse, even when functions are portable, the slowdown in\ntheir performance can be extreme and render performance untenable.\nCollectively, our results reveal how costly straying from a narrow set of\nhardware-software combinations can be - and suggest that specialization of\nhardware impedes innovation in machine learning research.",
            "author": [
                "Fraser Mince",
                "Dzung Dinh",
                "Jonas Kgomo",
                "Neil Thompson",
                "Sara Hooker"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07181v1",
                "http://arxiv.org/pdf/2309.07181v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.03028v1",
            "title": "SAF: Smart Aggregation Framework for Revealing Atoms Importance Rank and\n  Improving Prediction Rates in Drug Discovery",
            "updated": "2023-09-12T22:04:24Z",
            "published": "2023-09-12T22:04:24Z",
            "summary": "Machine learning, and representation learning in particular, has the\npotential to facilitate drug discovery by screening a large chemical space in\nsilico. A successful approach for representing molecules is to treat them as a\ngraph and utilize graph neural networks. One of the key limitations of such\nmethods is the necessity to represent compounds with different numbers of\natoms, which requires aggregating the atom's information. Common aggregation\noperators, such as averaging, result in loss of information at the atom level.\nIn this work, we propose a novel aggregating approach where each atom is\nweighted non-linearly using the Boltzmann distribution with a hyperparameter\nanalogous to temperature. We show that using this weighted aggregation improves\nthe ability of the gold standard message-passing neural network to predict\nantibiotic activity. Moreover, by changing the temperature hyperparameter, our\napproach can reveal the atoms that are important for activity prediction in a\nsmooth and consistent way, thus providing a novel, regulated attention\nmechanism for graph neural networks. We further validate our method by showing\nthat it recapitulates the functional group in beta-Lactam antibiotics. The\nability of our approach to rank the atoms' importance for a desired function\ncan be used within any graph neural network to provide interpretability of the\nresults and predictions at the node level.",
            "author": [
                "Ronen Taub",
                "Yonatan Savir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.03028v1",
                "http://arxiv.org/pdf/2310.03028v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06614v1",
            "title": "The Right Angled Artin Group Functor as a Categorical Embedding",
            "updated": "2023-09-12T22:03:01Z",
            "published": "2023-09-12T22:03:01Z",
            "summary": "It has long been known that the combinatorial properties of a graph $\\Gamma$\nare closely related to the group theoretic properties of its right angled artin\ngroup (raag). It's natural to ask if the graph homomorphisms are similarly\nrelated to the group homomorphisms between two raags. The main result of this\npaper shows that there is a purely algebraic way to characterize the raags\namongst groups, and the graph homomorphisms amongst the group homomorphisms. As\na corollary we present a new algorithm for recovering $\\Gamma$ from its raag.",
            "author": [
                "Chris Grossack"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06614v1",
                "http://arxiv.org/pdf/2309.06614v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO",
                "math.CT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07178v1",
            "title": "CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR\n  Spectroscopy Processing, Reconstruction and Analysis",
            "updated": "2023-09-12T21:40:51Z",
            "published": "2023-09-12T21:40:51Z",
            "summary": "Nuclear Magnetic Resonance (NMR) spectroscopy has served as a powerful\nanalytical tool for studying molecular structure and dynamics in chemistry and\nbiology. However, the processing of raw data acquired from NMR spectrometers\nand subsequent quantitative analysis involves various specialized tools, which\nnecessitates comprehensive knowledge in programming and NMR. Particularly, the\nemerging deep learning tools is hard to be widely used in NMR due to the\nsophisticated setup of computation. Thus, NMR processing is not an easy task\nfor chemist and biologists. In this work, we present CloudBrain-NMR, an\nintelligent online cloud computing platform designed for NMR data reading,\nprocessing, reconstruction, and quantitative analysis. The platform is\nconveniently accessed through a web browser, eliminating the need for any\nprogram installation on the user side. CloudBrain-NMR uses parallel computing\nwith graphics processing units and central processing units, resulting in\nsignificantly shortened computation time. Furthermore, it incorporates\nstate-of-the-art deep learning-based algorithms offering comprehensive\nfunctionalities that allow users to complete the entire processing procedure\nwithout relying on additional software. This platform has empowered NMR\napplications with advanced artificial intelligence processing. CloudBrain-NMR\nis openly accessible for free usage at https://csrc.xmu.edu.cn/CloudBrain.html",
            "author": [
                "Di Guo",
                "Sijin Li",
                "Jun Liu",
                "Zhangren Tu",
                "Tianyu Qiu",
                "Jingjing Xu",
                "Liubin Feng",
                "Donghai Lin",
                "Qing Hong",
                "Meijin Lin",
                "Yanqin Lin",
                "Xiaobo Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07178v1",
                "http://arxiv.org/pdf/2309.07178v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06607v1",
            "title": "An Empirical Analysis of Racial Categories in the Algorithmic Fairness\n  Literature",
            "updated": "2023-09-12T21:23:29Z",
            "published": "2023-09-12T21:23:29Z",
            "summary": "Recent work in algorithmic fairness has highlighted the challenge of defining\nracial categories for the purposes of anti-discrimination. These challenges are\nnot new but have previously fallen to the state, which enacts race through\ngovernment statistics, policies, and evidentiary standards in\nanti-discrimination law. Drawing on the history of state race-making, we\nexamine how longstanding questions about the nature of race and discrimination\nappear within the algorithmic fairness literature. Through a content analysis\nof 60 papers published at FAccT between 2018 and 2020, we analyze how race is\nconceptualized and formalized in algorithmic fairness frameworks. We note that\ndiffering notions of race are adopted inconsistently, at times even within a\nsingle analysis. We also explore the institutional influences and values\nassociated with these choices. While we find that categories used in\nalgorithmic fairness work often echo legal frameworks, we demonstrate that\nvalues from academic computer science play an equally important role in the\nconstruction of racial categories. Finally, we examine the reasoning behind\ndifferent operationalizations of race, finding that few papers explicitly\ndescribe their choices and even fewer justify them. We argue that the\nconstruction of racial categories is a value-laden process with significant\nsocial and political consequences for the project of algorithmic fairness. The\nwidespread lack of justification around the operationalization of race reflects\ninstitutional norms that allow these political decisions to remain obscured\nwithin the backstage of knowledge production.",
            "author": [
                "Amina A. Abdu",
                "Irene V. Pasquetto",
                "Abigail Z. Jacobs"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3593013.3594083",
                "http://arxiv.org/abs/2309.06607v1",
                "http://arxiv.org/pdf/2309.06607v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06588v2",
            "title": "Convergence of Gradient-based MAML in LQR",
            "updated": "2023-09-15T17:22:59Z",
            "published": "2023-09-12T20:24:37Z",
            "summary": "The main objective of this research paper is to investigate the local\nconvergence characteristics of Model-agnostic Meta-learning (MAML) when applied\nto linear system quadratic optimal control (LQR). MAML and its variations have\nbecome popular techniques for quickly adapting to new tasks by leveraging\nprevious learning knowledge in areas like regression, classification, and\nreinforcement learning. However, its theoretical guarantees remain unknown due\nto non-convexity and its structure, making it even more challenging to ensure\nstability in the dynamic system setting. This study focuses on exploring MAML\nin the LQR setting, providing its local convergence guarantees while\nmaintaining the stability of the dynamical system. The paper also presents\nsimple numerical results to demonstrate the convergence properties of MAML in\nLQR tasks.",
            "author": [
                "Negin Musavi",
                "Geir E. Dullerud"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06588v2",
                "http://arxiv.org/pdf/2309.06588v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06584v3",
            "title": "Explainable Graph Neural Network for Alzheimer's Disease And Related\n  Dementias Risk Prediction",
            "updated": "2023-09-18T14:10:54Z",
            "published": "2023-09-12T20:12:08Z",
            "summary": "Alzheimer's disease and related dementias (ADRD) ranks as the sixth leading\ncause of death in the US, underlining the importance of accurate ADRD risk\nprediction. While recent advancement in ADRD risk prediction have primarily\nrelied on imaging analysis, yet not all patients undergo medical imaging before\nan ADRD diagnosis. Merging machine learning with claims data can reveal\nadditional risk factors and uncover interconnections among diverse medical\ncodes. Our goal is to utilize Graph Neural Networks (GNNs) with claims data for\nADRD risk prediction. Addressing the lack of human-interpretable reasons behind\nthese predictions, we introduce an innovative method to evaluate relationship\nimportance and its influence on ADRD risk prediction, ensuring comprehensive\ninterpretation.\n  We employed Variationally Regularized Encoder-decoder Graph Neural Network\n(VGNN) for estimating ADRD likelihood. We created three scenarios to assess the\nmodel's efficiency, using Random Forest and Light Gradient Boost Machine as\nbaselines. We further used our relation importance method to clarify the key\nrelationships for ADRD risk prediction. VGNN surpassed other baseline models by\n10% in the area under the receiver operating characteristic. The integration of\nthe GNN model and relation importance interpretation could potentially play an\nessential role in providing valuable insight into factors that may contribute\nto or delay ADRD progression.\n  Employing a GNN approach with claims data enhances ADRD risk prediction and\nprovides insights into the impact of interconnected medical code relationships.\nThis methodology not only enables ADRD risk modeling but also shows potential\nfor other image analysis predictions using claims data.",
            "author": [
                "Xinyue Hu",
                "Zenan Sun",
                "Yi Nian",
                "Yifang Dang",
                "Fang Li",
                "Jingna Feng",
                "Evan Yu",
                "Cui Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06584v3",
                "http://arxiv.org/pdf/2309.06584v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06541v1",
            "title": "Text Encoders Lack Knowledge: Leveraging Generative LLMs for\n  Domain-Specific Semantic Textual Similarity",
            "updated": "2023-09-12T19:32:45Z",
            "published": "2023-09-12T19:32:45Z",
            "summary": "Amidst the sharp rise in the evaluation of large language models (LLMs) on\nvarious tasks, we find that semantic textual similarity (STS) has been\nunder-explored. In this study, we show that STS can be cast as a text\ngeneration problem while maintaining strong performance on multiple STS\nbenchmarks. Additionally, we show generative LLMs significantly outperform\nexisting encoder-based STS models when characterizing the semantic similarity\nbetween two texts with complex semantic relationships dependent on world\nknowledge. We validate this claim by evaluating both generative LLMs and\nexisting encoder-based STS models on three newly collected STS challenge sets\nwhich require world knowledge in the domains of Health, Politics, and Sports.\nAll newly collected data is sourced from social media content posted after May\n2023 to ensure the performance of closed-source models like ChatGPT cannot be\ncredited to memorization. Our results show that, on average, generative LLMs\noutperform the best encoder-only baselines by an average of 22.3% on STS tasks\nrequiring world knowledge. Our results suggest generative language models with\nSTS-specific prompting strategies achieve state-of-the-art performance in\ncomplex, domain-specific STS tasks.",
            "author": [
                "Joseph Gatto",
                "Omar Sharif",
                "Parker Seegmiller",
                "Philip Bohlman",
                "Sarah Masud Preum"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06541v1",
                "http://arxiv.org/pdf/2309.06541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06535v1",
            "title": "Automatic quantification of abdominal subcutaneous and visceral adipose\n  tissue in children, through MRI study, using total intensity maps and\n  Convolutional Neural Networks",
            "updated": "2023-09-12T19:19:47Z",
            "published": "2023-09-12T19:19:47Z",
            "summary": "Childhood overweight and obesity is one of the main health problems in the\nworld since it is related to the early appearance of different diseases, in\naddition to being a risk factor for later developing obesity in adulthood with\nits health and economic consequences. Visceral abdominal tissue (VAT) is\nstrongly related to the development of metabolic and cardiovascular diseases\ncompared to abdominal subcutaneous adipose tissue (ASAT). Therefore, precise\nand automatic VAT and ASAT quantification methods would allow better diagnosis,\nmonitoring and prevention of diseases caused by obesity at any stage of life.\nCurrently, magnetic resonance imaging is the standard for fat quantification,\nwith Dixon sequences being the most useful. Different semiautomatic and\nautomatic ASAT and VAT quantification methodologies have been proposed. In\nparticular, the semi-automated quantification methodology used commercially\nthrough the cloud-based service AMRA R Researcher stands out due to its\nextensive validation in different studies. In the present work, a database made\nup of Dixon MRI sequences, obtained from children between 7 and 9 years of age,\nwas studied. Applying a preprocessing to obtain what we call total intensity\nmaps, a convolutional neural network (CNN) was proposed for the automatic\nquantification of ASAT and VAT. The quantifications obtained from the proposed\nmethodology were compared with quantifications previously made through AMRA R\nResearcher. For the comparison, correlation analysis, Bland-Altman graphs and\nnon-parametric statistical tests were used. The results indicated a high\ncorrelation and similar precisions between the quantifications of this work and\nthose of AMRA R Researcher. The final objective is that the proposed\nmethodology can serve as an accessible and free tool for the diagnosis,\nmonitoring and prevention of diseases related to childhood obesity.",
            "author": [
                "Jos\u00e9 Gerardo Su\u00e1rez-Garc\u00eda",
                "Po-Wah So",
                "Javier Miguel Hern\u00e1ndez-L\u00f3pez",
                "Silvia S. Hidalgo-Tob\u00f3n",
                "Pilar Dies-Su\u00e1rez",
                "Benito de Celis-Alonso"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06535v1",
                "http://arxiv.org/pdf/2309.06535v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06534v1",
            "title": "Distributionally Robust Transfer Learning",
            "updated": "2023-09-12T19:18:52Z",
            "published": "2023-09-12T19:18:52Z",
            "summary": "Many existing transfer learning methods rely on leveraging information from\nsource data that closely resembles the target data. However, this approach\noften overlooks valuable knowledge that may be present in different yet\npotentially related auxiliary samples. When dealing with a limited amount of\ntarget data and a diverse range of source models, our paper introduces a novel\napproach, Distributionally Robust Optimization for Transfer Learning\n(TransDRO), that breaks free from strict similarity constraints. TransDRO is\ndesigned to optimize the most adversarial loss within an uncertainty set,\ndefined as a collection of target populations generated as a convex combination\nof source distributions that guarantee excellent prediction performances for\nthe target data. TransDRO effectively bridges the realms of transfer learning\nand distributional robustness prediction models. We establish the\nidentifiability of TransDRO and its interpretation as a weighted average of\nsource models closest to the baseline model. We also show that TransDRO\nachieves a faster convergence rate than the model fitted with the target data.\nOur comprehensive numerical studies and analysis of multi-institutional\nelectronic health records data using TransDRO further substantiate the\nrobustness and accuracy of TransDRO, highlighting its potential as a powerful\ntool in transfer learning applications.",
            "author": [
                "Xin Xiong",
                "Zijian Guo",
                "Tianxi Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06534v1",
                "http://arxiv.org/pdf/2309.06534v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06532v1",
            "title": "Bayesian topology inference on partially known networks from\n  input-output pairs",
            "updated": "2023-09-12T19:11:31Z",
            "published": "2023-09-12T19:11:31Z",
            "summary": "We propose a sampling algorithm to perform system identification from a set\nof input-output graph signal pairs. The dynamics of the systems we study are\ngiven by a partially known adjacency matrix and a generic parametric graph\nfilter of unknown parameters. The methodology we employ is built upon the\nprinciples of annealed Langevin diffusion. This enables us to draw samples from\nthe posterior distribution instead of following the classical approach of point\nestimation using maximum likelihood. We investigate how to harness the prior\ninformation inherent in a dataset of graphs of different sizes through the\nutilization of graph neural networks. We demonstrate, via numerical experiments\ninvolving both real-world and synthetic networks, that integrating prior\nknowledge into the estimation process enhances estimation performance.",
            "author": [
                "Mart\u00edn Sevilla",
                "Santiago Segarra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06532v1",
                "http://arxiv.org/pdf/2309.06532v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06528v1",
            "title": "Strong-Weak Integrated Semi-supervision for Unsupervised Single and\n  Multi Target Domain Adaptation",
            "updated": "2023-09-12T19:08:54Z",
            "published": "2023-09-12T19:08:54Z",
            "summary": "Unsupervised domain adaptation (UDA) focuses on transferring knowledge\nlearned in the labeled source domain to the unlabeled target domain. Despite\nsignificant progress that has been achieved in single-target domain adaptation\nfor image classification in recent years, the extension from single-target to\nmulti-target domain adaptation is still a largely unexplored problem area. In\ngeneral, unsupervised domain adaptation faces a major challenge when attempting\nto learn reliable information from a single unlabeled target domain. Increasing\nthe number of unlabeled target domains further exacerbate the problem rather\nsignificantly. In this paper, we propose a novel strong-weak integrated\nsemi-supervision (SWISS) learning strategy for image classification using\nunsupervised domain adaptation that works well for both single-target and\nmulti-target scenarios. Under the proposed SWISS-UDA framework, a strong\nrepresentative set with high confidence but low diversity target domain samples\nand a weak representative set with low confidence but high diversity target\ndomain samples are updated constantly during the training process. Both sets\nare fused to generate an augmented strong-weak training batch with\npseudo-labels to train the network during every iteration. The extension from\nsingle-target to multi-target domain adaptation is accomplished by exploring\nthe class-wise distance relationship between domains and replacing the strong\nrepresentative set with much stronger samples from peer domains via peer\nscaffolding. Moreover, a novel adversarial logit loss is proposed to reduce the\nintra-class divergence between source and target domains, which is\nback-propagated adversarially with a gradient reverse layer between the\nclassifier and the rest of the network. Experimental results based on three\nbenchmarks, Office-31, Office-Home, and DomainNet, show the effectiveness of\nthe proposed SWISS framework.",
            "author": [
                "Xiaohu Lu",
                "Hayder Radha"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06528v1",
                "http://arxiv.org/pdf/2309.06528v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06510v1",
            "title": "$Q$-voter model with independence on signed random graphs: homogeneous\n  approximations",
            "updated": "2023-09-12T18:34:10Z",
            "published": "2023-09-12T18:34:10Z",
            "summary": "The $q$-voter model with independence is generalized to signed random graphs\nand studied by means of Monte Carlo simulations and theoretically using the\nmean field approximation and different forms of the pair approximation. In the\nsigned network with quenched disorder, positive and negative signs associated\nrandomly with the links correspond to reinforcing and antagonistic\ninteractions, promoting, respectively, the same or opposite orientations of\ntwo-state spins representing agents' opinions; otherwise, the opinions are\ncalled mismatched. With probability $1-p$, the agents change their opinions if\nthe opinions of all members of a randomly selected $q$-neighborhood are\nmismatched, and with probability $p$, they choose an opinion randomly. The\nmodel on networks with finite mean degree $\\langle k \\rangle$ and fixed\nfraction of the antagonistic interactions $r$ exhibits ferromagnetic transition\nwith varying the independence parameter $p$, which can be first- or\nsecond-order, depending on $q$ and $r$, and disappears for large $r$. Besides,\nnumerical evidence is provided for the occurrence of the spin-glass-like\ntransition for large $r$. The order and critical lines for the ferromagnetic\ntransition on the $p$ vs. $r$ phase diagram obtained in Monte Carlo simulations\nare reproduced qualitatively by the mean field approximation. Within the range\nof applicability of the pair approximation, for the model with $\\langle k\n\\rangle$ finite but $\\langle k \\rangle \\gg q$, predictions of the homogeneous\npair approximation concerning the ferromagnetic transition show much better\nquantitative agreement with numerical results for small $r$ but fail for larger\n$r$. A more advanced signed homogeneous pair approximation is formulated which\ndistinguishes between classes of active links with a given sign connecting\nnodes occupied by agents with mismatched opinions...",
            "author": [
                "Andrzej Krawiecki",
                "Tomasz Gradowski"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06510v1",
                "http://arxiv.org/pdf/2309.06510v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06509v1",
            "title": "Homeostasis in Gene Regulatory Networks",
            "updated": "2023-09-12T18:31:29Z",
            "published": "2023-09-12T18:31:29Z",
            "summary": "In this paper, we use the framework of infinitesimal homeostasis to study\ngeneral design principles for the occurrence of homeostasis in gene regulatory\nnetworks. We assume that the dynamics of the genes explicitly includes both\ntranscription and translation, keeping track of both mRNA and protein\nconcentrations. Given a GRN we construct an associated Protein-mRNA Network\n(PRN), where each individual (mRNA and protein) concentration corresponds to a\nnode and the edges are defined in such a way that the PRN becomes a bipartite\ndirected graph. By simultaneously working with the GRN and the PRN we are able\nto apply our previous results about the classification of homeostasis types\n(i.e., topologically defined homeostasis generating mechanism) and their\ncorresponding homeostasis patterns. Given an arbitrarily large and complex GRN\n$\\mathcal{G}$ and its associated PRN $\\mathcal{R}$, we obtain a correspondence\nbetween all the homeostasis types (and homeostasis patterns) of $\\mathcal{G}$\nand a subset the homeostasis types (and homeostasis patterns) of $\\mathcal{R}$.\nMoreover, we completely characterize the homeostasis types of the PRN that do\nnot have GRN counterparts.",
            "author": [
                "Fernando Antoneli",
                "Martin Golubitsky",
                "Jiaxin Jin",
                "Ian Stewart"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06509v1",
                "http://arxiv.org/pdf/2309.06509v1"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "math.DS",
                "92B05, 37C20, 37N25, 15A15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06507v1",
            "title": "The maximum size of adjacency-crossing graphs",
            "updated": "2023-09-12T18:23:36Z",
            "published": "2023-09-12T18:23:36Z",
            "summary": "An adjacency-crossing graph is a graph that can be drawn such that every two\nedges that cross the same edge share a common endpoint. We show that the number\nof edges in an $n$-vertex adjacency-crossing graph is at most $5n-10$. If we\nrequire the edges to be drawn as straight-line segments, then this upper bound\nbecomes $5n-11$. Both of these bounds are tight. The former result also follows\nfrom a very recent and independent work of Cheong et al.\\cite{cheong2023weakly}\nwho showed that the maximum size of weakly and strongly fan-planar graphs\ncoincide. By combining this result with the bound of Kaufmann and\nUeckerdt\\cite{KU22} on the size of strongly fan-planar graphs and results of\nBrandenburg\\cite{Br20} by which the maximum size of adjacency-crossing graphs\nequals the maximum size of fan-crossing graphs which in turn equals the maximum\nsize of weakly fan-planar graphs, one obtains the same bound on the size of\nadjacency-crossing graphs. However, the proof presented here is different,\nsimpler and direct.",
            "author": [
                "Eyal Ackerman",
                "Bal\u00e1zs Keszegh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06507v1",
                "http://arxiv.org/pdf/2309.06507v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "68R10, 05C10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06490v1",
            "title": "Leveraging Large Language Models for Automated Dialogue Analysis",
            "updated": "2023-09-12T18:03:55Z",
            "published": "2023-09-12T18:03:55Z",
            "summary": "Developing high-performing dialogue systems benefits from the automatic\nidentification of undesirable behaviors in system responses. However, detecting\nsuch behaviors remains challenging, as it draws on a breadth of general\nknowledge and understanding of conversational practices. Although recent\nresearch has focused on building specialized classifiers for detecting specific\ndialogue behaviors, the behavior coverage is still incomplete and there is a\nlack of testing on real-world human-bot interactions. This paper investigates\nthe ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to\nperform dialogue behavior detection for nine categories in real human-bot\ndialogues. We aim to assess whether ChatGPT can match specialized models and\napproximate human performance, thereby reducing the cost of behavior detection\ntasks. Our findings reveal that neither specialized models nor ChatGPT have yet\nachieved satisfactory results for this task, falling short of human\nperformance. Nevertheless, ChatGPT shows promising potential and often\noutperforms specialized detection models. We conclude with an in-depth\nexamination of the prevalent shortcomings of ChatGPT, offering guidance for\nfuture research to enhance LLM capabilities.",
            "author": [
                "Sarah E. Finch",
                "Ellie S. Paek",
                "Jinho D. Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06490v1",
                "http://arxiv.org/pdf/2309.06490v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06472v1",
            "title": "Flows for Flows: Morphing one Dataset into another with Maximum\n  Likelihood Estimation",
            "updated": "2023-09-12T18:00:01Z",
            "published": "2023-09-12T18:00:01Z",
            "summary": "Many components of data analysis in high energy physics and beyond require\nmorphing one dataset into another. This is commonly solved via reweighting, but\nthere are many advantages of preserving weights and shifting the data points\ninstead. Normalizing flows are machine learning models with impressive\nprecision on a variety of particle physics tasks. Naively, normalizing flows\ncannot be used for morphing because they require knowledge of the probability\ndensity of the starting dataset. In most cases in particle physics, we can\ngenerate more examples, but we do not know densities explicitly. We propose a\nprotocol called flows for flows for training normalizing flows to morph one\ndataset into another even if the underlying probability density of neither\ndataset is known explicitly. This enables a morphing strategy trained with\nmaximum likelihood estimation, a setup that has been shown to be highly\neffective in related tasks. We study variations on this protocol to explore how\nfar the data points are moved to statistically match the two datasets.\nFurthermore, we show how to condition the learned flows on particular features\nin order to create a morphing function for every value of the conditioning\nfeature. For illustration, we demonstrate flows for flows for toy examples as\nwell as a collider physics example involving dijet events",
            "author": [
                "Tobias Golling",
                "Samuel Klein",
                "Radha Mastandrea",
                "Benjamin Nachman",
                "John Andrew Raine"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevD.108.096018",
                "http://arxiv.org/abs/2309.06472v1",
                "http://arxiv.org/pdf/2309.06472v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "hep-ex",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06476v1",
            "title": "Machine Learning the Dark Matter Halo Mass of Milky Way-Like Systems",
            "updated": "2023-09-12T18:00:01Z",
            "published": "2023-09-12T18:00:01Z",
            "summary": "Despite the Milky Way's proximity to us, our knowledge of its dark matter\nhalo is fairly limited, and there is still considerable uncertainty in its halo\nmass. Many past techniques have been limited by assumptions such as the Galaxy\nbeing in dynamical equilibrium as well as nearby galaxies being true satellites\nof the Galaxy, and/or the need to find large samples of Milky Way analogs in\nsimulations.Here, we propose a new technique based on neural networks that\nobtains high precision ($<0.14$ dex mass uncertainty) without assuming halo\ndynamical equilibrium or that neighboring galaxies are all satellites, and\nwhich can use information from a wide variety of simulated halos (even those\ndissimilar to the Milky Way) to improve its performance. This method uses only\nobservable information including satellite orbits, distances to nearby larger\nhalos, and the maximum circular velocity of the largest satellite galaxy. In\nthis paper, we demonstrate a proof-of-concept method on simulated dark matter\nhalos; in future papers in this series, we will apply neural networks to\nestimate the masses of the Milky Way's and M31's dark matter halos, and we will\ntrain variations of these networks to estimate other halo properties including\nconcentration, assembly history, and spin axis.",
            "author": [
                "Elaheh Hayati",
                "Peter Behroozi",
                "Ekta Patel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06476v1",
                "http://arxiv.org/pdf/2309.06476v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06462v2",
            "title": "Action Segmentation Using 2D Skeleton Heatmaps",
            "updated": "2023-09-19T00:01:06Z",
            "published": "2023-09-12T17:56:06Z",
            "summary": "This paper presents a 2D skeleton-based action segmentation method with\napplications in fine-grained human activity recognition. In contrast with\nstate-of-the-art methods which directly take sequences of 3D skeleton\ncoordinates as inputs and apply Graph Convolutional Networks (GCNs) for\nspatiotemporal feature learning, our main idea is to use sequences of 2D\nskeleton heatmaps as inputs and employ Temporal Convolutional Networks (TCNs)\nto extract spatiotemporal features. Despite lacking 3D information, our\napproach yields comparable/superior performances and better robustness against\nmissing keypoints than previous methods on action segmentation datasets.\nMoreover, we improve the performances further by using both 2D skeleton\nheatmaps and RGB videos as inputs. To our best knowledge, this is the first\nwork to utilize 2D skeleton heatmap inputs and the first work to explore 2D\nskeleton+RGB fusion for action segmentation.",
            "author": [
                "Syed Waleed Hyder",
                "Muhammad Usama",
                "Anas Zafar",
                "Muhammad Naufil",
                "Fawad Javed Fateh",
                "Andrey Konin",
                "M. Zeeshan Zia",
                "Quoc-Huy Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06462v2",
                "http://arxiv.org/pdf/2309.06462v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06436v1",
            "title": "Holographic Tensor Networks with Bulk Gauge Symmetries",
            "updated": "2023-09-12T17:56:02Z",
            "published": "2023-09-12T17:56:02Z",
            "summary": "Tensor networks are useful toy models for understanding the structure of\nentanglement in holographic states and reconstruction of bulk operators within\nthe entanglement wedge. They are, however, constrained to only prepare\nso-called \"fixed-area states\" with flat entanglement spectra, limiting their\nutility in understanding general features of holographic entanglement. Here, we\novercome this limitation by constructing a variant of random tensor networks\nthat enjoys bulk gauge symmetries. Our model includes a gauge theory on a\ngeneral graph, whose gauge-invariant states are fed into a random tensor\nnetwork. We show that the model satisfies the quantum-corrected Ryu-Takayanagi\nformula with a nontrivial area operator living in the center of a\ngauge-invariant algebra. We also demonstrate nontrivial, n-dependent\ncontributions to the R\\'enyi entropy and R\\'enyi mutual information from this\narea operator, a feature shared by general holographic states.",
            "author": [
                "Xi Dong",
                "Sean McBride",
                "Wayne W. Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06436v1",
                "http://arxiv.org/pdf/2309.06436v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06423v2",
            "title": "Accelerating Defect Predictions in Semiconductors Using Graph Neural\n  Networks",
            "updated": "2023-09-13T22:11:19Z",
            "published": "2023-09-12T17:40:23Z",
            "summary": "Here, we develop a framework for the prediction and screening of native\ndefects and functional impurities in a chemical space of Group IV, III-V, and\nII-VI zinc blende (ZB) semiconductors, powered by crystal Graph-based Neural\nNetworks (GNNs) trained on high-throughput density functional theory (DFT)\ndata. Using an innovative approach of sampling partially optimized defect\nconfigurations from DFT calculations, we generate one of the largest\ncomputational defect datasets to date, containing many types of vacancies,\nself-interstitials, anti-site substitutions, impurity interstitials and\nsubstitutions, as well as some defect complexes. We applied three types of\nestablished GNN techniques, namely Crystal Graph Convolutional Neural Network\n(CGCNN), Materials Graph Network (MEGNET), and Atomistic Line Graph Neural\nNetwork (ALIGNN), to rigorously train models for predicting defect formation\nenergy (DFE) in multiple charge states and chemical potential conditions. We\nfind that ALIGNN yields the best DFE predictions with root mean square errors\naround 0.3 eV, which represents a prediction accuracy of 98 % given the range\nof values within the dataset, improving significantly on the state-of-the-art.\nModels are tested for different defect types as well as for defect charge\ntransition levels. We further show that GNN-based defective structure\noptimization can take us close to DFT-optimized geometries at a fraction of the\ncost of full DFT. DFT-GNN models enable prediction and screening across\nthousands of hypothetical defects based on both unoptimized and\npartially-optimized defective structures, helping identify electronically\nactive defects in technologically-important semiconductors.",
            "author": [
                "Md Habibur Rahman",
                "Prince Gollapalli",
                "Panayotis Manganaris",
                "Satyesh Kumar Yadav",
                "Ghanshyam Pilania",
                "Brian DeCost",
                "Kamal Choudhary",
                "Arun Mannodi-Kanakkithodi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06423v2",
                "http://arxiv.org/pdf/2309.06423v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06421v2",
            "title": "AGMDT: Virtual Staining of Renal Histology Images with Adjacency-Guided\n  Multi-Domain Transfer",
            "updated": "2023-09-17T10:35:30Z",
            "published": "2023-09-12T17:37:56Z",
            "summary": "Renal pathology, as the gold standard of kidney disease diagnosis, requires\ndoctors to analyze a series of tissue slices stained by H&E staining and\nspecial staining like Masson, PASM, and PAS, respectively. These special\nstaining methods are costly, time-consuming, and hard to standardize for wide\nuse especially in primary hospitals. Advances of supervised learning methods\nhave enabled the virtually conversion of H&E images into special staining\nimages, but achieving pixel-to-pixel alignment for training remains\nchallenging. In contrast, unsupervised learning methods regarding different\nstains as different style transfer domains can utilize unpaired data, but they\nignore the spatial inter-domain correlations and thus decrease the\ntrustworthiness of structural details for diagnosis. In this paper, we propose\na novel virtual staining framework AGMDT to translate images into other domains\nby avoiding pixel-level alignment and meanwhile utilizing the correlations\namong adjacent tissue slices. We first build a high-quality multi-domain renal\nhistological dataset where each specimen case comprises a series of slices\nstained in various ways. Based on it, the proposed framework AGMDT discovers\npatch-level aligned pairs across the serial slices of multi-domains through\nglomerulus detection and bipartite graph matching, and utilizes such\ncorrelations to supervise the end-to-end model for multi-domain staining\ntransformation. Experimental results show that the proposed AGMDT achieves a\ngood balance between the precise pixel-level alignment and unpaired domain\ntransfer by exploiting correlations across multi-domain serial pathological\nslices, and outperforms the state-of-the-art methods in both quantitative\nmeasure and morphological details.",
            "author": [
                "Tao Ma",
                "Chao Zhang",
                "Min Lu",
                "Lin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06421v2",
                "http://arxiv.org/pdf/2309.06421v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06382v2",
            "title": "Ensemble Mask Networks",
            "updated": "2023-10-09T15:24:11Z",
            "published": "2023-09-12T16:48:00Z",
            "summary": "Can an $\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$ feedforward network learn\nmatrix-vector multiplication? This study introduces two mechanisms - flexible\nmasking to take matrix inputs, and a unique network pruning to respect the\nmask's dependency structure. Networks can approximate fixed operations such as\nmatrix-vector multiplication $\\phi(A,x) \\rightarrow Ax$, motivating the\nmechanisms introduced with applications towards litmus-testing dependencies or\ninteraction order in graph-based models.",
            "author": [
                "Jonny Luntzel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06382v2",
                "http://arxiv.org/pdf/2309.06382v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06380v1",
            "title": "InstaFlow: One Step is Enough for High-Quality Diffusion-Based\n  Text-to-Image Generation",
            "updated": "2023-09-12T16:42:09Z",
            "published": "2023-09-12T16:42:09Z",
            "summary": "Diffusion models have revolutionized text-to-image generation with its\nexceptional quality and creativity. However, its multi-step sampling process is\nknown to be slow, often requiring tens of inference steps to obtain\nsatisfactory results. Previous attempts to improve its sampling speed and\nreduce computational costs through distillation have been unsuccessful in\nachieving a functional one-step model. In this paper, we explore a recent\nmethod called Rectified Flow, which, thus far, has only been applied to small\ndatasets. The core of Rectified Flow lies in its \\emph{reflow} procedure, which\nstraightens the trajectories of probability flows, refines the coupling between\nnoises and images, and facilitates the distillation process with student\nmodels. We propose a novel text-conditioned pipeline to turn Stable Diffusion\n(SD) into an ultra-fast one-step model, in which we find reflow plays a\ncritical role in improving the assignment between noise and images. Leveraging\nour new pipeline, we create, to the best of our knowledge, the first one-step\ndiffusion-based text-to-image generator with SD-level image quality, achieving\nan FID (Frechet Inception Distance) of $23.3$ on MS COCO 2017-5k, surpassing\nthe previous state-of-the-art technique, progressive distillation, by a\nsignificant margin ($37.2$ $\\rightarrow$ $23.3$ in FID). By utilizing an\nexpanded network with 1.7B parameters, we further improve the FID to $22.4$. We\ncall our one-step models \\emph{InstaFlow}. On MS COCO 2014-30k, InstaFlow\nyields an FID of $13.1$ in just $0.09$ second, the best in $\\leq 0.1$ second\nregime, outperforming the recent StyleGAN-T ($13.9$ in $0.1$ second). Notably,\nthe training of InstaFlow only costs 199 A100 GPU days. Project\npage:~\\url{https://github.com/gnobitab/InstaFlow}.",
            "author": [
                "Xingchao Liu",
                "Xiwen Zhang",
                "Jianzhu Ma",
                "Jian Peng",
                "Qiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06380v1",
                "http://arxiv.org/pdf/2309.06380v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06351v1",
            "title": "Chemically inspired Erd\u0151s-R\u00e9nyi oriented hypergraphs",
            "updated": "2023-09-12T16:16:25Z",
            "published": "2023-09-12T16:16:25Z",
            "summary": "High-order structures have been recognised as suitable models for systems\ngoing beyond the binary relationships for which graph models are appropriate.\nDespite their importance and surge in research on these structures, their\nrandom cases have been only recently become subjects of interest. One of these\nhigh-order structures is the oriented hypergraph, which relates couples of\nsubsets of an arbitrary number of vertices. Here we develop the\nErd\\H{o}s-R\\'enyi model for oriented hypergraphs, which corresponds to the\nrandom realisation of oriented hyperedges of the complete oriented hypergraph.\nA particular feature of random oriented hypergraphs is that the ratio between\ntheir expected number of oriented hyperedges and their expected degree or size\nis 3/2 for large number of vertices. We highlight the suitability of oriented\nhypergraphs for modelling large collections of chemical reactions and the\nimportance of random oriented hypergraphs to analyse the unfolding of\nchemistry.",
            "author": [
                "Angel Garcia-Chung",
                "Marisol Berm\u00fadez-Monta\u00f1a",
                "Peter F. Stadler",
                "J\u00fcrgen Jost",
                "Guillermo Restrepo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06351v1",
                "http://arxiv.org/pdf/2309.06351v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06348v1",
            "title": "Band-gap regression with architecture-optimized message-passing neural\n  networks",
            "updated": "2023-09-12T16:13:10Z",
            "published": "2023-09-12T16:13:10Z",
            "summary": "Graph-based neural networks and, specifically, message-passing neural\nnetworks (MPNNs) have shown great potential in predicting physical properties\nof solids. In this work, we train an MPNN to first classify materials through\ndensity functional theory data from the AFLOW database as being metallic or\nsemiconducting/insulating. We then perform a neural-architecture search to\nexplore the model architecture and hyperparameter space of MPNNs to predict the\nband gaps of the materials identified as non-metals. The parameters in the\nsearch include the number of message-passing steps, latent size, and\nactivation-function, among others. The top-performing models from the search\nare pooled into an ensemble that significantly outperforms existing models from\nthe literature. Uncertainty quantification is evaluated with Monte-Carlo\nDropout and ensembling, with the ensemble method proving superior. The domain\nof applicability of the ensemble model is analyzed with respect to the crystal\nsystems, the inclusion of a Hubbard parameter in the density functional\ncalculations, and the atomic species building up the materials.",
            "author": [
                "Tim Bechtel",
                "Daniel T. Speckhard",
                "Jonathan Godwin",
                "Claudia Draxl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06348v1",
                "http://arxiv.org/pdf/2309.06348v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06338v1",
            "title": "Eccentric graph of trees and their Cartesian products",
            "updated": "2023-09-12T15:55:29Z",
            "published": "2023-09-12T15:55:29Z",
            "summary": "Let $G$ be an undirected simple connected graph. We say a vertex $u$ is\neccentric to a vertex $v$ in $G$ if $d(u,v)=\\max\\{d(v,w): w\\in V(G)\\}$. The\neccentric graph, $E(G)$ of $G$ is a graph defined on the same vertex set as of\n$G$ and two vertices are adjacent if one is eccentric to the other. We find the\nstructure and the girth of the eccentric graph of trees and see that the girth\nof the eccentric graph of a tree can either be zero, three, or four. Further,\nwe study the structure of the eccentric graph of the Cartesian product of\ngraphs and prove that the girth of the eccentric graph of the Cartesian product\nof trees can only be zero, three, four or six. Furthermore, we provide a\ncomprehensive classification when the eccentric girth assumes these values. We\nalso give the structure of the eccentric graph of the grid graphs and the\nCartesian product of cycles. Finally, we determine the conditions under which\nthe eccentricity matrix of the Cartesian product of trees becomes invertible.",
            "author": [
                "Anita Arora",
                "Rajiv Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06338v1",
                "http://arxiv.org/pdf/2309.06338v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C05, 05C12, 05C50, 05C75"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06335v1",
            "title": "Grounded Language Acquisition From Object and Action Imagery",
            "updated": "2023-09-12T15:52:08Z",
            "published": "2023-09-12T15:52:08Z",
            "summary": "Deep learning approaches to natural language processing have made great\nstrides in recent years. While these models produce symbols that convey vast\namounts of diverse knowledge, it is unclear how such symbols are grounded in\ndata from the world. In this paper, we explore the development of a private\nlanguage for visual data representation by training emergent language (EL)\nencoders/decoders in both i) a traditional referential game environment and ii)\na contrastive learning environment utilizing a within-class matching training\nparadigm. An additional classification layer utilizing neural machine\ntranslation and random forest classification was used to transform symbolic\nrepresentations (sequences of integer symbols) to class labels. These methods\nwere applied in two experiments focusing on object recognition and action\nrecognition. For object recognition, a set of sketches produced by human\nparticipants from real imagery was used (Sketchy dataset) and for action\nrecognition, 2D trajectories were generated from 3D motion capture systems\n(MOVI dataset). In order to interpret the symbols produced for data in each\nexperiment, gradient-weighted class activation mapping (Grad-CAM) methods were\nused to identify pixel regions indicating semantic features which contribute\nevidence towards symbols in learned languages. Additionally, a t-distributed\nstochastic neighbor embedding (t-SNE) method was used to investigate embeddings\nlearned by CNN feature extractors.",
            "author": [
                "James Robert Kubricht",
                "Zhaoyuan Yang",
                "Jianwei Qiu",
                "Peter Henry Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06335v1",
                "http://arxiv.org/pdf/2309.06335v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06330v3",
            "title": "Decentralized Constraint-Coupled Optimization with Inexact Oracle",
            "updated": "2023-10-05T11:28:00Z",
            "published": "2023-09-12T15:42:43Z",
            "summary": "We propose an inexact decentralized dual gradient tracking method (iDDGT) for\ndecentralized optimization problems with a globally coupled equality\nconstraint. Unlike existing algorithms that rely on either the exact dual\ngradient or an inexact one obtained through single-step gradient descent, iDDGT\nintroduces a new approach: utilizing an inexact dual gradient with controllable\nlevels of inexactness. Numerical experiments demonstrate that iDDGT achieves\nsignificantly higher computational efficiency compared to state-of-the-art\nmethods. Furthermore, it is proved that iDDGT can achieve linear convergence\nover directed graphs without imposing any conditions on the constraint matrix.\nThis expands its applicability beyond existing algorithms that require the\nconstraint matrix to have full row rank and undirected graphs for achieving\nlinear convergence.",
            "author": [
                "Jingwang Li",
                "Housheng Su"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06330v3",
                "http://arxiv.org/pdf/2309.06330v3"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06317v1",
            "title": "The Time Complexity of Fully Sparse Matrix Multiplication",
            "updated": "2023-09-12T15:27:50Z",
            "published": "2023-09-12T15:27:50Z",
            "summary": "What is the time complexity of matrix multiplication of sparse integer\nmatrices with $m_{in}$ nonzeros in the input and $m_{out}$ nonzeros in the\noutput? This paper provides improved upper bounds for this question for almost\nany choice of $m_{in}$ vs. $m_{out}$, and provides evidence that these new\nbounds might be optimal up to further progress on fast matrix multiplication.\n  Our main contribution is a new algorithm that reduces sparse matrix\nmultiplication to dense (but smaller) rectangular matrix multiplication. Our\nrunning time thus depends on the optimal exponent $\\omega(a,b,c)$ of\nmultiplying dense $n^a\\times n^b$ by $n^b\\times n^c$ matrices. We discover that\nwhen $m_{out}=\\Theta(m_{in}^r)$ the time complexity of sparse matrix\nmultiplication is $O(m_{in}^{\\sigma+\\epsilon})$, for all $\\epsilon > 0$, where\n$\\sigma$ is the solution to the equation\n$\\omega(\\sigma-1,2-\\sigma,1+r-\\sigma)=\\sigma$. No matter what\n$\\omega(\\cdot,\\cdot,\\cdot)$ turns out to be, and for all $r\\in(0,2)$, the new\nbound beats the state of the art, and we provide evidence that it is optimal\nbased on the complexity of the all-edge triangle problem.\n  In particular, in terms of the input plus output size $m = m_{in} + m_{out}$\nour algorithm runs in time $O(m^{1.3459})$. Even for Boolean matrices, this\nimproves over the previous\n$m^{\\frac{2\\omega}{\\omega+1}+\\epsilon}=O(m^{1.4071})$ bound [Amossen, Pagh;\n2009], which was a natural barrier since it coincides with the longstanding\nbound of all-edge triangle in sparse graphs [Alon, Yuster, Zwick; 1994]. We\nfind it interesting that matrix multiplication can be solved faster than\ntriangle detection in this natural setting. In fact, we establish an\nequivalence to a special case of the all-edge triangle problem.",
            "author": [
                "Amir Abboud",
                "Karl Bringmann",
                "Nick Fischer",
                "Marvin K\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06317v1",
                "http://arxiv.org/pdf/2309.06317v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06315v1",
            "title": "Learning Minimalistic Tsetlin Machine Clauses with Markov\n  Boundary-Guided Pruning",
            "updated": "2023-09-12T15:27:00Z",
            "published": "2023-09-12T15:27:00Z",
            "summary": "A set of variables is the Markov blanket of a random variable if it contains\nall the information needed for predicting the variable. If the blanket cannot\nbe reduced without losing useful information, it is called a Markov boundary.\nIdentifying the Markov boundary of a random variable is advantageous because\nall variables outside the boundary are superfluous. Hence, the Markov boundary\nprovides an optimal feature set. However, learning the Markov boundary from\ndata is challenging for two reasons. If one or more variables are removed from\nthe Markov boundary, variables outside the boundary may start providing\ninformation. Conversely, variables within the boundary may stop providing\ninformation. The true role of each candidate variable is only manifesting when\nthe Markov boundary has been identified. In this paper, we propose a new\nTsetlin Machine (TM) feedback scheme that supplements Type I and Type II\nfeedback. The scheme introduces a novel Finite State Automaton - a\nContext-Specific Independence Automaton. The automaton learns which features\nare outside the Markov boundary of the target, allowing them to be pruned from\nthe TM during learning. We investigate the new scheme empirically, showing how\nit is capable of exploiting context-specific independence to find Markov\nboundaries. Further, we provide a theoretical analysis of convergence. Our\napproach thus connects the field of Bayesian networks (BN) with TMs,\npotentially opening up for synergies when it comes to inference and learning,\nincluding TM-produced Bayesian knowledge bases and TM-based Bayesian inference.",
            "author": [
                "Ole-Christoffer Granmo",
                "Per-Arne Andersen",
                "Lei Jiao",
                "Xuan Zhang",
                "Christian Blakely",
                "Tor Tveit"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06315v1",
                "http://arxiv.org/pdf/2309.06315v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06312v1",
            "title": "Graded homotopy classification of Leavitt path algebras",
            "updated": "2023-09-12T15:23:27Z",
            "published": "2023-09-12T15:23:27Z",
            "summary": "We show that the graded Grothendieck group classifies unital Leavitt path\nalgebras of primitive graphs up to graded homotopy equivalence. To this end, we\nfurther develop classification techniques for Leavitt path algebras by means of\n(graded, bivariant) algebraic $K$-theory.",
            "author": [
                "Guido Arnone"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06312v1",
                "http://arxiv.org/pdf/2309.06312v1"
            ],
            "primary_category": "math.KT",
            "category": [
                "math.KT",
                "math.OA",
                "math.RA",
                "16S88 (Primary), 19A49, 16W50 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06308v1",
            "title": "AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and\n  Analysis of Eating Behaviours",
            "updated": "2023-09-12T15:19:36Z",
            "published": "2023-09-12T15:19:36Z",
            "summary": "Nowadays millions of images are shared on social media and web platforms. In\nparticular, many of them are food images taken from a smartphone over time,\nproviding information related to the individual's diet. On the other hand,\neating behaviours are directly related to some of the most prevalent diseases\nin the world. Exploiting recent advances in image processing and Artificial\nIntelligence (AI), this scenario represents an excellent opportunity to: i)\ncreate new methods that analyse the individuals' health from what they eat, and\nii) develop personalised recommendations to improve nutrition and diet under\nspecific circumstances (e.g., obesity or COVID). Having tunable tools for\ncreating food image datasets that facilitate research in both lines is very\nmuch needed.\n  This paper proposes AI4Food-NutritionFW, a framework for the creation of food\nimage datasets according to configurable eating behaviours. AI4Food-NutritionFW\nsimulates a user-friendly and widespread scenario where images are taken using\na smartphone. In addition to the framework, we also provide and describe a\nunique food image dataset that includes 4,800 different weekly eating\nbehaviours from 15 different profiles and 1,200 subjects. Specifically, we\nconsider profiles that comply with actual lifestyles from healthy eating\nbehaviours (according to established knowledge), variable profiles (e.g.,\neating out, holidays), to unhealthy ones (e.g., excess of fast food or sweets).\nFinally, we automatically evaluate a healthy index of the subject's eating\nbehaviours using multidimensional metrics based on guidelines for healthy diets\nproposed by international organisations, achieving promising results (99.53%\nand 99.60% accuracy and sensitivity, respectively). We also release to the\nresearch community a software implementation of our proposed\nAI4Food-NutritionFW and the mentioned food image dataset created with it.",
            "author": [
                "Sergio Romero-Tapiador",
                "Ruben Tolosana",
                "Aythami Morales",
                "Isabel Espinosa-Salinas",
                "Gala Freixer",
                "Julian Fierrez",
                "Ruben Vera-Rodriguez",
                "Enrique Carrillo de Santa Pau",
                "Ana Ram\u00edrez de Molina",
                "Javier Ortega-Garcia"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2023.3322770",
                "http://arxiv.org/abs/2309.06308v1",
                "http://arxiv.org/pdf/2309.06308v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06288v1",
            "title": "Self-Training and Multi-Task Learning for Limited Data: Evaluation Study\n  on Object Detection",
            "updated": "2023-09-12T14:50:14Z",
            "published": "2023-09-12T14:50:14Z",
            "summary": "Self-training allows a network to learn from the predictions of a more\ncomplicated model, thus often requires well-trained teacher models and mixture\nof teacher-student data while multi-task learning jointly optimizes different\ntargets to learn salient interrelationship and requires multi-task annotations\nfor each training example. These frameworks, despite being particularly data\ndemanding have potentials for data exploitation if such assumptions can be\nrelaxed. In this paper, we compare self-training object detection under the\ndeficiency of teacher training data where students are trained on unseen\nexamples by the teacher, and multi-task learning with partially annotated data,\ni.e. single-task annotation per training example. Both scenarios have their own\nlimitation but potentially helpful with limited annotated data. Experimental\nresults show the improvement of performance when using a weak teacher with\nunseen data for training a multi-task student. Despite the limited setup we\nbelieve the experimental results show the potential of multi-task knowledge\ndistillation and self-training, which could be beneficial for future study.\nSource code is at https://lhoangan.github.io/multas.",
            "author": [
                "Ho\u00e0ng-\u00c2n L\u00ea",
                "Minh-Tan Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06288v1",
                "http://arxiv.org/pdf/2309.06288v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06286v1",
            "title": "Transferability analysis of data-driven additive manufacturing\n  knowledge: a case study between powder bed fusion and directed energy\n  deposition",
            "updated": "2023-09-12T14:46:56Z",
            "published": "2023-09-12T14:46:56Z",
            "summary": "Data-driven research in Additive Manufacturing (AM) has gained significant\nsuccess in recent years. This has led to a plethora of scientific literature to\nemerge. The knowledge in these works consists of AM and Artificial Intelligence\n(AI) contexts that have not been mined and formalized in an integrated way.\nMoreover, no tools or guidelines exist to support data-driven knowledge\ntransfer from one context to another. As a result, data-driven solutions using\nspecific AI techniques are being developed and validated only for specific AM\nprocess technologies. There is a potential to exploit the inherent similarities\nacross various AM technologies and adapt the existing solutions from one\nprocess or problem to another using AI, such as Transfer Learning. We propose a\nthree-step knowledge transferability analysis framework in AM to support\ndata-driven AM knowledge transfer. As a prerequisite to transferability\nanalysis, AM knowledge is featurized into identified knowledge components. The\nframework consists of pre-transfer, transfer, and post-transfer steps to\naccomplish knowledge transfer. A case study is conducted between flagship metal\nAM processes. Laser Powder Bed Fusion (LPBF) is the source of knowledge\nmotivated by its relative matureness in applying AI over Directed Energy\nDeposition (DED), which drives the need for knowledge transfer as the less\nexplored target process. We show successful transfer at different levels of the\ndata-driven solution, including data representation, model architecture, and\nmodel parameters. The pipeline of AM knowledge transfer can be automated in the\nfuture to allow efficient cross-context or cross-process knowledge exchange.",
            "author": [
                "Mutahar Safdar",
                "Jiarui Xie",
                "Hyunwoong Ko",
                "Yan Lu",
                "Guy Lamouche",
                "Yaoyao Fiona Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06286v1",
                "http://arxiv.org/pdf/2309.06286v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06284v1",
            "title": "Fg-T2M: Fine-Grained Text-Driven Human Motion Generation via Diffusion\n  Model",
            "updated": "2023-09-12T14:43:47Z",
            "published": "2023-09-12T14:43:47Z",
            "summary": "Text-driven human motion generation in computer vision is both significant\nand challenging. However, current methods are limited to producing either\ndeterministic or imprecise motion sequences, failing to effectively control the\ntemporal and spatial relationships required to conform to a given text\ndescription. In this work, we propose a fine-grained method for generating\nhigh-quality, conditional human motion sequences supporting precise text\ndescription. Our approach consists of two key components: 1) a\nlinguistics-structure assisted module that constructs accurate and complete\nlanguage feature to fully utilize text information; and 2) a context-aware\nprogressive reasoning module that learns neighborhood and overall semantic\nlinguistics features from shallow and deep graph neural networks to achieve a\nmulti-step inference. Experiments show that our approach outperforms\ntext-driven motion generation methods on HumanML3D and KIT test sets and\ngenerates better visually confirmed motion to the text conditions.",
            "author": [
                "Yin Wang",
                "Zhiying Leng",
                "Frederick W. B. Li",
                "Shun-Cheng Wu",
                "Xiaohui Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06284v1",
                "http://arxiv.org/pdf/2309.06284v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.18745v1",
            "title": "On Cohomology of Graph Complexes",
            "updated": "2023-09-12T14:27:12Z",
            "published": "2023-09-12T14:27:12Z",
            "summary": "This is a copy of my bachelor thesis, written under supervision of Sergey\nShadrin in 2010. Original abstract: In this thesis we prove that the wheeled\nPoisson operad is not a wheeled Koszul operad. Chapter 1 introduces operads,\nthe subclass of quadratic operads, and their Koszulness. In chapter 2, all\nthese notions are extended to the case of wheeled operads, and we pose the main\nquestion. In chapter 3, some techniques for computing cohomology are\nintroduced, and the first cycle that obstructs the Koszulness of the wheeled\nPoisson operad is found.",
            "author": [
                "Simen Bruinsma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18745v1",
                "http://arxiv.org/pdf/2311.18745v1"
            ],
            "primary_category": "math.KT",
            "category": [
                "math.KT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06258v2",
            "title": "Work Statistics and Adiabatic Assumption in Nonequilibrium Many-Body\n  Theory",
            "updated": "2023-09-21T16:47:06Z",
            "published": "2023-09-12T14:17:43Z",
            "summary": "Keldysh field theory, based on adiabatic assumptions, serves as an widely\nused framework for addressing nonequilibrium many-body systems. Nonetheless,\nthe validity of such adiabatic assumptions when addressing interacting Gibbs\nstates remains a topic of contention. We use the knowledge of work statistics\ndeveloped in nonequilibrium thermodynamics to study this problem. Consequently,\nwe deduce a universal theorem delineating the characteristics of evolutions\nthat transition an initial Gibbs state to another. Based on this theorem, we\nanalytically ascertain that adiabatic evolutions fail to transition a\nnon-interacting Gibbs state to its interacting counterpart. However, this\nadiabatic approach remains a superior approximation relative to its\nnon-adiabatic counterpart. Numerics verifying our theory and predictions are\nalso provided. Furthermore, our findings render insights into the preparation\nof Gibbs states within the domain of quantum computation.",
            "author": [
                "Yi Zuo",
                "Qinghong Yang",
                "Bang-Gui Liu",
                "Dong E Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06258v2",
                "http://arxiv.org/pdf/2309.06258v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06247v1",
            "title": "Lipschitz harmonic functions on vertex-transitive graphs",
            "updated": "2023-09-12T14:04:06Z",
            "published": "2023-09-12T14:04:06Z",
            "summary": "We prove that every locally finite vertex-transitive graph $G$ admits a\nnon-constant Lipschitz harmonic function.",
            "author": [
                "Gideon Amir",
                "Guy Blachar",
                "Maria Gerasimova",
                "Gady Kozma"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06247v1",
                "http://arxiv.org/pdf/2309.06247v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "31C05, 05C63, 43A07, 05E18"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06234v1",
            "title": "The zero forcing span of a graph",
            "updated": "2023-09-12T13:51:14Z",
            "published": "2023-09-12T13:51:14Z",
            "summary": "In zero forcing, the focus is typically on finding the minimum cardinality of\nany zero forcing set in the graph; however, the number of cardinalities between\n$0$ and the number of vertices in the graph for which there are both zero\nforcing sets and sets that fail to be zero forcing sets is not well known. In\nthis paper, we introduce the zero forcing span of a graph, which is the number\nof distinct cardinalities for which there are sets that are zero forcing sets\nand sets that are not. We introduce the span within the context of standard\nzero forcing and skew zero forcing as well as for standard zero forcing on\ndirected graphs. We characterize graphs with high span and low span of each\ntype, and also investigate graphs with special zero forcing polynomials.",
            "author": [
                "Bonnie Jacob"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06234v1",
                "http://arxiv.org/pdf/2309.06234v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06229v3",
            "title": "PreciseBugCollector: Extensible, Executable and Precise Bug-fix\n  Collection",
            "updated": "2023-10-06T16:00:26Z",
            "published": "2023-09-12T13:47:44Z",
            "summary": "Bug datasets are vital for enabling deep learning techniques to address\nsoftware maintenance tasks related to bugs. However, existing bug datasets\nsuffer from precise and scale limitations: they are either small-scale but\nprecise with manual validation or large-scale but imprecise with simple commit\nmessage processing. In this paper, we introduce PreciseBugCollector, a precise,\nmulti-language bug collection approach that overcomes these two limitations.\nPreciseBugCollector is based on two novel components: a) A bug tracker to map\nthe codebase repositories with external bug repositories to trace bug type\ninformation, and b) A bug injector to generate project-specific bugs by\ninjecting noise into the correct codebases and then executing them against\ntheir test suites to obtain test failure messages.\n  We implement PreciseBugCollector against three sources: 1) A bug tracker that\nlinks to the national vulnerability data set (NVD) to collect general-wise\nvulnerabilities, 2) A bug tracker that links to OSS-Fuzz to collect\ngeneral-wise bugs, and 3) A bug injector based on 16 injection rules to\ngenerate project-wise bugs. To date, PreciseBugCollector comprises 1057818 bugs\nextracted from 2968 open-source projects. Of these, 12602 bugs are sourced from\nbug repositories (NVD and OSS-Fuzz), while the remaining 1045216\nproject-specific bugs are generated by the bug injector. Considering the\nchallenge objectives, we argue that a bug injection approach is highly valuable\nfor the industrial setting, since project-specific bugs align with domain\nknowledge, share the same codebase, and adhere to the coding style employed in\nindustrial projects.",
            "author": [
                "He Ye",
                "Zimin Chen",
                "Claire Le Goues"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06229v3",
                "http://arxiv.org/pdf/2309.06229v3"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06222v1",
            "title": "Lower bounds on the homology of Vietoris-Rips complexes of hypercube\n  graphs",
            "updated": "2023-09-12T13:42:18Z",
            "published": "2023-09-12T13:42:18Z",
            "summary": "We provide novel lower bounds on the Betti numbers of Vietoris-Rips complexes\nof hypercube graphs of all dimensions, and at all scales. In more detail, let\n$Q_n$ be the vertex set of $2^n$ vertices in the $n$-dimensional hypercube\ngraph, equipped with the shortest path metric. Let $VR(Q_n;r)$ be its\nVietoris--Rips complex at scale parameter $r \\ge 0$, which has $Q_n$ as its\nvertex set, and all subsets of diameter at most $r$ as its simplices. For\nintegers $r<r'$ the inclusion $VR(Q_n;r)\\hookrightarrow VR(Q_n;r')$ is\nnullhomotopic, meaning no persistent homology bars have length longer than one,\nand we therefore focus attention on the individual spaces $VR(Q_n;r)$. We\nprovide lower bounds on the ranks of homology groups of $VR(Q_n;r)$. For\nexample, using cross-polytopal generators, we prove that the rank of\n$H_{2^r-1}(VR(Q_n;r))$ is at least $2^{n-(r+1)}\\binom{n}{r+1}$. We also prove a\nversion of \\emph{homology propagation}: if $q\\ge 1$ and if $p$ is the smallest\ninteger for which $rank H_q(VR(Q_p;r))\\neq 0$, then $rank H_q(VR(Q_n;r)) \\ge\n\\sum_{i=p}^n 2^{i-p} \\binom{i-1}{p-1} \\cdot rank H_q(VR(Q_p;r))$ for all $n \\ge\np$. When $r\\le 3$, this result and variants thereof provide tight lower bounds\non the rank of $H_q(VR(Q_n;r))$ for all $n$, and for each $r \\ge 4$ we produce\nnovel lower bounds on the ranks of homology groups. Furthermore, we show that\nfor each $r\\ge 2$, the homology groups of $VR(Q_n;r)$ for $n \\ge 2r+1$ contain\npropagated homology not induced by the initial cross-polytopal generators.",
            "author": [
                "Henry Adams",
                "\u017diga Virk"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06222v1",
                "http://arxiv.org/pdf/2309.06222v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06219v2",
            "title": "Human Action Co-occurrence in Lifestyle Vlogs using Graph Link\n  Prediction",
            "updated": "2023-09-22T18:27:57Z",
            "published": "2023-09-12T13:38:44Z",
            "summary": "We introduce the task of automatic human action co-occurrence identification,\ni.e., determine whether two human actions can co-occur in the same interval of\ntime. We create and make publicly available the ACE (Action Co-occurrencE)\ndataset, consisting of a large graph of ~12k co-occurring pairs of visual\nactions and their corresponding video clips. We describe graph link prediction\nmodels that leverage visual and textual information to automatically infer if\ntwo actions are co-occurring. We show that graphs are particularly well suited\nto capture relations between human actions, and the learned graph\nrepresentations are effective for our task and capture novel and relevant\ninformation across different data domains. The ACE dataset and the code\nintroduced in this paper are publicly available at\nhttps://github.com/MichiganNLP/vlog_action_co-occurrence.",
            "author": [
                "Oana Ignat",
                "Santiago Castro",
                "Weiji Li",
                "Rada Mihalcea"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06219v2",
                "http://arxiv.org/pdf/2309.06219v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.CY",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06213v1",
            "title": "Higman-Thompson groups and profinite properties of right-angled Coxeter\n  groups",
            "updated": "2023-09-12T13:31:16Z",
            "published": "2023-09-12T13:31:16Z",
            "summary": "We prove that every right-angled Coxeter group (RACG) is profinitely rigid\namongst all Coxeter groups. On the other hand we exhibit RACGs which have\ninfinite profinite genus amongst all finitely generated residually finite\ngroups. We also establish profinite rigidity results for graph products of\nfinite groups. Along the way we prove that the Higman-Thompson groups $V_{n}$\nare generated by $4$ involutions, generalising a classical result of Higman for\nThompson's group $V$.",
            "author": [
                "Samuel M. Corson",
                "Sam Hughes",
                "Philip M\u00f6ller",
                "Olga Varghese"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06213v1",
                "http://arxiv.org/pdf/2309.06213v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "Primary: 20F55, 20E18, Secondary: 20E36, 20F65, 20E45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06207v1",
            "title": "SGFeat: Salient Geometric Feature for Point Cloud Registration",
            "updated": "2023-09-12T13:21:12Z",
            "published": "2023-09-12T13:21:12Z",
            "summary": "Point Cloud Registration (PCR) is a critical and challenging task in computer\nvision. One of the primary difficulties in PCR is identifying salient and\nmeaningful points that exhibit consistent semantic and geometric properties\nacross different scans. Previous methods have encountered challenges with\nambiguous matching due to the similarity among patch blocks throughout the\nentire point cloud and the lack of consideration for efficient global geometric\nconsistency. To address these issues, we propose a new framework that includes\nseveral novel techniques. Firstly, we introduce a semantic-aware geometric\nencoder that combines object-level and patch-level semantic information. This\nencoder significantly improves registration recall by reducing ambiguity in\npatch-level superpoint matching. Additionally, we incorporate a prior knowledge\napproach that utilizes an intrinsic shape signature to identify salient points.\nThis enables us to extract the most salient super points and meaningful dense\npoints in the scene. Secondly, we introduce an innovative transformer that\nencodes High-Order (HO) geometric features. These features are crucial for\nidentifying salient points within initial overlap regions while considering\nglobal high-order geometric consistency. To optimize this high-order\ntransformer further, we introduce an anchor node selection strategy. By\nencoding inter-frame triangle or polyhedron consistency features based on these\nanchor nodes, we can effectively learn high-order geometric features of salient\nsuper points. These high-order features are then propagated to dense points and\nutilized by a Sinkhorn matching module to identify key correspondences for\nsuccessful registration. In our experiments conducted on well-known datasets\nsuch as 3DMatch/3DLoMatch and KITTI, our approach has shown promising results,\nhighlighting the effectiveness of our novel method.",
            "author": [
                "Qianliang Wu",
                "Yaqing Ding",
                "Lei Luo",
                "Chuanwei Zhou",
                "Jin Xie",
                "Jian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06207v1",
                "http://arxiv.org/pdf/2309.06207v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06201v1",
            "title": "High Order Numerical Methods To Approximate The Singular Value\n  Decomposition",
            "updated": "2023-09-12T13:09:49Z",
            "published": "2023-09-12T13:09:49Z",
            "summary": "In this paper, we present a class of high order methods to approximate the\nsingular value decomposition of a given complex matrix (SVD). To the best of\nour knowledge, only methods up to order three appear in the the literature. A\nfirst part is dedicated to defline and analyse this class of method in the\nregular case, i.e., when the singular values are pairwise distinct. The\nconstruction is based on a perturbation analysis of a suitable system of\nassociated to the SVD (SVD system). More precisely, for an integer $p$ be\ngiven, we define a sequence which converges with an order $p + 1$ towards the\nleft-right singular vectors and the singular values if the initial\napproximation of the SVD system satisfies a condition which depends on three\nquantities : the norm of initial approximation of the SVD system, the greatest\nsingular value and the greatest inverse of the modulus of the difference\nbetween the singular values. From a numerical computational point of view, this\nfurnishes a very efficient simple test to prove and certifiy the existence of a\nSVD in neighborhood of the initial approximation. We generalize these result in\nthe case of clusters of singular values. We show also how to use the result of\nregular case to detect the clusters of singular values and to define a notion\nof deflation of the SVD. Moreover numerical experiments confirm the theoretical\nresults.",
            "author": [
                "Diego Armentano",
                "Jean-Claude Yakoubsohn"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06201v1",
                "http://arxiv.org/pdf/2309.06201v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65F99, 68W25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06175v2",
            "title": "AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity\n  Recognition and Linking",
            "updated": "2023-09-13T03:53:43Z",
            "published": "2023-09-12T12:37:37Z",
            "summary": "This paper presents a novel approach to address the Entity Recognition and\nLinking Challenge at NLPCC 2015. The task involves extracting named entity\nmentions from short search queries and linking them to entities within a\nreference Chinese knowledge base. To tackle this problem, we first expand the\nexisting knowledge base and utilize external knowledge to identify candidate\nentities, thereby improving the recall rate. Next, we extract features from the\ncandidate entities and utilize Support Vector Regression and Multiple Additive\nRegression Tree as scoring functions to filter the results. Additionally, we\napply rules to further refine the results and enhance precision. Our method is\ncomputationally efficient and achieves an F1 score of 0.535.",
            "author": [
                "Di Lu",
                "Zhongping Liang",
                "Caixia Yuan",
                "Xiaojie Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06175v2",
                "http://arxiv.org/pdf/2309.06175v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06144v1",
            "title": "Conjugacy Class Growth in Virtually Abelian Groups",
            "updated": "2023-09-12T11:33:26Z",
            "published": "2023-09-12T11:33:26Z",
            "summary": "We study the conjugacy class growth function in finitely generated virtually\nabelian groups. That is, the number of elements in the ball of radius $n$ in\nthe Cayley graph which intersect a fixed conjugacy class. In the class of\nvirtually abelian groups, we prove that this function is always asymptotically\nequivalent to a polynomial. Furthermore, we show that in any affine Coxeter\ngroup, the degree of polynomial growth of a conjugacy class is equivalent to\nthe reflection length of any element of that class.",
            "author": [
                "Aram Dermenjian",
                "Alex Evetts"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06144v1",
                "http://arxiv.org/pdf/2309.06144v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO",
                "05E16, 20E45, 20F55, 20F69"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06130v1",
            "title": "JOADAA: joint online action detection and action anticipation",
            "updated": "2023-09-12T11:17:25Z",
            "published": "2023-09-12T11:17:25Z",
            "summary": "Action anticipation involves forecasting future actions by connecting past\nevents to future ones. However, this reasoning ignores the real-life hierarchy\nof events which is considered to be composed of three main parts: past,\npresent, and future. We argue that considering these three main parts and their\ndependencies could improve performance. On the other hand, online action\ndetection is the task of predicting actions in a streaming manner. In this\ncase, one has access only to the past and present information. Therefore, in\nonline action detection (OAD) the existing approaches miss semantics or future\ninformation which limits their performance. To sum up, for both of these tasks,\nthe complete set of knowledge (past-present-future) is missing, which makes it\nchallenging to infer action dependencies, therefore having low performances. To\naddress this limitation, we propose to fuse both tasks into a single uniform\narchitecture. By combining action anticipation and online action detection, our\napproach can cover the missing dependencies of future information in online\naction detection. This method referred to as JOADAA, presents a uniform model\nthat jointly performs action anticipation and online action detection. We\nvalidate our proposed model on three challenging datasets: THUMOS'14, which is\na sparsely annotated dataset with one action per time step, CHARADES, and\nMulti-THUMOS, two densely annotated datasets with more complex scenarios.\nJOADAA achieves SOTA results on these benchmarks for both tasks.",
            "author": [
                "Mohammed Guermal",
                "Francois Bremond",
                "Rui Dai",
                "Abid Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06130v1",
                "http://arxiv.org/pdf/2309.06130v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06116v1",
            "title": "Distinguishing colorings, proper colorings, and covering properties\n  without the Axiom of Choice",
            "updated": "2023-09-12T10:31:59Z",
            "published": "2023-09-12T10:31:59Z",
            "summary": "We work with simple graphs in ZF (Zermelo--Fraenkel set theory without the\nAxiom of Choice (AC)) and cardinals in the absence of AC to prove that the\nfollowing statements are equivalent to K\\H{o}nig Lemma: (a) Any infinite\nlocally finite connected graph G such that the minimum degree of G is greater\nthan k, has a chromatic number for any fixed integer k greater than or equal to\n2. (b) Any infinite locally finite connected graph has a chromatic index. (c)\nAny infinite locally finite connected graph has a distinguishing number. (d)\nAny infinite locally finite connected graph has a distinguishing index.\n  Our results strengthen some results of Stawiski from a recent paper on the\nrole of the Axiom of Choice in proper and distinguishing colorings since\nStawiski worked with cardinals in the presence of AC.\n  We also formulate new conditions for the existence of irreducible proper\ncoloring, minimal edge cover, maximal matching, and minimal dominating set in\nconnected bipartite graphs and locally finite connected graphs, which are\neither equivalent to AC or K\\H{o}nig Lemma. Moreover, we show that if the Axiom\nof Choice for families of 2 element sets holds, then the Shelah--Soifer graph\nhas a minimal dominating set.",
            "author": [
                "Amitayu Banerjee",
                "Zal\u00e1n Moln\u00e1r",
                "Alexa Gopaulsingh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06116v1",
                "http://arxiv.org/pdf/2309.06116v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.LO",
                "03E25 (Primary) 05C63, 05C15, 05C69 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06089v1",
            "title": "Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms:\n  Exploring Tuning Strategies",
            "updated": "2023-09-12T09:37:08Z",
            "published": "2023-09-12T09:37:08Z",
            "summary": "The cross-lingual transfer is a promising technique to solve tasks in\nless-resourced languages. In this empirical study, we compare two fine-tuning\napproaches combined with zero-shot and full-shot learning approaches for large\nlanguage models in a cross-lingual setting. As fine-tuning strategies, we\ncompare parameter-efficient adapter methods with fine-tuning of all parameters.\nAs cross-lingual transfer strategies, we compare the intermediate-training\n(\\textit{IT}) that uses each language sequentially and cross-lingual validation\n(\\textit{CLV}) that uses a target language already in the validation phase of\nfine-tuning. We assess the success of transfer and the extent of catastrophic\nforgetting in a source language due to cross-lingual transfer, i.e., how much\npreviously acquired knowledge is lost when we learn new information in a\ndifferent language. The results on two different classification problems, hate\nspeech detection and product reviews, each containing datasets in several\nlanguages, show that the \\textit{IT} cross-lingual strategy outperforms\n\\textit{CLV} for the target language. Our findings indicate that, in the\nmajority of cases, the \\textit{CLV} strategy demonstrates superior retention of\nknowledge in the base language (English) compared to the \\textit{IT} strategy,\nwhen evaluating catastrophic forgetting in multiple cross-lingual transfers.",
            "author": [
                "Boshko Koloski",
                "Bla\u017e \u0160krlj",
                "Marko Robnik-\u0160ikonja",
                "Senja Pollak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06089v1",
                "http://arxiv.org/pdf/2309.06089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06087v1",
            "title": "Further results on the number of cliques in graphs covered by long\n  cycles",
            "updated": "2023-09-12T09:36:46Z",
            "published": "2023-09-12T09:36:46Z",
            "summary": "Let $\\Gamma(n,k)$ be the set of $2$-connected $n$-vertex graphs containing an\nedge that is not on any cycle of length at least $k+1.$ Let $g_s(n,k)$ denote\nthe maximum number of $s$-cliques in a graph in $\\Gamma(n,k).$ Recently, Ji and\nYe [SIAM J. Discrete Math., 37 (2023) 917-924] determined $g_s(n,k).$ They\nremark that it is interesting to characterize the extremal graphs. In this\npaper, we give such a characterization.",
            "author": [
                "Leilei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06087v1",
                "http://arxiv.org/pdf/2309.06087v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06086v1",
            "title": "Plasticity-Optimized Complementary Networks for Unsupervised Continual\n  Learning",
            "updated": "2023-09-12T09:31:34Z",
            "published": "2023-09-12T09:31:34Z",
            "summary": "Continuous unsupervised representation learning (CURL) research has greatly\nbenefited from improvements in self-supervised learning (SSL) techniques. As a\nresult, existing CURL methods using SSL can learn high-quality representations\nwithout any labels, but with a notable performance drop when learning on a\nmany-tasks data stream. We hypothesize that this is caused by the\nregularization losses that are imposed to prevent forgetting, leading to a\nsuboptimal plasticity-stability trade-off: they either do not adapt fully to\nthe incoming data (low plasticity), or incur significant forgetting when\nallowed to fully adapt to a new SSL pretext-task (low stability). In this work,\nwe propose to train an expert network that is relieved of the duty of keeping\nthe previous knowledge and can focus on performing optimally on the new tasks\n(optimizing plasticity). In the second phase, we combine this new knowledge\nwith the previous network in an adaptation-retrospection phase to avoid\nforgetting and initialize a new expert with the knowledge of the old network.\nWe perform several experiments showing that our proposed approach outperforms\nother CURL exemplar-free methods in few- and many-task split settings.\nFurthermore, we show how to adapt our approach to semi-supervised continual\nlearning (Semi-SCL) and show that we surpass the accuracy of other\nexemplar-free Semi-SCL methods and reach the results of some others that use\nexemplars.",
            "author": [
                "Alex Gomez-Villa",
                "Bartlomiej Twardowski",
                "Kai Wang",
                "Joost van de Weijer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06086v1",
                "http://arxiv.org/pdf/2309.06086v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06081v1",
            "title": "Information Flow in Graph Neural Networks: A Clinical Triage Use Case",
            "updated": "2023-09-12T09:18:12Z",
            "published": "2023-09-12T09:18:12Z",
            "summary": "Graph Neural Networks (GNNs) have gained popularity in healthcare and other\ndomains due to their ability to process multi-modal and multi-relational\ngraphs. However, efficient training of GNNs remains challenging, with several\nopen research questions. In this paper, we investigate how the flow of\nembedding information within GNNs affects the prediction of links in Knowledge\nGraphs (KGs). Specifically, we propose a mathematical model that decouples the\nGNN connectivity from the connectivity of the graph data and evaluate the\nperformance of GNNs in a clinical triage use case. Our results demonstrate that\nincorporating domain knowledge into the GNN connectivity leads to better\nperformance than using the same connectivity as the KG or allowing\nunconstrained embedding propagation. Moreover, we show that negative edges play\na crucial role in achieving good predictions, and that using too many GNN\nlayers can degrade performance.",
            "author": [
                "V\u00edctor Valls",
                "Mykhaylo Zayats",
                "Alessandra Pascale"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06081v1",
                "http://arxiv.org/pdf/2309.06081v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06072v1",
            "title": "The $\u03c7$-binding function of $d$-directional segment graphs",
            "updated": "2023-09-12T09:09:42Z",
            "published": "2023-09-12T09:09:42Z",
            "summary": "Given a positive integer $d$, the class $d$-DIR is defined as all those\nintersection graphs formed from a finite collection of line segments in\n${\\mathbb R}^2$ having at most $d$ slopes. Since each slope induces an interval\ngraph, it easily follows for every $G$ in $d$-DIR with clique number at most\n$\\omega$ that the chromatic number $\\chi(G)$ of $G$ is at most $d\\omega$. We\nshow for every even value of $\\omega$ how to construct a graph in $d$-DIR that\nmeets this bound exactly. This partially confirms a conjecture of Bhattacharya,\nDvo\\v{r}\\'ak and Noorizadeh. Furthermore, we show that the $\\chi$-binding\nfunction of $d$-DIR is $\\omega \\mapsto d\\omega$ for $\\omega$ even and $\\omega\n\\mapsto d(\\omega-1)+1$ for $\\omega$ odd. This refutes said conjecture of\nBhattacharya, Dvo\\v{r}\\'ak and Noorizadeh.",
            "author": [
                "Lech Duraj",
                "Ross J. Kang",
                "Hoang La",
                "Jonathan Narboni",
                "Filip Pokr\u00fdvka",
                "Cl\u00e9ment Rambaud",
                "Amadeus Reinald"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06072v1",
                "http://arxiv.org/pdf/2309.06072v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C15, 05C62, 05C17"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06066v1",
            "title": "From inhomogeneous random digraphs to random graphs with fixed arc\n  counts",
            "updated": "2023-09-12T09:06:40Z",
            "published": "2023-09-12T09:06:40Z",
            "summary": "Consider a random graph model with $n$ vertices where each vertex has a\nvertex-type drawn from some discrete distribution. Suppose that the number of\narcs to be placed between each pair of vertex-types is known, and that each arc\nis placed uniformly at random without replacement between one of the\nvertex-pairs with matching types. In this paper, we will show that under\ncertain conditions this random graph model is equivalent to the well-studied\ninhomogeneous random digraph model.\n  We will use this equivalence in three applications. First, we will apply the\nequivalence on some well known random graph models (the Erd\\H{o}s-R\\'enyi\nmodel, the stochastic block model, and the Chung-Lu model) to showcase what\ntheir equivalent counterparts with fixed arcs look like. Secondly, we will\nextend this equivalence to a practical model for inferring cell-cell\ninteractions to showcase how theoretical knowledge about inhomogeneous random\ndigraphs can be transferred to a modeling context. Thirdly, we will show how\nour model induces a natural fast algorithm to generate inhomogeneous random\ndigraphs.",
            "author": [
                "Mike van Santvoort",
                "Pim van der Hoorn"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06066v1",
                "http://arxiv.org/pdf/2309.06066v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60B99, 05C80, 60F99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06061v1",
            "title": "Verifiable Fairness: Privacy-preserving Computation of Fairness for\n  Machine Learning Systems",
            "updated": "2023-09-12T09:00:03Z",
            "published": "2023-09-12T09:00:03Z",
            "summary": "Fair machine learning is a thriving and vibrant research topic. In this\npaper, we propose Fairness as a Service (FaaS), a secure, verifiable and\nprivacy-preserving protocol to computes and verify the fairness of any machine\nlearning (ML) model. In the deisgn of FaaS, the data and outcomes are\nrepresented through cryptograms to ensure privacy. Also, zero knowledge proofs\nguarantee the well-formedness of the cryptograms and underlying data. FaaS is\nmodel--agnostic and can support various fairness metrics; hence, it can be used\nas a service to audit the fairness of any ML model. Our solution requires no\ntrusted third party or private channels for the computation of the fairness\nmetric. The security guarantees and commitments are implemented in a way that\nevery step is securely transparent and verifiable from the start to the end of\nthe process. The cryptograms of all input data are publicly available for\neveryone, e.g., auditors, social activists and experts, to verify the\ncorrectness of the process. We implemented FaaS to investigate performance and\ndemonstrate the successful use of FaaS for a publicly available data set with\nthousands of entries.",
            "author": [
                "Ehsan Toreini",
                "Maryam Mehrnezhad",
                "Aad van Moorsel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06061v1",
                "http://arxiv.org/pdf/2309.06061v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06056v1",
            "title": "Convergence to the asymptotic large deviation limit",
            "updated": "2023-09-12T08:50:38Z",
            "published": "2023-09-12T08:50:38Z",
            "summary": "Large deviation theory offers a powerful and general statistical framework to\nstudy the asymptotic dynamical properties of rare events. The application of\nthe formalism to concrete experimental situations is, however, often restricted\nby finite statistics. Data might not suffice to reach the asymptotic regime or\njudge whether large deviation estimators converge at all. We here\nexperimentally investigate the large deviation properties of the stochastic\nwork and heat of a levitated nanoparticle subjected to nonequilibrium feedback\ncontrol. This setting allows us to determine for each quantity the convergence\ndomain of the large deviation estimators using a criterion that does not\nrequire the knowledge of the probability distribution. By extracting both the\nasymptotic exponential decay and the subexponential prefactors, we demonstrate\nthat singular prefactors significantly restrict the convergence\ncharacteristics. Our results provide unique insight into the approach to the\nasymptotic large deviation limit and underscore the pivotal role of singular\nprefactors.",
            "author": [
                "Maxime Debiossac",
                "Nikolai Kiesel",
                "Eric Lutz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06056v1",
                "http://arxiv.org/pdf/2309.06056v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06053v2",
            "title": "Confounder selection via iterative graph expansion",
            "updated": "2023-10-24T22:01:23Z",
            "published": "2023-09-12T08:42:22Z",
            "summary": "Confounder selection, namely choosing a set of covariates to control for\nconfounding between a treatment and an outcome, is arguably the most important\nstep in the design of observational studies. Previous methods, such as Pearl's\ncelebrated back-door criterion, typically require pre-specifying a causal\ngraph, which can often be difficult in practice. We propose an interactive\nprocedure for confounder selection that does not require pre-specifying the\ngraph or the set of observed variables. This procedure iteratively expands the\ncausal graph by finding what we call \"primary adjustment sets\" for a pair of\npossibly confounded variables. This can be viewed as inverting a sequence of\nlatent projections of the underlying causal graph. Structural information in\nthe form of primary adjustment sets is elicited from the user, bit by bit,\nuntil either a set of covariates are found to control for confounding or it can\nbe determined that no such set exists. Other information, such as the causal\nrelations between confounders, is not required by the procedure. We show that\nif the user correctly specifies the primary adjustment sets in every step, our\nprocedure is both sound and complete.",
            "author": [
                "F. Richard Guo",
                "Qingyuan Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06053v2",
                "http://arxiv.org/pdf/2309.06053v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06034v2",
            "title": "Normality Learning-based Graph Anomaly Detection via Multi-Scale\n  Contrastive Learning",
            "updated": "2023-10-01T02:16:03Z",
            "published": "2023-09-12T08:06:04Z",
            "summary": "Graph anomaly detection (GAD) has attracted increasing attention in machine\nlearning and data mining. Recent works have mainly focused on how to capture\nricher information to improve the quality of node embeddings for GAD. Despite\ntheir significant advances in detection performance, there is still a relative\ndearth of research on the properties of the task. GAD aims to discern the\nanomalies that deviate from most nodes. However, the model is prone to learn\nthe pattern of normal samples which make up the majority of samples. Meanwhile,\nanomalies can be easily detected when their behaviors differ from normality.\nTherefore, the performance can be further improved by enhancing the ability to\nlearn the normal pattern. To this end, we propose a normality learning-based\nGAD framework via multi-scale contrastive learning networks (NLGAD for\nabbreviation). Specifically, we first initialize the model with the contrastive\nnetworks on different scales. To provide sufficient and reliable normal nodes\nfor normality learning, we design an effective hybrid strategy for normality\nselection. Finally, the model is refined with the only input of reliable normal\nnodes and learns a more accurate estimate of normality so that anomalous nodes\ncan be more easily distinguished. Eventually, extensive experiments on six\nbenchmark graph datasets demonstrate the effectiveness of our normality\nlearning-based scheme on GAD. Notably, the proposed algorithm improves the\ndetection performance (up to 5.89% AUC gain) compared with the state-of-the-art\nmethods. The source code is released at https://github.com/FelixDJC/NLGAD.",
            "author": [
                "Jingcan Duan",
                "Pei Zhang",
                "Siwei Wang",
                "Jingtao Hu",
                "Hu Jin",
                "Jiaxin Zhang",
                "Haifang Zhou",
                "Xinwang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06034v2",
                "http://arxiv.org/pdf/2309.06034v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07168v1",
            "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via\n  Reachability Analysis",
            "updated": "2023-09-12T06:53:11Z",
            "published": "2023-09-12T06:53:11Z",
            "summary": "Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this work, we propose a\ndevelopmental mechanism for subgoal discovery via an emergent representation\nthat abstracts (i.e., groups together) sets of environment states that have\nsimilar roles in the task. We create a HRL algorithm that gradually learns this\nrepresentation along with the policies and evaluate it on navigation tasks to\nshow the learned representation is interpretable and results in data\nefficiency.",
            "author": [
                "Mehdi Zadem",
                "Sergio Mover",
                "Sao Mai Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07168v1",
                "http://arxiv.org/pdf/2309.07168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.FL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05981v1",
            "title": "Learning Unbiased News Article Representations: A Knowledge-Infused\n  Approach",
            "updated": "2023-09-12T06:20:34Z",
            "published": "2023-09-12T06:20:34Z",
            "summary": "Quantification of the political leaning of online news articles can aid in\nunderstanding the dynamics of political ideology in social groups and measures\nto mitigating them. However, predicting the accurate political leaning of a\nnews article with machine learning models is a challenging task. This is due to\n(i) the political ideology of a news article is defined by several factors, and\n(ii) the innate nature of existing learning models to be biased with the\npolitical bias of the news publisher during the model training. There is only a\nlimited number of methods to study the political leaning of news articles which\nalso do not consider the algorithmic political bias which lowers the\ngeneralization of machine learning models to predict the political leaning of\nnews articles published by any new news publishers. In this work, we propose a\nknowledge-infused deep learning model that utilizes relatively reliable\nexternal data resources to learn unbiased representations of news articles\nusing their global and local contexts. We evaluate the proposed model by\nsetting the data in such a way that news domains or news publishers in the test\nset are completely unseen during the training phase. With this setup we show\nthat the proposed model mitigates algorithmic political bias and outperforms\nbaseline methods to predict the political leaning of news articles with up to\n73% accuracy.",
            "author": [
                "Sadia Kamal",
                "Jimmy Hartford",
                "Jeremy Willis",
                "Arunkumar Bagavathi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05981v1",
                "http://arxiv.org/pdf/2309.05981v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05979v1",
            "title": "Measure preservation and integrals for Lotka--Volterra $T$-systems and\n  their Kahan discretisation",
            "updated": "2023-09-12T06:13:49Z",
            "published": "2023-09-12T06:13:49Z",
            "summary": "We show that any Lotka--Volterra $T$-system associated with an $n$-vertex\ntree $T$ as introduced in Quispel et al., J. Phys. A 56 (2023) 315201,\npreserves a rational measure. We also prove that the Kahan discretisation of\nthese $T$-systems factorises and preserves the same measure. As a consequence,\nfor the Kahan maps of Lotka--Volterra systems related to the subclass of\n$T$-systems corresponding to graphs with more than one $n$-vertex subtree, we\nare able to construct rational integrals.",
            "author": [
                "Peter H. van der Kamp",
                "Robert I. McLachlan",
                "David I. McLaren",
                "G. R. W. Quispel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05979v1",
                "http://arxiv.org/pdf/2309.05979v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05976v1",
            "title": "Folded Morse flow trees",
            "updated": "2023-09-12T05:57:41Z",
            "published": "2023-09-12T05:57:41Z",
            "summary": "We present an approach to Morse theory on symmetric products of surfaces\nusing the notion of folded ribbon trees. We introduce an $A_\\infty$-category\nwith objects defined as $\\kappa$-tuples of Morse functions, where the\ndifferential of the tuple has no self-intersection. We show that when the graph\nof the differential of the $\\kappa$-tuple of Morse functions on\n$T^*\\mathbb{R}^2$ is the wrapped $\\kappa$ disjoint cotangent fibers, its\nendormorphism is the Hecke algebra associated to the symmetric group\n$\\mathfrak{S}_\\kappa$.",
            "author": [
                "Tianyu Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05976v1",
                "http://arxiv.org/pdf/2309.05976v1"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "math.GT",
                "math.QA",
                "58E05, 53D40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05972v1",
            "title": "Self-supervised Extraction of Human Motion Structures via Frame-wise\n  Discrete Features",
            "updated": "2023-09-12T05:43:13Z",
            "published": "2023-09-12T05:43:13Z",
            "summary": "The present paper proposes an encoder-decoder model for extracting the\nstructures of human motions represented by frame-wise discrete features in a\nself-supervised manner. In the proposed method, features are extracted as codes\nin a motion codebook without the use of human knowledge, and the relationship\nbetween these codes can be visualized on a graph. Since the codes are expected\nto be temporally sparse compared to the captured frame rate and can be shared\nby multiple sequences, the proposed network model also addresses the need for\ntraining constraints. Specifically, the model consists of self-attention layers\nand a vector clustering block. The attention layers contribute to finding\nsparse keyframes and discrete features as motion codes, which are then\nextracted by vector clustering. The constraints are realized as training losses\nso that the same motion codes can be as contiguous as possible and can be\nshared by multiple sequences. In addition, we propose the use of causal\nself-attention as a method by which to calculate attention for long sequences\nconsisting of numerous frames. In our experiments, the sparse structures of\nmotion codes were used to compile a graph that facilitates visualization of the\nrelationship between the codes and the differences between sequences. We then\nevaluated the effectiveness of the extracted motion codes by applying them to\nmultiple recognition tasks and found that performance levels comparable to\ntask-optimized methods could be achieved by linear probing.",
            "author": [
                "Tetsuya Abe",
                "Ryusuke Sagawa",
                "Ko Ayusawa",
                "Wataru Takano"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05972v1",
                "http://arxiv.org/pdf/2309.05972v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05954v1",
            "title": "$L^q$-spectra of box-like graph-directed self-affine measures: closed\n  forms, with rotation",
            "updated": "2023-09-12T04:22:06Z",
            "published": "2023-09-12T04:22:06Z",
            "summary": "We consider $L^q$-spectra of planar graph-directed self-affine measures\ngenerated by diagonal or anti-diagonal matrices. Assuming the directed graph is\nstrongly connected and the system satisfies the rectangular open set condition,\nwe obtain a general closed form expression for the $L^q$-spectra. Consequently,\nwe obtain a closed form expression for box dimensions of associated planar\ngraph-directed box-like self-affine sets. We also provide a precise answer to a\nquestion of Fraser in 2016 concerning the $L^q$-spectra of planar self-affine\nmeasures generated by diagonal matrices.",
            "author": [
                "Hua Qiu",
                "Qi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05954v1",
                "http://arxiv.org/pdf/2309.05954v1"
            ],
            "primary_category": "math.CA",
            "category": [
                "math.CA",
                "28A80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05953v1",
            "title": "GLAD: Content-aware Dynamic Graphs For Log Anomaly Detection",
            "updated": "2023-09-12T04:21:30Z",
            "published": "2023-09-12T04:21:30Z",
            "summary": "Logs play a crucial role in system monitoring and debugging by recording\nvaluable system information, including events and states. Although various\nmethods have been proposed to detect anomalies in log sequences, they often\noverlook the significance of considering relations among system components,\nsuch as services and users, which can be identified from log contents.\nUnderstanding these relations is vital for detecting anomalies and their\nunderlying causes. To address this issue, we introduce GLAD, a Graph-based Log\nAnomaly Detection framework designed to detect relational anomalies in system\nlogs. GLAD incorporates log semantics, relational patterns, and sequential\npatterns into a unified framework for anomaly detection. Specifically, GLAD\nfirst introduces a field extraction module that utilizes prompt-based few-shot\nlearning to identify essential fields from log contents. Then GLAD constructs\ndynamic log graphs for sliding windows by interconnecting extracted fields and\nlog events parsed from the log parser. These graphs represent events and fields\nas nodes and their relations as edges. Subsequently, GLAD utilizes a\ntemporal-attentive graph edge anomaly detection model for identifying anomalous\nrelations in these dynamic log graphs. This model employs a Graph Neural\nNetwork (GNN)-based encoder enhanced with transformers to capture content,\nstructural and temporal features. We evaluate our proposed method on three\ndatasets, and the results demonstrate the effectiveness of GLAD in detecting\nanomalies indicated by varying relational patterns.",
            "author": [
                "Yufei Li",
                "Yanchi Liu",
                "Haoyu Wang",
                "Zhengzhang Chen",
                "Wei Cheng",
                "Yuncong Chen",
                "Wenchao Yu",
                "Haifeng Chen",
                "Cong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05953v1",
                "http://arxiv.org/pdf/2309.05953v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05951v1",
            "title": "Balanced and Explainable Social Media Analysis for Public Health with\n  Large Language Models",
            "updated": "2023-09-12T04:15:34Z",
            "published": "2023-09-12T04:15:34Z",
            "summary": "As social media becomes increasingly popular, more and more public health\nactivities emerge, which is worth noting for pandemic monitoring and government\ndecision-making. Current techniques for public health analysis involve popular\nmodels such as BERT and large language models (LLMs). Although recent progress\nin LLMs has shown a strong ability to comprehend knowledge by being fine-tuned\non specific domain datasets, the costs of training an in-domain LLM for every\nspecific public health task are especially expensive. Furthermore, such kinds\nof in-domain datasets from social media are generally highly imbalanced, which\nwill hinder the efficiency of LLMs tuning. To tackle these challenges, the data\nimbalance issue can be overcome by sophisticated data augmentation methods for\nsocial media datasets. In addition, the ability of the LLMs can be effectively\nutilised by prompting the model properly. In light of the above discussion, in\nthis paper, a novel ALEX framework is proposed for social media analysis on\npublic health. Specifically, an augmentation pipeline is developed to resolve\nthe data imbalance issue. Furthermore, an LLMs explanation mechanism is\nproposed by prompting an LLM with the predicted results from BERT models.\nExtensive experiments conducted on three tasks at the Social Media Mining for\nHealth 2023 (SMM4H) competition with the first ranking in two tasks demonstrate\nthe superior performance of the proposed ALEX method. Our code has been\nreleased in https://github.com/YanJiangJerry/ALEX.",
            "author": [
                "Yan Jiang",
                "Ruihong Qiu",
                "Yi Zhang",
                "Peng-Fei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05951v1",
                "http://arxiv.org/pdf/2309.05951v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05943v1",
            "title": "Knowledge-Guided Short-Context Action Anticipation in Human-Centric\n  Videos",
            "updated": "2023-09-12T03:48:29Z",
            "published": "2023-09-12T03:48:29Z",
            "summary": "This work focuses on anticipating long-term human actions, particularly using\nshort video segments, which can speed up editing workflows through improved\nsuggestions while fostering creativity by suggesting narratives. To this end,\nwe imbue a transformer network with a symbolic knowledge graph for action\nanticipation in video segments by boosting certain aspects of the transformer's\nattention mechanism at run-time. Demonstrated on two benchmark datasets,\nBreakfast and 50Salads, our approach outperforms current state-of-the-art\nmethods for long-term action anticipation using short video context by up to\n9%.",
            "author": [
                "Sarthak Bhagat",
                "Simon Stepputtis",
                "Joseph Campbell",
                "Katia Sycara"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05943v1",
                "http://arxiv.org/pdf/2309.05943v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05938v2",
            "title": "Answering Subjective Induction Questions on Products by Summarizing\n  Multi-sources Multi-viewpoints Knowledge",
            "updated": "2023-10-06T12:35:20Z",
            "published": "2023-09-12T03:27:08Z",
            "summary": "This paper proposes a new task in the field of Answering Subjective Induction\nQuestion on Products (SUBJPQA). The answer to this kind of question is\nnon-unique, but can be interpreted from many perspectives. For example, the\nanswer to 'whether the phone is heavy' has a variety of different viewpoints. A\nsatisfied answer should be able to summarize these subjective opinions from\nmultiple sources and provide objective knowledge, such as the weight of a\nphone. That is quite different from the traditional QA task, in which the\nanswer to a factoid question is unique and can be found from a single data\nsource. To address this new task, we propose a three-steps method. We first\nretrieve all answer-related clues from multiple knowledge sources on facts and\nopinions. The implicit commonsense facts are also collected to supplement the\nnecessary but missing contexts. We then capture their relevance with the\nquestions by interactive attention. Next, we design a reinforcement-based\nsummarizer to aggregate all these knowledgeable clues. Based on a\ntemplate-controlled decoder, we can output a comprehensive and\nmulti-perspective answer. Due to the lack of a relevant evaluated benchmark set\nfor the new task, we construct a large-scale dataset, named SupQA, consisting\nof 48,352 samples across 15 product domains. Evaluation results show the\neffectiveness of our approach.",
            "author": [
                "Yufeng Zhang",
                "Meng-xiang Wang",
                "Jianxing Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05938v2",
                "http://arxiv.org/pdf/2309.05938v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05936v1",
            "title": "Do PLMs Know and Understand Ontological Knowledge?",
            "updated": "2023-09-12T03:20:50Z",
            "published": "2023-09-12T03:20:50Z",
            "summary": "Ontological knowledge, which comprises classes and properties and their\nrelationships, is integral to world knowledge. It is significant to explore\nwhether Pretrained Language Models (PLMs) know and understand such knowledge.\nHowever, existing PLM-probing studies focus mainly on factual knowledge,\nlacking a systematic probing of ontological knowledge. In this paper, we focus\non probing whether PLMs store ontological knowledge and have a semantic\nunderstanding of the knowledge rather than rote memorization of the surface\nform. To probe whether PLMs know ontological knowledge, we investigate how well\nPLMs memorize: (1) types of entities; (2) hierarchical relationships among\nclasses and properties, e.g., Person is a subclass of Animal and Member of\nSports Team is a subproperty of Member of ; (3) domain and range constraints of\nproperties, e.g., the subject of Member of Sports Team should be a Person and\nthe object should be a Sports Team. To further probe whether PLMs truly\nunderstand ontological knowledge beyond memorization, we comprehensively study\nwhether they can reliably perform logical reasoning with given knowledge\naccording to ontological entailment rules. Our probing results show that PLMs\ncan memorize certain ontological knowledge and utilize implicit knowledge in\nreasoning. However, both the memorizing and reasoning performances are less\nthan perfect, indicating incomplete knowledge and understanding.",
            "author": [
                "Weiqi Wu",
                "Chengyue Jiang",
                "Yong Jiang",
                "Pengjun Xie",
                "Kewei Tu"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.acl-long.173",
                "http://arxiv.org/abs/2309.05936v1",
                "http://arxiv.org/pdf/2309.05936v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05934v1",
            "title": "MatSciML: A Broad, Multi-Task Benchmark for Solid-State Materials\n  Modeling",
            "updated": "2023-09-12T03:08:37Z",
            "published": "2023-09-12T03:08:37Z",
            "summary": "We propose MatSci ML, a novel benchmark for modeling MATerials SCIence using\nMachine Learning (MatSci ML) methods focused on solid-state materials with\nperiodic crystal structures. Applying machine learning methods to solid-state\nmaterials is a nascent field with substantial fragmentation largely driven by\nthe great variety of datasets used to develop machine learning models. This\nfragmentation makes comparing the performance and generalizability of different\nmethods difficult, thereby hindering overall research progress in the field.\nBuilding on top of open-source datasets, including large-scale datasets like\nthe OpenCatalyst, OQMD, NOMAD, the Carolina Materials Database, and Materials\nProject, the MatSci ML benchmark provides a diverse set of materials systems\nand properties data for model training and evaluation, including simulated\nenergies, atomic forces, material bandgaps, as well as classification data for\ncrystal symmetries via space groups. The diversity of properties in MatSci ML\nmakes the implementation and evaluation of multi-task learning algorithms for\nsolid-state materials possible, while the diversity of datasets facilitates the\ndevelopment of new, more generalized algorithms and methods across multiple\ndatasets. In the multi-dataset learning setting, MatSci ML enables researchers\nto combine observations from multiple datasets to perform joint prediction of\ncommon properties, such as energy and forces. Using MatSci ML, we evaluate the\nperformance of different graph neural networks and equivariant point cloud\nnetworks on several benchmark tasks spanning single task, multitask, and\nmulti-data learning scenarios. Our open-source code is available at\nhttps://github.com/IntelLabs/matsciml.",
            "author": [
                "Kin Long Kelvin Lee",
                "Carmelo Gonzales",
                "Marcel Nassar",
                "Matthew Spellings",
                "Mikhail Galkin",
                "Santiago Miret"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05934v1",
                "http://arxiv.org/pdf/2309.05934v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09984v1",
            "title": "BDEC:Brain Deep Embedded Clustering model",
            "updated": "2023-09-12T02:42:11Z",
            "published": "2023-09-12T02:42:11Z",
            "summary": "An essential premise for neuroscience brain network analysis is the\nsuccessful segmentation of the cerebral cortex into functionally homogeneous\nregions. Resting-state functional magnetic resonance imaging (rs-fMRI),\ncapturing the spontaneous activities of the brain, provides the potential for\ncortical parcellation. Previous parcellation methods can be roughly categorized\ninto three groups, mainly employing either local gradient, global similarity,\nor a combination of both. The traditional clustering algorithms, such as\n\"K-means\" and \"Spectral clustering\" may affect the reproducibility or the\nbiological interpretation of parcellations; The region growing-based methods\ninfluence the expression of functional homogeneity in the brain at a large\nscale; The parcellation method based on probabilistic graph models inevitably\nintroduce model assumption biases. In this work, we develop an assumption-free\nmodel called as BDEC, which leverages the robust data fitting capability of\ndeep learning. To the best of our knowledge, this is the first study that uses\ndeep learning algorithm for rs-fMRI-based parcellation. By comparing with nine\ncommonly used brain parcellation methods, the BDEC model demonstrates\nsignificantly superior performance in various functional homogeneity\nindicators. Furthermore, it exhibits favorable results in terms of validity,\nnetwork analysis, task homogeneity, and generalization capability. These\nresults suggest that the BDEC parcellation captures the functional\ncharacteristics of the brain and holds promise for future voxel-wise brain\nnetwork analysis in the dimensionality reduction of fMRI data.",
            "author": [
                "Xiaoxiao Ma",
                "Chunzhi Yi",
                "Zhicai Zhong",
                "Hui Zhou",
                "Baichun Wei",
                "Haiqi Zhu",
                "Feng Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09984v1",
                "http://arxiv.org/pdf/2309.09984v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05918v3",
            "title": "Stochastic LLMs do not Understand Language: Towards Symbolic,\n  Explainable and Ontologically Based LLMs",
            "updated": "2023-09-14T12:58:39Z",
            "published": "2023-09-12T02:14:05Z",
            "summary": "In our opinion the exuberance surrounding the relative success of data-driven\nlarge language models (LLMs) is slightly misguided and for several reasons (i)\nLLMs cannot be relied upon for factual information since for LLMs all ingested\ntext (factual or non-factual) was created equal; (ii) due to their subsymbolic\nna-ture, whatever 'knowledge' these models acquire about language will always\nbe buried in billions of microfeatures (weights), none of which is meaningful\non its own; and (iii) LLMs will often fail to make the correct inferences in\nseveral linguistic contexts (e.g., nominal compounds, copredication, quantifier\nscope ambi-guities, intensional contexts. Since we believe the relative success\nof data-driven large language models (LLMs) is not a reflection on the symbolic\nvs. subsymbol-ic debate but a reflection on applying the successful strategy of\na bottom-up reverse engineering of language at scale, we suggest in this paper\napplying the effective bottom-up strategy in a symbolic setting resulting in\nsymbolic, explainable, and ontologically grounded language models.",
            "author": [
                "Walid S. Saba"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05918v3",
                "http://arxiv.org/pdf/2309.05918v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05904v2",
            "title": "Enhancing Representation in Radiography-Reports Foundation Model: A\n  Granular Alignment Algorithm Using Masked Contrastive Learning",
            "updated": "2023-09-18T01:23:52Z",
            "published": "2023-09-12T01:29:37Z",
            "summary": "Recently, multi-modal vision-language foundation models have gained\nsignificant attention in the medical field. While these models offer great\nopportunities, they still face a number of challenges, such as the requirement\nfor fine-grained knowledge understanding in computer-aided diagnosis and\ncapability of utilizing very limited or no task-specific labeled data in\nreal-world clinical applications. In this study, we present MaCo, a novel\nmulti-modal medical foundation model that explores masked contrastive learning\nto achieve granular alignment and zero-shot learning for a variety of medical\nimaging tasks. MaCo incorporates a correlation weighting mechanism to adjust\nthe correlation between masked image patches and their corresponding reports,\nthereby enhancing the representation learning capabilities. We evaluate MaCo on\nsix well-known open-source X-ray datasets, and the experimental results show it\noutperforms seven state-of-the-art approaches for classification, segmentation,\nand zero-shot phase grounding, demonstrating its great potential to promote a\nwide range of medical image analysis tasks.",
            "author": [
                "Weijian Huang",
                "Cheng Li",
                "Hao Yang",
                "Jiarun Liu",
                "Shanshan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05904v2",
                "http://arxiv.org/pdf/2309.05904v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05902v1",
            "title": "The Game of Cycles with Sources Allowed",
            "updated": "2023-09-12T01:23:37Z",
            "published": "2023-09-12T01:23:37Z",
            "summary": "In this paper, we introduce a variant of Francis Su's \"Game of Cycles,\" that\nwe call \"Cycles with Sources.\" The only change to the rules is permitting nodes\nto be sources, while sinks are still prohibited. Despite this minor change in\nthe rules, we show that even on simple games, like line graphs, there is a\ngreat change in the outcome of optimal play, which we fully analyze using\nSprague-Grundy Theory.",
            "author": [
                "Vigyan Sahai",
                "Ravi Tripathi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05902v1",
                "http://arxiv.org/pdf/2309.05902v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05895v1",
            "title": "Coexistence of near-EF flat band and van Hove singularity in a two-phase\n  superconductor",
            "updated": "2023-09-12T00:39:07Z",
            "published": "2023-09-12T00:39:07Z",
            "summary": "In quantum many-body systems, particularly, the ones with large near-EF\ndensity states, like flat bands or van Hove singularity (VHS), electron\ncorrelations often give rise to rich phase diagrams with multiple\ncoexisting/competing orders occurring at similar energy scales. The recently\ndiscovered locally noncentrosymmetric heavy fermion superconductor CeRh2As2 has\nstimulated extensive attention due to its unusual H-T phase diagram, consisting\nof two-phase superconductivity, antiferromagnetic order, and possible\nquadrupole-density wave orders. However, despite its great importance, the\nnear-EF electronic structure remains experimentally elusive. Here, we provide\nthis key information by combining soft X-ray and vacuum ultraviolet (VUV)\nangle-resolved photoemission spectroscopy measurements and atom-resolved DFT+U\ncalculations. With bulk-sensitive soft X-rays, we reveal quasi-2D hole- and 3D\nelectron- pockets with a pronounced nesting feature. Most importantly, we\nobserve a symmetry-protected fourfold VHS coexisting with the Ce 4f flat bands\nnear the EF, which, to the best of our knowledge, has never been reported\nbefore. Such a rare coexistence is expected to lead to a large density of\nstates at the zone edge, enhancement in electron correlations, and a large\nupper critical field of the odd-parity superconducting phase. Uniquely, it will\nalso result in a new type of f-VHS hybridization that alters the order and fine\nelectronic structure of the symmetry-protected VHS and flat bands. These\npeculiarities offer important dimensions for understanding the reported rich\nphase diagram and are discussed as an origin of superconductivity with two\nphases. Our findings not only provide key insights into the nature of multiple\nphases in CeRh$_2$As$_2$, but also open up new prospects for exploring the\nnovelties of many-body systems with f-VHS hybridization.",
            "author": [
                "Xuezhi Chen",
                "Le Wang",
                "Jun Ishizuka",
                "Kosuke Nogaki",
                "Yiwei Cheng",
                "Fazhi Yang",
                "Renjie Zhang",
                "Zhenhua Chen",
                "Fangyuan Zhu",
                "Youichi Yanase",
                "Baiqing Lv",
                "Yaobo Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05895v1",
                "http://arxiv.org/pdf/2309.05895v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.mtrl-sci",
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05889v1",
            "title": "Systemization of Knowledge (SoK)- Cross Impact of Transfer Learning in\n  Cybersecurity: Offensive, Defensive and Threat Intelligence Perspectives",
            "updated": "2023-09-12T00:26:38Z",
            "published": "2023-09-12T00:26:38Z",
            "summary": "Recent literature highlights a significant cross-impact between transfer\nlearning and cybersecurity. Many studies have been conducted on using transfer\nlearning to enhance security, leading to various applications in different\ncybersecurity tasks. However, previous research is focused on specific areas of\ncybersecurity. This paper presents a comprehensive survey of transfer learning\napplications in cybersecurity by covering a wide range of domains, identifying\ncurrent trends, and shedding light on under-explored areas. The survey\nhighlights the significance of transfer learning in addressing critical issues\nin cybersecurity, such as improving detection accuracy, reducing training time,\nhandling data imbalance, and enhancing privacy preservation. Additional\ninsights are provided on the common problems solved using transfer learning,\nsuch as the lack of labeled data, different data distributions, and privacy\nconcerns. The paper identifies future research directions and challenges that\nrequire community attention, including the need for privacy-preserving models,\nautomatic tools for knowledge transfer, metrics for measuring domain\nrelatedness, and enhanced privacy preservation mechanisms. The insights and\nroadmap presented in this paper will guide researchers in further advancing\ntransfer learning in cybersecurity, fostering the development of robust and\nefficient cybersecurity systems to counter emerging threats and protect\nsensitive information. To the best of our knowledge, this paper is the first of\nits kind to present a comprehensive taxonomy of all areas of cybersecurity that\nbenefited from transfer learning and propose a detailed future roadmap to shape\nthe possible research direction in this area.",
            "author": [
                "Sofiya Makar",
                "Ali Dehghantanha",
                "Fattane Zarrinkalam",
                "Gautam Srivastava",
                "Abbas Yazdinejad"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05889v1",
                "http://arxiv.org/pdf/2309.05889v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05881v1",
            "title": "On the pre- and post-positional semi-random graph processes",
            "updated": "2023-09-12T00:04:30Z",
            "published": "2023-09-12T00:04:30Z",
            "summary": "We study the semi-random graph process, and a variant process recently\nsuggested by Nick Wormald. We show that these two processes are asymptotically\nequally fast in constructing a semi-random graph $G$ that has property\n${\\mathcal P}$, for the following examples of ${\\mathcal P}$:\n  - ${\\mathcal P}$ is the set of graphs containing a $d$-degenerate subgraph,\nwhere $d\\ge 1$ is fixed;\n  - ${\\mathcal P}$ is the set of $k$-connected graphs, where $k\\ge 1$ is fixed.\nIn particular, our result of the $k$-connectedness above settles the open case\n$k=2$ of the original semi-random graph process.\n  We also prove that there exist properties ${\\mathcal P}$ where the two\nsemi-random graph processes do not construct a graph in ${\\mathcal P}$\nasymptotically equally fast. We further propose some conjectures on ${\\mathcal\nP}$ for which the two processes perform differently.",
            "author": [
                "Pu Gao",
                "Hidde Koerts"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05881v1",
                "http://arxiv.org/pdf/2309.05881v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05877v1",
            "title": "Choosing restart strategy at partial knowledge of process statistics",
            "updated": "2023-09-11T23:57:44Z",
            "published": "2023-09-11T23:57:44Z",
            "summary": "Optimization of a random processes by restart is a subject of active\ntheoretical research in statistical physics and has long found practical\napplication in computer science. Meanwhile, one of the key issues remains\nlargely unsolved: when should we restart a process whose detailed statistics\nare unknown to ensure that our intervention will improve performance?\nAddressing this query here we propose several constructive criteria for the\neffectiveness of various protocols of non-instantaneous restart in the mean\ncompletion time problem and in the success probability problem. Being expressed\nin terms of a small number of easily estimated statistical characteristics of\nthe original process, these criteria allow informed restart decision based on\npartial information.",
            "author": [
                "Ilia Nikitin",
                "Sergey Belan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05877v1",
                "http://arxiv.org/pdf/2309.05877v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05874v1",
            "title": "Cop-width, flip-width and strong colouring numbers",
            "updated": "2023-09-11T23:53:03Z",
            "published": "2023-09-11T23:53:03Z",
            "summary": "Cop-width and flip-width are new families of graph parameters introduced by\nToru\\'nczyk (2023) that generalise treewidth, degeneracy, generalised colouring\nnumbers, clique-width and twin-width. In this paper, we bound the cop-width and\nflip-width of a graph by its strong colouring numbers. In particular, we show\nthat for every $r\\in \\mathbb{N}$, every graph $G$ has $\\text{copwidth}_r(G)\\leq\n\\text{scol}_{4r}(G)$. This implies that every class of graphs with linear\nstrong colouring numbers has linear cop-width and linear flip-width. We use\nthis result to deduce improved bounds for cop-width and flip-width for various\nsparse graph classes.",
            "author": [
                "Robert Hickingbotham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05874v1",
                "http://arxiv.org/pdf/2309.05874v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05871v1",
            "title": "Generalized Rainbow Differential Privacy",
            "updated": "2023-09-11T23:39:13Z",
            "published": "2023-09-11T23:39:13Z",
            "summary": "We study a new framework for designing differentially private (DP) mechanisms\nvia randomized graph colorings, called rainbow differential privacy. In this\nframework, datasets are nodes in a graph, and two neighboring datasets are\nconnected by an edge. Each dataset in the graph has a preferential ordering for\nthe possible outputs of the mechanism, and these orderings are called rainbows.\nDifferent rainbows partition the graph of connected datasets into different\nregions. We show that if a DP mechanism at the boundary of such regions is\nfixed and it behaves identically for all same-rainbow boundary datasets, then a\nunique optimal $(\\epsilon,\\delta)$-DP mechanism exists (as long as the boundary\ncondition is valid) and can be expressed in closed-form. Our proof technique is\nbased on an interesting relationship between dominance ordering and DP, which\napplies to any finite number of colors and for $(\\epsilon,\\delta)$-DP,\nimproving upon previous results that only apply to at most three colors and for\n$\\epsilon$-DP. We justify the homogeneous boundary condition assumption by\ngiving an example with non-homogeneous boundary condition, for which there\nexists no optimal DP mechanism.",
            "author": [
                "Yuzhou Gu",
                "Ziqi Zhou",
                "Onur G\u00fcnl\u00fc",
                "Rafael G. L. D'Oliveira",
                "Parastoo Sadeghi",
                "Muriel M\u00e9dard",
                "Rafael F. Schaefer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05871v1",
                "http://arxiv.org/pdf/2309.05871v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.IR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05865v1",
            "title": "Force-directed graph embedding with hops distance",
            "updated": "2023-09-11T23:08:03Z",
            "published": "2023-09-11T23:08:03Z",
            "summary": "Graph embedding has become an increasingly important technique for analyzing\ngraph-structured data. By representing nodes in a graph as vectors in a\nlow-dimensional space, graph embedding enables efficient graph processing and\nanalysis tasks like node classification, link prediction, and visualization. In\nthis paper, we propose a novel force-directed graph embedding method that\nutilizes the steady acceleration kinetic formula to embed nodes in a way that\npreserves graph topology and structural features. Our method simulates a set of\ncustomized attractive and repulsive forces between all node pairs with respect\nto their hop distance. These forces are then used in Newton's second law to\nobtain the acceleration of each node. The method is intuitive, parallelizable,\nand highly scalable. We evaluate our method on several graph analysis tasks and\nshow that it achieves competitive performance compared to state-of-the-art\nunsupervised embedding techniques.",
            "author": [
                "Hamidreza Lotfalizadeh",
                "Mohammad Al Hasan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05865v1",
                "http://arxiv.org/pdf/2309.05865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05853v2",
            "title": "ChemSpaceAL: An Efficient Active Learning Methodology Applied to\n  Protein-Specific Molecular Generation",
            "updated": "2023-12-04T00:26:41Z",
            "published": "2023-09-11T22:28:36Z",
            "summary": "The incredible capabilities of generative artificial intelligence models have\ninevitably led to their application in the domain of drug discovery. Within\nthis domain, the vastness of chemical space motivates the development of more\nefficient methods for identifying regions with molecules that exhibit desired\ncharacteristics. In this work, we present a computationally efficient active\nlearning methodology that requires evaluation of only a subset of the generated\ndata in the constructed sample space to successfully align a generative model\nwith respect to a specified objective. We demonstrate the applicability of this\nmethodology to targeted molecular generation by fine-tuning a GPT-based\nmolecular generator toward a protein with FDA-approved small-molecule\ninhibitors, c-Abl kinase. Remarkably, the model learns to generate molecules\nsimilar to the inhibitors without prior knowledge of their existence, and even\nreproduces two of them exactly. We also show that the methodology is effective\nfor a protein without any commercially available small-molecule inhibitors, the\nHNH domain of the CRISPR-associated protein 9 (Cas9) enzyme. We believe that\nthe inherent generality of this method ensures that it will remain applicable\nas the exciting field of in silico molecular generation evolves. To facilitate\nimplementation and reproducibility, we have made all of our software available\nthrough the open-source ChemSpaceAL Python package.",
            "author": [
                "Gregory W. Kyro",
                "Anton Morgunov",
                "Rafael I. Brent",
                "Victor S. Batista"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05853v2",
                "http://arxiv.org/pdf/2309.05853v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05850v1",
            "title": "Predicting Interloper Fraction with Graph Neural Networks",
            "updated": "2023-09-11T22:23:53Z",
            "published": "2023-09-11T22:23:53Z",
            "summary": "Upcoming emission-line spectroscopic surveys, such as Euclid and the Roman\nSpace Telescope, will be affected by systematic effects due to the presence of\ninterlopers: galaxies whose redshift and distance from us are miscalculated due\nto line confusion in their emission spectra. Particularly pernicious are\ninterlopers involving the confusion between two lines with close emitted\nwavelengths, like H$\\beta$ emitters confused as \\oiii, since those are strongly\nspatially correlated with the target galaxies. They introduce a particular\npattern in the 3D distribution of the observed galaxy catalog that can shift\nthe position of the BAO peak in the galaxy correlation function and bias any\ncosmological analysis performed with that sample. Here we present a novel\nmethod to predict the fraction of interlopers in a galaxy catalog, using Graph\nNeural Networks (GNNs) to learn the posterior distribution of the interloper\nfraction while marginalizing over cosmology and galaxy bias. The method is\ndeveloped using simulations with halos acting as a proxy for galaxies. The GNN\ncan infer the mean and standard deviation of the posterior distribution of\ninterloper fraction using small-scale information that is usually not\nconsidered in cosmological analyses. The injection of large-scale information\ninto the graph as a global attribute improves the performance of the GNN when\nmarginalizing over cosmology.",
            "author": [
                "Elena Massara",
                "Francisco Villaescusa-Navarro",
                "Will J. Percival"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05850v1",
                "http://arxiv.org/pdf/2309.05850v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07166v1",
            "title": "Proceedings of the 31st International Symposium on Graph Drawing and\n  Network Visualization (GD 2023)",
            "updated": "2023-09-11T22:03:50Z",
            "published": "2023-09-11T22:03:50Z",
            "summary": "This is the arXiv index for the electronic proceedings of GD 2023, which\ncontains the peer-reviewed and revised accepted papers with an optional\nappendix. Proceedings (without appendices) are also to be published by Springer\nin the Lecture Notes in Computer Science series.",
            "author": [
                "Michael A. Bekos",
                "Markus Chimani"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07166v1",
                "http://arxiv.org/pdf/2309.07166v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.CC",
                "cs.DM",
                "cs.DS",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05828v1",
            "title": "Exploring Geometric Deep Learning For Precipitation Nowcasting",
            "updated": "2023-09-11T21:14:55Z",
            "published": "2023-09-11T21:14:55Z",
            "summary": "Precipitation nowcasting (up to a few hours) remains a challenge due to the\nhighly complex local interactions that need to be captured accurately.\nConvolutional Neural Networks rely on convolutional kernels convolving with\ngrid data and the extracted features are trapped by limited receptive field,\ntypically expressed in excessively smooth output compared to ground truth. Thus\nthey lack the capacity to model complex spatial relationships among the grids.\nGeometric deep learning aims to generalize neural network models to\nnon-Euclidean domains. Such models are more flexible in defining nodes and\nedges and can effectively capture dynamic spatial relationship among\ngeographical grids. Motivated by this, we explore a geometric deep\nlearning-based temporal Graph Convolutional Network (GCN) for precipitation\nnowcasting. The adjacency matrix that simulates the interactions among grid\ncells is learned automatically by minimizing the L1 loss between prediction and\nground truth pixel value during the training procedure. Then, the spatial\nrelationship is refined by GCN layers while the temporal information is\nextracted by 1D convolution with various kernel lengths. The neighboring\ninformation is fed as auxiliary input layers to improve the final result. We\ntest the model on sequences of radar reflectivity maps over the Trento/Italy\narea. The results show that GCNs improves the effectiveness of modeling the\nlocal details of the cloud profile as well as the prediction accuracy by\nachieving decreased error measures.",
            "author": [
                "Shan Zhao",
                "Sudipan Saha",
                "Zhitong Xiong",
                "Niklas Boers",
                "Xiao Xiang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05828v1",
                "http://arxiv.org/pdf/2309.05828v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05827v2",
            "title": "Digraph Branchings and Matrix Determinants",
            "updated": "2023-09-13T04:12:28Z",
            "published": "2023-09-11T21:14:08Z",
            "summary": "We present a version of the matrix-tree theorem, which relates the\ndeterminant of a matrix to sums of weights of arborescences of its directed\ngraph representation. Our treatment allows for non-zero column sums in the\nparent matrix by adding a root vertex to the usually considered matrix directed\ngraph. We use our result to prove a version of the matrix-forest, or\nall-minors, theorem, which relates minors of the matrix to forests of\narborescences of the matrix digraph. We then show that it is possible, when the\nsource and target vertices of an arc are not strongly connected, to move the\nsource of the arc in the matrix directed graph and leave the resulting matrix\ndeterminant unchanged, as long as the source and target vertices are not\nstrongly connected after the move. This result enables graphical strategies for\nfactoring matrix determinants.",
            "author": [
                "Sayani Ghosh",
                "Bradley S. Meyer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05827v2",
                "http://arxiv.org/pdf/2309.05827v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05826v1",
            "title": "KD-FixMatch: Knowledge Distillation Siamese Neural Networks",
            "updated": "2023-09-11T21:11:48Z",
            "published": "2023-09-11T21:11:48Z",
            "summary": "Semi-supervised learning (SSL) has become a crucial approach in deep learning\nas a way to address the challenge of limited labeled data. The success of deep\nneural networks heavily relies on the availability of large-scale high-quality\nlabeled data. However, the process of data labeling is time-consuming and\nunscalable, leading to shortages in labeled data. SSL aims to tackle this\nproblem by leveraging additional unlabeled data in the training process. One of\nthe popular SSL algorithms, FixMatch, trains identical weight-sharing teacher\nand student networks simultaneously using a siamese neural network (SNN).\nHowever, it is prone to performance degradation when the pseudo labels are\nheavily noisy in the early training stage. We present KD-FixMatch, a novel SSL\nalgorithm that addresses the limitations of FixMatch by incorporating knowledge\ndistillation. The algorithm utilizes a combination of sequential and\nsimultaneous training of SNNs to enhance performance and reduce performance\ndegradation. Firstly, an outer SNN is trained using labeled and unlabeled data.\nAfter that, the network of the well-trained outer SNN generates pseudo labels\nfor the unlabeled data, from which a subset of unlabeled data with trusted\npseudo labels is then carefully created through high-confidence sampling and\ndeep embedding clustering. Finally, an inner SNN is trained with the labeled\ndata, the unlabeled data, and the subset of unlabeled data with trusted pseudo\nlabels. Experiments on four public data sets demonstrate that KD-FixMatch\noutperforms FixMatch in all cases. Our results indicate that KD-FixMatch has a\nbetter training starting point that leads to improved model performance\ncompared to FixMatch.",
            "author": [
                "Chien-Chih Wang",
                "Shaoyuan Xu",
                "Jinmiao Fu",
                "Yang Liu",
                "Bryan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05826v1",
                "http://arxiv.org/pdf/2309.05826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05805v1",
            "title": "Online ML Self-adaptation in Face of Traps",
            "updated": "2023-09-11T20:17:11Z",
            "published": "2023-09-11T20:17:11Z",
            "summary": "Online machine learning (ML) is often used in self-adaptive systems to\nstrengthen the adaptation mechanism and improve the system utility. Despite\nsuch benefits, applying online ML for self-adaptation can be challenging, and\nnot many papers report its limitations. Recently, we experimented with applying\nonline ML for self-adaptation of a smart farming scenario and we had faced\nseveral unexpected difficulties -- traps -- that, to our knowledge, are not\ndiscussed enough in the community. In this paper, we report our experience with\nthese traps. Specifically, we discuss several traps that relate to the\nspecification and online training of the ML-based estimators, their impact on\nself-adaptation, and the approach used to evaluate the estimators. Our overview\nof these traps provides a list of lessons learned, which can serve as guidance\nfor other researchers and practitioners when applying online ML for\nself-adaptation.",
            "author": [
                "Michal T\u00f6pfer",
                "Franti\u0161ek Pl\u00e1\u0161il",
                "Tom\u00e1\u0161 Bure\u0161",
                "Petr Hn\u011btynka",
                "Martin Kruli\u0161",
                "Danny Weyns"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05805v1",
                "http://arxiv.org/pdf/2309.05805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05784v1",
            "title": "Grey-box Bayesian Optimization for Sensor Placement in Assisted Living\n  Environments",
            "updated": "2023-09-11T19:31:14Z",
            "published": "2023-09-11T19:31:14Z",
            "summary": "Optimizing the configuration and placement of sensors is crucial for reliable\nfall detection, indoor localization, and activity recognition in assisted\nliving spaces. We propose a novel, sample-efficient approach to find a\nhigh-quality sensor placement in an arbitrary indoor space based on grey-box\nBayesian optimization and simulation-based evaluation. Our key technical\ncontribution lies in capturing domain-specific knowledge about the spatial\ndistribution of activities and incorporating it into the iterative selection of\nquery points in Bayesian optimization. Considering two simulated indoor\nenvironments and a real-world dataset containing human activities and sensor\ntriggers, we show that our proposed method performs better compared to\nstate-of-the-art black-box optimization techniques in identifying high-quality\nsensor placements, leading to accurate activity recognition in terms of\nF1-score, while also requiring a significantly lower (51.3% on average) number\nof expensive function queries.",
            "author": [
                "Shadan Golestan",
                "Omid Ardakanian",
                "Pierre Boulanger"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05784v1",
                "http://arxiv.org/pdf/2309.05784v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05765v1",
            "title": "Contrarian Majority rule model with external oscillating propaganda and\n  individual inertias",
            "updated": "2023-09-11T18:47:29Z",
            "published": "2023-09-11T18:47:29Z",
            "summary": "We study the Galam majority rule dynamics with contrarian behavior and an\noscillating external propaganda, in a population of agents that can adopt one\nof two possible opinions. In an iteration step, a random agent interacts with\nother three random agents and takes the majority opinion among the agents with\nprobability $p(t)$ (majority behavior) or the opposite opinion with probability\n$1-p(t)$ (contrarian behavior). The probability of following the majority rule\n$p(t)$ varies with the temperature $T$ and is coupled to a time-dependent\noscillating field that mimics a mass media propaganda, in a way that agents are\nmore likely to adopt the majority opinion when it is aligned with the sign of\nthe field. We investigate the dynamics of this model on a complete graph and\nfind various regimes as $T$ is varied. A transition temperature $T_c$ separates\na bimodal oscillatory regime for $T<T_c$ where the population's mean opinion\n$m$ oscillates around a positive or a negative value, from a unimodal\noscillatory regime for $T>T_c$ in which $m$ oscillates around zero. These\nregimes are characterized by the distribution of residence times that exhibits\na unique peak for a resonance temperature $T^*$, where the response of the\nsystem is maximum. An insight into these results is given by a mean-field\napproach, which also shows that $T^*$ and $T_c$ are closely related.",
            "author": [
                "M. Cecilia Gimenez",
                "Luis Reinaudi",
                "Serge Galam",
                "Federico Vazquez"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05765v1",
                "http://arxiv.org/pdf/2309.05765v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.13061v2",
            "title": "Applying BioBERT to Extract Germline Gene-Disease Associations for\n  Building a Knowledge Graph from the Biomedical Literature",
            "updated": "2023-09-30T04:31:22Z",
            "published": "2023-09-11T18:05:12Z",
            "summary": "Published biomedical information has and continues to rapidly increase. The\nrecent advancements in Natural Language Processing (NLP), have generated\nconsiderable interest in automating the extraction, normalization, and\nrepresentation of biomedical knowledge about entities such as genes and\ndiseases. Our study analyzes germline abstracts in the construction of\nknowledge graphs of the of the immense work that has been done in this area for\ngenes and diseases. This paper presents SimpleGermKG, an automatic knowledge\ngraph construction approach that connects germline genes and diseases. For the\nextraction of genes and diseases, we employ BioBERT, a pre-trained BERT model\non biomedical corpora. We propose an ontology-based and rule-based algorithm to\nstandardize and disambiguate medical terms. For semantic relationships between\narticles, genes, and diseases, we implemented a part-whole relation approach to\nconnect each entity with its data source and visualize them in a graph-based\nknowledge representation. Lastly, we discuss the knowledge graph applications,\nlimitations, and challenges to inspire the future research of germline corpora.\nOur knowledge graph contains 297 genes, 130 diseases, and 46,747 triples.\nGraph-based visualizations are used to show the results.",
            "author": [
                "Armando D. Diaz Gonzalez",
                "Songhui Yue",
                "Sean T. Hayes",
                "Kevin S. Hughes"
            ],
            "link": [
                "http://arxiv.org/abs/2309.13061v2",
                "http://arxiv.org/pdf/2309.13061v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05740v1",
            "title": "REVERSIM: A Game-Based Approach to Accessing Large Populations for\n  Studying Human Aspects in Hardware Reverse Engineering",
            "updated": "2023-09-11T18:03:50Z",
            "published": "2023-09-11T18:03:50Z",
            "summary": "Hardware Reverse Engineering (HRE) is a technique for analyzing Integrated\nCircuits (ICs). Experts employ HRE for various security-critical tasks, such as\ndesign verification or the detection of intellectual property violations.\nHowever, HRE also enables threat actors to subvert the security of an IC.\nPrevious studies have shown that analysts rely heavily on their cognitive\nabilities to perform HRE as no fully automated solutions exist. Therefore,\nconducting controlled experimental studies to assess the cognitive processes\ninvolved in HRE could open new avenues for hardware protection. However,\nresearchers have faced the methodological challenge that HRE experts are\nlargely unavailable for such empirical research. To address this scarcity, we\nhave developed REVERSIM, a game-based simulation that mimics realistic HRE\nsubprocesses and is specifically designed to require no prior knowledge. To\nsupport these claims, we conducted two empirical studies: First, we performed\nsemi-structured interviews with 14 professionals and researchers from the HRE\ndomain, who attested to the comparability of REVERSIM to real-world HRE\nproblems. Second, we conducted a user study involving 89 non-expert\nparticipants, demonstrating that participants could engage in the simulation\nwithout prior knowledge in HRE or related domains. Finally, we outline several\nresearch directions for experiments with REVERSIM, highlighting its potential\nin advancing HRE research.",
            "author": [
                "Steffen Becker",
                "Carina Wiesen",
                "Ren\u00e9 Walendy",
                "Nikol Rummel",
                "Christof Paar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05740v1",
                "http://arxiv.org/pdf/2309.05740v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05728v1",
            "title": "A data-driven and model-agnostic approach to solving combinatorial\n  assignment problems in searches for new physics",
            "updated": "2023-09-11T18:01:21Z",
            "published": "2023-09-11T18:01:21Z",
            "summary": "We present a novel approach to solving combinatorial assignment problems in\nparticle physics without the need to introduce prior knowledge or assumptions\nabout the particles' decay. The correct assignment of decay products to parent\nparticles is achieved in a model-agnostic fashion by introducing a novel neural\nnetwork architecture, Passwd-ABC, which combines a custom layer based on\nattention mechanisms and dual autoencoders. We demonstrate how the network,\ntrained purely on background events in an unsupervised setting, is capable of\nreconstructing correctly hypothetical new particles regardless of their mass,\ndecay multiplicity and substructure, and produces simultaneously an anomaly\nscore that can be used to efficiently suppress the background. This model\nallows to extend the suite of searches for localized excesses to include\nnon-resonant particle pair production where the reconstruction of the two\nresonant masses is thwarted by combinatorics.",
            "author": [
                "Anthony Badea",
                "Javier Montejo Berlingen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05728v1",
                "http://arxiv.org/pdf/2309.05728v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05710v1",
            "title": "Gravity Amplitudes From Double Bonus Relations",
            "updated": "2023-09-11T18:00:03Z",
            "published": "2023-09-11T18:00:03Z",
            "summary": "In this letter we derive new expressions for tree-level graviton amplitudes\nin $\\mathcal{N}=8$ supergravity from BCFW recursion relations combined with new\ntypes of bonus relations. These bonus relations go beyond the famous $1/z^2$\nbehavior under a large BCFW shift, and use knowledge about certain zeroes of\ngraviton amplitudes in collinear kinematics. This extra knowledge can be used\nin the context of global residue theorems by writing the amplitude in a special\nform using canonical building blocks. In the NMHV case these building blocks\nare dressed one-loop leading singularities, the same objects that appear in the\nexpansion of Yang-Mills amplitudes, where each term corresponds to an\n$R$-invariant. Unlike other approaches, our formula is not an expansion in\nterms of cyclic objects and does not manifest color-kinematics duality, but\nrather preserves the permutational symmetry of its building blocks. We also\ncomment on the possible connection to Grassmannian geometry and give some\nnon-trivial evidence of such structure for graviton amplitudes.",
            "author": [
                "Shruti Paranjape",
                "Jaroslav Trnka"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05710v1",
                "http://arxiv.org/pdf/2309.05710v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05702v1",
            "title": "Unsupervised Machine Learning Techniques for Exploring Tropical\n  Coamoeba, Brane Tilings and Seiberg Duality",
            "updated": "2023-09-11T18:00:01Z",
            "published": "2023-09-11T18:00:01Z",
            "summary": "We introduce unsupervised machine learning techniques in order to identify\ntoric phases of 4d N=1 supersymmetric gauge theories corresponding to the same\ntoric Calabi-Yau 3-fold. These 4d N=1 supersymmetric gauge theories are\nworldvolume theories of a D3-brane probing a toric Calabi-Yau 3-fold and are\nrealized in terms of a Type IIB brane configuration known as a brane tiling. It\ncorresponds to the skeleton graph of the coamoeba projection of the mirror\ncurve associated to the toric Calabi-Yau 3-fold. When we vary the complex\nstructure moduli of the mirror Calabi-Yau 3-fold, the coamoeba and the\ncorresponding brane tilings change their shape, giving rise to different toric\nphases related by Seiberg duality. We illustrate that by employing techniques\nsuch as principal component analysis (PCA) and t-distributed stochastic\nneighbor embedding (t-SNE), we can project the space of coamoeba labelled by\ncomplex structure moduli down to a lower dimensional phase space with phase\nboundaries corresponding to Seiberg duality. In this work, we illustrate this\ntechnique by obtaining a 2-dimensional phase diagram for brane tilings\ncorresponding to the cone over the zeroth Hirzebruch surface F0.",
            "author": [
                "Rak-Kyeong Seong"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevD.108.106009",
                "http://arxiv.org/abs/2309.05702v1",
                "http://arxiv.org/pdf/2309.05702v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math-ph",
                "math.AG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05691v2",
            "title": "Robust extended states in Anderson model on partially disordered random\n  regular graphs",
            "updated": "2023-12-03T12:05:48Z",
            "published": "2023-09-11T18:00:00Z",
            "summary": "In this work we analytically explain the origin of the mobility edge in the\nensemble of random regular graphs (RRG), with the connectivity $d$ and the\nfraction $\\beta$ of disordered nodes, the location of which is under control.\nIt is shown that the mobility edge in the spectrum survives in a certain range\nof parameters $(d,\\beta)$ at infinitely large uniformly distributed disorder.\nThe critical curve separating extended and localized states is derived\nanalytically and confirmed numerically. The duality in the localization\nproperties between the sparse and extremely dense RRG has been found and\nunderstood. The mobility edge physics has been analyzed numerically for the\nabove partially disordered RRG, perturbed by the non-reciprocity parameter of\nnode as well as by the enhanced number of short cycles, usually almost absent\non RRG.",
            "author": [
                "Daniil Kochergin",
                "Ivan M. Khaymovich",
                "Olga Valba",
                "Alexander Gorsky"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05691v2",
                "http://arxiv.org/pdf/2309.05691v2"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "hep-th",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05643v1",
            "title": "Rapidly rotating neutron stars: Universal relations and EOS inference",
            "updated": "2023-09-11T17:33:38Z",
            "published": "2023-09-11T17:33:38Z",
            "summary": "We provide accurate universal relations that allow to estimate the moment of\ninertia $I$ and the ratio of kinetic to gravitational binding energy $T/W$ of\nuniformly rotating neutron stars from the knowledge of mass, radius, and moment\nof inertia of an associated non-rotating neutron star. Based on these, several\nother fluid quantities can be estimated as well. Astrophysical neutron stars\nrotate to varying degrees and although rotational effects may be neglected in\nsome cases, not modeling them will inevitably introduce bias when performing\nparameter estimation. This is especially important for future, high-precision\nmeasurements coming from electromagnetic and gravitational wave observations.\nThe proposed universal relations facilitate computationally cheap EOS inference\ncodes that permit the inclusion of observations of rotating neutron stars. To\ndemonstrate this, we deploy them into a recent Bayesian framework for equation\nof state parameter estimation that is now valid for arbitrary, uniform\nrotation. Our inference results are robust up to around percent level precision\nfor the generated neutron star observations, consisting of the mass, equatorial\nradius, rotation rate, as well as co- and counter-rotating $f$-mode\nfrequencies, that enter the framework as data.",
            "author": [
                "Christian J. Kr\u00fcger",
                "Sebastian H. V\u00f6lkel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05643v1",
                "http://arxiv.org/pdf/2309.05643v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05638v1",
            "title": "Combinative Cumulative Knowledge Processes",
            "updated": "2023-09-11T17:29:28Z",
            "published": "2023-09-11T17:29:28Z",
            "summary": "We analyze Cumulative Knowledge Processes, introduced by Ben-Eliezer,\nMikulincer, Mossel, and Sudan (ITCS 2023), in the setting of \"directed acyclic\ngraphs\", i.e., when new units of knowledge may be derived by combining multiple\nprevious units of knowledge. The main considerations in this model are the role\nof errors (when new units may be erroneous) and local checking (where a few\nantecedent units of knowledge are checked when a new unit of knowledge is\ndiscovered). The aforementioned work defined this model but only analyzed an\nidealized and simplified \"tree-like\" setting, i.e., a setting where new units\nof knowledge only depended directly on one previously generated unit of\nknowledge.\n  The main goal of our work is to understand when the general process is safe,\ni.e., when the effect of errors remains under control. We provide some\nnecessary and some sufficient conditions for safety. As in the earlier work, we\ndemonstrate that the frequency of checking as well as the depth of the checks\nplay a crucial role in determining safety. A key new parameter in the current\nwork is the $\\textit{combination factor}$ which is the distribution of the\nnumber of units $M$ of old knowledge that a new unit of knowledge depends on.\nOur results indicate that a large combination factor can compensate for a small\ndepth of checking. The dependency of the safety on the combination factor is\nfar from trivial. Indeed some of our main results are stated in terms of\n$\\mathbb{E}\\{1/M\\}$ while others depend on $\\mathbb{E}\\{M\\}$.",
            "author": [
                "Anna Brandenberger",
                "Cassandra Marcussen",
                "Elchanan Mossel",
                "Madhu Sudan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05638v1",
                "http://arxiv.org/pdf/2309.05638v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DS",
                "cs.SI",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05634v1",
            "title": "Kernel Interpolation of Incident Sound Field in Region Including\n  Scattering Objects",
            "updated": "2023-09-11T17:26:00Z",
            "published": "2023-09-11T17:26:00Z",
            "summary": "A method for estimating the incident sound field inside a region containing\nscattering objects is proposed. The sound field estimation method has various\napplications, such as spatial audio capturing and spatial active noise control;\nhowever, most existing methods do not take into account the presence of\nscatterers within the target estimation region. Although several techniques\nexist that employ knowledge or measurements of the properties of the scattering\nobjects, it is usually difficult to obtain them precisely in advance, and their\nproperties may change during the estimation process. Our proposed method is\nbased on the kernel ridge regression of the incident field, with a separation\nfrom the scattering field represented by a spherical wave function expansion,\nthus eliminating the need for prior modeling or measurements of the scatterers.\nMoreover, we introduce a weighting matrix to induce smoothness of the\nscattering field in the angular direction, which alleviates the effect of the\ntruncation order of the expansion coefficients on the estimation accuracy.\nExperimental results indicate that the proposed method achieves a higher level\nof estimation accuracy than the kernel ridge regression without separation.",
            "author": [
                "Shoichi Koyama",
                "Masaki Nakada",
                "Juliano G. C. Ribeiro",
                "Hiroshi Saruwatari"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05634v1",
                "http://arxiv.org/pdf/2309.05634v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05632v1",
            "title": "MAPS$^2$: Multi-Robot Anytime Motion Planning under Signal Temporal\n  Logic Specifications",
            "updated": "2023-09-11T17:25:08Z",
            "published": "2023-09-11T17:25:08Z",
            "summary": "This article presents MAPS$^2$ : a distributed algorithm that allows\nmulti-robot systems to deliver coupled tasks expressed as Signal Temporal Logic\n(STL) constraints. Classical control theoretical tools addressing STL\nconstraints either adopt a limited fragment of the STL formula or require\napproximations of min/max operators, whereas works maximising robustness\nthrough optimisation-based methods often suffer from local minima, relaxing any\ncompleteness arguments due to the NP-hard nature of the problem. Endowed with\nprobabilistic guarantees, MAPS$^2$ provides an anytime algorithm that\niteratively improves the robots' trajectories. The algorithm selectively\nimposes spatial constraints by taking advantage of the temporal properties of\nthe STL. The algorithm is distributed, in the sense that each robot calculates\nits trajectory by communicating only with its immediate neighbours as defined\nvia a communication graph. We illustrate the efficiency of MAPS$^2$ by\nconducting extensive simulation and experimental studies, verifying the\ngeneration of STL satisfying trajectories.",
            "author": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05632v1",
                "http://arxiv.org/pdf/2309.05632v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05622v1",
            "title": "Task-Oriented Cross-System Design for Timely and Accurate Modeling in\n  the Metaverse",
            "updated": "2023-09-11T17:11:32Z",
            "published": "2023-09-11T17:11:32Z",
            "summary": "In this paper, we establish a task-oriented cross-system design framework to\nminimize the required packet rate for timely and accurate modeling of a\nreal-world robotic arm in the Metaverse, where sensing, communication,\nprediction, control, and rendering are considered. To optimize a scheduling\npolicy and prediction horizons, we design a Constraint Proximal Policy\nOptimization(C-PPO) algorithm by integrating domain knowledge from relevant\nsystems into the advanced reinforcement learning algorithm, Proximal Policy\nOptimization(PPO). Specifically, the Jacobian matrix for analyzing the motion\nof the robotic arm is included in the state of the C-PPO algorithm, and the\nConditional Value-at-Risk(CVaR) of the state-value function characterizing the\nlong-term modeling error is adopted in the constraint. Besides, the policy is\nrepresented by a two-branch neural network determining the scheduling policy\nand the prediction horizons, respectively. To evaluate our algorithm, we build\na prototype including a real-world robotic arm and its digital model in the\nMetaverse. The experimental results indicate that domain knowledge helps to\nreduce the convergence time and the required packet rate by up to 50%, and the\ncross-system design framework outperforms a baseline framework in terms of the\nrequired packet rate and the tail distribution of the modeling error.",
            "author": [
                "Zhen Meng",
                "Kan Chen",
                "Yufeng Diao",
                "Changyang She",
                "Guodong Zhao",
                "Muhammad Ali Imran",
                "Branka Vucetic"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05622v1",
                "http://arxiv.org/pdf/2309.05622v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05614v1",
            "title": "Detecting communities via edge Random Walk Centrality",
            "updated": "2023-09-11T17:02:05Z",
            "published": "2023-09-11T17:02:05Z",
            "summary": "Herein we present a novel approach of identifying community structures in\ncomplex networks. We propose the usage of the Random Walk Centrality (RWC),\nfirst introduced by Noh and Rieger [Phys. Rev. Lett. 92.11 (2004): 118701]. We\nadapt this node centrality metric to an edge centrality metric by applying it\nto the line graph of a given network. A crucial feature of our algorithm is the\nneedlessness of recalculating the centrality metric after each step, in\ncontrast to most community detection algorithms. We test our algorithm on a\nwide variety of standard networks, and compare them with pre-existing\nalgorithms. As a predictive application, we analyze the Indian Railway network\nfor robustness and connectedness, and propose edges which would make the system\neven sturdier.",
            "author": [
                "Ashwat Jain",
                "P. Manimaran"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05614v1",
                "http://arxiv.org/pdf/2309.05614v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05613v2",
            "title": "Learning the Geodesic Embedding with Graph Neural Networks",
            "updated": "2023-10-04T09:42:43Z",
            "published": "2023-09-11T16:54:34Z",
            "summary": "We present GeGnn, a learning-based method for computing the approximate\ngeodesic distance between two arbitrary points on discrete polyhedra surfaces\nwith constant time complexity after fast precomputation. Previous relevant\nmethods either focus on computing the geodesic distance between a single source\nand all destinations, which has linear complexity at least or require a long\nprecomputation time. Our key idea is to train a graph neural network to embed\nan input mesh into a high-dimensional embedding space and compute the geodesic\ndistance between a pair of points using the corresponding embedding vectors and\na lightweight decoding function. To facilitate the learning of the embedding,\nwe propose novel graph convolution and graph pooling modules that incorporate\nlocal geodesic information and are verified to be much more effective than\nprevious designs. After training, our method requires only one forward pass of\nthe network per mesh as precomputation. Then, we can compute the geodesic\ndistance between a pair of points using our decoding function, which requires\nonly several matrix multiplications and can be massively parallelized on GPUs.\nWe verify the efficiency and effectiveness of our method on ShapeNet and\ndemonstrate that our method is faster than existing methods by orders of\nmagnitude while achieving comparable or better accuracy. Additionally, our\nmethod exhibits robustness on noisy and incomplete meshes and strong\ngeneralization ability on out-of-distribution meshes. The code and pretrained\nmodel can be found on https://github.com/IntelligentGeometry/GeGnn.",
            "author": [
                "Bo Pang",
                "Zhongtian Zheng",
                "Guoping Wang",
                "Peng-Shuai Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3618317",
                "http://arxiv.org/abs/2309.05613v2",
                "http://arxiv.org/pdf/2309.05613v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05608v1",
            "title": "Incorporating Pre-trained Model Prompting in Multimodal Stock Volume\n  Movement Prediction",
            "updated": "2023-09-11T16:47:01Z",
            "published": "2023-09-11T16:47:01Z",
            "summary": "Multimodal stock trading volume movement prediction with stock-related news\nis one of the fundamental problems in the financial area. Existing multimodal\nworks that train models from scratch face the problem of lacking universal\nknowledge when modeling financial news. In addition, the models ability may be\nlimited by the lack of domain-related knowledge due to insufficient data in the\ndatasets. To handle this issue, we propose the Prompt-based MUltimodal Stock\nvolumE prediction model (ProMUSE) to process text and time series modalities.\nWe use pre-trained language models for better comprehension of financial news\nand adopt prompt learning methods to leverage their capability in universal\nknowledge to model textual information. Besides, simply fusing two modalities\ncan cause harm to the unimodal representations. Thus, we propose a novel\ncross-modality contrastive alignment while reserving the unimodal heads beside\nthe fusion head to mitigate this problem. Extensive experiments demonstrate\nthat our proposed ProMUSE outperforms existing baselines. Comprehensive\nanalyses further validate the effectiveness of our architecture compared to\npotential variants and learning mechanisms.",
            "author": [
                "Ruibo Chen",
                "Zhiyuan Zhang",
                "Yi Liu",
                "Ruihan Bao",
                "Keiko Harimoto",
                "Xu Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05608v1",
                "http://arxiv.org/pdf/2309.05608v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05606v1",
            "title": "Distribution of colours in rainbow H-free colourings",
            "updated": "2023-09-11T16:41:00Z",
            "published": "2023-09-11T16:41:00Z",
            "summary": "An edge colouring of $K_n$ with $k$ colours is a Gallai $k$-colouring if it\ndoes not contain any rainbow triangle. Gy\\'arf\\'as, P\\'alv\\\"olgyi, Patk\\'os and\nWales proved that there exists a number $g(k)$ such that $n\\geq g(k)$ if and\nonly if for any colour distribution sequence $(e_1,\\cdots,e_k)$ with\n$\\sum_{i=1}^ke_i=\\binom{n}{2}$, there exist a Gallai $k$-colouring of $K_n$\nwith $e_i$ edges having colour $i$. They also showed that\n$\\Omega(k)=g(k)=O(k^2)$ and posed the problem of determining the exact order of\nmagnitude of $g(k)$. Feffer, Fu and Yan improved both bounds significantly by\nproving $\\Omega(k^{1.5}/\\log k)=g(k)=O(k^{1.5})$. We resolve this problem by\nshowing $g(k)=\\Theta(k^{1.5}/(\\log k)^{0.5})$.\n  Moreover, we generalise these definitions by considering rainbow $H$-free\ncolourings of $K_n$ for any general graph $H$, and the natural corresponding\nquantity $g(H,k)$. We prove that $g(H,k)$ is finite for every $k$ if and only\nif $H$ is not a forest, and determine the order of $g(H,k)$ when $H$ contains a\nsubgraph with minimum degree at least 3.",
            "author": [
                "Zhuo Wu",
                "Jun Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05606v1",
                "http://arxiv.org/pdf/2309.05606v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05687v1",
            "title": "Demystifying Practices, Challenges and Expected Features of Using GitHub\n  Copilot",
            "updated": "2023-09-11T16:39:37Z",
            "published": "2023-09-11T16:39:37Z",
            "summary": "With the advances in machine learning, there is a growing interest in\nAI-enabled tools for autocompleting source code. GitHub Copilot has been\ntrained on billions of lines of open source GitHub code, and is one of such\ntools that has been increasingly used since its launch in June 2021. However,\nlittle effort has been devoted to understanding the practices, challenges, and\nexpected features of using Copilot in programming for auto-completed source\ncode from the point of view of practitioners. To this end, we conducted an\nempirical study by collecting and analyzing the data from Stack Overflow (SO)\nand GitHub Discussions. We searched and manually collected 303 SO posts and 927\nGitHub discussions related to the usage of Copilot. We identified the\nprogramming languages, Integrated Development Environments (IDEs), technologies\nused with Copilot, functions implemented, benefits, limitations, and challenges\nwhen using Copilot. The results show that when practitioners use Copilot: (1)\nThe major programming languages used with Copilot are JavaScript and Python,\n(2) the main IDE used with Copilot is Visual Studio Code, (3) the most common\nused technology with Copilot is Node.js, (4) the leading function implemented\nby Copilot is data processing, (5) the main purpose of users using Copilot is\nto help generate code, (6) the significant benefit of using Copilot is useful\ncode generation, (7) the main limitation encountered by practitioners when\nusing Copilot is difficulty of integration, and (8) the most common expected\nfeature is that Copilot can be integrated with more IDEs. Our results suggest\nthat using Copilot is like a double-edged sword, which requires developers to\ncarefully consider various aspects when deciding whether or not to use it. Our\nstudy provides empirically grounded foundations that could inform developers\nand practitioners, as well as provide a basis for future investigations.",
            "author": [
                "Beiqi Zhang",
                "Peng Liang",
                "Xiyu Zhou",
                "Aakash Ahmad",
                "Muhammad Waseem"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05687v1",
                "http://arxiv.org/pdf/2309.05687v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05584v1",
            "title": "Distributional Probabilistic Model Checking",
            "updated": "2023-09-11T16:12:03Z",
            "published": "2023-09-11T16:12:03Z",
            "summary": "Probabilistic model checking can provide formal guarantees on the behavior of\nstochastic models relating to a wide range of quantitative properties, such as\nruntime, energy consumption or cost. But decision making is typically with\nrespect to the expected value of these quantities, which can mask important\naspects of the full probability distribution such as the possibility of\nhigh-risk, low-probability events or multimodalities. We propose a\ndistributional extension of probabilistic model checking, applicable to\ndiscrete-time Markov chains (DTMCs) and Markov decision processes (MDPs). We\nformulate distributional queries, which can reason about a variety of\ndistributional measures, such as variance, value-at-risk or conditional\nvalue-at-risk, for the accumulation of reward until a co-safe linear temporal\nlogic formula is satisfied. For DTMCs, we propose a method to compute the full\ndistribution to an arbitrary level of precision, based on a graph analysis and\nforward analysis of the model. For MDPs, we approximate the optimal policy with\nrespect to expected value or conditional value-at-risk using distributional\nvalue iteration. We implement our techniques and investigate their performance\nand scalability across a range of benchmark models. Experimental results\ndemonstrate that our techniques can be successfully applied to check various\ndistributional properties of large probabilistic models.",
            "author": [
                "Ingy Elsayed-Aly",
                "David Parker",
                "Lu Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05584v1",
                "http://arxiv.org/pdf/2309.05584v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.05956v1",
            "title": "Efficient Network Representation for GNN-based Intrusion Detection",
            "updated": "2023-09-11T16:10:12Z",
            "published": "2023-09-11T16:10:12Z",
            "summary": "The last decades have seen a growth in the number of cyber-attacks with\nsevere economic and privacy damages, which reveals the need for network\nintrusion detection approaches to assist in preventing cyber-attacks and\nreducing their risks. In this work, we propose a novel network representation\nas a graph of flows that aims to provide relevant topological information for\nthe intrusion detection task, such as malicious behavior patterns, the relation\nbetween phases of multi-step attacks, and the relation between spoofed and\npre-spoofed attackers activities. In addition, we present a Graph Neural\nNetwork (GNN) based framework responsible for exploiting the proposed graph\nstructure to classify communication flows by assigning them a maliciousness\nscore. The framework comprises three main steps that aim to embed nodes\nfeatures and learn relevant attack patterns from the network representation.\nFinally, we highlight a potential data leakage issue with classical evaluation\nprocedures and suggest a solution to ensure a reliable validation of intrusion\ndetection systems performance. We implement the proposed framework and prove\nthat exploiting the flow-based graph structure outperforms the classical\nmachine learning-based and the previous GNN-based solutions.",
            "author": [
                "Hamdi Friji",
                "Alexis Olivereau",
                "Mireille Sarkiss"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-33488-7_20",
                "http://arxiv.org/abs/2310.05956v1",
                "http://arxiv.org/pdf/2310.05956v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05557v3",
            "title": "An Empirical Study of NetOps Capability of Pre-Trained Large Language\n  Models",
            "updated": "2023-09-19T16:04:25Z",
            "published": "2023-09-11T15:45:40Z",
            "summary": "Nowadays, the versatile capabilities of Pre-trained Large Language Models\n(LLMs) have attracted much attention from the industry. However, some vertical\ndomains are more interested in the in-domain capabilities of LLMs. For the\nNetworks domain, we present NetEval, an evaluation set for measuring the\ncomprehensive capabilities of LLMs in Network Operations (NetOps). NetEval is\ndesigned for evaluating the commonsense knowledge and inference ability in\nNetOps in a multi-lingual context. NetEval consists of 5,732 questions about\nNetOps, covering five different sub-domains of NetOps. With NetEval, we\nsystematically evaluate the NetOps capability of 26 publicly available LLMs.\nThe results show that only GPT-4 can achieve a performance competitive to\nhumans. However, some open models like LLaMA 2 demonstrate significant\npotential.",
            "author": [
                "Yukai Miao",
                "Yu Bai",
                "Li Chen",
                "Dan Li",
                "Haifeng Sun",
                "Xizheng Wang",
                "Ziqiu Luo",
                "Yanyu Ren",
                "Dapeng Sun",
                "Xiuting Xu",
                "Qi Zhang",
                "Chao Xiang",
                "Xinchi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05557v3",
                "http://arxiv.org/pdf/2309.05557v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05527v2",
            "title": "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source\n  Reconstruction and Target Simulation",
            "updated": "2023-09-25T11:36:24Z",
            "published": "2023-09-11T15:11:11Z",
            "summary": "Domain shifts such as sensor type changes and geographical situation\nvariations are prevalent in Autonomous Driving (AD), which poses a challenge\nsince AD model relying on the previous-domain knowledge can be hardly directly\ndeployed to a new domain without additional costs. In this paper, we provide a\nnew perspective and approach of alleviating the domain shifts, by proposing a\nReconstruction-Simulation-Perception (ReSimAD) scheme. Specifically, the\nimplicit reconstruction process is based on the knowledge from the previous old\ndomain, aiming to convert the domain-related knowledge into domain-invariant\nrepresentations, e.g., 3D scene-level meshes. Besides, the point clouds\nsimulation process of multiple new domains is conditioned on the above\nreconstructed 3D meshes, where the target-domain-like simulation samples can be\nobtained, thus reducing the cost of collecting and annotating new-domain data\nfor the subsequent perception process. For experiments, we consider different\ncross-domain situations such as Waymo-to-KITTI, Waymo-to-nuScenes,\nWaymo-to-ONCE, etc, to verify the zero-shot target-domain perception using\nReSimAD. Results demonstrate that our method is beneficial to boost the domain\ngeneralization ability, even promising for 3D pre-training.",
            "author": [
                "Bo Zhang",
                "Xinyu Cai",
                "Jiakang Yuan",
                "Donglin Yang",
                "Jianfei Guo",
                "Xiangchao Yan",
                "Renqiu Xia",
                "Botian Shi",
                "Min Dou",
                "Tao Chen",
                "Si Liu",
                "Junchi Yan",
                "Yu Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05527v2",
                "http://arxiv.org/pdf/2309.05527v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05526v1",
            "title": "The Rational Number Game",
            "updated": "2023-09-11T15:10:52Z",
            "published": "2023-09-11T15:10:52Z",
            "summary": "We investigate a game played between two players, Maker and Breaker, on a\ncountably infinite complete graph where the vertices are the rational numbers.\nThe players alternately claim unclaimed edges. It is Maker's goal to have after\ncountably many turns a complete infinite graph contained in her coloured edges\nwhere the vertex set of the subgraph is order-isomorphic to the rationals. It\nis Breaker's goal to prevent Maker from achieving this. We prove that there is\na winning strategy for Maker in this game. We also prove that there is a\nwinning strategy for Breaker in the game where Maker must additionally make the\nvertex set of her complete graph dense in the rational numbers.",
            "author": [
                "Nathan Bowler",
                "Florian Gut"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05526v1",
                "http://arxiv.org/pdf/2309.05526v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C57, 05C55, 05C63,"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05525v3",
            "title": "Advancing Federated Learning in 6G: A Trusted Architecture with\n  Graph-based Analysis",
            "updated": "2023-09-27T19:27:30Z",
            "published": "2023-09-11T15:10:41Z",
            "summary": "Integrating native AI support into the network architecture is an essential\nobjective of 6G. Federated Learning (FL) emerges as a potential paradigm,\nfacilitating decentralized AI model training across a diverse range of devices\nunder the coordination of a central server. However, several challenges hinder\nits wide application in the 6G context, such as malicious attacks and privacy\nsnooping on local model updates, and centralization pitfalls. This work\nproposes a trusted architecture for supporting FL, which utilizes Distributed\nLedger Technology (DLT) and Graph Neural Network (GNN), including three key\nfeatures. First, a pre-processing layer employing homomorphic encryption is\nincorporated to securely aggregate local models, preserving the privacy of\nindividual models. Second, given the distributed nature and graph structure\nbetween clients and nodes in the pre-processing layer, GNN is leveraged to\nidentify abnormal local models, enhancing system security. Third, DLT is\nutilized to decentralize the system by selecting one of the candidates to\nperform the central server's functions. Additionally, DLT ensures reliable data\nmanagement by recording data exchanges in an immutable and transparent ledger.\nThe feasibility of the novel architecture is validated through simulations,\ndemonstrating improved performance in anomalous model detection and global\nmodel accuracy compared to relevant baselines.",
            "author": [
                "Wenxuan Ye",
                "Chendi Qian",
                "Xueli An",
                "Xueqiang Yan",
                "Georg Carle"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05525v3",
                "http://arxiv.org/pdf/2309.05525v3"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05507v1",
            "title": "A Co-design Study for Multi-Stakeholder Job Recommender System\n  Explanations",
            "updated": "2023-09-11T14:51:20Z",
            "published": "2023-09-11T14:51:20Z",
            "summary": "Recent legislation proposals have significantly increased the demand for\neXplainable Artificial Intelligence (XAI) in many businesses, especially in\nso-called `high-risk' domains, such as recruitment. Within recruitment, AI has\nbecome commonplace, mainly in the form of job recommender systems (JRSs), which\ntry to match candidates to vacancies, and vice versa. However, common XAI\ntechniques often fall short in this domain due to the different levels and\ntypes of expertise of the individuals involved, making explanations difficult\nto generalize. To determine the explanation preferences of the different\nstakeholder types - candidates, recruiters, and companies - we created and\nvalidated a semi-structured interview guide. Using grounded theory, we\nstructurally analyzed the results of these interviews and found that different\nstakeholder types indeed have strongly differing explanation preferences.\nCandidates indicated a preference for brief, textual explanations that allow\nthem to quickly judge potential matches. On the other hand, hiring managers\npreferred visual graph-based explanations that provide a more technical and\ncomprehensive overview at a glance. Recruiters found more exhaustive textual\nexplanations preferable, as those provided them with more talking points to\nconvince both parties of the match. Based on these findings, we describe\nguidelines on how to design an explanation interface that fulfills the\nrequirements of all three stakeholder types. Furthermore, we provide the\nvalidated interview guide, which can assist future research in determining the\nexplanation preferences of different stakeholder types.",
            "author": [
                "Roan Schellingerhout",
                "Francesco Barile",
                "Nava Tintarev"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05507v1",
                "http://arxiv.org/pdf/2309.05507v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05500v1",
            "title": "NeCo@ALQAC 2023: Legal Domain Knowledge Acquisition for Low-Resource\n  Languages through Data Enrichment",
            "updated": "2023-09-11T14:43:45Z",
            "published": "2023-09-11T14:43:45Z",
            "summary": "In recent years, natural language processing has gained significant\npopularity in various sectors, including the legal domain. This paper presents\nNeCo Team's solutions to the Vietnamese text processing tasks provided in the\nAutomated Legal Question Answering Competition 2023 (ALQAC 2023), focusing on\nlegal domain knowledge acquisition for low-resource languages through data\nenrichment. Our methods for the legal document retrieval task employ a\ncombination of similarity ranking and deep learning models, while for the\nsecond task, which requires extracting an answer from a relevant legal article\nin response to a question, we propose a range of adaptive techniques to handle\ndifferent question types. Our approaches achieve outstanding results on both\ntasks of the competition, demonstrating the potential benefits and\neffectiveness of question answering systems in the legal field, particularly\nfor low-resource languages.",
            "author": [
                "Hai-Long Nguyen",
                "Dieu-Quynh Nguyen",
                "Hoang-Trung Nguyen",
                "Thu-Trang Pham",
                "Huu-Dong Nguyen",
                "Thach-Anh Nguyen",
                "Thi-Hai-Yen Vuong",
                "Ha-Thanh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05500v1",
                "http://arxiv.org/pdf/2309.05500v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05495v3",
            "title": "Right-angled Artin groups and the cohomology basis graph",
            "updated": "2023-10-20T22:37:25Z",
            "published": "2023-09-11T14:37:04Z",
            "summary": "Let $\\Gamma$ be a finite graph and let $A(\\Gamma)$ be the corresponding\nright-angled Artin group. From an arbitrary basis $\\mathcal B$ of\n$H^1(A(\\Gamma),\\mathbb F)$ over an arbitrary field, we construct a natural\ngraph $\\Gamma_{\\mathcal B}$ from the cup product, called the \\emph{cohomology\nbasis graph}. We show that $\\Gamma_{\\mathcal B}$ always contains $\\Gamma$ as a\nsubgraph. This provides an effective way to reconstruct the defining graph\n$\\Gamma$ from the cohomology of $A(\\Gamma)$, to characterize the planarity of\nthe defining graph from the algebra of $A(\\Gamma)$, and to recover many other\nnatural graph-theoretic invariants. We also investigate the behavior of the\ncohomology basis graph under passage to elementary subminors, and show that it\nis not well-behaved under edge contraction.",
            "author": [
                "Ram\u00f3n Flores",
                "Delaram Kahrobaei",
                "Thomas Koberda",
                "Corentin Le Coz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05495v3",
                "http://arxiv.org/pdf/2309.05495v3"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO",
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07162v1",
            "title": "Model-based traffic state estimation for link traffic using moving\n  cameras",
            "updated": "2023-09-11T14:16:54Z",
            "published": "2023-09-11T14:16:54Z",
            "summary": "Traffic State Estimation (TSE) is the process of inferring traffic conditions\nbased on partially observed data using prior knowledge of traffic patterns. The\ntype of input data used has a significant impact on the accuracy and\nmethodology of TSE. Traditional TSE methods have relied on data from either\nstationary sensors like loop detectors or mobile sensors such as GPS-equipped\nfloating cars. However, both approaches have their limitations. This paper\nproposes a method for estimating traffic states on a road link using vehicle\ntrajectories obtained from cameras mounted on moving vehicles. It involves\ncombining data from multiple moving cameras to construct time-space diagrams\nand using them to estimate parameters for the link's fundamental diagram (FD)\nand densities in unobserved regions of space-time. The Cell Transmission Model\n(CTM) is utilized in conjunction with a Genetic Algorithm (GA) to optimize the\nFD parameters and boundary conditions necessary for accurate estimation. To\nevaluate the effectiveness of the proposed methodology, simulated traffic data\ngenerated by the SUMO traffic simulator was employed incorporating 140\ndifferent space-time diagrams with varying lane density and speed. The\nevaluation of the simulated data demonstrates the effectiveness of the proposed\napproach, as it achieves a low root mean square error (RMSE) value of 0.0079\nveh/m and is comparable to other CTM-based methods. In conclusion, the proposed\nTSE method opens new avenues for the estimation of traffic state using an\ninnovative data collection method that uses vehicle trajectories collected from\non-board cameras.",
            "author": [
                "Tanay Rastogi",
                "Michele D. Simoni",
                "Anders Karlstr\u00f6m"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07162v1",
                "http://arxiv.org/pdf/2309.07162v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05471v1",
            "title": "Electron and photon energy calibration with the ATLAS detector using LHC\n  Run 2 data",
            "updated": "2023-09-11T14:12:47Z",
            "published": "2023-09-11T14:12:47Z",
            "summary": "This paper presents the electron and photon energy calibration obtained with\nthe ATLAS detector using 140 fb$^{-1}$ of LHC proton-proton collision data\nrecorded at $\\sqrt{s}=13$ TeV between 2015 and 2018. Methods for the\nmeasurement of electron and photon energies are outlined, along with the\ncurrent knowledge of the passive material in front of the ATLAS electromagnetic\ncalorimeter. The energy calibration steps are discussed in detail, with\nemphasis on the improvements introduced in this paper. The absolute energy\nscale is set using a large sample of $Z$-boson decays into electron-positron\npairs, and its residual dependence on the electron energy is used for the first\ntime to further constrain systematic uncertainties. The achieved calibration\nuncertainties are typically 0.05% for electrons from resonant $Z$-boson decays,\n0.4% at $E_\\text{T}\\sim 10$ GeV, and 0.3% at $E_\\text{T}\\sim 1$ TeV; for\nphotons at $E_\\text{T}\\sim 60$ GeV, they are 0.2% on average. This is more than\ntwice as precise as the previous calibration. The new energy calibration is\nvalidated using $J/\\psi \\to ee$ and radiative $Z$-boson decays.",
            "author": [
                "ATLAS Collaboration"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05471v1",
                "http://arxiv.org/pdf/2309.05471v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05468v1",
            "title": "Universality for graphs of bounded degeneracy",
            "updated": "2023-09-11T14:08:57Z",
            "published": "2023-09-11T14:08:57Z",
            "summary": "Given a family $\\mathcal{H}$ of graphs, a graph $G$ is called\n$\\mathcal{H}$-universal if $G$ contains every graph of $\\mathcal{H}$ as a\nsubgraph. Following the extensive research on universal graphs of small size\nfor bounded-degree graphs, Alon asked what is the minimum number of edges that\na graph must have to be universal for the class of all $n$-vertex graphs that\nare $D$-degenerate. In this paper, we answer this question up to a factor that\nis polylogarithmic in $n.$",
            "author": [
                "Peter Allen",
                "Julia B\u00f6ttcher",
                "Anita Liebenau"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05468v1",
                "http://arxiv.org/pdf/2309.05468v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.11509v1",
            "title": "Using causal inference to avoid fallouts in data-driven parametric\n  analysis: a case study in the architecture, engineering, and construction\n  industry",
            "updated": "2023-09-11T13:54:58Z",
            "published": "2023-09-11T13:54:58Z",
            "summary": "The decision-making process in real-world implementations has been affected\nby a growing reliance on data-driven models. We investigated the synergetic\npattern between the data-driven methods, empirical domain knowledge, and\nfirst-principles simulations. We showed the potential risk of biased results\nwhen using data-driven models without causal analysis. Using a case study\nassessing the implication of several design solutions on the energy consumption\nof a building, we proved the necessity of causal analysis during the\ndata-driven modeling process. We concluded that: (a) Data-driven models'\naccuracy assessment or domain knowledge screening may not rule out biased and\nspurious results; (b) Data-driven models' feature selection should involve\ncareful consideration of causal relationships, especially colliders; (c) Causal\nanalysis results can be used as an aid to first-principles simulation design\nand parameter checking to avoid cognitive biases. We proved the benefits of\ncausal analysis when applied to data-driven models in building engineering.",
            "author": [
                "Xia Chen",
                "Ruiji Sun",
                "Ueli Saluz",
                "Stefano Schiavon",
                "Philipp Geyer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.11509v1",
                "http://arxiv.org/pdf/2309.11509v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG",
                "stat.ME",
                "62-06",
                "F.4; G.3; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05448v1",
            "title": "Panoptic Vision-Language Feature Fields",
            "updated": "2023-09-11T13:41:27Z",
            "published": "2023-09-11T13:41:27Z",
            "summary": "Recently, methods have been proposed for 3D open-vocabulary semantic\nsegmentation. Such methods are able to segment scenes into arbitrary classes\ngiven at run-time using their text description. In this paper, we propose to\nour knowledge the first algorithm for open-vocabulary panoptic segmentation,\nsimultaneously performing both semantic and instance segmentation. Our\nalgorithm, Panoptic Vision-Language Feature Fields (PVLFF) learns a feature\nfield of the scene, jointly learning vision-language features and hierarchical\ninstance features through a contrastive loss function from 2D instance segment\nproposals on input frames. Our method achieves comparable performance against\nthe state-of-the-art close-set 3D panoptic systems on the HyperSim, ScanNet and\nReplica dataset and outperforms current 3D open-vocabulary systems in terms of\nsemantic segmentation. We additionally ablate our method to demonstrate the\neffectiveness of our model architecture. Our code will be available at\nhttps://github.com/ethz-asl/autolabel.",
            "author": [
                "Haoran Chen",
                "Kenneth Blomqvist",
                "Francesco Milano",
                "Roland Siegwart"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05448v1",
                "http://arxiv.org/pdf/2309.05448v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05444v1",
            "title": "Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient\n  MoE for Instruction Tuning",
            "updated": "2023-09-11T13:31:00Z",
            "published": "2023-09-11T13:31:00Z",
            "summary": "The Mixture of Experts (MoE) is a widely known neural architecture where an\nensemble of specialized sub-models optimizes overall performance with a\nconstant computational cost. However, conventional MoEs pose challenges at\nscale due to the need to store all experts in memory. In this paper, we push\nMoE to the limit. We propose extremely parameter-efficient MoE by uniquely\ncombining MoE architecture with lightweight experts.Our MoE architecture\noutperforms standard parameter-efficient fine-tuning (PEFT) methods and is on\npar with full fine-tuning by only updating the lightweight experts -- less than\n1% of an 11B parameters model. Furthermore, our method generalizes to unseen\ntasks as it does not depend on any prior task knowledge. Our research\nunderscores the versatility of the mixture of experts architecture, showcasing\nits ability to deliver robust performance even when subjected to rigorous\nparameter constraints. Our code used in all the experiments is publicly\navailable here: https://github.com/for-ai/parameter-efficient-moe.",
            "author": [
                "Ted Zadouri",
                "Ahmet \u00dcst\u00fcn",
                "Arash Ahmadian",
                "Beyza Ermi\u015f",
                "Acyr Locatelli",
                "Sara Hooker"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05444v1",
                "http://arxiv.org/pdf/2309.05444v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05442v1",
            "title": "Testing Spreading Behavior in Networks with Arbitrary Topologies",
            "updated": "2023-09-11T13:28:19Z",
            "published": "2023-09-11T13:28:19Z",
            "summary": "Inspired by the works of Goldreich and Ron (J. ACM, 2017) and Nakar and Ron\n(ICALP, 2021), we initiate the study of property testing in dynamic\nenvironments with arbitrary topologies. Our focus is on the simplest\nnon-trivial rule that can be tested, which corresponds to the 1-BP rule of\nbootstrap percolation and models a simple spreading behavior: Every \"infected\"\nnode stays infected forever, and each \"healthy\" node becomes infected if and\nonly if it has at least one infected neighbor. We show various results for both\nthe case where we test a single time step of evolution and where the evolution\nspans several time steps. In the first, we show that the worst-case query\ncomplexity is $O(\\Delta/\\varepsilon)$ or $\\tilde{O}(\\sqrt{n}/\\varepsilon)$\n(whichever is smaller), where $\\Delta$ and $n$ are the maximum degree of a node\nand number of vertices, respectively, in the underlying graph, and we also show\nlower bounds for both one- and two-sided error testers that match our upper\nbounds up to $\\Delta = o(\\sqrt{n})$ and $\\Delta = O(n^{1/3})$, respectively. In\nthe second setting of testing the environment over $T$ time steps, we show\nupper bounds of $O(\\Delta^{T-1}/\\varepsilon T)$ and $\\tilde{O}(|E|/\\varepsilon\nT)$, where $E$ is the set of edges of the underlying graph. All of our\nalgorithms are one-sided error, and all of them are also time-conforming and\nnon-adaptive, with the single exception of the more complex\n$\\tilde{O}(\\sqrt{n}/\\varepsilon)$-query tester for the case $T = 2$.",
            "author": [
                "Augusto Modanese",
                "Yuichi Yoshida"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05442v1",
                "http://arxiv.org/pdf/2309.05442v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05434v1",
            "title": "A parameterised model for link prediction using node centrality and\n  similarity measure based on graph embedding",
            "updated": "2023-09-11T13:13:54Z",
            "published": "2023-09-11T13:13:54Z",
            "summary": "Link prediction is a key aspect of graph machine learning, with applications\nas diverse as disease prediction, social network recommendations, and drug\ndiscovery. It involves predicting new links that may form between network\nnodes. Despite the clear importance of link prediction, existing models have\nsignificant shortcomings. Graph Convolutional Networks, for instance, have been\nproven to be highly efficient for link prediction on a variety of datasets.\nHowever, they encounter severe limitations when applied to short-path networks\nand ego networks, resulting in poor performance. This presents a critical\nproblem space that this work aims to address. In this paper, we present the\nNode Centrality and Similarity Based Parameterised Model (NCSM), a novel method\nfor link prediction tasks. NCSM uniquely integrates node centrality and\nsimilarity measures as edge features in a customised Graph Neural Network (GNN)\nlayer, effectively leveraging the topological information of large networks.\nThis model represents the first parameterised GNN-based link prediction model\nthat considers topological information. The proposed model was evaluated on\nfive benchmark graph datasets, each comprising thousands of nodes and edges.\nExperimental results highlight NCSM's superiority over existing\nstate-of-the-art models like Graph Convolutional Networks and Variational Graph\nAutoencoder, as it outperforms them across various metrics and datasets. This\nexceptional performance can be attributed to NCSM's innovative integration of\nnode centrality, similarity measures, and its efficient use of topological\ninformation.",
            "author": [
                "Haohui Lu",
                "Shahadat Uddin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05434v1",
                "http://arxiv.org/pdf/2309.05434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05418v1",
            "title": "FlowIBR: Leveraging Pre-Training for Efficient Neural Image-Based\n  Rendering of Dynamic Scenes",
            "updated": "2023-09-11T12:35:17Z",
            "published": "2023-09-11T12:35:17Z",
            "summary": "We introduce a novel approach for monocular novel view synthesis of dynamic\nscenes. Existing techniques already show impressive rendering quality but tend\nto focus on optimization within a single scene without leveraging prior\nknowledge. This limitation has been primarily attributed to the lack of\ndatasets of dynamic scenes available for training and the diversity of scene\ndynamics. Our method FlowIBR circumvents these issues by integrating a neural\nimage-based rendering method, pre-trained on a large corpus of widely available\nstatic scenes, with a per-scene optimized scene flow field. Utilizing this flow\nfield, we bend the camera rays to counteract the scene dynamics, thereby\npresenting the dynamic scene as if it were static to the rendering network. The\nproposed method reduces per-scene optimization time by an order of magnitude,\nachieving comparable results to existing methods - all on a single\nconsumer-grade GPU.",
            "author": [
                "Marcel B\u00fcsching",
                "Josef Bengtson",
                "David Nilsson",
                "M\u00e5rten Bj\u00f6rkman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05418v1",
                "http://arxiv.org/pdf/2309.05418v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.2.10; I.4.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05386v1",
            "title": "Data-Driven Model Reduction and Nonlinear Model Predictive Control of an\n  Air Separation Unit by Applied Koopman Theory",
            "updated": "2023-09-11T11:18:16Z",
            "published": "2023-09-11T11:18:16Z",
            "summary": "Achieving real-time capability is an essential prerequisite for the\nindustrial implementation of nonlinear model predictive control (NMPC).\nData-driven model reduction offers a way to obtain low-order control models\nfrom complex digital twins. In particular, data-driven approaches require\nlittle expert knowledge of the particular process and its model, and provide\nreduced models of a well-defined generic structure. Herein, we apply our\nrecently proposed data-driven reduction strategy based on Koopman theory\n[Schulze et al. (2022), Comput. Chem. Eng.] to generate a low-order control\nmodel of an air separation unit (ASU). The reduced Koopman model combines\nautoencoders and linear latent dynamics and is constructed using machine\nlearning. Further, we present an NMPC implementation that uses derivative\ncomputation tailored to the fixed block structure of reduced Koopman models.\nOur reduction approach with tailored NMPC implementation enables real-time NMPC\nof an ASU at an average CPU time decrease by 98 %.",
            "author": [
                "Jan C. Schulze",
                "Danimir T. Doncevic",
                "Nils Erwes",
                "Alexander Mitsos"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05386v1",
                "http://arxiv.org/pdf/2309.05386v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05361v2",
            "title": "Cross-tokamak Disruption Prediction based on Physics-Guided Feature\n  Extraction and domain adaptation",
            "updated": "2023-11-01T09:18:35Z",
            "published": "2023-09-11T10:13:30Z",
            "summary": "The high acquisition cost and the significant demand for disruptive\ndischarges for data-driven disruption prediction models in future tokamaks pose\nan inherent contradiction in disruption prediction research. In this paper, we\ndemonstrated a novel approach to predict disruption in a future tokamak using\nonly a few discharges. The first step is to use the existing understanding of\nphysics to extract physics-guided features from the diagnostic signals of each\ntokamak, called physics-guided feature extraction (PGFE). The second step is to\nalign a few data from the future tokamak (target domain) and a large amount of\ndata from existing tokamak (source domain) based on a domain adaptation\nalgorithm called CORrelation ALignment (CORAL). It is the first attempt at\napplying domain adaptation in the task of disruption prediction. PGFE has been\nsuccessfully applied in J-TEXT to predict disruption with excellent\nperformance. PGFE can also reduce the data volume requirements due to\nextracting the less device-specific features, thereby establishing a solid\nfoundation for cross-tokamak disruption prediction. We have further improved\nCORAL (supervised CORAL, S-CORAL) to enhance its appropriateness in feature\nalignment for the disruption prediction task. To simulate the existing and\nfuture tokamak case, we selected J-TEXT as the existing tokamak and EAST as the\nfuture tokamak, which has a large gap in the ranges of plasma parameters. The\nutilization of the S-CORAL improves the disruption prediction performance on\nfuture tokamak. Through interpretable analysis, we discovered that the learned\nknowledge of the disruption prediction model through this approach exhibits\nmore similarities to the model trained on large data volumes of future tokamak.",
            "author": [
                "Chengshuo Shen",
                "Wei Zheng",
                "Bihao Guo",
                "Yonghua Ding",
                "Dalong Chen",
                "Xinkun Ai",
                "Fengming Xue",
                "Yu Zhong",
                "Nengchao Wang",
                "Biao Shen",
                "Binjia Xiao",
                "Zhongyong Chen",
                "Yuan Pan",
                "J-TEXT team"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05361v2",
                "http://arxiv.org/pdf/2309.05361v2"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05356v1",
            "title": "The number of $1$-nearly independent vertex subsets",
            "updated": "2023-09-11T10:02:24Z",
            "published": "2023-09-11T10:02:24Z",
            "summary": "Let $G$ be a graph with vertex set $V(G)$ and edge set $E(G)$. A subset $I$\nof $V(G)$ is an independent vertex subset if no two vertices in $I$ are\nadjacent in $G$. We study the number, $\\sigma_1(G)$, of all subsets of $v(G)$\nthat contain exactly one pair of adjacent vertices. We call those subsets\n1-nearly independent vertex subsets. Recursive formulas of $\\sigma_1$ are\nprovided, as well as some cases of explicit formulas. We prove a tight lower\n(resp. upper) bound on $\\sigma_1$ for graphs of order $n$. We deduce as a\ncorollary that the star $K_{1,n-1}$ (the tree with degree sequence\n$(n-1,1,\\dots,1)$) is the $n$-vertex tree with smallest $\\sigma_1$, while it is\nwell known that $K_{1,n-1}$ is the $n$-vertex tree with largest number of\nindependent subsets.",
            "author": [
                "Eric Ould Dadah Andriantiana",
                "Zekhaya B. Shozi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05356v1",
                "http://arxiv.org/pdf/2309.05356v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C69"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05334v1",
            "title": "MultIOD: Rehearsal-free Multihead Incremental Object Detector",
            "updated": "2023-09-11T09:32:45Z",
            "published": "2023-09-11T09:32:45Z",
            "summary": "Class-Incremental learning (CIL) is the ability of artificial agents to\naccommodate new classes as they appear in a stream. It is particularly\ninteresting in evolving environments where agents have limited access to memory\nand computational resources. The main challenge of class-incremental learning\nis catastrophic forgetting, the inability of neural networks to retain past\nknowledge when learning a new one. Unfortunately, most existing\nclass-incremental object detectors are applied to two-stage algorithms such as\nFaster-RCNN and rely on rehearsal memory to retain past knowledge. We believe\nthat the current benchmarks are not realistic, and more effort should be\ndedicated to anchor-free and rehearsal-free object detection. In this context,\nwe propose MultIOD, a class-incremental object detector based on CenterNet. Our\nmain contributions are: (1) we propose a multihead feature pyramid and\nmultihead detection architecture to efficiently separate class representations,\n(2) we employ transfer learning between classes learned initially and those\nlearned incrementally to tackle catastrophic forgetting, and (3) we use a\nclass-wise non-max-suppression as a post-processing technique to remove\nredundant boxes. Without bells and whistles, our method outperforms a range of\nstate-of-the-art methods on two Pascal VOC datasets.",
            "author": [
                "Eden Belouadah",
                "Arnaud Dapogny",
                "Kevin Bailly"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05334v1",
                "http://arxiv.org/pdf/2309.05334v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07159v1",
            "title": "A Strong and Simple Deep Learning Baseline for BCI MI Decoding",
            "updated": "2023-09-11T09:23:01Z",
            "published": "2023-09-11T09:23:01Z",
            "summary": "We propose EEG-SimpleConv, a straightforward 1D convolutional neural network\nfor Motor Imagery decoding in BCI. Our main motivation is to propose a very\nsimple baseline to compare to, using only very standard ingredients from the\nliterature. We evaluate its performance on four EEG Motor Imagery datasets,\nincluding simulated online setups, and compare it to recent Deep Learning and\nMachine Learning approaches. EEG-SimpleConv is at least as good or far more\nefficient than other approaches, showing strong knowledge-transfer capabilities\nacross subjects, at the cost of a low inference time. We advocate that using\noff-the-shelf ingredients rather than coming with ad-hoc solutions can\nsignificantly help the adoption of Deep Learning approaches for BCI. We make\nthe code of the models and the experiments accessible.",
            "author": [
                "Yassine El Ouahidi",
                "Vincent Gripon",
                "Bastien Pasdeloup",
                "Ghaith Bouallegue",
                "Nicolas Farrugia",
                "Giulia Lioi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07159v1",
                "http://arxiv.org/pdf/2309.07159v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05320v1",
            "title": "DynamicScore: a Novel Metric for Quantifying Graph Dynamics",
            "updated": "2023-09-11T09:08:14Z",
            "published": "2023-09-11T09:08:14Z",
            "summary": "This study introduces a new metric called ''DynamicScore'' to evaluate the\ndynamics of graphs. It can be applied to both vertices and edges. Unlike\ntraditional metrics, DynamicScore not only measures changes in the number of\nvertices or edges between consecutive time steps, but also takes into account\nthe composition of these sets. To illustrate the possible contributions of this\nmetric, we calculate it for increasing networks of preferential attachment\n(Barab{\\'a}si-Albert model) and Edge-Markovian graphs. The results improve our\nunderstanding of the dynamics inherent in these generated evolving graphs.",
            "author": [
                "Vincent Bridonneau",
                "Fr\u00e9d\u00e9ric Guinand",
                "Yoann Pign\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05320v1",
                "http://arxiv.org/pdf/2309.05320v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05317v1",
            "title": "Neural Koopman prior for data assimilation",
            "updated": "2023-09-11T09:04:36Z",
            "published": "2023-09-11T09:04:36Z",
            "summary": "With the increasing availability of large scale datasets, computational power\nand tools like automatic differentiation and expressive neural network\narchitectures, sequential data are now often treated in a data-driven way, with\na dynamical model trained from the observation data. While neural networks are\noften seen as uninterpretable black-box architectures, they can still benefit\nfrom physical priors on the data and from mathematical knowledge. In this\npaper, we use a neural network architecture which leverages the long-known\nKoopman operator theory to embed dynamical systems in latent spaces where their\ndynamics can be described linearly, enabling a number of appealing features. We\nintroduce methods that enable to train such a model for long-term continuous\nreconstruction, even in difficult contexts where the data comes in\nirregularly-sampled time series. The potential for self-supervised learning is\nalso demonstrated, as we show the promising use of trained dynamical models as\npriors for variational data assimilation techniques, with applications to e.g.\ntime series interpolation and forecasting.",
            "author": [
                "Anthony Frion",
                "Lucas Drumetz",
                "Mauro Dalla Mura",
                "Guillaume Tochon",
                "Abdeldjalil A\u00efssa El Bey"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05317v1",
                "http://arxiv.org/pdf/2309.05317v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05305v1",
            "title": "Fully-Connected Spatial-Temporal Graph for Multivariate Time Series Data",
            "updated": "2023-09-11T08:44:07Z",
            "published": "2023-09-11T08:44:07Z",
            "summary": "Multivariate Time-Series (MTS) data is crucial in various application fields.\nWith its sequential and multi-source (multiple sensors) properties, MTS data\ninherently exhibits Spatial-Temporal (ST) dependencies, involving temporal\ncorrelations between timestamps and spatial correlations between sensors in\neach timestamp. To effectively leverage this information, Graph Neural\nNetwork-based methods (GNNs) have been widely adopted. However, existing\napproaches separately capture spatial dependency and temporal dependency and\nfail to capture the correlations between Different sEnsors at Different\nTimestamps (DEDT). Overlooking such correlations hinders the comprehensive\nmodelling of ST dependencies within MTS data, thus restricting existing GNNs\nfrom learning effective representations. To address this limitation, we propose\na novel method called Fully-Connected Spatial-Temporal Graph Neural Network\n(FC-STGNN), including two key components namely FC graph construction and FC\ngraph convolution. For graph construction, we design a decay graph to connect\nsensors across all timestamps based on their temporal distances, enabling us to\nfully model the ST dependencies by considering the correlations between DEDT.\nFurther, we devise FC graph convolution with a moving-pooling GNN layer to\neffectively capture the ST dependencies for learning effective representations.\nExtensive experiments show the effectiveness of FC-STGNN on multiple MTS\ndatasets compared to SOTA methods.",
            "author": [
                "Yucheng Wang",
                "Yuecong Xu",
                "Jianfei Yang",
                "Min Wu",
                "Xiaoli Li",
                "Lihua Xie",
                "Zhenghua Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05305v1",
                "http://arxiv.org/pdf/2309.05305v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05297v1",
            "title": "On Ahn-Hendrey-Kim-Oum question for twin-width of graphs with 6 vertices",
            "updated": "2023-09-11T08:29:17Z",
            "published": "2023-09-11T08:29:17Z",
            "summary": "Twin-width is a recently introduced graph parameter for finite graphs. It is\nan open problem to determine whether there is an $n$-vertex graph having\ntwin-width at least $n/2$ (due to J. Ahn, K. Hendrey, D. Kim and S. Oum). In an\nearlier paper, the author showed that such a graph with less than equal to 5\nvertices does not exist. In this article, we show that such a graph with 6\nvertices does not exist. More precisely, we prove that each graph with 6\nvertices has twin-width less than equal to 2.",
            "author": [
                "Kajal Das"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05297v1",
                "http://arxiv.org/pdf/2309.05297v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C30, 05C38, 05C76, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05683v1",
            "title": "EANet: Expert Attention Network for Online Trajectory Prediction",
            "updated": "2023-09-11T07:09:40Z",
            "published": "2023-09-11T07:09:40Z",
            "summary": "Trajectory prediction plays a crucial role in autonomous driving. Existing\nmainstream research and continuoual learning-based methods all require training\non complete datasets, leading to poor prediction accuracy when sudden changes\nin scenarios occur and failing to promptly respond and update the model.\nWhether these methods can make a prediction in real-time and use data instances\nto update the model immediately(i.e., online learning settings) remains a\nquestion. The problem of gradient explosion or vanishing caused by data\ninstance streams also needs to be addressed. Inspired by Hedge Propagation\nalgorithm, we propose Expert Attention Network, a complete online learning\nframework for trajectory prediction. We introduce expert attention, which\nadjusts the weights of different depths of network layers, avoiding the model\nupdated slowly due to gradient problem and enabling fast learning of new\nscenario's knowledge to restore prediction accuracy. Furthermore, we propose a\nshort-term motion trend kernel function which is sensitive to scenario change,\nallowing the model to respond quickly. To the best of our knowledge, this work\nis the first attempt to address the online learning problem in trajectory\nprediction. The experimental results indicate that traditional methods suffer\nfrom gradient problems and that our method can quickly reduce prediction errors\nand reach the state-of-the-art prediction accuracy.",
            "author": [
                "Pengfei Yao",
                "Tianlu Mao",
                "Min Shi",
                "Jingkai Sun",
                "Zhaoqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05683v1",
                "http://arxiv.org/pdf/2309.05683v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05271v1",
            "title": "AutoFuse: Automatic Fusion Networks for Deformable Medical Image\n  Registration",
            "updated": "2023-09-11T07:05:02Z",
            "published": "2023-09-11T07:05:02Z",
            "summary": "Deformable image registration aims to find a dense non-linear spatial\ncorrespondence between a pair of images, which is a crucial step for many\nmedical tasks such as tumor growth monitoring and population analysis.\nRecently, Deep Neural Networks (DNNs) have been widely recognized for their\nability to perform fast end-to-end registration. However, DNN-based\nregistration needs to explore the spatial information of each image and fuse\nthis information to characterize spatial correspondence. This raises an\nessential question: what is the optimal fusion strategy to characterize spatial\ncorrespondence? Existing fusion strategies (e.g., early fusion, late fusion)\nwere empirically designed to fuse information by manually defined prior\nknowledge, which inevitably constrains the registration performance within the\nlimits of empirical designs. In this study, we depart from existing\nempirically-designed fusion strategies and develop a data-driven fusion\nstrategy for deformable image registration. To achieve this, we propose an\nAutomatic Fusion network (AutoFuse) that provides flexibility to fuse\ninformation at many potential locations within the network. A Fusion Gate (FG)\nmodule is also proposed to control how to fuse information at each potential\nnetwork location based on training data. Our AutoFuse can automatically\noptimize its fusion strategy during training and can be generalizable to both\nunsupervised registration (without any labels) and semi-supervised registration\n(with weak labels provided for partial training data). Extensive experiments on\ntwo well-benchmarked medical registration tasks (inter- and intra-patient\nregistration) with eight public datasets show that our AutoFuse outperforms\nstate-of-the-art unsupervised and semi-supervised registration methods.",
            "author": [
                "Mingyuan Meng",
                "Michael Fulham",
                "Dagan Feng",
                "Lei Bi",
                "Jinman Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05271v1",
                "http://arxiv.org/pdf/2309.05271v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05269v1",
            "title": "UniKG: A Benchmark and Universal Embedding for Large-Scale Knowledge\n  Graphs",
            "updated": "2023-09-11T06:56:42Z",
            "published": "2023-09-11T06:56:42Z",
            "summary": "Irregular data in real-world are usually organized as heterogeneous graphs\n(HGs) consisting of multiple types of nodes and edges. To explore useful\nknowledge from real-world data, both the large-scale encyclopedic HG datasets\nand corresponding effective learning methods are crucial, but haven't been well\ninvestigated. In this paper, we construct a large-scale HG benchmark dataset\nnamed UniKG from Wikidata to facilitate knowledge mining and heterogeneous\ngraph representation learning. Overall, UniKG contains more than 77 million\nmulti-attribute entities and 2000 diverse association types, which\nsignificantly surpasses the scale of existing HG datasets. To perform effective\nlearning on the large-scale UniKG, two key measures are taken, including (i)\nthe semantic alignment strategy for multi-attribute entities, which projects\nthe feature description of multi-attribute nodes into a common embedding space\nto facilitate node aggregation in a large receptive field; (ii) proposing a\nnovel plug-and-play anisotropy propagation module (APM) to learn effective\nmulti-hop anisotropy propagation kernels, which extends methods of large-scale\nhomogeneous graphs to heterogeneous graphs. These two strategies enable\nefficient information propagation among a tremendous number of multi-attribute\nentities and meantimes adaptively mine multi-attribute association through the\nmulti-hop aggregation in large-scale HGs. We set up a node classification task\non our UniKG dataset, and evaluate multiple baseline methods which are\nconstructed by embedding our APM into large-scale homogenous graph learning\nmethods. Our UniKG dataset and the baseline codes have been released at\nhttps://github.com/Yide-Qiu/UniKG.",
            "author": [
                "Yide Qiu",
                "Shaoxiang Ling",
                "Tong Zhang",
                "Bo Huang",
                "Zhen Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05269v1",
                "http://arxiv.org/pdf/2309.05269v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05260v1",
            "title": "Generalized Graphon Process: Convergence of Graph Frequencies in\n  Stretched Cut Distance",
            "updated": "2023-09-11T06:34:46Z",
            "published": "2023-09-11T06:34:46Z",
            "summary": "Graphons have traditionally served as limit objects for dense graph\nsequences, with the cut distance serving as the metric for convergence.\nHowever, sparse graph sequences converge to the trivial graphon under the\nconventional definition of cut distance, which make this framework inadequate\nfor many practical applications. In this paper, we utilize the concepts of\ngeneralized graphons and stretched cut distance to describe the convergence of\nsparse graph sequences. Specifically, we consider a random graph process\ngenerated from a generalized graphon. This random graph process converges to\nthe generalized graphon in stretched cut distance. We use this random graph\nprocess to model the growing sparse graph, and prove the convergence of the\nadjacency matrices' eigenvalues. We supplement our findings with experimental\nvalidation. Our results indicate the possibility of transfer learning between\nsparse graphs.",
            "author": [
                "Xingchao Jian",
                "Feng Ji",
                "Wee Peng Tay"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05260v1",
                "http://arxiv.org/pdf/2309.05260v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05259v2",
            "title": "A physics-informed and attention-based graph learning approach for\n  regional electric vehicle charging demand prediction",
            "updated": "2023-11-06T06:35:11Z",
            "published": "2023-09-11T06:31:45Z",
            "summary": "Along with the proliferation of electric vehicles (EVs), optimizing the use\nof EV charging space can significantly alleviate the growing load on\nintelligent transportation systems. As the foundation to achieve such an\noptimization, a spatiotemporal method for EV charging demand prediction in\nurban areas is required. Although several solutions have been proposed by using\ndata-driven deep learning methods, it can be found that these\nperformance-oriented methods may suffer from misinterpretations to correctly\nhandle the reverse relationship between charging demands and prices. To tackle\nthe emerging challenges of training an accurate and interpretable prediction\nmodel, this paper proposes a novel approach that enables the integration of\ngraph and temporal attention mechanisms for feature extraction and the usage of\nphysic-informed meta-learning in the model pre-training step for knowledge\ntransfer. Evaluation results on a dataset of 18,013 EV charging piles in\nShenzhen, China, show that the proposed approach, named PAG, can achieve\nstate-of-the-art forecasting performance and the ability in understanding the\nadaptive changes in charging demands caused by price fluctuations.",
            "author": [
                "Haohao Qu",
                "Haoxuan Kuang",
                "Jun Li",
                "Linlin You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05259v2",
                "http://arxiv.org/pdf/2309.05259v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05248v3",
            "title": "Enhancing Speaker Diarization with Large Language Models: A Contextual\n  Beam Search Approach",
            "updated": "2023-09-14T01:08:08Z",
            "published": "2023-09-11T05:47:56Z",
            "summary": "Large language models (LLMs) have shown great promise for capturing\ncontextual information in natural language processing tasks. We propose a novel\napproach to speaker diarization that incorporates the prowess of LLMs to\nexploit contextual cues in human dialogues. Our method builds upon an\nacoustic-based speaker diarization system by adding lexical information from an\nLLM in the inference stage. We model the multi-modal decoding process\nprobabilistically and perform joint acoustic and lexical beam search to\nincorporate cues from both modalities: audio and text. Our experiments\ndemonstrate that infusing lexical knowledge from the LLM into an acoustics-only\ndiarization system improves overall speaker-attributed word error rate\n(SA-WER). The experimental results show that LLMs can provide complementary\ninformation to acoustic models for the speaker diarization task via proposed\nbeam search decoding approach showing up to 39.8% relative delta-SA-WER\nimprovement from the baseline system. Thus, we substantiate that the proposed\ntechnique is able to exploit contextual information that is inaccessible to\nacoustics-only systems which is represented by speaker embeddings. In addition,\nthese findings point to the potential of using LLMs to improve speaker\ndiarization and other speech processing tasks by capturing semantic and\ncontextual cues.",
            "author": [
                "Tae Jin Park",
                "Kunal Dhawan",
                "Nithin Koluguri",
                "Jagadeesh Balam"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05248v3",
                "http://arxiv.org/pdf/2309.05248v3"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05247v1",
            "title": "l-connectivity, l-edge-connectivity and spectral radius of graphs",
            "updated": "2023-09-11T05:43:41Z",
            "published": "2023-09-11T05:43:41Z",
            "summary": "Let G be a connected graph. The toughness of G is defined as\nt(G)=min{\\frac{|S|}{c(G-S)}}, in which the minimum is taken over all proper\nsubsets S\\subset V(G) such that c(G-S)\\geq 2 where c(G-S) denotes the number of\ncomponents of G-S. Confirming a conjecture of Brouwer, Gu [SIAM J. Discrete\nMath. 35 (2021) 948--952] proved a tight lower bound on toughness of regular\ngraphs in terms of the second largest absolute eigenvalue. Fan, Lin and Lu\n[European J. Combin. 110 (2023) 103701] then studied the toughness of simple\ngraphs from the spectral radius perspective. While the toughness is an\nimportant concept in graph theory, it is also very interesting to study |S| for\nwhich c(G-S)\\geq l for a given integer l\\geq 2. This leads to the concept of\nthe l-connectivity, which is defined to be the minimum number of vertices of G\nwhose removal produces a disconnected graph with at least l components or a\ngraph with fewer than l vertices. Gu [European J. Combin. 92 (2021) 103255]\ndiscovered a lower bound on the l-connectivity of regular graphs via the second\nlargest absolute eigenvalue. As a counterpart, we discover the connection\nbetween the l-connectivity of simple graphs and the spectral radius. We also\nstudy similar problems for digraphs and an edge version.",
            "author": [
                "Dandan Fan",
                "Xiaofeng Gu",
                "Huiqiu Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05247v1",
                "http://arxiv.org/pdf/2309.05247v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06574v1",
            "title": "Circle Feature Graphormer: Can Circle Features Stimulate Graph\n  Transformer?",
            "updated": "2023-09-11T03:58:26Z",
            "published": "2023-09-11T03:58:26Z",
            "summary": "In this paper, we introduce two local graph features for missing link\nprediction tasks on ogbl-citation2. We define the features as Circle Features,\nwhich are borrowed from the concept of circle of friends. We propose the\ndetailed computing formulas for the above features. Firstly, we define the\nfirst circle feature as modified swing for common graph, which comes from\nbipartite graph. Secondly, we define the second circle feature as bridge, which\nindicates the importance of two nodes for different circle of friends. In\naddition, we firstly propose the above features as bias to enhance graph\ntransformer neural network, such that graph self-attention mechanism can be\nimproved. We implement a Circled Feature aware Graph transformer (CFG) model\nbased on SIEG network, which utilizes a double tower structure to capture both\nglobal and local structure features. Experimental results show that CFG\nachieves the state-of-the-art performance on dataset ogbl-citation2.",
            "author": [
                "Jingsong Lv",
                "Hongyang Chen",
                "Yao Qi",
                "Lei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06574v1",
                "http://arxiv.org/pdf/2309.06574v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05222v4",
            "title": "Facilitating Practical Fault-tolerant Quantum Computing Based on Color\n  Codes",
            "updated": "2023-09-27T02:55:30Z",
            "published": "2023-09-11T03:56:18Z",
            "summary": "Color code is a promising topological code for fault-tolerant quantum\ncomputing. Insufficient research on color code has delayed its practical\napplication. In this work, we address several key issues to facilitate\npractical fault-tolerant quantum computing based on color codes. First, by\nintroducing decoding graphs with error-rate-related weights, we improve the\nthreshold of the triangular color code under the standard circuit-level noise\nmodel to $0.47\\%$, narrowing the gap to that of the surface code. Second, we\ninvestigate the circuit-level decoding strategy of color code lattice surgery,\nwhich is crucial for performing logical operations in a quantum computer with\ntwo-dimensional architecture. Lastly, the state injection protocol of\ntriangular color code is proposed, offering an optimal logical error rate\ncompared to any other state injection protocol of the CSS code, which is\nbeneficial for increasing the efficiency of magic state distillation.",
            "author": [
                "Jiaxuan Zhang",
                "Yu-Chun Wu",
                "Guo-Ping Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05222v4",
                "http://arxiv.org/pdf/2309.05222v4"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05202v1",
            "title": "Graph Contextual Contrasting for Multivariate Time Series Classification",
            "updated": "2023-09-11T02:35:22Z",
            "published": "2023-09-11T02:35:22Z",
            "summary": "Contrastive learning, as a self-supervised learning paradigm, becomes popular\nfor Multivariate Time-Series (MTS) classification. It ensures the consistency\nacross different views of unlabeled samples and then learns effective\nrepresentations for these samples. Existing contrastive learning methods mainly\nfocus on achieving temporal consistency with temporal augmentation and\ncontrasting techniques, aiming to preserve temporal patterns against\nperturbations for MTS data. However, they overlook spatial consistency that\nrequires the stability of individual sensors and their correlations. As MTS\ndata typically originate from multiple sensors, ensuring spatial consistency\nbecomes essential for the overall performance of contrastive learning on MTS\ndata. Thus, we propose Graph Contextual Contrasting (GCC) for spatial\nconsistency across MTS data. Specifically, we propose graph augmentations\nincluding node and edge augmentations to preserve the stability of sensors and\ntheir correlations, followed by graph contrasting with both node- and\ngraph-level contrasting to extract robust sensor- and global-level features. We\nfurther introduce multi-window temporal contrasting to ensure temporal\nconsistency in the data for each sensor. Extensive experiments demonstrate that\nour proposed GCC achieves state-of-the-art performance on various MTS\nclassification tasks.",
            "author": [
                "Yucheng Wang",
                "Yuecong Xu",
                "Jianfei Yang",
                "Min Wu",
                "Xiaoli Li",
                "Lihua Xie",
                "Zhenghua Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05202v1",
                "http://arxiv.org/pdf/2309.05202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05201v1",
            "title": "Two is Better Than One: Answering Complex Questions by Multiple\n  Knowledge Sources with Generalized Links",
            "updated": "2023-09-11T02:31:41Z",
            "published": "2023-09-11T02:31:41Z",
            "summary": "Incorporating multiple knowledge sources is proven to be beneficial for\nanswering complex factoid questions. To utilize multiple knowledge bases (KB),\nprevious works merge all KBs into a single graph via entity alignment and\nreduce the problem to question-answering (QA) over the fused KB. In reality,\nvarious link relations between KBs might be adopted in QA over multi-KBs. In\naddition to the identity between the alignable entities (i.e. full link),\nunalignable entities expressing the different aspects or types of an abstract\nconcept may also be treated identical in a question (i.e. partial link). Hence,\nthe KB fusion in prior works fails to represent all types of links, restricting\ntheir ability to comprehend multi-KBs for QA. In this work, we formulate the\nnovel Multi-KB-QA task that leverages the full and partial links among multiple\nKBs to derive correct answers, a benchmark with diversified link and query\ntypes is also constructed to efficiently evaluate Multi-KB-QA performance.\nFinally, we propose a method for Multi-KB-QA that encodes all link relations in\nthe KB embedding to score and rank candidate answers. Experiments show that our\nmethod markedly surpasses conventional KB-QA systems in Multi-KB-QA, justifying\nthe necessity of devising this task.",
            "author": [
                "Minhao Zhang",
                "Yongliang Ma",
                "Yanzeng Li",
                "Ruoyu Zhang",
                "Lei Zou",
                "Ming Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05201v1",
                "http://arxiv.org/pdf/2309.05201v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05199v3",
            "title": "A Note Related to Graph Theory",
            "updated": "2023-09-29T16:17:09Z",
            "published": "2023-09-11T02:29:59Z",
            "summary": "This article foucuses on $(P_3\\cup P_2,K_4)$-free graph. In this paper, we\nprove that if G is $(P_3\\cup P_2,K_4)$-free, then $\\chi(G)\\le 7$. We then use\nour result to obtain the upper bound of order and chromatic number of\n$(4K_1,\\overline{P_3\\cup P_2},K_{\\omega})$-free graph .",
            "author": [
                "Jinfeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05199v3",
                "http://arxiv.org/pdf/2309.05199v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05195v1",
            "title": "Cloud-mediated self-triggered synchronization of a general linear\n  multi-agent system over a directed graph",
            "updated": "2023-09-11T02:14:54Z",
            "published": "2023-09-11T02:14:54Z",
            "summary": "This paper proposes a self-triggered synchronization control method of a\ngeneral high-order linear time-invariant multi-agent system through a cloud\nrepository. In the cloud-mediated self-triggered control, each agent\nasynchronously accesses the cloud repository to get past information on its\nneighboring agents. Then, the agent predicts future behaviors of its neighbors\nas well as of its own, and locally determines its next access time to the cloud\nrepository. In the case of a general high-order linear agent dynamics, each\nagent has to estimate exponential evolution of its trajectory characterized by\neigenvalues of a system matrix, which is different from single/double\nintegrator or first-order linear agents. Our proposed method deals with\nexponential behaviors of the agents by tightly evaluating the bounds on matrix\nexponentials. Based on these bound, we design the self-triggered controller\nthrough a cloud which achieves bounded state synchronization of the closed-loop\nsystem without exhibiting any Zeno behaviors. The effectiveness of the proposed\nmethod is demonstrated through the numerical simulation.",
            "author": [
                "Takumi Namba",
                "Kiyotsugu Takaba"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05195v1",
                "http://arxiv.org/pdf/2309.05195v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05184v1",
            "title": "SIM-Sync: From Certifiably Optimal Synchronization over the 3D\n  Similarity Group to Scene Reconstruction with Learned Depth",
            "updated": "2023-09-11T01:02:20Z",
            "published": "2023-09-11T01:02:20Z",
            "summary": "This paper presents SIM-Sync, a certifiably optimal algorithm that estimates\ncamera trajectory and 3D scene structure directly from multiview image\nkeypoints. SIM-Sync fills the gap between pose graph optimization and bundle\nadjustment; the former admits efficient global optimization but requires\nrelative pose measurements and the latter directly consumes image keypoints but\nis difficult to optimize globally (due to camera projective geometry). The\nbridge to this gap is a pretrained depth prediction network. Given a graph with\nnodes representing monocular images taken at unknown camera poses and edges\ncontaining pairwise image keypoint correspondences, SIM-Sync first uses a\npretrained depth prediction network to lift the 2D keypoints into 3D scaled\npoint clouds, where the scaling of the per-image point cloud is unknown due to\nthe scale ambiguity in monocular depth prediction. SIM-Sync then seeks to\nsynchronize jointly the unknown camera poses and scaling factors (i.e., over\nthe 3D similarity group). The SIM-Sync formulation, despite nonconvex, allows\ndesigning an efficient certifiably optimal solver that is almost identical to\nthe SE-Sync algorithm. We demonstrate the tightness, robustness, and practical\nusefulness of SIM-Sync in both simulated and real experiments. In simulation,\nwe show (i) SIM-Sync compares favorably with SE-Sync in scale-free\nsynchronization, and (ii) SIM-Sync can be used together with robust estimators\nto tolerate a high amount of outliers. In real experiments, we show (a)\nSIM-Sync achieves similar performance as Ceres on bundle adjustment datasets,\nand (b) SIM-Sync performs on par with ORB-SLAM3 on the TUM dataset with\nzero-shot depth prediction.",
            "author": [
                "Xihang Yu",
                "Heng Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05184v1",
                "http://arxiv.org/pdf/2309.05184v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05182v1",
            "title": "Graph Matching in Correlated Stochastic Block Models for Improved Graph\n  Clustering",
            "updated": "2023-09-11T00:56:23Z",
            "published": "2023-09-11T00:56:23Z",
            "summary": "We consider community detection from multiple correlated graphs sharing the\nsame community structure. The correlated graphs are generated by independent\nsubsampling of a parent graph sampled from the stochastic block model. The\nvertex correspondence between the correlated graphs is assumed to be unknown.\nWe consider the two-step procedure where the vertex correspondence between the\ncorrelated graphs is first revealed, and the communities are recovered from the\nunion of the correlated graphs, which becomes denser than each single graph. We\nderive the information-theoretic limits for exact graph matching in general\ndensity regimes and the number of communities, and then analyze the regime of\ngraph parameters, where one can benefit from the matching of the correlated\ngraphs in recovering the latent community structure of the graphs.",
            "author": [
                "Joonhyuk Yang",
                "Hye Won Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05182v1",
                "http://arxiv.org/pdf/2309.05182v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.DS",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05178v1",
            "title": "Quantifying Uncertainty in Aggregate Queries over Integrated Datasets",
            "updated": "2023-09-11T00:14:49Z",
            "published": "2023-09-11T00:14:49Z",
            "summary": "Data integration is a notoriously difficult and heuristic-driven process,\nespecially when ground-truth data are not readily available. This paper\npresents a measure of uncertainty by providing maximal and minimal ranges of a\nquery outcome in two-table, one-to-many data integration workflows. Users can\nuse these query results to guide a search through different matching\nparameters, similarity metrics, and constraints. Even though there are\nexponentially many such matchings, we show that in appropriately constrained\ncircumstances that this result range can be calculated in polynomial time with\nbipartite graph matching. We evaluate this on real-world datasets and synthetic\ndatasets, and find that uncertainty estimates are more robust when a\ngraph-matching based approach is used for data integration.",
            "author": [
                "Deniz Turkcapar",
                "Sanjay Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05178v1",
                "http://arxiv.org/pdf/2309.05178v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05171v1",
            "title": "Bounds on Kemeny's constant of a graph and the Nordhaus-Gaddum problem",
            "updated": "2023-09-11T00:00:36Z",
            "published": "2023-09-11T00:00:36Z",
            "summary": "We study Nordhaus-Gaddum problems for Kemeny's constant $\\mathcal{K}(G)$ of a\nconnected graph $G$. We prove bounds on\n$\\min\\{\\mathcal{K}(G),\\mathcal{K}(\\overline{G})\\}$ and the product\n$\\mathcal{K}(G)\\mathcal{K}(\\overline{G})$ for various families of graphs. In\nparticular, we show that if the maximum degree of a graph $G$ on $n$ vertices\nis $n-O(1)$ or $n-\\Omega(n)$, then\n$\\min\\{\\mathcal{K}(G),\\mathcal{K}(\\overline{G})\\}$ is at most $O(n)$.",
            "author": [
                "Sooyeong Kim",
                "Neal Madras",
                "Ada Chan",
                "Mark Kempton",
                "Stephen Kirkland",
                "Adam Knudson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05171v1",
                "http://arxiv.org/pdf/2309.05171v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C09, 60J10, 05C81, 05C50, 05A19"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05166v1",
            "title": "A quantum Monte Carlo algorithm for Bose-Hubbard models on arbitrary\n  graphs",
            "updated": "2023-09-10T23:22:00Z",
            "published": "2023-09-10T23:22:00Z",
            "summary": "We propose a quantum Monte Carlo algorithm capable of simulating the\nBose-Hubbard model on arbitrary graphs, obviating the need for devising\nlattice-specific updates for different input graphs. We show that with our\nmethod, which is based on the recently introduced Permutation Matrix\nRepresentation Quantum Monte Carlo [Gupta, Albash and Hen, J. Stat. Mech.\n(2020) 073105], the problem of adapting the simulation to a given geometry\namounts to generating a cycle basis for the graph on which the model is\ndefined, a procedure that can be carried out efficiently and and in an\nautomated manner. To showcase the versatility of our approach, we provide\nsimulation results for Bose-Hubbard models defined on two-dimensional lattices\nas well as on a number of random graphs.",
            "author": [
                "Itay Hen",
                "Emre Akaturk"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05166v1",
                "http://arxiv.org/pdf/2309.05166v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05149v1",
            "title": "From Erdos-Renyi graphs to Linial-Meshulam complexes via the\n  multineighbor construction",
            "updated": "2023-09-10T21:53:11Z",
            "published": "2023-09-10T21:53:11Z",
            "summary": "The $m$-neighbor complex of a graph is the simplicial complex in which faces\nare sets of vertices with at least $m$ common neighbors. We consider these\ncomplexes for Erdos-Renyi random graphs and find that for certain explicit\nfamilies of parameters the resulting complexes are with high probability\n$(t-1)$-dimensional with all $(t-2)$-faces and each $(t-1)$-face present with a\nfixed probability. Unlike the Linial-Meshulam measure on the same complexes\nthere can be correlations between pairs of $(t-1)$-faces but we conjecture that\nthe two measures converge in total variation for certain parameter sequences.",
            "author": [
                "Eric Babson",
                "Jan Spali\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05149v1",
                "http://arxiv.org/pdf/2309.05149v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C80 (Primary) 62R99 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07157v1",
            "title": "Distribution Grid Line Outage Identification with Unknown Pattern and\n  Performance Guarantee",
            "updated": "2023-09-10T21:11:36Z",
            "published": "2023-09-10T21:11:36Z",
            "summary": "Line outage identification in distribution grids is essential for sustainable\ngrid operation. In this work, we propose a practical yet robust detection\napproach that utilizes only readily available voltage magnitudes, eliminating\nthe need for costly phase angles or power flow data. Given the sensor data,\nmany existing detection methods based on change-point detection require prior\nknowledge of outage patterns, which are unknown for real-world outage\nscenarios. To remove this impractical requirement, we propose a data-driven\nmethod to learn the parameters of the post-outage distribution through gradient\ndescent. However, directly using gradient descent presents feasibility issues.\nTo address this, we modify our approach by adding a Bregman divergence\nconstraint to control the trajectory of the parameter updates, which eliminates\nthe feasibility problems. As timely operation is the key nowadays, we prove\nthat the optimal parameters can be learned with convergence guarantees via\nleveraging the statistical and physical properties of voltage data. We evaluate\nour approach using many representative distribution grids and real load\nprofiles with 17 outage configurations. The results show that we can detect and\nlocalize the outage in a timely manner with only voltage magnitudes and without\nassuming a prior knowledge of outage patterns.",
            "author": [
                "Chenhan Xiao",
                "Yizheng Liao",
                "Yang Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07157v1",
                "http://arxiv.org/pdf/2309.07157v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "math.OC",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05135v1",
            "title": "Streaming Semidefinite Programs: $O(\\sqrt{n})$ Passes, Small Space and\n  Fast Runtime",
            "updated": "2023-09-10T21:07:19Z",
            "published": "2023-09-10T21:07:19Z",
            "summary": "We study the problem of solving semidefinite programs (SDP) in the streaming\nmodel. Specifically, $m$ constraint matrices and a target matrix $C$, all of\nsize $n\\times n$ together with a vector $b\\in \\mathbb{R}^m$ are streamed to us\none-by-one. The goal is to find a matrix $X\\in \\mathbb{R}^{n\\times n}$ such\nthat $\\langle C, X\\rangle$ is maximized, subject to $\\langle A_i, X\\rangle=b_i$\nfor all $i\\in [m]$ and $X\\succeq 0$. Previous algorithmic studies of SDP\nprimarily focus on \\emph{time-efficiency}, and all of them require a\nprohibitively large $\\Omega(mn^2)$ space in order to store \\emph{all the\nconstraints}. Such space consumption is necessary for fast algorithms as it is\nthe size of the input. In this work, we design an interior point method (IPM)\nthat uses $\\widetilde O(m^2+n^2)$ space, which is strictly sublinear in the\nregime $n\\gg m$. Our algorithm takes $O(\\sqrt n\\log(1/\\epsilon))$ passes, which\nis standard for IPM. Moreover, when $m$ is much smaller than $n$, our algorithm\nalso matches the time complexity of the state-of-the-art SDP solvers. To\nachieve such a sublinear space bound, we design a novel sketching method that\nenables one to compute a spectral approximation to the Hessian matrix in\n$O(m^2)$ space. To the best of our knowledge, this is the first method that\nsuccessfully applies sketching technique to improve SDP algorithm in terms of\nspace (also time).",
            "author": [
                "Zhao Song",
                "Mingquan Ye",
                "Lichen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05135v1",
                "http://arxiv.org/pdf/2309.05135v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05133v3",
            "title": "Parallel RAM from Cyclic Circuits",
            "updated": "2023-10-27T05:04:51Z",
            "published": "2023-09-10T20:53:18Z",
            "summary": "Known simulations of random access machines (RAMs) or parallel RAMs (PRAMs)\nby Boolean circuits incur significant polynomial blowup, due to the need to\nrepeatedly simulate accesses to a large main memory.\n  Consider a single modification to Boolean circuits that removes the\nrestriction that circuit graphs are acyclic. We call this the cyclic circuit\nmodel. Note, cyclic circuits remain combinational, as they do not allow wire\nvalues to change over time.\n  We simulate PRAM with a cyclic circuit, and the blowup from our simulation is\nonly polylogarithmic. Consider a PRAM program $P$ that on a length-$n$ input\nuses an arbitrary number of processors to manipulate words of size $\\Theta(\\log\nn)$ bits and then halts within $W(n)$ work. We construct a size-$O(W(n)\\cdot\n\\log^4 n)$ cyclic circuit that simulates $P$. Suppose that on a particular\ninput, $P$ halts in time $T$; our circuit computes the same output within $T\n\\cdot O(\\log^3 n)$ gate delay.\n  This implies theoretical feasibility of powerful parallel machines. Cyclic\ncircuits can be implemented in hardware, and our circuit achieves performance\nwithin polylog factors of PRAM. Our simulated PRAM synchronizes processors via\nlogical dependencies between wires.",
            "author": [
                "David Heath"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05133v3",
                "http://arxiv.org/pdf/2309.05133v3"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05132v1",
            "title": "DAD++: Improved Data-free Test Time Adversarial Defense",
            "updated": "2023-09-10T20:39:53Z",
            "published": "2023-09-10T20:39:53Z",
            "summary": "With the increasing deployment of deep neural networks in safety-critical\napplications such as self-driving cars, medical imaging, anomaly detection,\netc., adversarial robustness has become a crucial concern in the reliability of\nthese networks in real-world scenarios. A plethora of works based on\nadversarial training and regularization-based techniques have been proposed to\nmake these deep networks robust against adversarial attacks. However, these\nmethods require either retraining models or training them from scratch, making\nthem infeasible to defend pre-trained models when access to training data is\nrestricted. To address this problem, we propose a test time Data-free\nAdversarial Defense (DAD) containing detection and correction frameworks.\nMoreover, to further improve the efficacy of the correction framework in cases\nwhen the detector is under-confident, we propose a soft-detection scheme\n(dubbed as \"DAD++\"). We conduct a wide range of experiments and ablations on\nseveral datasets and network architectures to show the efficacy of our proposed\napproach. Furthermore, we demonstrate the applicability of our approach in\nimparting adversarial defense at test time under data-free (or data-efficient)\napplications/setups, such as Data-free Knowledge Distillation and Source-free\nUnsupervised Domain Adaptation, as well as Semi-supervised classification\nframeworks. We observe that in all the experiments and applications, our DAD++\ngives an impressive performance against various adversarial attacks with a\nminimal drop in clean accuracy. The source code is available at:\nhttps://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense",
            "author": [
                "Gaurav Kumar Nayak",
                "Inder Khatri",
                "Shubham Randive",
                "Ruchit Rawal",
                "Anirban Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05132v1",
                "http://arxiv.org/pdf/2309.05132v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05121v1",
            "title": "Cardy's formula does not hold on some 2D lattices for critical\n  two-dimensional percolation",
            "updated": "2023-09-10T19:46:17Z",
            "published": "2023-09-10T19:46:17Z",
            "summary": "The scaling limit of crossing probabilities is believed to satisfy a\nconformal mapping formula, called Cardy's formula, in two-dimensional\npercolation at the criticality. The formula has been confirmed to hold for site\npercolation on the equilateral triangular lattice. In this paper, we show that\nCardy's formula could not hold for some two-dimensional triangular and\nsquare-type lattices, in particular for some periodic 2D graphs.",
            "author": [
                "Yu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05121v1",
                "http://arxiv.org/pdf/2309.05121v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60K35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05100v1",
            "title": "A shorter proof of the path-width theorem",
            "updated": "2023-09-10T18:06:04Z",
            "published": "2023-09-10T18:06:04Z",
            "summary": "A graph has {\\em path-width} at most $w$ if it can be built from a sequence\nof graphs each with at most $w+1$ vertices, by overlapping consecutive terms.\nEvery graph with path-width at least $w-1$ contains every $w$-vertex forest as\na minor: this was originally proved by Bienstock, Robertson, Thomas and the\nauthor, and was given a short proof by Diestel. Here we give a proof even\nshorter and simpler than that of Diestel.",
            "author": [
                "P. Seymour"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05100v1",
                "http://arxiv.org/pdf/2309.05100v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C83"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05092v1",
            "title": "Adaptive conformal classification with noisy labels",
            "updated": "2023-09-10T17:35:43Z",
            "published": "2023-09-10T17:35:43Z",
            "summary": "This paper develops novel conformal prediction methods for classification\ntasks that can automatically adapt to random label contamination in the\ncalibration sample, enabling more informative prediction sets with stronger\ncoverage guarantees compared to state-of-the-art approaches. This is made\npossible by a precise theoretical characterization of the effective coverage\ninflation (or deflation) suffered by standard conformal inferences in the\npresence of label contamination, which is then made actionable through new\ncalibration algorithms. Our solution is flexible and can leverage different\nmodeling assumptions about the label contamination process, while requiring no\nknowledge about the data distribution or the inner workings of the\nmachine-learning classifier. The advantages of the proposed methods are\ndemonstrated through extensive simulations and an application to object\nclassification with the CIFAR-10H image data set.",
            "author": [
                "Matteo Sesia",
                "Y. X. Rachel Wang",
                "Xin Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05092v1",
                "http://arxiv.org/pdf/2309.05092v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05091v1",
            "title": "SpeechMirror: A Multimodal Visual Analytics System for Personalized\n  Reflection of Online Public Speaking Effectiveness",
            "updated": "2023-09-10T17:34:40Z",
            "published": "2023-09-10T17:34:40Z",
            "summary": "As communications are increasingly taking place virtually, the ability to\npresent well online is becoming an indispensable skill. Online speakers are\nfacing unique challenges in engaging with remote audiences. However, there has\nbeen a lack of evidence-based analytical systems for people to comprehensively\nevaluate online speeches and further discover possibilities for improvement.\nThis paper introduces SpeechMirror, a visual analytics system facilitating\nreflection on a speech based on insights from a collection of online speeches.\nThe system estimates the impact of different speech techniques on effectiveness\nand applies them to a speech to give users awareness of the performance of\nspeech techniques. A similarity recommendation approach based on speech factors\nor script content supports guided exploration to expand knowledge of\npresentation evidence and accelerate the discovery of speech delivery\npossibilities. SpeechMirror provides intuitive visualizations and interactions\nfor users to understand speech factors. Among them, SpeechTwin, a novel\nmultimodal visual summary of speech, supports rapid understanding of critical\nspeech factors and comparison of different speech samples, and SpeechPlayer\naugments the speech video by integrating visualization of the speaker's body\nlanguage with interaction, for focused analysis. The system utilizes\nvisualizations suited to the distinct nature of different speech factors for\nuser comprehension. The proposed system and visualization techniques were\nevaluated with domain experts and amateurs, demonstrating usability for users\nwith low visualization literacy and its efficacy in assisting users to develop\ninsights for potential improvement.",
            "author": [
                "Zeyuan Huang",
                "Qiang He",
                "Kevin Maher",
                "Xiaoming Deng",
                "Yu-Kun Lai",
                "Cuixia Ma",
                "Sheng-feng Qin",
                "Yong-Jin Liu",
                "Hongan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05091v1",
                "http://arxiv.org/pdf/2309.05091v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05088v1",
            "title": "Towards Trustworthy Artificial Intelligence for Equitable Global Health",
            "updated": "2023-09-10T17:22:41Z",
            "published": "2023-09-10T17:22:41Z",
            "summary": "Artificial intelligence (AI) can potentially transform global health, but\nalgorithmic bias can exacerbate social inequities and disparity. Trustworthy AI\nentails the intentional design to ensure equity and mitigate potential biases.\nTo advance trustworthy AI in global health, we convened a workshop on Fairness\nin Machine Intelligence for Global Health (FairMI4GH). The event brought\ntogether a global mix of experts from various disciplines, community health\npractitioners, policymakers, and more. Topics covered included managing AI bias\nin socio-technical systems, AI's potential impacts on global health, and\nbalancing data privacy with transparency. Panel discussions examined the\ncultural, political, and ethical dimensions of AI in global health. FairMI4GH\naimed to stimulate dialogue, facilitate knowledge transfer, and spark\ninnovative solutions. Drawing from NIST's AI Risk Management Framework, it\nprovided suggestions for handling AI risks and biases. The need to mitigate\ndata biases from the research design stage, adopt a human-centered approach,\nand advocate for AI transparency was recognized. Challenges such as updating\nlegal frameworks, managing cross-border data sharing, and motivating developers\nto reduce bias were acknowledged. The event emphasized the necessity of diverse\nviewpoints and multi-dimensional dialogue for creating a fair and ethical AI\nframework for equitable global health.",
            "author": [
                "Hong Qin",
                "Jude Kong",
                "Wandi Ding",
                "Ramneek Ahluwalia",
                "Christo El Morr",
                "Zeynep Engin",
                "Jake Okechukwu Effoduh",
                "Rebecca Hwa",
                "Serena Jingchuan Guo",
                "Laleh Seyyed-Kalantari",
                "Sylvia Kiwuwa Muyingo",
                "Candace Makeda Moore",
                "Ravi Parikh",
                "Reva Schwartz",
                "Dongxiao Zhu",
                "Xiaoqian Wang",
                "Yiye Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05088v1",
                "http://arxiv.org/pdf/2309.05088v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "q-bio.OT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05086v2",
            "title": "Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler",
            "updated": "2023-09-28T19:44:09Z",
            "published": "2023-09-10T17:13:25Z",
            "summary": "We propose a neuralized undirected graphical model called Neural-Hidden-CRF\nto solve the weakly-supervised sequence labeling problem. Under the umbrella of\nprobabilistic undirected graph theory, the proposed Neural-Hidden-CRF embedded\nwith a hidden CRF layer models the variables of word sequence, latent ground\ntruth sequence, and weak label sequence with the global perspective that\nundirected graphical models particularly enjoy. In Neural-Hidden-CRF, we can\ncapitalize on the powerful language model BERT or other deep models to provide\nrich contextual semantic knowledge to the latent ground truth sequence, and use\nthe hidden CRF layer to capture the internal label dependencies.\nNeural-Hidden-CRF is conceptually simple and empirically powerful. It obtains\nnew state-of-the-art results on one crowdsourcing benchmark and three\nweak-supervision benchmarks, including outperforming the recent advanced model\nCHMM by 2.80 F1 points and 2.23 F1 points in average generalization and\ninference performance, respectively.",
            "author": [
                "Zhijun Chen",
                "Hailong Sun",
                "Wanhao Zhang",
                "Chunyi Xu",
                "Qianren Mao",
                "Pengpeng Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3580305.3599445",
                "http://arxiv.org/abs/2309.05086v2",
                "http://arxiv.org/pdf/2309.05086v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05084v2",
            "title": "Quantile mixed graphical models with an application to mass public\n  shootings in the United States",
            "updated": "2023-09-27T12:16:30Z",
            "published": "2023-09-10T17:11:11Z",
            "summary": "Over the last fifty years, the United States have experienced hundreds of\nmass public shootings that resulted in thousands of victims. Characterized by\ntheir frequent occurrence and devastating nature, mass shootings have become a\nmajor public health hazard that dramatically impact safety and well-being of\nindividuals and communities. Given the epidemic traits of this phenomenon,\nthere have been concerted efforts to understand the root causes that lead to\npublic mass shootings in order to implement effective prevention strategies. We\npropose a quantile mixed graphical model for investigating the intricacies of\ninter- and infra-domain relationships of this complex phenomenon, where\nconditional relations between discrete and continuous variables are modeled\nwithout stringent distributional assumptions using Parzen's definition of\nmid-quantile. To retrieve the graph structure and recover only the most\nrelevant connections, we consider the neighborhood selection approach in which\nconditional mid-quantiles of each variable in the network are modeled as a\nsparse function of all others. We propose a two-step procedure to estimate the\ngraph where, in the first step, conditional mid-probabilities are obtained\nsemi-parametrically and, in the second step, the model parameters are estimated\nby solving an implicit equation with a LASSO penalty.",
            "author": [
                "Luca Merlo",
                "Marco Geraci",
                "Lea Petrella"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05084v2",
                "http://arxiv.org/pdf/2309.05084v2"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05078v2",
            "title": "Laboratory Measurement of Volatile Ice Vapor Pressures with a Quartz\n  Crystal Microbalance",
            "updated": "2023-09-21T18:16:48Z",
            "published": "2023-09-10T16:56:27Z",
            "summary": "Nitrogen, carbon monoxide, and methane are key materials in the far outer\nSolar System where their high volatility enables them to sublimate, potentially\ndriving activity at very low temperatures. Knowledge of their vapor pressures\nand latent heats of sublimation at relevant temperatures is needed to model the\nprocesses involved. We describe a method for using a quartz crystal\nmicrobalance to measure the sublimation flux of these volatile ices in the free\nmolecular flow regime, accounting for the simultaneous sublimation from and\ncondensation onto the quartz crystal to derive vapor pressures and latent heats\nof sublimation. We find vapor pressures to be somewhat lower than previous\nestimates in literature, with carbon monoxide being the most discrepant of the\nthree species, almost an order of magnitude lower than had been thought. These\nresults have important implications across a variety of astrophysical and\nplanetary environments.",
            "author": [
                "W. M. Grundy",
                "S. C. Tegler",
                "J. K. Steckloff",
                "S. P. Tan",
                "M. J. Loeffler",
                "A. V. Jasko",
                "K. J. Koga",
                "B. P. Blakley",
                "S. M. Raposa",
                "A. E. Engle",
                "C. L. Thieberger",
                "J. Hanley",
                "G. E. Lindberg",
                "M. D. Gomez",
                "A. O. Madden-Watson"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.icarus.2023.115767",
                "http://arxiv.org/abs/2309.05078v2",
                "http://arxiv.org/pdf/2309.05078v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05072v1",
            "title": "Spatiotemporal Graph Neural Networks with Uncertainty Quantification for\n  Traffic Incident Risk Prediction",
            "updated": "2023-09-10T16:35:47Z",
            "published": "2023-09-10T16:35:47Z",
            "summary": "Predicting traffic incident risks at granular spatiotemporal levels is\nchallenging. The datasets predominantly feature zero values, indicating no\nincidents, with sporadic high-risk values for severe incidents. Notably, a\nmajority of current models, especially deep learning methods, focus solely on\nestimating risk values, overlooking the uncertainties arising from the\ninherently unpredictable nature of incidents. To tackle this challenge, we\nintroduce the Spatiotemporal Zero-Inflated Tweedie Graph Neural Networks\n(STZITD-GNNs). Our model merges the reliability of traditional statistical\nmodels with the flexibility of graph neural networks, aiming to precisely\nquantify uncertainties associated with road-level traffic incident risks. This\nmodel strategically employs a compound model from the Tweedie family, as a\nPoisson distribution to model risk frequency and a Gamma distribution to\naccount for incident severity. Furthermore, a zero-inflated component helps to\nidentify the non-incident risk scenarios. As a result, the STZITD-GNNs\neffectively capture the dataset's skewed distribution, placing emphasis on\ninfrequent but impactful severe incidents. Empirical tests using real-world\ntraffic data from London, UK, demonstrate that our model excels beyond current\nbenchmarks. The forte of STZITD-GNN resides not only in its accuracy but also\nin its adeptness at curtailing uncertainties, delivering robust predictions\nover short (7 days) and extended (14 days) timeframes.",
            "author": [
                "Xiaowei Gao",
                "Xinke Jiang",
                "Dingyi Zhuang",
                "Huanfa Chen",
                "Shenhao Wang",
                "James Haworth"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05072v1",
                "http://arxiv.org/pdf/2309.05072v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05069v1",
            "title": "Exploiting CLIP for Zero-shot HOI Detection Requires Knowledge\n  Distillation at Multiple Levels",
            "updated": "2023-09-10T16:27:54Z",
            "published": "2023-09-10T16:27:54Z",
            "summary": "In this paper, we investigate the task of zero-shot human-object interaction\n(HOI) detection, a novel paradigm for identifying HOIs without the need for\ntask-specific annotations. To address this challenging task, we employ CLIP, a\nlarge-scale pre-trained vision-language model (VLM), for knowledge distillation\non multiple levels. Specifically, we design a multi-branch neural network that\nleverages CLIP for learning HOI representations at various levels, including\nglobal images, local union regions encompassing human-object pairs, and\nindividual instances of humans or objects. To train our model, CLIP is utilized\nto generate HOI scores for both global images and local union regions that\nserve as supervision signals. The extensive experiments demonstrate the\neffectiveness of our novel multi-level CLIP knowledge integration strategy.\nNotably, the model achieves strong performance, which is even comparable with\nsome fully-supervised and weakly-supervised methods on the public HICO-DET\nbenchmark.",
            "author": [
                "Bo Wan",
                "Tinne Tuytelaars"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05069v1",
                "http://arxiv.org/pdf/2309.05069v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05065v1",
            "title": "An introduction to the local-to-global behaviour of groups acting on\n  trees and the theory of local action diagrams",
            "updated": "2023-09-10T16:12:44Z",
            "published": "2023-09-10T16:12:44Z",
            "summary": "The primary tool for analysing groups acting on trees is Bass--Serre Theory.\nIt is comprised of two parts: a decomposition result, in which an action is\ndecomposed via a graph of groups, and a construction result, in which graphs of\ngroups are used to build examples of groups acting on trees. The usefulness of\nthe latter for constructing new examples of `large' (e.g. nondiscrete) groups\nacting on trees is severely limited. There is a pressing need for new examples\nof such groups as they play an important role in the theory of locally compact\ngroups. An alternative `local-to-global' approach to the study of groups acting\non trees has recently emerged, inspired by a paper of Marc Burger and Shahar\nMozes, based on groups that are `universal' with respect to some specified\n`local' action. In recent work, the authors of this survey article have\ndeveloped a general theory of universal groups of local actions, that behaves,\nin many respects, like Bass--Serre Theory. We call this the theory of local\naction diagrams. The theory is powerful enough to completely describe all\nclosed groups of automorphisms of trees that enjoy Tits' Independence Property\n(P).\n  This article is an introductory survey of the local-to-global behaviour of\ngroups acting on trees and the theory of local action diagrams. The article\ncontains many ideas for future research projects.",
            "author": [
                "Colin D. Reid",
                "Simon M. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05065v1",
                "http://arxiv.org/pdf/2309.05065v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "20E08"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05058v1",
            "title": "Multimodal Fish Feeding Intensity Assessment in Aquaculture",
            "updated": "2023-09-10T15:52:56Z",
            "published": "2023-09-10T15:52:56Z",
            "summary": "Fish feeding intensity assessment (FFIA) aims to evaluate the intensity\nchange of fish appetite during the feeding process, which is vital in\nindustrial aquaculture applications. The main challenges surrounding FFIA are\ntwo-fold. 1) robustness: existing work has mainly leveraged single-modality\n(e.g., vision, audio) methods, which have a high sensitivity to input noise. 2)\nefficiency: FFIA models are generally expected to be employed on devices. This\npresents a challenge in terms of computational efficiency. In this work, we\nfirst introduce an audio-visual dataset, called AV-FFIA. AV-FFIA consists of\n27,000 labeled audio and video clips that capture different levels of fish\nfeeding intensity. To our knowledge, AV-FFIA is the first large-scale\nmultimodal dataset for FFIA research. Then, we introduce a multi-modal approach\nfor FFIA by leveraging single-modality pre-trained models and modality-fusion\nmethods, with benchmark studies on AV-FFIA. Our experimental results indicate\nthat the multi-modal approach substantially outperforms the single-modality\nbased approach, especially in noisy environments. While multimodal approaches\nprovide a performance gain for FFIA, it inherently increase the computational\ncost. To overcome this issue, we further present a novel unified model, termed\nas U-FFIA. U-FFIA is a single model capable of processing audio, visual, or\naudio-visual modalities, by leveraging modality dropout during training and\nknowledge distillation from single-modality pre-trained models. We demonstrate\nthat U-FFIA can achieve performance better than or on par with the\nstate-of-the-art modality-specific FFIA models, with significantly lower\ncomputational overhead. Our proposed U-FFIA approach enables a more robust and\nefficient method for FFIA, with the potential to contribute to improved\nmanagement practices and sustainability in aquaculture.",
            "author": [
                "Meng Cui",
                "Xubo Liu",
                "Haohe Liu",
                "Zhuangzhuang Du",
                "Tao Chen",
                "Guoping Lian",
                "Daoliang Li",
                "Wenwu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05058v1",
                "http://arxiv.org/pdf/2309.05058v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05056v2",
            "title": "Cohen-Macaulay edge-weighted graphs of girth $5$ or greater",
            "updated": "2023-09-24T10:25:35Z",
            "published": "2023-09-10T15:38:41Z",
            "summary": "Let $G_\\omega$ be an edge-weighted graph whose underlying graph is $G$. In\nthis paper, we enlarge the class of Cohen-Macaulay edge-weighted graphs\n$G_\\omega$ by classifying completely them when the graph $G$ has girth $5$ or\ngreater.",
            "author": [
                "Truong Thi Hien"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05056v2",
                "http://arxiv.org/pdf/2309.05056v2"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.13060v1",
            "title": "Implementing Learning Principles with a Personal AI Tutor: A Case Study",
            "updated": "2023-09-10T15:35:47Z",
            "published": "2023-09-10T15:35:47Z",
            "summary": "Effective learning strategies based on principles like personalization,\nretrieval practice, and spaced repetition are often challenging to implement\ndue to practical constraints. Here we explore the integration of AI tutors to\ncomplement learning programs in accordance with learning sciences. A\nsemester-long study was conducted at UniDistance Suisse, where an AI tutor app\nwas provided to psychology students taking a neuroscience course (N=51). After\nautomatically generating microlearning questions from existing course materials\nusing GPT-3, the AI tutor developed a dynamic neural-network model of each\nstudent's grasp of key concepts. This enabled the implementation of distributed\nretrieval practice, personalized to each student's individual level and\nabilities. The results indicate that students who actively engaged with the AI\ntutor achieved significantly higher grades. Moreover, active engagement led to\nan average improvement of up to 15 percentile points compared to a parallel\ncourse without AI tutor. Additionally, the grasp strongly correlated with the\nexam grade, thus validating the relevance of neural-network predictions. This\nresearch demonstrates the ability of personal AI tutors to model human learning\nprocesses and effectively enhance academic performance. By integrating AI\ntutors into their programs, educators can offer students personalized learning\nexperiences grounded in the principles of learning sciences, thereby addressing\nthe challenges associated with implementing effective learning strategies.\nThese findings contribute to the growing body of knowledge on the\ntransformative potential of AI in education.",
            "author": [
                "Ambroise Baillifard",
                "Maxime Gabella",
                "Pamela Banta Lavenex",
                "Corinna S. Martarelli"
            ],
            "link": [
                "http://arxiv.org/abs/2309.13060v1",
                "http://arxiv.org/pdf/2309.13060v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05036v1",
            "title": "What Is Near?: Room Locality Learning for Enhanced Robot\n  Vision-Language-Navigation in Indoor Living Environments",
            "updated": "2023-09-10T14:15:01Z",
            "published": "2023-09-10T14:15:01Z",
            "summary": "Humans use their knowledge of common house layouts obtained from previous\nexperiences to predict nearby rooms while navigating in new environments. This\ngreatly helps them navigate previously unseen environments and locate their\ntarget room. To provide layout prior knowledge to navigational agents based on\ncommon human living spaces, we propose WIN (\\textit{W}hat \\textit{I}s\n\\textit{N}ear), a commonsense learning model for Vision Language Navigation\n(VLN) tasks. VLN requires an agent to traverse indoor environments based on\ndescriptive navigational instructions. Unlike existing layout learning works,\nWIN predicts the local neighborhood map based on prior knowledge of living\nspaces and current observation, operating on an imagined global map of the\nentire environment. The model infers neighborhood regions based on visual cues\nof current observations, navigational history, and layout common sense. We show\nthat local-global planning based on locality knowledge and predicting the\nindoor layout allows the agent to efficiently select the appropriate action.\nSpecifically, we devised a cross-modal transformer that utilizes this locality\nprior for decision-making in addition to visual inputs and instructions.\nExperimental results show that locality learning using WIN provides better\ngeneralizability compared to classical VLN agents in unseen environments. Our\nmodel performs favorably on standard VLN metrics, with Success Rate 68\\% and\nSuccess weighted by Path Length 63\\% in unseen environments.",
            "author": [
                "Muraleekrishna Gopinathan",
                "Jumana Abu-Khalaf",
                "David Suter",
                "Sidike Paheding",
                "Nathir A. Rawashdeh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05036v1",
                "http://arxiv.org/pdf/2309.05036v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "I.5.4; I.4.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05035v2",
            "title": "Duplicate Question Retrieval and Confirmation Time Prediction in\n  Software Communities",
            "updated": "2023-10-25T20:23:38Z",
            "published": "2023-09-10T14:13:54Z",
            "summary": "Community Question Answering (CQA) in different domains is growing at a large\nscale because of the availability of several platforms and huge shareable\ninformation among users. With the rapid growth of such online platforms, a\nmassive amount of archived data makes it difficult for moderators to retrieve\npossible duplicates for a new question and identify and confirm existing\nquestion pairs as duplicates at the right time. This problem is even more\ncritical in CQAs corresponding to large software systems like askubuntu where\nmoderators need to be experts to comprehend something as a duplicate. Note that\nthe prime challenge in such CQA platforms is that the moderators are themselves\nexperts and are therefore usually extremely busy with their time being\nextraordinarily expensive. To facilitate the task of the moderators, in this\nwork, we have tackled two significant issues for the askubuntu CQA platform:\n(1) retrieval of duplicate questions given a new question and (2) duplicate\nquestion confirmation time prediction. In the first task, we focus on\nretrieving duplicate questions from a question pool for a particular newly\nposted question. In the second task, we solve a regression problem to rank a\npair of questions that could potentially take a long time to get confirmed as\nduplicates. For duplicate question retrieval, we propose a Siamese neural\nnetwork based approach by exploiting both text and network-based features,\nwhich outperforms several state-of-the-art baseline techniques. Our method\noutperforms DupPredictor and DUPE by 5% and 7% respectively. For duplicate\nconfirmation time prediction, we have used both the standard machine learning\nmodels and neural network along with the text and graph-based features. We\nobtain Spearman's rank correlation of 0.20 and 0.213 (statistically\nsignificant) for text and graph based features respectively.",
            "author": [
                "Rima Hazra",
                "Debanjan Saha",
                "Amruit Sahoo",
                "Somnath Banerjee",
                "Animesh Mukherjee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05035v2",
                "http://arxiv.org/pdf/2309.05035v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.SE",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05033v1",
            "title": "Evolving landscape of US-China science collaboration: Convergence and\n  divergence",
            "updated": "2023-09-10T14:11:46Z",
            "published": "2023-09-10T14:11:46Z",
            "summary": "International research collaboration among global scientific powerhouses has\nexhibited a discernible trend towards convergence in recent decades. Notably,\nthe US and China have significantly fortified their collaboration across\ndiverse scientific disciplines, solidifying their status as a national-level\nduopoly in global scientific knowledge production. However, recent reports hint\nat a potential decline in collaboration between these two giants, even amidst\nthe backdrop of advancing global convergence. Understanding the intricate\ninterplay between cooperation and disparity within the US-China relationship is\nvital for both academia and policy leaders, as it provides invaluable insights\ninto the potential future trajectory of global science collaboration. Despite\nits significance, there remains a noticeable dearth of quantitative evidence\nthat adequately encapsulates the dynamism across disciplines and over time. To\nbridge this knowledge gap, this study delves into the evolving landscape of\ninteraction between the US and China over recent decades. This investigation\nemploys two approaches, one based on paper identifiers and the other on\nresearcher identifiers, both obtained from bibliometric data sourced from\nOpenAlex. From both approaches, our findings unveil the unique and dynamic\nnature of the US-China relationship, characterised by a collaboration pattern\ninitially marked by rapid convergence, followed by a recent phase of\ndivergence.",
            "author": [
                "Kensei Kitajima",
                "Keisuke Okamura"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05033v1",
                "http://arxiv.org/pdf/2309.05033v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.CY",
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07909v1",
            "title": "Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data\n  Augmentation From Scratch",
            "updated": "2023-09-10T13:28:46Z",
            "published": "2023-09-10T13:28:46Z",
            "summary": "Unsupervised contrastive learning methods have recently seen significant\nimprovements, particularly through data augmentation strategies that aim to\nproduce robust and generalizable representations. However, prevailing data\naugmentation methods, whether hand designed or based on foundation models, tend\nto rely heavily on prior knowledge or external data. This dependence often\ncompromises their effectiveness and efficiency. Furthermore, the applicability\nof most existing data augmentation strategies is limited when transitioning to\nother research domains, especially science-related data. This limitation stems\nfrom the paucity of prior knowledge and labeled data available in these\ndomains. To address these challenges, we introduce DiffAug-a novel and\nefficient Diffusion-based data Augmentation technique. DiffAug aims to ensure\nthat the augmented and original data share a smoothed latent space, which is\nachieved through diffusion steps. Uniquely, unlike traditional methods, DiffAug\nfirst mines sufficient prior semantic knowledge about the neighborhood. This\nprovides a constraint to guide the diffusion steps, eliminating the need for\nlabels, external data/models, or prior knowledge. Designed as an\narchitecture-agnostic framework, DiffAug provides consistent improvements.\nSpecifically, it improves image classification and clustering accuracy by\n1.6%~4.5%. When applied to biological data, DiffAug improves performance by up\nto 10.1%, with an average improvement of 5.8%. DiffAug shows good performance\nin both vision and biological domains.",
            "author": [
                "Zelin Zang",
                "Hao Luo",
                "Kai Wang",
                "Panpan Zhang",
                "Fan Wang",
                "Stan. Z Li",
                "Yang You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07909v1",
                "http://arxiv.org/pdf/2309.07909v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05015v1",
            "title": "DeViT: Decomposing Vision Transformers for Collaborative Inference in\n  Edge Devices",
            "updated": "2023-09-10T12:26:17Z",
            "published": "2023-09-10T12:26:17Z",
            "summary": "Recent years have witnessed the great success of vision transformer (ViT),\nwhich has achieved state-of-the-art performance on multiple computer vision\nbenchmarks. However, ViT models suffer from vast amounts of parameters and high\ncomputation cost, leading to difficult deployment on resource-constrained edge\ndevices. Existing solutions mostly compress ViT models to a compact model but\nstill cannot achieve real-time inference. To tackle this issue, we propose to\nexplore the divisibility of transformer structure, and decompose the large ViT\ninto multiple small models for collaborative inference at edge devices. Our\nobjective is to achieve fast and energy-efficient collaborative inference while\nmaintaining comparable accuracy compared with large ViTs. To this end, we first\npropose a collaborative inference framework termed DeViT to facilitate edge\ndeployment by decomposing large ViTs. Subsequently, we design a\ndecomposition-and-ensemble algorithm based on knowledge distillation, termed\nDEKD, to fuse multiple small decomposed models while dramatically reducing\ncommunication overheads, and handle heterogeneous models by developing a\nfeature matching module to promote the imitations of decomposed models from the\nlarge ViT. Extensive experiments for three representative ViT backbones on four\nwidely-used datasets demonstrate our method achieves efficient collaborative\ninference for ViTs and outperforms existing lightweight ViTs, striking a good\ntrade-off between efficiency and accuracy. For example, our DeViTs improves\nend-to-end latency by 2.89$\\times$ with only 1.65% accuracy sacrifice using\nCIFAR-100 compared to the large ViT, ViT-L/16, on the GPU server. DeDeiTs\nsurpasses the recent efficient ViT, MobileViT-S, by 3.54% in accuracy on\nImageNet-1K, while running 1.72$\\times$ faster and requiring 55.28% lower\nenergy consumption on the edge device.",
            "author": [
                "Guanyu Xu",
                "Zhiwei Hao",
                "Yong Luo",
                "Han Hu",
                "Jianping An",
                "Shiwen Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05015v1",
                "http://arxiv.org/pdf/2309.05015v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05006v1",
            "title": "Uniform algebras and distinguished varieties",
            "updated": "2023-09-10T11:41:32Z",
            "published": "2023-09-10T11:41:32Z",
            "summary": "In this article, we point out the connections between the distinguished\nvarieties introduced by Agler and McCarthy with certain uniform algebras on\nbidisc studied by Samuelsson and Wold. We also prove analogues of\nSamuelsson-Wold result for the domains in $\\mathbb{C}^2$ that are the images of\nthe bidisc under certain proper polynomial map on $\\mathbb{C}^2$. We also give\na description of polynomial convex hull of graph of anti-holomorphic polynomial\nover the distinguished boundary of such domains. We mention the case for the\nsymmetrized bidisc as an example.",
            "author": [
                "Sushil Gorai",
                "Golam Mostafa Mondal"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05006v1",
                "http://arxiv.org/pdf/2309.05006v1"
            ],
            "primary_category": "math.CV",
            "category": [
                "math.CV",
                "32E30, 32E20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04995v1",
            "title": "How to assign volunteers to tasks compatibly ? A graph theoretic and\n  parameterized approach",
            "updated": "2023-09-10T11:02:16Z",
            "published": "2023-09-10T11:02:16Z",
            "summary": "In this paper we study a resource allocation problem that encodes correlation\nbetween items in terms of \\conflict and maximizes the minimum utility of the\nagents under a conflict free allocation. Admittedly, the problem is\ncomputationally hard even under stringent restrictions because it encodes a\nvariant of the {\\sc Maximum Weight Independent Set} problem which is one of the\ncanonical hard problems in both classical and parameterized complexity.\nRecently, this subject was explored by Chiarelli et al.~[Algorithmica'22] from\nthe classical complexity perspective to draw the boundary between {\\sf\nNP}-hardness and tractability for a constant number of agents. The problem was\nshown to be hard even for small constant number of agents and various other\nrestrictions on the underlying graph. Notwithstanding this computational\nbarrier, we notice that there are several parameters that are worth studying:\nnumber of agents, number of items, combinatorial structure that defines the\nconflict among the items, all of which could well be small under specific\ncircumstancs. Our search rules out several parameters (even when taken\ntogether) and takes us towards a characterization of families of input\ninstances that are amenable to polynomial time algorithms when the parameters\nare constant. In addition to this we give a superior $2^{m}|I|^{\\Co{O}(1)}$\nalgorithm for our problem where $m$ denotes the number of items that\nsignificantly beats the exhaustive $\\Oh(m^{m})$ algorithm by cleverly using\nideas from FFT based fast polynomial multiplication; and we identify simple\ngraph classes relevant to our problem's motivation that admit efficient\nalgorithms.",
            "author": [
                "Sushmita Gupta",
                "Pallavi Jain",
                "Saket Saurabh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04995v1",
                "http://arxiv.org/pdf/2309.04995v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04979v1",
            "title": "Retrieval-Augmented Meta Learning for Low-Resource Text Classification",
            "updated": "2023-09-10T10:05:03Z",
            "published": "2023-09-10T10:05:03Z",
            "summary": "Meta learning have achieved promising performance in low-resource text\nclassification which aims to identify target classes with knowledge transferred\nfrom source classes with sets of small tasks named episodes. However, due to\nthe limited training data in the meta-learning scenario and the inherent\nproperties of parameterized neural networks, poor generalization performance\nhas become a pressing problem that needs to be addressed. To deal with this\nissue, we propose a meta-learning based method called Retrieval-Augmented Meta\nLearning(RAML). It not only uses parameterization for inference but also\nretrieves non-parametric knowledge from an external corpus to make inferences,\nwhich greatly alleviates the problem of poor generalization performance caused\nby the lack of diverse training data in meta-learning. This method differs from\nprevious models that solely rely on parameters, as it explicitly emphasizes the\nimportance of non-parametric knowledge, aiming to strike a balance between\nparameterized neural networks and non-parametric knowledge. The model is\nrequired to determine which knowledge to access and utilize during inference.\nAdditionally, our multi-view passages fusion network module can effectively and\nefficiently integrate the retrieved information into low-resource\nclassification task. The extensive experiments demonstrate that RAML\nsignificantly outperforms current SOTA low-resource text classification models.",
            "author": [
                "Rongsheng Li",
                "Yangning Li",
                "Yinghui Li",
                "Chaiyut Luoyiching",
                "Hai-Tao Zheng",
                "Nannan Zhou",
                "Hanjing Su"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04979v1",
                "http://arxiv.org/pdf/2309.04979v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04977v1",
            "title": "RGAT: A Deeper Look into Syntactic Dependency Information for\n  Coreference Resolution",
            "updated": "2023-09-10T09:46:38Z",
            "published": "2023-09-10T09:46:38Z",
            "summary": "Although syntactic information is beneficial for many NLP tasks, combining it\nwith contextual information between words to solve the coreference resolution\nproblem needs to be further explored. In this paper, we propose an end-to-end\nparser that combines pre-trained BERT with a Syntactic Relation Graph Attention\nNetwork (RGAT) to take a deeper look into the role of syntactic dependency\ninformation for the coreference resolution task. In particular, the RGAT model\nis first proposed, then used to understand the syntactic dependency graph and\nlearn better task-specific syntactic embeddings. An integrated architecture\nincorporating BERT embeddings and syntactic embeddings is constructed to\ngenerate blending representations for the downstream task. Our experiments on a\npublic Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision\nlearning of the syntactic dependency graph and without fine-tuning the entire\nBERT, we increased the F1-score of the previous best model (RGCN-with-BERT)\nfrom 80.3% to 82.5%, compared to the F1-score by single BERT embeddings from\n78.5% to 82.5%. Experimental results on another public dataset - OntoNotes 5.0\ndemonstrate that the performance of the model is also improved by incorporating\nsyntactic dependency information learned from RGAT.",
            "author": [
                "Yuan Meng",
                "Xuhao Pan",
                "Jun Chang",
                "Yue Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN54540.2023.10191577",
                "http://arxiv.org/abs/2309.04977v1",
                "http://arxiv.org/pdf/2309.04977v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "14J60 (Primary) 14F05, 14J26 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04971v1",
            "title": "Prompt Learning With Knowledge Memorizing Prototypes For Generalized\n  Few-Shot Intent Detection",
            "updated": "2023-09-10T09:16:38Z",
            "published": "2023-09-10T09:16:38Z",
            "summary": "Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic\nbecause it needs to categorize both seen and novel intents simultaneously.\nPrevious GFSID methods rely on the episodic learning paradigm, which makes it\nhard to extend to a generalized setup as they do not explicitly learn the\nclassification of seen categories and the knowledge of seen intents. To address\nthe dilemma, we propose to convert the GFSID task into the class incremental\nlearning paradigm. Specifically, we propose a two-stage learning framework,\nwhich sequentially learns the knowledge of different intents in various periods\nvia prompt learning. And then we exploit prototypes for categorizing both seen\nand novel intents. Furthermore, to achieve the transfer knowledge of intents in\ndifferent stages, for different scenarios we design two knowledge preservation\nmethods which close to realistic applications. Extensive experiments and\ndetailed analyses on two widely used datasets show that our framework based on\nthe class incremental learning paradigm achieves promising performance.",
            "author": [
                "Chaiyut Luoyiching",
                "Yangning Li",
                "Yinghui Li",
                "Rongsheng Li",
                "Hai-Tao Zheng",
                "Nannan Zhou",
                "Hanjing Su"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04971v1",
                "http://arxiv.org/pdf/2309.04971v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04963v1",
            "title": "Packings in bipartite prisms and hypercubes",
            "updated": "2023-09-10T08:40:38Z",
            "published": "2023-09-10T08:40:38Z",
            "summary": "The $2$-packing number $\\rho_2(G)$ of a graph $G$ is the cardinality of a\nlargest $2$-packing of $G$ and the open packing number $\\rho^{\\rm o}(G)$ is the\ncardinality of a largest open packing of $G$, where an open packing (resp.\n$2$-packing) is a set of vertices in $G$ no two (closed) neighborhoods of which\nintersect. It is proved that if $G$ is bipartite, then $\\rho^{\\rm o}(G\\Box K_2)\n= 2\\rho_2(G)$. For hypercubes, the lower bounds $\\rho_2(Q_n) \\ge 2^{n - \\lfloor\n\\log n\\rfloor -1}$ and $\\rho^{\\rm o}(Q_n) \\ge 2^{n - \\lfloor \\log (n-1)\\rfloor\n-1}$ are established. These findings are applied to injective colorings of\nhypercubes. In particular, it is demonstrated that $Q_9$ is the smallest\nhypercube which is not perfect injectively colorable. It is also proved that\n$\\gamma_t(Q_{2^k}\\times H) = 2^{2^k-k}\\gamma_t(H)$, where $H$ is an arbitrary\ngraph with no isolated vertices.",
            "author": [
                "Bo\u0161tjan Bre\u0161ar",
                "Sandi Klav\u017ear",
                "Douglas F. Rall"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04963v1",
                "http://arxiv.org/pdf/2309.04963v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C69, 05C76"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04954v1",
            "title": "A Penny a Function: Towards Cost Transparent Cloud Programming",
            "updated": "2023-09-10T08:02:12Z",
            "published": "2023-09-10T08:02:12Z",
            "summary": "Understanding and managing monetary cost factors is crucial when developing\ncloud applications. However, the diverse range of factors influencing costs for\ncomputation, storage, and networking in cloud applications poses a challenge\nfor developers who want to manage and minimize costs proactively. Existing\ntools for understanding cost factors are often detached from source code,\ncausing opaqueness regarding the origin of costs. Moreover, existing cost\nmodels for cloud applications focus on specific factors such as compute\nresources and necessitate manual effort to create the models. This paper\npresents initial work toward a cost model based on a directed graph that allows\nderiving monetary cost estimations directly from code using static analysis.\nLeveraging the cost model, we explore visualizations embedded in a code editor\nthat display costs close to the code causing them. This makes cost exploration\nan integrated part of the developer experience, thereby removing the overhead\nof external tooling for cost estimation of cloud applications at development\ntime.",
            "author": [
                "Lukas B\u00f6hme",
                "Tom Beckmann",
                "Sebastian Baltes",
                "Robert Hirschfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04954v1",
                "http://arxiv.org/pdf/2309.04954v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04949v1",
            "title": "A multiple k-means cluster ensemble framework for clustering citation\n  trajectories",
            "updated": "2023-09-10T07:10:31Z",
            "published": "2023-09-10T07:10:31Z",
            "summary": "Citation maturity time varies for different articles. However, the impact of\nall articles is measured in a fixed window. Clustering their citation\ntrajectories helps understand the knowledge diffusion process and reveals that\nnot all articles gain immediate success after publication. Moreover, clustering\ntrajectories is necessary for paper impact recommendation algorithms. It is a\nchallenging problem because citation time series exhibit significant\nvariability due to non linear and non stationary characteristics. Prior works\npropose a set of arbitrary thresholds and a fixed rule based approach. All\nmethods are primarily parameter dependent. Consequently, it leads to\ninconsistencies while defining similar trajectories and ambiguities regarding\ntheir specific number. Most studies only capture extreme trajectories. Thus, a\ngeneralised clustering framework is required. This paper proposes a feature\nbased multiple k means cluster ensemble framework. 1,95,783 and 41,732 well\ncited articles from the Microsoft Academic Graph data are considered for\nclustering short term (10 year) and long term (30 year) trajectories,\nrespectively. It has linear run time. Four distinct trajectories are obtained\nEarly Rise Rapid Decline (2.2%), Early Rise Slow Decline (45%), Delayed Rise No\nDecline (53%), and Delayed Rise Slow Decline (0.8%). Individual trajectory\ndifferences for two different spans are studied. Most papers exhibit Early Rise\nSlow Decline and Delayed Rise No Decline patterns. The growth and decay times,\ncumulative citation distribution, and peak characteristics of individual\ntrajectories are redefined empirically. A detailed comparative study reveals\nour proposed methodology can detect all distinct trajectory classes.",
            "author": [
                "Joyita Chakraborty",
                "Dinesh K. Pradhan",
                "Subrata Nandi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04949v1",
                "http://arxiv.org/pdf/2309.04949v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.DB",
                "cs.DL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04941v2",
            "title": "Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle\n  Counting Power",
            "updated": "2023-10-26T18:43:19Z",
            "published": "2023-09-10T06:13:29Z",
            "summary": "The ability of graph neural networks (GNNs) to count certain graph\nsubstructures, especially cycles, is important for the success of GNNs on a\nwide range of tasks. It has been recently used as a popular metric for\nevaluating the expressive power of GNNs. Many of the proposed GNN models with\nprovable cycle counting power are based on subgraph GNNs, i.e., extracting a\nbag of subgraphs from the input graph, generating representations for each\nsubgraph, and using them to augment the representation of the input graph.\nHowever, those methods require heavy preprocessing, and suffer from high time\nand memory costs. In this paper, we overcome the aforementioned limitations of\nsubgraph GNNs by proposing a novel class of GNNs -- $d$-Distance-Restricted\nFWL(2) GNNs, or $d$-DRFWL(2) GNNs. $d$-DRFWL(2) GNNs use node pairs whose\nmutual distances are at most $d$ as the units for message passing to balance\nthe expressive power and complexity. By performing message passing among\ndistance-restricted node pairs in the original graph, $d$-DRFWL(2) GNNs avoid\nthe expensive subgraph extraction operations in subgraph GNNs, making both the\ntime and space complexity lower. We theoretically show that the discriminative\npower of $d$-DRFWL(2) GNNs strictly increases as $d$ increases. More\nimportantly, $d$-DRFWL(2) GNNs have provably strong cycle counting power even\nwith $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene\nrings) are ubiquitous in organic molecules, being able to detect and count them\nis crucial for achieving robust and generalizable performance on molecular\ntasks. Experiments on both synthetic datasets and molecular datasets verify our\ntheory. To the best of our knowledge, our model is the most efficient GNN model\nto date (both theoretically and empirically) that can count up to 6-cycles.",
            "author": [
                "Junru Zhou",
                "Jiarui Feng",
                "Xiyuan Wang",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04941v2",
                "http://arxiv.org/pdf/2309.04941v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04938v1",
            "title": "On The 2-Spanning Cyclability Of Honeycomb Toroidal Graphs",
            "updated": "2023-09-10T06:06:05Z",
            "published": "2023-09-10T06:06:05Z",
            "summary": "A graph $X$ is 2-spanning cyclable if for any pair of distinct vertices $u$\nand $v$ there is a 2-factor of $X$ consisting of two cycles such that $u$ and\n$v$ belong to distinct cycles. In this paper we examine the 2-spanning\ncyclability of honeycomb toroidal graphs.",
            "author": [
                "Brian Alspach",
                "Aditya Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04938v1",
                "http://arxiv.org/pdf/2309.04938v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02159v1",
            "title": "Spectral Temporal Graph Neural Network for massive MIMO CSI Prediction",
            "updated": "2023-09-10T04:13:43Z",
            "published": "2023-09-10T04:13:43Z",
            "summary": "In the realm of 5G communication systems, the accuracy of Channel State\nInformation (CSI) prediction is vital for optimizing performance. This letter\nintroduces a pioneering approach: the Spectral-Temporal Graph Neural Network\n(STEM GNN), which fuses spatial relationships and temporal dynamics of the\nwireless channel using the Graph Fourier Transform. We compare the STEM GNN\napproach with conventional Recurrent Neural Network (RNN) and Long Short-Term\nMemory (LSTM) models for CSI prediction. Our findings reveal a significant\nenhancement in overall communication system performance through STEM GNNs. For\ninstance, in one scenario, STEM GNN achieves a sum rate of 5.009 bps/Hz which\nis $11.9\\%$ higher than that of LSTM and $35\\%$ higher than that of RNN. The\nspectral-temporal analysis capabilities of STEM GNNs capture intricate patterns\noften overlooked by traditional models, offering improvements in beamforming,\ninterference mitigation, and ultra-reliable low-latency communication (URLLC).",
            "author": [
                "Sharan Mourya",
                "Pavan Reddy",
                "SaiDhiraj Amuru",
                "Kiran Kumar Kuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02159v1",
                "http://arxiv.org/pdf/2312.02159v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04922v1",
            "title": "Quantification of Distributionally Robust Risk of Cascade of Failures in\n  Platoon of Vehicles",
            "updated": "2023-09-10T03:01:10Z",
            "published": "2023-09-10T03:01:10Z",
            "summary": "Achieving safety is a critical aspect of attaining autonomy in a platoon of\nautonomous vehicles. In this paper, we propose a distributionally robust risk\nframework to investigate cascading failures in platoons. To examine the impact\nof network connectivity and system dynamics on the emergence of cascading\nfailures, we consider a time-delayed network model of the platoon of vehicles\nas a benchmark. To study the cascading effects among pairs of vehicles in the\nplatoon, we use the measure of conditional distributionally robust functional.\nWe extend the risk framework to quantify cascading failures by utilizing a\nbi-variate normal distribution. Our work establishes closed-form risk formulas\nthat illustrate the effects of time-delay, noise statistics, underlying\ncommunication graph, and sets of soft failures. The insights gained from our\nresearch can be applied to design safe platoons that are robust to the risk of\ncascading failures. We validate our results through extensive simulations.",
            "author": [
                "Vivek Pandey",
                "Guangyi Liu",
                "Arash Amini",
                "Nader Motee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04922v1",
                "http://arxiv.org/pdf/2309.04922v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05681v1",
            "title": "Knowledge-based Refinement of Scientific Publication Knowledge Graphs",
            "updated": "2023-09-10T02:06:49Z",
            "published": "2023-09-10T02:06:49Z",
            "summary": "We consider the problem of identifying authorship by posing it as a knowledge\ngraph construction and refinement. To this effect, we model this problem as\nlearning a probabilistic logic model in the presence of human guidance\n(knowledge-based learning). Specifically, we learn relational regression trees\nusing functional gradient boosting that outputs explainable rules. To\nincorporate human knowledge, advice in the form of first-order clauses is\ninjected to refine the trees. We demonstrate the usefulness of human knowledge\nboth quantitatively and qualitatively in seven authorship domains.",
            "author": [
                "Siwen Yan",
                "Phillip Odom",
                "Sriraam Natarajan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05681v1",
                "http://arxiv.org/pdf/2309.05681v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04914v2",
            "title": "MFPNet: Multi-scale Feature Propagation Network For Lightweight Semantic\n  Segmentation",
            "updated": "2023-09-12T05:08:47Z",
            "published": "2023-09-10T02:02:29Z",
            "summary": "In contrast to the abundant research focusing on large-scale models, the\nprogress in lightweight semantic segmentation appears to be advancing at a\ncomparatively slower pace. However, existing compact methods often suffer from\nlimited feature representation capability due to the shallowness of their\nnetworks. In this paper, we propose a novel lightweight segmentation\narchitecture, called Multi-scale Feature Propagation Network (MFPNet), to\naddress the dilemma. Specifically, we design a robust Encoder-Decoder structure\nfeaturing symmetrical residual blocks that consist of flexible bottleneck\nresidual modules (BRMs) to explore deep and rich muti-scale semantic context.\nFurthermore, taking benefit from their capacity to model latent long-range\ncontextual relationships, we leverage Graph Convolutional Networks (GCNs) to\nfacilitate multi-scale feature propagation between the BRM blocks. When\nevaluated on benchmark datasets, our proposed approach shows superior\nsegmentation results.",
            "author": [
                "Guoan Xu",
                "Wenjing Jia",
                "Tao Wu",
                "Ligeng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04914v2",
                "http://arxiv.org/pdf/2309.04914v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04892v1",
            "title": "Descriptive complexity of controllable graphs",
            "updated": "2023-09-09T23:04:00Z",
            "published": "2023-09-09T23:04:00Z",
            "summary": "Let $G$ be a graph on $n$ vertices with adjacency matrix $A$, and let\n$\\mathbf{1}$ be the all-ones vector. We call $G$ controllable if the set of\nvectors $\\mathbf{1}, A\\mathbf{1}, \\dots, A^{n-1}\\mathbf{1}$ spans the whole\nspace $\\mathbb{R}^n$. We characterize the isomorphism problem of controllable\ngraphs in terms of other combinatorial, geometric and logical problems. We also\ndescribe a polynomial time algorithm for graph isomorphism that works for\nalmost all graphs.",
            "author": [
                "Aida Abiad",
                "Anuj Dawar",
                "Octavio Zapata"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04892v1",
                "http://arxiv.org/pdf/2309.04892v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04889v1",
            "title": "A subspace constrained randomized Kaczmarz method for structure or\n  external knowledge exploitation",
            "updated": "2023-09-09T22:56:52Z",
            "published": "2023-09-09T22:56:52Z",
            "summary": "We study a subspace constrained version of the randomized Kaczmarz algorithm\nfor solving large linear systems in which the iterates are confined to the\nspace of solutions of a selected subsystem. We show that the subspace\nconstraint leads to an accelerated convergence rate, especially when the system\nhas structure such as having coherent rows or being approximately low-rank. On\nGaussian-like random data, it results in a form of dimension reduction that\neffectively improves the aspect ratio of the system. Furthermore, this method\nserves as a building block for a second, quantile-based algorithm for the\nproblem of solving linear systems with arbitrary sparse corruptions, which is\nable to efficiently exploit partial external knowledge about uncorrupted\nequations and achieve convergence in difficult settings such as in\nalmost-square systems. Numerical experiments on synthetic and real-world data\nsupport our theoretical results and demonstrate the validity of the proposed\nmethods for even more general data models than guaranteed by the theory.",
            "author": [
                "Jackie Lok",
                "Elizaveta Rebrova"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04889v1",
                "http://arxiv.org/pdf/2309.04889v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04885v3",
            "title": "Symplectic Structure-Aware Hamiltonian (Graph) Embeddings",
            "updated": "2023-12-01T10:31:32Z",
            "published": "2023-09-09T22:27:38Z",
            "summary": "In traditional Graph Neural Networks (GNNs), the assumption of a fixed\nembedding manifold often limits their adaptability to diverse graph geometries.\nRecently, Hamiltonian system-inspired GNNs have been proposed to address the\ndynamic nature of such embeddings by incorporating physical laws into node\nfeature updates. We present Symplectic Structure-Aware Hamiltonian GNN\n(SAH-GNN), a novel approach that generalizes Hamiltonian dynamics for more\nflexible node feature updates. Unlike existing Hamiltonian approaches, SAH-GNN\nemploys Riemannian optimization on the symplectic Stiefel manifold to\nadaptively learn the underlying symplectic structure, circumventing the\nlimitations of existing Hamiltonian GNNs that rely on a pre-defined form of\nstandard symplectic structure. This innovation allows SAH-GNN to automatically\nadapt to various graph datasets without extensive hyperparameter tuning.\nMoreover, it conserves energy during training meaning the implicit Hamiltonian\nsystem is physically meaningful. Finally, we empirically validate SAH-GNN's\nsuperiority and adaptability in node classification tasks across multiple types\nof graph datasets.",
            "author": [
                "Jiaxu Liu",
                "Xinping Yi",
                "Tianle Zhang",
                "Xiaowei Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04885v3",
                "http://arxiv.org/pdf/2309.04885v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.SG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04884v1",
            "title": "RecAD: Towards A Unified Library for Recommender Attack and Defense",
            "updated": "2023-09-09T22:23:05Z",
            "published": "2023-09-09T22:23:05Z",
            "summary": "In recent years, recommender systems have become a ubiquitous part of our\ndaily lives, while they suffer from a high risk of being attacked due to the\ngrowing commercial and social values. Despite significant research progress in\nrecommender attack and defense, there is a lack of a widely-recognized\nbenchmarking standard in the field, leading to unfair performance comparison\nand limited credibility of experiments. To address this, we propose RecAD, a\nunified library aiming at establishing an open benchmark for recommender attack\nand defense. RecAD takes an initial step to set up a unified benchmarking\npipeline for reproducible research by integrating diverse datasets, standard\nsource codes, hyper-parameter settings, running logs, attack knowledge, attack\nbudget, and evaluation results. The benchmark is designed to be comprehensive\nand sustainable, covering both attack, defense, and evaluation tasks, enabling\nmore researchers to easily follow and contribute to this promising field. RecAD\nwill drive more solid and reproducible research on recommender systems attack\nand defense, reduce the redundant efforts of researchers, and ultimately\nincrease the credibility and practical value of recommender attack and defense.\nThe project is released at https://github.com/gusye1234/recad.",
            "author": [
                "Changsheng Wang",
                "Jianbai Ye",
                "Wenjie Wang",
                "Chongming Gao",
                "Fuli Feng",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04884v1",
                "http://arxiv.org/pdf/2309.04884v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04882v1",
            "title": "Ambiguity, Invisibility, and Negativity",
            "updated": "2023-09-09T22:01:18Z",
            "published": "2023-09-09T22:01:18Z",
            "summary": "Many widely different problems have a common mathematical structure wherein\nlimited knowledge lead to ambiguity that can be captured conveniently using a\nconcept of invisibility that requires the introduction of negative values for\nquantities that are inherently positive. Here I analyze three examples taken\nfrom perception theory, rigid body mechanics, and quantum measurement.",
            "author": [
                "Frank Wilczek"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04882v1",
                "http://arxiv.org/pdf/2309.04882v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.class-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04879v1",
            "title": "A new class of multiple nonlocal problems with two parameters and\n  variable-order fractional $p(\\cdot)$-Laplacian",
            "updated": "2023-09-09T21:50:58Z",
            "published": "2023-09-09T21:50:58Z",
            "summary": "In the present manuscript, we focus on a novel tri-nonlocal Kirchhoff\nproblem, which involves the $p(x)$-fractional Laplacian equations of variable\norder. The problem is stated as follows: \\begin{eqnarray*} \\left\\{\n  \\begin{array}{ll}\n  M\\Big(\\sigma_{p(x,y)}(u)\\Big)(-\\Delta)^{s(\\cdot)}_{p(\\cdot)}u(x) =\\lambda\n|u|^{q(x)-2}u\\left(\\int_\\O\\frac{1}{q(x)} |u|^{q(x)}dx\n\\right)^{k_1}+\\beta|u|^{r(x)-2}u\\left(\\int_\\O\\frac{1}{r(x)} |u|^{r(x)}dx\n\\right)^{k_2}\n  \\quad \\mbox{in }\\Omega,\n  \\\\ u=0 \\quad \\mbox{on }\\partial\\Omega, \\end{array} \\right. \\end{eqnarray*}\nwhere the nonlocal term is defined as $$ \\sigma_{p(x,y)}(u)=\\int_{\\Omega\\times\n\\Omega}\\frac{1}{p(x,y)}\\frac{|u(x)-u(y)|^{p(x,y)}}{|x-y|^{N+s(x,y)p(x,y)}}\n\\,dx\\,dy. $$ Here, $\\Omega\\subset\\mathbb{R}^{N}$ represents a bounded smooth\ndomain with at least $N\\geq2$. The function $M(s)$ is given by $M(s) = a -\nbs^\\gamma$, where $a\\geq 0$, $b>0$, and $\\gamma>0$. The parameters $k_1$,\n$k_2$, $\\lambda$ and $\\beta$ are real parameters, while the variables $p(x)$,\n$s(\\cdot)$, $q(x)$, and $r(x)$ are continuous and can change with respect to\n$x$. To tackle this problem, we employ some new methods and variational\napproaches along with two specific methods, namely the Fountain theorem and the\nsymmetric Mountain Pass theorem. By utilizing these techniques, we establish\nthe existence and multiplicity of solutions for this problem separately in two\ndistinct cases: when $a>0$ and when $a=0$. To the best of our knowledge, these\nresults are the first contributions to research on the variable-order\n$p(x)$-fractional Laplacian operator.",
            "author": [
                "Mohamed Karim Hamdani",
                "Lamine Mbarki",
                "Mostafa Allaoui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04879v1",
                "http://arxiv.org/pdf/2309.04879v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35J60, 35J20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04868v1",
            "title": "MemSPICE: Automated Simulation and Energy Estimation Framework for\n  MAGIC-Based Logic-in-Memory",
            "updated": "2023-09-09T19:37:52Z",
            "published": "2023-09-09T19:37:52Z",
            "summary": "Existing logic-in-memory (LiM) research is limited to generating mappings and\nmicro-operations. In this paper, we present~\\emph{MemSPICE}, a novel framework\nthat addresses this gap by automatically generating both the netlist and\ntestbench needed to evaluate the LiM on a memristive crossbar. MemSPICE goes\nbeyond conventional approaches by providing energy estimation scripts to\ncalculate the precise energy consumption of the testbench at the SPICE level.\nWe propose an automated framework that utilizes the mapping obtained from the\nSIMPLER tool to perform accurate energy estimation through SPICE simulations.\nTo the best of our knowledge, no existing framework is capable of generating a\nSPICE netlist from a hardware description language. By offering a comprehensive\nsolution for SPICE-based netlist generation, testbench creation, and accurate\nenergy estimation, MemSPICE empowers researchers and engineers working on\nmemristor-based LiM to enhance their understanding and optimization of energy\nusage in these systems. Finally, we tested the circuits from the ISCAS'85\nbenchmark on MemSPICE and conducted a detailed energy analysis.",
            "author": [
                "Simranjeet Singh",
                "Chandan Kumar Jha",
                "Ankit Bende",
                "Vikas Rana",
                "Sachin Patkar",
                "Rolf Drechsler",
                "Farhad Merchant"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04868v1",
                "http://arxiv.org/pdf/2309.04868v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04862v1",
            "title": "Distributional Data Augmentation Methods for Low Resource Language",
            "updated": "2023-09-09T19:01:59Z",
            "published": "2023-09-09T19:01:59Z",
            "summary": "Text augmentation is a technique for constructing synthetic data from an\nunder-resourced corpus to improve predictive performance. Synthetic data\ngeneration is common in numerous domains. However, recently text augmentation\nhas emerged in natural language processing (NLP) to improve downstream tasks.\nOne of the current state-of-the-art text augmentation techniques is easy data\naugmentation (EDA), which augments the training data by injecting and replacing\nsynonyms and randomly permuting sentences. One major obstacle with EDA is the\nneed for versatile and complete synonym dictionaries, which cannot be easily\nfound in low-resource languages. To improve the utility of EDA, we propose two\nextensions, easy distributional data augmentation (EDDA) and type specific\nsimilar word replacement (TSSR), which uses semantic word context information\nand part-of-speech tags for word replacement and augmentation. In an extensive\nempirical evaluation, we show the utility of the proposed methods, measured by\nF1 score, on two representative datasets in Swedish as an example of a\nlow-resource language. With the proposed methods, we show that augmented data\nimprove classification performances in low-resource settings.",
            "author": [
                "Mosleh Mahamud",
                "Zed Lee",
                "Isak Samsten"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04862v1",
                "http://arxiv.org/pdf/2309.04862v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04849v1",
            "title": "Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect\n  Representations",
            "updated": "2023-09-09T17:30:35Z",
            "published": "2023-09-09T17:30:35Z",
            "summary": "We propose EmoDistill, a novel speech emotion recognition (SER) framework\nthat leverages cross-modal knowledge distillation during training to learn\nstrong linguistic and prosodic representations of emotion from speech. During\ninference, our method only uses a stream of speech signals to perform unimodal\nSER thus reducing computation overhead and avoiding run-time transcription and\nprosodic feature extraction errors. During training, our method distills\ninformation at both embedding and logit levels from a pair of pre-trained\nProsodic and Linguistic teachers that are fine-tuned for SER. Experiments on\nthe IEMOCAP benchmark demonstrate that our method outperforms other unimodal\nand multimodal techniques by a considerable margin, and achieves\nstate-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted\naccuracy. Detailed ablation studies demonstrate the impact of each component of\nour method.",
            "author": [
                "Debaditya Shome",
                "Ali Etemad"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04849v1",
                "http://arxiv.org/pdf/2309.04849v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04840v1",
            "title": "AnyPose: Anytime 3D Human Pose Forecasting via Neural Ordinary\n  Differential Equations",
            "updated": "2023-09-09T16:59:57Z",
            "published": "2023-09-09T16:59:57Z",
            "summary": "Anytime 3D human pose forecasting is crucial to synchronous real-world\nhuman-machine interaction, where the term ``anytime\" corresponds to predicting\nhuman pose at any real-valued time step. However, to the best of our knowledge,\nall the existing methods in human pose forecasting perform predictions at\npreset, discrete time intervals. Therefore, we introduce AnyPose, a lightweight\ncontinuous-time neural architecture that models human behavior dynamics with\nneural ordinary differential equations. We validate our framework on the\nHuman3.6M, AMASS, and 3DPW dataset and conduct a series of comprehensive\nanalyses towards comparison with existing methods and the intersection of human\npose and neural ordinary differential equations. Our results demonstrate that\nAnyPose exhibits high-performance accuracy in predicting future poses and takes\nsignificantly lower computational time than traditional methods in solving\nanytime prediction tasks.",
            "author": [
                "Zixing Wang",
                "Ahmed H. Qureshi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04840v1",
                "http://arxiv.org/pdf/2309.04840v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04831v1",
            "title": "Global Convergence of Receding-Horizon Policy Search in Learning\n  Estimator Designs",
            "updated": "2023-09-09T16:03:49Z",
            "published": "2023-09-09T16:03:49Z",
            "summary": "We introduce the receding-horizon policy gradient (RHPG) algorithm, the first\nPG algorithm with provable global convergence in learning the optimal linear\nestimator designs, i.e., the Kalman filter (KF). Notably, the RHPG algorithm\ndoes not require any prior knowledge of the system for initialization and does\nnot require the target system to be open-loop stable. The key of RHPG is that\nwe integrate vanilla PG (or any other policy search directions) into a dynamic\nprogramming outer loop, which iteratively decomposes the infinite-horizon KF\nproblem that is constrained and non-convex in the policy parameter into a\nsequence of static estimation problems that are unconstrained and\nstrongly-convex, thus enabling global convergence. We further provide\nfine-grained analyses of the optimization landscape under RHPG and detail the\nconvergence and sample complexity guarantees of the algorithm. This work serves\nas an initial attempt to develop reinforcement learning algorithms specifically\nfor control applications with performance guarantees by utilizing classic\ncontrol theory in both algorithmic design and theoretical analyses. Lastly, we\nvalidate our theories by deploying the RHPG algorithm to learn the Kalman\nfilter design of a large-scale convection-diffusion model. We open-source the\ncode repository at \\url{https://github.com/xiangyuan-zhang/LearningKF}.",
            "author": [
                "Xiangyuan Zhang",
                "Saviz Mowlavi",
                "Mouhacine Benosman",
                "Tamer Ba\u015far"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04831v1",
                "http://arxiv.org/pdf/2309.04831v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04828v1",
            "title": "FAIR: Flow Type-Aware Pre-Training of Compiler Intermediate\n  Representations",
            "updated": "2023-09-09T15:51:49Z",
            "published": "2023-09-09T15:51:49Z",
            "summary": "While the majority of existing pre-trained models from code learn source code\nfeatures such as code tokens and abstract syntax trees, there are some other\nworks that focus on learning from compiler intermediate representations (IRs).\nExisting IR-based models typically utilize IR features such as instructions,\ncontrol and data flow graphs (CDFGs), call graphs, etc. However, these methods\nconfuse variable nodes and instruction nodes in a CDFG and fail to distinguish\ndifferent types of flows, and the neural networks they use fail to capture\nlong-distance dependencies and have over-smoothing and over-squashing problems.\nTo address these weaknesses, we propose FAIR, a Flow type-Aware pre-trained\nmodel for IR that involves employing (1) a novel input representation of IR\nprograms; (2) Graph Transformer to address over-smoothing, over-squashing and\nlong-dependencies problems; and (3) five pre-training tasks that we\nspecifically propose to enable FAIR to learn the semantics of IR tokens, flow\ntype information, and the overall representation of IR. Experimental results\nshow that FAIR can achieve state-of-the-art results on four code-related\ndownstream tasks.",
            "author": [
                "Changan Niu",
                "Chuanyi Li",
                "Vincent Ng",
                "David Lo",
                "Bin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04828v1",
                "http://arxiv.org/pdf/2309.04828v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04827v1",
            "title": "Neurons in Large Language Models: Dead, N-gram, Positional",
            "updated": "2023-09-09T15:51:36Z",
            "published": "2023-09-09T15:51:36Z",
            "summary": "We analyze a family of large language models in such a lightweight manner\nthat can be done on a single GPU. Specifically, we focus on the OPT family of\nmodels ranging from 125m to 66b parameters and rely only on whether an FFN\nneuron is activated or not. First, we find that the early part of the network\nis sparse and represents many discrete features. Here, many neurons (more than\n70% in some layers of the 66b model) are \"dead\", i.e. they never activate on a\nlarge collection of diverse data. At the same time, many of the alive neurons\nare reserved for discrete features and act as token and n-gram detectors.\nInterestingly, their corresponding FFN updates not only promote next token\ncandidates as could be expected, but also explicitly focus on removing the\ninformation about triggering them tokens, i.e., current input. To the best of\nour knowledge, this is the first example of mechanisms specialized at removing\n(rather than adding) information from the residual stream. With scale, models\nbecome more sparse in a sense that they have more dead neurons and token\ndetectors. Finally, some neurons are positional: them being activated or not\ndepends largely (or solely) on position and less so (or not at all) on textual\ndata. We find that smaller models have sets of neurons acting as position range\nindicators while larger models operate in a less explicit manner.",
            "author": [
                "Elena Voita",
                "Javier Ferrando",
                "Christoforos Nalmpantis"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04827v1",
                "http://arxiv.org/pdf/2309.04827v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04818v2",
            "title": "Graph topological transformations in space-filling cell aggregates",
            "updated": "2023-11-17T07:37:29Z",
            "published": "2023-09-09T14:59:28Z",
            "summary": "Cell rearrangements are fundamental mechanisms driving large-scale\ndeformations of living tissues. In three-dimensional (3D) space-filling cell\naggregates, cells rearrange through local topological transitions of the\nnetwork of cell-cell interfaces, which is most conveniently described by the\nvertex model. Since these transitions are not yet mathematically properly\nformulated, the 3D vertex model is generally difficult to implement. The few\nexisting implementations rely on highly customized and complex\nsoftware-engineering solutions, which cannot be transparently delineated and\nare thus mostly non-reproducible. To solve this outstanding problem, we propose\na reformulation of the vertex model. Our approach, called Graph Vertex Model\n(GVM), is based on storing the topology of the cell network into a knowledge\ngraph with a particular data structure that allows performing\ncell-rearrangement events by simple graph transformations. We find these\ntransformations consinsting of transformation patterns corresponding to T1\ntransitions, thereby unifying topological transitions in 2D and 3D\nspace-filling packings. This result suggests that the GVM's graph data\nstructure may be the most natural representation of cell aggregates and\ntissues. We use GVM to characterize solid-fluid transition in 3D cell\naggregates, driven by active noise and find aggregates undergoing efficient\nordering close to the transition point. In all, our work showcases knowledge\ngraphs as particularly suitable data models for structured storage, analysis,\nand manipulation of tissue data, which potentially has paradigm-shifting\nimplications for the fields of tissue biophysics and biology.",
            "author": [
                "Tanmoy Sarkar",
                "Matej Krajnc"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04818v2",
                "http://arxiv.org/pdf/2309.04818v2"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.bio-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04811v1",
            "title": "Chemical Properties from Graph Neural Network-Predicted Electron\n  Densities",
            "updated": "2023-09-09T14:31:08Z",
            "published": "2023-09-09T14:31:08Z",
            "summary": "According to density functional theory, any chemical property can be inferred\nfrom the electron density, making it the most informative attribute of an\natomic structure. In this work, we demonstrate the use of established physical\nmethods to obtain important chemical properties from model-predicted electron\ndensities. We introduce graph neural network architectural choices that provide\nphysically relevant and useful electron density predictions. Despite not\ntraining to predict atomic charges, the model is able to predict atomic charges\nwith an order of magnitude lower error than a sum of atomic charge densities.\nSimilarly, the model predicts dipole moments with half the error of the sum of\natomic charge densities method. We demonstrate that larger data sets lead to\nmore useful predictions in these tasks. These results pave the way for an\nalternative path in atomistic machine learning, where data-driven approaches\nand existing physical methods are used in tandem to obtain a variety of\nchemical properties in an explainable and self-consistent manner.",
            "author": [
                "Ethan M. Sunshine",
                "Muhammed Shuaibi",
                "Zachary W. Ulissi",
                "John R. Kitchin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04811v1",
                "http://arxiv.org/pdf/2309.04811v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04810v3",
            "title": "Neural Latent Geometry Search: Product Manifold Inference via\n  Gromov-Hausdorff-Informed Bayesian Optimization",
            "updated": "2023-10-27T14:05:02Z",
            "published": "2023-09-09T14:29:22Z",
            "summary": "Recent research indicates that the performance of machine learning models can\nbe improved by aligning the geometry of the latent space with the underlying\ndata structure. Rather than relying solely on Euclidean space, researchers have\nproposed using hyperbolic and spherical spaces with constant curvature, or\ncombinations thereof, to better model the latent space and enhance model\nperformance. However, little attention has been given to the problem of\nautomatically identifying the optimal latent geometry for the downstream task.\nWe mathematically define this novel formulation and coin it as neural latent\ngeometry search (NLGS). More specifically, we introduce an initial attempt to\nsearch for a latent geometry composed of a product of constant curvature model\nspaces with a small number of query evaluations, under some simplifying\nassumptions. To accomplish this, we propose a novel notion of distance between\ncandidate latent geometries based on the Gromov-Hausdorff distance from metric\ngeometry. In order to compute the Gromov-Hausdorff distance, we introduce a\nmapping function that enables the comparison of different manifolds by\nembedding them in a common high-dimensional ambient space. We then design a\ngraph search space based on the notion of smoothness between latent geometries\nand employ the calculated distances as an additional inductive bias. Finally,\nwe use Bayesian optimization to search for the optimal latent geometry in a\nquery-efficient manner. This is a general method which can be applied to search\nfor the optimal latent geometry for a variety of models and downstream tasks.\nWe perform experiments on synthetic and real-world datasets to identify the\noptimal latent geometry for multiple machine learning problems.",
            "author": [
                "Haitz Saez de Ocariz Borde",
                "Alvaro Arroyo",
                "Ismael Morales",
                "Ingmar Posner",
                "Xiaowen Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04810v3",
                "http://arxiv.org/pdf/2309.04810v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07153v1",
            "title": "Finding Influencers in Complex Networks: An Effective Deep Reinforcement\n  Learning Approach",
            "updated": "2023-09-09T14:19:00Z",
            "published": "2023-09-09T14:19:00Z",
            "summary": "Maximizing influences in complex networks is a practically important but\ncomputationally challenging task for social network analysis, due to its NP-\nhard nature. Most current approximation or heuristic methods either require\ntremendous human design efforts or achieve unsatisfying balances between\neffectiveness and efficiency. Recent machine learning attempts only focus on\nspeed but lack performance enhancement. In this paper, different from previous\nattempts, we propose an effective deep reinforcement learning model that\nachieves superior performances over traditional best influence maximization\nalgorithms. Specifically, we design an end-to-end learning framework that\ncombines graph neural network as the encoder and reinforcement learning as the\ndecoder, named DREIM. Trough extensive training on small synthetic graphs,\nDREIM outperforms the state-of-the-art baseline methods on very large synthetic\nand real-world networks on solution quality, and we also empirically show its\nlinear scalability with regard to the network size, which demonstrates its\nsuperiority in solving this problem.",
            "author": [
                "Changan Liu",
                "Changjun Fan",
                "Zhongzhi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07153v1",
                "http://arxiv.org/pdf/2309.07153v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04802v3",
            "title": "CPMR: Context-Aware Incremental Sequential Recommendation with\n  Pseudo-Multi-Task Learning",
            "updated": "2023-09-16T08:52:00Z",
            "published": "2023-09-09T14:07:11Z",
            "summary": "The motivations of users to make interactions can be divided into static\npreference and dynamic interest. To accurately model user representations over\ntime, recent studies in sequential recommendation utilize information\npropagation and evolution to mine from batches of arriving interactions.\nHowever, they ignore the fact that people are easily influenced by the recent\nactions of other users in the contextual scenario, and applying evolution\nacross all historical interactions dilutes the importance of recent ones, thus\nfailing to model the evolution of dynamic interest accurately. To address this\nissue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR)\nto model the evolution in both historical and contextual scenarios by creating\nthree representations for each user and item under different dynamics: static\nembedding, historical temporal states, and contextual temporal states. To\ndually improve the performance of temporal states evolution and incremental\nrecommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by\nstacking the incremental single-target recommendations into one multi-target\ntask for joint optimization. Within the PMTL paradigm, CPMR employs a\nshared-bottom network to conduct the evolution of temporal states across\nhistorical and contextual scenarios, as well as the fusion of them at the\nuser-item level. In addition, CPMR incorporates one real tower for incremental\npredictions, and two pseudo towers dedicated to updating the respective\ntemporal states based on new batches of interactions. Experimental results on\nfour benchmark recommendation datasets show that CPMR consistently outperforms\nstate-of-the-art baselines and achieves significant gains on three of them. The\ncode is available at: https://github.com/DiMarzioBian/CPMR.",
            "author": [
                "Qingtian Bian",
                "Jiaxing Xu",
                "Hui Fang",
                "Yiping Ke"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615512",
                "http://arxiv.org/abs/2309.04802v3",
                "http://arxiv.org/pdf/2309.04802v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04791v1",
            "title": "osmAG: Hierarchical Semantic Topometric Area Graph Maps in the OSM\n  Format for Mobile Robotics",
            "updated": "2023-09-09T13:36:24Z",
            "published": "2023-09-09T13:36:24Z",
            "summary": "Maps are essential to mobile robotics tasks like localization and planning.\nWe propose the open street map (osm) XML based Area Graph file format to store\nhierarchical, topometric semantic multi-floor maps of indoor and outdoor\nenvironments, since currently no such format is popular within the robotics\ncommunity. Building on-top of osm we leverage the available open source editing\ntools and libraries of osm, while adding the needed mobile robotics aspect with\nbuilding-level obstacle representation yet very compact, topometric data that\nfacilitates planning algorithms. Through the use of common osm keys as well as\ncustom ones we leverage the power of semantic annotation to enable various\napplications. For example, we support planning based on robot capabilities, to\ntake the locomotion mode and attributes in conjunction with the environment\ninformation into account. The provided C++ library is integrated into ROS. We\nevaluate the performance of osmAG using real data in a global path planning\napplication on a very big osmAG map, demonstrating its convenience and\neffectiveness for mobile robots.",
            "author": [
                "Delin Feng",
                "Chengqian Li",
                "Yongqi Zhang",
                "Chen Yu",
                "Soeren Schwertfeger"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04791v1",
                "http://arxiv.org/pdf/2309.04791v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04790v1",
            "title": "MMHQA-ICL: Multimodal In-context Learning for Hybrid Question Answering\n  over Text, Tables and Images",
            "updated": "2023-09-09T13:35:01Z",
            "published": "2023-09-09T13:35:01Z",
            "summary": "In the real world, knowledge often exists in a multimodal and heterogeneous\nform. Addressing the task of question answering with hybrid data types,\nincluding text, tables, and images, is a challenging task (MMHQA). Recently,\nwith the rise of large language models (LLM), in-context learning (ICL) has\nbecome the most popular way to solve QA problems. We propose MMHQA-ICL\nframework for addressing this problems, which includes stronger heterogeneous\ndata retriever and an image caption module. Most importantly, we propose a\nType-specific In-context Learning Strategy for MMHQA, enabling LLMs to leverage\ntheir powerful performance in this task. We are the first to use end-to-end LLM\nprompting method for this task. Experimental results demonstrate that our\nframework outperforms all baselines and methods trained on the full dataset,\nachieving state-of-the-art results under the few-shot setting on the\nMultimodalQA dataset.",
            "author": [
                "Weihao Liu",
                "Fangyu Lei",
                "Tongxu Luo",
                "Jiahe Lei",
                "Shizhu He",
                "Jun Zhao",
                "Kang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04790v1",
                "http://arxiv.org/pdf/2309.04790v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04789v1",
            "title": "Local Certification of Some Geometric Intersection Graph Classes",
            "updated": "2023-09-09T13:29:23Z",
            "published": "2023-09-09T13:29:23Z",
            "summary": "In the context of distributed certification, the recognition of graph classes\nhas started to be intensively studied. For instance, different results related\nto the recognition of planar, bounded tree-width and $H$-minor free graphs have\nbeen recently obtained. The goal of the present work is to design compact\ncertificates for the local recognition of relevant geometric intersection graph\nclasses, namely interval, chordal, circular arc, trapezoid and permutation.\nMore precisely, we give proof labeling schemes recognizing each of these\nclasses with logarithmic-sized certificates. We also provide tight logarithmic\nlower bounds on the size of the certificates on the proof labeling schemes for\nthe recognition of any of the aforementioned geometric intersection graph\nclasses.",
            "author": [
                "Benjam\u00edn Jauregui",
                "Pedro Montealegre",
                "Diego Ram\u00edrez-Romero",
                "Ivan Rapaport"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04789v1",
                "http://arxiv.org/pdf/2309.04789v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04766v1",
            "title": "SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment\n  to Cultural Reasoning",
            "updated": "2023-09-09T11:42:22Z",
            "published": "2023-09-09T11:42:22Z",
            "summary": "We present SeaEval, a benchmark for multilingual foundation models. In\naddition to characterizing how these models understand and reason with natural\nlanguage, we also investigate how well they comprehend cultural practices,\nnuances, and values. Alongside standard accuracy metrics, we investigate the\nbrittleness of foundation models in the dimensions of semantics and\nmultilinguality. Our analyses span both open-sourced and closed models, leading\nto empirical results across classic NLP tasks, reasoning, and cultural\ncomprehension. Key findings indicate (1) Most models exhibit varied behavior\nwhen given paraphrased instructions. (2) Many models still suffer from exposure\nbias (e.g., positional bias, majority label bias). (3) For questions rooted in\nfactual, scientific, and commonsense knowledge, consistent responses are\nexpected across multilingual queries that are semantically equivalent. Yet,\nmost models surprisingly demonstrate inconsistent performance on these queries.\n(4) Multilingually-trained models have not attained \"balanced multilingual\"\ncapabilities. Our endeavors underscore the need for more generalizable semantic\nrepresentations and enhanced multilingual contextualization. SeaEval can serve\nas a launchpad for more thorough investigations and evaluations for\nmultilingual and multicultural scenarios.",
            "author": [
                "Bin Wang",
                "Zhengyuan Liu",
                "Xin Huang",
                "Fangkai Jiao",
                "Yang Ding",
                "Ai Ti Aw",
                "Nancy F. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04766v1",
                "http://arxiv.org/pdf/2309.04766v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04761v2",
            "title": "A Comprehensive Survey on Deep Learning Techniques in Educational Data\n  Mining",
            "updated": "2023-10-13T11:18:13Z",
            "published": "2023-09-09T11:20:40Z",
            "summary": "Educational Data Mining (EDM) has emerged as a vital field of research, which\nharnesses the power of computational techniques to analyze educational data.\nWith the increasing complexity and diversity of educational data, Deep Learning\ntechniques have shown significant advantages in addressing the challenges\nassociated with analyzing and modeling this data. This survey aims to\nsystematically review the state-of-the-art in EDM with Deep Learning. We begin\nby providing a brief introduction to EDM and Deep Learning, highlighting their\nrelevance in the context of modern education. Next, we present a detailed\nreview of Deep Learning techniques applied in four typical educational\nscenarios, including knowledge tracing, undesirable student detecting,\nperformance prediction, and personalized recommendation. Furthermore, a\ncomprehensive overview of public datasets and processing tools for EDM is\nprovided. Finally, we point out emerging trends and future directions in this\nresearch area.",
            "author": [
                "Yuanguo Lin",
                "Hong Chen",
                "Wei Xia",
                "Fan Lin",
                "Pengcheng Wu",
                "Zongyue Wang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04761v2",
                "http://arxiv.org/pdf/2309.04761v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05678v1",
            "title": "Gromov-Hausdorff Distances for Comparing Product Manifolds of Model\n  Spaces",
            "updated": "2023-09-09T11:17:06Z",
            "published": "2023-09-09T11:17:06Z",
            "summary": "Recent studies propose enhancing machine learning models by aligning the\ngeometric characteristics of the latent space with the underlying data\nstructure. Instead of relying solely on Euclidean space, researchers have\nsuggested using hyperbolic and spherical spaces with constant curvature, or\ntheir combinations (known as product manifolds), to improve model performance.\nHowever, there exists no principled technique to determine the best latent\nproduct manifold signature, which refers to the choice and dimensionality of\nmanifold components. To address this, we introduce a novel notion of distance\nbetween candidate latent geometries using the Gromov-Hausdorff distance from\nmetric geometry. We propose using a graph search space that uses the estimated\nGromov-Hausdorff distances to search for the optimal latent geometry. In this\nwork we focus on providing a description of an algorithm to compute the\nGromov-Hausdorff distance between model spaces and its computational\nimplementation.",
            "author": [
                "Haitz Saez de Ocariz Borde",
                "Alvaro Arroyo",
                "Ismael Morales",
                "Ingmar Posner",
                "Xiaowen Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05678v1",
                "http://arxiv.org/pdf/2309.05678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04737v3",
            "title": "Learning Spiking Neural Network from Easy to Hard task",
            "updated": "2023-09-26T02:33:21Z",
            "published": "2023-09-09T09:46:32Z",
            "summary": "Starting with small and simple concepts, and gradually introducing complex\nand difficult concepts is the natural process of human learning. Spiking Neural\nNetworks (SNNs) aim to mimic the way humans process information, but current\nSNNs models treat all samples equally, which does not align with the principles\nof human learning and overlooks the biological plausibility of SNNs. To address\nthis, we propose a CL-SNN model that introduces Curriculum Learning(CL) into\nSNNs, making SNNs learn more like humans and providing higher biological\ninterpretability. CL is a training strategy that advocates presenting easier\ndata to models before gradually introducing more challenging data, mimicking\nthe human learning process. We use a confidence-aware loss to measure and\nprocess the samples with different difficulty levels. By learning the\nconfidence of different samples, the model reduces the contribution of\ndifficult samples to parameter optimization automatically. We conducted\nexperiments on static image datasets MNIST, Fashion-MNIST, CIFAR10, and\nneuromorphic datasets N-MNIST, CIFAR10-DVS, DVS-Gesture. The results are\npromising. To our best knowledge, this is the first proposal to enhance the\nbiologically plausibility of SNNs by introducing CL.",
            "author": [
                "Lingling Tang",
                "Jiangtao Hu",
                "Hua Yu",
                "Surui Liu",
                "Jielei Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04737v3",
                "http://arxiv.org/pdf/2309.04737v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04734v1",
            "title": "Towards Better Multi-modal Keyphrase Generation via Visual Entity\n  Enhancement and Multi-granularity Image Noise Filtering",
            "updated": "2023-09-09T09:41:36Z",
            "published": "2023-09-09T09:41:36Z",
            "summary": "Multi-modal keyphrase generation aims to produce a set of keyphrases that\nrepresent the core points of the input text-image pair. In this regard,\ndominant methods mainly focus on multi-modal fusion for keyphrase generation.\nNevertheless, there are still two main drawbacks: 1) only a limited number of\nsources, such as image captions, can be utilized to provide auxiliary\ninformation. However, they may not be sufficient for the subsequent keyphrase\ngeneration. 2) the input text and image are often not perfectly matched, and\nthus the image may introduce noise into the model. To address these\nlimitations, in this paper, we propose a novel multi-modal keyphrase generation\nmodel, which not only enriches the model input with external knowledge, but\nalso effectively filters image noise. First, we introduce external visual\nentities of the image as the supplementary input to the model, which benefits\nthe cross-modal semantic alignment for keyphrase generation. Second, we\nsimultaneously calculate an image-text matching score and image region-text\ncorrelation scores to perform multi-granularity image noise filtering.\nParticularly, we introduce the correlation scores between image regions and\nground-truth keyphrases to refine the calculation of the previously-mentioned\ncorrelation scores. To demonstrate the effectiveness of our model, we conduct\nseveral groups of experiments on the benchmark dataset.\n  Experimental results and in-depth analyses show that our model achieves the\nstate-of-the-art performance. Our code is available on\nhttps://github.com/DeepLearnXMU/MM-MKP.",
            "author": [
                "Yifan Dong",
                "Suhang Wu",
                "Fandong Meng",
                "Jie Zhou",
                "Xiaoli Wang",
                "Jianxin Lin",
                "Jinsong Su"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612413",
                "http://arxiv.org/abs/2309.04734v1",
                "http://arxiv.org/pdf/2309.04734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04733v1",
            "title": "A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind\n  Prediction",
            "updated": "2023-09-09T09:36:28Z",
            "published": "2023-09-09T09:36:28Z",
            "summary": "The prediction of wind in terms of both wind speed and direction, which has a\ncrucial impact on many real-world applications like aviation and wind power\ngeneration, is extremely challenging due to the high stochasticity and\ncomplicated correlation in the weather data. Existing methods typically focus\non a sub-set of influential factors and thus lack a systematic treatment of the\nproblem. In addition, fine-grained forecasting is essential for efficient\nindustry operations, but has been less attended in the literature. In this\nwork, we propose a novel data-driven model, Multi-Horizon SpatioTemporal\nNetwork (MHSTN), generally for accurate and efficient fine-grained wind\nprediction. MHSTN integrates multiple deep neural networks targeting different\nfactors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract\nfeatures from various data sources and produce multi-horizon predictions for\nall sites within a given region. MHSTN is composed of four major modules.\nFirst, a temporal module fuses coarse-grained forecasts derived by Numerical\nWeather Prediction (NWP) and historical on-site observation data at stations so\nas to leverage both global and local atmospheric information. Second, a spatial\nmodule exploits spatial correlation by modeling the joint representation of all\nstations. Third, an ensemble module weighs the above two modules for final\npredictions. Furthermore, a covariate selection module automatically choose\ninfluential meteorological variables as initial input. MHSTN is already\nintegrated into the scheduling platform of one of the busiest international\nairports of China. The evaluation results demonstrate that our model\noutperforms competitors by a significant margin.",
            "author": [
                "Fanling Huang",
                "Yangdong Deng"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.neunet.2023.06.033",
                "http://arxiv.org/abs/2309.04733v1",
                "http://arxiv.org/pdf/2309.04733v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04732v1",
            "title": "TCGAN: Convolutional Generative Adversarial Network for Time Series\n  Classification and Clustering",
            "updated": "2023-09-09T09:33:25Z",
            "published": "2023-09-09T09:33:25Z",
            "summary": "Recent works have demonstrated the superiority of supervised Convolutional\nNeural Networks (CNNs) in learning hierarchical representations from time\nseries data for successful classification. These methods require sufficiently\nlarge labeled data for stable learning, however acquiring high-quality labeled\ntime series data can be costly and potentially infeasible. Generative\nAdversarial Networks (GANs) have achieved great success in enhancing\nunsupervised and semi-supervised learning. Nonetheless, to our best knowledge,\nit remains unclear how effectively GANs can serve as a general-purpose solution\nto learn representations for time series recognition, i.e., classification and\nclustering. The above considerations inspire us to introduce a Time-series\nConvolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between\ntwo one-dimensional CNNs (i.e., a generator and a discriminator) in the absence\nof label information. Parts of the trained TCGAN are then reused to construct a\nrepresentation encoder to empower linear recognition methods. We conducted\ncomprehensive experiments on synthetic and real-world datasets. The results\ndemonstrate that TCGAN is faster and more accurate than existing time-series\nGANs. The learned representations enable simple classification and clustering\nmethods to achieve superior and stable performance. Furthermore, TCGAN retains\nhigh efficacy in scenarios with few-labeled and imbalanced-labeled data. Our\nwork provides a promising path to effectively utilize abundant unlabeled time\nseries data.",
            "author": [
                "Fanling Huang",
                "Yangdong Deng"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.neunet.2023.06.033",
                "http://arxiv.org/abs/2309.04732v1",
                "http://arxiv.org/pdf/2309.04732v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04726v1",
            "title": "Eigenvalues of some classes of signed complete graphs",
            "updated": "2023-09-09T09:07:23Z",
            "published": "2023-09-09T09:07:23Z",
            "summary": "In this work, we discuss some properties of the eigenvalues of some classes\nof signed complete graphs. We also obtain the form of characteristic polynomial\nfor these graphs.",
            "author": [
                "Prajnanaswaroopa S"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04726v1",
                "http://arxiv.org/pdf/2309.04726v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C20, 15A18",
                "G.2.1; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04716v1",
            "title": "Toward Reproducing Network Research Results Using Large Language Models",
            "updated": "2023-09-09T08:07:54Z",
            "published": "2023-09-09T08:07:54Z",
            "summary": "Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.",
            "author": [
                "Qiao Xiang",
                "Yuling Lin",
                "Mingjun Fang",
                "Bang Huang",
                "Siyong Huang",
                "Ridi Wen",
                "Franck Le",
                "Linghe Kong",
                "Jiwu Shu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04716v1",
                "http://arxiv.org/pdf/2309.04716v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04695v1",
            "title": "Code-Style In-Context Learning for Knowledge-Based Question Answering",
            "updated": "2023-09-09T06:27:00Z",
            "published": "2023-09-09T06:27:00Z",
            "summary": "Current methods for Knowledge-Based Question Answering (KBQA) usually rely on\ncomplex training techniques and model frameworks, leading to many limitations\nin practical applications. Recently, the emergence of In-Context Learning (ICL)\ncapabilities in Large Language Models (LLMs) provides a simple and\ntraining-free semantic parsing paradigm for KBQA: Given a small number of\nquestions and their labeled logical forms as demo examples, LLMs can understand\nthe task intent and generate the logic form for a new question. However,\ncurrent powerful LLMs have little exposure to logic forms during pre-training,\nresulting in a high format error rate. To solve this problem, we propose a\ncode-style in-context learning method for KBQA, which converts the generation\nprocess of unfamiliar logical form into the more familiar code generation\nprocess for LLMs. Experimental results on three mainstream datasets show that\nour method dramatically mitigated the formatting error problem in generating\nlogic forms while realizing a new SOTA on WebQSP, GrailQA, and GraphQ under the\nfew-shot setting.",
            "author": [
                "Zhijie Nie",
                "Richong Zhang",
                "Zhongyuan Wang",
                "Xudong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04695v1",
                "http://arxiv.org/pdf/2309.04695v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04694v1",
            "title": "Redundancy-Free Self-Supervised Relational Learning for Graph Clustering",
            "updated": "2023-09-09T06:18:50Z",
            "published": "2023-09-09T06:18:50Z",
            "summary": "Graph clustering, which learns the node representations for effective cluster\nassignments, is a fundamental yet challenging task in data analysis and has\nreceived considerable attention accompanied by graph neural networks in recent\nyears. However, most existing methods overlook the inherent relational\ninformation among the non-independent and non-identically distributed nodes in\na graph. Due to the lack of exploration of relational attributes, the semantic\ninformation of the graph-structured data fails to be fully exploited which\nleads to poor clustering performance. In this paper, we propose a novel\nself-supervised deep graph clustering method named Relational Redundancy-Free\nGraph Clustering (R$^2$FGC) to tackle the problem. It extracts the attribute-\nand structure-level relational information from both global and local views\nbased on an autoencoder and a graph autoencoder. To obtain effective\nrepresentations of the semantic information, we preserve the consistent\nrelation among augmented nodes, whereas the redundant relation is further\nreduced for learning discriminative embeddings. In addition, a simple yet valid\nstrategy is utilized to alleviate the over-smoothing issue. Extensive\nexperiments are performed on widely used benchmark datasets to validate the\nsuperiority of our R$^2$FGC over state-of-the-art baselines. Our codes are\navailable at https://github.com/yisiyu95/R2FGC.",
            "author": [
                "Si-Yu Yi",
                "Wei Ju",
                "Yifang Qin",
                "Xiao Luo",
                "Luchen Liu",
                "Yong-Dao Zhou",
                "Ming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04694v1",
                "http://arxiv.org/pdf/2309.04694v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04691v1",
            "title": "Asynchronous Majority Dynamics on Binomial Random Graphs",
            "updated": "2023-09-09T06:01:18Z",
            "published": "2023-09-09T06:01:18Z",
            "summary": "We study information aggregation in networks when agents interact to learn a\nbinary state of the world. Initially each agent privately observes an\nindependent signal which is \"correct\" with probability $\\frac{1}{2}+\\delta$ for\nsome $\\delta > 0$. At each round, a node is selected uniformly at random to\nupdate their public opinion to match the majority of their neighbours (breaking\nties in favour of their initial private signal). Our main result shows that for\nsparse and connected binomial random graphs $\\mathcal G(n,p)$ the process\nstabilizes in a \"correct\" consensus in $\\mathcal O(n\\log^2 n/\\log\\log n)$ steps\nwith high probability. In fact, when $\\log n/n \\ll p = o(1)$ the process\nterminates at time $\\hat T = (1+o(1))n\\log n$, where $\\hat T$ is the first time\nwhen all nodes have been selected at least once. However, in dense binomial\nrandom graphs with $p=\\Omega(1)$, there is an information cascade where the\nprocess terminates in the \"incorrect\" consensus with probability bounded away\nfrom zero.",
            "author": [
                "Divyarthi Mohan",
                "Pawel Pralat"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04691v1",
                "http://arxiv.org/pdf/2309.04691v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04668v1",
            "title": "Influence Maximization in Social Networks: A Survey",
            "updated": "2023-09-09T02:57:57Z",
            "published": "2023-09-09T02:57:57Z",
            "summary": "Online social networks have become an important platform for people to\ncommunicate, share knowledge and disseminate information. Given the widespread\nusage of social media, individuals' ideas, preferences and behavior are often\ninfluenced by their peers or friends in the social networks that they\nparticipate in. Since the last decade, influence maximization (IM) problem has\nbeen extensively adopted to model the diffusion of innovations and ideas. The\npurpose of IM is to select a set of k seed nodes who can influence the most\nindividuals in the network.\n  In this survey, we present a systematical study over the researches and\nfuture directions with respect to IM problem. We review the information\ndiffusion models and analyze a variety of algorithms for the classic IM\nalgorithms. We propose a taxonomy for potential readers to understand the key\ntechniques and challenges. We also organize the milestone works in time order\nsuch that the readers of this survey can experience the research roadmap in\nthis field. Moreover, we also categorize other application-oriented IM studies\nand correspondingly study each of them. What's more, we list a series of open\nquestions as the future directions for IM-related researches, where a potential\nreader of this survey can easily observe what should be done next in this\nfield.",
            "author": [
                "Hui Li",
                "Susu Yang",
                "Mengting Xu",
                "Sourav S Bhowmick",
                "Jiangtao Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04668v1",
                "http://arxiv.org/pdf/2309.04668v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04660v1",
            "title": "Compiling Recurrences over Dense and Sparse Arrays",
            "updated": "2023-09-09T02:05:24Z",
            "published": "2023-09-09T02:05:24Z",
            "summary": "Recurrence equations lie at the heart of many computational paradigms\nincluding dynamic programming, graph analysis, and linear solvers. These\nequations are often expensive to compute and much work has gone into optimizing\nthem for different situations. The set of recurrence implementations is a large\ndesign space across the set of all recurrences (e.g., the Viterbi and\nFloyd-Warshall algorithms), the choice of data structures (e.g., dense and\nsparse matrices), and the set of different loop orders. Optimized library\nimplementations do not exist for most points in this design space, and\ndevelopers must therefore often manually implement and optimize recurrences. We\npresent a general framework for compiling recurrence equations into native code\ncorresponding to any valid point in this general design space. In this\nframework, users specify a system of recurrences, the type of data structures\nfor storing the input and outputs, and a set of scheduling primitives for\noptimization. A greedy algorithm then takes this specification and lowers it\ninto a native program that respects the dependencies inherent to the recurrence\nequation. We describe the compiler transformations necessary to lower this\nhigh-level specification into native parallel code for either sparse and dense\ndata structures and provide an algorithm for determining whether the recurrence\nsystem is solvable with the provided scheduling primitives. We evaluate the\nperformance and correctness of the generated code on various computational\ntasks from domains including dense and sparse matrix solvers, dynamic\nprogramming, graph problems, and sparse tensor algebra. We demonstrate that\ngenerated code has competitive performance to handwritten implementations in\nlibraries.",
            "author": [
                "Shiv Sundram",
                "Muhammad Usman Tariq",
                "Fredrik Kjolstad"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04660v1",
                "http://arxiv.org/pdf/2309.04660v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04653v1",
            "title": "Relative representations for cognitive graphs",
            "updated": "2023-09-09T00:58:02Z",
            "published": "2023-09-09T00:58:02Z",
            "summary": "Although the latent spaces learned by distinct neural networks are not\ngenerally directly comparable, recent work in machine learning has shown that\nit is possible to use the similarities and differences among latent space\nvectors to derive \"relative representations\" with comparable representational\npower to their \"absolute\" counterparts, and which are nearly identical across\nmodels trained on similar data distributions. Apart from their intrinsic\ninterest in revealing the underlying structure of learned latent spaces,\nrelative representations are useful to compare representations across networks\nas a generic proxy for convergence, and for zero-shot model stitching.\n  In this work we examine an extension of relative representations to discrete\nstate-space models, using Clone-Structured Cognitive Graphs (CSCGs) for 2D\nspatial localization and navigation as a test case. Our work shows that the\nprobability vectors computed during message passing can be used to define\nrelative representations on CSCGs, enabling effective communication across\nagents trained using different random initializations and training sequences,\nand on only partially similar spaces. We introduce a technique for zero-shot\nmodel stitching that can be applied post hoc, without the need for using\nrelative representations during training. This exploratory work is intended as\na proof-of-concept for the application of relative representations to the study\nof cognitive maps in neuroscience and AI.",
            "author": [
                "Alex B. Kiefer",
                "Christopher L. Buckley"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04653v1",
                "http://arxiv.org/pdf/2309.04653v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "nlin.AO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04646v1",
            "title": "Efficient Finetuning Large Language Models For Vietnamese Chatbot",
            "updated": "2023-09-09T00:11:53Z",
            "published": "2023-09-09T00:11:53Z",
            "summary": "Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown\nto achieve remarkable performance across a variety of natural language tasks.\nRecent advancements in instruction tuning bring LLMs with ability in following\nuser's instructions and producing human-like responses. However, the high costs\nassociated with training and implementing LLMs pose challenges to academic\nresearch. Furthermore, the availability of pretrained LLMs and instruction-tune\ndatasets for Vietnamese language is limited. To tackle these concerns, we\nleverage large-scale instruction-following datasets from open-source projects,\nnamely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and\nspecific medical domain. To the best of our knowledge, these are the first\ninstructional dataset for Vietnamese. Subsequently, we utilize\nparameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs:\nBloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models:\nBloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-Doctor.Finally, we assess the\neffectiveness of our methodology on a per-sample basis, taking into\nconsideration the helpfulness, relevance, accuracy, level of detail in their\nresponses. This evaluation process entails the utilization of GPT-4 as an\nautomated scoring mechanism. Despite utilizing a low-cost setup, our method\ndemonstrates about 20-30\\% improvement over the original models in our\nevaluation tasks.",
            "author": [
                "Vu-Thuan Doan",
                "Quoc-Truong Truong",
                "Duc-Vu Nguyen",
                "Vinh-Tiep Nguyen",
                "Thuy-Ngan Nguyen Luu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04646v1",
                "http://arxiv.org/pdf/2309.04646v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04616v2",
            "title": "Knowledge Distillation-Empowered Digital Twin for Anomaly Detection",
            "updated": "2023-09-12T10:45:10Z",
            "published": "2023-09-08T22:13:03Z",
            "summary": "Cyber-physical systems (CPSs), like train control and management systems\n(TCMS), are becoming ubiquitous in critical infrastructures. As safety-critical\nsystems, ensuring their dependability during operation is crucial. Digital\ntwins (DTs) have been increasingly studied for this purpose owing to their\ncapability of runtime monitoring and warning, prediction and detection of\nanomalies, etc. However, constructing a DT for anomaly detection in TCMS\nnecessitates sufficient training data and extracting both chronological and\ncontext features with high quality. Hence, in this paper, we propose a novel\nmethod named KDDT for TCMS anomaly detection. KDDT harnesses a language model\n(LM) and a long short-term memory (LSTM) network to extract contexts and\nchronological features, respectively. To enrich data volume, KDDT benefits from\nout-of-domain data with knowledge distillation (KD). We evaluated KDDT with two\ndatasets from our industry partner Alstom and obtained the F1 scores of 0.931\nand 0.915, respectively, demonstrating the effectiveness of KDDT. We also\nexplored individual contributions of the DT model, LM, and KD to the overall\nperformance of KDDT, via a comprehensive empirical study, and observed average\nF1 score improvements of 12.4%, 3%, and 6.05%, respectively.",
            "author": [
                "Qinghua Xu",
                "Shaukat Ali",
                "Tao Yue",
                "Zaimovic Nedim",
                "Inderjeet Singh"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3611643.3613879",
                "http://arxiv.org/abs/2309.04616v2",
                "http://arxiv.org/pdf/2309.04616v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04615v1",
            "title": "Leveraging World Model Disentanglement in Value-Based Multi-Agent\n  Reinforcement Learning",
            "updated": "2023-09-08T22:12:43Z",
            "published": "2023-09-08T22:12:43Z",
            "summary": "In this paper, we propose a novel model-based multi-agent reinforcement\nlearning approach named Value Decomposition Framework with Disentangled World\nModel to address the challenge of achieving a common goal of multiple agents\ninteracting in the same environment with reduced sample complexity. Due to\nscalability and non-stationarity problems posed by multi-agent systems,\nmodel-free methods rely on a considerable number of samples for training. In\ncontrast, we use a modularized world model, composed of action-conditioned,\naction-free, and static branches, to unravel the environment dynamics and\nproduce imagined outcomes based on past experience, without sampling directly\nfrom the real environment. We employ variational auto-encoders and variational\ngraph auto-encoders to learn the latent representations for the world model,\nwhich is merged with a value-based framework to predict the joint action-value\nfunction and optimize the overall training objective. We present experimental\nresults in Easy, Hard, and Super-Hard StarCraft II micro-management challenges\nto demonstrate that our method achieves high sample efficiency and exhibits\nsuperior performance in defeating the enemy armies compared to other baselines.",
            "author": [
                "Zhizun Wang",
                "David Meger"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04615v1",
                "http://arxiv.org/pdf/2309.04615v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04589v1",
            "title": "Motif-aware Attribute Masking for Molecular Graph Pre-training",
            "updated": "2023-09-08T20:36:03Z",
            "published": "2023-09-08T20:36:03Z",
            "summary": "Attribute reconstruction is used to predict node or edge features in the\npre-training of graph neural networks. Given a large number of molecules, they\nlearn to capture structural knowledge, which is transferable for various\ndownstream property prediction tasks and vital in chemistry, biomedicine, and\nmaterial science. Previous strategies that randomly select nodes to do\nattribute masking leverage the information of local neighbors However, the\nover-reliance of these neighbors inhibits the model's ability to learn from\nhigher-level substructures. For example, the model would learn little from\npredicting three carbon atoms in a benzene ring based on the other three but\ncould learn more from the inter-connections between the functional groups, or\ncalled chemical motifs. In this work, we propose and investigate motif-aware\nattribute masking strategies to capture inter-motif structures by leveraging\nthe information of atoms in neighboring motifs. Once each graph is decomposed\ninto disjoint motifs, the features for every node within a sample motif are\nmasked. The graph decoder then predicts the masked features of each node within\nthe motif for reconstruction. We evaluate our approach on eight molecular\nproperty prediction datasets and demonstrate its advantages.",
            "author": [
                "Eric Inae",
                "Gang Liu",
                "Meng Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04589v1",
                "http://arxiv.org/pdf/2309.04589v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04588v1",
            "title": "Distributed Optimization via Gradient Descent with Event-Triggered\n  Zooming over Quantized Communication",
            "updated": "2023-09-08T20:33:24Z",
            "published": "2023-09-08T20:33:24Z",
            "summary": "In this paper, we study unconstrained distributed optimization strongly\nconvex problems, in which the exchange of information in the network is\ncaptured by a directed graph topology over digital channels that have limited\ncapacity (and hence information should be quantized). Distributed methods in\nwhich nodes use quantized communication yield a solution at the proximity of\nthe optimal solution, hence reaching an error floor that depends on the\nquantization level used; the finer the quantization the lower the error floor.\nHowever, it is not possible to determine in advance the optimal quantization\nlevel that ensures specific performance guarantees (such as achieving an error\nfloor below a predefined threshold). Choosing a very small quantization level\nthat would guarantee the desired performance, requires {information} packets of\nvery large size, which is not desirable (could increase the probability of\npacket losses, increase delays, etc) and often not feasible due to the limited\ncapacity of the channels available. In order to obtain a\ncommunication-efficient distributed solution and a sufficiently close proximity\nto the optimal solution, we propose a quantized distributed optimization\nalgorithm that converges in a finite number of steps and is able to adjust the\nquantization level accordingly. The proposed solution uses a finite-time\ndistributed optimization protocol to find a solution to the problem for a given\nquantization level in a finite number of steps and keeps refining the\nquantization level until the difference in the solution between two successive\nsolutions with different quantization levels is below a certain pre-specified\nthreshold.",
            "author": [
                "Apostolos I. Rikos",
                "Wei Jiang",
                "Themistoklis Charalambous",
                "Karl H. Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04588v1",
                "http://arxiv.org/pdf/2309.04588v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06559v1",
            "title": "Media Moments and Corporate Connections: A Deep Learning Approach to\n  Stock Movement Classification",
            "updated": "2023-09-08T20:13:34Z",
            "published": "2023-09-08T20:13:34Z",
            "summary": "The financial industry poses great challenges with risk modeling and profit\ngeneration. These entities are intricately tied to the sophisticated prediction\nof stock movements. A stock forecaster must untangle the randomness and\never-changing behaviors of the stock market. Stock movements are influenced by\na myriad of factors, including company history, performance, and\neconomic-industry connections. However, there are other factors that aren't\ntraditionally included, such as social media and correlations between stocks.\nSocial platforms such as Reddit, Facebook, and X (Twitter) create opportunities\nfor niche communities to share their sentiment on financial assets. By\naggregating these opinions from social media in various mediums such as posts,\ninterviews, and news updates, we propose a more holistic approach to include\nthese \"media moments\" within stock market movement prediction. We introduce a\nmethod that combines financial data, social media, and correlated stock\nrelationships via a graph neural network in a hierarchical temporal fashion.\nThrough numerous trials on current S&P 500 index data, with results showing an\nimprovement in cumulative returns by 28%, we provide empirical evidence of our\ntool's applicability for use in investment decisions.",
            "author": [
                "Luke Sanborn",
                "Matthew Sahagun"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06559v1",
                "http://arxiv.org/pdf/2309.06559v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.SI",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04570v1",
            "title": "A Torelli theorem for graphs via quasistable divisors",
            "updated": "2023-09-08T20:01:34Z",
            "published": "2023-09-08T20:01:34Z",
            "summary": "The Torelli theorem establishes that the Jacobian of a smooth projective\ncurve, together with the polarization provided by the theta divisor, fully\ncharacterizes the curve. In the case of nodal curves, there exists a concept\nknown as fine compactified Jacobian. The fine compactified Jacobian of a curve\ncomes with a natural stratification that can be regarded as a poset.\nFurthermore, this poset is entirely determined by the dual graph of the curve\nand is referred to as the poset of quasistable divisors on the graph. We\npresent a combinatorial version of the Torelli theorem, which demonstrates that\nthe poset of quasistable divisors of a graph completely determines the\nbiconnected components of the graph (up to contracting separating edges).\nMoreover, we achieve a natural extension of this theorem to tropical curves.",
            "author": [
                "Alex Abreu",
                "Marco Pacini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04570v1",
                "http://arxiv.org/pdf/2309.04570v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04565v1",
            "title": "Unleashing the Power of Graph Learning through LLM-based Autonomous\n  Agents",
            "updated": "2023-09-08T19:34:29Z",
            "published": "2023-09-08T19:34:29Z",
            "summary": "Graph structured data are widely existed and applied in the real-world\napplications, while it is a challenge to handling these diverse data and\nlearning tasks on graph in an efficient manner. When facing the complicated\ngraph learning tasks, experts have designed diverse Graph Neural Networks\n(GNNs) in recent years. They have also implemented AutoML in Graph, also known\nas AutoGraph, to automatically generate data-specific solutions. Despite their\nsuccess, they encounter limitations in (1) managing diverse learning tasks at\nvarious levels, (2) dealing with different procedures in graph learning beyond\narchitecture design, and (3) the huge requirements on the prior knowledge when\nusing AutoGraph. In this paper, we propose to use Large Language Models (LLMs)\nas autonomous agents to simplify the learning process on diverse real-world\ngraphs. Specifically, in response to a user request which may contain varying\ndata and learning targets at the node, edge, or graph levels, the complex graph\nlearning task is decomposed into three components following the agent planning,\nnamely, detecting the learning intent, configuring solutions based on\nAutoGraph, and generating a response. The AutoGraph agents manage crucial\nprocedures in automated graph learning, including data-processing, AutoML\nconfiguration, searching architectures, and hyper-parameter fine-tuning. With\nthese agents, those components are processed by decomposing and completing step\nby step, thereby generating a solution for the given data automatically,\nregardless of the learning task on node or graph. The proposed method is dubbed\nAuto$^2$Graph, and the comparable performance on different datasets and\nlearning tasks. Its effectiveness is demonstrated by its comparable performance\non different datasets and learning tasks, as well as the human-like decisions\nmade by the agents.",
            "author": [
                "Lanning Wei",
                "Zhiqiang He",
                "Huan Zhao",
                "Quanming Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04565v1",
                "http://arxiv.org/pdf/2309.04565v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04558v1",
            "title": "Towards Interpretable Solar Flare Prediction with Attention-based Deep\n  Neural Networks",
            "updated": "2023-09-08T19:21:10Z",
            "published": "2023-09-08T19:21:10Z",
            "summary": "Solar flare prediction is a central problem in space weather forecasting and\nrecent developments in machine learning and deep learning accelerated the\nadoption of complex models for data-driven solar flare forecasting. In this\nwork, we developed an attention-based deep learning model as an improvement\nover the standard convolutional neural network (CNN) pipeline to perform\nfull-disk binary flare predictions for the occurrence of $\\geq$M1.0-class\nflares within the next 24 hours. For this task, we collected compressed images\ncreated from full-disk line-of-sight (LoS) magnetograms. We used data-augmented\noversampling to address the class imbalance issue and used true skill statistic\n(TSS) and Heidke skill score (HSS) as the evaluation metrics. Furthermore, we\ninterpreted our model by overlaying attention maps on input magnetograms and\nvisualized the important regions focused on by the model that led to the\neventual decision. The significant findings of this study are: (i) We\nsuccessfully implemented an attention-based full-disk flare predictor ready for\noperational forecasting where the candidate model achieves an average\nTSS=0.54$\\pm$0.03 and HSS=0.37$\\pm$0.07. (ii) we demonstrated that our\nfull-disk model can learn conspicuous features corresponding to active regions\nfrom full-disk magnetogram images, and (iii) our experimental evaluation\nsuggests that our model can predict near-limb flares with adept skill and the\npredictions are based on relevant active regions (ARs) or AR characteristics\nfrom full-disk magnetograms.",
            "author": [
                "Chetraj Pandey",
                "Anli Ji",
                "Rafal A. Angryk",
                "Berkay Aydin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04558v1",
                "http://arxiv.org/pdf/2309.04558v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04537v1",
            "title": "The complexity of the greedoid Tutte polynomial",
            "updated": "2023-09-08T18:01:03Z",
            "published": "2023-09-08T18:01:03Z",
            "summary": "We consider the Tutte polynomial of three classes of greedoids: those arising\nfrom rooted graphs, rooted digraphs and binary matrices. We establish the\ncomputational complexity of evaluating each of these polynomials at each fixed\nrational point (x,y). In each case we show that evaluation is #P-hard except\nfor a small number of exceptional cases when there is a polynomial time\nalgorithm. In the binary case, establishing #P-hardness along one line relies\non Vertigan's unpublished result on the complexity of counting bases of a\nmatroid. For completeness, we include an appendix providing a proof if this\nresult.",
            "author": [
                "Christopher Knapp",
                "Steven Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04537v1",
                "http://arxiv.org/pdf/2309.04537v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C31 (Primary) 68Q17, 05B35 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04471v4",
            "title": "Multiplicative Anomaly matches Casimir Energy for GJMS Operators on\n  Spheres",
            "updated": "2023-12-06T17:45:26Z",
            "published": "2023-09-08T17:59:22Z",
            "summary": "An explicit formula to compute the multiplicative anomaly or defect of\n$\\zeta$-regularized products of linear factors is derived, by using a Feynman\nparametrization, generalizing Shintani-Mizuno formulas. Firstly, this is\napplied on $n$-spheres, reproducing known results in the literature. Then, this\nframework is applied to a closed Einstein universe at finite temperature,\nnamely $S^1_{\\beta}\\times S^{n-1}$. In doing so, it is shown that the standard\nCasimir energy for GJMS operators coincides with the accumulated multiplicative\nanomaly for the shifted Laplacians that build them up. This equivalence between\nCasimir energy and multiplicative anomaly, unnoticed so far to our knowledge,\nbrings about a new turn regarding the physical significance of the\nmultiplicative anomaly, putting both now on equal footing. An emergent improved\nCasimir energy, that takes into account the multiplicative anomaly among the\nbuilding Laplacians, is also discussed.",
            "author": [
                "R. Aros",
                "F. Bugini",
                "D. E. D\u00edaz",
                "B. Z\u00fa\u00f1iga"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04471v4",
                "http://arxiv.org/pdf/2309.04471v4"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04470v1",
            "title": "On the Actionability of Outcome Prediction",
            "updated": "2023-09-08T17:57:31Z",
            "published": "2023-09-08T17:57:31Z",
            "summary": "Predicting future outcomes is a prevalent application of machine learning in\nsocial impact domains. Examples range from predicting student success in\neducation to predicting disease risk in healthcare. Practitioners recognize\nthat the ultimate goal is not just to predict but to act effectively.\nIncreasing evidence suggests that relying on outcome predictions for downstream\ninterventions may not have desired results.\n  In most domains there exists a multitude of possible interventions for each\nindividual, making the challenge of taking effective action more acute. Even\nwhen causal mechanisms connecting the individual's latent states to outcomes is\nwell understood, in any given instance (a specific student or patient),\npractitioners still need to infer -- from budgeted measurements of latent\nstates -- which of many possible interventions will be most effective for this\nindividual. With this in mind, we ask: when are accurate predictors of outcomes\nhelpful for identifying the most suitable intervention?\n  Through a simple model encompassing actions, latent states, and measurements,\nwe demonstrate that pure outcome prediction rarely results in the most\neffective policy for taking actions, even when combined with other\nmeasurements. We find that except in cases where there is a single decisive\naction for improving the outcome, outcome prediction never maximizes \"action\nvalue\", the utility of taking actions. Making measurements of actionable latent\nstates, where specific actions lead to desired outcomes, considerably enhances\nthe action value compared to outcome prediction, and the degree of improvement\ndepends on action costs and the outcome model. This analysis emphasizes the\nneed to go beyond generic outcome prediction in interventional settings by\nincorporating knowledge of plausible actions and latent states.",
            "author": [
                "Lydia T. Liu",
                "Solon Barocas",
                "Jon Kleinberg",
                "Karen Levy"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04470v1",
                "http://arxiv.org/pdf/2309.04470v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05671v1",
            "title": "tSPM+; a high-performance algorithm for mining transitive sequential\n  patterns from clinical data",
            "updated": "2023-09-08T17:47:31Z",
            "published": "2023-09-08T17:47:31Z",
            "summary": "The increasing availability of large clinical datasets collected from\npatients can enable new avenues for computational characterization of complex\ndiseases using different analytic algorithms. One of the promising new methods\nfor extracting knowledge from large clinical datasets involves temporal pattern\nmining integrated with machine learning workflows. However, mining these\ntemporal patterns is a computational intensive task and has memory\nrepercussions. Current algorithms, such as the temporal sequence pattern mining\n(tSPM) algorithm, are already providing promising outcomes, but still leave\nroom for optimization. In this paper, we present the tSPM+ algorithm, a\nhigh-performance implementation of the tSPM algorithm, which adds a new\ndimension by adding the duration to the temporal patterns. We show that the\ntSPM+ algorithm provides a speed up to factor 980 and a up to 48 fold\nimprovement in memory consumption. Moreover, we present a docker container with\nan R-package, We also provide vignettes for an easy integration into already\nexisting machine learning workflows and use the mined temporal sequences to\nidentify Post COVID-19 patients and their symptoms according to the WHO\ndefinition.",
            "author": [
                "Jonas H\u00fcgel",
                "Ulrich Sax",
                "Shawn N. Murphy",
                "Hossein Estiri"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05671v1",
                "http://arxiv.org/pdf/2309.05671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04460v1",
            "title": "Essentially tight bounds for rainbow cycles in proper edge-colourings",
            "updated": "2023-09-08T17:42:11Z",
            "published": "2023-09-08T17:42:11Z",
            "summary": "An edge-coloured graph is said to be rainbow if no colour appears more than\nonce. Extremal problems involving rainbow objects have been a focus of much\nresearch over the last decade as they capture the essence of a number of\ninteresting problems in a variety of areas. A particularly intensively studied\nquestion due to Keevash, Mubayi, Sudakov and Verstra\\\"ete from 2007 asks for\nthe maximum possible average degree of a properly edge-coloured graph on $n$\nvertices without a rainbow cycle. Improving upon a series of earlier bounds,\nTomon proved an upper bound of $(\\log n)^{2+o(1)}$ for this question. Very\nrecently, Janzer-Sudakov and Kim-Lee-Liu-Tran independently removed the $o(1)$\nterm in Tomon's bound, showing a bound of $O(\\log^2 n)$. We prove an upper\nbound of $(\\log n)^{1+o(1)}$ for this maximum possible average degree when\nthere is no rainbow cycle. Our result is tight up to the $o(1)$ term, and so it\nessentially resolves this question. In addition, we observe a connection\nbetween this problem and several questions in additive number theory, allowing\nus to extend existing results on these questions for abelian groups to the case\nof non-abelian groups.",
            "author": [
                "Noga Alon",
                "Matija Buci\u0107",
                "Lisa Sauermann",
                "Dmitrii Zakharov",
                "Or Zamir"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04460v1",
                "http://arxiv.org/pdf/2309.04460v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.GR",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04453v1",
            "title": "WiSARD: A Labeled Visual and Thermal Image Dataset for Wilderness Search\n  and Rescue",
            "updated": "2023-09-08T17:22:26Z",
            "published": "2023-09-08T17:22:26Z",
            "summary": "Sensor-equipped unoccupied aerial vehicles (UAVs) have the potential to help\nreduce search times and alleviate safety risks for first responders carrying\nout Wilderness Search and Rescue (WiSAR) operations, the process of finding and\nrescuing person(s) lost in wilderness areas. Unfortunately, visual sensors\nalone do not address the need for robustness across all the possible terrains,\nweather, and lighting conditions that WiSAR operations can be conducted in. The\nuse of multi-modal sensors, specifically visual-thermal cameras, is critical in\nenabling WiSAR UAVs to perform in diverse operating conditions. However, due to\nthe unique challenges posed by the wilderness context, existing dataset\nbenchmarks are inadequate for developing vision-based algorithms for autonomous\nWiSAR UAVs. To this end, we present WiSARD, a dataset with roughly 56,000\nlabeled visual and thermal images collected from UAV flights in various\nterrains, seasons, weather, and lighting conditions. To the best of our\nknowledge, WiSARD is the first large-scale dataset collected with multi-modal\nsensors for autonomous WiSAR operations. We envision that our dataset will\nprovide researchers with a diverse and challenging benchmark that can test the\nrobustness of their algorithms when applied to real-world (life-saving)\napplications.",
            "author": [
                "Daniel Broyles",
                "Christopher R. Hayner",
                "Karen Leung"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IROS47612.2022.9981298",
                "http://arxiv.org/abs/2309.04453v1",
                "http://arxiv.org/pdf/2309.04453v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04450v1",
            "title": "Density of $3$-critical signed graphs",
            "updated": "2023-09-08T17:15:43Z",
            "published": "2023-09-08T17:15:43Z",
            "summary": "We say that a signed graph is $k$-critical if it is not $k$-colorable but\nevery one of its proper subgraphs is $k$-colorable. Using the definition of\ncolorability due to Naserasr, Wang, and Zhu that extends the notion of circular\ncolorability, we prove that every $3$-critical signed graph on $n$ vertices has\nat least $\\frac{3n-1}{2}$ edges, and that this bound is asymptotically tight.\nIt follows that every signed planar or projective-planar graph of girth at\nleast $6$ is (circular) $3$-colorable, and for the projective-planar case, this\ngirth condition is best possible. To prove our main result, we reformulate it\nin terms of the existence of a homomorphism to the signed graph $C_{3}^*$,\nwhich is the positive triangle augmented with a negative loop on each vertex.",
            "author": [
                "Laurent Beaudou",
                "Penny Haxell",
                "Kathryn Nurse",
                "Sagnik Sen",
                "Zhouningxin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04450v1",
                "http://arxiv.org/pdf/2309.04450v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04517v1",
            "title": "Corrigendum on Wiener index, Zagreb Indices and Harary index of Eulerian\n  graphs",
            "updated": "2023-09-08T17:13:48Z",
            "published": "2023-09-08T17:13:48Z",
            "summary": "In the original article ``Wiener index of Eulerian graphs'' [Discrete Applied\nMathematics Volume 162, 10 January 2014, Pages 247-250], the authors state that\nthe Wiener index (total distance) of an Eulerian graph is maximized by the\ncycle. We explain that the initial proof contains a flaw and note that it is a\ncorollary of a result by Plesn\\'ik, since an Eulerian graph is\n$2$-edge-connected. The same incorrect proof is used in two referencing papers,\n``Zagreb Indices and Multiplicative Zagreb Indices of Eulerian Graphs'' [Bull.\nMalays. Math. Sci. Soc. (2019) 42:67-78] and ``Harary index of Eulerian\ngraphs'' [J. Math. Chem., 59(5):1378-1394, 2021]. We give proofs of the main\nresults of those papers and the $2$-edge-connected analogues.",
            "author": [
                "Stijn Cambie"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04517v1",
                "http://arxiv.org/pdf/2309.04517v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C09, 05C12, 05C45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04437v2",
            "title": "Single View Refractive Index Tomography with Neural Fields",
            "updated": "2023-12-01T21:33:13Z",
            "published": "2023-09-08T17:01:34Z",
            "summary": "Refractive Index Tomography is the inverse problem of reconstructing the\ncontinuously-varying 3D refractive index in a scene using 2D projected image\nmeasurements. Although a purely refractive field is not directly visible, it\nbends light rays as they travel through space, thus providing a signal for\nreconstruction. The effects of such fields appear in many scientific computer\nvision settings, ranging from refraction due to transparent cells in microscopy\nto the lensing of distant galaxies caused by dark matter in astrophysics.\nReconstructing these fields is particularly difficult due to the complex\nnonlinear effects of the refractive field on observed images. Furthermore,\nwhile standard 3D reconstruction and tomography settings typically have access\nto observations of the scene from many viewpoints, many refractive index\ntomography problem settings only have access to images observed from a single\nviewpoint. We introduce a method that leverages prior knowledge of light\nsources scattered throughout the refractive medium to help disambiguate the\nsingle-view refractive index tomography problem. We differentiably trace curved\nrays through a neural field representation of the refractive field, and\noptimize its parameters to best reproduce the observed image. We demonstrate\nthe efficacy of our approach by reconstructing simulated refractive fields,\nanalyze the effects of light source distribution on the recovered field, and\ntest our method on a simulated dark matter mapping problem where we\nsuccessfully recover the 3D refractive field caused by a realistic dark matter\ndistribution.",
            "author": [
                "Brandon Zhao",
                "Aviad Levis",
                "Liam Connor",
                "Pratul P. Srinivasan",
                "Katherine L. Bouman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04437v2",
                "http://arxiv.org/pdf/2309.04437v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04430v1",
            "title": "Create Your World: Lifelong Text-to-Image Diffusion",
            "updated": "2023-09-08T16:45:56Z",
            "published": "2023-09-08T16:45:56Z",
            "summary": "Text-to-image generative models can produce diverse high-quality images of\nconcepts with a text prompt, which have demonstrated excellent ability in image\ngeneration, image translation, etc. We in this work study the problem of\nsynthesizing instantiations of a use's own concepts in a never-ending manner,\ni.e., create your world, where the new concepts from user are quickly learned\nwith a few examples. To achieve this goal, we propose a Lifelong text-to-image\nDiffusion Model (L2DM), which intends to overcome knowledge \"catastrophic\nforgetting\" for the past encountered concepts, and semantic \"catastrophic\nneglecting\" for one or more concepts in the text prompt. In respect of\nknowledge \"catastrophic forgetting\", our L2DM framework devises a task-aware\nmemory enhancement module and a elastic-concept distillation module, which\ncould respectively safeguard the knowledge of both prior concepts and each past\npersonalized concept. When generating images with a user text prompt, the\nsolution to semantic \"catastrophic neglecting\" is that a concept attention\nartist module can alleviate the semantic neglecting from concept aspect, and an\northogonal attention module can reduce the semantic binding from attribute\naspect. To the end, our model can generate more faithful image across a range\nof continual text prompts in terms of both qualitative and quantitative\nmetrics, when comparing with the related state-of-the-art models. The code will\nbe released at https://wenqiliang.github.io/.",
            "author": [
                "Gan Sun",
                "Wenqi Liang",
                "Jiahua Dong",
                "Jun Li",
                "Zhengming Ding",
                "Yang Cong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04430v1",
                "http://arxiv.org/pdf/2309.04430v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04424v1",
            "title": "Neuroqueer Literacies in a Physics Context: A Discussion on Changing the\n  Physics Classroom Using a Neuroqueer Literacy Framework",
            "updated": "2023-09-08T16:38:03Z",
            "published": "2023-09-08T16:38:03Z",
            "summary": "Life experience, identity, the relationship between ourselves and the world\naround us among others, all affect and shape how we, as scientists, construct\nknowledge. Neurodiversity, the diversity of minds, is an interesting concept\nwhen keeping this in mind. Being neurodivergent, or neuroqueer (the viewing of\nbeing neurodivergent as a queer thing, along with the intersection of\nneurodiversity and queerness), means having non-neurotypical ways of perceiving\nand interacting with the world, and especially of creating knowledge about the\nrules and regulations, both natural and societal, that govern it locally and\nbroadly. Neuroqueer physicists, therefore, have unique non-normative ways of\ndoing physics, the study of the rules (which is done societally) which govern\nthe natural world. It is imperative that, when teaching neurodivergent\nstudents, we encourage and support this non-normative way of thinking about\nphysics, and help them do physics in ways that they will be successful, and\nsupport the development of Neuroqueer (Scientific) Literacies, from Kleekamp's\nand Smilges's works on literacy. We here present a brief overview of Neuroqueer\nLiteracies and how to apply them in the physics classroom.",
            "author": [
                "Liam G. McDermott",
                "Daniel P. Oleynik"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04424v1",
                "http://arxiv.org/pdf/2309.04424v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04390v2",
            "title": "Induced subgraphs and tree decompositions XI. Local structure in\n  even-hole-free graphs of large treewidth",
            "updated": "2023-11-22T19:48:56Z",
            "published": "2023-09-08T15:43:11Z",
            "summary": "Treewidth is a fundamental graph parameter that quantifies the complexity of\ngraphs by measuring their \"thickness\" compared to a tree. In 1986, Robertson\nand Seymour proved that the only way a graph may have large treewidth is by\ncontaining a large hexagonal grid as a minor, or equivalently, as a\n(subdivided) subgraph. Which induced subgraphs prevent a graph from having\nsmall treewidth?\n  Along with complete graphs, there are three other \"basic\" obstructions that\nshould appear in the answer. But the full list remains beyond the reach of\ncurrent methods, and \"even holes\" seem to be the crux of this matter. The\nreason lies in the observation that even holes are the only (non-trivial)\ninduced subgraphs that all basic obstructions except for complete graphs have\nin common, and yet graphs with no even hole and no $4$-vertex complete subgraph\nfail to have bounded treewidth.\n  The only known example of (even-hole, $K_4$)-free graphs of unbounded\ntreewidth, called \"layered wheels\", is due to Sintiari and Trotignon. While\nrather complicated in global structure, layered wheels are unexpectedly sparse\nfrom a local perspective: for every $h\\geq 1$, there are layered wheels of\narbitrarily large treewidth in which every induced subgraph on at most $h$\nvertices is chordal. The converse is also true, that every $K_4$-free chordal\ngraph $H$ appears as an induced subgraph in every layered wheel of sufficiently\nlarge treewidth.\n  It turns out, despite their technically involved construction, that layered\nwheels are in fact quite canonical: our main result shows that the local\nstructure of layered wheels is realized in every (even-hole, $K_4$)-free graph\nof large treewidth. More precisely, we prove that for a graph $H$, every\n(even-hole, $K_4$)-free graph of large enough treewidth contains an induced\nsubgraph isomorphic to $H$, if and only if $H$ is a $K_4$-free chordal graph.",
            "author": [
                "Bogdan Alecu",
                "Maria Chudnovsky",
                "Sepehr Hajebi",
                "Sophie Spirkl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04390v2",
                "http://arxiv.org/pdf/2309.04390v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04512v2",
            "title": "Elastic bounds for anisotropic layers",
            "updated": "2023-11-14T13:36:45Z",
            "published": "2023-09-08T14:37:19Z",
            "summary": "The complete set of bounds for the technical constants of an elastic layer,\nplate or laminate is given. The bounds are valid in general, also for\ncompletely anisotropic bodies. They are obtained transforming the polar bounds\npreviously found. These bounds complete the knowledge of classical elasticity\nat least in the two-dimensional case and are useful in several situations,\ne.g., for determining the correct feasibility domain in design problems or as\nnecessary conditions for accepting the results of laboratory tests on\nanisotropic layers.",
            "author": [
                "Paolo Vannucci"
            ],
            "link": [
                "http://dx.doi.org/10.1098/rspa.2023.0662",
                "http://arxiv.org/abs/2309.04512v2",
                "http://arxiv.org/pdf/2309.04512v2"
            ],
            "primary_category": "physics.class-ph",
            "category": [
                "physics.class-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04357v1",
            "title": "SSIG: A Visually-Guided Graph Edit Distance for Floor Plan Similarity",
            "updated": "2023-09-08T14:28:28Z",
            "published": "2023-09-08T14:28:28Z",
            "summary": "We propose a simple yet effective metric that measures structural similarity\nbetween visual instances of architectural floor plans, without the need for\nlearning. Qualitatively, our experiments show that the retrieval results are\nsimilar to deeply learned methods. Effectively comparing instances of floor\nplan data is paramount to the success of machine understanding of floor plan\ndata, including the assessment of floor plan generative models and floor plan\nrecommendation systems. Comparing visual floor plan images goes beyond a sole\npixel-wise visual examination and is crucially about similarities and\ndifferences in the shapes and relations between subdivisions that compose the\nlayout. Currently, deep metric learning approaches are used to learn a\npair-wise vector representation space that closely mimics the structural\nsimilarity, in which the models are trained on similarity labels that are\nobtained by Intersection-over-Union (IoU). To compensate for the lack of\nstructural awareness in IoU, graph-based approaches such as Graph Matching\nNetworks (GMNs) are used, which require pairwise inference for comparing data\ninstances, making GMNs less practical for retrieval applications. In this\npaper, an effective evaluation metric for judging the structural similarity of\nfloor plans, coined SSIG (Structural Similarity by IoU and GED), is proposed\nbased on both image and graph distances. In addition, an efficient algorithm is\ndeveloped that uses SSIG to rank a large-scale floor plan database. Code will\nbe openly available.",
            "author": [
                "Casper van Engelenburg",
                "Seyran Khademi",
                "Jan van Gemert"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04357v1",
                "http://arxiv.org/pdf/2309.04357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04350v1",
            "title": "Exploring Cohesive Subgraphs in Hypergraphs: The (k,g)-core Approach",
            "updated": "2023-09-08T14:21:46Z",
            "published": "2023-09-08T14:21:46Z",
            "summary": "Identifying cohesive subgraphs in hypergraphs is a fundamental problem that\nhas received recent attention in data mining and engineering fields. Existing\napproaches mainly focus on a strongly induced subhypergraph or edge\ncardinality, overlooking the importance of the frequency of co-occurrence. In\nthis paper, we propose a new cohesive subgraph named (k,g)-core, which\nconsiders both neighbour and co-occurrence simultaneously. The $(k,g)$-core has\nvarious applications including recommendation system, network analysis, and\nfraud detection. To the best of our knowledge, this is the first work to\ncombine these factors. We extend an existing efficient algorithm to find\nsolutions for $(k,g)$-core. Finally, we conduct extensive experimental studies\nthat demonstrate the efficiency and effectiveness of our proposed algorithm.",
            "author": [
                "Dahee Kim",
                "Junghoon Kim",
                "Sungsu Lim",
                "Hyun Ji Jeong"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615275",
                "http://arxiv.org/abs/2309.04350v1",
                "http://arxiv.org/pdf/2309.04350v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04346v1",
            "title": "Shortest Path with Positive Disjunctive Constraints -- a Parameterized\n  Perspective",
            "updated": "2023-09-08T14:16:53Z",
            "published": "2023-09-08T14:16:53Z",
            "summary": "We study the SHORTEST PATH problem with positive disjunctive constraints from\nthe perspective of parameterized complexity. For positive disjunctive\nconstraints, there are certain pair of edges such that any feasible solution\nmust contain at least one edge from every such pair. In this paper, we initiate\nthe study of SHORTEST PATH problem subject to some positive disjunctive\nconstraints the classical version is known to be NP-Complete. Formally, given\nan undirected graph G = (V, E) with a forcing graph H = (E, F) such that the\nvertex set of H is same as the edge set of G. The goal is to find a set S of at\nmost k edges from G such that S forms a vertex cover in H and there is a path\nfrom s to t in the subgraph of G induced by the edge set S. In this paper, we\nconsider two natural parameterizations for this problem. One natural parameter\nis the solution size, i.e. k for which we provide a kernel with O(k^5) vertices\nwhen both G and H are general graphs. Additionally, when either G or H (but not\nboth) belongs to some special graph classes, we provied kernelization results\nwith O(k^3) vertices . The other natural parameter we consider is structural\nproperties of H, i.e. the size of a vertex deletion set of H to some special\ngraph classes. We provide some fixed-parameter tractability results for those\nstructural parameterizations.",
            "author": [
                "Susobhan Bandopadhyay",
                "Suman Banerjee",
                "Diptapriyo Majumdar",
                "Fahad Panolan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04346v1",
                "http://arxiv.org/pdf/2309.04346v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04341v1",
            "title": "Design of a Single-User RIS-Aided MISO System Based on Statistical\n  Channel Knowledge",
            "updated": "2023-09-08T14:12:02Z",
            "published": "2023-09-08T14:12:02Z",
            "summary": "Reconfigurable intelligent surface (RIS) is considered a prospective\ntechnology for beyond fifth-generation (5G) networks to improve the spectral\nand energy efficiency at a low cost. Prior works on the RIS mainly rely on\nperfect channel state information (CSI), which imposes a huge computational\ncomplexity. This work considers a single-user RIS-assisted communication\nsystem, where the second-order statistical knowledge of the channels is\nexploited to reduce the training overhead. We present algorithms that do not\nrequire estimation of the CSI and reconfiguration of the RIS in every channel\ncoherence interval, which constitutes one of the most critical practical issues\nin an RIS-aided system.",
            "author": [
                "Sadaf Syed",
                "Dominik Semmler",
                "Donia Ben Amor",
                "Michael Joham",
                "Wolfgang Utschick"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04341v1",
                "http://arxiv.org/pdf/2309.04341v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04340v1",
            "title": "Identifying Single-Input Linear System Dynamics from Reachable Sets",
            "updated": "2023-09-08T14:11:46Z",
            "published": "2023-09-08T14:11:46Z",
            "summary": "This paper is concerned with identifying linear system dynamics without the\nknowledge of individual system trajectories, but from the knowledge of the\nsystem's reachable sets observed at different times. Motivated by a scenario\nwhere the reachable sets are known from partially transparent manufacturer\nspecifications or observations of the collective behavior of adversarial\nagents, we aim to utilize such sets to determine the unknown system's dynamics.\nThis paper has two contributions. Firstly, we show that the sequence of the\nsystem's reachable sets can be used to uniquely determine the system's dynamics\nfor asymmetric input sets under some generic assumptions, regardless of the\nsystem's dimensions. We also prove the same property holds up to a sign change\nfor two-dimensional systems where the input set is symmetric around zero.\nSecondly, we present an algorithm to determine these dynamics. We apply and\nverify the developed theory and algorithms on an unknown band-pass filter\ncircuit solely provided the unknown system's reachable sets over a finite\nobservation period.",
            "author": [
                "Taha Shafa",
                "Roy Dong",
                "Melkior Ornik"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04340v1",
                "http://arxiv.org/pdf/2309.04340v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04332v1",
            "title": "Graph Neural Networks Use Graphs When They Shouldn't",
            "updated": "2023-09-08T13:59:18Z",
            "published": "2023-09-08T13:59:18Z",
            "summary": "Predictions over graphs play a crucial role in various domains, including\nsocial networks, molecular biology, medicine, and more. Graph Neural Networks\n(GNNs) have emerged as the dominant approach for learning on graph data.\nInstances of graph labeling problems consist of the graph-structure (i.e., the\nadjacency matrix), along with node-specific feature vectors. In some cases,\nthis graph-structure is non-informative for the predictive task. For instance,\nmolecular properties such as molar mass depend solely on the constituent atoms\n(node features), and not on the molecular structure. While GNNs have the\nability to ignore the graph-structure in such cases, it is not clear that they\nwill. In this work, we show that GNNs actually tend to overfit the\ngraph-structure in the sense that they use it even when a better solution can\nbe obtained by ignoring it. We examine this phenomenon with respect to\ndifferent graph distributions and find that regular graphs are more robust to\nthis overfitting. We then provide a theoretical explanation for this\nphenomenon, via analyzing the implicit bias of gradient-descent-based learning\nof GNNs in this setting. Finally, based on our empirical and theoretical\nfindings, we propose a graph-editing method to mitigate the tendency of GNNs to\noverfit graph-structures that should be ignored. We show that this method\nindeed improves the accuracy of GNNs across multiple benchmarks.",
            "author": [
                "Maya Bechler-Speicher",
                "Ido Amos",
                "Ran Gilad-Bachrach",
                "Amir Globerson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04332v1",
                "http://arxiv.org/pdf/2309.04332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04316v2",
            "title": "Incremental Learning of Humanoid Robot Behavior from Natural Interaction\n  and Large Language Models",
            "updated": "2023-11-02T17:38:37Z",
            "published": "2023-09-08T13:29:05Z",
            "summary": "Natural-language dialog is key for intuitive human-robot interaction. It can\nbe used not only to express humans' intents, but also to communicate\ninstructions for improvement if a robot does not understand a command\ncorrectly. Of great importance is to endow robots with the ability to learn\nfrom such interaction experience in an incremental way to allow them to improve\ntheir behaviors or avoid mistakes in the future. In this paper, we propose a\nsystem to achieve incremental learning of complex behavior from natural\ninteraction, and demonstrate its implementation on a humanoid robot. Building\non recent advances, we present a system that deploys Large Language Models\n(LLMs) for high-level orchestration of the robot's behavior, based on the idea\nof enabling the LLM to generate Python statements in an interactive console to\ninvoke both robot perception and action. The interaction loop is closed by\nfeeding back human instructions, environment observations, and execution\nresults to the LLM, thus informing the generation of the next statement.\nSpecifically, we introduce incremental prompt learning, which enables the\nsystem to interactively learn from its mistakes. For that purpose, the LLM can\ncall another LLM responsible for code-level improvements of the current\ninteraction based on human feedback. The improved interaction is then saved in\nthe robot's memory, and thus retrieved on similar requests. We integrate the\nsystem in the robot cognitive architecture of the humanoid robot ARMAR-6 and\nevaluate our methods both quantitatively (in simulation) and qualitatively (in\nsimulation and real-world) by demonstrating generalized incrementally-learned\nknowledge.",
            "author": [
                "Leonard B\u00e4rmann",
                "Rainer Kartmann",
                "Fabian Peller-Konrad",
                "Alex Waibel",
                "Tamim Asfour"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04316v2",
                "http://arxiv.org/pdf/2309.04316v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04298v1",
            "title": "Confidence in Causal Inference under Structure Uncertainty in Linear\n  Causal Models with Equal Variances",
            "updated": "2023-09-08T12:43:18Z",
            "published": "2023-09-08T12:43:18Z",
            "summary": "Inferring the effect of interventions within complex systems is a fundamental\nproblem of statistics. A widely studied approach employs structural causal\nmodels that postulate noisy functional relations among a set of interacting\nvariables. The underlying causal structure is then naturally represented by a\ndirected graph whose edges indicate direct causal dependencies. In a recent\nline of work, additional assumptions on the causal models have been shown to\nrender this causal graph identifiable from observational data alone. One\nexample is the assumption of linear causal relations with equal error variances\nthat we will take up in this work. When the graph structure is known, classical\nmethods may be used for calculating estimates and confidence intervals for\ncausal effects. However, in many applications, expert knowledge that provides\nan a priori valid causal structure is not available. Lacking alternatives, a\ncommonly used two-step approach first learns a graph and then treats the graph\nas known in inference. This, however, yields confidence intervals that are\noverly optimistic and fail to account for the data-driven model choice. We\nargue that to draw reliable conclusions, it is necessary to incorporate the\nremaining uncertainty about the underlying causal structure in confidence\nstatements about causal effects. To address this issue, we present a framework\nbased on test inversion that allows us to give confidence regions for total\ncausal effects that capture both sources of uncertainty: causal structure and\nnumerical size of nonzero effects.",
            "author": [
                "David Strieder",
                "Mathias Drton"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04298v1",
                "http://arxiv.org/pdf/2309.04298v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.TH",
                "62D20, 62H22"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04296v3",
            "title": "Navigating Out-of-Distribution Electricity Load Forecasting during\n  COVID-19: Benchmarking energy load forecasting models without and with\n  continual learning",
            "updated": "2023-10-04T00:37:16Z",
            "published": "2023-09-08T12:36:49Z",
            "summary": "In traditional deep learning algorithms, one of the key assumptions is that\nthe data distribution remains constant during both training and deployment.\nHowever, this assumption becomes problematic when faced with\nOut-of-Distribution periods, such as the COVID-19 lockdowns, where the data\ndistribution significantly deviates from what the model has seen during\ntraining. This paper employs a two-fold strategy: utilizing continual learning\ntechniques to update models with new data and harnessing human mobility data\ncollected from privacy-preserving pedestrian counters located outside\nbuildings. In contrast to online learning, which suffers from 'catastrophic\nforgetting' as newly acquired knowledge often erases prior information,\ncontinual learning offers a holistic approach by preserving past insights while\nintegrating new data. This research applies FSNet, a powerful continual\nlearning algorithm, to real-world data from 13 building complexes in Melbourne,\nAustralia, a city which had the second longest total lockdown duration globally\nduring the pandemic. Results underscore the crucial role of continual learning\nin accurate energy forecasting, particularly during Out-of-Distribution\nperiods. Secondary data such as mobility and temperature provided ancillary\nsupport to the primary forecasting model. More importantly, while traditional\nmethods struggled to adapt during lockdowns, models featuring at least online\nlearning demonstrated resilience, with lockdown periods posing fewer challenges\nonce armed with adaptive learning techniques. This study contributes valuable\nmethodologies and insights to the ongoing effort to improve energy load\nforecasting during future Out-of-Distribution periods.",
            "author": [
                "Arian Prabowo",
                "Kaixuan Chen",
                "Hao Xue",
                "Subbu Sethuvenkatraman",
                "Flora D. Salim"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3600100.3623726",
                "http://arxiv.org/abs/2309.04296v3",
                "http://arxiv.org/pdf/2309.04296v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04291v1",
            "title": "Star Colouring of Bounded Degree Graphs and Regular Graphs",
            "updated": "2023-09-08T12:25:12Z",
            "published": "2023-09-08T12:25:12Z",
            "summary": "A $k$-star colouring of a graph $G$ is a function\n$f:V(G)\\to\\{0,1,\\dots,k-1\\}$ such that $f(u)\\neq f(v)$ for every edge $uv$ of\n$G$, and every bicoloured connected subgraph of $G$ is a star. The star\nchromatic number of $G$, $\\chi_s(G)$, is the least integer $k$ such that $G$ is\n$k$-star colourable. We prove that $\\chi_s(G)\\geq \\lceil (d+4)/2\\rceil$ for\nevery $d$-regular graph $G$ with $d\\geq 3$. We reveal the structure and\nproperties of even-degree regular graphs $G$ that attain this lower bound. The\nstructure of such graphs $G$ is linked with a certain type of Eulerian\norientations of $G$. Moreover, this structure can be expressed in the LC-VSP\nframework of Telle and Proskurowski (SIDMA, 1997), and hence can be tested by\nan FPT algorithm with the parameter either treewidth, cliquewidth, or\nrankwidth. We prove that for $p\\geq 2$, a $2p$-regular graph $G$ is\n$(p+2)$-star colourable only if $n:=|V(G)|$ is divisible by $(p+1)(p+2)$. For\neach $p\\geq 2$ and $n$ divisible by $(p+1)(p+2)$, we construct a $2p$-regular\nHamiltonian graph on $n$ vertices which is $(p+2)$-star colourable.\n  The problem $k$-STAR COLOURABILITY takes a graph $G$ as input and asks\nwhether $G$ is $k$-star colourable. We prove that 3-STAR COLOURABILITY is\nNP-complete for planar bipartite graphs of maximum degree three and arbitrarily\nlarge girth. Besides, it is coNP-hard to test whether a bipartite graph of\nmaximum degree eight has a unique 3-star colouring up to colour swaps. For\n$k\\geq 3$, $k$-STAR COLOURABILITY of bipartite graphs of maximum degree $k$ is\nNP-complete, and does not even admit a $2^{o(n)}$-time algorithm unless ETH\nfails.",
            "author": [
                "Shalu M. A.",
                "Cyriac Antony"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.disc.2022.112850",
                "http://arxiv.org/abs/2309.04291v1",
                "http://arxiv.org/pdf/2309.04291v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04284v1",
            "title": "Viewing the process of generating counterfactuals as a source of\n  knowledge -- Application to the Naive Bayes classifier",
            "updated": "2023-09-08T12:06:48Z",
            "published": "2023-09-08T12:06:48Z",
            "summary": "There are now many comprehension algorithms for understanding the decisions\nof a machine learning algorithm. Among these are those based on the generation\nof counterfactual examples. This article proposes to view this generation\nprocess as a source of creating a certain amount of knowledge that can be\nstored to be used, later, in different ways. This process is illustrated in the\nadditive model and, more specifically, in the case of the naive Bayes\nclassifier, whose interesting properties for this purpose are shown.",
            "author": [
                "Vincent Lemaire",
                "Nathan Le Boudec",
                "Fran\u00e7oise Fessant",
                "Victor Guyomard"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04284v1",
                "http://arxiv.org/pdf/2309.04284v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04508v1",
            "title": "Spatial-Temporal Graph Attention Fuser for Calibration in IoT Air\n  Pollution Monitoring Systems",
            "updated": "2023-09-08T12:04:47Z",
            "published": "2023-09-08T12:04:47Z",
            "summary": "The use of Internet of Things (IoT) sensors for air pollution monitoring has\nsignificantly increased, resulting in the deployment of low-cost sensors.\nDespite this advancement, accurately calibrating these sensors in uncontrolled\nenvironmental conditions remains a challenge. To address this, we propose a\nnovel approach that leverages graph neural networks, specifically the graph\nattention network module, to enhance the calibration process by fusing data\nfrom sensor arrays. Through our experiments, we demonstrate the effectiveness\nof our approach in significantly improving the calibration accuracy of sensors\nin IoT air pollution monitoring platforms.",
            "author": [
                "Keivan Faghih Niresi",
                "Mengjie Zhao",
                "Hugo Bissig",
                "Henri Baumann",
                "Olga Fink"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04508v1",
                "http://arxiv.org/pdf/2309.04508v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04274v2",
            "title": "Data-Flow-Based Normalization Generation Algorithm of R1CS for\n  Zero-Knowledge Proof",
            "updated": "2023-09-16T13:21:48Z",
            "published": "2023-09-08T11:52:11Z",
            "summary": "The communities of blockchains and distributed ledgers have been stirred up\nby the introduction of zero-knowledge proofs (ZKPs). Originally designed to\nsolve privacy issues, ZKPs have now evolved into an effective remedy for\nscalability concerns and are applied in Zcash (internet money like Bitcoin). To\nenable ZKPs, Rank-1 Constraint Systems (R1CS) offer a verifier for bi-linear\nequations. To accurately and efficiently represent R1CS, several language tools\nlike Circom, Noir, and Snarky have been proposed to automate the compilation of\nadvanced programs into R1CS. However, due to the flexible nature of R1CS\nrepresentation, there can be significant differences in the compiled R1CS forms\ngenerated from circuit language programs with the same underlying semantics. To\naddress this issue, this paper uses a data-flow-based R1CS paradigm algorithm,\nwhich produces a standardized format for different R1CS instances with\nidentical semantics. By using the normalized R1CS format circuits, the\ncomplexity of circuits' verification can be reduced. In addition, this paper\npresents an R1CS normalization algorithm benchmark, and our experimental\nevaluation demonstrates the effectiveness and correctness of our methods.",
            "author": [
                "Chenhao Shi",
                "Hao Chen",
                "Ruibang Liu",
                "Guoqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04274v2",
                "http://arxiv.org/pdf/2309.04274v2"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04259v1",
            "title": "C++ Design Patterns for Low-latency Applications Including\n  High-frequency Trading",
            "updated": "2023-09-08T11:01:05Z",
            "published": "2023-09-08T11:01:05Z",
            "summary": "This work aims to bridge the existing knowledge gap in the optimisation of\nlatency-critical code, specifically focusing on high-frequency trading (HFT)\nsystems. The research culminates in three main contributions: the creation of a\nLow-Latency Programming Repository, the optimisation of a market-neutral\nstatistical arbitrage pairs trading strategy, and the implementation of the\nDisruptor pattern in C++. The repository serves as a practical guide and is\nenriched with rigorous statistical benchmarking, while the trading strategy\noptimisation led to substantial improvements in speed and profitability. The\nDisruptor pattern showcased significant performance enhancement over\ntraditional queuing methods. Evaluation metrics include speed, cache\nutilisation, and statistical significance, among others. Techniques like Cache\nWarming and Constexpr showed the most significant gains in latency reduction.\nFuture directions involve expanding the repository, testing the optimised\ntrading algorithm in a live trading environment, and integrating the Disruptor\npattern with the trading algorithm for comprehensive system benchmarking. The\nwork is oriented towards academics and industry practitioners seeking to\nimprove performance in latency-sensitive applications.",
            "author": [
                "Paul Bilokon",
                "Burak Gunduz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04259v1",
                "http://arxiv.org/pdf/2309.04259v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04257v1",
            "title": "A Tutorial on Distributed Optimization for Cooperative Robotics: from\n  Setups and Algorithms to Toolboxes and Research Directions",
            "updated": "2023-09-08T10:50:22Z",
            "published": "2023-09-08T10:50:22Z",
            "summary": "Several interesting problems in multi-robot systems can be cast in the\nframework of distributed optimization. Examples include multi-robot task\nallocation, vehicle routing, target protection and surveillance. While the\ntheoretical analysis of distributed optimization algorithms has received\nsignificant attention, its application to cooperative robotics has not been\ninvestigated in detail. In this paper, we show how notable scenarios in\ncooperative robotics can be addressed by suitable distributed optimization\nsetups. Specifically, after a brief introduction on the widely investigated\nconsensus optimization (most suited for data analytics) and on the\npartition-based setup (matching the graph structure in the optimization), we\nfocus on two distributed settings modeling several scenarios in cooperative\nrobotics, i.e., the so-called constraint-coupled and aggregative optimization\nframeworks. For each one, we consider use-case applications, and we discuss\ntailored distributed algorithms with their convergence properties. Then, we\nrevise state-of-the-art toolboxes allowing for the implementation of\ndistributed schemes on real networks of robots without central coordinators.\nFor each use case, we discuss their implementation in these toolboxes and\nprovide simulations and real experiments on networks of heterogeneous robots.",
            "author": [
                "Andrea Testa",
                "Guido Carnevale",
                "Giuseppe Notarstefano"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04257v1",
                "http://arxiv.org/pdf/2309.04257v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04233v1",
            "title": "Multifunction full space graphene assisted metasurface",
            "updated": "2023-09-08T09:40:19Z",
            "published": "2023-09-08T09:40:19Z",
            "summary": "In recent years, there has been notable advancement in programmable\nmetasurfaces, primarily attributed to their cost-effectiveness and capacity to\nmanipulate electromagnetic (EM) waves. Nevertheless, a significant limitation\nof numerous available metasurfaces is their capability to influence wavefronts\nonly in reflection mode or transmission mode, thus catering to only half of the\nspatial coverage. To the best of our knowledge and for the first time, a novel\ngraphene-assisted reprogrammable metasurface that offers the unprecedented\ncapability to independently and concurrently manipulate EM waves within both\nhalf-spaces has been introduced in the THz frequency band.",
            "author": [
                "Parsa Farzin",
                "Amir saman Nooramin",
                "Mohammad Soleimani"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04233v1",
                "http://arxiv.org/pdf/2309.04233v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07149v1",
            "title": "Decoding visual brain representations from electroencephalography\n  through Knowledge Distillation and latent diffusion models",
            "updated": "2023-09-08T09:13:50Z",
            "published": "2023-09-08T09:13:50Z",
            "summary": "Decoding visual representations from human brain activity has emerged as a\nthriving research domain, particularly in the context of brain-computer\ninterfaces. Our study presents an innovative method that employs to classify\nand reconstruct images from the ImageNet dataset using electroencephalography\n(EEG) data from subjects that had viewed the images themselves (i.e. \"brain\ndecoding\"). We analyzed EEG recordings from 6 participants, each exposed to 50\nimages spanning 40 unique semantic categories. These EEG readings were\nconverted into spectrograms, which were then used to train a convolutional\nneural network (CNN), integrated with a knowledge distillation procedure based\non a pre-trained Contrastive Language-Image Pre-Training (CLIP)-based image\nclassification teacher network. This strategy allowed our model to attain a\ntop-5 accuracy of 80%, significantly outperforming a standard CNN and various\nRNN-based benchmarks. Additionally, we incorporated an image reconstruction\nmechanism based on pre-trained latent diffusion models, which allowed us to\ngenerate an estimate of the images which had elicited EEG activity. Therefore,\nour architecture not only decodes images from neural activity but also offers a\ncredible image reconstruction from EEG only, paving the way for e.g. swift,\nindividualized feedback experiments. Our research represents a significant step\nforward in connecting neural signals with visual cognition.",
            "author": [
                "Matteo Ferrante",
                "Tommaso Boccato",
                "Stefano Bargione",
                "Nicola Toschi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07149v1",
                "http://arxiv.org/pdf/2309.07149v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04505v1",
            "title": "COVID-19 Detection System: A Comparative Analysis of System Performance\n  Based on Acoustic Features of Cough Audio Signals",
            "updated": "2023-09-08T08:33:24Z",
            "published": "2023-09-08T08:33:24Z",
            "summary": "A wide range of respiratory diseases, such as cold and flu, asthma, and\nCOVID-19, affect people's daily lives worldwide. In medical practice,\nrespiratory sounds are widely used in medical services to diagnose various\nrespiratory illnesses and lung disorders. The traditional diagnosis of such\nsounds requires specialized knowledge, which can be costly and reliant on human\nexpertise. Recently, cough audio recordings have been used to automate the\nprocess of detecting respiratory conditions. This research aims to examine\nvarious acoustic features that enhance the performance of machine learning (ML)\nmodels in detecting COVID-19 from cough signals. This study investigates the\nefficacy of three feature extraction techniques, including Mel Frequency\nCepstral Coefficients (MFCC), Chroma, and Spectral Contrast features, on two ML\nalgorithms, Support Vector Machine (SVM) and Multilayer Perceptron (MLP), and\nthus proposes an efficient COVID-19 detection system. The proposed system\nproduces a practical solution and demonstrates higher state-of-the-art\nclassification performance on COUGHVID and Virufy datasets for COVID-19\ndetection.",
            "author": [
                "Asmaa Shati",
                "Ghulam Mubashar Hassan",
                "Amitava Datta"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04505v1",
                "http://arxiv.org/pdf/2309.04505v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04200v1",
            "title": "Cyclic Operator Precedence Grammars for Parallel Parsing",
            "updated": "2023-09-08T08:25:03Z",
            "published": "2023-09-08T08:25:03Z",
            "summary": "Operator precedence languages (OPL) enjoy the local parsability property,\nwhich essentially means that a code fragment enclosed within a pair of markers\n-- playing the role of parentheses -- can be compiled with no knowledge of its\nexternal context. Such a property has been exploited to build parallel\ncompilers for languages formalized as OPLs. It has been observed, however, that\nwhen the syntax trees of the sentences have a linear substructure, its parsing\nmust necessarily proceed sequentially making it impossible to split such a\nsubtree into chunks to be processed in parallel. Such an inconvenience is due\nto the fact that so far much literature on OPLs has assumed the hypothesis that\nequality precedence relation cannot be cyclic. This hypothesis was motivated by\nthe need to keep the mathematical notation as simple as possible.\n  We present an enriched version of operator precedence grammars, called\ncyclic, that allows to use a simplified version of regular expressions in the\nright hand sides of grammar's rules; for this class of operator precedence\ngrammars the acyclicity hypothesis of the equality precedence relation is no\nmore needed to guarantee the algebraic properties of the generated languages.\nThe expressive power of the cyclic grammars is now fully equivalent to that of\nother formalisms defining OPLs such as operator precedence automata, monadic\nsecond order logic and operator precedence expressions. As a result cyclic\noperator precedence grammars now produce also unranked syntax trees and\nsentences with flat unbounded substructures that can be naturally partitioned\ninto chunks suitable for parallel parsing.",
            "author": [
                "Michele Chiari",
                "Dino Mandrioli",
                "Matteo Pradella"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04200v1",
                "http://arxiv.org/pdf/2309.04200v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04198v2",
            "title": "The CALLA Dataset: Probing LLMs' Interactive Knowledge Acquisition from\n  Chinese Medical Literature",
            "updated": "2023-09-12T13:51:14Z",
            "published": "2023-09-08T08:20:46Z",
            "summary": "The application of Large Language Models (LLMs) to the medical domain has\nstimulated the interest of researchers. Recent studies have focused on\nconstructing Instruction Fine-Tuning (IFT) data through medical knowledge\ngraphs to enrich the interactive medical knowledge of LLMs. However, the\nmedical literature serving as a rich source of medical knowledge remains\nunexplored. Our work introduces the CALLA dataset to probe LLMs' interactive\nknowledge acquisition from Chinese medical literature. It assesses the\nproficiency of LLMs in mastering medical knowledge through a free-dialogue\nfact-checking task. We identify a phenomenon called the ``fact-following\nresponse``, where LLMs tend to affirm facts mentioned in questions and display\na reluctance to challenge them. To eliminate the inaccurate evaluation caused\nby this phenomenon, for the golden fact, we artificially construct test data\nfrom two perspectives: one consistent with the fact and one inconsistent with\nthe fact. Drawing from the probing experiment on the CALLA dataset, we conclude\nthat IFT data highly correlated with the medical literature corpus serves as a\npotent catalyst for LLMs, enabling themselves to skillfully employ the medical\nknowledge acquired during the pre-training phase within interactive scenarios,\nenhancing accuracy. Furthermore, we design a framework for automatically\nconstructing IFT data based on medical literature and discuss some real-world\napplications.",
            "author": [
                "Yanrui Du",
                "Sendong Zhao",
                "Muzhen Cai",
                "Jianyu Chen",
                "Haochun Wang",
                "Yuhan Chen",
                "Haoqiang Guo",
                "Bing Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04198v2",
                "http://arxiv.org/pdf/2309.04198v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04194v1",
            "title": "Spatial Modulation with Energy Detection: Diversity Analysis and\n  Experimental Evaluation",
            "updated": "2023-09-08T08:11:25Z",
            "published": "2023-09-08T08:11:25Z",
            "summary": "In this paper, we present a non-coherent energy detection scheme for spatial\nmodulation (SM) systems. In particular, the use of SM is motivated by its\nlow-complexity implementation in comparison to multiple-input multiple-output\n(MIMO) systems, achieved through the activation of a single antenna during\ntransmission. Moreover, energy detection-based communications restrict the\nchannel state information to the magnitude of the fading gains. This\nconsideration makes the design applicable for low-cost low-powered devices\nsince phase estimation and its associated circuitry are avoided. We derive an\nenergy detection metric for a multi-antenna receiver based on the\nmaximum-likelihood (ML) criterion. By considering a biased pulse amplitude\nmodulation, we develop an analytical framework for the SM symbol error rate at\nhigh signal-to-noise ratios. Numerical results show that the diversity order is\nproportional to half the number of receive antennas; this result stems from\nhaving partial receiver channel knowledge. In addition, we compare the\nperformance of the proposed scheme with that of the coherent ML receiver and\nshow that the SM energy detector outperforms its coherent counterpart in\ncertain scenarios, particularly when utilizing non-negative constellations.\nUltimately, we implement an SM testbed using software-defined radio devices and\nprovide experimental error rate measurements that validate our theoretical\ncontribution.",
            "author": [
                "Elio Faddoul",
                "Ghassan M. Kraidy",
                "Constantinos Psomas",
                "Symeon Chatzinotas",
                "Ioannis Krikidis"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04194v1",
                "http://arxiv.org/pdf/2309.04194v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04182v1",
            "title": "A Long-Tail Friendly Representation Framework for Artist and Music\n  Similarity",
            "updated": "2023-09-08T07:53:21Z",
            "published": "2023-09-08T07:53:21Z",
            "summary": "The investigation of the similarity between artists and music is crucial in\nmusic retrieval and recommendation, and addressing the challenge of the\nlong-tail phenomenon is increasingly important. This paper proposes a Long-Tail\nFriendly Representation Framework (LTFRF) that utilizes neural networks to\nmodel the similarity relationship. Our approach integrates music, user,\nmetadata, and relationship data into a unified metric learning framework, and\nemploys a meta-consistency relationship as a regular term to introduce the\nMulti-Relationship Loss. Compared to the Graph Neural Network (GNN), our\nproposed framework improves the representation performance in long-tail\nscenarios, which are characterized by sparse relationships between artists and\nmusic. We conduct experiments and analysis on the AllMusic dataset, and the\nresults demonstrate that our framework provides a favorable generalization of\nartist and music representation. Specifically, on similar artist/music\nrecommendation tasks, the LTFRF outperforms the baseline by 9.69%/19.42% in Hit\nRatio@10, and in long-tail cases, the framework achieves 11.05%/14.14% higher\nthan the baseline in Consistent@10.",
            "author": [
                "Haoran Xiang",
                "Junyu Dai",
                "Xuchen Song",
                "Furao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04182v1",
                "http://arxiv.org/pdf/2309.04182v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.IR",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04175v1",
            "title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge\n  Bases for Reliable Response Generation in Chinese",
            "updated": "2023-09-08T07:42:57Z",
            "published": "2023-09-08T07:42:57Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable success in diverse\nnatural language processing (NLP) tasks in general domains. However, LLMs\nsometimes generate responses with the hallucination about medical facts due to\nlimited domain knowledge. Such shortcomings pose potential risks in the\nutilization of LLMs within medical contexts. To address this challenge, we\npropose knowledge-tuning, which leverages structured medical knowledge bases\nfor the LLMs to grasp domain knowledge efficiently and facilitate reliable\nresponse generation. We also release cMedKnowQA, a Chinese medical knowledge\nquestion-answering dataset constructed from medical knowledge bases to assess\nthe medical knowledge proficiency of LLMs. Experimental results show that the\nLLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of\naccuracy in response generation compared with vanilla instruction-tuning and\noffer a new reliable way for the domain adaptation of LLMs.",
            "author": [
                "Haochun Wang",
                "Sendong Zhao",
                "Zewen Qiang",
                "Zijian Li",
                "Nuwa Xi",
                "Yanrui Du",
                "MuZhen Cai",
                "Haoqiang Guo",
                "Yuhan Chen",
                "Haoming Xu",
                "Bing Qin",
                "Ting Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04175v1",
                "http://arxiv.org/pdf/2309.04175v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04169v1",
            "title": "Grouping Boundary Proposals for Fast Interactive Image Segmentation",
            "updated": "2023-09-08T07:22:54Z",
            "published": "2023-09-08T07:22:54Z",
            "summary": "Geodesic models are known as an efficient tool for solving various image\nsegmentation problems. Most of existing approaches only exploit local pointwise\nimage features to track geodesic paths for delineating the objective\nboundaries. However, such a segmentation strategy cannot take into account the\nconnectivity of the image edge features, increasing the risk of shortcut\nproblem, especially in the case of complicated scenario. In this work, we\nintroduce a new image segmentation model based on the minimal geodesic\nframework in conjunction with an adaptive cut-based circular optimal path\ncomputation scheme and a graph-based boundary proposals grouping scheme.\nSpecifically, the adaptive cut can disconnect the image domain such that the\ntarget contours are imposed to pass through this cut only once. The boundary\nproposals are comprised of precomputed image edge segments, providing the\nconnectivity information for our segmentation model. These boundary proposals\nare then incorporated into the proposed image segmentation model, such that the\ntarget segmentation contours are made up of a set of selected boundary\nproposals and the corresponding geodesic paths linking them. Experimental\nresults show that the proposed model indeed outperforms state-of-the-art\nminimal paths-based image segmentation approaches.",
            "author": [
                "Li Liu",
                "Da Chen",
                "Minglei Shu",
                "Laurent D. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04169v1",
                "http://arxiv.org/pdf/2309.04169v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04158v1",
            "title": "Context-Aware Prompt Tuning for Vision-Language Model with\n  Dual-Alignment",
            "updated": "2023-09-08T06:51:15Z",
            "published": "2023-09-08T06:51:15Z",
            "summary": "Large-scale vision-language models (VLMs), e.g., CLIP, learn broad visual\nconcepts from tedious training data, showing superb generalization ability.\nAmount of prompt learning methods have been proposed to efficiently adapt the\nVLMs to downstream tasks with only a few training samples. We introduce a novel\nmethod to improve the prompt learning of vision-language models by\nincorporating pre-trained large language models (LLMs), called Dual-Aligned\nPrompt Tuning (DuAl-PT). Learnable prompts, like CoOp, implicitly model the\ncontext through end-to-end training, which are difficult to control and\ninterpret. While explicit context descriptions generated by LLMs, like GPT-3,\ncan be directly used for zero-shot classification, such prompts are overly\nrelying on LLMs and still underexplored in few-shot domains. With DuAl-PT, we\npropose to learn more context-aware prompts, benefiting from both explicit and\nimplicit context modeling. To achieve this, we introduce a pre-trained LLM to\ngenerate context descriptions, and we encourage the prompts to learn from the\nLLM's knowledge by alignment, as well as the alignment between prompts and\nlocal image features. Empirically, DuAl-PT achieves superior performance on 11\ndownstream datasets on few-shot recognition and base-to-new generalization.\nHopefully, DuAl-PT can serve as a strong baseline. Code will be available.",
            "author": [
                "Hongyu Hu",
                "Tiancheng Lin",
                "Jie Wang",
                "Zhenbang Sun",
                "Yi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04158v1",
                "http://arxiv.org/pdf/2309.04158v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04154v2",
            "title": "A novel model for layer jamming-based continuum robots",
            "updated": "2023-09-11T05:14:40Z",
            "published": "2023-09-08T06:43:11Z",
            "summary": "Continuum robots with variable stiffness have gained wide popularity in the\nlast decade. Layer jamming (LJ) has emerged as a simple and efficient technique\nto achieve tunable stiffness for continuum robots. Despite its merits, the\ndevelopment of a control-oriented dynamical model tailored for this specific\nclass of robots remains an open problem in the literature. This paper aims to\npresent the first solution, to the best of our knowledge, to close the gap. We\npropose an energy-based model that is integrated with the LuGre frictional\nmodel for LJ-based continuum robots. Then, we take a comprehensive theoretical\nanalysis for this model, focusing on two fundamental characteristics of\nLJ-based continuum robots: shape locking and adjustable stiffness. To validate\nthe modeling approach and theoretical results, a series of experiments using\nour \\textit{OctRobot-I} continuum robotic platform was conducted. The results\nshow that the proposed model is capable of interpreting and predicting the\ndynamical behaviors in LJ-based continuum robots.",
            "author": [
                "Bowen Yi",
                "Yeman Fan",
                "Dikai Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04154v2",
                "http://arxiv.org/pdf/2309.04154v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04141v1",
            "title": "RST-style Discourse Parsing Guided by Document-level Content Structures",
            "updated": "2023-09-08T05:50:27Z",
            "published": "2023-09-08T05:50:27Z",
            "summary": "Rhetorical Structure Theory based Discourse Parsing (RST-DP) explores how\nclauses, sentences, and large text spans compose a whole discourse and presents\nthe rhetorical structure as a hierarchical tree. Existing RST parsing pipelines\nconstruct rhetorical structures without the knowledge of document-level content\nstructures, which causes relatively low performance when predicting the\ndiscourse relations for large text spans. Recognizing the value of high-level\ncontent-related information in facilitating discourse relation recognition, we\npropose a novel pipeline for RST-DP that incorporates structure-aware news\ncontent sentence representations derived from the task of News Discourse\nProfiling. By incorporating only a few additional layers, this enhanced\npipeline exhibits promising performance across various RST parsing metrics.",
            "author": [
                "Ming Li",
                "Ruihong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04141v1",
                "http://arxiv.org/pdf/2309.04141v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04134v1",
            "title": "A Grounded Conceptual Model for Ownership Types in Rust",
            "updated": "2023-09-08T05:28:56Z",
            "published": "2023-09-08T05:28:56Z",
            "summary": "Programmers learning Rust struggle to understand ownership types, Rust's core\nmechanism for ensuring memory safety without garbage collection. This paper\ndescribes our attempt to systematically design a pedagogy for ownership types.\nFirst, we studied Rust developers' misconceptions of ownership to create the\nOwnership Inventory, a new instrument for measuring a person's knowledge of\nownership. We found that Rust learners could not connect Rust's static and\ndynamic semantics, such as determining why an ill-typed program would (or would\nnot) exhibit undefined behavior. Second, we created a conceptual model of\nRust's semantics that explains borrow checking in terms of flow-sensitive\npermissions on paths into memory. Third, we implemented a Rust compiler plugin\nthat visualizes programs under the model. Fourth, we integrated the permissions\nmodel and visualizations into a broader pedagogy of ownership by writing a new\nownership chapter for The Rust Programming Language, a popular Rust textbook.\nFifth, we evaluated an initial deployment of our pedagogy against the original\nversion, using reader responses to the Ownership Inventory as a point of\ncomparison. Thus far, the new pedagogy has improved learner scores on the\nOwnership Inventory by an average of 9% ($N = 342, d = 0.56$).",
            "author": [
                "Will Crichton",
                "Gavin Gray",
                "Shriram Krishnamurthi"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3622841",
                "http://arxiv.org/abs/2309.04134v1",
                "http://arxiv.org/pdf/2309.04134v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04123v1",
            "title": "BMT Independence",
            "updated": "2023-09-08T04:56:54Z",
            "published": "2023-09-08T04:56:54Z",
            "summary": "We introduce the notion of BMT independence, allowing us to take arbitrary\nmixtures of boolean, monotone, and tensor independence and generalizing the\nnotion of BM independence of Wysoczanski. Pair-wise independence relations are\nencoded through a directed graph, which in turn determines the way mixed\nmoments must be computed. Corresponding Central and Poisson-Type Limit Theorems\nare provided along with an explicit construction to realize BMT independent\nrandom variables as bounded operators on certain Hilbert space.",
            "author": [
                "Octavio Arizmendi",
                "Saul Rogelio Mendoza",
                "Josu\u00e9 Vazquez-Becerra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04123v1",
                "http://arxiv.org/pdf/2309.04123v1"
            ],
            "primary_category": "math.OA",
            "category": [
                "math.OA",
                "math.PR",
                "46L54"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04120v1",
            "title": "Boltzmann sampling with quantum annealers via fast Stein correction",
            "updated": "2023-09-08T04:47:10Z",
            "published": "2023-09-08T04:47:10Z",
            "summary": "Despite the attempts to apply a quantum annealer to Boltzmann sampling, it is\nstill impossible to perform accurate sampling at arbitrary temperatures.\nConventional distribution correction methods such as importance sampling and\nresampling cannot be applied, because the analytical expression of sampling\ndistribution is unknown for a quantum annealer. Stein correction (Liu and Lee,\n2017) can correct the samples by weighting without the knowledge of the\nsampling distribution, but the naive implementation requires the solution of a\nlarge-scale quadratic program, hampering usage in practical problems. In this\nletter, a fast and approximate method based on random feature map and\nexponentiated gradient updates is developed to compute the sample weights, and\nused to correct the samples generated by D-Wave quantum annealers. In\nbenchmarking problems, it is observed that the residual error of thermal\naverage calculations is reduced significantly. If combined with our method,\nquantum annealers may emerge as a viable alternative to long-established Markov\nchain Monte Carlo methods.",
            "author": [
                "Ryosuke Shibukawa",
                "Ryo Tamura",
                "Koji Tsuda"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04120v1",
                "http://arxiv.org/pdf/2309.04120v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04119v1",
            "title": "Penetrating Shields: A Systematic Analysis of Memory Corruption\n  Mitigations in the Spectre Era",
            "updated": "2023-09-08T04:43:33Z",
            "published": "2023-09-08T04:43:33Z",
            "summary": "This paper provides the first systematic analysis of a synergistic threat\nmodel encompassing memory corruption vulnerabilities and microarchitectural\nside-channel vulnerabilities. We study speculative shield bypass attacks that\nleverage speculative execution attacks to leak secrets that are critical to the\nsecurity of memory corruption mitigations (i.e., the shields), and then use the\nleaked secrets to bypass the mitigation mechanisms and successfully conduct\nmemory corruption exploits, such as control-flow hijacking. We start by\nsystematizing a taxonomy of the state-of-the-art memory corruption mitigations\nfocusing on hardware-software co-design solutions. The taxonomy helps us to\nidentify 10 likely vulnerable defense schemes out of 20 schemes that we\nanalyze. Next, we develop a graph-based model to analyze the 10 likely\nvulnerable defenses and reason about possible countermeasures. Finally, we\npresent three proof-of-concept attacks targeting an already-deployed mitigation\nmechanism and two state-of-the-art academic proposals.",
            "author": [
                "Weon Taek Na",
                "Joel S. Emer",
                "Mengjia Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04119v1",
                "http://arxiv.org/pdf/2309.04119v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR",
                "K.6.5; D.4.6; C.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04503v1",
            "title": "Quantum Algorithm for Maximum Biclique Problem",
            "updated": "2023-09-08T04:43:05Z",
            "published": "2023-09-08T04:43:05Z",
            "summary": "Identifying a biclique with the maximum number of edges bears considerable\nimplications for numerous fields of application, such as detecting anomalies in\nE-commerce transactions, discerning protein-protein interactions in biology,\nand refining the efficacy of social network recommendation algorithms. However,\nthe inherent NP-hardness of this problem significantly complicates the matter.\nThe prohibitive time complexity of existing algorithms is the primary\nbottleneck constraining the application scenarios. Aiming to address this\nchallenge, we present an unprecedented exploration of a quantum computing\napproach. Efficient quantum algorithms, as a crucial future direction for\nhandling NP-hard problems, are presently under intensive investigation, of\nwhich the potential has already been proven in practical arenas such as\ncybersecurity. However, in the field of quantum algorithms for graph databases,\nlittle work has been done due to the challenges presented by the quantum\nrepresentation of complex graph topologies. In this study, we delve into the\nintricacies of encoding a bipartite graph on a quantum computer. Given a\nbipartite graph with n vertices, we propose a ground-breaking algorithm qMBS\nwith time complexity O^*(2^(n/2)), illustrating a quadratic speed-up in terms\nof complexity compared to the state-of-the-art. Furthermore, we detail two\nvariants tailored for the maximum vertex biclique problem and the maximum\nbalanced biclique problem. To corroborate the practical performance and\nefficacy of our proposed algorithms, we have conducted proof-of-principle\nexperiments utilizing IBM quantum simulators, of which the results provide a\nsubstantial validation of our approach to the extent possible to date.",
            "author": [
                "Xiaofan Li",
                "Prasenjit Mitra",
                "Rui Zhou",
                "Wolfgang Nejdl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04503v1",
                "http://arxiv.org/pdf/2309.04503v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DB",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04109v1",
            "title": "From Text to Mask: Localizing Entities Using the Attention of\n  Text-to-Image Diffusion Models",
            "updated": "2023-09-08T04:10:01Z",
            "published": "2023-09-08T04:10:01Z",
            "summary": "Diffusion models have revolted the field of text-to-image generation\nrecently. The unique way of fusing text and image information contributes to\ntheir remarkable capability of generating highly text-related images. From\nanother perspective, these generative models imply clues about the precise\ncorrelation between words and pixels. In this work, a simple but effective\nmethod is proposed to utilize the attention mechanism in the denoising network\nof text-to-image diffusion models. Without re-training nor inference-time\noptimization, the semantic grounding of phrases can be attained directly. We\nevaluate our method on Pascal VOC 2012 and Microsoft COCO 2014 under\nweakly-supervised semantic segmentation setting and our method achieves\nsuperior performance to prior methods. In addition, the acquired word-pixel\ncorrelation is found to be generalizable for the learned text embedding of\ncustomized generation methods, requiring only a few modifications. To validate\nour discovery, we introduce a new practical task called \"personalized referring\nimage segmentation\" with a new dataset. Experiments in various situations\ndemonstrate the advantages of our method compared to strong baselines on this\ntask. In summary, our work reveals a novel way to extract the rich multi-modal\nknowledge hidden in diffusion models for segmentation.",
            "author": [
                "Changming Xiao",
                "Qi Yang",
                "Feng Zhou",
                "Changshui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04109v1",
                "http://arxiv.org/pdf/2309.04109v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04101v1",
            "title": "The largest eigenvalue of $\\mathcal{C}_4^{-}$-free signed graphs",
            "updated": "2023-09-08T03:43:31Z",
            "published": "2023-09-08T03:43:31Z",
            "summary": "Let $\\mathcal{C}_{k}^{-}$ be the set of all negative $C_k$. For odd cycle,\nWang, Hou and Li [29] gave a spectral condition for the existence of negative\n$C_3$ in unbalanced signed graphs. For even cycle, we determine the maximum\nindex among all $\\mathcal{C}_4^{-}$-free unbalanced signed graphs and\ncompletely characterize the extremal signed graph in this paper. This could be\nregarded as a signed graph version of the results by Nikiforov [23] and Zhai\nand Wang [37].",
            "author": [
                "Yongang Wang",
                "Huiqiu Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04101v1",
                "http://arxiv.org/pdf/2309.04101v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04099v1",
            "title": "Hardness of Approximating Bounded-Degree Max 2-CSP and Independent Set\n  on k-Claw-Free Graphs",
            "updated": "2023-09-08T03:27:08Z",
            "published": "2023-09-08T03:27:08Z",
            "summary": "We consider the question of approximating Max 2-CSP where each variable\nappears in at most $d$ constraints (but with possibly arbitrarily large\nalphabet). There is a simple $(\\frac{d+1}{2})$-approximation algorithm for the\nproblem. We prove the following results for any sufficiently large $d$:\n  - Assuming the Unique Games Conjecture (UGC), it is NP-hard (under randomized\nreduction) to approximate this problem to within a factor of $\\left(\\frac{d}{2}\n- o(d)\\right)$.\n  - It is NP-hard (under randomized reduction) to approximate the problem to\nwithin a factor of $\\left(\\frac{d}{3} - o(d)\\right)$.\n  Thanks to a known connection [Dvorak et al., Algorithmica 2023], we establish\nthe following hardness results for approximating Maximum Independent Set on\n$k$-claw-free graphs:\n  - Assuming the Unique Games Conjecture (UGC), it is NP-hard (under randomized\nreduction) to approximate this problem to within a factor of $\\left(\\frac{k}{4}\n- o(k)\\right)$.\n  - It is NP-hard (under randomized reduction) to approximate the problem to\nwithin a factor of $\\left(\\frac{k}{3 + 2\\sqrt{2}} - o(k)\\right) \\geq\n\\left(\\frac{k}{5.829} - o(k)\\right)$.\n  In comparison, known approximation algorithms achieve $\\left(\\frac{k}{2} -\no(k)\\right)$-approximation in polynomial time [Neuwohner, STACS 2021; Thiery\nand Ward, SODA 2023] and $(\\frac{k}{3} + o(k))$-approximation in\nquasi-polynomial time [Cygan et al., SODA 2013].",
            "author": [
                "Euiwoong Lee",
                "Pasin Manurangsi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04099v1",
                "http://arxiv.org/pdf/2309.04099v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04082v1",
            "title": "Curve Your Attention: Mixed-Curvature Transformers for Graph\n  Representation Learning",
            "updated": "2023-09-08T02:44:37Z",
            "published": "2023-09-08T02:44:37Z",
            "summary": "Real-world graphs naturally exhibit hierarchical or cyclical structures that\nare unfit for the typical Euclidean space. While there exist graph neural\nnetworks that leverage hyperbolic or spherical spaces to learn representations\nthat embed such structures more accurately, these methods are confined under\nthe message-passing paradigm, making the models vulnerable against side-effects\nsuch as oversmoothing and oversquashing. More recent work have proposed global\nattention-based graph Transformers that can easily model long-range\ninteractions, but their extensions towards non-Euclidean geometry are yet\nunexplored. To bridge this gap, we propose Fully Product-Stereographic\nTransformer, a generalization of Transformers towards operating entirely on the\nproduct of constant curvature spaces. When combined with tokenized graph\nTransformers, our model can learn the curvature appropriate for the input graph\nin an end-to-end fashion, without the need of additional tuning on different\ncurvature initializations. We also provide a kernelized approach to\nnon-Euclidean attention, which enables our model to run in time and memory cost\nlinear to the number of nodes and edges while respecting the underlying\ngeometry. Experiments on graph reconstruction and node classification\ndemonstrate the benefits of generalizing Transformers to the non-Euclidean\ndomain.",
            "author": [
                "Sungjun Cho",
                "Seunghyuk Cho",
                "Sungwoo Park",
                "Hankook Lee",
                "Honglak Lee",
                "Moontae Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04082v1",
                "http://arxiv.org/pdf/2309.04082v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04081v1",
            "title": "UER: A Heuristic Bias Addressing Approach for Online Continual Learning",
            "updated": "2023-09-08T02:42:40Z",
            "published": "2023-09-08T02:42:40Z",
            "summary": "Online continual learning aims to continuously train neural networks from a\ncontinuous data stream with a single pass-through data. As the most effective\napproach, the rehearsal-based methods replay part of previous data. Commonly\nused predictors in existing methods tend to generate biased dot-product logits\nthat prefer to the classes of current data, which is known as a bias issue and\na phenomenon of forgetting. Many approaches have been proposed to overcome the\nforgetting problem by correcting the bias; however, they still need to be\nimproved in online fashion. In this paper, we try to address the bias issue by\na more straightforward and more efficient method. By decomposing the\ndot-product logits into an angle factor and a norm factor, we empirically find\nthat the bias problem mainly occurs in the angle factor, which can be used to\nlearn novel knowledge as cosine logits. On the contrary, the norm factor\nabandoned by existing methods helps remember historical knowledge. Based on\nthis observation, we intuitively propose to leverage the norm factor to balance\nthe new and old knowledge for addressing the bias. To this end, we develop a\nheuristic approach called unbias experience replay (UER). UER learns current\nsamples only by the angle factor and further replays previous samples by both\nthe norm and angle factors. Extensive experiments on three datasets show that\nUER achieves superior performance over various state-of-the-art methods. The\ncode is in https://github.com/FelixHuiweiLin/UER.",
            "author": [
                "Huiwei Lin",
                "Shanshan Feng",
                "Baoquan Zhang",
                "Hongliang Qiao",
                "Xutao Li",
                "Yunming Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04081v1",
                "http://arxiv.org/pdf/2309.04081v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04077v3",
            "title": "SayNav: Grounding Large Language Models for Dynamic Planning to\n  Navigation in New Environments",
            "updated": "2023-09-22T20:35:17Z",
            "published": "2023-09-08T02:24:37Z",
            "summary": "Semantic reasoning and dynamic planning capabilities are crucial for an\nautonomous agent to perform complex navigation tasks in unknown environments.\nIt requires a large amount of common-sense knowledge, that humans possess, to\nsucceed in these tasks. We present SayNav, a new approach that leverages human\nknowledge from Large Language Models (LLMs) for efficient generalization to\ncomplex navigation tasks in unknown large-scale environments. SayNav uses a\nnovel grounding mechanism, that incrementally builds a 3D scene graph of the\nexplored environment as inputs to LLMs, for generating feasible and\ncontextually appropriate high-level plans for navigation. The LLM-generated\nplan is then executed by a pre-trained low-level planner, that treats each\nplanned step as a short-distance point-goal navigation sub-task. SayNav\ndynamically generates step-by-step instructions during navigation and\ncontinuously refines future steps based on newly perceived information. We\nevaluate SayNav on a new multi-object navigation task, that requires the agent\nto utilize a massive amount of human knowledge to efficiently search multiple\ndifferent objects in an unknown environment. SayNav outperforms an oracle based\nPoint-nav baseline, achieving a success rate of 95.35% (vs 56.06% for the\nbaseline), under the ideal settings on this task, highlighting its ability to\ngenerate dynamic plans for successfully locating objects in large-scale new\nenvironments. In addition, SayNav also enables efficient generalization of\nlearning to navigate from simulation to real novel environments.",
            "author": [
                "Abhinav Rajvanshi",
                "Karan Sikka",
                "Xiao Lin",
                "Bhoram Lee",
                "Han-Pang Chiu",
                "Alvaro Velasquez"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04077v3",
                "http://arxiv.org/pdf/2309.04077v3"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04076v2",
            "title": "Towards Smaller, Faster, and Greener Language Models of Code",
            "updated": "2023-10-08T04:52:19Z",
            "published": "2023-09-08T02:20:44Z",
            "summary": "Large language models of code have shown remarkable effectiveness across\nvarious software engineering tasks. Despite the availability of many cloud\nservices built upon these powerful models, there remain several scenarios where\ndevelopers cannot take full advantage of them, stemming from factors such as\nrestricted or unreliable internet access, institutional privacy policies that\nprohibit external transmission of code to third-party vendors, and more.\nTherefore, developing a compact, efficient, and yet energy-saving model for\ndeployment on developers' devices becomes essential.\n  To this aim, we propose Avatar, a novel approach that crafts a deployable\nmodel from a large language model of code by optimizing it in terms of model\nsize, inference latency, energy consumption, and carbon footprint while\nmaintaining a comparable level of effectiveness. The key idea of Avatar is to\nformulate the optimization of language models as a multi-objective\nconfiguration tuning problem and solve it with the help of a Satisfiability\nModulo Theories (SMT) solver and a tailored optimization algorithm. The SMT\nsolver is used to form an appropriate configuration space, while the\noptimization algorithm identifies the Pareto-optimal set of configurations for\ntraining the optimized models using knowledge distillation. We evaluate Avatar\nwith two popular language models of code, i.e., CodeBERT and GraphCodeBERT, on\ntwo popular tasks, i.e., vulnerability prediction and clone detection. We use\nAvatar to produce optimized models with a small size (3 MB), which is\n160$\\times$ smaller than the original large models. On the two tasks, the\noptimized models significantly reduce the energy consumption (up to 184$\\times$\nless), carbon footprint (up to 157$\\times$ less), and inference latency (up to\n76$\\times$ faster), with only a negligible loss in effectiveness (1.67\\% on\naverage).",
            "author": [
                "Jieke Shi",
                "Zhou Yang",
                "Hong Jin Kang",
                "Bowen Xu",
                "Junda He",
                "David Lo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04076v2",
                "http://arxiv.org/pdf/2309.04076v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04069v2",
            "title": "Inferring physical laws by artificial intelligence based causal models",
            "updated": "2023-11-09T12:05:53Z",
            "published": "2023-09-08T01:50:32Z",
            "summary": "The advances in Artificial Intelligence (AI) and Machine Learning (ML) have\nopened up many avenues for scientific research, and are adding new dimensions\nto the process of knowledge creation. However, even the most powerful and\nversatile of ML applications till date are primarily in the domain of analysis\nof associations and boil down to complex data fitting. Judea Pearl has pointed\nout that Artificial General Intelligence must involve interventions involving\nthe acts of doing and imagining. Any machine assisted scientific discovery thus\nmust include casual analysis and interventions. In this context, we propose a\ncausal learning model of physical principles, which not only recognizes\ncorrelations but also brings out casual relationships. We use the principles of\ncausal inference and interventions to study the cause-and-effect relationships\nin the context of some well-known physical phenomena. We show that this\ntechnique can not only figure out associations among data, but is also able to\ncorrectly ascertain the cause-and-effect relations amongst the variables,\nthereby strengthening (or weakening) our confidence in the proposed model of\nthe underlying physical process.",
            "author": [
                "Jorawar Singh",
                "Kishor Bharti",
                "Arvind"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04069v2",
                "http://arxiv.org/pdf/2309.04069v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "physics.data-an",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04062v1",
            "title": "3D Denoisers are Good 2D Teachers: Molecular Pretraining via Denoising\n  and Cross-Modal Distillation",
            "updated": "2023-09-08T01:36:58Z",
            "published": "2023-09-08T01:36:58Z",
            "summary": "Pretraining molecular representations from large unlabeled data is essential\nfor molecular property prediction due to the high cost of obtaining\nground-truth labels. While there exist various 2D graph-based molecular\npretraining approaches, these methods struggle to show statistically\nsignificant gains in predictive performance. Recent work have thus instead\nproposed 3D conformer-based pretraining under the task of denoising, which led\nto promising results. During downstream finetuning, however, models trained\nwith 3D conformers require accurate atom-coordinates of previously unseen\nmolecules, which are computationally expensive to acquire at scale. In light of\nthis limitation, we propose D&D, a self-supervised molecular representation\nlearning framework that pretrains a 2D graph encoder by distilling\nrepresentations from a 3D denoiser. With denoising followed by cross-modal\nknowledge distillation, our approach enjoys use of knowledge obtained from\ndenoising as well as painless application to downstream tasks with no access to\naccurate conformers. Experiments on real-world molecular property prediction\ndatasets show that the graph encoder trained via D&D can infer 3D information\nbased on the 2D graph and shows superior performance and label-efficiency\nagainst other baselines.",
            "author": [
                "Sungjun Cho",
                "Dae-Woong Jeong",
                "Sung Moon Ko",
                "Jinwoo Kim",
                "Sehui Han",
                "Seunghoon Hong",
                "Honglak Lee",
                "Moontae Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04062v1",
                "http://arxiv.org/pdf/2309.04062v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04054v1",
            "title": "Can we \"effectivize'' spacetime?",
            "updated": "2023-09-08T00:59:28Z",
            "published": "2023-09-08T00:59:28Z",
            "summary": "According to \\textit{effective realism}, scientific theories give us\nknowledge about the unobservable world, but not at the fundamental level. This\nview is justified by the well-received \\textit{effective-field-theory} (EFT)\napproach to physics, according to which our best physical theories are only\napplicable up to a certain energy scale and expected to break down beyond that.\nIn this paper, I explain the motivations for the EFT approach and effective\nrealism and their benefits. I also raise new challenges for this approach.\nApplying effective realism to \\textit{effective quantum gravity} (EQG) reveals\nits shortcomings: EQG does not give us a realistic theory of spacetime even\nwithin its scope of validity. It also exposes a general interpretative dilemma\nfaced by all EFTs concerning their indispensable references to classical\nspacetime beyond their scope of validity.",
            "author": [
                "Lu Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.shpsa.2022.07.004",
                "http://arxiv.org/abs/2309.04054v1",
                "http://arxiv.org/pdf/2309.04054v1"
            ],
            "primary_category": "physics.hist-ph",
            "category": [
                "physics.hist-ph",
                "gr-qc",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04499v1",
            "title": "Weighted Unsupervised Domain Adaptation Considering Geometry Features\n  and Engineering Performance of 3D Design Data",
            "updated": "2023-09-08T00:26:44Z",
            "published": "2023-09-08T00:26:44Z",
            "summary": "The product design process in manufacturing involves iterative design\nmodeling and analysis to achieve the target engineering performance, but such\nan iterative process is time consuming and computationally expensive. Recently,\ndeep learning-based engineering performance prediction models have been\nproposed to accelerate design optimization. However, they only guarantee\npredictions on training data and may be inaccurate when applied to new domain\ndata. In particular, 3D design data have complex features, which means domains\nwith various distributions exist. Thus, the utilization of deep learning has\nlimitations due to the heavy data collection and training burdens. We propose a\nbi-weighted unsupervised domain adaptation approach that considers the geometry\nfeatures and engineering performance of 3D design data. It is specialized for\ndeep learning-based engineering performance predictions. Domain-invariant\nfeatures can be extracted through an adversarial training strategy by using\nhypothesis discrepancy, and a multi-output regression task can be performed\nwith the extracted features to predict the engineering performance. In\nparticular, we present a source instance weighting method suitable for 3D\ndesign data to avoid negative transfers. The developed bi-weighting strategy\nbased on the geometry features and engineering performance of engineering\nstructures is incorporated into the training process. The proposed model is\ntested on a wheel impact analysis problem to predict the magnitude of the\nmaximum von Mises stress and the corresponding location of 3D road wheels. This\nmechanism can reduce the target risk for unlabeled target domains on the basis\nof weighted multi-source domain knowledge and can efficiently replace\nconventional finite element analysis.",
            "author": [
                "Seungyeon Shin",
                "Namwoo Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04499v1",
                "http://arxiv.org/pdf/2309.04499v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.13054v1",
            "title": "Data Commons",
            "updated": "2023-09-08T00:14:09Z",
            "published": "2023-09-08T00:14:09Z",
            "summary": "Publicly available data from open sources (e.g., United States Census Bureau\n(Census), World Health Organization (WHO), Intergovernmental Panel on Climate\nChange (IPCC)) are vital resources for policy makers, students and researchers\nacross different disciplines. Combining data from different sources requires\nthe user to reconcile the differences in schemas, formats, assumptions, and\nmore. This data wrangling is time consuming, tedious and needs to be repeated\nby every user of the data. Our goal with Data Commons (DC) is to help make\npublic data accessible and useful to those who want to understand this data and\nuse it to solve societal challenges and opportunities. We do the data\nprocessing and make the processed data widely available via standard schemas\nand Cloud APIs. Data Commons is a distributed network of sites that publish\ndata in a common schema and interoperate using the Data Commons APIs. Data from\ndifferent Data Commons can be joined easily. The aggregate of these Data\nCommons can be viewed as a single Knowledge Graph. This Knowledge Graph can\nthen be searched over using Natural Language questions utilizing advances in\nLarge Language Models. This paper describes the architecture of Data Commons,\nsome of the major deployments and highlights directions for future work.",
            "author": [
                "Ramanathan V. Guha",
                "Prashanth Radhakrishnan",
                "Bo Xu",
                "Wei Sun",
                "Carolyn Au",
                "Ajai Tirumali",
                "Muhammad J. Amjad",
                "Samantha Piekos",
                "Natalie Diaz",
                "Jennifer Chen",
                "Julia Wu",
                "Prem Ramaswami",
                "James Manyika"
            ],
            "link": [
                "http://arxiv.org/abs/2309.13054v1",
                "http://arxiv.org/pdf/2309.13054v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04046v1",
            "title": "The mean-field Limit of sparse networks of integrate and fire neurons",
            "updated": "2023-09-07T23:28:35Z",
            "published": "2023-09-07T23:28:35Z",
            "summary": "We study the mean-field limit of a model of biological neuron networks based\non the so-called stochastic integrate-and-fire (IF) dynamics. Our approach\nallows to derive a continuous limit for the macroscopic behavior of the system,\nthe 1-particle distribution, for a large number of neurons with no structural\nassumptions on the connection map outside of a generalized mean-field scaling.\nWe propose a novel notion of observables that naturally extends the notion of\nmarginals to systems with non-identical or non-exchangeable agents. Our new\nobservables satisfy a complex approximate hierarchy, essentially a tree-indexed\nextension of the classical BBGKY hierarchy. We are able to pass to the limit in\nthis hierarchy as the number of neurons increases through novel quantitative\nstability estimates in some adapted weak norm. While we require non-vanishing\ndiffusion, this approach notably addresses the challenges of sparse interacting\ngraphs/matrices and singular interactions from Poisson jumps, and requires no\nadditional regularity on the initial distribution.",
            "author": [
                "Pierre-Emmanuel Jabin",
                "Datong Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04046v1",
                "http://arxiv.org/pdf/2309.04046v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.AP",
                "nlin.AO",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07080v2",
            "title": "Bayesian Dynamic DAG Learning: Application in Discovering Dynamic\n  Effective Connectome of Brain",
            "updated": "2023-10-29T11:47:28Z",
            "published": "2023-09-07T22:54:06Z",
            "summary": "Understanding the complex mechanisms of the brain can be unraveled by\nextracting the Dynamic Effective Connectome (DEC). Recently, score-based\nDirected Acyclic Graph (DAG) discovery methods have shown significant\nimprovements in extracting the causal structure and inferring effective\nconnectivity. However, learning DEC through these methods still faces two main\nchallenges: one with the fundamental impotence of high-dimensional dynamic DAG\ndiscovery methods and the other with the low quality of fMRI data. In this\npaper, we introduce Bayesian Dynamic DAG learning with M-matrices Acyclicity\ncharacterization \\textbf{(BDyMA)} method to address the challenges in\ndiscovering DEC. The presented dynamic causal model enables us to discover\nbidirected edges as well. Leveraging an unconstrained framework in the BDyMA\nmethod leads to more accurate results in detecting high-dimensional networks,\nachieving sparser outcomes, making it particularly suitable for extracting DEC.\nAdditionally, the score function of the BDyMA method allows the incorporation\nof prior knowledge into the process of dynamic causal discovery which further\nenhances the accuracy of results. Comprehensive simulations on synthetic data\nand experiments on Human Connectome Project (HCP) data demonstrate that our\nmethod can handle both of the two main challenges, yielding more accurate and\nreliable DEC compared to state-of-the-art and baseline methods. Additionally,\nwe investigate the trustworthiness of DTI data as prior knowledge for DEC\ndiscovery and show the improvements in DEC discovery when the DTI data is\nincorporated into the process.",
            "author": [
                "Abdolmahdi Bagheri",
                "Mohammad Pasande",
                "Kevin Bello",
                "Babak Nadjar Araabi",
                "Alireza Akhondi-Asl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07080v2",
                "http://arxiv.org/pdf/2309.07080v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04039v1",
            "title": "Use of Interactive Simulations in Fundamentals of Biochemistry, a\n  LibreText Online Educational Resource, to Promote Understanding of Dynamic\n  Reactions",
            "updated": "2023-09-07T22:38:16Z",
            "published": "2023-09-07T22:38:16Z",
            "summary": "Biology is perhaps the most complex of the sciences, given the incredible\nvariety of chemical species that are interconnected in spatial and temporal\npathways that are daunting to understand. Their interconnections lead to\nemergent properties such as memory, consciousness, and recognition of self and\nnon-self. To understand how these interconnected reactions lead to cellular\nlife characterized by activation, inhibition, regulation, homeostasis, and\nadaptation, computational analyses and simulations are essential, a fact\nrecognized by the biological communities. At the same time, students struggle\nto understand and apply binding and kinetic analyses for the simplest reactions\nsuch as the irreversible first-order conversion of a single reactant to a\nproduct. This likely results from cognitive difficulties in combining\nstructural, chemical, mathematical, and textual descriptions of binding and\ncatalytic reactions. To help students better understand dynamic reactions and\ntheir analyses, we have introduced two kinds of interactive graphs and\nsimulations into the online educational resource, Fundamentals of Biochemistry,\na multivolume biochemistry textbook that is part of the LibreText collection.\nOne type is available for simple binding and kinetic reactions. The other\ndisplays progress curves (concentrations vs time) for both simple reactions and\nmore complex metabolic and signal transduction pathways, including those\navailable through databases using systems biology markup language (SBML) files.\nUsers can move sliders to change dissociation and kinetic constants as well as\ninitial concentrations and see instantaneous changes in the graphs. They can\nalso export data into a spreadsheet for further processing, such as producing\nderivative Lineweaver-Burk and traditional Michaelis-Menten graphs of initial\nvelocity (v0) vs substrate concentration.",
            "author": [
                "Henry V. Jakubowski",
                "Henry Agnew",
                "Bartholomew E. Jardine",
                "Herbert M. Sauro"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04039v1",
                "http://arxiv.org/pdf/2309.04039v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04031v1",
            "title": "Multiple Representation Transfer from Large Language Models to\n  End-to-End ASR Systems",
            "updated": "2023-09-07T21:57:39Z",
            "published": "2023-09-07T21:57:39Z",
            "summary": "Transferring the knowledge of large language models (LLMs) is a promising\ntechnique to incorporate linguistic knowledge into end-to-end automatic speech\nrecognition (ASR) systems. However, existing works only transfer a single\nrepresentation of LLM (e.g. the last layer of pretrained BERT), while the\nrepresentation of a text is inherently non-unique and can be obtained variously\nfrom different layers, contexts and models. In this work, we explore a wide\nrange of techniques to obtain and transfer multiple representations of LLMs\ninto a transducer-based ASR system. While being conceptually simple, we show\nthat transferring multiple representations of LLMs can be an effective\nalternative to transferring only a single representation.",
            "author": [
                "Takuma Udagawa",
                "Masayuki Suzuki",
                "Gakuto Kurata",
                "Masayasu Muraoka",
                "George Saon"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04031v1",
                "http://arxiv.org/pdf/2309.04031v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04019v1",
            "title": "Evaluation of large language models for discovery of gene set function",
            "updated": "2023-09-07T21:10:48Z",
            "published": "2023-09-07T21:10:48Z",
            "summary": "Gene set analysis is a mainstay of functional genomics, but it relies on\nmanually curated databases of gene functions that are incomplete and unaware of\nbiological context. Here we evaluate the ability of OpenAI's GPT-4, a Large\nLanguage Model (LLM), to develop hypotheses about common gene functions from\nits embedded biomedical knowledge. We created a GPT-4 pipeline to label gene\nsets with names that summarize their consensus functions, substantiated by\nanalysis text and citations. Benchmarking against named gene sets in the Gene\nOntology, GPT-4 generated very similar names in 50% of cases, while in most\nremaining cases it recovered the name of a more general concept. In gene sets\ndiscovered in 'omics data, GPT-4 names were more informative than gene set\nenrichment, with supporting statements and citations that largely verified in\nhuman review. The ability to rapidly synthesize common gene functions positions\nLLMs as valuable functional genomics assistants.",
            "author": [
                "Mengzhou Hu",
                "Sahar Alkhairy",
                "Ingoo Lee",
                "Rudolf T. Pillich",
                "Robin Bachelder",
                "Trey Ideker",
                "Dexter Pratt"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04019v1",
                "http://arxiv.org/pdf/2309.04019v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.AI",
                "cs.CL",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04006v1",
            "title": "Reachable set-based dynamic quantization for the remote state estimation\n  of linear systems",
            "updated": "2023-09-07T20:21:23Z",
            "published": "2023-09-07T20:21:23Z",
            "summary": "We employ reachability analysis in designing dynamic quantization schemes for\nthe remote state estimation of linear systems over a finite date rate\ncommunication channel. The quantization region is dynamically updated at each\ntransmission instant, with an approximated reachable set of the linear system.\nWe propose a set-based method using zonotopes and compare it to a norm-based\nmethod in dynamically updating the quantization region. For both methods, we\nguarantee that the quantization error is bounded and consequently, the remote\nstate reconstruction error is also bounded. To the best of our knowledge, the\nset-based method using zonotopes has no precedent in the literature and admits\na larger class of linear systems and communication channels, where the\nset-based method allows for a longer inter-transmission time and lower bit\nrate. Finally, we corroborate our theoretical guarantees with a numerical\nexample.",
            "author": [
                "Yaodong Li",
                "Michelle S. Chong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04006v1",
                "http://arxiv.org/pdf/2309.04006v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03964v1",
            "title": "REALM: Robust Entropy Adaptive Loss Minimization for Improved\n  Single-Sample Test-Time Adaptation",
            "updated": "2023-09-07T18:44:58Z",
            "published": "2023-09-07T18:44:58Z",
            "summary": "Fully-test-time adaptation (F-TTA) can mitigate performance loss due to\ndistribution shifts between train and test data (1) without access to the\ntraining data, and (2) without knowledge of the model training procedure. In\nonline F-TTA, a pre-trained model is adapted using a stream of test samples by\nminimizing a self-supervised objective, such as entropy minimization. However,\nmodels adapted with online using entropy minimization, are unstable especially\nin single sample settings, leading to degenerate solutions, and limiting the\nadoption of TTA inference strategies. Prior works identify noisy, or\nunreliable, samples as a cause of failure in online F-TTA. One solution is to\nignore these samples, which can lead to bias in the update procedure, slow\nadaptation, and poor generalization. In this work, we present a general\nframework for improving robustness of F-TTA to these noisy samples, inspired by\nself-paced learning and robust loss functions. Our proposed approach, Robust\nEntropy Adaptive Loss Minimization (REALM), achieves better adaptation accuracy\nthan previous approaches throughout the adaptation process on corruptions of\nCIFAR-10 and ImageNet-1K, demonstrating its effectiveness.",
            "author": [
                "Skyler Seto",
                "Barry-John Theobald",
                "Federico Danieli",
                "Navdeep Jaitly",
                "Dan Busbridge"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03964v1",
                "http://arxiv.org/pdf/2309.03964v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03895v1",
            "title": "InstructDiffusion: A Generalist Modeling Interface for Vision Tasks",
            "updated": "2023-09-07T17:56:57Z",
            "published": "2023-09-07T17:56:57Z",
            "summary": "We present InstructDiffusion, a unifying and generic framework for aligning\ncomputer vision tasks with human instructions. Unlike existing approaches that\nintegrate prior knowledge and pre-define the output space (e.g., categories and\ncoordinates) for each vision task, we cast diverse vision tasks into a\nhuman-intuitive image-manipulating process whose output space is a flexible and\ninteractive pixel space. Concretely, the model is built upon the diffusion\nprocess and is trained to predict pixels according to user instructions, such\nas encircling the man's left shoulder in red or applying a blue mask to the\nleft car. InstructDiffusion could handle a variety of vision tasks, including\nunderstanding tasks (such as segmentation and keypoint detection) and\ngenerative tasks (such as editing and enhancement). It even exhibits the\nability to handle unseen tasks and outperforms prior methods on novel datasets.\nThis represents a significant step towards a generalist modeling interface for\nvision tasks, advancing artificial general intelligence in the field of\ncomputer vision.",
            "author": [
                "Zigang Geng",
                "Binxin Yang",
                "Tiankai Hang",
                "Chen Li",
                "Shuyang Gu",
                "Ting Zhang",
                "Jianmin Bao",
                "Zheng Zhang",
                "Han Hu",
                "Dong Chen",
                "Baining Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03895v1",
                "http://arxiv.org/pdf/2309.03895v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03893v1",
            "title": "DiffusionEngine: Diffusion Model is Scalable Data Engine for Object\n  Detection",
            "updated": "2023-09-07T17:55:01Z",
            "published": "2023-09-07T17:55:01Z",
            "summary": "Data is the cornerstone of deep learning. This paper reveals that the\nrecently developed Diffusion Model is a scalable data engine for object\ndetection. Existing methods for scaling up detection-oriented data often\nrequire manual collection or generative models to obtain target images,\nfollowed by data augmentation and labeling to produce training pairs, which are\ncostly, complex, or lacking diversity. To address these issues, we\npresentDiffusionEngine (DE), a data scaling-up engine that provides\nhigh-quality detection-oriented training pairs in a single stage. DE consists\nof a pre-trained diffusion model and an effective Detection-Adapter,\ncontributing to generating scalable, diverse and generalizable detection data\nin a plug-and-play manner. Detection-Adapter is learned to align the implicit\nsemantic and location knowledge in off-the-shelf diffusion models with\ndetection-aware signals to make better bounding-box predictions. Additionally,\nwe contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing\ndetection benchmarks for facilitating follow-up research. Extensive experiments\ndemonstrate that data scaling-up via DE can achieve significant improvements in\ndiverse scenarios, such as various detection algorithms, self-supervised\npre-training, data-sparse, label-scarce, cross-domain, and semi-supervised\nlearning. For example, when using DE with a DINO-based adapter to scale up\ndata, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.",
            "author": [
                "Manlin Zhang",
                "Jie Wu",
                "Yuxi Ren",
                "Ming Li",
                "Jie Qin",
                "Xuefeng Xiao",
                "Wei Liu",
                "Rui Wang",
                "Min Zheng",
                "Andy J. Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03893v1",
                "http://arxiv.org/pdf/2309.03893v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03883v1",
            "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large\n  Language Models",
            "updated": "2023-09-07T17:45:31Z",
            "published": "2023-09-07T17:45:31Z",
            "summary": "Despite their impressive capabilities, large language models (LLMs) are prone\nto hallucinations, i.e., generating content that deviates from facts seen\nduring pretraining. We propose a simple decoding strategy for reducing\nhallucinations with pretrained LLMs that does not require conditioning on\nretrieved external knowledge nor additional fine-tuning. Our approach obtains\nthe next-token distribution by contrasting the differences in logits obtained\nfrom projecting the later layers versus earlier layers to the vocabulary space,\nexploiting the fact that factual knowledge in an LLMs has generally been shown\nto be localized to particular transformer layers. We find that this Decoding by\nContrasting Layers (DoLa) approach is able to better surface factual knowledge\nand reduce the generation of incorrect facts. DoLa consistently improves the\ntruthfulness across multiple choices tasks and open-ended generation tasks, for\nexample improving the performance of LLaMA family models on TruthfulQA by\n12-17% absolute points, demonstrating its potential in making LLMs reliably\ngenerate truthful facts.",
            "author": [
                "Yung-Sung Chuang",
                "Yujia Xie",
                "Hongyin Luo",
                "Yoon Kim",
                "James Glass",
                "Pengcheng He"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03883v1",
                "http://arxiv.org/pdf/2309.03883v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03880v1",
            "title": "First passage percolation, local uniqueness for interlacements and\n  capacity of random walk",
            "updated": "2023-09-07T17:44:22Z",
            "published": "2023-09-07T17:44:22Z",
            "summary": "The study of first passage percolation (FPP) for the random interlacements\nmodel has been initiated in arXiv:2112.12096, where it is shown that on\n$\\mathbb{Z}^d$, $d\\geq 3$, the FPP distance is comparable to the graph distance\nwith high probability. In this article, we give an asymptotically sharp lower\nbound on this last probability, which additionally holds on a large class of\ntransient graphs with polynomial volume growth and polynomial decay of the\nGreen function. When considering the interlacement set in the low-intensity\nregime, the previous bound is in fact valid throughout the near-critical phase.\nIn low dimension, we also present two applications of this FPP result: sharp\nlarge deviation bounds on local uniqueness of random interlacements, and on the\ncapacity of a random walk in a ball.",
            "author": [
                "Alexis Pr\u00e9vost"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03880v1",
                "http://arxiv.org/pdf/2309.03880v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP",
                "60K35, 82B43, 60G50, 05C81"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03877v1",
            "title": "Introducing \"Forecast Utterance\" for Conversational Data Science",
            "updated": "2023-09-07T17:41:41Z",
            "published": "2023-09-07T17:41:41Z",
            "summary": "Envision an intelligent agent capable of assisting users in conducting\nforecasting tasks through intuitive, natural conversations, without requiring\nin-depth knowledge of the underlying machine learning (ML) processes. A\nsignificant challenge for the agent in this endeavor is to accurately\ncomprehend the user's prediction goals and, consequently, formulate precise ML\ntasks. In this paper, we take a pioneering step towards this ambitious goal by\nintroducing a new concept called Forecast Utterance and then focus on the\nautomatic and accurate interpretation of users' prediction goals from these\nutterances. Specifically, we frame the task as a slot-filling problem, where\neach slot corresponds to a specific aspect of the goal prediction task. We then\nemploy two zero-shot methods for solving the slot-filling task, namely: 1)\nEntity Extraction (EE), and 2) Question-Answering (QA) techniques. Our\nexperiments, conducted with three meticulously crafted data sets, validate the\nviability of our ambitious goal and demonstrate the effectiveness of both EE\nand QA techniques in interpreting Forecast Utterances.",
            "author": [
                "Md Mahadi Hassan",
                "Alex Knipper",
                "Shubhra Kanti Karmaker"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03877v1",
                "http://arxiv.org/pdf/2309.03877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03852v2",
            "title": "FLM-101B: An Open LLM and How to Train It with $100K Budget",
            "updated": "2023-09-17T07:38:10Z",
            "published": "2023-09-07T17:07:36Z",
            "summary": "Large language models (LLMs) have achieved remarkable success in NLP and\nmultimodal tasks, among others. Despite these successes, two main challenges\nremain in developing LLMs: (i) high computational cost, and (ii) fair and\nobjective evaluations. In this paper, we report a solution to significantly\nreduce LLM training cost through a growth strategy. We demonstrate that a\n101B-parameter LLM with 0.31T tokens can be trained with a budget of 100K US\ndollars. Inspired by IQ tests, we also consolidate an additional range of\nevaluations on top of existing evaluations that focus on knowledge-oriented\nabilities. These IQ evaluations include symbolic mapping, rule understanding,\npattern mining, and anti-interference. Such evaluations minimize the potential\nimpact of memorization. Experimental results show that our model, named\nFLM-101B, trained with a budget of 100K US dollars, achieves performance\ncomparable to powerful and well-known models, e.g., GPT-3 and GLM-130B,\nespecially on the additional range of IQ evaluations. The checkpoint of\nFLM-101B is released at https://huggingface.co/CofeAI/FLM-101B.",
            "author": [
                "Xiang Li",
                "Yiqun Yao",
                "Xin Jiang",
                "Xuezhi Fang",
                "Xuying Meng",
                "Siqi Fan",
                "Peng Han",
                "Jing Li",
                "Li Du",
                "Bowen Qin",
                "Zheng Zhang",
                "Aixin Sun",
                "Yequan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03852v2",
                "http://arxiv.org/pdf/2309.03852v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03848v2",
            "title": "Bipartite Friends and Strangers Walking on Bipartite Graphs",
            "updated": "2023-09-17T19:24:07Z",
            "published": "2023-09-07T17:03:21Z",
            "summary": "Given $n$-vertex simple graphs $X$ and $Y$, the friends-and-strangers graph\n$\\mathsf{FS}(X, Y)$ has as its vertices all $n!$ bijections from $V(X)$ to\n$V(Y)$, where two bijections are adjacent if and only if they differ on two\nadjacent elements of $V(X)$ whose mappings are adjacent in $Y$. We consider the\nsetting where $X$ and $Y$ are both edge-subgraphs of $K_{r,r}$: due to a parity\nobstruction, $\\mathsf{FS}(X,Y)$ is always disconnected in this setting.\nSharpening a result of Bangachev, we show that if $X$ and $Y$ respectively have\nminimum degrees $\\delta(X)$ and $\\delta(Y)$ and they satisfy $\\delta(X) +\n\\delta(Y) \\geq \\lfloor 3r/2 \\rfloor + 1$, then $\\mathsf{FS}(X,Y)$ has exactly\ntwo connected components. This proves that the cutoff for $\\mathsf{FS}(X,Y)$ to\navoid isolated vertices is equal to the cutoff for $\\mathsf{FS}(X,Y)$ to have\nexactly two connected components. We also consider a probabilistic setup in\nwhich we fix $Y$ to be $K_{r,r}$, but randomly generate $X$ by including each\nedge in $K_{r,r}$ independently with probability $p$. Invoking a result of Zhu,\nwe exhibit a phase transition phenomenon with threshold function $(\\log r)/r$:\nbelow the threshold, $\\mathsf{FS}(X,Y)$ has more than two connected components\nwith high probability, while above the threshold, $\\mathsf{FS}(X,Y)$ has\nexactly two connected components with high probability. Altogether, our results\nsettle a conjecture and completely answer two problems of Alon, Defant, and\nKravitz.",
            "author": [
                "Ryan Jeong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03848v2",
                "http://arxiv.org/pdf/2309.03848v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C35, 05D40, 05C80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03810v1",
            "title": "Three Hardness Results for Graph Similarity Problems",
            "updated": "2023-09-07T16:04:45Z",
            "published": "2023-09-07T16:04:45Z",
            "summary": "Notions of graph similarity provide alternative perspective on the graph\nisomorphism problem and vice-versa. In this paper, we consider measures of\nsimilarity arising from mismatch norms as studied in Gervens and Grohe: the\nedit distance $\\delta_{\\mathcal{E}}$, and the metrics arising from\n$\\ell_p$-operator norms, which we denote by $\\delta_p$ and $\\delta_{|p|}$. We\naddress the following question: can these measures of similarity be used to\ndesign polynomial-time approximation algorithms for graph isomorphism? We show\nthat computing an optimal value of $\\delta_{\\mathcal{E}}$ is \\NP-hard on pairs\nof graphs with the same number of edges. In addition, we show that computing\noptimal values of $\\delta_p$ and $\\delta_{|p|}$ is \\NP-hard even on pairs of\n$1$-planar graphs with the same degree sequence and bounded degree. These two\nresults improve on previous known ones, which did not examine the restricted\ncase where the pairs of graphs are required to have the same number of edges.\n  Finally, we study similarity problems on strongly regular graphs and prove\nsome near optimal inequalities with interesting consequences on the\ncomputational complexity of graph and group isomorphism.",
            "author": [
                "He Sun",
                "Danny Vagnozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03810v1",
                "http://arxiv.org/pdf/2309.03810v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03809v1",
            "title": "SimNP: Learning Self-Similarity Priors Between Neural Points",
            "updated": "2023-09-07T16:02:40Z",
            "published": "2023-09-07T16:02:40Z",
            "summary": "Existing neural field representations for 3D object reconstruction either (1)\nutilize object-level representations, but suffer from low-quality details due\nto conditioning on a global latent code, or (2) are able to perfectly\nreconstruct the observations, but fail to utilize object-level prior knowledge\nto infer unobserved regions. We present SimNP, a method to learn category-level\nself-similarities, which combines the advantages of both worlds by connecting\nneural point radiance fields with a category-level self-similarity\nrepresentation. Our contribution is two-fold. (1) We design the first neural\npoint representation on a category level by utilizing the concept of coherent\npoint clouds. The resulting neural point radiance fields store a high level of\ndetail for locally supported object regions. (2) We learn how information is\nshared between neural points in an unconstrained and unsupervised fashion,\nwhich allows to derive unobserved regions of an object during the\nreconstruction process from given observations. We show that SimNP is able to\noutperform previous methods in reconstructing symmetric unseen object regions,\nsurpassing methods that build upon category-level or pixel-aligned radiance\nfields, while providing semantic correspondences between instances",
            "author": [
                "Christopher Wewer",
                "Eddy Ilg",
                "Bernt Schiele",
                "Jan Eric Lenssen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03809v1",
                "http://arxiv.org/pdf/2309.03809v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03800v2",
            "title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and\n  Luck",
            "updated": "2023-10-30T15:32:25Z",
            "published": "2023-09-07T15:52:48Z",
            "summary": "In modern deep learning, algorithmic choices (such as width, depth, and\nlearning rate) are known to modulate nuanced resource tradeoffs. This work\ninvestigates how these complexities necessarily arise for feature learning in\nthe presence of computational-statistical gaps. We begin by considering offline\nsparse parity learning, a supervised classification problem which admits a\nstatistical query lower bound for gradient-based training of a multilayer\nperceptron. This lower bound can be interpreted as a multi-resource tradeoff\nfrontier: successful learning can only occur if one is sufficiently rich (large\nmodel), knowledgeable (large dataset), patient (many training iterations), or\nlucky (many random guesses). We show, theoretically and experimentally, that\nsparse initialization and increasing network width yield significant\nimprovements in sample efficiency in this setting. Here, width plays the role\nof parallel search: it amplifies the probability of finding \"lottery ticket\"\nneurons, which learn sparse features more sample-efficiently. Finally, we show\nthat the synthetic sparse parity task can be useful as a proxy for real\nproblems requiring axis-aligned feature learning. We demonstrate improved\nsample efficiency on tabular classification benchmarks by using wide,\nsparsely-initialized MLP models; these networks sometimes outperform tuned\nrandom forests.",
            "author": [
                "Benjamin L. Edelman",
                "Surbhi Goel",
                "Sham Kakade",
                "Eran Malach",
                "Cyril Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03800v2",
                "http://arxiv.org/pdf/2309.03800v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03799v1",
            "title": "FisheyePP4AV: A privacy-preserving method for autonomous vehicles on\n  fisheye camera images",
            "updated": "2023-09-07T15:51:31Z",
            "published": "2023-09-07T15:51:31Z",
            "summary": "In many parts of the world, the use of vast amounts of data collected on\npublic roadways for autonomous driving has increased. In order to detect and\nanonymize pedestrian faces and nearby car license plates in actual road-driving\nscenarios, there is an urgent need for effective solutions. As more data is\ncollected, privacy concerns regarding it increase, including but not limited to\npedestrian faces and surrounding vehicle license plates. Normal and fisheye\ncameras are the two common camera types that are typically mounted on\ncollection vehicles. With complex camera distortion models, fisheye camera\nimages were deformed in contrast to regular images. It causes computer vision\ntasks to perform poorly when using numerous deep learning models. In this work,\nwe pay particular attention to protecting privacy while yet adhering to several\nlaws for fisheye camera photos taken by driverless vehicles. First, we suggest\na framework for extracting face and plate identification knowledge from several\nteacher models. Our second suggestion is to transform both the image and the\nlabel from a regular image to fisheye-like data using a varied and realistic\nfisheye transformation. Finally, we run a test using the open-source PP4AV\ndataset. The experimental findings demonstrated that our model outperformed\nbaseline methods when trained on data from autonomous vehicles, even when the\ndata were softly labeled. The implementation code is available at our github:\nhttps://github.com/khaclinh/FisheyePP4AV.",
            "author": [
                "Linh Trinh",
                "Bach Ha",
                "Tu Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03799v1",
                "http://arxiv.org/pdf/2309.03799v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03791v1",
            "title": "Adversarially Robust Deep Learning with Optimal-Transport-Regularized\n  Divergences",
            "updated": "2023-09-07T15:41:45Z",
            "published": "2023-09-07T15:41:45Z",
            "summary": "We introduce the $ARMOR_D$ methods as novel approaches to enhancing the\nadversarial robustness of deep learning models. These methods are based on a\nnew class of optimal-transport-regularized divergences, constructed via an\ninfimal convolution between an information divergence and an optimal-transport\n(OT) cost. We use these as tools to enhance adversarial robustness by\nmaximizing the expected loss over a neighborhood of distributions, a technique\nknown as distributionally robust optimization. Viewed as a tool for\nconstructing adversarial samples, our method allows samples to be both\ntransported, according to the OT cost, and re-weighted, according to the\ninformation divergence. We demonstrate the effectiveness of our method on\nmalware detection and image recognition applications and find that, to our\nknowledge, it outperforms existing methods at enhancing the robustness against\nadversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\\%$\nagainst $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing\nthe error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to\nprior methods. Similarly, in malware detection, a discrete (binary) data\ndomain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack\ncompared to the previous best-performing adversarial training methods by\n$37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and\n$57.53\\%$, respectively.",
            "author": [
                "Jeremiah Birrell",
                "Mohammadreza Ebrahimi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03791v1",
                "http://arxiv.org/pdf/2309.03791v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03790v1",
            "title": "TaleStream: Supporting Story Ideation with Trope Knowledge",
            "updated": "2023-09-07T15:40:06Z",
            "published": "2023-09-07T15:40:06Z",
            "summary": "Story ideation is a critical part of the story-writing process. It is\nchallenging to support computationally due to its exploratory and subjective\nnature. Tropes, which are recurring narrative elements across stories, are\nessential in stories as they shape the structure of narratives and our\nunderstanding of them. In this paper, we propose to use tropes as an\nintermediate representation of stories to approach story ideation. We present\nTaleStream, a canvas system that uses tropes as building blocks of stories\nwhile providing steerable suggestions of story ideas in the form of tropes. Our\ntrope suggestion methods leverage data from the tvtropes.org wiki. We find that\n97% of the time, trope suggestions generated by our methods provide better\nstory ideation materials than random tropes. Our system evaluation suggests\nthat TaleStream can support writers' creative flow and greatly facilitates\nstory development. Tropes, as a rich lexicon of narratives with available\nexamples, play a key role in TaleStream and hold promise for story-creation\nsupport systems.",
            "author": [
                "Jean-Pe\u00efc Chou",
                "Alexa F. Siu",
                "Nedim Lipka",
                "Ryan Rossi",
                "Franck Dernoncourt",
                "Maneesh Agrawala"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3586183.3606807",
                "http://arxiv.org/abs/2309.03790v1",
                "http://arxiv.org/pdf/2309.03790v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "D.2.2; H.1.2; H.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03773v1",
            "title": "Extending Transductive Knowledge Graph Embedding Models for Inductive\n  Logical Relational Inference",
            "updated": "2023-09-07T15:24:18Z",
            "published": "2023-09-07T15:24:18Z",
            "summary": "Many downstream inference tasks for knowledge graphs, such as relation\nprediction, have been handled successfully by knowledge graph embedding\ntechniques in the transductive setting. To address the inductive setting\nwherein new entities are introduced into the knowledge graph at inference time,\nmore recent work opts for models which learn implicit representations of the\nknowledge graph through a complex function of a network's subgraph structure,\noften parametrized by graph neural network architectures. These come at the\ncost of increased parametrization, reduced interpretability and limited\ngeneralization to other downstream inference tasks. In this work, we bridge the\ngap between traditional transductive knowledge graph embedding approaches and\nmore recent inductive relation prediction models by introducing a generalized\nform of harmonic extension which leverages representations learned through\ntransductive embedding methods to infer representations of new entities\nintroduced at inference time as in the inductive setting. This harmonic\nextension technique provides the best such approximation, can be implemented\nvia an efficient iterative scheme, and can be employed to answer a family of\nconjunctive logical queries over the knowledge graph, further expanding the\ncapabilities of transductive embedding methods. In experiments on a number of\nlarge-scale knowledge graph embedding benchmarks, we find that this approach\nfor extending the functionality of transductive knowledge graph embedding\nmodels to perform knowledge graph completion and answer logical queries in the\ninductive setting is competitive with--and in some scenarios\noutperforms--several state-of-the-art models derived explicitly for such\ninductive tasks.",
            "author": [
                "Thomas Gebhart",
                "John Cobb"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03773v1",
                "http://arxiv.org/pdf/2309.03773v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03769v1",
            "title": "Min-max optimization over slowly time-varying graphs",
            "updated": "2023-09-07T15:16:44Z",
            "published": "2023-09-07T15:16:44Z",
            "summary": "Distributed optimization is an important direction of research in modern\noptimization theory. Its applications include large scale machine learning,\ndistributed signal processing and many others. The paper studies decentralized\nmin-max optimization for saddle point problems. Saddle point problems arise in\ntraining adversarial networks and in robust machine learning. The focus of the\nwork is optimization over (slowly) time-varying networks. The topology of the\nnetwork changes from time to time, and the velocity of changes is limited. We\nshow that, analogically to decentralized optimization, it is sufficient to\nchange only two edges per iteration in order to slow down convergence to the\narbitrary time-varying case. At the same time, we investigate several classes\nof time-varying graphs for which the communication complexity can be reduced.",
            "author": [
                "Nhat Trung Nguyen",
                "Alexander Rogozin",
                "Dmitry Metelev",
                "Alexander Gasnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03769v1",
                "http://arxiv.org/pdf/2309.03769v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03758v1",
            "title": "Hybrid of representation learning and reinforcement learning for dynamic\n  and complex robotic motion planning",
            "updated": "2023-09-07T15:00:49Z",
            "published": "2023-09-07T15:00:49Z",
            "summary": "Motion planning is the soul of robot decision making. Classical planning\nalgorithms like graph search and reaction-based algorithms face challenges in\ncases of dense and dynamic obstacles. Deep learning algorithms generate\nsuboptimal one-step predictions that cause many collisions. Reinforcement\nlearning algorithms generate optimal or near-optimal time-sequential\npredictions. However, they suffer from slow convergence, suboptimal converged\nresults, and overfittings. This paper introduces a hybrid algorithm for robotic\nmotion planning: long short-term memory (LSTM) pooling and skip connection for\nattention-based discrete soft actor critic (LSA-DSAC). First, graph network\n(relational graph) and attention network (attention weight) interpret the\nenvironmental state for the learning of the discrete soft actor critic\nalgorithm. The expressive power of attention network outperforms that of graph\nin our task by difference analysis of these two representation methods.\nHowever, attention based DSAC faces the overfitting problem in training.\nSecond, the skip connection method is integrated to attention based DSAC to\nmitigate overfitting and improve convergence speed. Third, LSTM pooling is\ntaken to replace the sum operator of attention weigh and eliminate overfitting\nby slightly sacrificing convergence speed at early-stage training. Experiments\nshow that LSA-DSAC outperforms the state-of-the-art in training and most\nevaluations. The physical robot is also implemented and tested in the real\nworld.",
            "author": [
                "Chengmin Zhou",
                "Xin Lu",
                "Jiapeng Dai",
                "Bingding Huang",
                "Xiaoxu Liu",
                "Pasi Fr\u00e4nti"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03758v1",
                "http://arxiv.org/pdf/2309.03758v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03757v1",
            "title": "Compact metric spaces with infinite cop number",
            "updated": "2023-09-07T15:00:46Z",
            "published": "2023-09-07T15:00:46Z",
            "summary": "Mohar recently adapted the classical game of Cops and Robber from graphs to\nmetric spaces, thereby unifying previously studied pursuit-evasion games. He\nconjectured that finitely many cops can win on any compact geodesic metric\nspace, and that their number can be upper-bounded in terms of the ranks of the\nhomology groups when the space is a simplicial pseudo-manifold. We disprove\nthese conjectures by constructing a metric on $\\mathbb{S}^3$ with infinite cop\nnumber. More problems are raised than settled.",
            "author": [
                "Agelos Georgakopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03757v1",
                "http://arxiv.org/pdf/2309.03757v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.MG",
                "math.OC",
                "91A44, 05C57, 91A24, 91A05, 49N75"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03728v1",
            "title": "Adjacency Sketches in Adversarial Environments",
            "updated": "2023-09-07T14:13:44Z",
            "published": "2023-09-07T14:13:44Z",
            "summary": "An adjacency sketching or implicit labeling scheme for a family $\\cal F$ of\ngraphs is a method that defines for any $n$ vertex $G \\in \\cal F$ an assignment\nof labels to each vertex in $G$, so that the labels of two vertices tell you\nwhether or not they are adjacent. The goal is to come up with labeling schemes\nthat use as few bits as possible to represent the labels. By using randomness\nwhen assigning labels, it is sometimes possible to produce adjacency sketches\nwith much smaller label sizes, but this comes at the cost of introducing some\nprobability of error. Both deterministic and randomized labeling schemes have\nbeen extensively studied, as they have applications for distributed data\nstructures and deeper connections to universal graphs and communication\ncomplexity. The main question of interest is which graph families have schemes\nusing short labels, usually $O(\\log n)$ in the deterministic case or constant\nfor randomized sketches.\n  In this work we consider the resilience of probabilistic adjacency sketches\nagainst an adversary making adaptive queries to the labels. This differs from\nthe previously analyzed probabilistic setting which is ``one shot\". We show\nthat in the adaptive adversarial case the size of the labels is tightly related\nto the maximal degree of the graphs in $\\cal F$. This results in a stronger\ncharacterization compared to what is known in the non-adversarial setting. In\nmore detail, we construct sketches that fail with probability $\\varepsilon$ for\ngraphs with maximal degree $d$ using $2d\\log (1/\\varepsilon)$ bit labels and\nshow that this is roughly the best that can be done for any specific graph of\nmaximal degree $d$, e.g.\\ a $d$-ary tree.",
            "author": [
                "Moni Naor",
                "Eugene Pekel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03728v1",
                "http://arxiv.org/pdf/2309.03728v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CR",
                "68W20, 68W40, 68Q87",
                "E.1; F.2.0; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07147v1",
            "title": "DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial\n  Attention Detection",
            "updated": "2023-09-07T13:43:46Z",
            "published": "2023-09-07T13:43:46Z",
            "summary": "Auditory Attention Detection (AAD) aims to detect target speaker from brain\nsignals in a multi-speaker environment. Although EEG-based AAD methods have\nshown promising results in recent years, current approaches primarily rely on\ntraditional convolutional neural network designed for processing Euclidean data\nlike images. This makes it challenging to handle EEG signals, which possess\nnon-Euclidean characteristics. In order to address this problem, this paper\nproposes a dynamical graph self-distillation (DGSD) approach for AAD, which\ndoes not require speech stimuli as input. Specifically, to effectively\nrepresent the non-Euclidean properties of EEG signals, dynamical graph\nconvolutional networks are applied to represent the graph structure of EEG\nsignals, which can also extract crucial features related to auditory spatial\nattention in EEG signals. In addition, to further improve AAD detection\nperformance, self-distillation, consisting of feature distillation and\nhierarchical distillation strategies at each layer, is integrated. These\nstrategies leverage features and classification results from the deepest\nnetwork layers to guide the learning of shallow layers. Our experiments are\nconducted on two publicly available datasets, KUL and DTU. Under a 1-second\ntime window, we achieve results of 90.0\\% and 79.6\\% accuracy on KUL and DTU,\nrespectively. We compare our DGSD method with competitive baselines, and the\nexperimental results indicate that the detection performance of our proposed\nDGSD method is not only superior to the best reproducible baseline but also\nsignificantly reduces the number of trainable parameters by approximately 100\ntimes.",
            "author": [
                "Cunhang Fan",
                "Hongyu Zhang",
                "Wei Huang",
                "Jun Xue",
                "Jianhua Tao",
                "Jiangyan Yi",
                "Zhao Lv",
                "Xiaopei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07147v1",
                "http://arxiv.org/pdf/2309.07147v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.HC",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03703v1",
            "title": "Enhanced strength-ductility combination by introducing bimodal grains\n  structures in high-density oxide dispersion strengthened FeCrAl alloys\n  fabricated by spark plasma sintering technology",
            "updated": "2023-09-07T13:31:04Z",
            "published": "2023-09-07T13:31:04Z",
            "summary": "Oxide dispersion strengthened FeCrAl alloys dispersed high-density\nnano-oxides in the matrix show outstanding corrosion resistance and mechanical\nproperties. However, ODS FeCrAl alloys achieve the high strength generally at\nthe expense of ductility in some way. Here, a method by introducing a bimodal\ngrain structure was designed to overcome the strength-ductility tradeoff. In\nthis work, ODS FeCrAl alloys were successfully fabricated through various\nmechanical alloying time, combined with spark plasma sintering under the vacuum\nof less than 4Pa. Microstructural characterization showed that the average\ngrains size and nano-oxides size decrease gradually, and the density of\nnano-oxides increases, as the milling time increases. Mechanical properties\nrevealed that both the strength and ductility were significantly synergistic\nenhanced with increasing milling time. The bimodal grain distribution\ncharacterized by electron backscatter diffraction (EBSD) (vacuum degree was\nless than 5E-5pa) was beneficial for the activation of the back stress\nstrengthening and the annihilation of these microcracks, thus achieving the\nexcellent ductility (27.65%). In addition, transmission electron microscope\n(TEM) characterization under the vacuum degree of less than 10-6pa illustrated\nthat ultra-high-density nano-oxides (9.61E22/m3) was crucial for enhancing the\nstrength of ODS FeCrAl alloys (993MPa). The strengthening mechanism\nsuperposition, based on the model of nano-oxides interrelated with the\ndislocation, illustrated an excellent agreement with experimental results from\nyield strength strengthening mechanisms. To our best knowledge, H40 (milled for\n40h, and sintered at 1100C) alloy presents the outstanding strength with the\nexceptional ductility among all studied ODS FeCrAl alloys, which makes it the\npromising cladding materials for the accident tolerant fuel cladding.",
            "author": [
                "Xu Yan",
                "Zhifeng Li",
                "Haoxian Yang",
                "Sheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03703v1",
                "http://arxiv.org/pdf/2309.03703v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03696v1",
            "title": "Efficient Adaptive Human-Object Interaction Detection with\n  Concept-guided Memory",
            "updated": "2023-09-07T13:10:06Z",
            "published": "2023-09-07T13:10:06Z",
            "summary": "Human Object Interaction (HOI) detection aims to localize and infer the\nrelationships between a human and an object. Arguably, training supervised\nmodels for this task from scratch presents challenges due to the performance\ndrop over rare classes and the high computational cost and time required to\nhandle long-tailed distributions of HOIs in complex HOI scenes in realistic\nsettings. This observation motivates us to design an HOI detector that can be\ntrained even with long-tailed labeled data and can leverage existing knowledge\nfrom pre-trained models. Inspired by the powerful generalization ability of the\nlarge Vision-Language Models (VLM) on classification and retrieval tasks, we\npropose an efficient Adaptive HOI Detector with Concept-guided Memory (ADA-CM).\nADA-CM has two operating modes. The first mode makes it tunable without\nlearning new parameters in a training-free paradigm. Its second mode\nincorporates an instance-aware adapter mechanism that can further efficiently\nboost performance if updating a lightweight set of parameters can be afforded.\nOur proposed method achieves competitive results with state-of-the-art on the\nHICO-DET and V-COCO datasets with much less training time. Code can be found at\nhttps://github.com/ltttpku/ADA-CM.",
            "author": [
                "Ting Lei",
                "Fabian Caba",
                "Qingchao Chen",
                "Hailin Jin",
                "Yuxin Peng",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03696v1",
                "http://arxiv.org/pdf/2309.03696v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03685v1",
            "title": "PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your\n  Fingertips",
            "updated": "2023-09-07T13:00:09Z",
            "published": "2023-09-07T13:00:09Z",
            "summary": "Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g. an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand knowledge graphs. The synthesized schemas encompass various RDFS and OWL\nconstructs, while the synthesized KGs emulate the characteristics and scale of\nreal-world KGs. Logical consistency of the generated resources is ultimately\nensured by running a description logic (DL) reasoner. By providing a way of\ngenerating both a schema and KG in a single pipeline, PyGraft's aim is to\nempower the generation of a more diverse array of KGs for benchmarking novel\napproaches in areas such as graph-based machine learning (ML), or more\ngenerally KG processing. In graph-based ML in particular, this should foster a\nmore holistic evaluation of model performance and generalization capability,\nthereby going beyond the limited collection of available benchmarks. PyGraft is\navailable at: https://github.com/nicolas-hbt/pygraft.",
            "author": [
                "Nicolas Hubert",
                "Pierre Monnin",
                "Mathieu d'Aquin",
                "Armelle Brun",
                "Davy Monticolo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03685v1",
                "http://arxiv.org/pdf/2309.03685v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03678v1",
            "title": "Fully Onboard SLAM for Distributed Mapping with a Swarm of Nano-Drones",
            "updated": "2023-09-07T12:40:06Z",
            "published": "2023-09-07T12:40:06Z",
            "summary": "The use of Unmanned Aerial Vehicles (UAVs) is rapidly increasing in\napplications ranging from surveillance and first-aid missions to industrial\nautomation involving cooperation with other machines or humans. To maximize\narea coverage and reduce mission latency, swarms of collaborating drones have\nbecome a significant research direction. However, this approach requires open\nchallenges in positioning, mapping, and communications to be addressed. This\nwork describes a distributed mapping system based on a swarm of nano-UAVs,\ncharacterized by a limited payload of 35 g and tightly constrained on-board\nsensing and computing capabilities. Each nano-UAV is equipped with four\n64-pixel depth sensors that measure the relative distance to obstacles in four\ndirections. The proposed system merges the information from the swarm and\ngenerates a coherent grid map without relying on any external infrastructure.\nThe data fusion is performed using the iterative closest point algorithm and a\ngraph-based simultaneous localization and mapping algorithm, running entirely\non-board the UAV's low-power ARM Cortex-M microcontroller with just 192 kB of\nSRAM memory. Field results gathered in three different mazes from a swarm of up\nto 4 nano-UAVs prove a mapping accuracy of 12 cm and demonstrate that the\nmapping time is inversely proportional to the number of agents. The proposed\nframework scales linearly in terms of communication bandwidth and on-board\ncomputational complexity, supporting communication between up to 20 nano-UAVs\nand mapping of areas up to 180 m2 with the chosen configuration requiring only\n50 kB of memory.",
            "author": [
                "Carl Friess",
                "Vlad Niculescu",
                "Tommaso Polonelli",
                "Michele Magno",
                "Luca Benini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03678v1",
                "http://arxiv.org/pdf/2309.03678v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03672v1",
            "title": "A computationally lightweight safe learning algorithm",
            "updated": "2023-09-07T12:21:22Z",
            "published": "2023-09-07T12:21:22Z",
            "summary": "Safety is an essential asset when learning control policies for physical\nsystems, as violating safety constraints during training can lead to expensive\nhardware damage. In response to this need, the field of safe learning has\nemerged with algorithms that can provide probabilistic safety guarantees\nwithout knowledge of the underlying system dynamics. Those algorithms often\nrely on Gaussian process inference. Unfortunately, Gaussian process inference\nscales cubically with the number of data points, limiting applicability to\nhigh-dimensional and embedded systems. In this paper, we propose a safe\nlearning algorithm that provides probabilistic safety guarantees but leverages\nthe Nadaraya-Watson estimator instead of Gaussian processes. For the\nNadaraya-Watson estimator, we can reach logarithmic scaling with the number of\ndata points. We provide theoretical guarantees for the estimates, embed them\ninto a safe learning algorithm, and show numerical experiments on a simulated\nseven-degrees-of-freedom robot manipulator.",
            "author": [
                "Dominik Baumann",
                "Krzysztof Kowalczyk",
                "Koen Tiels",
                "Pawe\u0142 Wachel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03672v1",
                "http://arxiv.org/pdf/2309.03672v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03661v2",
            "title": "Prompt-based Context- and Domain-aware Pretraining for Vision and\n  Language Navigation",
            "updated": "2023-11-30T11:25:33Z",
            "published": "2023-09-07T11:58:34Z",
            "summary": "With strong representation capabilities, pretrained vision-language models\nare widely used in vision and language navigation (VLN). However, most of them\nare trained on web-crawled general-purpose datasets, which incurs a\nconsiderable domain gap when used for VLN tasks. Another challenge for VLN is\nhow the agent understands the contextual relations between actions on a\ntrajectory and performs cross-modal alignment sequentially. In this paper, we\npropose a novel Prompt-bAsed coNtext- and Domain-Aware (PANDA) pretraining\nframework to address these problems. It performs prompting in two stages. In\nthe domain-aware stage, we apply a low-cost prompt tuning paradigm to learn\nsoft visual prompts from an in-domain dataset for equipping the pretrained\nmodels with object-level and scene-level cross-modal alignment in VLN tasks.\nFurthermore, in the context-aware stage, we design a set of hard context\nprompts to capture the sequence-level semantics and instill both out-of-context\nand contextual knowledge in the instruction into cross-modal representations.\nThey enable further tuning of the pretrained models via contrastive learning.\nExperimental results on both R2R and REVERIE show the superiority of PANDA\ncompared to previous state-of-the-art methods.",
            "author": [
                "Ting Liu",
                "Wansen Wu",
                "Yue Hu",
                "Youkai Wang",
                "Kai Xu",
                "Quanjun Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03661v2",
                "http://arxiv.org/pdf/2309.03661v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03660v1",
            "title": "Learning from Limited Heterogeneous Training Data: Meta-Learning for\n  Unsupervised Zero-Day Web Attack Detection across Web Domains",
            "updated": "2023-09-07T11:58:20Z",
            "published": "2023-09-07T11:58:20Z",
            "summary": "Recently unsupervised machine learning based systems have been developed to\ndetect zero-day Web attacks, which can effectively enhance existing Web\nApplication Firewalls (WAFs). However, prior arts only consider detecting\nattacks on specific domains by training particular detection models for the\ndomains. These systems require a large amount of training data, which causes a\nlong period of time for model training and deployment. In this paper, we\npropose RETSINA, a novel meta-learning based framework that enables zero-day\nWeb attack detection across different domains in an organization with limited\ntraining data. Specifically, it utilizes meta-learning to share knowledge\nacross these domains, e.g., the relationship between HTTP requests in\nheterogeneous domains, to efficiently train detection models. Moreover, we\ndevelop an adaptive preprocessing module to facilitate semantic analysis of Web\nrequests across different domains and design a multi-domain representation\nmethod to capture semantic correlations between different domains for\ncross-domain model training. We conduct experiments using four real-world\ndatasets on different domains with a total of 293M Web requests. The\nexperimental results demonstrate that RETSINA outperforms the existing\nunsupervised Web attack detection methods with limited training data, e.g.,\nRETSINA needs only 5-minute training data to achieve comparable detection\nperformance to the existing methods that train separate models for different\ndomains using 1-day training data. We also conduct real-world deployment in an\nInternet company. RETSINA captures on average 126 and 218 zero-day attack\nrequests per day in two domains, respectively, in one month.",
            "author": [
                "Peiyang Li",
                "Ye Wang",
                "Qi Li",
                "Zhuotao Liu",
                "Ke Xu",
                "Ju Ren",
                "Zhiying Liu",
                "Ruilin Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03660v1",
                "http://arxiv.org/pdf/2309.03660v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03659v1",
            "title": "Towards Comparable Knowledge Distillation in Semantic Image Segmentation",
            "updated": "2023-09-07T11:56:23Z",
            "published": "2023-09-07T11:56:23Z",
            "summary": "Knowledge Distillation (KD) is one proposed solution to large model sizes and\nslow inference speed in semantic segmentation. In our research we identify 25\nproposed distillation loss terms from 14 publications in the last 4 years.\nUnfortunately, a comparison of terms based on published results is often\nimpossible, because of differences in training configurations. A good\nillustration of this problem is the comparison of two publications from 2022.\nUsing the same models and dataset, Structural and Statistical Texture\nDistillation (SSTKD) reports an increase of student mIoU of 4.54 and a final\nperformance of 29.19, while Adaptive Perspective Distillation (APD) only\nimproves student performance by 2.06 percentage points, but achieves a final\nperformance of 39.25. The reason for such extreme differences is often a\nsuboptimal choice of hyperparameters and a resulting underperformance of the\nstudent model used as reference point. In our work, we reveal problems of\ninsufficient hyperparameter tuning by showing that distillation improvements of\ntwo widely accepted frameworks, SKD and IFVD, vanish when hyperparameters are\noptimized sufficiently. To improve comparability of future research in the\nfield, we establish a solid baseline for three datasets and two student models\nand provide extensive information on hyperparameter tuning. We find that only\ntwo out of eight techniques can compete with our simple baseline on the ADE20K\ndataset.",
            "author": [
                "Onno Niemann",
                "Christopher Vox",
                "Thorben Werner"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03659v1",
                "http://arxiv.org/pdf/2309.03659v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03658v1",
            "title": "BNS-Net: A Dual-channel Sarcasm Detection Method Considering\n  Behavior-level and Sentence-level Conflicts",
            "updated": "2023-09-07T11:55:11Z",
            "published": "2023-09-07T11:55:11Z",
            "summary": "Sarcasm detection is a binary classification task that aims to determine\nwhether a given utterance is sarcastic. Over the past decade, sarcasm detection\nhas evolved from classical pattern recognition to deep learning approaches,\nwhere features such as user profile, punctuation and sentiment words have been\ncommonly employed for sarcasm detection. In real-life sarcastic expressions,\nbehaviors without explicit sentimental cues often serve as carriers of implicit\nsentimental meanings. Motivated by this observation, we proposed a dual-channel\nsarcasm detection model named BNS-Net. The model considers behavior and\nsentence conflicts in two channels. Channel 1: Behavior-level Conflict Channel\nreconstructs the text based on core verbs while leveraging the modified\nattention mechanism to highlight conflict information. Channel 2:\nSentence-level Conflict Channel introduces external sentiment knowledge to\nsegment the text into explicit and implicit sentences, capturing conflicts\nbetween them. To validate the effectiveness of BNS-Net, several comparative and\nablation experiments are conducted on three public sarcasm datasets. The\nanalysis and evaluation of experimental results demonstrate that the BNS-Net\neffectively identifies sarcasm in text and achieves the state-of-the-art\nperformance.",
            "author": [
                "Liming Zhou",
                "Xiaowei Xu",
                "Xiaodong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03658v1",
                "http://arxiv.org/pdf/2309.03658v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03657v1",
            "title": "Parameters of Quotient-Polynomial Graphs",
            "updated": "2023-09-07T11:50:42Z",
            "published": "2023-09-07T11:50:42Z",
            "summary": "Fiol has characterized quotient-polynomial graphs as precisely the connected\ngraphs whose adjacency matrix generates the adjacency algebra of a symmetric\nassociation scheme. We show that a subset of parameters of size $d +\n\\frac{d(d-1)}{2}$ is adequate for describing all quotient-polynomial graphs\ngenerating a symmetric association scheme of class $d$. We use this to generate\na database of quotient-polynomial graphs with small valency for up to $6$\nclasses, and to determine feasible parameter sets for quotient-polynomial\ngraphs of small valency and up to $6$ classes that would have noncyclotomic\neigenvalues if shown to exist.",
            "author": [
                "Allen Herman",
                "Roghayeh Maleki"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03657v1",
                "http://arxiv.org/pdf/2309.03657v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "Primary 05E30, Secondary 05E16, 05C75, 13P99, 42C05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03651v1",
            "title": "Learning of Generalizable and Interpretable Knowledge in Grid-Based\n  Reinforcement Learning Environments",
            "updated": "2023-09-07T11:46:57Z",
            "published": "2023-09-07T11:46:57Z",
            "summary": "Understanding the interactions of agents trained with deep reinforcement\nlearning is crucial for deploying agents in games or the real world. In the\nformer, unreasonable actions confuse players. In the latter, that effect is\neven more significant, as unexpected behavior cause accidents with potentially\ngrave and long-lasting consequences for the involved individuals. In this work,\nwe propose using program synthesis to imitate reinforcement learning policies\nafter seeing a trajectory of the action sequence. Programs have the advantage\nthat they are inherently interpretable and verifiable for correctness. We adapt\nthe state-of-the-art program synthesis system DreamCoder for learning concepts\nin grid-based environments, specifically, a navigation task and two miniature\nversions of Atari games, Space Invaders and Asterix. By inspecting the\ngenerated libraries, we can make inferences about the concepts the black-box\nagent has learned and better understand the agent's behavior. We achieve the\nsame by visualizing the agent's decision-making process for the imitated\nsequences. We evaluate our approach with different types of program\nsynthesizers based on a search-only method, a neural-guided search, and a\nlanguage model fine-tuned on code.",
            "author": [
                "Manuel Eberhardinger",
                "Johannes Maucher",
                "Setareh Maghsudi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03651v1",
                "http://arxiv.org/pdf/2309.03651v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03648v2",
            "title": "Promoting Fairness in GNNs: A Characterization of Stability",
            "updated": "2023-09-19T16:20:42Z",
            "published": "2023-09-07T11:29:16Z",
            "summary": "The Lipschitz bound, a technique from robust statistics, can limit the\nmaximum changes in the output concerning the input, taking into account\nassociated irrelevant biased factors. It is an efficient and provable method\nfor examining the output stability of machine learning models without incurring\nadditional computation costs. Recently, Graph Neural Networks (GNNs), which\noperate on non-Euclidean data, have gained significant attention. However, no\nprevious research has investigated the GNN Lipschitz bounds to shed light on\nstabilizing model outputs, especially when working on non-Euclidean data with\ninherent biases. Given the inherent biases in common graph data used for GNN\ntraining, it poses a serious challenge to constraining the GNN output\nperturbations induced by input biases, thereby safeguarding fairness during\ntraining. Recently, despite the Lipschitz constant's use in controlling the\nstability of Euclideanneural networks, the calculation of the precise Lipschitz\nconstant remains elusive for non-Euclidean neural networks like GNNs,\nespecially within fairness contexts. To narrow this gap, we begin with the\ngeneral GNNs operating on an attributed graph, and formulate a Lipschitz bound\nto limit the changes in the output regarding biases associated with the input.\nAdditionally, we theoretically analyze how the Lipschitz constant of a GNN\nmodel could constrain the output perturbations induced by biases learned from\ndata for fairness training. We experimentally validate the Lipschitz bound's\neffectiveness in limiting biases of the model output. Finally, from a training\ndynamics perspective, we demonstrate why the theoretical Lipschitz bound can\neffectively guide the GNN training to better trade-off between accuracy and\nfairness.",
            "author": [
                "Yaning Jia",
                "Chunhui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03648v2",
                "http://arxiv.org/pdf/2309.03648v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03647v1",
            "title": "ProvG-Searcher: A Graph Representation Learning Approach for Efficient\n  Provenance Graph Search",
            "updated": "2023-09-07T11:29:01Z",
            "published": "2023-09-07T11:29:01Z",
            "summary": "We present ProvG-Searcher, a novel approach for detecting known APT behaviors\nwithin system security logs. Our approach leverages provenance graphs, a\ncomprehensive graph representation of event logs, to capture and depict data\nprovenance relations by mapping system entities as nodes and their interactions\nas edges. We formulate the task of searching provenance graphs as a subgraph\nmatching problem and employ a graph representation learning method. The central\ncomponent of our search methodology involves embedding of subgraphs in a vector\nspace where subgraph relationships can be directly evaluated. We achieve this\nthrough the use of order embeddings that simplify subgraph matching to\nstraightforward comparisons between a query and precomputed subgraph\nrepresentations. To address challenges posed by the size and complexity of\nprovenance graphs, we propose a graph partitioning scheme and a\nbehavior-preserving graph reduction method. Overall, our technique offers\nsignificant computational efficiency, allowing most of the search computation\nto be performed offline while incorporating a lightweight comparison step\nduring query execution. Experimental results on standard datasets demonstrate\nthat ProvG-Searcher achieves superior performance, with an accuracy exceeding\n99% in detecting query behaviors and a false positive rate of approximately\n0.02%, outperforming other approaches.",
            "author": [
                "Enes Altinisik",
                "Fatih Deniz",
                "Husrev Taha Sencar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03647v1",
                "http://arxiv.org/pdf/2309.03647v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03645v1",
            "title": "VideolandGPT: A User Study on a Conversational Recommender System",
            "updated": "2023-09-07T11:24:47Z",
            "published": "2023-09-07T11:24:47Z",
            "summary": "This paper investigates how large language models (LLMs) can enhance\nrecommender systems, with a specific focus on Conversational Recommender\nSystems that leverage user preferences and personalised candidate selections\nfrom existing ranking models. We introduce VideolandGPT, a recommender system\nfor a Video-on-Demand (VOD) platform, Videoland, which uses ChatGPT to select\nfrom a predetermined set of contents, considering the additional context\nindicated by users' interactions with a chat interface. We evaluate ranking\nmetrics, user experience, and fairness of recommendations, comparing a\npersonalised and a non-personalised version of the system, in a between-subject\nuser study. Our results indicate that the personalised version outperforms the\nnon-personalised in terms of accuracy and general user satisfaction, while both\nversions increase the visibility of items which are not in the top of the\nrecommendation lists. However, both versions present inconsistent behavior in\nterms of fairness, as the system may generate recommendations which are not\navailable on Videoland.",
            "author": [
                "Mateo Gutierrez Granada",
                "Dina Zilbershtein",
                "Daan Odijk",
                "Francesco Barile"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03645v1",
                "http://arxiv.org/pdf/2309.03645v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03624v1",
            "title": "Navigating Homogeneous Paths through Amyloidogenic and Non-Amyloidogenic\n  Hexapeptides",
            "updated": "2023-09-07T10:34:41Z",
            "published": "2023-09-07T10:34:41Z",
            "summary": "Hexapeptides are increasingly applied as model systems for studying the\namyloidogenecity properties of oligo- and polypeptides. It is possible to\nconstruct 64 million different hexapeptides from the twenty proteinogenic amino\nacid residues. Today's experimental amyloid databases contain only a fraction\nof these annotated hexapeptides. For labeling all the possible hexapeptides as\n\"amyloidogenic\" or \"non-amyloidogenic\" there exist several computational\npredictors with good accuracies. It may be of interest to define and study a\nsimple graph structure on the 64 million hexapeptides as nodes when two\nhexapeptides are connected by an edge if they differ by only a single residue.\nFor example, in this graph, HIKKLM is connected to AIKKLM, or HIKKNM, or\nHIKKLC, but it is not connected with an edge to VVKKLM or HIKNPM. In the\npresent contribution, we consider our previously published artificial\nintelligence-based tool, the Budapest Amyloid Predictor (BAP for short), and\ndemonstrate a spectacular property of this predictor in the graph defined\nabove. We show that for any two hexapeptides predicted to be \"amyloidogenic\" by\nthe BAP predictor, there exists an easily constructible path of length at most\n6 that passes through neighboring hexapeptides all predicted to be\n\"amyloidogenic\" by BAP. For example, the predicted amyloidogenic ILVWIW and\nFWLCYL hexapeptides can be connected through the length-6 path\nILVWIW-IWVWIW-IWVCIW-IWVCIL-FWVCIL-FWLCIL-FWLCYL in such a way that the\nneighbors differ in exactly one residue, and all hexapeptides on the path are\npredicted to be amyloidogenic by BAP. The symmetric statement also holds for\nnon-amyloidogenic hexapeptides. It is noted that the mentioned property of the\nBudapest Amyloid Predictor \\url{https://pitgroup.org/bap} is not proprietary;\nit is also true for any linear Support Vector Machine (SVM)-based predictors.",
            "author": [
                "Laszlo Keresztes",
                "Evelin Szogi",
                "Balint Varga",
                "Viktor Farkas",
                "Andras Perczel",
                "Vince Grolmusz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03624v1",
                "http://arxiv.org/pdf/2309.03624v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03616v2",
            "title": "Filtration Surfaces for Dynamic Graph Classification",
            "updated": "2023-10-21T09:12:24Z",
            "published": "2023-09-07T10:18:36Z",
            "summary": "Existing approaches for classifying dynamic graphs either lift graph kernels\nto the temporal domain, or use graph neural networks (GNNs). However, current\nbaselines have scalability issues, cannot handle a changing node set, or do not\ntake edge weight information into account. We propose filtration surfaces, a\nnovel method that is scalable and flexible, to alleviate said restrictions. We\nexperimentally validate the efficacy of our model and show that filtration\nsurfaces outperform previous state-of-the-art baselines on datasets that rely\non edge weight information. Our method does so while being either completely\nparameter-free or having at most one parameter, and yielding the lowest overall\nstandard deviation among similarly scalable methods.",
            "author": [
                "Franz Srambical",
                "Bastian Rieck"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03616v2",
                "http://arxiv.org/pdf/2309.03616v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03604v1",
            "title": "Estimating the Coverage Measure and the Area Explored by a Line-Sweep\n  Sensor on the Plane",
            "updated": "2023-09-07T09:57:26Z",
            "published": "2023-09-07T09:57:26Z",
            "summary": "This paper presents a method for determining the area explored by a\nline-sweep sensor during an area-covering mission in a two-dimensional plane.\nAccurate knowledge of the explored area is crucial for various applications in\nrobotics, such as mapping, surveillance, and coverage optimization. The\nproposed method leverages the concept of coverage measure of the environment\nand its relation to the topological degree in the plane, to estimate the extent\nof the explored region. In addition, we extend the approach to uncertain\ncoverage measure values using interval analysis. This last contribution allows\nfor a guaranteed characterization of the explored area, essential considering\nthe often critical character of area-covering missions. Finally, this paper\nalso proposes a novel algorithm for computing the topological degree in the\n2-dimensional plane, for all the points inside an area of interest, which\ndiffers from existing solutions that compute the topological degree for single\npoints. The applicability of the method is evaluated through a real-world\nexperiment.",
            "author": [
                "Maria Costa Vianna",
                "Eric Goubault",
                "Luc Jaulin",
                "Sylvie Putot"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03604v1",
                "http://arxiv.org/pdf/2309.03604v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY",
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03603v1",
            "title": "Enhancing 5G Radio Planning with Graph Representations and Deep Learning",
            "updated": "2023-09-07T09:55:57Z",
            "published": "2023-09-07T09:55:57Z",
            "summary": "The roll out of new mobile network generations poses hard challenges due to\nvarious factors such as cost-benefit tradeoffs, existing infrastructure, and\nnew technology aspects. In particular, one of the main challenges for the 5G\ndeployment lies in optimal 5G radio coverage while accounting for diverse\nservice performance metrics. This paper introduces a Deep Learning-based\napproach to assist in 5G radio planning by utilizing data from\nprevious-generation cells. Our solution relies on a custom graph representation\nto leverage the information available from existing cells, and employs a Graph\nNeural Network (GNN) model to process such data efficiently. In our evaluation,\nwe test its potential to model the transition from 4G to 5G NSA using\nreal-world data from a UK mobile network operator. The experimental results\nshow that our solution achieves high accuracy in predicting key performance\nindicators in new 5G cells, with a Mean Absolute Percentage Error (MAPE)~<17\\%\nwhen evaluated on samples from the same area where it was trained. Moreover, we\ntest its generalization capability over various geographical areas not included\nin the training, achieving a MAPE~<19\\%. This suggests beneficial properties\nfor achieving robust solutions applicable to 5G planning in new areas without\nthe need of retraining.",
            "author": [
                "Paul Almasan",
                "Jos\u00e9 Su\u00e1rez-Varela",
                "Andra Lutu",
                "Albert Cabellos-Aparicio",
                "Pere Barlet-Ros"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03603v1",
                "http://arxiv.org/pdf/2309.03603v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03925v1",
            "title": "Beyond attention: deriving biologically interpretable insights from\n  weakly-supervised multiple-instance learning models",
            "updated": "2023-09-07T09:44:35Z",
            "published": "2023-09-07T09:44:35Z",
            "summary": "Recent advances in attention-based multiple instance learning (MIL) have\nimproved our insights into the tissue regions that models rely on to make\npredictions in digital pathology. However, the interpretability of these\napproaches is still limited. In particular, they do not report whether\nhigh-attention regions are positively or negatively associated with the class\nlabels or how well these regions correspond to previously established clinical\nand biological knowledge. We address this by introducing a post-training\nmethodology to analyse MIL models. Firstly, we introduce\nprediction-attention-weighted (PAW) maps by combining tile-level attention and\nprediction scores produced by a refined encoder, allowing us to quantify the\npredictive contribution of high-attention regions. Secondly, we introduce a\nbiological feature instantiation technique by integrating PAW maps with nuclei\nsegmentation masks. This further improves interpretability by providing\nbiologically meaningful features related to the cellular organisation of the\ntissue and facilitates comparisons with known clinical features. We illustrate\nthe utility of our approach by comparing PAW maps obtained for prostate cancer\ndiagnosis (i.e. samples containing malignant tissue, 381/516 tissue samples)\nand prognosis (i.e. samples from patients with biochemical recurrence following\nsurgery, 98/663 tissue samples) in a cohort of patients from the international\ncancer genome consortium (ICGC UK Prostate Group). Our approach reveals that\nregions that are predictive of adverse prognosis do not tend to co-locate with\nthe tumour regions, indicating that non-cancer cells should also be studied\nwhen evaluating prognosis.",
            "author": [
                "Willem Bonnaff\u00e9",
                "CRUK ICGC Prostate Group",
                "Freddie Hamdy",
                "Yang Hu",
                "Ian Mills",
                "Jens Rittscher",
                "Clare Verrill",
                "Dan J. Woodcock"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03925v1",
                "http://arxiv.org/pdf/2309.03925v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03593v1",
            "title": "Quantum Graph-State Synthesis with SAT",
            "updated": "2023-09-07T09:35:31Z",
            "published": "2023-09-07T09:35:31Z",
            "summary": "In quantum computing and quantum information processing, graph states are a\nspecific type of quantum states which are commonly used in quantum networking\nand quantum error correction. A recurring problem is finding a transformation\nfrom a given source graph state to a desired target graph state using only\nlocal operations. Recently it has been shown that deciding transformability is\nalready NP-hard. In this paper, we present a CNF encoding for both local and\nnon-local graph state operations, corresponding to one- and two-qubit Clifford\ngates and single-qubit Pauli measurements. We use this encoding in a\nbounded-model-checking set-up to synthesize the desired transformation. For a\ncompleteness threshold, we provide an upper bound on the length of the\ntransformation if it exists. We evaluate the approach in two settings: the\nfirst is the synthesis of the ubiquitous GHZ state from a random graph state\nwhere we can vary the number of qubits, while the second is based on a proposed\n14 node quantum network. We find that the approach is able to synthesize\ntransformations for graphs up to 17 qubits in under 30 minutes.",
            "author": [
                "Sebastiaan Brand",
                "Tim Coopmans",
                "Alfons Laarman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03593v1",
                "http://arxiv.org/pdf/2309.03593v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03585v1",
            "title": "Shooting methods for computing geodesics on the Stiefel manifold",
            "updated": "2023-09-07T09:25:04Z",
            "published": "2023-09-07T09:25:04Z",
            "summary": "This paper shows how to use the shooting method, a classical numerical\nalgorithm for solving boundary value problems, to compute the Riemannian\ndistance on the Stiefel manifold $\\mathrm{St}(n,p)$, the set of $ n \\times p $\nmatrices with orthonormal columns. The main feature is that we provide neat,\nexplicit expressions for the Jacobians. To the author's knowledge, this is the\nfirst time some explicit formulas are given for the Jacobians involved in the\nshooting methods to find the distance between two given points on the Stiefel\nmanifold. This allows us to perform a preliminary analysis for the single\nshooting method. Numerical experiments demonstrate the algorithms in terms of\naccuracy and performance. Finally, we showcase three example applications in\nsummary statistics, shape analysis, and model order reduction.",
            "author": [
                "Marco Sutti"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03585v1",
                "http://arxiv.org/pdf/2309.03585v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65L10, 65F45, 65F60, 65L05, 53C22, 58C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03566v1",
            "title": "P4R-Type: a Verified API for P4 Control Plane Programs (Technical\n  Report)",
            "updated": "2023-09-07T08:52:49Z",
            "published": "2023-09-07T08:52:49Z",
            "summary": "Software-Defined Networking (SDN) significantly simplifies programming,\nreconfiguring, and optimizing network devices, such as switches and routers.\nThe de facto standard for programmming SDN devices is the P4 language. However,\nthe flexibility and power of P4, and SDN more generally, gives rise to\nimportant risks. As a number of incidents at major cloud providers have shown,\nerrors in SDN programs can compromise the availability of networks, leaving\nthem in a non-functional state. The focus of this paper are errors in\ncontrol-plane programs that interact with P4-enabled network devices via the\nstandardized P4Runtime API. For clients of the P4Runtime API it is easy to make\nmistakes that lead to catastrophic failures, despite the use of Google's\nProtocol Buffers as an interface definition language.\n  This paper proposes P4R-Type, a novel verified P4Runtime API for Scala that\nperforms static checks for P4 control plane operations, ruling out mismatches\nbetween P4 tables, allowed actions, and action parameters. As a formal\nfoundation of P4R-Type, we present the $F_{\\text{P4R}}$ calculus and its typing\nsystem, which ensure that well-typed programs never get stuck by issuing\ninvalid P4Runtime operations. We evaluate the safety and flexibility of\nP4R-Type with 3 case studies. To the best of our knowledge, this is the first\nwork that formalises P4Runtime control plane applications, and a typing\ndiscipline ensuring the correctness of P4Runtime operations.",
            "author": [
                "Jens Kanstrup Larsen",
                "Roberto Guanciale",
                "Philipp Haller",
                "Alceste Scalas"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3622866",
                "http://arxiv.org/abs/2309.03566v1",
                "http://arxiv.org/pdf/2309.03566v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "D.3.1; D.3.2; C.2.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03542v1",
            "title": "Zero-Shot Scene Graph Generation via Triplet Calibration and Reduction",
            "updated": "2023-09-07T08:01:07Z",
            "published": "2023-09-07T08:01:07Z",
            "summary": "Scene Graph Generation (SGG) plays a pivotal role in downstream\nvision-language tasks. Existing SGG methods typically suffer from poor\ncompositional generalizations on unseen triplets. They are generally trained on\nincompletely annotated scene graphs that contain dominant triplets and tend to\nbias toward these seen triplets during inference. To address this issue, we\npropose a Triplet Calibration and Reduction (T-CAR) framework in this paper. In\nour framework, a triplet calibration loss is first presented to regularize the\nrepresentations of diverse triplets and to simultaneously excavate the unseen\ntriplets in incompletely annotated training scene graphs. Moreover, the unseen\nspace of scene graphs is usually several times larger than the seen space since\nit contains a huge number of unrealistic compositions. Thus, we propose an\nunseen space reduction loss to shift the attention of excavation to reasonable\nunseen compositions to facilitate the model training. Finally, we propose a\ncontextual encoder to improve the compositional generalizations of unseen\ntriplets by explicitly modeling the relative spatial relations between subjects\nand objects. Extensive experiments show that our approach achieves consistent\nimprovements for zero-shot SGG over state-of-the-art methods. The code is\navailable at https://github.com/jkli1998/T-CAR.",
            "author": [
                "Jiankai Li",
                "Yunhong Wang",
                "Weixin Li"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604284",
                "http://arxiv.org/abs/2309.03542v1",
                "http://arxiv.org/pdf/2309.03542v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03537v1",
            "title": "Subgraph-based Tight Frames on Graphs with Compact Supports and\n  Vanishing Moments",
            "updated": "2023-09-07T07:49:43Z",
            "published": "2023-09-07T07:49:43Z",
            "summary": "In this work, we proposed a novel and general method to construct tight\nframes on graphs with compact supports based on a series of hierarchical\npartitions. Starting from our abstract construction that generalizes previous\nmethods based on partition trees, we are able to flexibly incorporate subgraph\nLaplacians into our design of graph frames. Consequently, our general methods\npermit adjusting the (subgraph) vanishing moments of the framelets and extra\nproperties, such as directionality, for efficiently representing graph signals\nwith path-like supports. Several variants are explicitly defined and tested.\nExperimental results show our proposed graph frames perform superiorly in\nnon-linear approximation tasks.",
            "author": [
                "Ruigang Zheng",
                "Xiaosheng Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03537v1",
                "http://arxiv.org/pdf/2309.03537v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG",
                "43A99, 41A45, 94A11, 94A16"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03534v2",
            "title": "Local Well-posedness of the Incompressible Current-Vortex Sheet Problems",
            "updated": "2023-11-14T05:13:46Z",
            "published": "2023-09-07T07:38:09Z",
            "summary": "We prove the local well-posedness of the incompressible current-vortex sheet\nproblems in standard Sobolev spaces under the surface tension or the\nSyrovatskij condition, which shows that both capillary forces and large\ntangential magnetic fields can stabilize the motion of current-vortex sheets.\nFurthermore, under the Syrovatskij condition, the vanishing surface tension\nlimit is established for the motion of current-vortex sheets. These results\nhold without assuming the interface separating the two plasmas being a graph.",
            "author": [
                "Sicheng Liu",
                "Zhouping Xin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03534v2",
                "http://arxiv.org/pdf/2309.03534v2"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03523v1",
            "title": "DGC: Training Dynamic Graphs with Spatio-Temporal Non-Uniformity using\n  Graph Partitioning by Chunks",
            "updated": "2023-09-07T07:12:59Z",
            "published": "2023-09-07T07:12:59Z",
            "summary": "Dynamic Graph Neural Network (DGNN) has shown a strong capability of learning\ndynamic graphs by exploiting both spatial and temporal features. Although DGNN\nhas recently received considerable attention by AI community and various DGNN\nmodels have been proposed, building a distributed system for efficient DGNN\ntraining is still challenging. It has been well recognized that how to\npartition the dynamic graph and assign workloads to multiple GPUs plays a\ncritical role in training acceleration. Existing works partition a dynamic\ngraph into snapshots or temporal sequences, which only work well when the graph\nhas uniform spatio-temporal structures. However, dynamic graphs in practice are\nnot uniformly structured, with some snapshots being very dense while others are\nsparse. To address this issue, we propose DGC, a distributed DGNN training\nsystem that achieves a 1.25x - 7.52x speedup over the state-of-the-art in our\ntestbed. DGC's success stems from a new graph partitioning method that\npartitions dynamic graphs into chunks, which are essentially subgraphs with\nmodest training workloads and few inter connections. This partitioning\nalgorithm is based on graph coarsening, which can run very fast on large\ngraphs. In addition, DGC has a highly efficient run-time, powered by the\nproposed chunk fusion and adaptive stale aggregation techniques. Extensive\nexperimental results on 3 typical DGNN models and 4 popular dynamic graph\ndatasets are presented to show the effectiveness of DGC.",
            "author": [
                "Fahao Chen",
                "Peng Li",
                "Celimuge Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03523v1",
                "http://arxiv.org/pdf/2309.03523v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03519v1",
            "title": "A cutting-surface consensus approach for distributed robust optimization\n  of multi-agent systems",
            "updated": "2023-09-07T07:00:18Z",
            "published": "2023-09-07T07:00:18Z",
            "summary": "A novel and fully distributed optimization method is proposed for the\ndistributed robust convex program (DRCP) over a time-varying unbalanced\ndirected network without imposing any differentiability assumptions. Firstly, a\ntractable approximated DRCP (ADRCP) is introduced by discretizing the\nsemi-infinite constraints into a finite number of inequality constraints and\nrestricting the right-hand side of the constraints with a proper positive\nparameter, which will be iteratively solved by a random-fixed projection\nalgorithm. Secondly, a cutting-surface consensus approach is proposed for\nlocating an approximately optimal consensus solution of the DRCP with\nguaranteed feasibility. This approach is based on iteratively approximating the\nDRCP by successively reducing the restriction parameter of the right-hand\nconstraints and populating the cutting-surfaces into the existing finite set of\nconstraints. Thirdly, to ensure finite-time convergence of the distributed\noptimization, a distributed termination algorithm is developed based on\nuniformly local consensus and zeroth-order optimality under uniformly strongly\nconnected graphs. Fourthly, it is proved that the cutting-surface consensus\napproach converges within a finite number of iterations. Finally, the\neffectiveness of the approach is illustrated through a numerical example.",
            "author": [
                "Jun Fu",
                "Xunhao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03519v1",
                "http://arxiv.org/pdf/2309.03519v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.MA",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03507v1",
            "title": "Quantum retrodiction in Gaussian systems and applications in\n  optomechanics",
            "updated": "2023-09-07T06:36:11Z",
            "published": "2023-09-07T06:36:11Z",
            "summary": "What knowledge can be obtained from the record of a continuous measurement\nabout the quantum state the measured system was in at the beginning of the\nmeasurement? The task of quantum state retrodiction, the inverse of the more\ncommon state prediction, is rigorously and elegantly addressed in quantum\nmeasurement theory through retrodictive Positive Operator Valued Measures. This\narticle provides an introduction to this general framework, presents its\npractical formulation for retrodicting Gaussian quantum states using\ncontinuous-time homodyne measurements, and applies it to optomechanical\nsystems. We identify and characterise achievable retrodictive POVMs in common\noptomechanical operating modes with resonant or off-resonant driving fields and\nspecific choices of local oscillator frequencies in homodyne detection. In\nparticular, we demonstrate the possibility of a near-ideal measurement of the\nquadrature of the mechanical oscillator, giving direct access to the position\nor momentum distribution of the oscillator at a given time. This forms the\nbasis for complete quantum state tomography, albeit in a destructive manner.",
            "author": [
                "Jonas Lammers",
                "Klemens Hammerer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03507v1",
                "http://arxiv.org/pdf/2309.03507v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03499v1",
            "title": "Instance Segmentation of Dislocations in TEM Images",
            "updated": "2023-09-07T06:17:31Z",
            "published": "2023-09-07T06:17:31Z",
            "summary": "Quantitative Transmission Electron Microscopy (TEM) during in-situ straining\nexperiment is able to reveal the motion of dislocations -- linear defects in\nthe crystal lattice of metals. In the domain of materials science, the\nknowledge about the location and movement of dislocations is important for\ncreating novel materials with superior properties. A long-standing problem,\nhowever, is to identify the position and extract the shape of dislocations,\nwhich would ultimately help to create a digital twin of such materials. In this\nwork, we quantitatively compare state-of-the-art instance segmentation methods,\nincluding Mask R-CNN and YOLOv8. The dislocation masks as the results of the\ninstance segmentation are converted to mathematical lines, enabling\nquantitative analysis of dislocation length and geometry -- important\ninformation for the domain scientist, which we then propose to include as a\nnovel length-aware quality metric for estimating the network performance. Our\nsegmentation pipeline shows a high accuracy suitable for all domain-specific,\nfurther post-processing. Additionally, our physics-based metric turns out to\nperform much more consistently than typically used pixel-wise metrics.",
            "author": [
                "Karina Ruzaeva",
                "Kishan Govind",
                "Marc Legros",
                "Stefan Sandfeld"
            ],
            "link": [
                "http://dx.doi.org/10.1109/nano58406.2023.10231169",
                "http://arxiv.org/abs/2309.03499v1",
                "http://arxiv.org/pdf/2309.03499v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03496v1",
            "title": "HOPPER: Interpretative Fuzzing for Libraries",
            "updated": "2023-09-07T06:11:18Z",
            "published": "2023-09-07T06:11:18Z",
            "summary": "Despite the fact that the state-of-the-art fuzzers can generate inputs\nefficiently, existing fuzz drivers still cannot adequately cover entries in\nlibraries. Most of these fuzz drivers are crafted manually by developers, and\ntheir quality depends on the developers' understanding of the code. Existing\nworks have attempted to automate the generation of fuzz drivers by learning API\nusage from code and execution traces. However, the generated fuzz drivers are\nlimited to a few specific call sequences by the code being learned. To address\nthese challenges, we present HOPPER, which can fuzz libraries without requiring\nany domain knowledge to craft fuzz drivers. It transforms the problem of\nlibrary fuzzing into the problem of interpreter fuzzing. The interpreters\nlinked against libraries under test can interpret the inputs that describe\narbitrary API usage. To generate semantically correct inputs for the\ninterpreter, HOPPER learns the intra- and inter-API constraints in the\nlibraries and mutates the program with grammar awareness. We implemented HOPPER\nand evaluated its effectiveness on 11 real-world libraries against manually\ncrafted fuzzers and other automatic solutions. Our results show that HOPPER\ngreatly outperformed the other fuzzers in both code coverage and bug finding,\nhaving uncovered 25 previously unknown bugs that other fuzzers couldn't.\nMoreover, we have demonstrated that the proposed intra- and inter-API\nconstraint learning methods can correctly learn constraints implied by the\nlibrary and, therefore, significantly improve the fuzzing efficiency. The\nexperiment results indicate that HOPPER is able to explore a vast range of API\nusages for library fuzzing out of the box.",
            "author": [
                "Peng Chen",
                "Yuxuan Xie",
                "Yunlong Lyu",
                "Yuxiao Wang",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03496v1",
                "http://arxiv.org/pdf/2309.03496v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.06852v1",
            "title": "DeepCrysTet: A Deep Learning Approach Using Tetrahedral Mesh for\n  Predicting Properties of Crystalline Materials",
            "updated": "2023-09-07T05:23:52Z",
            "published": "2023-09-07T05:23:52Z",
            "summary": "Machine learning (ML) is becoming increasingly popular for predicting\nmaterial properties to accelerate materials discovery. Because material\nproperties are strongly affected by its crystal structure, a key issue is\nconverting the crystal structure into the features for input to the ML model.\nCurrently, the most common method is to convert the crystal structure into a\ngraph and predicting its properties using a graph neural network (GNN). Some\nGNN models, such as crystal graph convolutional neural network (CGCNN) and\natomistic line graph neural network (ALIGNN), have achieved highly accurate\npredictions of material properties. Despite these successes, using a graph to\nrepresent a crystal structure has the notable limitation of losing the crystal\nstructure's three-dimensional (3D) information. In this work, we propose\nDeepCrysTet, a novel deep learning approach for predicting material properties,\nwhich uses crystal structures represented as a 3D tetrahedral mesh generated by\nDelaunay tetrahedralization. DeepCrysTet provides a useful framework that\nincludes a 3D mesh generation method, mesh-based feature design, and neural\nnetwork design. The experimental results using the Materials Project dataset\nshow that DeepCrysTet significantly outperforms existing GNN models in\nclassifying crystal structures and achieves state-of-the-art performance in\npredicting elastic properties.",
            "author": [
                "Hirofumi Tsuruta",
                "Yukari Katsura",
                "Masaya Kumagai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.06852v1",
                "http://arxiv.org/pdf/2310.06852v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03470v1",
            "title": "Machine Learning for Tangible Effects: Natural Language Processing for\n  Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing",
            "updated": "2023-09-07T04:04:01Z",
            "published": "2023-09-07T04:04:01Z",
            "summary": "I explore two questions in this thesis: how can computer science be used to\nfight human trafficking? And how can computer vision create a sense of touch?\n  I use natural language processing (NLP) to monitor the United States illicit\nmassage industry (IMI), a multi-billion dollar industry that offers not just\ntherapeutic massages but also commercial sexual services. Employees of this\nindustry are often immigrant women with few job opportunities, leaving them\nvulnerable to fraud, coercion, and other facets of human trafficking.\nMonitoring spatiotemporal trends helps prevent trafficking in the IMI. By\ncreating datasets with three publicly-accessible websites: Google Places,\nRubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and\nWord2Vec, I show how to derive insights into the labor pressures and language\nbarriers that employees face, as well as the income, demographics, and societal\npressures affecting sex buyers. I include a call-to-action to other researchers\ngiven these datasets. I also consider how to creating synthetic financial data,\nwhich can aid with counter-trafficking in the banking sector. I use an\nagent-based model to create both tabular and payee-recipient graph data.\n  I then consider the role of computer vision in making tactile sensors. I\nreport on a novel sensor, the Digger Finger, that adapts the Gelsight sensor to\nfinding objects in granular media. Changes include using a wedge shape to\nfacilitate digging, replacing the internal lighting LEDs with fluorescent\npaint, and adding a vibrator motor to counteract jamming. Finally, I also show\nhow to use a webcam and a printed reference marker, or fiducial, to create a\nlow-cost six-axis force-torque sensor. This sensor is up to a hundred times\nless expensive than commercial sensors, allowing for a wider range of\napplications. For this and earlier chapters I release design files and code as\nopen source.",
            "author": [
                "Rui Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03470v1",
                "http://arxiv.org/pdf/2309.03470v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03924v1",
            "title": "Automatic Algorithm Selection for Pseudo-Boolean Optimization with Given\n  Computational Time Limits",
            "updated": "2023-09-07T03:04:50Z",
            "published": "2023-09-07T03:04:50Z",
            "summary": "Machine learning (ML) techniques have been proposed to automatically select\nthe best solver from a portfolio of solvers, based on predicted performance.\nThese techniques have been applied to various problems, such as Boolean\nSatisfiability, Traveling Salesperson, Graph Coloring, and others.\n  These methods, known as meta-solvers, take an instance of a problem and a\nportfolio of solvers as input. They then predict the best-performing solver and\nexecute it to deliver a solution. Typically, the quality of the solution\nimproves with a longer computational time. This has led to the development of\nanytime selectors, which consider both the instance and a user-prescribed\ncomputational time limit. Anytime meta-solvers predict the best-performing\nsolver within the specified time limit.\n  Constructing an anytime meta-solver is considerably more challenging than\nbuilding a meta-solver without the \"anytime\" feature. In this study, we focus\non the task of designing anytime meta-solvers for the NP-hard optimization\nproblem of Pseudo-Boolean Optimization (PBO), which generalizes Satisfiability\nand Maximum Satisfiability problems. The effectiveness of our approach is\ndemonstrated via extensive empirical study in which our anytime meta-solver\nimproves dramatically on the performance of Mixed Integer Programming solver\nGurobi, which is the best-performing single solver in the portfolio. For\nexample, out of all instances and time limits for which Gurobi failed to find\nfeasible solutions, our meta-solver identified feasible solutions for 47% of\nthese.",
            "author": [
                "Catalina Pezo",
                "Dorit Hochbaum",
                "Julio Godoy",
                "Roberto Asin-Acha"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03924v1",
                "http://arxiv.org/pdf/2309.03924v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03455v2",
            "title": "Thresholds for zero-sums with small cross numbers in abelian groups",
            "updated": "2023-09-08T13:49:56Z",
            "published": "2023-09-07T02:34:28Z",
            "summary": "For an additive group $\\Gamma$ the sequence $S = (g_1, \\ldots, g_t)$ of\nelements of $\\Gamma$ is a zero-sum sequence if $g_1 + \\cdots + g_t = 0_\\Gamma$.\nThe cross number of $S$ is defined to be the sum $\\sum_{i=1}^k 1/|g_i|$, where\n$|g_i|$ denotes the order of $g_i$ in $\\Gamma$. Call $S$ good if it contains a\nzero-sum subsequence with cross number at most 1. In 1993, Geroldinger proved\nthat if $\\Gamma$ is abelian then every length $|\\Gamma|$ sequence of its\nelements is good, generalizing a 1989 result of Lemke and Kleitman that had\nproved an earlier conjecture of Erd\\H{o}s and Lemke. In 1989 Chung re-proved\nthe Lemke and Kleitman result by applying a theorem of graph pebbling, and in\n2005, Elledge and Hurlbert used graph pebbling to re-prove and generalize\nGeroldinger's result. Here we use probabilistic theorems from graph pebbling to\nderive a sharp threshold version of Geroldinger's theorem for abelian groups of\na certain form. Specifically, we prove that if $p_1, \\ldots, p_d$ are (not\nnecessarily distinct) primes and $\\Gamma_k$ has the form $\\prod_{i=1}^d\n{\\mathbb Z}_{p_i^k}$ then there is a function $\\tau=\\tau(k)$ (which we specify\nin Theorem 4) with the following property: if $t-\\tau\\rightarrow\\infty$ as\n$k\\rightarrow\\infty$ then the probability that $S$ is good in $\\Gamma_k$ tends\nto 1, while if $\\tau-t\\rightarrow\\infty$ then that probability tends to 0.",
            "author": [
                "Neal Bushaw",
                "Glenn Hurlbert"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03455v2",
                "http://arxiv.org/pdf/2309.03455v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "11P70 (Primary) 20K01, 60C05 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03452v1",
            "title": "Multi-Modality Guidance Network For Missing Modality Inference",
            "updated": "2023-09-07T02:26:55Z",
            "published": "2023-09-07T02:26:55Z",
            "summary": "Multimodal models have gained significant success in recent years. Standard\nmultimodal approaches often assume unchanged modalities from training stage to\ninference stage. In practice, however, many scenarios fail to satisfy such\nassumptions with missing modalities during inference, leading to limitations on\nwhere multimodal models can be applied. While existing methods mitigate the\nproblem through reconstructing the missing modalities, it increases unnecessary\ncomputational cost, which could be just as critical, especially for large,\ndeployed systems. To solve the problem from both sides, we propose a novel\nguidance network that promotes knowledge sharing during training, taking\nadvantage of the multimodal representations to train better single-modality\nmodels for inference. Real-life experiment in violence detection shows that our\nproposed framework trains single-modality models that significantly outperform\nits traditionally trained counterparts while maintaining the same inference\ncost.",
            "author": [
                "Zhuokai Zhao",
                "Harish Palani",
                "Tianyi Liu",
                "Lena Evans",
                "Ruth Toner"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03452v1",
                "http://arxiv.org/pdf/2309.03452v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03448v1",
            "title": "Introduction to Molecular-Scale Understanding of Surface Tension",
            "updated": "2023-09-07T02:16:01Z",
            "published": "2023-09-07T02:16:01Z",
            "summary": "In this article, microscopic understanding of the surface tension are\nprovided, which needs basic knowledge of thermodynamics, statistical mechanics\nas well as continuum mechanics. By introducing the intermolecular interaction\npotential and temperature definition, and by showing conceptual pictures\nincluding some results obtained by molecular dynamics simulations, the author\nhopes that the target readers of undergraduate level students can find\nfascinating aspects of surface tension as the boundary of macroscopic and\nmicroscopic physics.",
            "author": [
                "Yasutaka Yamaguchi",
                "Hiroshi Kawamura"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03448v1",
                "http://arxiv.org/pdf/2309.03448v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03406v1",
            "title": "Distribution-Aware Prompt Tuning for Vision-Language Models",
            "updated": "2023-09-06T23:49:11Z",
            "published": "2023-09-06T23:49:11Z",
            "summary": "Pre-trained vision-language models (VLMs) have shown impressive performance\non various downstream tasks by utilizing knowledge learned from large data. In\ngeneral, the performance of VLMs on target tasks can be further improved by\nprompt tuning, which adds context to the input image or text. By leveraging\ndata from target tasks, various prompt-tuning methods have been studied in the\nliterature. A key to prompt tuning is the feature space alignment between two\nmodalities via learnable vectors with model parameters fixed. We observed that\nthe alignment becomes more effective when embeddings of each modality are\n`well-arranged' in the latent space. Inspired by this observation, we proposed\ndistribution-aware prompt tuning (DAPT) for vision-language models, which is\nsimple yet effective. Specifically, the prompts are learned by maximizing\ninter-dispersion, the distance between classes, as well as minimizing the\nintra-dispersion measured by the distance between embeddings from the same\nclass. Our extensive experiments on 11 benchmark datasets demonstrate that our\nmethod significantly improves generalizability. The code is available at\nhttps://github.com/mlvlab/DAPT.",
            "author": [
                "Eulrang Cho",
                "Jooyeon Kim",
                "Hyunwoo J. Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03406v1",
                "http://arxiv.org/pdf/2309.03406v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03387v2",
            "title": "Efficient Baselines for Motion Prediction in Autonomous Driving",
            "updated": "2023-10-31T22:14:51Z",
            "published": "2023-09-06T22:18:16Z",
            "summary": "Motion Prediction (MP) of multiple surroundings agents is a crucial task in\narbitrarily complex environments, from simple robots to Autonomous Driving\nStacks (ADS). Current techniques tackle this problem using end-to-end\npipelines, where the input data is usually a rendered top-view of the physical\ninformation and the past trajectories of the most relevant agents; leveraging\nthis information is a must to obtain optimal performance. In that sense, a\nreliable ADS must produce reasonable predictions on time. However, despite many\napproaches use simple ConvNets and LSTMs to obtain the social latent features,\nState-Of-The-Art (SOTA) models might be too complex for real-time applications\nwhen using both sources of information (map and past trajectories) as well as\nlittle interpretable, specially considering the physical information. Moreover,\nthe performance of such models highly depends on the number of available inputs\nfor each particular traffic scenario, which are expensive to obtain,\nparticularly, annotated High-Definition (HD) maps.\n  In this work, we propose several efficient baselines for the well-known\nArgoverse 1 Motion Forecasting Benchmark. We aim to develop compact models\nusing SOTA techniques for MP, including attention mechanisms and GNNs. Our\nlightweight models use standard social information and interpretable map\ninformation such as points from the driveable area and plausible centerlines by\nmeans of a novel preprocessing step based on kinematic constraints, in\nopposition to black-box CNN-based or too-complex graphs methods for map\nencoding, to generate plausible multimodal trajectories achieving up-to-pair\naccuracy with less operations and parameters than other SOTA methods. Our code\nis publicly available at https://github.com/Cram3r95/mapfe4mp .",
            "author": [
                "Carlos G\u00f3mez-Hu\u00e9lamo",
                "Marcos V. Conde",
                "Rafael Barea",
                "Manuel Oca\u00f1a",
                "Luis M. Bergasa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03387v2",
                "http://arxiv.org/pdf/2309.03387v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03367v1",
            "title": "Self-Supervised Masked Digital Elevation Models Encoding for\n  Low-Resource Downstream Tasks",
            "updated": "2023-09-06T21:20:10Z",
            "published": "2023-09-06T21:20:10Z",
            "summary": "The lack of quality labeled data is one of the main bottlenecks for training\nDeep Learning models. As the task increases in complexity, there is a higher\npenalty for overfitting and unstable learning. The typical paradigm employed\ntoday is Self-Supervised learning, where the model attempts to learn from a\nlarge corpus of unstructured and unlabeled data and then transfer that\nknowledge to the required task. Some notable examples of self-supervision in\nother modalities are BERT for Large Language Models, Wav2Vec for Speech\nRecognition, and the Masked AutoEncoder for Vision, which all utilize\nTransformers to solve a masked prediction task. GeoAI is uniquely poised to\ntake advantage of the self-supervised methodology due to the decades of data\ncollected, little of which is precisely and dependably annotated. Our goal is\nto extract building and road segmentations from Digital Elevation Models (DEM)\nthat provide a detailed topography of the earths surface. The proposed\narchitecture is the Masked Autoencoder pre-trained on ImageNet (with the\nlimitation that there is a large domain discrepancy between ImageNet and DEM)\nwith an UperNet Head for decoding segmentations. We tested this model with 450\nand 50 training images only, utilizing roughly 5% and 0.5% of the original data\nrespectively. On the building segmentation task, this model obtains an 82.1%\nIntersection over Union (IoU) with 450 Images and 69.1% IoU with only 50\nimages. On the more challenging road detection task the model obtains an 82.7%\nIoU with 450 images and 73.2% IoU with only 50 images. Any hand-labeled dataset\nmade today about the earths surface will be immediately obsolete due to the\nconstantly changing nature of the landscape. This motivates the clear necessity\nfor data-efficient learners that can be used for a wide variety of downstream\ntasks.",
            "author": [
                "Priyam Mazumdar",
                "Aiman Soliman",
                "Volodymyr Kindratenko",
                "Luigi Marini",
                "Kenton McHenry"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03367v1",
                "http://arxiv.org/pdf/2309.03367v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03362v1",
            "title": "Unity is Strength: Cross-Task Knowledge Distillation to Improve Code\n  Review Generation",
            "updated": "2023-09-06T21:10:33Z",
            "published": "2023-09-06T21:10:33Z",
            "summary": "Code review is a fundamental process in software development that plays a\ncritical role in ensuring code quality and reducing the likelihood of errors\nand bugs. However, code review might be complex, subjective, and\ntime-consuming. Comment generation and code refinement are two key tasks of\nthis process and their automation has traditionally been addressed separately\nin the literature using different approaches. In this paper, we propose a novel\ndeep-learning architecture, DISCOREV, based on cross-task knowledge\ndistillation that addresses these two tasks simultaneously. In our approach,\nthe fine-tuning of the comment generation model is guided by the code\nrefinement model. We implemented this guidance using two strategies,\nfeedback-based learning objective and embedding alignment objective. We\nevaluated our approach based on cross-task knowledge distillation by comparing\nit to the state-of-the-art methods that are based on independent training and\nfine-tuning. Our results show that our approach generates better review\ncomments as measured by the BLEU score.",
            "author": [
                "Oussama Ben Sghaier",
                "Lucas Maes",
                "Houari Sahraoui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03362v1",
                "http://arxiv.org/pdf/2309.03362v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03923v1",
            "title": "Mathematical Singularities in the Farthest Confines of the Universe --\n  And a Brief Report on Its Evolutionary History",
            "updated": "2023-09-06T20:48:34Z",
            "published": "2023-09-06T20:48:34Z",
            "summary": "It is advisable to avoid and, even better, demystify such grandiose terms as\n\"infinity\" or \"singularity\" in the description of the cosmos. Its proliferation\ndoes not positively contribute to the understanding of key concepts that are\nessential for an updated account of its origin and evolutionary history. It\nwill be here argued that, as a matter of fact, there are no infinities in\nphysics, in the real world: all that appears, in any given formulation of\nnature by means of mathematical equations, actually arises from extrapolations,\nwhich are made beyond the bounds of validity of the equations themselves. Such\na crucial point is rather well known, but too often forgotten, and is discussed\nin this paper with several examples; namely, the famous Big Bang singularity\nand others, which appeared before in classical mechanics and electrodynamics,\nand notably in the quantization of field theories. A brief description of the\nUniverse's history and evolution follows. Special emphasis is put on what is\npresently known, from detailed observations of the cosmos and, complementarily,\nfrom advanced experiments of very high-energy physics. To conclude, a future\nperspective on how this knowledge might soon improve is given.",
            "author": [
                "Emilio Elizalde"
            ],
            "link": [
                "http://dx.doi.org/10.3390/universe9010033",
                "http://arxiv.org/abs/2309.03923v1",
                "http://arxiv.org/pdf/2309.03923v1"
            ],
            "primary_category": "physics.gen-ph",
            "category": [
                "physics.gen-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03331v1",
            "title": "Expert Uncertainty and Severity Aware Chest X-Ray Classification by\n  Multi-Relationship Graph Learning",
            "updated": "2023-09-06T19:19:41Z",
            "published": "2023-09-06T19:19:41Z",
            "summary": "Patients undergoing chest X-rays (CXR) often endure multiple lung diseases.\nWhen evaluating a patient's condition, due to the complex pathologies, subtle\ntexture changes of different lung lesions in images, and patient condition\ndifferences, radiologists may make uncertain even when they have experienced\nlong-term clinical training and professional guidance, which makes much noise\nin extracting disease labels based on CXR reports. In this paper, we re-extract\ndisease labels from CXR reports to make them more realistic by considering\ndisease severity and uncertainty in classification. Our contributions are as\nfollows: 1. We re-extracted the disease labels with severity and uncertainty by\na rule-based approach with keywords discussed with clinical experts. 2. To\nfurther improve the explainability of chest X-ray diagnosis, we designed a\nmulti-relationship graph learning method with an expert uncertainty-aware loss\nfunction. 3. Our multi-relationship graph learning method can also interpret\nthe disease classification results. Our experimental results show that models\nconsidering disease severity and uncertainty outperform previous\nstate-of-the-art methods.",
            "author": [
                "Mengliang Zhang",
                "Xinyue Hu",
                "Lin Gu",
                "Liangchen Liu",
                "Kazuma Kobayashi",
                "Tatsuya Harada",
                "Ronald M. Summers",
                "Yingying Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03331v1",
                "http://arxiv.org/pdf/2309.03331v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03190v2",
            "title": "Blink: Link Local Differential Privacy in Graph Neural Networks via\n  Bayesian Estimation",
            "updated": "2023-09-07T08:28:29Z",
            "published": "2023-09-06T17:53:31Z",
            "summary": "Graph neural networks (GNNs) have gained an increasing amount of popularity\ndue to their superior capability in learning node embeddings for various graph\ninference tasks, but training them can raise privacy concerns. To address this,\nwe propose using link local differential privacy over decentralized nodes,\nenabling collaboration with an untrusted server to train GNNs without revealing\nthe existence of any link. Our approach spends the privacy budget separately on\nlinks and degrees of the graph for the server to better denoise the graph\ntopology using Bayesian estimation, alleviating the negative impact of LDP on\nthe accuracy of the trained GNNs. We bound the mean absolute error of the\ninferred link probabilities against the ground truth graph topology. We then\npropose two variants of our LDP mechanism complementing each other in different\nprivacy settings, one of which estimates fewer links under lower privacy\nbudgets to avoid false positive link estimates when the uncertainty is high,\nwhile the other utilizes more information and performs better given relatively\nhigher privacy budgets. Furthermore, we propose a hybrid variant that combines\nboth strategies and is able to perform better across different privacy budgets.\nExtensive experiments show that our approach outperforms existing methods in\nterms of accuracy under varying privacy budgets.",
            "author": [
                "Xiaochen Zhu",
                "Vincent Y. F. Tan",
                "Xiaokui Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03190v2",
                "http://arxiv.org/pdf/2309.03190v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03179v3",
            "title": "SLiMe: Segment Like Me",
            "updated": "2023-11-13T03:59:36Z",
            "published": "2023-09-06T17:39:05Z",
            "summary": "Significant strides have been made using large vision-language models, like\nStable Diffusion (SD), for a variety of downstream tasks, including image\nediting, image correspondence, and 3D shape generation. Inspired by these\nadvancements, we explore leveraging these extensive vision-language models for\nsegmenting images at any desired granularity using as few as one annotated\nsample by proposing SLiMe. SLiMe frames this problem as an optimization task.\nSpecifically, given a single training image and its segmentation mask, we first\nextract attention maps, including our novel \"weighted accumulated\nself-attention map\" from the SD prior. Then, using the extracted attention\nmaps, the text embeddings of Stable Diffusion are optimized such that, each of\nthem, learn about a single segmented region from the training image. These\nlearned embeddings then highlight the segmented region in the attention maps,\nwhich in turn can then be used to derive the segmentation map. This enables\nSLiMe to segment any real-world image during inference with the granularity of\nthe segmented region in the training image, using just one example. Moreover,\nleveraging additional training data when available, i.e. few-shot, improves the\nperformance of SLiMe. We carried out a knowledge-rich set of experiments\nexamining various design factors and showed that SLiMe outperforms other\nexisting one-shot and few-shot segmentation methods.",
            "author": [
                "Aliasghar Khani",
                "Saeid Asgari Taghanaki",
                "Aditya Sanghi",
                "Ali Mahdavi Amiri",
                "Ghassan Hamarneh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03179v3",
                "http://arxiv.org/pdf/2309.03179v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03781v2",
            "title": "State-to-state rovibrational transition rates for CO2 in the bend mode\n  in collisions with He atoms",
            "updated": "2023-10-09T17:23:40Z",
            "published": "2023-09-06T17:39:04Z",
            "summary": "Modeling environments that are not in local thermal equilibrium, such as\nprotoplanetary disks or planetary atmospheres, with molecular spectroscopic\ndata from space telescopes requires knowledge of the rate coefficients of\nrovibrationally inelastic molecular collisions. Here, we present such rate\ncoefficients in a temperature range from 10 to 500 K for collisions of CO$_2$\nwith He atoms in which CO$_2$ is (de)excited in the bend mode. They are\nobtained from numerically exact coupled-channel (CC) calculations as well as\nfrom calculations with the less demanding coupled-states approximation (CSA)\nand the vibrational close-coupling rotational infinite-order sudden (VCC-IOS)\nmethod. All of the calculations are based on a newly calculated accurate ab\ninitio four-dimensional CO$_2$-He potential surface including the CO$_2$ bend\n($\\nu_2$) mode. We find that the rovibrationally inelastic collision cross\nsections and rate coefficients from the CSA and VCC-IOS calculations agree to\nwithin 50% with the CC results at the rotational state-to-state level, except\nfor the smaller ones and in the low energy resonance region, and to within 20%\nfor the overall vibrational quenching rates except for temperatures below 50 K\nwhere resonances provide a substantial contribution. Our CC quenching rates\nagree with the most recent experimental data within the error bars. We also\ncompared our results with data from Clary et al. calculated in the 1980's with\nthe CSA and VCC-IOS methods and a simple atom-atom model potential based on ab\ninitio Hartree-Fock calculations and found that their cross sections agree\nfairly well with ours for collision energies above 500 cm$^{-1}$, but that the\ninclusion of long range attractive dispersion interactions is crucial to obtain\nreliable cross sections at lower energies and rate coefficients at lower\ntemperatures.",
            "author": [
                "Taha Selim",
                "Ad van der Avoird",
                "Gerrit C. Groenenboom"
            ],
            "link": [
                "http://dx.doi.org/10.1063/5.0174787",
                "http://arxiv.org/abs/2309.03781v2",
                "http://arxiv.org/pdf/2309.03781v2"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph",
                "astro-ph.EP",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03251v1",
            "title": "Temporal Inductive Path Neural Network for Temporal Knowledge Graph\n  Reasoning",
            "updated": "2023-09-06T17:37:40Z",
            "published": "2023-09-06T17:37:40Z",
            "summary": "Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph\n(KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial\ntask that aims to predict future facts based on historical occurrences. The key\nchallenge lies in uncovering structural dependencies within historical\nsubgraphs and temporal patterns. Most existing approaches model TKGs relying on\nentity modeling, as nodes in the graph play a crucial role in knowledge\nrepresentation. However, the real-world scenario often involves an extensive\nnumber of entities, with new entities emerging over time. This makes it\nchallenging for entity-dependent methods to cope with extensive volumes of\nentities, and effectively handling newly emerging entities also becomes a\nsignificant challenge. Therefore, we propose Temporal Inductive Path Neural\nNetwork (TiPNN), which models historical information in an entity-independent\nperspective. Specifically, TiPNN adopts a unified graph, namely history\ntemporal graph, to comprehensively capture and encapsulate information from\nhistory. Subsequently, we utilize the defined query-aware temporal paths to\nmodel historical path information related to queries on history temporal graph\nfor the reasoning. Extensive experiments illustrate that the proposed model not\nonly attains significant performance enhancements but also handles inductive\nsettings, while additionally facilitating the provision of reasoning evidence\nthrough history temporal graphs.",
            "author": [
                "Hao Dong",
                "Pengyang Wang",
                "Meng Xiao",
                "Zhiyuan Ning",
                "Pengfei Wang",
                "Yuanchun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03251v1",
                "http://arxiv.org/pdf/2309.03251v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03169v2",
            "title": "Impression-Informed Multi-Behavior Recommender System: A Hierarchical\n  Graph Attention Approach",
            "updated": "2023-09-07T03:13:39Z",
            "published": "2023-09-06T17:09:43Z",
            "summary": "While recommender systems have significantly benefited from implicit\nfeedback, they have often missed the nuances of multi-behavior interactions\nbetween users and items. Historically, these systems either amalgamated all\nbehaviors, such as \\textit{impression} (formerly \\textit{view}),\n\\textit{add-to-cart}, and \\textit{buy}, under a singular 'interaction' label,\nor prioritized only the target behavior, often the \\textit{buy} action,\ndiscarding valuable auxiliary signals. Although recent advancements tried\naddressing this simplification, they primarily gravitated towards optimizing\nthe target behavior alone, battling with data scarcity. Additionally, they\ntended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge these\ngaps, we introduce the \\textbf{H}ierarchical \\textbf{M}ulti-behavior\n\\textbf{G}raph Attention \\textbf{N}etwork (HMGN). This pioneering framework\nleverages attention mechanisms to discern information from both inter and\nintra-behaviors while employing a multi-task Hierarchical Bayesian Personalized\nRanking (HBPR) for optimization. Recognizing the need for scalability, our\napproach integrates a specialized multi-behavior sub-graph sampling technique.\nMoreover, the adaptability of HMGN allows for the seamless inclusion of\nknowledge metadata and time-series data. Empirical results attest to our\nmodel's prowess, registering a notable performance boost of up to 64\\% in\nNDCG@100 metrics over conventional graph neural network methods.",
            "author": [
                "Dong Li",
                "Divya Bhargavi",
                "Vidya Sagar Ravipati"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03169v2",
                "http://arxiv.org/pdf/2309.03169v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03165v1",
            "title": "A Semiparametric Generalized Exponential Regression Model with a\n  Principled Distance-based Prior for Analyzing Trends in Rainfall",
            "updated": "2023-09-06T17:07:21Z",
            "published": "2023-09-06T17:07:21Z",
            "summary": "The Western Ghats mountain range holds critical importance in regulating\nmonsoon rainfall across Southern India, with a profound impact on regional\nagriculture. Here, we analyze daily wet-day rainfall data for the monsoon\nmonths between 1901-2022 for the Northern, Middle, and Southern Western Ghats\nregions. Motivated by an exploratory data analysis, we introduce a\nsemiparametric Bayesian generalized exponential (GE) regression model; despite\nthe underlying GE distribution assumption being well-known in the literature,\nincluding in the context of rainfall analysis, no research explored it in a\nregression setting, as of our knowledge. Our proposed approach involves\nmodeling the GE rate parameter within a generalized additive model framework.\nAn important feature is the integration of a principled distance-based prior\nfor the GE shape parameter; this allows the model to shrink to an exponential\nregression model that retains the advantages of the exponential family. We draw\ninferences using the Markov chain Monte Carlo algorithm. Extensive simulations\ndemonstrate that the proposed model outperforms simpler alternatives. Applying\nthe model to analyze the rainfall data over 122 years provides insights into\nmodel parameters, temporal patterns, and the impact of climate change. We\nobserve a significant decreasing trend in wet-day rainfall for the Southern\nWestern Ghats region.",
            "author": [
                "Arijit Dey",
                "Arnab Hazra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03165v1",
                "http://arxiv.org/pdf/2309.03165v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "62P12, 62F15, 62G08, 62J12"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03139v1",
            "title": "Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural\n  Networks",
            "updated": "2023-09-06T16:24:26Z",
            "published": "2023-09-06T16:24:26Z",
            "summary": "We present a natural extension to E(n)-equivariant graph neural networks that\nuses multiple equivariant vectors per node. We formulate the extension and show\nthat it improves performance across different physical systems benchmark tasks,\nwith minimal differences in runtime or number of parameters. The proposed\nmultichannel EGNN outperforms the standard singlechannel EGNN on N-body charged\nparticle dynamics, molecular property predictions, and predicting the\ntrajectories of solar system bodies. Given the additional benefits and minimal\nadditional cost of multi-channel EGNN, we suggest that this extension may be of\npractical use to researchers working in machine learning for the physical\nsciences",
            "author": [
                "Daniel Levy",
                "S\u00e9kou-Oumar Kaba",
                "Carmelo Gonzales",
                "Santiago Miret",
                "Siamak Ravanbakhsh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03139v1",
                "http://arxiv.org/pdf/2309.03139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03137v2",
            "title": "There are only two paradoxes",
            "updated": "2023-10-08T09:05:16Z",
            "published": "2023-09-06T16:19:09Z",
            "summary": "Using a graph representation of classical logic, the paper shows that the\nliar or Yablo pattern occurs in every semantic paradox. The core graph\ntheoretic result generalizes theorem of Richardson, showing solvability of\nfinite graphs without odd cycles, to arbitrary graphs which are proven solvable\nwhen no odd cycles nor patterns generalizing Yablo's occur. This follows from\nan earlier result by a new compactness-like theorem, holding for infinitary\nlogic and utilizing the graph representation.",
            "author": [
                "Michal Walicki"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03137v2",
                "http://arxiv.org/pdf/2309.03137v2"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03118v1",
            "title": "Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from\n  Knowledge Graphs",
            "updated": "2023-09-06T15:55:01Z",
            "published": "2023-09-06T15:55:01Z",
            "summary": "Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and\ncan solve different tasks due to their emergent ability and generalizability.\nHowever, LLMs sometimes lack domain-specific knowledge to perform tasks, which\nwould also cause hallucination during inference. In some previous works,\nadditional modules like graph neural networks (GNNs) are trained on retrieved\nknowledge from external knowledge bases, aiming to mitigate the problem of\nlacking domain-specific knowledge. However, incorporating additional modules:\n1) would need retraining additional modules when encountering novel domains; 2)\nwould become a bottleneck since LLMs' strong abilities are not fully utilized\nfor retrieval. In this paper, we propose a paradigm, termed Knowledge Solver\n(KSL), to teach LLMs to search for essential knowledge from external knowledge\nbases by harnessing their own strong generalizability. Specifically, we design\na simple yet effective prompt to transform retrieval into a multi-hop decision\nsequence, which empowers LLMs with searching knowledge ability in zero-shot\nmanner. Additionally, KSL is able to provide complete retrieval paths and\ntherefore increase explainability of LLMs' reasoning processes. We conduct\nexperiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and\nfound that our approach improves LLM baseline performance by a relatively large\nmargin.",
            "author": [
                "Chao Feng",
                "Xinyu Zhang",
                "Zichu Fei"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03118v1",
                "http://arxiv.org/pdf/2309.03118v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03249v2",
            "title": "Graph Theory Applications in Advanced Geospatial Research",
            "updated": "2023-10-09T16:20:33Z",
            "published": "2023-09-06T15:47:18Z",
            "summary": "Geospatial sciences include a wide range of applications, from environmental\nmonitoring transportation to infrastructure planning, as well as location-based\nanalysis and services. Graph theory algorithms in mathematics have emerged as\nindispensable tools in these domains due to their capability to model and\nanalyse spatial relationships efficiently. This article explores the\napplications of graph theory algorithms in geospatial sciences, highlighting\ntheir role in network analysis, spatial connectivity, geographic information\nsystems, and various other spatial problem-solving scenarios like digital twin.\nThe article provides a comprehensive idea about graph theory's key concepts and\nalgorithms that assist the geospatial modelling processes and insights into\nreal-world geospatial challenges and opportunities. It lists the extensive\nresearch, innovative technologies and methodologies implemented in this domain.",
            "author": [
                "Surajit Ghosh",
                "Archita Mallick",
                "Anuva Chowdhury",
                "Kounik De Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03249v2",
                "http://arxiv.org/pdf/2309.03249v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.CY",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03103v1",
            "title": "ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation\n  Following the Metaphor Identification Procedure",
            "updated": "2023-09-06T15:41:38Z",
            "published": "2023-09-06T15:41:38Z",
            "summary": "This paper presents ContrastWSD, a RoBERTa-based metaphor detection model\nthat integrates the Metaphor Identification Procedure (MIP) and Word Sense\nDisambiguation (WSD) to extract and contrast the contextual meaning with the\nbasic meaning of a word to determine whether it is used metaphorically in a\nsentence. By utilizing the word senses derived from a WSD model, our model\nenhances the metaphor detection process and outperforms other methods that rely\nsolely on contextual embeddings or integrate only the basic definitions and\nother external knowledge. We evaluate our approach on various benchmark\ndatasets and compare it with strong baselines, indicating the effectiveness in\nadvancing metaphor detection.",
            "author": [
                "Mohamad Elzohbi",
                "Richard Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03103v1",
                "http://arxiv.org/pdf/2309.03103v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03076v1",
            "title": "Purposeful Co-Design of OFDM Signals for Ranging and Communications",
            "updated": "2023-09-06T15:24:42Z",
            "published": "2023-09-06T15:24:42Z",
            "summary": "This paper analyzes the fundamental trade-offs that occur in the co-design of\northogonal frequency-division multiplexing signals for both ranging (via\ntime-of-arrival estimation) and communications. These trade-offs are quantified\nthrough the Shannon capacity bound, probability of outage, and the Ziv-Zakai\nbound on range estimation variance. Bounds are derived for signals experiencing\nfrequency-selective Rayleigh block fading, accounting for the impact of limited\nchannel knowledge and multi-antenna reception. Uncompensated carrier frequency\noffset and phase errors are also factored into the capacity bounds. Analysis\nbased on the derived bounds demonstrates how Pareto-optimal design choices can\nbe made to optimize the communication throughput, probability of outage, and\nranging variance. Different signal design strategies are then analyzed, showing\nhow Pareto-optimal design choices change depending on the channel.",
            "author": [
                "Andrew Graff",
                "Todd E. Humphreys"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03076v1",
                "http://arxiv.org/pdf/2309.03076v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03067v1",
            "title": "A modelling framework for detecting and leveraging node-level\n  information in Bayesian network inference",
            "updated": "2023-09-06T15:12:37Z",
            "published": "2023-09-06T15:12:37Z",
            "summary": "Bayesian graphical models are powerful tools to infer complex relationships\nin high dimension, yet are often fraught with computational and statistical\nchallenges. If exploited in a principled way, the increasing information\ncollected alongside the data of primary interest constitutes an opportunity to\nmitigate these difficulties by guiding the detection of dependence structures.\nFor instance, gene network inference may be informed by the use of publicly\navailable summary statistics on the regulation of genes by genetic variants.\nHere we present a novel Gaussian graphical modelling framework to identify and\nleverage information on the centrality of nodes in conditional independence\ngraphs. Specifically, we consider a fully joint hierarchical model to\nsimultaneously infer (i) sparse precision matrices and (ii) the relevance of\nnode-level information for uncovering the sought-after network structure. We\nencode such information as candidate auxiliary variables using a spike-and-slab\nsubmodel on the propensity of nodes to be hubs, which allows hypothesis-free\nselection and interpretation of a sparse subset of relevant variables. As\nefficient exploration of large posterior spaces is needed for real-world\napplications, we develop a variational expectation conditional maximisation\nalgorithm that scales inference to hundreds of samples, nodes and auxiliary\nvariables. We illustrate and exploit the advantages of our approach in\nsimulations and in a gene network study which identifies hub genes involved in\nbiological pathways relevant to immune-mediated diseases.",
            "author": [
                "Xiaoyue Xi",
                "H\u00e9l\u00e8ne Ruffieux"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03067v1",
                "http://arxiv.org/pdf/2309.03067v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03023v1",
            "title": "Universal Preprocessing Operators for Embedding Knowledge Graphs with\n  Literals",
            "updated": "2023-09-06T14:08:46Z",
            "published": "2023-09-06T14:08:46Z",
            "summary": "Knowledge graph embeddings are dense numerical representations of entities in\na knowledge graph (KG). While the majority of approaches concentrate only on\nrelational information, i.e., relations between entities, fewer approaches\nexist which also take information about literal values (e.g., textual\ndescriptions or numerical information) into account. Those which exist are\ntypically tailored towards a particular modality of literal and a particular\nembedding method. In this paper, we propose a set of universal preprocessing\noperators which can be used to transform KGs with literals for numerical,\ntemporal, textual, and image information, so that the transformed KGs can be\nembedded with any method. The results on the kgbench dataset with three\ndifferent embedding methods show promising results.",
            "author": [
                "Patryk Preisner",
                "Heiko Paulheim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03023v1",
                "http://arxiv.org/pdf/2309.03023v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03019v1",
            "title": "Leveraging ASR Pretrained Conformers for Speaker Verification through\n  Transfer Learning and Knowledge Distillation",
            "updated": "2023-09-06T14:02:50Z",
            "published": "2023-09-06T14:02:50Z",
            "summary": "This paper explores the use of ASR-pretrained Conformers for speaker\nverification, leveraging their strengths in modeling speech signals. We\nintroduce three strategies: (1) Transfer learning to initialize the speaker\nembedding network, improving generalization and reducing overfitting. (2)\nKnowledge distillation to train a more flexible speaker verification model,\nincorporating frame-level ASR loss as an auxiliary task. (3) A lightweight\nspeaker adaptor for efficient feature conversion without altering the original\nASR Conformer, allowing parallel ASR and speaker verification. Experiments on\nVoxCeleb show significant improvements: transfer learning yields a 0.48% EER,\nknowledge distillation results in a 0.43% EER, and the speaker adaptor\napproach, with just an added 4.92M parameters to a 130.94M-parameter model,\nachieves a 0.57% EER. Overall, our methods effectively transfer ASR\ncapabilities to speaker verification tasks.",
            "author": [
                "Danwei Cai",
                "Ming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03019v1",
                "http://arxiv.org/pdf/2309.03019v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03006v2",
            "title": "Fuzz on the Beach: Fuzzing Solana Smart Contracts",
            "updated": "2023-10-04T09:42:17Z",
            "published": "2023-09-06T13:54:07Z",
            "summary": "Solana has quickly emerged as a popular platform for building decentralized\napplications (DApps), such as marketplaces for non-fungible tokens (NFTs). A\nkey reason for its success are Solana's low transaction fees and high\nperformance, which is achieved in part due to its stateless programming model.\nAlthough the literature features extensive tooling support for smart contract\nsecurity, current solutions are largely tailored for the Ethereum Virtual\nMachine. Unfortunately, the very stateless nature of Solana's execution\nenvironment introduces novel attack patterns specific to Solana requiring a\nrethinking for building vulnerability analysis methods.\n  In this paper, we address this gap and propose FuzzDelSol, the first\nbinary-only coverage-guided fuzzing architecture for Solana smart contracts.\nFuzzDelSol faithfully models runtime specifics such as smart contract\ninteractions. Moreover, since source code is not available for the large\nmajority of Solana contracts, FuzzDelSol operates on the contract's binary\ncode. Hence, due to the lack of semantic information, we carefully extracted\nlow-level program and state information to develop a diverse set of bug oracles\ncovering all major bug classes in Solana. Our extensive evaluation on 6049\nsmart contracts shows that FuzzDelSol's bug oracles find bugs with a high\nprecision and recall. To the best of our knowledge, this is the largest\nevaluation of the security landscape on the Solana mainnet.",
            "author": [
                "Sven Smolka",
                "Jens-Rene Giesen",
                "Pascal Winkler",
                "Oussama Draissi",
                "Lucas Davi",
                "Ghassan Karame",
                "Klaus Pohl"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03006v2",
                "http://arxiv.org/pdf/2309.03006v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02993v1",
            "title": "Counting triangles in regular graphs",
            "updated": "2023-09-06T13:36:39Z",
            "published": "2023-09-06T13:36:39Z",
            "summary": "In this paper, we investigate the minimum number of triangles, denoted by\n$t(n,k)$, in $n$-vertex $k$-regular graphs, where $n$ is an odd integer and $k$\nis an even integer. The well-known Andr\\'asfai-Erd\\H{o}s-S\\'os Theorem has\nestablished that $t(n,k)>0$ if $k>\\frac{2n}{5}$. In a striking work, Lo has\nprovided the exact value of $t(n,k)$ for sufficiently large $n$, given that\n$\\frac{2n}{5}+\\frac{12\\sqrt{n}}{5}<k<\\frac{n}{2}$. Here, we bridge the gap\nbetween the aforementioned results by determining the precise value of $t(n,k)$\nin the entire range $\\frac{2n}{5}<k<\\frac{n}{2}$. This confirms a conjecture of\nCambie, de Verclos, and Kang.",
            "author": [
                "Jialin He",
                "Xinmin Hou",
                "Jie Ma",
                "Tianying Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02993v1",
                "http://arxiv.org/pdf/2309.02993v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02990v1",
            "title": "Maximal Cliques in Scale-Free Random Graphs",
            "updated": "2023-09-06T13:35:13Z",
            "published": "2023-09-06T13:35:13Z",
            "summary": "We investigate the number of maximal cliques, i.e., cliques that are not\ncontained in any larger clique, in three network models: Erd\\H{o}s-R\\'enyi\nrandom graphs, inhomogeneous random graphs (also called Chung-Lu graphs), and\ngeometric inhomogeneous random graphs. For sparse and not-too-dense\nErd\\H{o}s-R\\'enyi graphs, we give linear and polynomial upper bounds on the\nnumber of maximal cliques. For the dense regime, we give super-polynomial and\neven exponential lower bounds. Although (geometric) inhomogeneous random graphs\nare sparse, we give super-polynomial lower bounds for these models. This comes\nform the fact that these graphs have a power-law degree distribution, which\nleads to a dense subgraph in which we find many maximal cliques. These lower\nbounds seem to contradict previous empirical evidence that (geometric)\ninhomogeneous random graphs have only few maximal cliques. We resolve this\ncontradiction by providing experiments indicating that, even for large\nnetworks, the linear lower-order terms dominate, before the super-polynomial\nasymptotic behavior kicks in only for networks of extreme size.",
            "author": [
                "Thomas Bl\u00e4sius",
                "Maximillian Katzmann",
                "Clara Stegehuis"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02990v1",
                "http://arxiv.org/pdf/2309.02990v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02986v1",
            "title": "Innovative approaches to high school physics competitions: Harnessing\n  the power of AI and open science",
            "updated": "2023-09-06T13:32:46Z",
            "published": "2023-09-06T13:32:46Z",
            "summary": "High school physics competitions serve as a platform for talented students to\nshowcase their skills, engage in challenging problems, and foster a passion for\nscience. This paper explores innovative approaches to enhance these\ncompetitions by harnessing the power of open science and artificial\nintelligence (AI) tools. Particularly we delve into the capabilities of\nstate-of-the-art AI chatbots, i.e. ChatGPT, Bard, Claude, related to problem\nsolving in physics. Together with open science tools like SageMath and Jupyter\nAI, they have the potential to serve as intelligent, powerful co-pilots,\ntutors, and assistants in understanding and applying physics, as well as\nknowledge from connected STEM fields. Furthermore, these innovative approaches\ncan revolutionize high school physics competitions, providing students and\ntheir tutors with powerful resources to excel in their scientific pursuits.",
            "author": [
                "Dominik Borovsk\u00fd",
                "Jozef Han\u010d",
                "Martina Han\u010dov\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02986v1",
                "http://arxiv.org/pdf/2309.02986v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02965v1",
            "title": "Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction",
            "updated": "2023-09-06T13:00:10Z",
            "published": "2023-09-06T13:00:10Z",
            "summary": "Reconstructing both objects and hands in 3D from a single RGB image is\ncomplex. Existing methods rely on manually defined hand-object constraints in\nEuclidean space, leading to suboptimal feature learning. Compared with\nEuclidean space, hyperbolic space better preserves the geometric properties of\nmeshes thanks to its exponentially-growing space distance, which amplifies the\ndifferences between the features based on similarity. In this work, we propose\nthe first precise hand-object reconstruction method in hyperbolic space, namely\nDynamic Hyperbolic Attention Network (DHANet), which leverages intrinsic\nproperties of hyperbolic space to learn representative features. Our method\nthat projects mesh and image features into a unified hyperbolic space includes\ntwo modules, ie. dynamic hyperbolic graph convolution and image-attention\nhyperbolic graph convolution. With these two modules, our method learns mesh\nfeatures with rich geometry-image multi-modal information and models better\nhand-object interaction. Our method provides a promising alternative for fine\nhand-object reconstruction in hyperbolic space. Extensive experiments on three\npublic datasets demonstrate that our method outperforms most state-of-the-art\nmethods.",
            "author": [
                "Zhiying Leng",
                "Shun-Cheng Wu",
                "Mahdi Saleh",
                "Antonio Montanaro",
                "Hao Yu",
                "Yin Wang",
                "Nassir Navab",
                "Xiaohui Liang",
                "Federico Tombari"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02965v1",
                "http://arxiv.org/pdf/2309.02965v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02953v1",
            "title": "Blended learning: A data-literate science teacher is a better teacher",
            "updated": "2023-09-06T12:42:49Z",
            "published": "2023-09-06T12:42:49Z",
            "summary": "The COVID-19 pandemic has underscored the importance of blended learning in\ncontemporary physics and, more generally, STEM education. In this contribution,\nwe summarize current pedagogical models of blended learning, such as rotational\nand flexible non-rotational models, and customizable configurations of physical\nand virtual learning spaces. With the inevitable integration of digital\ntechnology as one of the pillars of blended learning, teachers find themselves\nin an unprecedented position to not only obtain data more frequently but also\nanalyze it and adjust instruction accordingly. Consequently, we discuss a\ncrucial element of blended learning effectiveness: data management and usage.\nIn this context, data literacy for teaching emerges as an essential skill for\neffective blended learning, encompassing the ability to transform various data\ntypes into actionable instructional knowledge and practices. In other words,\ncurrent research in physics education shows that a data-literate science\nteacher is a more prosperous and effective teacher.",
            "author": [
                "Jozef Han\u010d",
                "Dominik Borovsk\u00fd",
                "Martina Han\u010dov\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02953v1",
                "http://arxiv.org/pdf/2309.02953v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02952v1",
            "title": "SecureCyclon: Dependable Peer Sampling",
            "updated": "2023-09-06T12:40:00Z",
            "published": "2023-09-06T12:40:00Z",
            "summary": "Overlay management is the cornerstone of building robust and dependable\nPeer-to-Peer systems. A key component for building such overlays is the\npeer-sampling service, a mechanism that continuously supplies each node with a\nset of up-to-date peers randomly selected across all alive nodes. Arguably, the\nmost pernicious malicious action against such mechanisms is the provision of\narbitrarily created links that point at malicious nodes. This paper proposes\nSecureCyclon, a peer-sampling protocol that deterministically eliminates the\nability of malicious nodes to overrepresent themselves in Peer-to-Peer\noverlays. To the best of our knowledge, this is the first protocol to offer\nthis property, as previous works were able to only bound the proportion of\nexcessive links to malicious nodes, without completely eliminating them.\nSecureCyclon redefines the concept of node descriptors from just being\ncontainers of information that enable communication with specific nodes, to\nbeing communication certificates that traverse the network and enable nodes to\nprovably discover malicious nodes. We evaluate our solution with the conduction\nof extended simulations, and we demonstrate that it provides resilience even at\nthe extreme condition of 40% malicious node participation.",
            "author": [
                "Alexandros Antonov",
                "Spyros Voulgaris"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02952v1",
                "http://arxiv.org/pdf/2309.02952v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02938v1",
            "title": "MCMC Sampling of Directed Flag Complexes with Fixed Undirected Graphs",
            "updated": "2023-09-06T12:06:33Z",
            "published": "2023-09-06T12:06:33Z",
            "summary": "Constructing null models to test the significance of extracted information is\na crucial step in data analysis. In this work, we provide a uniformly\nsampleable null model of directed graphs with the same (or similar) number of\nsimplices in the flag complex, with the restriction of retaining the underlying\nundirected graph. We describe an MCMC-based algorithm to sample from this null\nmodel and statistically investigate the mixing behaviour. This is paired with a\nhigh-performance, Rust-based, publicly available implementation. The motivation\ncomes from topological data analysis of connectomes in neuroscience. In\nparticular, we answer the fundamental question: are the high Betti numbers\nobserved in the investigated graphs evidence of an interesting topology, or are\nthey merely a byproduct of the high numbers of simplices? Indeed, by applying\nour new tool on the connectome of C. Elegans and parts of the statistical\nreconstructions of the Blue Brain Project, we find that the Betti numbers\nobserved are considerable statistical outliers with respect to this new null\nmodel. We thus, for the first time, statistically confirm that topological data\nanalysis in microscale connectome research is extracting statistically\nmeaningful information.",
            "author": [
                "Florian Unger",
                "Jonathan Krebs"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02938v1",
                "http://arxiv.org/pdf/2309.02938v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.DM",
                "math.CO",
                "q-bio.QM",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03919v1",
            "title": "A hybrid quantum-classical fusion neural network to improve\n  protein-ligand binding affinity predictions for drug discovery",
            "updated": "2023-09-06T11:56:33Z",
            "published": "2023-09-06T11:56:33Z",
            "summary": "The field of drug discovery hinges on the accurate prediction of binding\naffinity between prospective drug molecules and target proteins, especially\nwhen such proteins directly influence disease progression. However, estimating\nbinding affinity demands significant financial and computational resources.\nWhile state-of-the-art methodologies employ classical machine learning (ML)\ntechniques, emerging hybrid quantum machine learning (QML) models have shown\npromise for enhanced performance, owing to their inherent parallelism and\ncapacity to manage exponential increases in data dimensionality. Despite these\nadvances, existing models encounter issues related to convergence stability and\nprediction accuracy. This paper introduces a novel hybrid quantum-classical\ndeep learning model tailored for binding affinity prediction in drug discovery.\nSpecifically, the proposed model synergistically integrates 3D and spatial\ngraph convolutional neural networks within an optimized quantum architecture.\nSimulation results demonstrate a 6% improvement in prediction accuracy relative\nto existing classical models, as well as a significantly more stable\nconvergence performance compared to previous classical approaches.",
            "author": [
                "S. Banerjee",
                "S. He Yuxun",
                "S. Konakanchi",
                "L. Ogunfowora",
                "S. Roy",
                "S. Selvaras",
                "L. Domingo",
                "M. Chehimi",
                "M. Djukic",
                "C. Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03919v1",
                "http://arxiv.org/pdf/2309.03919v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02933v1",
            "title": "How I got to like graph polynomials",
            "updated": "2023-09-06T11:53:48Z",
            "published": "2023-09-06T11:53:48Z",
            "summary": "For Boris Zilber on his 75th birthday.\n  I trace the roots of my collaboration with Boris Zilber, which combines\ncategoricity theory, finite model theory, algorithmics, and combinatorics.",
            "author": [
                "Johann A. Makowsky"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02933v1",
                "http://arxiv.org/pdf/2309.02933v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "03, 05, 68, 03C13, 03C35, 05C31, 68Q99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02923v1",
            "title": "Patched Line Segment Learning for Vector Road Mapping",
            "updated": "2023-09-06T11:33:25Z",
            "published": "2023-09-06T11:33:25Z",
            "summary": "This paper presents a novel approach to computing vector road maps from\nsatellite remotely sensed images, building upon a well-defined Patched Line\nSegment (PaLiS) representation for road graphs that holds geometric\nsignificance. Unlike prevailing methods that derive road vector representations\nfrom satellite images using binary masks or keypoints, our method employs line\nsegments. These segments not only convey road locations but also capture their\norientations, making them a robust choice for representation. More precisely,\ngiven an input image, we divide it into non-overlapping patches and predict a\nsuitable line segment within each patch. This strategy enables us to capture\nspatial and structural cues from these patch-based line segments, simplifying\nthe process of constructing the road network graph without the necessity of\nadditional neural networks for connectivity. In our experiments, we demonstrate\nhow an effective representation of a road graph significantly enhances the\nperformance of vector road mapping on established benchmarks, without requiring\nextensive modifications to the neural network architecture. Furthermore, our\nmethod achieves state-of-the-art performance with just 6 GPU hours of training,\nleading to a substantial 32-fold reduction in training costs in terms of GPU\nhours.",
            "author": [
                "Jiakun Xu",
                "Bowen Xu",
                "Gui-Song Xia",
                "Liang Dong",
                "Nan Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02923v1",
                "http://arxiv.org/pdf/2309.02923v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02902v1",
            "title": "ViCGCN: Graph Convolutional Network with Contextualized Language Models\n  for Social Media Mining in Vietnamese",
            "updated": "2023-09-06T10:51:34Z",
            "published": "2023-09-06T10:51:34Z",
            "summary": "Social media processing is a fundamental task in natural language processing\nwith numerous applications. As Vietnamese social media and information science\nhave grown rapidly, the necessity of information-based mining on Vietnamese\nsocial media has become crucial. However, state-of-the-art research faces\nseveral significant drawbacks, including imbalanced data and noisy data on\nsocial media platforms. Imbalanced and noisy are two essential issues that need\nto be addressed in Vietnamese social media texts. Graph Convolutional Networks\ncan address the problems of imbalanced and noisy data in text classification on\nsocial media by taking advantage of the graph structure of the data. This study\npresents a novel approach based on contextualized language model (PhoBERT) and\ngraph-based method (Graph Convolutional Networks). In particular, the proposed\napproach, ViCGCN, jointly trained the power of Contextualized embeddings with\nthe ability of Graph Convolutional Networks, GCN, to capture more syntactic and\nsemantic dependencies to address those drawbacks. Extensive experiments on\nvarious Vietnamese benchmark datasets were conducted to verify our approach.\nThe observation shows that applying GCN to BERTology models as the final layer\nsignificantly improves performance. Moreover, the experiments demonstrate that\nViCGCN outperforms 13 powerful baseline models, including BERTology models,\nfusion BERTology and GCN models, other baselines, and SOTA on three benchmark\nsocial media datasets. Our proposed ViCGCN approach demonstrates a significant\nimprovement of up to 6.21%, 4.61%, and 2.63% over the best Contextualized\nLanguage Models, including multilingual and monolingual, on three benchmark\ndatasets, UIT-VSMEC, UIT-ViCTSD, and UIT-VSFC, respectively. Additionally, our\nintegrated model ViCGCN achieves the best performance compared to other\nBERTology integrated with GCN models.",
            "author": [
                "Chau-Thang Phan",
                "Quoc-Nam Nguyen",
                "Chi-Thanh Dang",
                "Trong-Hop Do",
                "Kiet Van Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02902v1",
                "http://arxiv.org/pdf/2309.02902v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02894v2",
            "title": "A Large-Scale Empirical Study on Semantic Versioning in Golang Ecosystem",
            "updated": "2023-09-18T02:07:59Z",
            "published": "2023-09-06T10:33:00Z",
            "summary": "Third-party libraries (TPLs) have become an essential component of software,\naccelerating development and reducing maintenance costs. However, breaking\nchanges often occur during the upgrades of TPLs and prevent client programs\nfrom moving forward. Semantic versioning (SemVer) has been applied to\nstandardize the versions of releases according to compatibility, but not all\nreleases follow SemVer compliance. Lots of work focuses on SemVer compliance in\necosystems such as Java and JavaScript beyond Golang (Go for short). Due to the\nlack of tools to detect breaking changes and dataset for Go, developers of TPLs\ndo not know if breaking changes occur and affect client programs, and\ndevelopers of client programs may hesitate to upgrade dependencies in terms of\nbreaking changes.\n  To bridge this gap, we conduct the first large-scale empirical study in the\nGo ecosystem to study SemVer compliance in terms of breaking changes and their\nimpact. In detail, we purpose GoSVI (Go Semantic Versioning Insight) to detect\nbreaking changes and analyze their impact by resolving identifiers in client\nprograms and comparing their types with breaking changes. Moreover, we collect\nthe first large-scale Go dataset with a dependency graph from GitHub, including\n124K TPLs and 532K client programs. Based on the dataset, our results show that\n86.3% of library upgrades follow SemVer compliance and 28.6% of no-major\nupgrades introduce breaking changes. Furthermore, the tendency to comply with\nSemVer has improved over time from 63.7% in 2018/09 to 92.2% in 2023/03.\nFinally, we find 33.3% of downstream client programs may be affected by\nbreaking changes. These findings provide developers and users of TPLs with\nvaluable insights to help make decisions related to SemVer.",
            "author": [
                "Wenke Li",
                "Feng Wu",
                "Cai Fu",
                "Fan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02894v2",
                "http://arxiv.org/pdf/2309.02894v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "K.6.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02887v1",
            "title": "A deep Natural Language Inference predictor without language-specific\n  training data",
            "updated": "2023-09-06T10:20:59Z",
            "published": "2023-09-06T10:20:59Z",
            "summary": "In this paper we present a technique of NLP to tackle the problem of\ninference relation (NLI) between pairs of sentences in a target language of\nchoice without a language-specific training dataset. We exploit a generic\ntranslation dataset, manually translated, along with two instances of the same\npre-trained model - the first to generate sentence embeddings for the source\nlanguage, and the second fine-tuned over the target language to mimic the\nfirst. This technique is known as Knowledge Distillation. The model has been\nevaluated over machine translated Stanford NLI test dataset, machine translated\nMulti-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We\nalso test the proposed architecture over different tasks to empirically\ndemonstrate the generality of the NLI task. The model has been evaluated over\nthe native Italian ABSITA dataset, on the tasks of Sentiment Analysis,\nAspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the\ngenerality and exploitability of the Knowledge Distillation technique that\noutperforms other methodologies based on machine translation, even though the\nformer was not directly trained on the data it was tested over.",
            "author": [
                "Lorenzo Corradi",
                "Alessandro Manenti",
                "Francesca Del Bonifro",
                "Francesco Setti",
                "Dario Del Sorbo"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43153-1_15",
                "http://arxiv.org/abs/2309.02887v1",
                "http://arxiv.org/pdf/2309.02887v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02876v1",
            "title": "Non-Clashing Teaching Maps for Balls in Graphs",
            "updated": "2023-09-06T10:02:58Z",
            "published": "2023-09-06T10:02:58Z",
            "summary": "Recently, Kirkpatrick et al. [ALT 2019] and Fallat et al. [JMLR 2023]\nintroduced non-clashing teaching and showed it to be the most efficient machine\nteaching model satisfying the benchmark for collusion-avoidance set by Goldman\nand Mathias. A teaching map $T$ for a concept class $\\cal{C}$ assigns a\n(teaching) set $T(C)$ of examples to each concept $C \\in \\cal{C}$. A teaching\nmap is non-clashing if no pair of concepts are consistent with the union of\ntheir teaching sets. The size of a non-clashing teaching map (NCTM) $T$ is the\nmaximum size of a $T(C)$, $C \\in \\cal{C}$. The non-clashing teaching dimension\nNCTD$(\\cal{C})$ of $\\cal{C}$ is the minimum size of an NCTM for $\\cal{C}$.\nNCTM$^+$ and NCTD$^+(\\cal{C})$ are defined analogously, except the teacher may\nonly use positive examples.\n  We study NCTMs and NCTM$^+$s for the concept class $\\mathcal{B}(G)$\nconsisting of all balls of a graph $G$. We show that the associated decision\nproblem {\\sc B-NCTD$^+$} for NCTD$^+$ is NP-complete in split, co-bipartite,\nand bipartite graphs. Surprisingly, we even prove that, unless the ETH fails,\n{\\sc B-NCTD$^+$} does not admit an algorithm running in time\n$2^{2^{o(vc)}}\\cdot n^{O(1)}$, nor a kernelization algorithm outputting a\nkernel with $2^{o(vc)}$ vertices, where vc is the vertex cover number of $G$.\nThese are extremely rare results: it is only the second (fourth, resp.) problem\nin NP to admit a double-exponential lower bound parameterized by vc (treewidth,\nresp.), and only one of very few problems to admit an ETH-based conditional\nlower bound on the number of vertices in a kernel. We complement these lower\nbounds with matching upper bounds. For trees, interval graphs, cycles, and\ntrees of cycles, we derive NCTM$^+$s or NCTMs for $\\mathcal{B}(G)$ of size\nproportional to its VC-dimension. For Gromov-hyperbolic graphs, we design an\napproximate NCTM$^+$ for $\\mathcal{B}(G)$ of size 2.",
            "author": [
                "J\u00e9r\u00e9mie Chalopin",
                "Victor Chepoi",
                "Fionn Mc Inerney",
                "S\u00e9bastien Ratel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02876v1",
                "http://arxiv.org/pdf/2309.02876v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DM",
                "cs.DS",
                "cs.LG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02871v2",
            "title": "Moment of Inertia for Axisymmetric Neutron Stars in the Standard-Model\n  Extension",
            "updated": "2023-10-24T13:24:05Z",
            "published": "2023-09-06T09:50:48Z",
            "summary": "We develop a consistent approach to calculate the moment of inertia (MOI) for\naxisymmetric neutron stars (NSs) in the Lorentz-violating Standard-Model\nExtension (SME) framework. To our knowledge, this is the first relativistic MOI\ncalculation for axisymmetric NSs in a Lorentz-violating gravity theory other\nthan deformed, rotating NSs in the General Relativity. Under Lorentz violation,\nthere is a specific direction in the spacetime and NSs get stretched or\ncompressed along that direction. When a NS is spinning stationarily along this\ndirection, a conserved angular momentum and the concept of MOI are well\ndefined. In the SME framework, we calculate the partial differential equation\ngoverning the rotation and solve it numerically with the finite element method\nto get the MOI for axisymmetric NSs caused by Lorentz violation. Besides, we\nstudy an approximate case where the correction to the MOI is regarded solely\nfrom the deformation of the NS and compare it with its counterpart in the\nNewtonian gravity. Our formalism and the numerical method can be extended to\nother theories of gravity for static axisymmetric NSs.",
            "author": [
                "Yiming Dong",
                "Zexin Hu",
                "Rui Xu",
                "Lijing Shao"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevD.108.104039",
                "http://arxiv.org/abs/2309.02871v2",
                "http://arxiv.org/pdf/2309.02871v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02870v1",
            "title": "Rethinking Momentum Knowledge Distillation in Online Continual Learning",
            "updated": "2023-09-06T09:49:20Z",
            "published": "2023-09-06T09:49:20Z",
            "summary": "Online Continual Learning (OCL) addresses the problem of training neural\nnetworks on a continuous data stream where multiple classification tasks emerge\nin sequence. In contrast to offline Continual Learning, data can be seen only\nonce in OCL. In this context, replay-based strategies have achieved impressive\nresults and most state-of-the-art approaches are heavily depending on them.\nWhile Knowledge Distillation (KD) has been extensively used in offline\nContinual Learning, it remains under-exploited in OCL, despite its potential.\nIn this paper, we theoretically analyze the challenges in applying KD to OCL.\nWe introduce a direct yet effective methodology for applying Momentum Knowledge\nDistillation (MKD) to many flagship OCL methods and demonstrate its\ncapabilities to enhance existing approaches. In addition to improving existing\nstate-of-the-arts accuracy by more than $10\\%$ points on ImageNet100, we shed\nlight on MKD internal mechanics and impacts during training in OCL. We argue\nthat similar to replay, MKD should be considered a central component of OCL.",
            "author": [
                "Nicolas Michel",
                "Maorong Wang",
                "Ling Xiao",
                "Toshihiko Yamasaki"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02870v1",
                "http://arxiv.org/pdf/2309.02870v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02868v2",
            "title": "Enhancing Asynchronous Time Series Forecasting with Contrastive\n  Relational Inference",
            "updated": "2023-10-07T02:14:44Z",
            "published": "2023-09-06T09:47:03Z",
            "summary": "Asynchronous time series, also known as temporal event sequences, are the\nbasis of many applications throughout different industries. Temporal point\nprocesses(TPPs) are the standard method for modeling such data. Existing TPP\nmodels have focused on parameterizing the conditional distribution of future\nevents instead of explicitly modeling event interactions, imposing challenges\nfor event predictions. In this paper, we propose a novel approach that\nleverages Neural Relational Inference (NRI) to learn a relation graph that\ninfers interactions while simultaneously learning the dynamics patterns from\nobservational data. Our approach, the Contrastive Relational Inference-based\nHawkes Process (CRIHP), reasons about event interactions under a variational\ninference framework. It utilizes intensity-based learning to search for\nprototype paths to contrast relationship constraints. Extensive experiments on\nthree real-world datasets demonstrate the effectiveness of our model in\ncapturing event interactions for event sequence modeling tasks. Code will be\nintegrated into the EasyTPP framework.",
            "author": [
                "Yan Wang",
                "Zhixuan Chu",
                "Tao Zhou",
                "Caigao Jiang",
                "Hongyan Hao",
                "Minjie Zhu",
                "Xindong Cai",
                "Qing Cui",
                "Longfei Li",
                "James Y Zhang",
                "Siqiao Xue",
                "Jun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02868v2",
                "http://arxiv.org/pdf/2309.02868v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02861v1",
            "title": "Image Aesthetics Assessment via Learnable Queries",
            "updated": "2023-09-06T09:42:16Z",
            "published": "2023-09-06T09:42:16Z",
            "summary": "Image aesthetics assessment (IAA) aims to estimate the aesthetics of images.\nDepending on the content of an image, diverse criteria need to be selected to\nassess its aesthetics. Existing works utilize pre-trained vision backbones\nbased on content knowledge to learn image aesthetics. However, training those\nbackbones is time-consuming and suffers from attention dispersion. Inspired by\nlearnable queries in vision-language alignment, we propose the Image Aesthetics\nAssessment via Learnable Queries (IAA-LQ) approach. It adapts learnable queries\nto extract aesthetic features from pre-trained image features obtained from a\nfrozen image encoder. Extensive experiments on real-world data demonstrate the\nadvantages of IAA-LQ, beating the best state-of-the-art method by 2.2% and 2.1%\nin terms of SRCC and PLCC, respectively.",
            "author": [
                "Zhiwei Xiong",
                "Yunfan Zhang",
                "Zhiqi Shen",
                "Peiran Ren",
                "Han Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02861v1",
                "http://arxiv.org/pdf/2309.02861v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02852v2",
            "title": "CelticGraph: Drawing Graphs as Celtic Knots and Links",
            "updated": "2023-09-14T20:51:55Z",
            "published": "2023-09-06T09:25:40Z",
            "summary": "Celtic knots are an ancient art form often attributed to Celtic cultures,\nused to decorate monuments and manuscripts, and to symbolise eternity and\ninterconnectedness. This paper describes the framework CelticGraph to draw\ngraphs as Celtic knots and links. The drawing process raises interesting\ncombinatorial concepts in the theory of circuits in planar graphs. Further,\nCelticGraph uses a novel algorithm to represent edges as B\\'ezier curves,\naiming to show each link as a smooth curve with limited curvature.",
            "author": [
                "Peter Eades",
                "Niklas Gr\u00f6ne",
                "Karsten Klein",
                "Patrick Eades",
                "Leo Schreiber",
                "Ulf Hailer",
                "Falk Schreiber"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02852v2",
                "http://arxiv.org/pdf/2309.02852v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02848v1",
            "title": "Prompt-based Node Feature Extractor for Few-shot Learning on\n  Text-Attributed Graphs",
            "updated": "2023-09-06T09:12:52Z",
            "published": "2023-09-06T09:12:52Z",
            "summary": "Text-attributed Graphs (TAGs) are commonly found in the real world, such as\nsocial networks and citation networks, and consist of nodes represented by\ntextual descriptions. Currently, mainstream machine learning methods on TAGs\ninvolve a two-stage modeling approach: (1) unsupervised node feature extraction\nwith pre-trained language models (PLMs); and (2) supervised learning using\nGraph Neural Networks (GNNs). However, we observe that these representations,\nwhich have undergone large-scale pre-training, do not significantly improve\nperformance with a limited amount of training samples. The main issue is that\nexisting methods have not effectively integrated information from the graph and\ndownstream tasks simultaneously. In this paper, we propose a novel framework\ncalled G-Prompt, which combines a graph adapter and task-specific prompts to\nextract node features. First, G-Prompt introduces a learnable GNN layer\n(\\emph{i.e.,} adaptor) at the end of PLMs, which is fine-tuned to better\ncapture the masked tokens considering graph neighborhood information. After the\nadapter is trained, G-Prompt incorporates task-specific prompts to obtain\n\\emph{interpretable} node representations for the downstream task. Our\nexperiment results demonstrate that our proposed method outperforms current\nstate-of-the-art (SOTA) methods on few-shot node classification. More\nimportantly, in zero-shot settings, the G-Prompt embeddings can not only\nprovide better task interpretability than vanilla PLMs but also achieve\ncomparable performance with fully-supervised baselines.",
            "author": [
                "Xuanwen Huang",
                "Kaiqiao Han",
                "Dezheng Bao",
                "Quanjin Tao",
                "Zhisheng Zhang",
                "Yang Yang",
                "Qi Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02848v1",
                "http://arxiv.org/pdf/2309.02848v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02843v1",
            "title": "Knowledge Distillation Layer that Lets the Student Decide",
            "updated": "2023-09-06T09:05:03Z",
            "published": "2023-09-06T09:05:03Z",
            "summary": "Typical technique in knowledge distillation (KD) is regularizing the learning\nof a limited capacity model (student) by pushing its responses to match a\npowerful model's (teacher). Albeit useful especially in the penultimate layer\nand beyond, its action on student's feature transform is rather implicit,\nlimiting its practice in the intermediate layers. To explicitly embed the\nteacher's knowledge in feature transform, we propose a learnable KD layer for\nthe student which improves KD with two distinct abilities: i) learning how to\nleverage the teacher's knowledge, enabling to discard nuisance information, and\nii) feeding forward the transferred knowledge deeper. Thus, the student enjoys\nthe teacher's knowledge during the inference besides training. Formally, we\nrepurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each\nlocal region according to the template (supervised by the teacher) that the\ncorresponding region of the student matches. To facilitate template learning in\nthe intermediate layers, we propose a novel form of supervision based on the\nteacher's decisions. Through rigorous experimentation, we demonstrate the\neffectiveness of our approach on 3 popular classification benchmarks. Code is\navailable at: https://github.com/adagorgun/letKD-framework",
            "author": [
                "Ada Gorgun",
                "Yeti Z. Gurbuz",
                "A. Aydin Alatan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02843v1",
                "http://arxiv.org/pdf/2309.02843v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02833v1",
            "title": "Image-Object-Specific Prompt Learning for Few-Shot Class-Incremental\n  Learning",
            "updated": "2023-09-06T08:40:01Z",
            "published": "2023-09-06T08:40:01Z",
            "summary": "While many FSCIL studies have been undertaken, achieving satisfactory\nperformance, especially during incremental sessions, has remained challenging.\nOne prominent challenge is that the encoder, trained with an ample base session\ntraining set, often underperforms in incremental sessions. In this study, we\nintroduce a novel training framework for FSCIL, capitalizing on the\ngeneralizability of the Contrastive Language-Image Pre-training (CLIP) model to\nunseen classes. We achieve this by formulating image-object-specific (IOS)\nclassifiers for the input images. Here, an IOS classifier refers to one that\ntargets specific attributes (like wings or wheels) of class objects rather than\nthe image's background. To create these IOS classifiers, we encode a bias\nprompt into the classifiers using our specially designed module, which\nharnesses key-prompt pairs to pinpoint the IOS features of classes in each\nsession. From an FSCIL standpoint, our framework is structured to retain\nprevious knowledge and swiftly adapt to new sessions without forgetting or\noverfitting. This considers the updatability of modules in each session and\nsome tricks empirically found for fast convergence. Our approach consistently\ndemonstrates superior performance compared to state-of-the-art methods across\nthe miniImageNet, CIFAR100, and CUB200 datasets. Further, we provide additional\nexperiments to validate our learned model's ability to achieve IOS classifiers.\nWe also conduct ablation studies to analyze the impact of each module within\nthe architecture.",
            "author": [
                "In-Ug Yoon",
                "Tae-Min Choi",
                "Sun-Kyung Lee",
                "Young-Min Kim",
                "Jong-Hwan Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02833v1",
                "http://arxiv.org/pdf/2309.02833v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02821v1",
            "title": "A simple construction of the Anderson operator via its quadratic form in\n  dimensions two and three",
            "updated": "2023-09-06T08:09:00Z",
            "published": "2023-09-06T08:09:00Z",
            "summary": "We provide a simple construction of the Anderson operator in dimensions two\nand three. This is done through its quadratic form. We rely on an exponential\ntransform instead of the regularity structures or paracontrolled calculus which\nare usually used for the construction of the operator. The knowledge of the\nform is robust enough to deduce important properties such as positivity and\nirreducibility of the corresponding semigroup. The latter property gives\nexistence of a spectral gap.",
            "author": [
                "Antoine Mouzard",
                "El Maati Ouhabaz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02821v1",
                "http://arxiv.org/pdf/2309.02821v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math.PR",
                "math.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02817v1",
            "title": "On Minimizing the Energy of a Spherical Graph Representation",
            "updated": "2023-09-06T08:03:19Z",
            "published": "2023-09-06T08:03:19Z",
            "summary": "Graph representations are the generalization of geometric graph drawings from\nthe plane to higher dimensions. A method introduced by Tutte to optimize\nproperties of graph drawings is to minimize their energy. We explore this\nminimization for spherical graph representations, where the vertices lie on a\nunit sphere such that the origin is their barycentre. We present a primal and\ndual semidefinite program which can be used to find such a spherical graph\nrepresentation minimizing the energy. We denote the optimal value of this\nprogram by $\\rho(G)$ for a given graph $G$. The value turns out to be related\nto the second largest eigenvalue of the adjacency matrix of $G$, which we\ndenote by $\\lambda_2$. We show that for $G$ regular, $\\rho(G) \\leq\n\\frac{\\lambda_{2}}{2} \\cdot v(G)$, and that equality holds if and only if the\n$\\lambda_{2}$ eigenspace contains a spherical 1-design. Moreover, if $G$ is a\nrandom $d$-regular graph, $\\rho(G)=\\left(\\sqrt{(d-1)} +o(1)\\right)\\cdot v(G)$,\nasymptotically almost surely.",
            "author": [
                "Matt DeVos",
                "Danielle Rogers",
                "Alexandra Wesolek"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02817v1",
                "http://arxiv.org/pdf/2309.02817v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02805v1",
            "title": "Introducing Thermodynamics-Informed Symbolic Regression -- A Tool for\n  Thermodynamic Equations of State Development",
            "updated": "2023-09-06T07:48:22Z",
            "published": "2023-09-06T07:48:22Z",
            "summary": "Thermodynamic equations of state (EOS) are essential for many industries as\nwell as in academia. Even leaving aside the expensive and extensive measurement\ncampaigns required for the data acquisition, the development of EOS is an\nintensely time-consuming process, which does often still heavily rely on expert\nknowledge and iterative fine-tuning. To improve upon and accelerate the EOS\ndevelopment process, we introduce thermodynamics-informed symbolic regression\n(TiSR), a symbolic regression (SR) tool aimed at thermodynamic EOS modeling.\nTiSR is already a capable SR tool, which was used in the research of\nhttps://doi.org/10.1007/s10765-023-03197-z. It aims to combine an SR base with\nthe extensions required to work with often strongly scattered experimental\ndata, different residual pre- and post-processing options, and additional\nfeatures required to consider thermodynamic EOS development. Although TiSR is\nnot ready for end users yet, this paper is intended to report on its current\nstate, showcase the progress, and discuss (distant and not so distant) future\ndirections. TiSR is available at https://github.com/scoop-group/TiSR and can be\ncited as https://doi.org/10.5281/zenodo.8317547.",
            "author": [
                "Viktor Martinek",
                "Ophelia Frotscher",
                "Markus Richter",
                "Roland Herzog"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02805v1",
                "http://arxiv.org/pdf/2309.02805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02769v2",
            "title": "Unifying over-smoothing and over-squashing in graph neural networks: A\n  physics informed approach and beyond",
            "updated": "2023-09-13T00:17:19Z",
            "published": "2023-09-06T06:22:18Z",
            "summary": "Graph Neural Networks (GNNs) have emerged as one of the leading approaches\nfor machine learning on graph-structured data. Despite their great success,\ncritical computational challenges such as over-smoothing, over-squashing, and\nlimited expressive power continue to impact the performance of GNNs. In this\nstudy, inspired from the time-reversal principle commonly utilized in classical\nand quantum physics, we reverse the time direction of the graph heat equation.\nThe resulted reversing process yields a class of high pass filtering functions\nthat enhance the sharpness of graph node features. Leveraging this concept, we\nintroduce the Multi-Scaled Heat Kernel based GNN (MHKG) by amalgamating diverse\nfiltering functions' effects on node features. To explore more flexible\nfiltering conditions, we further generalize MHKG into a model termed G-MHKG and\nthoroughly show the roles of each element in controlling over-smoothing,\nover-squashing and expressive power. Notably, we illustrate that all\naforementioned issues can be characterized and analyzed via the properties of\nthe filtering functions, and uncover a trade-off between over-smoothing and\nover-squashing: enhancing node feature sharpness will make model suffer more\nfrom over-squashing, and vice versa. Furthermore, we manipulate the time again\nto show how G-MHKG can handle both two issues under mild conditions. Our\nconclusive experiments highlight the effectiveness of proposed models. It\nsurpasses several GNN baseline models in performance across graph datasets\ncharacterized by both homophily and heterophily.",
            "author": [
                "Zhiqi Shao",
                "Dai Shi",
                "Andi Han",
                "Yi Guo",
                "Qibin Zhao",
                "Junbin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02769v2",
                "http://arxiv.org/pdf/2309.02769v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02762v1",
            "title": "Towards Unsupervised Graph Completion Learning on Graphs with Features\n  and Structure Missing",
            "updated": "2023-09-06T06:20:12Z",
            "published": "2023-09-06T06:20:12Z",
            "summary": "In recent years, graph neural networks (GNN) have achieved significant\ndevelopments in a variety of graph analytical tasks. Nevertheless, GNN's\nsuperior performance will suffer from serious damage when the collected node\nfeatures or structure relationships are partially missing owning to numerous\nunpredictable factors. Recently emerged graph completion learning (GCL) has\nreceived increasing attention, which aims to reconstruct the missing node\nfeatures or structure relationships under the guidance of a specifically\nsupervised task. Although these proposed GCL methods have made great success,\nthey still exist the following problems: the reliance on labels, the bias of\nthe reconstructed node features and structure relationships. Besides, the\ngeneralization ability of the existing GCL still faces a huge challenge when\nboth collected node features and structure relationships are partially missing\nat the same time. To solve the above issues, we propose a more general GCL\nframework with the aid of self-supervised learning for improving the task\nperformance of the existing GNN variants on graphs with features and structure\nmissing, termed unsupervised GCL (UGCL). Specifically, to avoid the mismatch\nbetween missing node features and structure during the message-passing process\nof GNN, we separate the feature reconstruction and structure reconstruction and\ndesign its personalized model in turn. Then, a dual contrastive loss on the\nstructure level and feature level is introduced to maximize the mutual\ninformation of node representations from feature reconstructing and structure\nreconstructing paths for providing more supervision signals. Finally, the\nreconstructed node features and structure can be applied to the downstream node\nclassification task. Extensive experiments on eight datasets, three GNN\nvariants and five missing rates demonstrate the effectiveness of our proposed\nmethod.",
            "author": [
                "Sichao Fu",
                "Qinmu Peng",
                "Yang He",
                "Baokun Du",
                "Xinge You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02762v1",
                "http://arxiv.org/pdf/2309.02762v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02755v1",
            "title": "When Stars Control a Grammar's Work",
            "updated": "2023-09-06T06:18:10Z",
            "published": "2023-09-06T06:18:10Z",
            "summary": "Graph-controlled insertion-deletion (GCID) systems are regulated extensions\nof insertion-deletion systems. Such a system has several components and each\ncomponent contains some insertion-deletion rules. The components are the\nvertices of a directed control graph. A rule is applied to a string in a\ncomponent and the resultant string is moved to the target component specified\nin the rule. The language of the system is the set of all terminal strings\ncollected in the final component. We impose the restriction in the structure of\nthe underlying graph to be a star structure where there is a central, control\ncomponent which acts like a master and transmits a string (after applying one\nof its rules) to one of the components specified in the (applied) rule. A\ncomponent which receives the string can process the obtained string with any\napplicable rule available in it and sends back the resultant string only to the\ncenter component. With this restriction, we obtain computational completeness\nfor some descriptional complexity measures",
            "author": [
                "Henning Fernau",
                "Lakshmanan Kuppusamy",
                "Indhumathi Raman"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.386.9",
                "http://arxiv.org/abs/2309.02755v1",
                "http://arxiv.org/pdf/2309.02755v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "F.4.2; F.4.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02754v1",
            "title": "Pre- and post-contact policy decomposition for non-prehensile\n  manipulation with zero-shot sim-to-real transfer",
            "updated": "2023-09-06T06:17:53Z",
            "published": "2023-09-06T06:17:53Z",
            "summary": "We present a system for non-prehensile manipulation that require a\nsignificant number of contact mode transitions and the use of environmental\ncontacts to successfully manipulate an object to a target location. Our method\nis based on deep reinforcement learning which, unlike state-of-the-art planning\nalgorithms, does not require apriori knowledge of the physical parameters of\nthe object or environment such as friction coefficients or centers of mass. The\nplanning time is reduced to the simple feed-forward prediction time on a neural\nnetwork. We propose a computational structure, action space design, and\ncurriculum learning scheme that facilitates efficient exploration and\nsim-to-real transfer. In challenging real-world non-prehensile manipulation\ntasks, we show that our method can generalize over different objects, and\nsucceed even for novel objects not seen during training. Project website:\nhttps://sites.google.com/view/nonprenehsile-decomposition",
            "author": [
                "Minchan Kim",
                "Junhyek Han",
                "Jaehyung Kim",
                "Beomjoon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02754v1",
                "http://arxiv.org/pdf/2309.02754v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03240v1",
            "title": "RepSGG: Novel Representations of Entities and Relationships for Scene\n  Graph Generation",
            "updated": "2023-09-06T05:37:19Z",
            "published": "2023-09-06T05:37:19Z",
            "summary": "Scene Graph Generation (SGG) has achieved significant progress recently.\nHowever, most previous works rely heavily on fixed-size entity representations\nbased on bounding box proposals, anchors, or learnable queries. As each\nrepresentation's cardinality has different trade-offs between performance and\ncomputation overhead, extracting highly representative features efficiently and\ndynamically is both challenging and crucial for SGG. In this work, a novel\narchitecture called RepSGG is proposed to address the aforementioned\nchallenges, formulating a subject as queries, an object as keys, and their\nrelationship as the maximum attention weight between pairwise queries and keys.\nWith more fine-grained and flexible representation power for entities and\nrelationships, RepSGG learns to sample semantically discriminative and\nrepresentative points for relationship inference. Moreover, the long-tailed\ndistribution also poses a significant challenge for generalization of SGG. A\nrun-time performance-guided logit adjustment (PGLA) strategy is proposed such\nthat the relationship logits are modified via affine transformations based on\nrun-time performance during training. This strategy encourages a more balanced\nperformance between dominant and rare classes. Experimental results show that\nRepSGG achieves the state-of-the-art or comparable performance on the Visual\nGenome and Open Images V6 datasets with fast inference speed, demonstrating the\nefficacy and efficiency of the proposed methods.",
            "author": [
                "Hengyue Liu",
                "Bir Bhanu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03240v1",
                "http://arxiv.org/pdf/2309.03240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02726v1",
            "title": "Large Language Models for Automated Open-domain Scientific Hypotheses\n  Discovery",
            "updated": "2023-09-06T05:19:41Z",
            "published": "2023-09-06T05:19:41Z",
            "summary": "Hypothetical induction is recognized as the main reasoning type when\nscientists make observations about the world and try to propose hypotheses to\nexplain those observations. Past research on hypothetical induction has a\nlimited setting that (1) the observation annotations of the dataset are not raw\nweb corpus but are manually selected sentences (resulting in a close-domain\nsetting); and (2) the ground truth hypotheses annotations are mostly\ncommonsense knowledge, making the task less challenging. In this work, we\npropose the first NLP dataset for social science academic hypotheses discovery,\nconsisting of 50 recent papers published in top social science journals. Raw\nweb corpora that are necessary for developing hypotheses in the published\npapers are also collected in the dataset, with the final goal of creating a\nsystem that automatically generates valid, novel, and helpful (to human\nresearchers) hypotheses, given only a pile of raw web corpora. The new dataset\ncan tackle the previous problems because it requires to (1) use raw web corpora\nas observations; and (2) propose hypotheses even new to humanity. A\nmulti-module framework is developed for the task, as well as three different\nfeedback mechanisms that empirically show performance gain over the base\nframework. Finally, our framework exhibits high performance in terms of both\nGPT-4 based evaluation and social science expert evaluation.",
            "author": [
                "Zonglin Yang",
                "Xinya Du",
                "Junxian Li",
                "Jie Zheng",
                "Soujanya Poria",
                "Erik Cambria"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02726v1",
                "http://arxiv.org/pdf/2309.02726v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02723v1",
            "title": "Using the Shapes Constraint Language for modelling regulatory\n  requirements",
            "updated": "2023-09-06T05:16:08Z",
            "published": "2023-09-06T05:16:08Z",
            "summary": "Ontologies are traditionally expressed in the Web Ontology Language (OWL),\nthat provides a syntax for expressing taxonomies with axioms regulating class\nmembership. The semantics of OWL, based on Description Logic (DL), allows for\nthe use of automated reasoning to check the consistency of ontologies, perform\nclassification, and to answer DL queries. However, the open world assumption of\nOWL, along with limitations in its expressiveness, makes OWL less suitable for\nmodelling rules and regulations, used in public administration. In such cases,\nit is desirable to have closed world semantics and a rule-based engine to check\ncompliance with regulations. In this paper we describe and discuss data model\nmanagement using the Shapes Constraint Language (SHACL), for concept modelling\nof concrete requirements in regulation documents within the public sector. We\nshow how complex regulations, often containing a number of alternative\nrequirements, can be expressed as constraints, and the utility of SHACL engines\nin verification of instance data against the SHACL model. We discuss benefits\nof modelling with SHACL, compared to OWL, and demonstrate the maintainability\nof the SHACL model by domain experts without prior knowledge of ontology\nmanagement.",
            "author": [
                "Veronika Heimsbakk",
                "Kristian Torkelsen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02723v1",
                "http://arxiv.org/pdf/2309.02723v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02722v1",
            "title": "Reinforcement Learning of Action and Query Policies with LTL\n  Instructions under Uncertain Event Detector",
            "updated": "2023-09-06T05:12:07Z",
            "published": "2023-09-06T05:12:07Z",
            "summary": "Reinforcement learning (RL) with linear temporal logic (LTL) objectives can\nallow robots to carry out symbolic event plans in unknown environments. Most\nexisting methods assume that the event detector can accurately map\nenvironmental states to symbolic events; however, uncertainty is inevitable for\nreal-world event detectors. Such uncertainty in an event detector generates\nmultiple branching possibilities on LTL instructions, confusing action\ndecisions. Moreover, the queries to the uncertain event detector, necessary for\nthe task's progress, may increase the uncertainty further. To cope with those\nissues, we propose an RL framework, Learning Action and Query over Belief LTL\n(LAQBL), to learn an agent that can consider the diversity of LTL instructions\ndue to uncertain event detection while avoiding task failure due to the\nunnecessary event-detection query. Our framework simultaneously learns 1) an\nembedding of belief LTL, which is multiple branching possibilities on LTL\ninstructions using a graph neural network, 2) an action policy, and 3) a query\npolicy which decides whether or not to query for the event detector.\nSimulations in a 2D grid world and image-input robotic inspection environments\nshow that our method successfully learns actions to follow LTL instructions\neven with uncertain event detectors.",
            "author": [
                "Wataru Hatanaka",
                "Ryota Yamashina",
                "Takamitsu Matsubara"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02722v1",
                "http://arxiv.org/pdf/2309.02722v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02719v2",
            "title": "DMKD: Improving Feature-based Knowledge Distillation for Object\n  Detection Via Dual Masking Augmentation",
            "updated": "2023-09-07T03:36:37Z",
            "published": "2023-09-06T05:08:51Z",
            "summary": "Recent mainstream masked distillation methods function by reconstructing\nselectively masked areas of a student network from the feature map of its\nteacher counterpart. In these methods, the masked regions need to be properly\nselected, such that reconstructed features encode sufficient discrimination and\nrepresentation capability like the teacher feature. However, previous masked\ndistillation methods only focus on spatial masking, making the resulting masked\nareas biased towards spatial importance without encoding informative channel\nclues. In this study, we devise a Dual Masked Knowledge Distillation (DMKD)\nframework which can capture both spatially important and channel-wise\ninformative clues for comprehensive masked feature reconstruction. More\nspecifically, we employ dual attention mechanism for guiding the respective\nmasking branches, leading to reconstructed feature encoding dual significance.\nFurthermore, fusing the reconstructed features is achieved by self-adjustable\nweighting strategy for effective feature distillation. Our experiments on\nobject detection task demonstrate that the student networks achieve performance\ngains of 4.1% and 4.3% with the help of our method when RetinaNet and Cascade\nMask R-CNN are respectively used as the teacher networks, while outperforming\nthe other state-of-the-art distillation methods.",
            "author": [
                "Guang Yang",
                "Yin Tang",
                "Zhijian Wu",
                "Jun Li",
                "Jianhua Xu",
                "Xili Wan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02719v2",
                "http://arxiv.org/pdf/2309.02719v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02714v1",
            "title": "Atomic-scale observation of localized phonons at FeSe/SrTiO3 interface",
            "updated": "2023-09-06T04:57:52Z",
            "published": "2023-09-06T04:57:52Z",
            "summary": "In single unit-cell FeSe grown on SrTiO3, the superconductivity transition\ntemperature features a significant enhancement. Local phonon modes at the\ninterface associated with electron-phonon coupling may play an important role\nin the interface-induced enhancement. However, such phonon modes have eluded\ndirect experimental observations. Indeed, the complicated atomic structure of\nthe interface brings challenges to obtain the accurate structure-phonon\nrelation knowledge from either experiment or theory, thus hindering our\nunderstanding of the enhancement mechanism. Here, we achieve direct\ncharacterizations of atomic structure and phonon modes at the FeSe/SrTiO3\ninterface with atomically resolved imaging and electron energy loss\nspectroscopy in a scanning transmission electron microscope. We find several\nphonon modes highly localized (~1.3 nm) at the unique double layer Ti-O\ntermination at the interface, one of which (~ 83 meV) engages in strong\ninteractions with the electrons in FeSe based on ab initio calculations. The\nelectron-phonon coupling strength for such a localized interface phonon with\nshort-range interactions is comparable to that of Fuchs-Kliewer (FK) phonon\nmode with long-rang interactions. Thus, our atomic-scale study provides new\ninsights into understanding the origin of superconductivity enhancement at the\nFeSe/SrTiO3 interface.",
            "author": [
                "Ruochen Sh",
                "Qize Li",
                "Xiaofeng Xu",
                "Bo Han",
                "Ruixue Zhu",
                "Fachen Liu",
                "Ruishi Qi",
                "Xiaowen Zhang",
                "Jinlong Du",
                "Ji Chen",
                "Dapeng Yu",
                "Xuetao Zhu",
                "Jiandong Guo",
                "Peng Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02714v1",
                "http://arxiv.org/pdf/2309.02714v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02711v1",
            "title": "Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic\n  Extension",
            "updated": "2023-09-06T04:47:46Z",
            "published": "2023-09-06T04:47:46Z",
            "summary": "Symmetry, a fundamental concept to understand our environment, often\noversimplifies reality from a mathematical perspective. Humans are a prime\nexample, deviating from perfect symmetry in terms of appearance and cognitive\nbiases (e.g. having a dominant hand). Nevertheless, our brain can easily\novercome these imperfections and efficiently adapt to symmetrical tasks. The\ndriving motivation behind this work lies in capturing this ability through\nreinforcement learning. To this end, we introduce Adaptive Symmetry Learning\n(ASL) $\\unicode{x2013}$ a model-minimization actor-critic extension that\naddresses incomplete or inexact symmetry descriptions by adapting itself during\nthe learning process. ASL consists of a symmetry fitting component and a\nmodular loss function that enforces a common symmetric relation across all\nstates while adapting to the learned policy. The performance of ASL is compared\nto existing symmetry-enhanced methods in a case study involving a four-legged\nant model for multidirectional locomotion tasks. The results demonstrate that\nASL is capable of recovering from large perturbations and generalizing\nknowledge to hidden symmetric states. It achieves comparable or better\nperformance than alternative methods in most scenarios, making it a valuable\napproach for leveraging model symmetry while compensating for inherent\nperturbations.",
            "author": [
                "Miguel Abreu",
                "Luis Paulo Reis",
                "Nuno Lau"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02711v1",
                "http://arxiv.org/pdf/2309.02711v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02706v4",
            "title": "HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models",
            "updated": "2023-09-23T07:44:06Z",
            "published": "2023-09-06T04:38:16Z",
            "summary": "Large Language Models (LLMs) trained on massive corpora demonstrate\nimpressive capabilities in a wide range of tasks. While there are ongoing\nefforts to adapt these models to languages beyond English, the attention given\nto their evaluation methodologies remains limited. Current multilingual\nbenchmarks often rely on back translations or re-implementations of English\ntests, limiting their capacity to capture unique cultural and linguistic\nnuances. To bridge this gap for the Korean language, we introduce HAE-RAE\nBench, a dataset curated to challenge models lacking Korean cultural and\ncontextual depth. The dataset encompasses six downstream tasks across four\ndomains: vocabulary, history, general knowledge, and reading comprehension.\nContrary to traditional evaluation suites focused on token or sequence\nclassification and specific mathematical or logical reasoning, HAE-RAE Bench\nemphasizes a model's aptitude for recalling Korean-specific knowledge and\ncultural contexts. Comparative analysis with prior Korean benchmarks indicates\nthat the HAE-RAE Bench presents a greater challenge to non-native models, by\ndisturbing abilities and knowledge learned from English being transferred.",
            "author": [
                "Guijin Son",
                "Hanwool Lee",
                "Suwan Kim",
                "Huiseo Kim",
                "Jaecheol Lee",
                "Je Won Yeom",
                "Jihyu Jung",
                "Jung Woo Kim",
                "Songseong Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02706v4",
                "http://arxiv.org/pdf/2309.02706v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02704v1",
            "title": "Resistance distance in $k$-coalescence of certain graphs",
            "updated": "2023-09-06T04:31:56Z",
            "published": "2023-09-06T04:31:56Z",
            "summary": "Any graph can be considered as a network of resistors, each of which has a\nresistance of $1 \\Omega.$ The resistance distance $r_{ij}$ between a pair of\nvertices $i$ and $j$ in a graph is defined as the effective resistance between\n$i$ and $j$. This article deals with the resistance distance in the\n$k$-coalescence of complete graphs. We also present its results in connection\nwith the Kemeny's constant, Kirchhoff index, additive degree-Kirchhoff index,\nmultiplicative degree-Kirchhoff index and mixed degree-Kirchhoff index.\nMoreover, we obtain the resistance distance in the $k$-coalescence of a\ncomplete graph with particular graphs. As an application, we provide the\nresistance distance of certain graphs such as the vertex coalescence of a\ncomplete bipartite graph with a complete graph, a complete bipartite graph with\na star graph, the windmill graph, pineapple graph, etc.",
            "author": [
                "Haritha T",
                "Chithra A V"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02704v1",
                "http://arxiv.org/pdf/2309.02704v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C76, 05C09"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02700v1",
            "title": "The Rhodes semilattice of a biased graph",
            "updated": "2023-09-06T04:24:18Z",
            "published": "2023-09-06T04:24:18Z",
            "summary": "We reinterpret the Rhodes semilattices $R_n(\\mathfrak{G})$ of a group\n$\\mathfrak{G}$ in terms of gain graphs and generalize them to all gain graphs,\nboth as sets of partition-potential pairs and as sets of subgraphs, and for the\nlatter, further to biased graphs. Based on this we propose four different\nnatural lattices in which the Rhodes semilattices and its generalizations are\norder ideals.",
            "author": [
                "Michael J. Gottstein",
                "Thomas Zaslavsky"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02700v1",
                "http://arxiv.org/pdf/2309.02700v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "06A12 (Primary) 05B35, 05C22, 06C10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02692v1",
            "title": "Hy-DeFake: Hypergraph Neural Networks for Detecting Fake News in Online\n  Social Networks",
            "updated": "2023-09-06T04:00:21Z",
            "published": "2023-09-06T04:00:21Z",
            "summary": "Nowadays social media is the primary platform for people to obtain news and\nshare information. Combating online fake news has become an urgent task to\nreduce the damage it causes to society. Existing methods typically improve\ntheir fake news detection performances by utilizing textual auxiliary\ninformation (such as relevant retweets and comments) or simple structural\ninformation (i.e., graph construction). However, these methods face two\nchallenges. First, an increasing number of users tend to directly forward the\nsource news without adding comments, resulting in a lack of textual auxiliary\ninformation. Second, simple graphs are unable to extract complex relations\nbeyond pairwise association in a social context. Given that real-world social\nnetworks are intricate and involve high-order relations, we argue that\nexploring beyond pairwise relations between news and users is crucial for fake\nnews detection. Therefore, we propose constructing an attributed hypergraph to\nrepresent non-textual and high-order relations for user participation in news\nspreading. We also introduce a hypergraph neural network-based method called\nHy-DeFake to overcome the challenges. Our proposed method captures semantic\ninformation from news content, credibility information from involved users, and\nhigh-order correlations between news and users to learn distinctive embeddings\nfor fake news detection. The superiority of Hy-DeFake is demonstrated through\nexperiments conducted on four widely-used datasets, and it is compared against\nsix baselines using four evaluation metrics.",
            "author": [
                "Xing Su",
                "Jian Yang",
                "Jia Wu",
                "Zitai Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02692v1",
                "http://arxiv.org/pdf/2309.02692v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03239v2",
            "title": "Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd\n  Flow Inference",
            "updated": "2023-09-12T10:19:45Z",
            "published": "2023-09-06T02:51:24Z",
            "summary": "Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal\nfor effective traffic management, public service, and urban planning. Despite\nthis importance, due to the limitations of urban sensing techniques, the data\nquality from most sources is inadequate for monitoring crowd flow at each POI.\nThis renders the inference of accurate crowd flow from low-quality data a\ncritical and challenging task. The complexity is heightened by three key\nfactors: 1) The scarcity and rarity of labeled data, 2) The intricate\nspatio-temporal dependencies among POIs, and 3) The myriad correlations between\nprecise crowd flow and GPS reports.\n  To address these challenges, we recast the crowd flow inference problem as a\nself-supervised attributed graph representation learning task and introduce a\nnovel Contrastive Self-learning framework for Spatio-Temporal data (CSST). Our\napproach initiates with the construction of a spatial adjacency graph founded\non the POIs and their respective distances. We then employ a contrastive\nlearning technique to exploit large volumes of unlabeled spatio-temporal data.\nWe adopt a swapped prediction approach to anticipate the representation of the\ntarget subgraph from similar instances. Following the pre-training phase, the\nmodel is fine-tuned with accurate crowd flow data. Our experiments, conducted\non two real-world datasets, demonstrate that the CSST pre-trained on extensive\nnoisy data consistently outperforms models trained from scratch.",
            "author": [
                "Songyu Ke",
                "Ting Li",
                "Li Song",
                "Yanping Sun",
                "Qintian Sun",
                "Junbo Zhang",
                "Yu Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03239v2",
                "http://arxiv.org/pdf/2309.03239v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02668v1",
            "title": "Neural Networks for Fast Optimisation in Model Predictive Control: A\n  Review",
            "updated": "2023-09-06T02:34:00Z",
            "published": "2023-09-06T02:34:00Z",
            "summary": "Model Predictive Control (MPC) is an optimal control algorithm with strong\nstability and robustness guarantees. Despite its popularity in robotics and\nindustrial applications, the main challenge in deploying MPC is its high\ncomputation cost, stemming from the need to solve an optimisation problem at\neach control interval. There are several methods to reduce this cost. This\nsurvey focusses on approaches where a neural network is used to approximate an\nexisting controller. Herein, relevant and unique neural approximation methods\nfor linear, nonlinear, and robust MPC are presented and compared. Comparisons\nare based on the theoretical guarantees that are preserved, the factor by which\nthe original controller is sped up, and the size of problem that a framework is\napplicable to. Research contributions include: a taxonomy that organises\nexisting knowledge, a summary of literary gaps, discussion on promising\nresearch directions, and simple guidelines for choosing an approximation\nframework. The main conclusions are that (1) new benchmarking tools are needed\nto help prove the generalisability and scalability of approximation frameworks,\n(2) future breakthroughs most likely lie in the development of ties between\ncontrol and learning, and (3) the potential and applicability of recently\ndeveloped neural architectures and tools remains unexplored in this field.",
            "author": [
                "Camilo Gonzalez",
                "Houshyar Asadi",
                "Lars Kooijman",
                "Chee Peng Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02668v1",
                "http://arxiv.org/pdf/2309.02668v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC",
                "93-08",
                "I.2.8; J.2; J.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02665v1",
            "title": "Human Learning of Hierarchical Graphs",
            "updated": "2023-09-06T02:22:17Z",
            "published": "2023-09-06T02:22:17Z",
            "summary": "Humans are constantly exposed to sequences of events in the environment.\nThose sequences frequently evince statistical regularities, such as the\nprobabilities with which one event transitions to another. Collectively,\ninter-event transition probabilities can be modeled as a graph or network. Many\nreal-world networks are organized hierarchically and understanding how humans\nlearn these networks is an ongoing aim of current investigations. While much is\nknown about how humans learn basic transition graph topology, whether and to\nwhat degree humans can learn hierarchical structures in such graphs remains\nunknown. We investigate how humans learn hierarchical graphs of the\nSierpi\\'nski family using computer simulations and behavioral laboratory\nexperiments. We probe the mental estimates of transition probabilities via the\nsurprisal effect: a phenomenon in which humans react more slowly to less\nexpected transitions, such as those between communities or modules in the\nnetwork. Using mean-field predictions and numerical simulations, we show that\nsurprisal effects are stronger for finer-level than coarser-level hierarchical\ntransitions. Surprisal effects at coarser levels of the hierarchy are difficult\nto detect for limited learning times or in small samples. Using a serial\nresponse experiment with human participants (n=$100$), we replicate our\npredictions by detecting a surprisal effect at the finer-level of the hierarchy\nbut not at the coarser-level of the hierarchy. To further explain our findings,\nwe evaluate the presence of a trade-off in learning, whereby humans who learned\nthe finer-level of the hierarchy better tended to learn the coarser-level\nworse, and vice versa. Our study elucidates the processes by which humans learn\nhierarchical sequential events. Our work charts a road map for future\ninvestigation of the neural underpinnings and behavioral manifestations of\ngraph learning.",
            "author": [
                "Xiaohuan Xia",
                "Andrei A. Klishin",
                "Jennifer Stiso",
                "Christopher W. Lynn",
                "Ari E. Kahn",
                "Lorenzo Caciagli",
                "Dani S. Bassett"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02665v1",
                "http://arxiv.org/pdf/2309.02665v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cond-mat.stat-mech",
                "physics.bio-ph",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02662v1",
            "title": "Subsethood Measures of Spatial Granules",
            "updated": "2023-09-06T02:14:53Z",
            "published": "2023-09-06T02:14:53Z",
            "summary": "Subsethood, which is to measure the degree of set inclusion relation, is\npredominant in fuzzy set theory. This paper introduces some basic concepts of\nspatial granules, coarse-fine relation, and operations like meet, join,\nquotient meet and quotient join. All the atomic granules can be hierarchized by\nset-inclusion relation and all the granules can be hierarchized by coarse-fine\nrelation. Viewing an information system from the micro and the macro\nperspectives, we can get a micro knowledge space and a micro knowledge space,\nfrom which a rough set model and a spatial rough granule model are respectively\nobtained. The classical rough set model is the special case of the rough set\nmodel induced from the micro knowledge space, while the spatial rough granule\nmodel will be play a pivotal role in the problem-solving of structures. We\ndiscuss twelve axioms of monotone increasing subsethood and twelve\ncorresponding axioms of monotone decreasing supsethood, and generalize\nsubsethood and supsethood to conditional granularity and conditional fineness\nrespectively. We develop five conditional granularity measures and five\nconditional fineness measures and prove that each conditional granularity or\nfineness measure satisfies its corresponding twelve axioms although its\nsubsethood or supsethood measure only hold one of the two boundary conditions.\nWe further define five conditional granularity entropies and five conditional\nfineness entropies respectively, and each entropy only satisfies part of the\nboundary conditions but all the ten monotone conditions.",
            "author": [
                "Liquan Zhao",
                "Yiyu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02662v1",
                "http://arxiv.org/pdf/2309.02662v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02649v1",
            "title": "Controllability Backbone in Networks",
            "updated": "2023-09-06T01:21:45Z",
            "published": "2023-09-06T01:21:45Z",
            "summary": "This paper studies the controllability backbone problem in dynamical networks\ndefined over graphs. The main idea of the controllability backbone is to\nidentify a small subset of edges in a given network such that any subnetwork\ncontaining those edges/links has at least the same network controllability as\nthe original network while assuming the same set of input/leader vertices. We\nconsider the strong structural controllability (SSC) in our work, which is\nuseful but computationally challenging. Thus, we utilize two lower bounds on\nthe network's SSC based on the zero forcing notion and graph distances. We\nprovide algorithms to compute controllability backbones while preserving these\nlower bounds. We thoroughly analyze the proposed algorithms and compute the\nnumber of edges in the controllability backbones. Finally, we compare and\nnumerically evaluate our methods on random graphs.",
            "author": [
                "Obaid Ullah Ahmad",
                "Waseem Abbas",
                "Mudassir Shabbir"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02649v1",
                "http://arxiv.org/pdf/2309.02649v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.MA",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02637v1",
            "title": "Malicious Package Detection in NPM and PyPI using a Single Model of\n  Malicious Behavior Sequence",
            "updated": "2023-09-06T00:58:59Z",
            "published": "2023-09-06T00:58:59Z",
            "summary": "Open-source software (OSS) supply chain enlarges the attack surface, which\nmakes package registries attractive targets for attacks. Recently, package\nregistries NPM and PyPI have been flooded with malicious packages. The\neffectiveness of existing malicious NPM and PyPI package detection approaches\nis hindered by two challenges. The first challenge is how to leverage the\nknowledge of malicious packages from different ecosystems in a unified way such\nthat multi-lingual malicious package detection can be feasible. The second\nchallenge is how to model malicious behavior in a sequential way such that\nmaliciousness can be precisely captured. To address the two challenges, we\npropose and implement Cerebro to detect malicious packages in NPM and PyPI. We\ncurate a feature set based on a high-level abstraction of malicious behavior to\nenable multi-lingual knowledge fusing. We organize extracted features into a\nbehavior sequence to model sequential malicious behavior. We fine-tune the BERT\nmodel to understand the semantics of malicious behavior. Extensive evaluation\nhas demonstrated the effectiveness of Cerebro over the state-of-the-art as well\nas the practically acceptable efficiency. Cerebro has successfully detected 306\nand 196 new malicious packages in PyPI and NPM, and received 385 thank letters\nfrom the official PyPI and NPM teams.",
            "author": [
                "Junan Zhang",
                "Kaifeng Huang",
                "Bihuan Chen",
                "Chong Wang",
                "Zhenhao Tian",
                "Xin Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02637v1",
                "http://arxiv.org/pdf/2309.02637v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02635v1",
            "title": "Efficient Maximum $k$-Defective Clique Computation with Improved Time\n  Complexity",
            "updated": "2023-09-06T00:50:53Z",
            "published": "2023-09-06T00:50:53Z",
            "summary": "$k$-defective cliques relax cliques by allowing up-to $k$ missing edges from\nbeing a complete graph. This relaxation enables us to find larger near-cliques\nand has applications in link prediction, cluster detection, social network\nanalysis and transportation science. The problem of finding the largest\n$k$-defective clique has been recently studied with several algorithms being\nproposed in the literature. However, the currently fastest algorithm KDBB does\nnot improve its time complexity from being the trivial $O(2^n)$, and also,\nKDBB's practical performance is still not satisfactory. In this paper, we\nadvance the state of the art for exact maximum $k$-defective clique\ncomputation, in terms of both time complexity and practical performance.\nMoreover, we separate the techniques required for achieving the time complexity\nfrom others purely used for practical performance consideration; this design\nchoice may facilitate the research community to further improve the practical\nefficiency while not sacrificing the worst case time complexity. In specific,\nwe first develop a general framework kDC that beats the trivial time complexity\nof $O(2^n)$ and achieves a better time complexity than all existing algorithms.\nThe time complexity of kDC is solely achieved by non-fully-adjacent-first\nbranching rule, excess-removal reduction rule and high-degree reduction rule.\nThen, to make kDC practically efficient, we further propose a new upper bound,\ntwo reduction rules, and an algorithm for efficiently computing a large initial\nsolution. Extensive empirical studies on three benchmark graph collections with\n$290$ graphs in total demonstrate that kDC outperforms the currently fastest\nalgorithm KDBB by several orders of magnitude.",
            "author": [
                "Lijun Chang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3617313",
                "http://arxiv.org/abs/2309.02635v1",
                "http://arxiv.org/pdf/2309.02635v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02601v1",
            "title": "Compatibility graphs in scheduling on batch processing machines",
            "updated": "2023-09-05T22:17:33Z",
            "published": "2023-09-05T22:17:33Z",
            "summary": "We consider the problem of minimizing the makespan on batch processing\nidentical machines, subject to compatibility constraints, where two jobs are\ncompatible if they can be processed simultaneously in a same batch. These\nconstraints are modeled by an undirected graph $G$, in which compatible jobs\nare represented by adjacent vertices. We show that several subproblems are\npolynomial. We propose some exact polynomial algorithms to solve these\nsubproblems. To solve the general case, we propose a mixed-integer linear\nprogramming (MILP) formulation alongside with heuristic approaches.\nFurthermore, computational experiments are carried out to measure the\nperformance of the proposed methods.",
            "author": [
                "Khaoula Bouakaz",
                "Mourad Boudhar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02601v1",
                "http://arxiv.org/pdf/2309.02601v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "90B35, 68R10, 05C85, 05C90, 05C70"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02589v2",
            "title": "Approximating High-Dimensional Minimal Surfaces with Physics-Informed\n  Neural Networks",
            "updated": "2023-09-07T03:25:15Z",
            "published": "2023-09-05T21:25:50Z",
            "summary": "In this paper, we compute numerical approximations of the minimal surfaces,\nan essential type of Partial Differential Equation (PDE), in higher dimensions.\nClassical methods cannot handle it in this case because of the Curse of\nDimensionality, where the computational cost of these methods increases\nexponentially fast in response to higher problem dimensions, far beyond the\ncomputing capacity of any modern supercomputers. Only in the past few years\nhave machine learning researchers been able to mitigate this problem. The\nsolution method chosen here is a model known as a Physics-Informed Neural\nNetwork (PINN) which trains a deep neural network (DNN) to solve the minimal\nsurface PDE. It can be scaled up into higher dimensions and trained relatively\nquickly even on a laptop with no GPU. Due to the inability to view the\nhigh-dimension output, our data is presented as snippets of a higher-dimension\nshape with enough fixed axes so that it is viewable with 3-D graphs. Not only\nwill the functionality of this method be tested, but we will also explore\npotential limitations in the method's performance.",
            "author": [
                "Steven Zhou",
                "Xiaojing Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02589v2",
                "http://arxiv.org/pdf/2309.02589v2"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02583v1",
            "title": "Representation Learning for Sequential Volumetric Design Tasks",
            "updated": "2023-09-05T21:21:06Z",
            "published": "2023-09-05T21:21:06Z",
            "summary": "Volumetric design, also called massing design, is the first and critical step\nin professional building design which is sequential in nature. As the\nvolumetric design process is complex, the underlying sequential design process\nencodes valuable information for designers. Many efforts have been made to\nautomatically generate reasonable volumetric designs, but the quality of the\ngenerated design solutions varies, and evaluating a design solution requires\neither a prohibitively comprehensive set of metrics or expensive human\nexpertise. While previous approaches focused on learning only the final design\ninstead of sequential design tasks, we propose to encode the design knowledge\nfrom a collection of expert or high-performing design sequences and extract\nuseful representations using transformer-based models. Later we propose to\nutilize the learned representations for crucial downstream applications such as\ndesign preference evaluation and procedural design generation. We develop the\npreference model by estimating the density of the learned representations\nwhereas we train an autoregressive transformer model for sequential design\ngeneration. We demonstrate our ideas by leveraging a novel dataset of thousands\nof sequential volumetric designs. Our preference model can compare two\narbitrarily given design sequences and is almost 90% accurate in evaluation\nagainst random design sequences. Our autoregressive model is also capable of\nautocompleting a volumetric design sequence from a partial design sequence.",
            "author": [
                "Md Ferdous Alam",
                "Yi Wang",
                "Linh Tran",
                "Chin-Yi Cheng",
                "Jieliang Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02583v1",
                "http://arxiv.org/pdf/2309.02583v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02579v2",
            "title": "A Social Network Approach to Analyzing Token Properties and Abnormal\n  Events in Decentralized Exchanges",
            "updated": "2023-10-21T11:22:16Z",
            "published": "2023-09-05T20:59:38Z",
            "summary": "The properties of tokens within the Ethereum blockchain, such as their\ncurrent prices, trade volumes, and potential future values, have been the\nsubjects of numerous studies. Employing social networks and graphs, as powerful\ntools for modeling connections within groups or communities would provide\nvaluable guidance for analyzing these properties. This study mainly focuses on\ncreating and examining networks related to two major decentralized exchanges\nincluding Uniswap Version 2 (UniswapV2) and SushiSwap. We have discovered that\nthe distribution of nodes' degrees follows a power law that makes them\nscale-free networks, in addition, the centrality of tokens in exchange graphs\nprovides valuable insights into their price and significance in cryptocurrency\nmarkets. These measures of centrality can be used to detect anomalies in\ncryptocurrency markets and prices. Notably, these networks exhibit remarkably\nsimilar structures, hinting at exciting research opportunities for modeling\nsuch networks.",
            "author": [
                "Aryan Soltani Mohammadi",
                "Moein Karami",
                "Amir Pasha Motamed",
                "Behnam Bahrak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02579v2",
                "http://arxiv.org/pdf/2309.02579v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02572v1",
            "title": "Experience Capture in Shipbuilding through Computer Applications and\n  Neural Networks",
            "updated": "2023-09-05T20:48:27Z",
            "published": "2023-09-05T20:48:27Z",
            "summary": "It has always been a severe loss for any establishment when an experienced\nhand retires or moves to another firm. The specific details of what his\njob/position entails will always make the work more efficient. To curtail such\nlosses, it is possible to implement a system that takes input from a new\nemployee regarding the challenges he/she is facing and match it to a previous\noccurrence where someone else held his/her chair. This system could be made\npossible with input through the ages from the array of individuals who managed\nthat particular job and processing this data through a neural network that\nrecognizes the pattern. The paper is based on data collected from traditional\nwooden dhow builders and some of the modern day unconventional shipyards. Since\nthe requirements for successful implementation in such scenarios seems too\nsteep at the moment, an alternate approach has been suggested by implementation\nthrough the design processes across multiple shipyards. The process entails the\ntraditional value passed down through generations regarding a particular\nprofession and analysis has been done regarding how this knowledge/experience\ncan be captured and preserved for future generations to work upon. A series of\ntools including SharePoint, MATLAB, and some similar software working in tandem\ncan be used for the design of the same. This research will provide valuable\ninsight as to how information sharing can be applied through generations for\neffective application of production capabilities.",
            "author": [
                "Sankaramangalam Ulhas Sangeet",
                "Sivaprasad K",
                "Yashwant R. Kamath"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02572v1",
                "http://arxiv.org/pdf/2309.02572v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02571v1",
            "title": "Causal Structure Recovery of Linear Dynamical Systems: An FFT based\n  Approach",
            "updated": "2023-09-05T20:45:34Z",
            "published": "2023-09-05T20:45:34Z",
            "summary": "Learning causal effects from data is a fundamental and well-studied problem\nacross science, especially when the cause-effect relationship is static in\nnature. However, causal effect is less explored when there are dynamical\ndependencies, i.e., when dependencies exist between entities across time.\nIdentifying dynamic causal effects from time-series observations is\ncomputationally expensive when compared to the static scenario. We demonstrate\nthat the computational complexity of recovering the causation structure for the\nvector auto-regressive (VAR) model is $O(Tn^3N^2)$, where $n$ is the number of\nnodes, $T$ is the number of samples, and $N$ is the largest time-lag in the\ndependency between entities. We report a method, with a reduced complexity of\n$O(Tn^3 \\log N)$, to recover the causation structure to obtain frequency-domain\n(FD) representations of time-series. Since FFT accumulates all the time\ndependencies on every frequency, causal inference can be performed efficiently\nby considering the state variables as random variables at any given frequency.\nWe additionally show that, for systems with interactions that are LTI,\ndo-calculus machinery can be realized in the FD resulting in versions of the\nclassical single-door (with cycles), front and backdoor criteria. We\ndemonstrate, for a large class of problems, graph reconstruction using\nmultivariate Wiener projections results in a significant computational\nadvantage with $O(n)$ complexity over reconstruction algorithms such as the PC\nalgorithm which has $O(n^q)$ complexity, where $q$ is the maximum neighborhood\nsize. This advantage accrues due to some remarkable properties of the phase\nresponse of the frequency-dependent Wiener coefficients which is not present in\nany time-domain approach.",
            "author": [
                "Mishfad Shaikh Veedu",
                "James Melbourne",
                "Murti V. Salapaka"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02571v1",
                "http://arxiv.org/pdf/2309.02571v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.DS",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02567v2",
            "title": "Symbolic Music Representations for Classification Tasks: A Systematic\n  Evaluation",
            "updated": "2023-09-10T12:36:04Z",
            "published": "2023-09-05T20:27:31Z",
            "summary": "Music Information Retrieval (MIR) has seen a recent surge in deep\nlearning-based approaches, which often involve encoding symbolic music (i.e.,\nmusic represented in terms of discrete note events) in an image-like or\nlanguage like fashion. However, symbolic music is neither an image nor a\nsentence, and research in the symbolic domain lacks a comprehensive overview of\nthe different available representations. In this paper, we investigate matrix\n(piano roll), sequence, and graph representations and their corresponding\nneural architectures, in combination with symbolic scores and performances on\nthree piece-level classification tasks. We also introduce a novel graph\nrepresentation for symbolic performances and explore the capability of graph\nrepresentations in global classification tasks. Our systematic evaluation shows\nadvantages and limitations of each input representation. Our results suggest\nthat the graph representation, as the newest and least explored among the three\napproaches, exhibits promising performance, while being more light-weight in\ntraining.",
            "author": [
                "Huan Zhang",
                "Emmanouil Karystinaios",
                "Simon Dixon",
                "Gerhard Widmer",
                "Carlos Eduardo Cancino-Chac\u00f3n"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02567v2",
                "http://arxiv.org/pdf/2309.02567v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.MM",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02565v1",
            "title": "2-Edge Distance-Balanced Graphs",
            "updated": "2023-09-05T20:24:54Z",
            "published": "2023-09-05T20:24:54Z",
            "summary": "In a graph A, for each two arbitrary vertices g, h with\nd(g,h)=2,|MAg2h|=mAg2h is introduced the number of edges of A that are closer\nto g than to h. We say A is a 2-edge distance-balanced graph if we have\nmAg2h=mAh2g. In this article, we verify the concept of these graphs and present\na method to recognize k-edge distance-balanced graphs for k = 2,3 using\nexistence of either even or odd cycles. Moreover, we investigate situations\nunder which the Cartesian and lexicographic products lead to 2-edge distance\n-balanced graphs. In some subdivision-related graphs 2-edge distance-balanced\nproperty is verified.",
            "author": [
                "Zohreh Aliannejadi",
                "Mehdi alaeiyan",
                "Alireza Gilani",
                "Jafar Asadpour"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02565v1",
                "http://arxiv.org/pdf/2309.02565v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C12, 05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02557v1",
            "title": "Sparse Partitioning Around Medoids",
            "updated": "2023-09-05T19:52:24Z",
            "published": "2023-09-05T19:52:24Z",
            "summary": "Partitioning Around Medoids (PAM, k-Medoids) is a popular clustering\ntechnique to use with arbitrary distance functions or similarities, where each\ncluster is represented by its most central object, called the medoid or the\ndiscrete median. In operations research, this family of problems is also known\nas facility location problem (FLP). FastPAM recently introduced a speedup for\nlarge k to make it applicable for larger problems, but the method still has a\nruntime quadratic in N. In this chapter, we discuss a sparse and asymmetric\nvariant of this problem, to be used for example on graph data such as road\nnetworks. By exploiting sparsity, we can avoid the quadratic runtime and memory\nrequirements, and make this method scalable to even larger problems, as long as\nwe are able to build a small enough graph of sufficient connectivity to perform\nlocal optimization. Furthermore, we consider asymmetric cases, where the set of\nmedoids is not identical to the set of points to be covered (or in the\ninterpretation of facility location, where the possible facility locations are\nnot identical to the consumer locations). Because of sparsity, it may be\nimpossible to cover all points with just k medoids for too small k, which would\nrender the problem unsolvable, and this breaks common heuristics for finding a\ngood starting condition. We, hence, consider determining k as a part of the\noptimization problem and propose to first construct a greedy initial solution\nwith a larger k, then to optimize the problem by alternating between PAM-style\n\"swap\" operations where the result is improved by replacing medoids with better\nalternatives and \"remove\" operations to reduce the number of k until neither\nallows further improving the result quality. We demonstrate the usefulness of\nthis method on a problem from electrical engineering, with the input graph\nderived from cartographic data.",
            "author": [
                "Lars Lenssen",
                "Erich Schubert"
            ],
            "link": [
                "http://dx.doi.org/10.1515/9783110785944-005",
                "http://arxiv.org/abs/2309.02557v1",
                "http://arxiv.org/pdf/2309.02557v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02555v1",
            "title": "A Survey of the Impact of Self-Supervised Pretraining for Diagnostic\n  Tasks with Radiological Images",
            "updated": "2023-09-05T19:45:09Z",
            "published": "2023-09-05T19:45:09Z",
            "summary": "Self-supervised pretraining has been observed to be effective at improving\nfeature representations for transfer learning, leveraging large amounts of\nunlabelled data. This review summarizes recent research into its usage in\nX-ray, computed tomography, magnetic resonance, and ultrasound imaging,\nconcentrating on studies that compare self-supervised pretraining to fully\nsupervised learning for diagnostic tasks such as classification and\nsegmentation. The most pertinent finding is that self-supervised pretraining\ngenerally improves downstream task performance compared to full supervision,\nmost prominently when unlabelled examples greatly outnumber labelled examples.\nBased on the aggregate evidence, recommendations are provided for practitioners\nconsidering using self-supervised learning. Motivated by limitations identified\nin current research, directions and practices for future study are suggested,\nsuch as integrating clinical knowledge with theoretically justified\nself-supervised learning methods, evaluating on public datasets, growing the\nmodest body of evidence for ultrasound, and characterizing the impact of\nself-supervised pretraining on generalization.",
            "author": [
                "Blake VanBerlo",
                "Jesse Hoey",
                "Alexander Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02555v1",
                "http://arxiv.org/pdf/2309.02555v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02547v1",
            "title": "Structural Concept Learning via Graph Attention for Multi-Level\n  Rearrangement Planning",
            "updated": "2023-09-05T19:35:44Z",
            "published": "2023-09-05T19:35:44Z",
            "summary": "Robotic manipulation tasks, such as object rearrangement, play a crucial role\nin enabling robots to interact with complex and arbitrary environments.\nExisting work focuses primarily on single-level rearrangement planning and,\neven if multiple levels exist, dependency relations among substructures are\ngeometrically simpler, like tower stacking. We propose Structural Concept\nLearning (SCL), a deep learning approach that leverages graph attention\nnetworks to perform multi-level object rearrangement planning for scenes with\nstructural dependency hierarchies. It is trained on a self-generated simulation\ndata set with intuitive structures, works for unseen scenes with an arbitrary\nnumber of objects and higher complexity of structures, infers independent\nsubstructures to allow for task parallelization over multiple manipulators, and\ngeneralizes to the real world. We compare our method with a range of classical\nand model-based baselines to show that our method leverages its scene\nunderstanding to achieve better performance, flexibility, and efficiency. The\ndataset, supplementary details, videos, and code implementation are available\nat: https://manavkulshrestha.github.io/scl",
            "author": [
                "Manav Kulshrestha",
                "Ahmed H. Qureshi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02547v1",
                "http://arxiv.org/pdf/2309.02547v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02529v1",
            "title": "Fast and High-Performance Learned Image Compression With Improved\n  Checkerboard Context Model, Deformable Residual Module, and Knowledge\n  Distillation",
            "updated": "2023-09-05T18:41:31Z",
            "published": "2023-09-05T18:41:31Z",
            "summary": "Deep learning-based image compression has made great progresses recently.\nHowever, many leading schemes use serial context-adaptive entropy model to\nimprove the rate-distortion (R-D) performance, which is very slow. In addition,\nthe complexities of the encoding and decoding networks are quite high and not\nsuitable for many practical applications. In this paper, we introduce four\ntechniques to balance the trade-off between the complexity and performance. We\nare the first to introduce deformable convolutional module in compression\nframework, which can remove more redundancies in the input image, thereby\nenhancing compression performance. Second, we design a checkerboard context\nmodel with two separate distribution parameter estimation networks and\ndifferent probability models, which enables parallel decoding without\nsacrificing the performance compared to the sequential context-adaptive model.\nThird, we develop an improved three-step knowledge distillation and training\nscheme to achieve different trade-offs between the complexity and the\nperformance of the decoder network, which transfers both the final and\nintermediate results of the teacher network to the student network to help its\ntraining. Fourth, we introduce $L_{1}$ regularization to make the numerical\nvalues of the latent representation more sparse. Then we only encode non-zero\nchannels in the encoding and decoding process, which can greatly reduce the\nencoding and decoding time. Experiments show that compared to the\nstate-of-the-art learned image coding scheme, our method can be about 20 times\nfaster in encoding and 70-90 times faster in decoding, and our R-D performance\nis also $2.3 \\%$ higher. Our method outperforms the traditional approach in\nH.266/VVC-intra (4:4:4) and some leading learned schemes in terms of PSNR and\nMS-SSIM metrics when testing on Kodak and Tecnick-40 datasets.",
            "author": [
                "Haisheng Fu",
                "Feng Liang",
                "Jie Liang",
                "Yongqiang Wang",
                "Guohe Zhang",
                "Jingning Han"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02529v1",
                "http://arxiv.org/pdf/2309.02529v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02525v1",
            "title": "Learning Observation Models with Incremental Non-Differentiable Graph\n  Optimizers in the Loop for Robotics State Estimation",
            "updated": "2023-09-05T18:38:02Z",
            "published": "2023-09-05T18:38:02Z",
            "summary": "We consider the problem of learning observation models for robot state\nestimation with incremental non-differentiable optimizers in the loop.\nConvergence to the correct belief over the robot state is heavily dependent on\na proper tuning of observation models which serve as input to the optimizer. We\npropose a gradient-based learning method which converges much quicker to model\nestimates that lead to solutions of much better quality compared to an existing\nstate-of-the-art method as measured by the tracking accuracy over unseen robot\ntest trajectories.",
            "author": [
                "Mohamad Qadri",
                "Michael Kaess"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02525v1",
                "http://arxiv.org/pdf/2309.02525v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02509v2",
            "title": "Nucleon axial-vector radius and form factor from future neutrino\n  experiments",
            "updated": "2023-09-11T23:24:56Z",
            "published": "2023-09-05T18:00:57Z",
            "summary": "Precision measurements of antineutrino elastic scattering on hydrogen from\nfuture neutrino experiments offer a unique opportunity to access the low-energy\nstructure of protons and neutrons. We discuss the determination of the nucleon\naxial-vector form factor and radius from antineutrino interactions on hydrogen\nwhich can be collected at the future Long-Baseline Neutrino Facility (LBNF),\nand study the sources of theoretical and experimental uncertainties. The\nprojected accuracy would improve existing measurements by one order of\nmagnitude and be competitive with contemporary lattice-QCD determinations,\npotentially helping to resolve the corresponding tension with measurements from\n(anti)neutrino elastic scattering on deuterium. We find that the current\nknowledge of the nucleon vector form factors could be one of the dominant\nsources of uncertainty. We also evaluate the constraints which can be\nsimultaneously obtained on the absolute $\\bar \\nu_\\mu$ flux normalization.",
            "author": [
                "Roberto Petti",
                "Richard J. Hill",
                "Oleksandr Tomalak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02509v2",
                "http://arxiv.org/pdf/2309.02509v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "nucl-ex",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02435v1",
            "title": "Efficient RL via Disentangled Environment and Agent Representations",
            "updated": "2023-09-05T17:59:45Z",
            "published": "2023-09-05T17:59:45Z",
            "summary": "Agents that are aware of the separation between themselves and their\nenvironments can leverage this understanding to form effective representations\nof visual input. We propose an approach for learning such structured\nrepresentations for RL algorithms, using visual knowledge of the agent, such as\nits shape or mask, which is often inexpensive to obtain. This is incorporated\ninto the RL objective using a simple auxiliary loss. We show that our method,\nStructured Environment-Agent Representations, outperforms state-of-the-art\nmodel-free approaches over 18 different challenging visual simulation\nenvironments spanning 5 different robots. Website at https://sear-rl.github.io/",
            "author": [
                "Kevin Gmelin",
                "Shikhar Bahl",
                "Russell Mendonca",
                "Deepak Pathak"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02435v1",
                "http://arxiv.org/pdf/2309.02435v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.NE",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02414v1",
            "title": "Cohen-Macaulay weighted chordal graphs",
            "updated": "2023-09-05T17:46:18Z",
            "published": "2023-09-05T17:46:18Z",
            "summary": "In this paper I give a combinatorial characterization of all the\nCohen-Macaulay weighted chordal graphs. In particular, it is shown that a\nweighted chordal graph is Cohen- Macaulay if and only if it is unmixed.",
            "author": [
                "Shuai Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02414v1",
                "http://arxiv.org/pdf/2309.02414v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02396v1",
            "title": "Black-Box Attacks against Signed Graph Analysis via Balance Poisoning",
            "updated": "2023-09-05T17:09:38Z",
            "published": "2023-09-05T17:09:38Z",
            "summary": "Signed graphs are well-suited for modeling social networks as they capture\nboth positive and negative relationships. Signed graph neural networks (SGNNs)\nare commonly employed to predict link signs (i.e., positive and negative) in\nsuch graphs due to their ability to handle the unique structure of signed\ngraphs. However, real-world signed graphs are vulnerable to malicious attacks\nby manipulating edge relationships, and existing adversarial graph attack\nmethods do not consider the specific structure of signed graphs. SGNNs often\nincorporate balance theory to effectively model the positive and negative\nlinks. Surprisingly, we find that the balance theory that they rely on can\nironically be exploited as a black-box attack. In this paper, we propose a\nnovel black-box attack called balance-attack that aims to decrease the balance\ndegree of the signed graphs. We present an efficient heuristic algorithm to\nsolve this NP-hard optimization problem. We conduct extensive experiments on\nfive popular SGNN models and four real-world datasets to demonstrate the\neffectiveness and wide applicability of our proposed attack method. By\naddressing these challenges, our research contributes to a better understanding\nof the limitations and resilience of robust models when facing attacks on\nSGNNs. This work contributes to enhancing the security and reliability of\nsigned graph analysis in social network modeling. Our PyTorch implementation of\nthe attack is publicly available on GitHub:\nhttps://github.com/JialongZhou666/Balance-Attack.git.",
            "author": [
                "Jialong Zhou",
                "Yuni Lai",
                "Jian Ren",
                "Kai Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02396v1",
                "http://arxiv.org/pdf/2309.02396v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02369v2",
            "title": "Adaptive Bayesian Predictive Inference",
            "updated": "2023-09-13T21:02:03Z",
            "published": "2023-09-05T16:31:35Z",
            "summary": "Bayesian predictive inference provides a coherent description of entire\npredictive uncertainty through predictive distributions. We examine several\nwidely used sparsity priors from the predictive (as opposed to estimation)\ninference viewpoint. Our context is estimating a predictive distribution of a\nhigh-dimensional Gaussian observation with a known variance but an unknown\nsparse mean under the Kullback-Leibler loss. First, we show that LASSO\n(Laplace) priors are incapable of achieving rate-optimal performance. This new\nresult contributes to the literature on negative findings about Bayesian LASSO\nposteriors. However, deploying the Laplace prior inside the Spike-and-Slab\nframework (for example with the Spike-and-Slab LASSO prior), rate-minimax\nperformance can be attained with properly tuned parameters (depending on the\nsparsity level sn). We highlight the discrepancy between prior calibration for\nthe purpose of prediction and estimation. Going further, we investigate popular\nhierarchical priors which are known to attain adaptive rate-minimax performance\nfor estimation. Whether or not they are rate-minimax also for predictive\ninference has, until now, been unclear. We answer affirmatively by showing that\nhierarchical Spike-and-Slab priors are adaptive and attain the minimax rate\nwithout the knowledge of sn. This is the first rate-adaptive result in the\nliterature on predictive density estimation in sparse setups. This finding\ncelebrates benefits of fully Bayesian inference.",
            "author": [
                "Veronika Rockova"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02369v2",
                "http://arxiv.org/pdf/2309.02369v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02365v1",
            "title": "Investigation of RF performance of Ku-band GaN HEMT device and an\n  in-depth analysis of short channel effects",
            "updated": "2023-09-05T16:26:05Z",
            "published": "2023-09-05T16:26:05Z",
            "summary": "In this paper, we have characterized an AlGaN/GaN High Electron Mobility\nTransistor (HEMT) with a short gate length (Lg $\\approx$ 0.15$\\mu$m). We have\nstudied the effect of short gate length on the small signal parameters,\nlinearity parameters and gm-gd ratio in GaN HEMT devices. To understand how\nscaling results in the variation of the above-mentioned parameters a\ncomparative study with higher gate length devices on similar heterostructure is\nalso presented here. We have scaled down the gate length but the barrier\nthickness(t$_{bar}$) remained same which affects the aspect ratio\n(L$_{g}$/t$_{bar}$) of the device and its inseparable consequences are the\nprominent short channel effects (SCEs) barring the optimum output performance\nof the device. These interesting phenomena were studied in detail and explored\nover a temperature range of -40$^\\circ$C to 80$^\\circ$C. To the best of our\nknowledge this paper explores temperature dependence of SCEs of GaN HEMT for\nthe first time. With an approach to reduce the impact of SCEs a simulation\nstudy in Silvaco TCAD was carried out and it is observed that a recessed gate\nstructure on conventional heterostructure successfully reduces SCEs and\nimproves RF performance of the device. This work gives an overall view of gate\nlength scaling on conventional AlGaN/GaN HEMTs.",
            "author": [
                "Jagori Raychaudhuri",
                "Jayjit Mukherjee",
                "Sudhir Kumar",
                "D. S. Rawal",
                "Meena Mishra",
                "Santanu Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02365v1",
                "http://arxiv.org/pdf/2309.02365v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02350v1",
            "title": "Conformal Dimension of the Brownian Graph",
            "updated": "2023-09-05T16:06:48Z",
            "published": "2023-09-05T16:06:48Z",
            "summary": "Conformal dimension of a metric space $X$, denoted by $\\dim_C X$, is the\ninfimum of the Hausdorff dimension among all its quasisymmetric images. If\nconformal dimension of $X$ is equal to its Hausdorff dimension, $X$ is said to\nbe minimal for conformal dimension. In this paper we show that the graph of the\none dimensional Brownian motion is almost surely minimal for conformal\ndimension. We also give many other examples of minimal sets for conformal\ndimension, which we call Bedford-McMullen type sets. In particular we show that\nBedford-McMullen self-affine sets with uniform fibers are minimal for conformal\ndimension. The main technique in the proofs is the construction of ``rich\nfamilies of minimal sets of conformal dimension one''. The latter concept is\nquantified using Fuglede's modulus of measures.",
            "author": [
                "Ilia Binder",
                "Hrant Hakobyan",
                "Wen-Bo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02350v1",
                "http://arxiv.org/pdf/2309.02350v1"
            ],
            "primary_category": "math.MG",
            "category": [
                "math.MG",
                "math.PR",
                "60D05, 30L99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02331v1",
            "title": "Ultrafast optical polarimetry in magnetic phases of Kondo semi metal\n  CeSb",
            "updated": "2023-09-05T15:51:36Z",
            "published": "2023-09-05T15:51:36Z",
            "summary": "We investigated photo induced ultrafast transient dynamics in different\nmagnetic phases in CeSb by means of the time resolved magneto-optical\nspectroscopy. We observe a distinctive coherent oscillations in the\nground-state antiferromagnetic (AFM) phase and the high-magnetic field\nferromagnetic (F) phase. While the AFM-phase oscillations frequencies match the\nrecent Raman scattering findings the F-phase oscillation frequency does not\ncorrespond to the previously observed magnetic excitation. The large\nspectroscopic factor, g=3.94, and optical polarization properties suggest that\nit corresponds to a previously undetected Ce^{3+} crystal field excitation. To\nour best knowledge this is the first observation of a coherently excited\nexcitonic magnetic transition. The AFM-phase oscillations show no magnetic\nfield dependence so their lattice origin cannot be excluded. The\nnon-oscillatory part of the transients is qualitatively similar in all\ninvestigated magnetic phases with a faster sub-picosecond dynamics in the\nferromagnetic and ferro-para-magnetic phases and is attributed to differences\nin the electronic structure, which affect the photo-excited quasiparticle\nenergy relaxation.",
            "author": [
                "M. Naseska",
                "E. Goreshnik",
                "N. Zhigadlo",
                "T. Mertelj"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02331v1",
                "http://arxiv.org/pdf/2309.02331v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02314v1",
            "title": "The role of three-nucleon potentials within the shell model: past and\n  present",
            "updated": "2023-09-05T15:29:25Z",
            "published": "2023-09-05T15:29:25Z",
            "summary": "We survey the impact of nuclear three-body forces on structure properties of\nnuclei within the shell model.\n  It has long been acknowledged, since the seminal works of Zuker and\ncoworkers, that three-body forces play a fundamental role in making the\nmonopole component of shell-model Hamiltonians, derived from realistic\nnucleon-nucleon potentials, able to reproduce the observed evolution of the\nshell structure. In the vast majority of calculations, however, their effects\nhave been taken into account by shell-model practitioners by introducing ad hoc\nmodifications of the monopole matrix elements. During last twenty years, a new\ntheoretical approach, framed within the chiral perturbation theory, has\nprogressed in developing nuclear potentials, where two- and many-body\ncomponents are naturally and consistently built in. This new class of nuclear\nforces allows to carry out nuclear structure studies that are improving our\nability to understand nuclear phenomena in a microscopic approach. We provide\nin this work an update on the status of the nuclear shell model based on\nrealistic Hamiltonians that are derived from two- and three-nucleon chiral\npotentials, focusing on the role of the three-body component to provide the\nobserved shell evolution and closure properties, as well as the location of\ndriplines. To this end, we present the results of shell-model calculations and\ntheir comparison with recent experimental measurements, which enlighten the\nrelevance of the inclusion of three-nucleon forces to master our knowledge of\nthe physics of atomic nuclei.",
            "author": [
                "L. Coraggio",
                "G. De Gregorio",
                "T. Fukui",
                "A. Gargano",
                "Y. Z. Ma",
                "Z. H. Cheng",
                "F. R. Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02314v1",
                "http://arxiv.org/pdf/2309.02314v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.06846v1",
            "title": "Exploiting Language Models as a Source of Knowledge for Cognitive Agents",
            "updated": "2023-09-05T15:18:04Z",
            "published": "2023-09-05T15:18:04Z",
            "summary": "Large language models (LLMs) provide capabilities far beyond sentence\ncompletion, including question answering, summarization, and natural-language\ninference. While many of these capabilities have potential application to\ncognitive systems, our research is exploiting language models as a source of\ntask knowledge for cognitive agents, that is, agents realized via a cognitive\narchitecture. We identify challenges and opportunities for using language\nmodels as an external knowledge source for cognitive systems and possible ways\nto improve the effectiveness of knowledge extraction by integrating extraction\nwith cognitive architecture capabilities, highlighting with examples from our\nrecent work in this area.",
            "author": [
                "James R. Kirk",
                "Robert E. Wray",
                "John E. Laird"
            ],
            "link": [
                "http://arxiv.org/abs/2310.06846v1",
                "http://arxiv.org/pdf/2310.06846v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "I.2.7; I.2.11"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02304v1",
            "title": "Graph Self-Contrast Representation Learning",
            "updated": "2023-09-05T15:13:48Z",
            "published": "2023-09-05T15:13:48Z",
            "summary": "Graph contrastive learning (GCL) has recently emerged as a promising approach\nfor graph representation learning. Some existing methods adopt the 1-vs-K\nscheme to construct one positive and K negative samples for each graph, but it\nis difficult to set K. For those methods that do not use negative samples, it\nis often necessary to add additional strategies to avoid model collapse, which\ncould only alleviate the problem to some extent. All these drawbacks will\nundoubtedly have an adverse impact on the generalizability and efficiency of\nthe model. In this paper, to address these issues, we propose a novel graph\nself-contrast framework GraphSC, which only uses one positive and one negative\nsample, and chooses triplet loss as the objective. Specifically, self-contrast\nhas two implications. First, GraphSC generates both positive and negative views\nof a graph sample from the graph itself via graph augmentation functions of\nvarious intensities, and use them for self-contrast. Second, GraphSC uses\nHilbert-Schmidt Independence Criterion (HSIC) to factorize the representations\ninto multiple factors and proposes a masked self-contrast mechanism to better\nseparate positive and negative samples. Further, Since the triplet loss only\noptimizes the relative distance between the anchor and its positive/negative\nsamples, it is difficult to ensure the absolute distance between the anchor and\npositive sample. Therefore, we explicitly reduced the absolute distance between\nthe anchor and positive sample to accelerate convergence. Finally, we conduct\nextensive experiments to evaluate the performance of GraphSC against 19 other\nstate-of-the-art methods in both unsupervised and transfer learning settings.",
            "author": [
                "Minjie Chen",
                "Yao Cheng",
                "Ye Wang",
                "Xiang Li",
                "Ming Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02304v1",
                "http://arxiv.org/pdf/2309.02304v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02286v1",
            "title": "Haystack: A Panoptic Scene Graph Dataset to Evaluate Rare Predicate\n  Classes",
            "updated": "2023-09-05T14:45:54Z",
            "published": "2023-09-05T14:45:54Z",
            "summary": "Current scene graph datasets suffer from strong long-tail distributions of\ntheir predicate classes. Due to a very low number of some predicate classes in\nthe test sets, no reliable metrics can be retrieved for the rarest classes. We\nconstruct a new panoptic scene graph dataset and a set of metrics that are\ndesigned as a benchmark for the predictive performance especially on rare\npredicate classes. To construct the new dataset, we propose a model-assisted\nannotation pipeline that efficiently finds rare predicate classes that are\nhidden in a large set of images like needles in a haystack.\n  Contrary to prior scene graph datasets, Haystack contains explicit negative\nannotations, i.e. annotations that a given relation does not have a certain\npredicate class. Negative annotations are helpful especially in the field of\nscene graph generation and open up a whole new set of possibilities to improve\ncurrent scene graph generation models.\n  Haystack is 100% compatible with existing panoptic scene graph datasets and\ncan easily be integrated with existing evaluation pipelines. Our dataset and\ncode can be found here: https://lorjul.github.io/haystack/. It includes\nannotation files and simple to use scripts and utilities, to help with\nintegrating our dataset in existing work.",
            "author": [
                "Julian Lorenz",
                "Florian Barthel",
                "Daniel Kienzle",
                "Rainer Lienhart"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02286v1",
                "http://arxiv.org/pdf/2309.02286v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02281v1",
            "title": "s-ID: Causal Effect Identification in a Sub-Population",
            "updated": "2023-09-05T14:43:10Z",
            "published": "2023-09-05T14:43:10Z",
            "summary": "Causal inference in a sub-population involves identifying the causal effect\nof an intervention on a specific subgroup within a larger population. However,\nignoring the subtleties introduced by sub-populations can either lead to\nerroneous inference or limit the applicability of existing methods. We\nintroduce and advocate for a causal inference problem in sub-populations\n(henceforth called s-ID), in which we merely have access to observational data\nof the targeted sub-population (as opposed to the entire population). Existing\ninference problems in sub-populations operate on the premise that the given\ndata distributions originate from the entire population, thus, cannot tackle\nthe s-ID problem. To address this gap, we provide necessary and sufficient\nconditions that must hold in the causal graph for a causal effect in a\nsub-population to be identifiable from the observational distribution of that\nsub-population. Given these conditions, we present a sound and complete\nalgorithm for the s-ID problem.",
            "author": [
                "Amir Mohammad Abouei",
                "Ehsan Mokhtarian",
                "Negar Kiyavash"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02281v1",
                "http://arxiv.org/pdf/2309.02281v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02273v1",
            "title": "Computing Hive Plots: A Combinatorial Framework",
            "updated": "2023-09-05T14:37:59Z",
            "published": "2023-09-05T14:37:59Z",
            "summary": "Hive plots are a graph visualization style placing vertices on a set of\nradial axes emanating from a common center and drawing edges as smooth curves\nconnecting their respective endpoints. In previous work on hive plots,\nassignment to an axis and vertex positions on each axis were determined based\non selected vertex attributes and the order of axes was prespecified. Here, we\npresent a new framework focusing on combinatorial aspects of these drawings to\nextend the original hive plot idea and optimize visual properties such as the\ntotal edge length and the number of edge crossings in the resulting hive plots.\nOur framework comprises three steps: (1) partition the vertices into multiple\ngroups, each corresponding to an axis of the hive plot; (2) optimize the cyclic\naxis order to bring more strongly connected groups near each other; (3)\noptimize the vertex ordering on each axis to minimize edge crossings. Each of\nthe three steps is related to a well-studied, but NP-complete computational\nproblem. We combine and adapt suitable algorithmic approaches, implement them\nas an instantiation of our framework and show in a case study how it can be\napplied in a practical setting. Furthermore, we conduct computational\nexperiments to gain further insights regarding algorithmic choices of the\nframework. The code of the implementation and a prototype web application can\nbe found on OSF.",
            "author": [
                "Martin N\u00f6llenburg",
                "Markus Wallinger"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02273v1",
                "http://arxiv.org/pdf/2309.02273v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02272v1",
            "title": "Graph-Based Automatic Feature Selection for Multi-Class Classification\n  via Mean Simplified Silhouette",
            "updated": "2023-09-05T14:37:31Z",
            "published": "2023-09-05T14:37:31Z",
            "summary": "This paper introduces a novel graph-based filter method for automatic feature\nselection (abbreviated as GB-AFS) for multi-class classification tasks. The\nmethod determines the minimum combination of features required to sustain\nprediction performance while maintaining complementary discriminating abilities\nbetween different classes. It does not require any user-defined parameters such\nas the number of features to select. The methodology employs the\nJeffries-Matusita (JM) distance in conjunction with t-distributed Stochastic\nNeighbor Embedding (t-SNE) to generate a low-dimensional space reflecting how\neffectively each feature can differentiate between each pair of classes. The\nminimum number of features is selected using our newly developed Mean\nSimplified Silhouette (abbreviated as MSS) index, designed to evaluate the\nclustering results for the feature selection task. Experimental results on\npublic data sets demonstrate the superior performance of the proposed GB-AFS\nover other filter-based techniques and automatic feature selection approaches.\nMoreover, the proposed algorithm maintained the accuracy achieved when\nutilizing all features, while using only $7\\%$ to $30\\%$ of the features.\nConsequently, this resulted in a reduction of the time needed for\nclassifications, from $15\\%$ to $70\\%$.",
            "author": [
                "David Levin",
                "Gonen Singer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02272v1",
                "http://arxiv.org/pdf/2309.02272v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02270v1",
            "title": "SAM-Deblur: Let Segment Anything Boost Image Deblurring",
            "updated": "2023-09-05T14:33:56Z",
            "published": "2023-09-05T14:33:56Z",
            "summary": "Image deblurring is a critical task in the field of image restoration, aiming\nto eliminate blurring artifacts. However, the challenge of addressing\nnon-uniform blurring leads to an ill-posed problem, which limits the\ngeneralization performance of existing deblurring models. To solve the problem,\nwe propose a framework SAM-Deblur, integrating prior knowledge from the Segment\nAnything Model (SAM) into the deblurring task for the first time. In\nparticular, SAM-Deblur is divided into three stages. First, We preprocess the\nblurred images, obtain image masks via SAM, and propose a mask dropout method\nfor training to enhance model robustness. Then, to fully leverage the\nstructural priors generated by SAM, we propose a Mask Average Pooling (MAP)\nunit specifically designed to average SAM-generated segmented areas, serving as\na plug-and-play component which can be seamlessly integrated into existing\ndeblurring networks. Finally, we feed the fused features generated by the MAP\nUnit into the deblurring model to obtain a sharp image. Experimental results on\nthe RealBlurJ, ReloBlur, and REDS datasets reveal that incorporating our\nmethods improves NAFNet's PSNR by 0.05, 0.96, and 7.03, respectively. Code will\nbe available at \\href{https://github.com/HPLQAQ/SAM-Deblur}{SAM-Deblur}.",
            "author": [
                "Siwei Li",
                "Mingxuan Liu",
                "Yating Zhang",
                "Shu Chen",
                "Haoxiang Li",
                "Hong Chen",
                "Zifei Dou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02270v1",
                "http://arxiv.org/pdf/2309.02270v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02258v1",
            "title": "On 3-Coloring Circle Graphs",
            "updated": "2023-09-05T14:11:29Z",
            "published": "2023-09-05T14:11:29Z",
            "summary": "Given a graph $G$ with a fixed vertex order $\\prec$, one obtains a circle\ngraph $H$ whose vertices are the edges of $G$ and where two such edges are\nadjacent if and only if their endpoints are pairwise distinct and alternate in\n$\\prec$. Therefore, the problem of determining whether $G$ has a $k$-page book\nembedding with spine order $\\prec$ is equivalent to deciding whether $H$ can be\ncolored with $k$ colors. Finding a $k$-coloring for a circle graph is known to\nbe NP-complete for $k \\geq 4$ and trivial for $k \\leq 2$. For $k = 3$, Unger\n(1992) claims an efficient algorithm that finds a 3-coloring in $O(n \\log n)$\ntime, if it exists. Given a circle graph $H$, Unger's algorithm (1) constructs\na 3-\\textsc{Sat} formula $\\Phi$ that is satisfiable if and only if $H$ admits a\n3-coloring and (2) solves $\\Phi$ by a backtracking strategy that relies on the\nstructure imposed by the circle graph. However, the extended abstract misses\nseveral details and Unger refers to his PhD thesis (in German) for details. In\nthis paper we argue that Unger's algorithm for 3-coloring circle graphs is not\ncorrect and that 3-coloring circle graphs should be considered as an open\nproblem. We show that step (1) of Unger's algorithm is incorrect by exhibiting\na circle graph whose formula $\\Phi$ is satisfiable but that is not 3-colorable.\nWe further show that Unger's backtracking strategy for solving $\\Phi$ in step\n(2) may produce incorrect results and give empirical evidence that it exhibits\na runtime behaviour that is not consistent with the claimed running time.",
            "author": [
                "Patricia Bachmann",
                "Ignaz Rutter",
                "Peter Stumpf"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02258v1",
                "http://arxiv.org/pdf/2309.02258v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02251v1",
            "title": "STGIN: Spatial-Temporal Graph Interaction Network for Large-scale POI\n  Recommendation",
            "updated": "2023-09-05T14:04:00Z",
            "published": "2023-09-05T14:04:00Z",
            "summary": "In Location-Based Services, Point-Of-Interest(POI) recommendation plays a\ncrucial role in both user experience and business opportunities. Graph neural\nnetworks have been proven effective in providing personalized POI\nrecommendation services. However, there are still two critical challenges.\nFirst, existing graph models attempt to capture users' diversified interests\nthrough a unified graph, which limits their ability to express interests in\nvarious spatial-temporal contexts. Second, the efficiency limitations of graph\nconstruction and graph sampling in large-scale systems make it difficult to\nadapt quickly to new real-time interests. To tackle the above challenges, we\npropose a novel Spatial-Temporal Graph Interaction Network. Specifically, we\nconstruct subgraphs of spatial, temporal, spatial-temporal, and global views\nrespectively to precisely characterize the user's interests in various\ncontexts. In addition, we design an industry-friendly framework to track the\nuser's latest interests. Extensive experiments on the real-world dataset show\nthat our method outperforms state-of-the-art models. This work has been\nsuccessfully deployed in a large e-commerce platform, delivering a 1.1% CTR and\n6.3% RPM improvement.",
            "author": [
                "Shaohua Liu",
                "Yu Qi",
                "Gen Li",
                "Mingjian Chen",
                "Teng Zhang",
                "Jia Cheng",
                "Jun Lei"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615200",
                "http://arxiv.org/abs/2309.02251v1",
                "http://arxiv.org/pdf/2309.02251v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02240v1",
            "title": "Dialog Action-Aware Transformer for Dialog Policy Learning",
            "updated": "2023-09-05T13:47:25Z",
            "published": "2023-09-05T13:47:25Z",
            "summary": "Recent works usually address Dialog policy learning DPL by training a\nreinforcement learning (RL) agent to determine the best dialog action. However,\nexisting works on deep RL require a large volume of agent-user interactions to\nachieve acceptable performance. In this paper, we propose to make full use of\nthe plain text knowledge from the pre-trained language model to accelerate the\nRL agent's learning speed. Specifically, we design a dialog action-aware\ntransformer encoder (DaTrans), which integrates a new fine-tuning procedure\nnamed masked last action task to encourage DaTrans to be dialog-aware and\ndistils action-specific features. Then, DaTrans is further optimized in an RL\nsetting with ongoing interactions and evolves through exploration in the dialog\naction space toward maximizing long-term accumulated rewards. The effectiveness\nand efficiency of the proposed model are demonstrated with both simulator\nevaluation and human evaluation.",
            "author": [
                "Huimin Wang",
                "Wai-Chung Kwan",
                "Kam-Fai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02240v1",
                "http://arxiv.org/pdf/2309.02240v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.06495v1",
            "title": "AGIBench: A Multi-granularity, Multimodal, Human-referenced,\n  Auto-scoring Benchmark for Large Language Models",
            "updated": "2023-09-05T13:43:37Z",
            "published": "2023-09-05T13:43:37Z",
            "summary": "Large language models (LLMs) like ChatGPT have revealed amazing intelligence.\nHow to evaluate the question-solving abilities of LLMs and their degrees of\nintelligence is a hot-spot but challenging issue. First, the question-solving\nabilities are interlaced with different ability branches like understanding and\nmassive knowledge categories like mathematics. Second, the inputs of questions\nare multimodal that may involve text and images. Third, the response format of\nLLMs is diverse and thus poses great challenges for result extraction and\nevaluation. In this paper, we propose AGIBench -- a multi-granularity,\nmultimodal, human-referenced, and auto-scoring benchmarking methodology for\nLLMs. Instead of a collection of blended questions, AGIBench focuses on three\ntypical ability branches and adopts a four-tuple <ability branch, knowledge,\ndifficulty, modal> to label the attributes of each question. First, it supports\nmulti-granularity benchmarking, e.g., per-question, per-ability branch,\nper-knowledge, per-modal, per-dataset, and per-difficulty level granularities.\nSecond, it contains multimodal input, including text and images. Third, it\nclassifies all the questions into five degrees of difficulty according to the\naverage accuracy rate of abundant educated humans (human-referenced). Fourth,\nit adopts zero-shot learning to avoid introducing additional unpredictability\nand provides an auto-scoring method to extract and judge the result. Finally,\nit defines multi-dimensional metrics, including accuracy under the average,\nworst, best, and majority voting cases, and repeatability. AGIBench is\npublically available from \\url{https://www.benchcouncil.org/agibench}.",
            "author": [
                "Fei Tang",
                "Wanling Gao",
                "Luzhou Peng",
                "Jianfeng Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.06495v1",
                "http://arxiv.org/pdf/2309.06495v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02234v2",
            "title": "Potential Outcomes and Decision Theoretic Foundations for Statistical\n  Causality: Response to Richardson and Robins",
            "updated": "2023-10-01T17:04:20Z",
            "published": "2023-09-05T13:40:34Z",
            "summary": "I thank Thomas Richardson and James Robins for their discussion of my paper,\nand discuss the similarities and differences between their approach to causal\nmodelling, based on single world intervention graphs, and my own\ndecision-theoretic approach.",
            "author": [
                "A. Philip Dawid"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02234v2",
                "http://arxiv.org/pdf/2309.02234v2"
            ],
            "primary_category": "stat.OT",
            "category": [
                "stat.OT",
                "62D20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02233v1",
            "title": "Augmenting Black-box LLMs with Medical Textbooks for Clinical Question\n  Answering",
            "updated": "2023-09-05T13:39:38Z",
            "published": "2023-09-05T13:39:38Z",
            "summary": "Large-scale language models (LLMs), such as ChatGPT, are capable of\ngenerating human-like responses for various downstream tasks, such as\ntask-oriented dialogues and question answering. However, applying LLMs to\nmedical domains remains challenging due to their inability to leverage\ndomain-specific knowledge. In this study, we present the Large-scale Language\nModels Augmented with Medical Textbooks (LLM-AMT), which integrates\nauthoritative medical textbooks as the cornerstone of its design, enhancing its\nproficiency in the specialized domain through plug-and-play modules, comprised\nof a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM\nReader. Experimental evaluation on three open-domain medical question-answering\ntasks reveals a substantial enhancement in both the professionalism and\naccuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement\nranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that\nmedical textbooks as the retrieval corpus serves as a more valuable external\nknowledge source than Wikipedia in the medical domain. Our experiments show\nthat textbook augmentation results in a performance improvement ranging from\n9.7% to 12.2% over Wikipedia augmentation.",
            "author": [
                "Yubo Wang",
                "Xueguang Ma",
                "Wenhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02233v1",
                "http://arxiv.org/pdf/2309.02233v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02229v1",
            "title": "How Metal/Insulator Interfaces Enable the Enhancement of the Hydrogen\n  Evolution Reaction Kinetics in Two Ways",
            "updated": "2023-09-05T13:34:35Z",
            "published": "2023-09-05T13:34:35Z",
            "summary": "Laterally nanostructured surfaces give rise to a new dimension of\nunderstanding and improving electrochemical reactions. In this study, we\npresent a peculiar mechanism appearing at a metal/insulator interface, which\ncan significantly enhance the Hydrogen Evolution Reaction (HER) from water\nreduction by altering the local reaction conditions in two ways: facilitated\nadsorption of hydrogen on the metal catalyst surface and improved transfer of\nions through the double layer. The mechanism is uncovered using electrodes\nconsisting of well-defined nanometer-sized metal arrays (Au, Cu, Pt) embedded\nin an insulator layer (silicon nitride), varying various parameters of both the\nelectrode (size of the metal patches, catalyst material) and the electrolyte\n(cationic species, cation concentration, pH). In addition, simulations of the\nelectrochemical double layer are carried out, which support the elaborated\nmechanism. Knowledge of this mechanism will enable new design principles for\nnovel composite electrocatalytic systems.",
            "author": [
                "Thomas L. Maier",
                "Lucas B. T. de Kam",
                "Matthias Golibrzuch",
                "Tina Angerer",
                "Markus Becherer",
                "Katharina Krischer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02229v1",
                "http://arxiv.org/pdf/2309.02229v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02225v1",
            "title": "A combinatorial view on star moments of regular directed graphs and\n  trees",
            "updated": "2023-09-05T13:27:46Z",
            "published": "2023-09-05T13:27:46Z",
            "summary": "We investigate the method of moments for $d$-regular digraphs and the\nlimiting $d$-regular directed tree $T_d$ as the number of vertices tends to\ninfinity, in the same spirit as McKay (Linear Algebra Appl., 1981) for the\nundirected setting. In particular, we provide a combinatorial derivation of the\nformula for the star moments (from a root vertex $o\\in T_d$)\n$$M_d(w)\\qquad:=\\sum_{\\substack{v_0,v_1\\ldots,v_{k-1},v_k\\in T_d\\\\v_0=v_k=o}}\nA^{w_1}(v_0,v_1)A^{w_2}(v_1,v_2) \\cdots A^{w_k}(v_{k-1},v_k)$$ with $A$ the\nadjacency matrix of $T_d$, where $w:=w_1\\cdots w_k$ is any word on the alphabet\n$\\{1,{*}\\}$ and $A^*$ is the adjoint matrix of $A$. Our analysis highlights a\nconnection between the non-zero summands of $M_d(w)$ and the non-crossing\npartitions of $\\{1,\\ldots,k\\}$ which are in some sense compatible with $w$.",
            "author": [
                "Benjamin Dadoun",
                "Patrick Oliveira Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02225v1",
                "http://arxiv.org/pdf/2309.02225v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "05C20, 05C30, 05C80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02223v1",
            "title": "The Worst-Case Complexity of Symmetric Strategy Improvement",
            "updated": "2023-09-05T13:27:00Z",
            "published": "2023-09-05T13:27:00Z",
            "summary": "Symmetric strategy improvement is an algorithm introduced by Schewe et al.\n(ICALP 2015) that can be used to solve two-player games on directed graphs such\nas parity games and mean payoff games. In contrast to the usual well-known\nstrategy improvement algorithm, it iterates over strategies of both players\nsimultaneously. The symmetric version solves the known worst-case examples for\nstrategy improvement quickly, however its worst-case complexity remained open.\n  We present a class of worst-case examples for symmetric strategy improvement\non which this symmetric version also takes exponentially many steps.\nRemarkably, our examples exhibit this behaviour for any choice of improvement\nrule, which is in contrast to classical strategy improvement where hard\ninstances are usually hand-crafted for a specific improvement rule. We present\na generalized version of symmetric strategy iteration depending less rigidly on\nthe interplay of the strategies of both players. However, it turns out it has\nthe same shortcomings.",
            "author": [
                "Tom van Dijk",
                "Georg Loho",
                "Matthew Maat"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02223v1",
                "http://arxiv.org/pdf/2309.02223v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02212v1",
            "title": "Detecting quantum speedup of random walks with machine learning",
            "updated": "2023-09-05T13:19:47Z",
            "published": "2023-09-05T13:19:47Z",
            "summary": "We explore the use of machine-learning techniques to detect quantum speedup\nin random walks on graphs. Specifically, we investigate the performance of\nthree different neural-network architectures (variations on fully connected and\nconvolutional neural networks) for identifying linear, cyclic, and random\ngraphs that yield quantum speedups in terms of the hitting time for reaching a\ntarget node after starting in another node of the graph. Our results indicate\nthat carefully building the data set for training can improve the performance\nof the neural networks, but all architectures we test struggle to classify\nlarge random graphs and generalize from training on one graph size to testing\non another. If classification accuracy can be improved further, valuable\ninsights about quantum advantage may be gleaned from these neural networks, not\nonly for random walks, but more generally for quantum computing and quantum\ntransport.",
            "author": [
                "Hanna Linn",
                "Yu Zheng",
                "Anton Frisk Kockum"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02212v1",
                "http://arxiv.org/pdf/2309.02212v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02210v1",
            "title": "Continual Cross-Dataset Adaptation in Road Surface Classification",
            "updated": "2023-09-05T13:18:52Z",
            "published": "2023-09-05T13:18:52Z",
            "summary": "Accurate road surface classification is crucial for autonomous vehicles (AVs)\nto optimize driving conditions, enhance safety, and enable advanced road\nmapping. However, deep learning models for road surface classification suffer\nfrom poor generalization when tested on unseen datasets. To update these models\nwith new information, also the original training dataset must be taken into\naccount, in order to avoid catastrophic forgetting. This is, however,\ninefficient if not impossible, e.g., when the data is collected in streams or\nlarge amounts. To overcome this limitation and enable fast and efficient\ncross-dataset adaptation, we propose to employ continual learning finetuning\nmethods designed to retain past knowledge while adapting to new data, thus\neffectively avoiding forgetting. Experimental results demonstrate the\nsuperiority of this approach over naive finetuning, achieving performance close\nto fresh retraining. While solving this known problem, we also provide a\ngeneral description of how the same technique can be adopted in other AV\nscenarios. We highlight the potential computational and economic benefits that\na continual-based adaptation can bring to the AV industry, while also reducing\ngreenhouse emissions due to unnecessary joint retraining.",
            "author": [
                "Paolo Cudrano",
                "Matteo Bellusci",
                "Giuseppe Macino",
                "Matteo Matteucci"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02210v1",
                "http://arxiv.org/pdf/2309.02210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02475v1",
            "title": "Variations on Reinforced Random Walks",
            "updated": "2023-09-05T13:16:41Z",
            "published": "2023-09-05T13:16:41Z",
            "summary": "This thesis examines edge-reinforced random walks with some modifications to\nthe standard definition. An overview of known results relating to the standard\nmodel is given and the proof of recurrence for the standard linearly\nedge-reinforced random walk on bounded degree graphs with small initial edge\nweights is repeated. Then, the edge-reinforced random walk with multiple\nwalkers influencing each other is considered. The following new results are\nshown: on a segment of three nodes, the edge weights resemble a P\\'olya urn and\nthe fraction of the edge weights divided by the total weight forms a converging\nmartingale. On Z, the behavior is the same as for a single walker - either all\nwalkers have finite range or all walkers are recurrent. Finally,\nedge-reinforced random walks with a bias in a certain direction are analysed,\nin particular on Z. It is shown that the bias can introduce a phase transition\nbetween recurrence and transience, depending on the strength of the bias, thus\nfundamentally altering the behavior in comparison to the standard linearly\nreinforced random walk.",
            "author": [
                "Fabian Michel"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02475v1",
                "http://arxiv.org/pdf/2309.02475v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60K37, 60K35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02206v1",
            "title": "Language Models for Novelty Detection in System Call Traces",
            "updated": "2023-09-05T13:11:40Z",
            "published": "2023-09-05T13:11:40Z",
            "summary": "Due to the complexity of modern computer systems, novel and unexpected\nbehaviors frequently occur. Such deviations are either normal occurrences, such\nas software updates and new user activities, or abnormalities, such as\nmisconfigurations, latency issues, intrusions, and software bugs. Regardless,\nnovel behaviors are of great interest to developers, and there is a genuine\nneed for efficient and effective methods to detect them. Nowadays, researchers\nconsider system calls to be the most fine-grained and accurate source of\ninformation to investigate the behavior of computer systems. Accordingly, this\npaper introduces a novelty detection methodology that relies on a probability\ndistribution over sequences of system calls, which can be seen as a language\nmodel. Language models estimate the likelihood of sequences, and since\nnovelties deviate from previously observed behaviors by definition, they would\nbe unlikely under the model. Following the success of neural networks for\nlanguage models, three architectures are evaluated in this work: the widespread\nLSTM, the state-of-the-art Transformer, and the lower-complexity Longformer.\nHowever, large neural networks typically require an enormous amount of data to\nbe trained effectively, and to the best of our knowledge, no massive modern\ndatasets of kernel traces are publicly available. This paper addresses this\nlimitation by introducing a new open-source dataset of kernel traces comprising\nover 2 million web requests with seven distinct behaviors. The proposed\nmethodology requires minimal expert hand-crafting and achieves an F-score and\nAuROC greater than 95% on most novelties while being data- and task-agnostic.\nThe source code and trained models are publicly available on GitHub while the\ndatasets are available on Zenodo.",
            "author": [
                "Quentin Fournier",
                "Daniel Aloise",
                "Leandro R. Costa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02206v1",
                "http://arxiv.org/pdf/2309.02206v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.OS",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02200v1",
            "title": "Run for Cover: Dominating Set via Mobile Agents",
            "updated": "2023-09-05T13:06:05Z",
            "published": "2023-09-05T13:06:05Z",
            "summary": "Research involving computing with mobile agents is a fast-growing field,\ngiven the advancement of technology in automated systems, e.g., robots, drones,\nself-driving cars, etc. Therefore, it is pressing to focus on solving classical\nnetwork problems using mobile agents. In this paper, we study one such problem\n-- finding small dominating sets of a graph $G$ using mobile agents. Dominating\nset is interesting in the field of mobile agents as it opens up a way for\nsolving various robotic problems, e.g., guarding, covering, facility location,\ntransport routing, etc. In this paper, we first present two algorithms for\ncomputing a {\\em minimal dominating set}: (i) an $O(m)$ time algorithm if the\nrobots start from a single node (i.e., gathered initially), (ii) an\n$O(\\ell\\Delta\\log(\\lambda)+n\\ell+m)$ time algorithm, if the robots start from\nmultiple nodes (i.e., positioned arbitrarily), where $m$ is the number of edges\nand $\\Delta$ is the maximum degree of $G$, $\\ell$ is the number of clusters of\nthe robot initially and $\\lambda$ is the maximum ID-length of the robots. Then\nwe present a $\\ln (\\Delta)$ approximation algorithm for the {\\em minimum}\ndominating set which takes $O(n\\Delta\\log (\\lambda))$ rounds.",
            "author": [
                "Prabhat Kumar Chand",
                "Anisur Rahaman Molla",
                "Sumathi Sivasubramaniam"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02200v1",
                "http://arxiv.org/pdf/2309.02200v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02190v1",
            "title": "Exchanging-based Multimodal Fusion with Transformer",
            "updated": "2023-09-05T12:48:25Z",
            "published": "2023-09-05T12:48:25Z",
            "summary": "We study the problem of multimodal fusion in this paper. Recent\nexchanging-based methods have been proposed for vision-vision fusion, which aim\nto exchange embeddings learned from one modality to the other. However, most of\nthem project inputs of multimodalities into different low-dimensional spaces\nand cannot be applied to the sequential input data. To solve these issues, in\nthis paper, we propose a novel exchanging-based multimodal fusion model MuSE\nfor text-vision fusion based on Transformer. We first use two encoders to\nseparately map multimodal inputs into different low-dimensional spaces. Then we\nemploy two decoders to regularize the embeddings and pull them into the same\nspace. The two decoders capture the correlations between texts and images with\nthe image captioning task and the text-to-image generation task, respectively.\nFurther, based on the regularized embeddings, we present CrossTransformer,\nwhich uses two Transformer encoders with shared parameters as the backbone\nmodel to exchange knowledge between multimodalities. Specifically,\nCrossTransformer first learns the global contextual information of the inputs\nin the shallow layers. After that, it performs inter-modal exchange by\nselecting a proportion of tokens in one modality and replacing their embeddings\nwith the average of embeddings in the other modality. We conduct extensive\nexperiments to evaluate the performance of MuSE on the Multimodal Named Entity\nRecognition task and the Multimodal Sentiment Analysis task. Our results show\nthe superiority of MuSE against other competitors. Our code and data are\nprovided at https://github.com/RecklessRonan/MuSE.",
            "author": [
                "Renyu Zhu",
                "Chengcheng Han",
                "Yong Qian",
                "Qiushi Sun",
                "Xiang Li",
                "Ming Gao",
                "Xuezhi Cao",
                "Yunsen Xian"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02190v1",
                "http://arxiv.org/pdf/2309.02190v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02185v4",
            "title": "BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in\n  Bird's-Eye View",
            "updated": "2023-11-22T13:56:48Z",
            "published": "2023-09-05T12:42:26Z",
            "summary": "3D Single Object Tracking (SOT) is a fundamental task of computer vision,\nproving essential for applications like autonomous driving. It remains\nchallenging to localize the target from surroundings due to appearance\nvariations, distractors, and the high sparsity of point clouds. The spatial\ninformation indicating objects' spatial adjacency across consecutive frames is\ncrucial for effective object tracking. However, existing trackers typically\nemploy point-wise representation with irregular formats, leading to\ninsufficient use of this important spatial knowledge. As a result, these\ntrackers usually require elaborate designs and solving multiple subtasks. In\nthis paper, we propose BEVTrack, a simple yet effective baseline that performs\ntracking in Bird's-Eye View (BEV). This representation greatly retains spatial\ninformation owing to its ordered structure and inherently encodes the implicit\nmotion relations of the target as well as distractors. To achieve accurate\nregression for targets with diverse attributes (\\textit{e.g.}, sizes and motion\npatterns), BEVTrack constructs the likelihood function with the learned\nunderlying distributions adapted to different targets, rather than making a\nfixed Laplace or Gaussian assumption as in previous works. This provides\nvaluable priors for tracking and thus further boosts performance. While only\nusing a single regression loss with a plain convolutional architecture,\nBEVTrack achieves state-of-the-art performance on three large-scale datasets,\nKITTI, NuScenes, and Waymo Open Dataset while maintaining a high inference\nspeed of about 200 FPS. The code will be released at\nhttps://github.com/xmm-prio/BEVTrack.",
            "author": [
                "Yuxiang Yang",
                "Yingqi Deng",
                "Jing Zhang",
                "Jiahao Nie",
                "Zheng-Jun Zha"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02185v4",
                "http://arxiv.org/pdf/2309.02185v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02142v1",
            "title": "Who are the users of ChatGPT? Implications for the digital divide from\n  web tracking data",
            "updated": "2023-09-05T11:31:54Z",
            "published": "2023-09-05T11:31:54Z",
            "summary": "A major challenge of our time is reducing disparities in access to and\neffective use of digital technologies, with recent discussions highlighting the\nrole of AI in exacerbating the digital divide. We examine user characteristics\nthat predict usage of the AI-powered conversational agent ChatGPT. We combine\nweb tracking and survey data of N=1068 German citizens to investigate\ndifferences in activity (usage, visits and duration on chat.openai.com). We\nexamine socio-demographics commonly associated with the digital divide and\nexplore further socio-political attributes identified via stability selection\nin Lasso regressions. We confirm lower age and more education to affect ChatGPT\nusage, but not gender and income. We find full-time employment and more\nchildren to be barriers to ChatGPT activity. Rural residence, writing and\nsocial media activities, as well as more political knowledge, were positively\nassociated with ChatGPT activity. Our research informs efforts to address\ndigital disparities and promote digital literacy among underserved populations.",
            "author": [
                "Celina Kacperski",
                "Roberto Ulloa",
                "Denis Bonnay",
                "Juhi Kulshrestha",
                "Peter Selb",
                "Andreas Spitz"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02142v1",
                "http://arxiv.org/pdf/2309.02142v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02138v1",
            "title": "Generalized Simplicial Attention Neural Networks",
            "updated": "2023-09-05T11:29:25Z",
            "published": "2023-09-05T11:29:25Z",
            "summary": "The aim of this work is to introduce Generalized Simplicial Attention Neural\nNetworks (GSANs), i.e., novel neural architectures designed to process data\ndefined on simplicial complexes using masked self-attentional layers. Hinging\non topological signal processing principles, we devise a series of\nself-attention schemes capable of processing data components defined at\ndifferent simplicial orders, such as nodes, edges, triangles, and beyond. These\nschemes learn how to weight the neighborhoods of the given topological domain\nin a task-oriented fashion, leveraging the interplay among simplices of\ndifferent orders through the Dirac operator and its Dirac decomposition. We\nalso theoretically establish that GSANs are permutation equivariant and\nsimplicial-aware. Finally, we illustrate how our approach compares favorably\nwith other methods when applied to several (inductive and transductive) tasks\nsuch as trajectory prediction, missing data imputation, graph classification,\nand simplex prediction.",
            "author": [
                "Claudio Battiloro",
                "Lucia Testa",
                "Lorenzo Giusti",
                "Stefania Sardellitti",
                "Paolo Di Lorenzo",
                "Sergio Barbarossa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02138v1",
                "http://arxiv.org/pdf/2309.02138v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02132v1",
            "title": "The $K^4$-Game",
            "updated": "2023-09-05T11:21:01Z",
            "published": "2023-09-05T11:21:01Z",
            "summary": "We investigate a two player game called the $K^4$-building game: two players\nalternately claim edges of an infinite complete graph. Each player's aim is to\nclaim all six edges on some vertex set of size four for themself. The first\nplayer to accomplish this goal is declared the winner of the game. We present a\nwinning strategy which guarantees a win for the first player.",
            "author": [
                "Nathan Bowler",
                "Florian Gut"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02132v1",
                "http://arxiv.org/pdf/2309.02132v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C57, 05C15, 05D10, 05C63, 05C85, 91A46"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02124v1",
            "title": "Exploiting Spatial-temporal Data for Sleep Stage Classification via\n  Hypergraph Learning",
            "updated": "2023-09-05T11:01:30Z",
            "published": "2023-09-05T11:01:30Z",
            "summary": "Sleep stage classification is crucial for detecting patients' health\nconditions. Existing models, which mainly use Convolutional Neural Networks\n(CNN) for modelling Euclidean data and Graph Convolution Networks (GNN) for\nmodelling non-Euclidean data, are unable to consider the heterogeneity and\ninteractivity of multimodal data as well as the spatial-temporal correlation\nsimultaneously, which hinders a further improvement of classification\nperformance. In this paper, we propose a dynamic learning framework STHL, which\nintroduces hypergraph to encode spatial-temporal data for sleep stage\nclassification. Hypergraphs can construct multi-modal/multi-type data instead\nof using simple pairwise between two subjects. STHL creates spatial and\ntemporal hyperedges separately to build node correlations, then it conducts\ntype-specific hypergraph learning process to encode the attributes into the\nembedding space. Extensive experiments show that our proposed STHL outperforms\nthe state-of-the-art models in sleep stage classification tasks.",
            "author": [
                "Yuze Liu",
                "Ziming Zhao",
                "Tiehua Zhang",
                "Kang Wang",
                "Xin Chen",
                "Xiaowei Huang",
                "Jun Yin",
                "Zhishu Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02124v1",
                "http://arxiv.org/pdf/2309.02124v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02114v1",
            "title": "Casimir and Casimir-Polder Interactions for Magneto-dielectric\n  Materials: Surface Scattering Expansion",
            "updated": "2023-09-05T10:46:23Z",
            "published": "2023-09-05T10:46:23Z",
            "summary": "We develop a general multiple scattering expansion (MSE) for computing\nCasimir forces between magneto-dielectric bodies and Casimir-Polder forces\nbetween polarizable particles and magneto-dielectric bodies. The approach is\nbased on fluctuating electric and magnetic surface currents and charges. The\nsurface integral equations for these surface fields can be formulated in terms\nof surface scattering operators (SSO). We show that there exists an entire\nfamily of such operators. One particular member of this family is only weakly\ndivergent and allows for a MSE that appears to be convergent for general\nmagneto-dielectric bodies. We proof a number of properties of this operator,\nand demonstrate explicitly convergence for sufficiently low and high\nfrequencies, and for perfect conductors. General expressions are derived for\nthe Casimir interaction between macroscopic bodies and for the Casimir-Polder\ninteraction between particles and macroscopic bodies in terms of the SSO, both\nat zero and finite temperatures. An advantage of our approach above previous\nscattering methods is that it does not require the knowledge of the scattering\namplitude (T-operator) of the bodies. A number of simple examples are provided\nto demonstrate the use of the method. Some applications of our approach have\nappeared previously [T. Emig, G. Bimonte, Phys. Rev. Lett. 130, 200401 (2023)].\nHere we provide additional technical aspects and details of our approach.",
            "author": [
                "Giuseppe Bimonte",
                "Thorsten Emig"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02114v1",
                "http://arxiv.org/pdf/2309.02114v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02105v1",
            "title": "Improving Query-Focused Meeting Summarization with Query-Relevant\n  Knowledge",
            "updated": "2023-09-05T10:26:02Z",
            "published": "2023-09-05T10:26:02Z",
            "summary": "Query-Focused Meeting Summarization (QFMS) aims to generate a summary of a\ngiven meeting transcript conditioned upon a query. The main challenges for QFMS\nare the long input text length and sparse query-relevant information in the\nmeeting transcript. In this paper, we propose a knowledge-enhanced two-stage\nframework called Knowledge-Aware Summarizer (KAS) to tackle the challenges. In\nthe first stage, we introduce knowledge-aware scores to improve the\nquery-relevant segment extraction. In the second stage, we incorporate\nquery-relevant knowledge in the summary generation. Experimental results on the\nQMSum dataset show that our approach achieves state-of-the-art performance.\nFurther analysis proves the competency of our methods in generating relevant\nand faithful summaries.",
            "author": [
                "Tiezheng Yu",
                "Ziwei Ji",
                "Pascale Fung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02105v1",
                "http://arxiv.org/pdf/2309.02105v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02086v1",
            "title": "Detecting Spatial Health Disparities Using Disease Maps",
            "updated": "2023-09-05T09:48:17Z",
            "published": "2023-09-05T09:48:17Z",
            "summary": "Epidemiologists commonly use regional aggregates of health outcomes to map\nmortality or incidence rates and identify geographic disparities. However, to\ndetect health disparities across regions, it is necessary to identify\n\"difference boundaries\" that separate neighboring regions with significantly\ndifferent spatial effects. This can be particularly challenging when dealing\nwith multiple outcomes for each unit and accounting for dependence among\ndiseases and across areal units. In this study, we address the issue of\nmultivariate difference boundary detection for correlated diseases by\nformulating the problem in terms of Bayesian pairwise multiple comparisons by\nextending it through the introduction of adjacency modeling and disease graph\ndependencies. Specifically, we seek the posterior probabilities of neighboring\nspatial effects being different. To accomplish this, we adopt a class of\nmultivariate areally referenced Dirichlet process models that accommodate\nspatial and interdisease dependence by endowing the spatial random effects with\na discrete probability law. Our method is evaluated through simulation studies\nand applied to detect difference boundaries for multiple cancers using data\nfrom the Surveillance, Epidemiology, and End Results Program of the National\nCancer Institute.",
            "author": [
                "Luca Aiello",
                "Sudipto Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02086v1",
                "http://arxiv.org/pdf/2309.02086v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02070v2",
            "title": "Why CAT(0) cube complexes should be replaced with median graphs",
            "updated": "2023-12-03T09:37:57Z",
            "published": "2023-09-05T09:16:11Z",
            "summary": "In this note, we discuss and motivate the use of the terminology ``median\ngraphs'' in place of ``CAT(0) cube complexes'' in geometric group theory.",
            "author": [
                "Anthony Genevois"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02070v2",
                "http://arxiv.org/pdf/2309.02070v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.MG",
                "20F65, 20F67"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02062v1",
            "title": "Boxicity and Interval-Orders: Petersen and the Complements of Line\n  Graphs",
            "updated": "2023-09-05T09:05:10Z",
            "published": "2023-09-05T09:05:10Z",
            "summary": "The boxicity of a graph is the smallest dimension $d$ allowing a\nrepresentation of it as the intersection graph of a set of $d$-dimensional\naxis-parallel boxes. We present a simple general approach to determining the\nboxicity of a graph based on studying its ``interval-order subgraphs''.\n  The power of the method is first tested on the boxicity of some popular\ngraphs that have resisted previous attempts: the boxicity of the Petersen graph\nis $3$, and more generally, that of the Kneser-graphs $K(n,2)$ is $n-2$ if\n$n\\ge 5$, confirming a conjecture of Caoduro and Lichev [Discrete Mathematics,\nVol. 346, 5, 2023].\n  Since every line graph is an induced subgraph of the complement of $K(n,2)$,\nthe developed tools show furthermore that line graphs have only a polynomial\nnumber of edge-maximal interval-order subgraphs. This opens the way to\npolynomial-time algorithms for problems that are in general\n$\\mathcal{NP}$-hard: for the existence and optimization of interval-order\nsubgraphs of line-graphs, or of interval-completions of their complement.",
            "author": [
                "Marco Caoduro",
                "Andr\u00e1s Seb\u0151"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02062v1",
                "http://arxiv.org/pdf/2309.02062v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C62, 05C76, 05C85",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02048v1",
            "title": "Probabilistic Self-supervised Learning via Scoring Rules Minimization",
            "updated": "2023-09-05T08:48:25Z",
            "published": "2023-09-05T08:48:25Z",
            "summary": "In this paper, we propose a novel probabilistic self-supervised learning via\nScoring Rule Minimization (ProSMIN), which leverages the power of probabilistic\nmodels to enhance representation quality and mitigate collapsing\nrepresentations. Our proposed approach involves two neural networks; the online\nnetwork and the target network, which collaborate and learn the diverse\ndistribution of representations from each other through knowledge distillation.\nBy presenting the input samples in two augmented formats, the online network is\ntrained to predict the target network representation of the same sample under a\ndifferent augmented view. The two networks are trained via our new loss\nfunction based on proper scoring rules. We provide a theoretical justification\nfor ProSMIN's convergence, demonstrating the strict propriety of its modified\nscoring rule. This insight validates the method's optimization process and\ncontributes to its robustness and effectiveness in improving representation\nquality. We evaluate our probabilistic model on various downstream tasks, such\nas in-distribution generalization, out-of-distribution detection, dataset\ncorruption, low-shot learning, and transfer learning. Our method achieves\nsuperior accuracy and calibration, surpassing the self-supervised baseline in a\nwide range of experiments on large-scale datasets like ImageNet-O and\nImageNet-C, ProSMIN demonstrates its scalability and real-world applicability.",
            "author": [
                "Amirhossein Vahidi",
                "Simon Scho\u00dfer",
                "Lisa Wimmer",
                "Yawei Li",
                "Bernd Bischl",
                "Eyke H\u00fcllermeier",
                "Mina Rezaei"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02048v1",
                "http://arxiv.org/pdf/2309.02048v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02040v2",
            "title": "Diffusion Generative Inverse Design",
            "updated": "2023-09-18T08:01:50Z",
            "published": "2023-09-05T08:32:07Z",
            "summary": "Inverse design refers to the problem of optimizing the input of an objective\nfunction in order to enact a target outcome. For many real-world engineering\nproblems, the objective function takes the form of a simulator that predicts\nhow the system state will evolve over time, and the design challenge is to\noptimize the initial conditions that lead to a target outcome. Recent\ndevelopments in learned simulation have shown that graph neural networks (GNNs)\ncan be used for accurate, efficient, differentiable estimation of simulator\ndynamics, and support high-quality design optimization with gradient- or\nsampling-based optimization procedures. However, optimizing designs from\nscratch requires many expensive model queries, and these procedures exhibit\nbasic failures on either non-convex or high-dimensional problems. In this work,\nwe show how denoising diffusion models (DDMs) can be used to solve inverse\ndesign problems efficiently and propose a particle sampling algorithm for\nfurther improving their efficiency. We perform experiments on a number of fluid\ndynamics design challenges, and find that our approach substantially reduces\nthe number of calls to the simulator compared to standard techniques.",
            "author": [
                "Marin Vlastelica",
                "Tatiana L\u00f3pez-Guevara",
                "Kelsey Allen",
                "Peter Battaglia",
                "Arnaud Doucet",
                "Kimberley Stachenfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02040v2",
                "http://arxiv.org/pdf/2309.02040v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02036v1",
            "title": "On the third ABC index of trees and unicyclic graphs",
            "updated": "2023-09-05T08:28:08Z",
            "published": "2023-09-05T08:28:08Z",
            "summary": "Let $G=(V,E)$ be a simple connected graph with vertex set $V(G)$ and edge set\n$E(G)$. The third atom-bond connectivity index, $ABC_3$ index, of $G$ is\ndefined as $ABC_3(G)=\\sum\\limits_{uv\\in\nE(G)}\\sqrt{\\frac{e(u)+e(v)-2}{e(u)e(v)}}$, where eccentricity $e(u)$ is the\nlargest distance between $u$ and any other vertex of $G$, namely\n$e(u)=\\max\\{d(u,v)|v\\in V(G)\\}$. This work determines the maximal $ABC_3$ index\nof unicyclic graphs with any given girth and trees with any given diameter, and\ncharacterizes the corresponding graphs.",
            "author": [
                "Rui Song"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02036v1",
                "http://arxiv.org/pdf/2309.02036v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02031v1",
            "title": "A survey on efficient vision transformers: algorithms, techniques, and\n  performance benchmarking",
            "updated": "2023-09-05T08:21:16Z",
            "published": "2023-09-05T08:21:16Z",
            "summary": "Vision Transformer (ViT) architectures are becoming increasingly popular and\nwidely employed to tackle computer vision applications. Their main feature is\nthe capacity to extract global information through the self-attention\nmechanism, outperforming earlier convolutional neural networks. However, ViT\ndeployment and performance have grown steadily with their size, number of\ntrainable parameters, and operations. Furthermore, self-attention's\ncomputational and memory cost quadratically increases with the image\nresolution. Generally speaking, it is challenging to employ these architectures\nin real-world applications due to many hardware and environmental restrictions,\nsuch as processing and computational capabilities. Therefore, this survey\ninvestigates the most efficient methodologies to ensure sub-optimal estimation\nperformances. More in detail, four efficient categories will be analyzed:\ncompact architecture, pruning, knowledge distillation, and quantization\nstrategies. Moreover, a new metric called Efficient Error Rate has been\nintroduced in order to normalize and compare models' features that affect\nhardware devices at inference time, such as the number of parameters, bits,\nFLOPs, and model size. Summarizing, this paper firstly mathematically defines\nthe strategies used to make Vision Transformer efficient, describes and\ndiscusses state-of-the-art methodologies, and analyzes their performances over\ndifferent application scenarios. Toward the end of this paper, we also discuss\nopen challenges and promising research directions.",
            "author": [
                "Lorenzo Papa",
                "Paolo Russo",
                "Irene Amerini",
                "Luping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02031v1",
                "http://arxiv.org/pdf/2309.02031v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02027v1",
            "title": "Granger Causal Inference in Multivariate Hawkes Processes by Minimum\n  Message Length",
            "updated": "2023-09-05T08:13:34Z",
            "published": "2023-09-05T08:13:34Z",
            "summary": "Multivariate Hawkes processes (MHPs) are versatile probabilistic tools used\nto model various real-life phenomena: earthquakes, operations on stock markets,\nneuronal activity, virus propagation and many others. In this paper, we focus\non MHPs with exponential decay kernels and estimate connectivity graphs, which\nrepresent the Granger causal relations between their components. We approach\nthis inference problem by proposing an optimization criterion and model\nselection algorithm based on the minimum message length (MML) principle. MML\ncompares Granger causal models using the Occam's razor principle in the\nfollowing way: even when models have a comparable goodness-of-fit to the\nobserved data, the one generating the most concise explanation of the data is\npreferred. While most of the state-of-art methods using lasso-type penalization\ntend to overfitting in scenarios with short time horizons, the proposed\nMML-based method achieves high F1 scores in these settings. We conduct a\nnumerical study comparing the proposed algorithm to other related classical and\nstate-of-art methods, where we achieve the highest F1 scores in specific sparse\ngraph settings. We illustrate the proposed method also on G7 sovereign bond\ndata and obtain causal connections, which are in agreement with the expert\nknowledge available in the literature.",
            "author": [
                "Katerina Hlavackova-Schindler",
                "Anna Melnykova",
                "Irene Tubikanec"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02027v1",
                "http://arxiv.org/pdf/2309.02027v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02025v1",
            "title": "RDGSL: Dynamic Graph Representation Learning with Structure Learning",
            "updated": "2023-09-05T08:03:59Z",
            "published": "2023-09-05T08:03:59Z",
            "summary": "Temporal Graph Networks (TGNs) have shown remarkable performance in learning\nrepresentation for continuous-time dynamic graphs. However, real-world dynamic\ngraphs typically contain diverse and intricate noise. Noise can significantly\ndegrade the quality of representation generation, impeding the effectiveness of\nTGNs in downstream tasks. Though structure learning is widely applied to\nmitigate noise in static graphs, its adaptation to dynamic graph settings poses\ntwo significant challenges. i) Noise dynamics. Existing structure learning\nmethods are ill-equipped to address the temporal aspect of noise, hampering\ntheir effectiveness in such dynamic and ever-changing noise patterns. ii) More\nsevere noise. Noise may be introduced along with multiple interactions between\ntwo nodes, leading to the re-pollution of these nodes and consequently causing\nmore severe noise compared to static graphs. In this paper, we present RDGSL, a\nrepresentation learning method in continuous-time dynamic graphs. Meanwhile, we\npropose dynamic graph structure learning, a novel supervisory signal that\nempowers RDGSL with the ability to effectively combat noise in dynamic graphs.\nTo address the noise dynamics issue, we introduce the Dynamic Graph Filter,\nwhere we innovatively propose a dynamic noise function that dynamically\ncaptures both current and historical noise, enabling us to assess the temporal\naspect of noise and generate a denoised graph. We further propose the Temporal\nEmbedding Learner to tackle the challenge of more severe noise, which utilizes\nan attention mechanism to selectively turn a blind eye to noisy edges and hence\nfocus on normal edges, enhancing the expressiveness for representation\ngeneration that remains resilient to noise. Our method demonstrates robustness\ntowards downstream tasks, resulting in up to 5.1% absolute AUC improvement in\nevolving classification versus the second-best baseline.",
            "author": [
                "Siwei Zhang",
                "Yun Xiong",
                "Yao Zhang",
                "Yiheng Sun",
                "Xi Chen",
                "Yizhu Jiao",
                "Yangyong Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02025v1",
                "http://arxiv.org/pdf/2309.02025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02023v1",
            "title": "Guided modes in a hexagonal periodic graph like domain",
            "updated": "2023-09-05T08:00:02Z",
            "published": "2023-09-05T08:00:02Z",
            "summary": "This paper deals with the existence of guided waves and edge states in\nparticular two-dimensional media obtained by perturbing a reference periodic\nmedium with honeycomb symmetry. This reference medium is a thin periodic domain\n(the thickness is denoted $\\delta$ > 0) with an hexagonal structure, which is\nclose to an honeycomb quantum graph. In a first step, we show the existence of\nDirac points (conical crossings) at arbitrarily large frequencies if $\\delta$\nis chosen small enough. We then perturbe the domain by cutting the perfectly\nperiodic medium along the so-called zigzag direction, and we consider either\nDirichlet or Neumann boundary conditions on the cut edge. In the two cases, we\nprove the existence of edges modes as well as their robustness with respect to\nsome perturbations, namely the location of the cut and the thickness of the\nperturbed edge. In particular, we show that different locations of the cut lead\nto almost-non dispersive edge states, the number of locations increasing with\nthe frequency. All the results are obtained via asymptotic analysis and\nsemi-explicit computations done on the limit quantum graph. Numerical\nsimulations illustrate the theoretical results.",
            "author": [
                "B\u00e9rang\u00e8re Delourme",
                "Sonia Fliss"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02023v1",
                "http://arxiv.org/pdf/2309.02023v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02012v1",
            "title": "iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and\n  Re-occurrence Preservation",
            "updated": "2023-09-05T07:48:52Z",
            "published": "2023-09-05T07:48:52Z",
            "summary": "Continuous-time dynamic graph modeling is a crucial task for many real-world\napplications, such as financial risk management and fraud detection. Though\nexisting dynamic graph modeling methods have achieved satisfactory results,\nthey still suffer from three key limitations, hindering their scalability and\nfurther applicability. i) Indiscriminate updating. For incoming edges, existing\nmethods would indiscriminately deal with them, which may lead to more time\nconsumption and unexpected noisy information. ii) Ineffective node-wise\nlong-term modeling. They heavily rely on recurrent neural networks (RNNs) as a\nbackbone, which has been demonstrated to be incapable of fully capturing\nnode-wise long-term dependencies in event sequences. iii) Neglect of\nre-occurrence patterns. Dynamic graphs involve the repeated occurrence of\nneighbors that indicates their importance, which is disappointedly neglected by\nexisting methods. In this paper, we present iLoRE, a novel dynamic graph\nmodeling method with instant node-wise Long-term modeling and Re-occurrence\npreservation. To overcome the indiscriminate updating issue, we introduce the\nAdaptive Short-term Updater module that will automatically discard the useless\nor noisy edges, ensuring iLoRE's effectiveness and instant ability. We further\npropose the Long-term Updater to realize more effective node-wise long-term\nmodeling, where we innovatively propose the Identity Attention mechanism to\nempower a Transformer-based updater, bypassing the limited effectiveness of\ntypical RNN-dominated designs. Finally, the crucial re-occurrence patterns are\nalso encoded into a graph module for informative representation learning, which\nwill further improve the expressiveness of our method. Our experimental results\non real-world datasets demonstrate the effectiveness of our iLoRE for dynamic\ngraph modeling.",
            "author": [
                "Siwei Zhang",
                "Yun Xiong",
                "Yao Zhang",
                "Xixi Wu",
                "Yiheng Sun",
                "Jiawei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02012v1",
                "http://arxiv.org/pdf/2309.02012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04024v1",
            "title": "Scale-Score: Investigation of a Meta yet Multi-level Label to Support\n  Nutritious and Sustainable Food Choices When Online Grocery Shopping",
            "updated": "2023-09-05T07:03:22Z",
            "published": "2023-09-05T07:03:22Z",
            "summary": "Food consumption is one of the biggest contributors to climate change.\nHowever, online grocery shoppers often lack the time, motivation, or knowledge\nto contemplate a food's environmental impact. At the same time, they are\nconcerned with their own well-being. To empower grocery shoppers in making\nnutritionally and environmentally informed decisions, we investigate the\nefficacy of the Scale-Score, a label combining nutritional and environmental\ninformation to highlight a product's benefit to both the consumer's and the\nplanet's health, without obscuring either information. We conducted an online\nsurvey to understand user needs and requirements regarding a joint food label,\nwe developed an open-source mock online grocery environment, and assessed label\nefficacy. We find that the Scale-Score supports nutritious purchases, yet needs\nimproving regarding sustainability support. Our research shows first insights\ninto design considerations and performance of a combined yet disjoint food\nlabel, potentially altering the label design space.",
            "author": [
                "Marco Druschba",
                "G\u00f6zel Shakeri"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04024v1",
                "http://arxiv.org/pdf/2309.04024v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.06844v1",
            "title": "Exploiting Unfair Advantages: Investigating Opportunistic Trading in the\n  NFT Market",
            "updated": "2023-09-05T06:43:38Z",
            "published": "2023-09-05T06:43:38Z",
            "summary": "As cryptocurrency evolved, new financial instruments, such as lending and\nborrowing protocols, currency exchanges, fungible and non-fungible tokens\n(NFT), staking and mining protocols have emerged. A financial ecosystem built\non top of a blockchain is supposed to be fair and transparent for each\nparticipating actor. Yet, there are sophisticated actors who turn their domain\nknowledge and market inefficiencies to their strategic advantage; thus\nextracting value from trades not accessible to others. This situation is\nfurther exacerbated by the fact that blockchain-based markets and decentralized\nfinance (DeFi) instruments are mostly unregulated. Though a large body of work\nhas already studied the unfairness of different aspects of DeFi and\ncryptocurrency trading, the economic intricacies of non-fungible token (NFT)\ntrades necessitate further analysis and academic scrutiny.\n  The trading volume of NFTs has skyrocketed in recent years. A single NFT\ntrade worth over a million US dollars, or marketplaces making billions in\nrevenue is not uncommon nowadays. While previous research indicated the\npresence of wrongdoings in the NFT market, to our knowledge, we are the first\nto study predatory trading practices, what we call opportunistic trading, in\ndepth. Opportunistic traders are sophisticated actors who employ automated,\nhigh-frequency NFT trading strategies, which, oftentimes, are malicious,\ndeceptive, or, at the very least, unfair. Such attackers weaponize their\nadvanced technical knowledge and superior understanding of DeFi protocols to\ndisrupt trades of unsuspecting users, and collect profits from economic\nsituations that are inaccessible to ordinary users, in a \"supposedly\" fair\nmarket. In this paper, we explore three such broad classes of opportunistic\nstrategies aiming to realize three distinct trading objectives, viz., acquire,\ninstant profit generation, and loss minimization.",
            "author": [
                "Priyanka Bose",
                "Dipanjan Das",
                "Fabio Gritti",
                "Nicola Ruaro",
                "Christopher Kruegel",
                "Giovanni Vigna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.06844v1",
                "http://arxiv.org/pdf/2310.06844v1"
            ],
            "primary_category": "q-fin.TR",
            "category": [
                "q-fin.TR",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01981v1",
            "title": "Graph-Based Interaction-Aware Multimodal 2D Vehicle Trajectory\n  Prediction using Diffusion Graph Convolutional Networks",
            "updated": "2023-09-05T06:28:13Z",
            "published": "2023-09-05T06:28:13Z",
            "summary": "Predicting vehicle trajectories is crucial for ensuring automated vehicle\noperation efficiency and safety, particularly on congested multi-lane highways.\nIn such dynamic environments, a vehicle's motion is determined by its\nhistorical behaviors as well as interactions with surrounding vehicles. These\nintricate interactions arise from unpredictable motion patterns, leading to a\nwide range of driving behaviors that warrant in-depth investigation. This study\npresents the Graph-based Interaction-aware Multi-modal Trajectory Prediction\n(GIMTP) framework, designed to probabilistically predict future vehicle\ntrajectories by effectively capturing these interactions. Within this\nframework, vehicles' motions are conceptualized as nodes in a time-varying\ngraph, and the traffic interactions are represented by a dynamic adjacency\nmatrix. To holistically capture both spatial and temporal dependencies embedded\nin this dynamic adjacency matrix, the methodology incorporates the Diffusion\nGraph Convolutional Network (DGCN), thereby providing a graph embedding of both\nhistorical states and future states. Furthermore, we employ a driving\nintention-specific feature fusion, enabling the adaptive integration of\nhistorical and future embeddings for enhanced intention recognition and\ntrajectory prediction. This model gives two-dimensional predictions for each\nmode of longitudinal and lateral driving behaviors and offers probabilistic\nfuture paths with corresponding probabilities, addressing the challenges of\ncomplex vehicle interactions and multi-modality of driving behaviors.\nValidation using real-world trajectory datasets demonstrates the efficiency and\npotential.",
            "author": [
                "Keshu Wu",
                "Yang Zhou",
                "Haotian Shi",
                "Xiaopeng Li",
                "Bin Ran"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01981v1",
                "http://arxiv.org/pdf/2309.01981v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01971v1",
            "title": "VFFINDER: A Graph-based Approach for Automated Silent Vulnerability-Fix\n  Identification",
            "updated": "2023-09-05T05:55:18Z",
            "published": "2023-09-05T05:55:18Z",
            "summary": "The increasing reliance of software projects on third-party libraries has\nraised concerns about the security of these libraries due to hidden\nvulnerabilities. Managing these vulnerabilities is challenging due to the time\ngap between fixes and public disclosures. Moreover, a significant portion of\nopen-source projects silently fix vulnerabilities without disclosure, impacting\nvulnerability management. Existing tools like OWASP heavily rely on public\ndisclosures, hindering their effectiveness in detecting unknown\nvulnerabilities. To tackle this problem, automated identification of\nvulnerability-fixing commits has emerged. However, identifying silent\nvulnerability fixes remains challenging. This paper presents VFFINDER, a novel\ngraph-based approach for automated silent vulnerability fix identification.\nVFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and\nrepresents them in annotated ASTs. VFFINDER distinguishes vulnerability-fixing\ncommits from non-fixing ones using attention-based graph neural network models\nto extract structural features. We conducted experiments to evaluate VFFINDER\non a dataset of 36K+ fixing and non-fixing commits in 507 real-world C/C++\nprojects. Our results show that VFFINDER significantly improves the\nstate-of-the-art methods by 39-83% in Precision, 19-148% in Recall, and 30-109%\nin F1. Especially, VFFINDER speeds up the silent fix identification process by\nup to 47% with the same review effort of 5% compared to the existing\napproaches.",
            "author": [
                "Son Nguyen",
                "Thanh Trong Vu",
                "Hieu Dinh Vo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01971v1",
                "http://arxiv.org/pdf/2309.01971v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01964v1",
            "title": "Gender Inequalities: Women Researchers Require More Knowledge in\n  Specific and Experimental Topics",
            "updated": "2023-09-05T05:36:06Z",
            "published": "2023-09-05T05:36:06Z",
            "summary": "Gender inequalities in science have long been observed globally. Studies have\ndemonstrated it through survey data or published literature, focusing on the\ninterests of subjects or authors; few, however, examined the manifestation of\ngender inequalities on researchers' knowledge status. This study analyzes the\nrelationship between regional and gender identities, topics, and knowledge\nstatus while revealing the female labor division in science and scientific\nresearch using online Q&A from researchers. We find that gender inequalities\nare merged with both regional-specific characteristics and global common\npatterns. Women's field and topic distribution within fields are influenced by\nregions, yet the prevalent topics are consistent in all regions. Women are more\ninvolved in specific topics, particularly topics about experiments with weaker\nlevels of knowledge and they are of less assistance. To promote inequality in\nscience, the scientific community should pay more attention to reducing the\nknowledge gap and encourage women to work on unexplored topics and areas.",
            "author": [
                "Shiqi Tang",
                "Dongyi Wang",
                "Jianhua Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01964v1",
                "http://arxiv.org/pdf/2309.01964v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16111v1",
            "title": "Deep Explainability: Spin-Geometrical Neural Meta-Structures",
            "updated": "2023-09-05T05:34:57Z",
            "published": "2023-09-05T05:34:57Z",
            "summary": "We face up to the challenge of explainability in multimodal artificial\nintelligence. At the nexus of neuroscience-inspired and quantum computing,\ninterpretable and transparent spin-geometrical meta-architectures for early\nfusion of large-scale, heterogeneous, graph-structured data are envisioned,\nharnessing recent evidence for relativistic quantum neural coding of\n(co-)behavioral states in the self-organizing brain, under competitive,\nmultidimensional dynamics. The designs draw on a self-dual classical\ndescription - via special Clifford-Lipschitz operations - of spinorial quantum\nstates within registers of at most 16 qubits for efficient encoding of\nexponentially large neural structures. Formally 'trained', Lorentz neural\narchitectures with precisely one lateral layer of exclusively inhibitory\ninterneurons accounting for anti-modalities, as well as their co-architectures\nwith intra-layer connections are highlighted. In principle, the approach\naccommodates the fusion of up to 16 time-invariant interconnected\n(anti-)modalities and the explicit recognition of underlying multidimensional\npatterns. Comprehensive insights are expected to be gained through applications\nto multimodal big data, under real-world scenarios.",
            "author": [
                "Sofia Karamintziou",
                "Georgios Meditskos",
                "Dimos Ntioudis",
                "Thanassis Mavropoulos",
                "Stefanos Vrochidis",
                "Ioannis",
                "Kompatsiaris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16111v1",
                "http://arxiv.org/pdf/2311.16111v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01957v2",
            "title": "Automatic Data Transformation Using Large Language Model: An\n  Experimental Study on Building Energy Data",
            "updated": "2023-09-06T04:25:02Z",
            "published": "2023-09-05T05:19:35Z",
            "summary": "Existing approaches to automatic data transformation are insufficient to meet\nthe requirements in many real-world scenarios, such as the building sector.\nFirst, there is no convenient interface for domain experts to provide domain\nknowledge easily. Second, they require significant training data collection\noverheads. Third, the accuracy suffers from complicated schema changes. To\nbridge this gap, we present a novel approach that leverages the unique\ncapabilities of large language models (LLMs) in coding, complex reasoning, and\nzero-shot learning to generate SQL code that transforms the source datasets\ninto the target datasets. We demonstrate the viability of this approach by\ndesigning an LLM-based framework, termed SQLMorpher, which comprises a prompt\ngenerator that integrates the initial prompt with optional domain knowledge and\nhistorical patterns in external databases. It also implements an iterative\nprompt optimization mechanism that automatically improves the prompt based on\nflaw detection. The key contributions of this work include (1) pioneering an\nend-to-end LLM-based solution for data transformation, (2) developing a\nbenchmark dataset of 105 real-world building energy data transformation\nproblems, and (3) conducting an extensive empirical evaluation where our\napproach achieved 96% accuracy in all 105 problems. SQLMorpher demonstrates the\neffectiveness of utilizing LLMs in complex, domain-specific challenges,\nhighlighting the potential of their potential to drive sustainable solutions.",
            "author": [
                "Ankita Sharma",
                "Xuanmao Li",
                "Hong Guan",
                "Guoxin Sun",
                "Liang Zhang",
                "Lanjun Wang",
                "Kesheng Wu",
                "Lei Cao",
                "Erkang Zhu",
                "Alexander Sim",
                "Teresa Wu",
                "Jia Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01957v2",
                "http://arxiv.org/pdf/2309.01957v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01947v2",
            "title": "TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression\n  For On-device ASR Models",
            "updated": "2023-11-27T05:03:31Z",
            "published": "2023-09-05T04:47:55Z",
            "summary": "Automatic Speech Recognition (ASR) models need to be optimized for specific\nhardware before they can be deployed on devices. This can be done by tuning the\nmodel's hyperparameters or exploring variations in its architecture.\nRe-training and re-validating models after making these changes can be a\nresource-intensive task. This paper presents TODM (Train Once Deploy Many), a\nnew approach to efficiently train many sizes of hardware-friendly on-device ASR\nmodels with comparable GPU-hours to that of a single training job. TODM\nleverages insights from prior work on Supernet, where Recurrent Neural Network\nTransducer (RNN-T) models share weights within a Supernet. It reduces layer\nsizes and widths of the Supernet to obtain subnetworks, making them smaller\nmodels suitable for all hardware types. We introduce a novel combination of\nthree techniques to improve the outcomes of the TODM Supernet: adaptive\ndropouts, an in-place Alpha-divergence knowledge distillation, and the use of\nScaledAdam optimizer. We validate our approach by comparing Supernet-trained\nversus individually tuned Multi-Head State Space Model (MH-SSM) RNN-T using\nLibriSpeech. Results demonstrate that our TODM Supernet either matches or\nsurpasses the performance of manually tuned models by up to a relative of 3%\nbetter in word error rate (WER), while efficiently keeping the cost of training\nmany models at a small constant.",
            "author": [
                "Yuan Shangguan",
                "Haichuan Yang",
                "Danni Li",
                "Chunyang Wu",
                "Yassir Fathullah",
                "Dilin Wang",
                "Ayushi Dalmia",
                "Raghuraman Krishnamoorthi",
                "Ozlem Kalinli",
                "Junteng Jia",
                "Jay Mahadeokar",
                "Xin Lei",
                "Mike Seltzer",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01947v2",
                "http://arxiv.org/pdf/2309.01947v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01919v2",
            "title": "Towards Understanding of Deepfake Videos in the Wild",
            "updated": "2023-09-06T08:57:13Z",
            "published": "2023-09-05T03:16:38Z",
            "summary": "Deepfakes have become a growing concern in recent years, prompting\nresearchers to develop benchmark datasets and detection algorithms to tackle\nthe issue. However, existing datasets suffer from significant drawbacks that\nhamper their effectiveness. Notably, these datasets fail to encompass the\nlatest deepfake videos produced by state-of-the-art methods that are being\nshared across various platforms. This limitation impedes the ability to keep\npace with the rapid evolution of generative AI techniques employed in\nreal-world deepfake production. Our contributions in this IRB-approved study\nare to bridge this knowledge gap from current real-world deepfakes by providing\nin-depth analysis. We first present the largest and most diverse and recent\ndeepfake dataset (RWDF-23) collected from the wild to date, consisting of 2,000\ndeepfake videos collected from 4 platforms targeting 4 different languages span\ncreated from 21 countries: Reddit, YouTube, TikTok, and Bilibili. By expanding\nthe dataset's scope beyond the previous research, we capture a broader range of\nreal-world deepfake content, reflecting the ever-evolving landscape of online\nplatforms. Also, we conduct a comprehensive analysis encompassing various\naspects of deepfakes, including creators, manipulation strategies, purposes,\nand real-world content production methods. This allows us to gain valuable\ninsights into the nuances and characteristics of deepfakes in different\ncontexts. Lastly, in addition to the video content, we also collect viewer\ncomments and interactions, enabling us to explore the engagements of internet\nusers with deepfake content. By considering this rich contextual information,\nwe aim to provide a holistic understanding of the {evolving} deepfake\nphenomenon and its impact on online platforms.",
            "author": [
                "Beomsang Cho",
                "Binh M. Le",
                "Jiwon Kim",
                "Simon Woo",
                "Shahroz Tariq",
                "Alsharif Abuadbba",
                "Kristen Moore"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614729",
                "http://arxiv.org/abs/2309.01919v2",
                "http://arxiv.org/pdf/2309.01919v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01904v1",
            "title": "Improving Drone Imagery For Computer Vision/Machine Learning in\n  Wilderness Search and Rescue",
            "updated": "2023-09-05T02:31:04Z",
            "published": "2023-09-05T02:31:04Z",
            "summary": "This paper describes gaps in acquisition of drone imagery that impair the use\nwith computer vision/machine learning (CV/ML) models and makes five\nrecommendations to maximize image suitability for CV/ML post-processing. It\ndescribes a notional work process for the use of drones in wilderness search\nand rescue incidents. The large volume of data from the wide area search phase\noffers the greatest opportunity for CV/ML techniques because of the large\nnumber of images that would otherwise have to be manually inspected. The 2023\nWu-Murad search in Japan, one of the largest missing person searches conducted\nin that area, serves as a case study. Although drone teams conducting wide area\nsearches may not know in advance if the data they collect is going to be used\nfor CV/ML post-processing, there are data collection procedures that can\nimprove the search in general with automated collection software. If the drone\nteams do expect to use CV/ML, then they can exploit knowledge about the model\nto further optimize flights.",
            "author": [
                "Robin Murphy",
                "Thomas Manzini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01904v1",
                "http://arxiv.org/pdf/2309.01904v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01900v1",
            "title": "Non-$\\ell$-distance-balanced generalized Petersen graphs $GP(n,3)$ and\n  $GP(n,4)$",
            "updated": "2023-09-05T02:16:12Z",
            "published": "2023-09-05T02:16:12Z",
            "summary": "A connected graph $G$ of diameter ${\\rm diam}(G) \\ge \\ell$ is\n$\\ell$-distance-balanced if $|W_{xy}|=|W_{yx}|$ for every $x,y\\in V(G)$ with\n$d_{G}(x,y)=\\ell$, where $W_{xy}$ is the set of vertices of $G$ that are closer\nto $x$ than to $y$. We prove that the generalized Petersen graph $GP(n,3)$\nwhere $n>16$ is not $\\ell$-distance-balanced for any $1\\le \\ell < {\\rm\ndiam}(GP(n,3))$, and $GP(n,4)$ where $n>24$ is not $\\ell$-distance-balanced for\nany $1\\le \\ell < {\\rm diam}(GP(n,4))$. This partially solves a conjecture posed\nby \\v{S}. Miklavi\\v{c} and P. \\v{S}parl (Discrete Appl. Math. 244:143-154,\n2018).",
            "author": [
                "Gang Ma",
                "Jianfeng Wang",
                "Sandi Klav\u017ear"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01900v1",
                "http://arxiv.org/pdf/2309.01900v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C12"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01899v1",
            "title": "Unsupervised Skin Lesion Segmentation via Structural Entropy\n  Minimization on Multi-Scale Superpixel Graphs",
            "updated": "2023-09-05T02:15:51Z",
            "published": "2023-09-05T02:15:51Z",
            "summary": "Skin lesion segmentation is a fundamental task in dermoscopic image analysis.\nThe complex features of pixels in the lesion region impede the lesion\nsegmentation accuracy, and existing deep learning-based methods often lack\ninterpretability to this problem. In this work, we propose a novel unsupervised\nSkin Lesion sEgmentation framework based on structural entropy and isolation\nforest outlier Detection, namely SLED. Specifically, skin lesions are segmented\nby minimizing the structural entropy of a superpixel graph constructed from the\ndermoscopic image. Then, we characterize the consistency of healthy skin\nfeatures and devise a novel multi-scale segmentation mechanism by outlier\ndetection, which enhances the segmentation accuracy by leveraging the\nsuperpixel features from multiple scales. We conduct experiments on four skin\nlesion benchmarks and compare SLED with nine representative unsupervised\nsegmentation methods. Experimental results demonstrate the superiority of the\nproposed framework. Additionally, some case studies are analyzed to demonstrate\nthe effectiveness of SLED.",
            "author": [
                "Guangjie Zeng",
                "Hao Peng",
                "Angsheng Li",
                "Zhiwei Liu",
                "Chunyang Liu",
                "Philip S. Yu",
                "Lifang He"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01899v1",
                "http://arxiv.org/pdf/2309.01899v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01897v3",
            "title": "Inferring Actual Treatment Pathways from Patient Records",
            "updated": "2023-11-25T22:52:24Z",
            "published": "2023-09-05T02:15:08Z",
            "summary": "Treatment pathways are step-by-step plans outlining the recommended medical\ncare for specific diseases; they get revised when different treatments are\nfound to improve patient outcomes. Examining health records is an important\npart of this revision process, but inferring patients' actual treatments from\nhealth data is challenging due to complex event-coding schemes and the absence\nof pathway-related annotations. This study aims to infer the actual treatment\nsteps for a particular patient group from administrative health records (AHR) -\na common form of tabular healthcare data - and address several technique- and\nmethodology-based gaps in treatment pathway-inference research. We introduce\nDefrag, a method for examining AHRs to infer the real-world treatment steps for\na particular patient group. Defrag learns the semantic and temporal meaning of\nhealthcare event sequences, allowing it to reliably infer treatment steps from\ncomplex healthcare data. To our knowledge, Defrag is the first\npathway-inference method to utilise a neural network (NN), an approach made\npossible by a novel, self-supervised learning objective. We also developed a\ntesting and validation framework for pathway inference, which we use to\ncharacterise and evaluate Defrag's pathway inference ability and compare\nagainst baselines. We demonstrate Defrag's effectiveness by identifying\nbest-practice pathway fragments for breast cancer, lung cancer, and melanoma in\npublic healthcare records. Additionally, we use synthetic data experiments to\ndemonstrate the characteristics of the Defrag method, and to compare Defrag to\nseveral baselines where it significantly outperforms non-NN-based methods.\nDefrag significantly outperforms several existing pathway-inference methods and\noffers an innovative and effective approach for inferring treatment pathways\nfrom AHRs. Open-source code is provided to encourage further research in this\narea.",
            "author": [
                "Adrian Wilkins-Caruana",
                "Madhushi Bandara",
                "Katarzyna Musial",
                "Daniel Catchpoole",
                "Paul J. Kennedy"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jbi.2023.104554",
                "http://arxiv.org/abs/2309.01897v3",
                "http://arxiv.org/pdf/2309.01897v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01869v1",
            "title": "The Three Tree Theorem",
            "updated": "2023-09-05T00:20:24Z",
            "published": "2023-09-05T00:20:24Z",
            "summary": "We prove that every 2-sphere graph different from a prism can be vertex\n4-colored in such a way that all Kempe chains are forests. This implies the\nfollowing three tree theorem: the arboricity of a discrete 2-sphere is 3.\nMoreover, the three trees can be chosen so that each hits every triangle. A\nconsequence is a result of an exercise in the book of Bondy and Murty based on\nwork of A. Frank, A. Gyarfas and C. Nash-Williams: the arboricity of a planar\ngraph is less or equal than 3.",
            "author": [
                "Oliver Knill"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01869v1",
                "http://arxiv.org/pdf/2309.01869v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C10, 05C15, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01868v1",
            "title": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
            "updated": "2023-09-05T00:19:31Z",
            "published": "2023-09-05T00:19:31Z",
            "summary": "The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.",
            "author": [
                "Yunhao Yang",
                "Anshul Tomar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01868v1",
                "http://arxiv.org/pdf/2309.01868v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01866v2",
            "title": "Efficient Query-Based Attack against ML-Based Android Malware Detection\n  under Zero Knowledge Setting",
            "updated": "2023-09-06T11:50:03Z",
            "published": "2023-09-05T00:14:12Z",
            "summary": "The widespread adoption of the Android operating system has made malicious\nAndroid applications an appealing target for attackers. Machine learning-based\n(ML-based) Android malware detection (AMD) methods are crucial in addressing\nthis problem; however, their vulnerability to adversarial examples raises\nconcerns. Current attacks against ML-based AMD methods demonstrate remarkable\nperformance but rely on strong assumptions that may not be realistic in\nreal-world scenarios, e.g., the knowledge requirements about feature space,\nmodel parameters, and training dataset. To address this limitation, we\nintroduce AdvDroidZero, an efficient query-based attack framework against\nML-based AMD methods that operates under the zero knowledge setting. Our\nextensive evaluation shows that AdvDroidZero is effective against various\nmainstream ML-based AMD methods, in particular, state-of-the-art such methods\nand real-world antivirus solutions.",
            "author": [
                "Ping He",
                "Yifan Xia",
                "Xuhong Zhang",
                "Shouling Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01866v2",
                "http://arxiv.org/pdf/2309.01866v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01863v1",
            "title": "Global Topology of 3D Symmetric Tensor Fields",
            "updated": "2023-09-04T23:48:33Z",
            "published": "2023-09-04T23:48:33Z",
            "summary": "There have been recent advances in the analysis and visualization of 3D\nsymmetric tensor fields, with a focus on the robust extraction of tensor field\ntopology. However, topological features such as degenerate curves and neutral\nsurfaces do not live in isolation. Instead, they intriguingly interact with\neach other. In this paper, we introduce the notion of {\\em topological graph}\nfor 3D symmetric tensor fields to facilitate global topological analysis of\nsuch fields. The nodes of the graph include degenerate curves and regions\nbounded by neutral surfaces in the domain. The edges in the graph denote the\nadjacency information between the regions and degenerate curves. In addition,\nwe observe that a degenerate curve can be a loop and even a knot and that two\ndegenerate curves (whether in the same region or not) can form a link. We\nprovide a definition and theoretical analysis of individual degenerate curves\nin order to help understand why knots and links may occur. Moreover, we\ndifferentiate between wedges and trisectors, thus making the analysis more\ndetailed about degenerate curves. We incorporate this information into the\ntopological graph. Such a graph can not only reveal the global structure in a\n3D symmetric tensor field but also allow two symmetric tensor fields to be\ncompared. We demonstrate our approach by applying it to solid mechanics and\nmaterial science data sets.",
            "author": [
                "Shih-Hsuan Hung",
                "Yue Zhang",
                "Eugene Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01863v1",
                "http://arxiv.org/pdf/2309.01863v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01861v1",
            "title": "FlexRDZ: Autonomous Mobility Management for Radio Dynamic Zones",
            "updated": "2023-09-04T23:35:54Z",
            "published": "2023-09-04T23:35:54Z",
            "summary": "FlexRDZ is an online, autonomous manager for radio dynamic zones (RDZ) that\nseeks to enable the safe operation of RDZs through real-time control of\ndeployed test transmitters. FlexRDZ leverages Hierarchical Task Networks and\ndigital twin modeling to plan and resolve RDZ violations in near real-time. We\nprototype FlexRDZ with GTPyhop and the Terrain Integrated Rough Earth Model\n(TIREM). We deploy and evaluate FlexRDZ within a simulated version of the Salt\nLake City POWDER testbed, a potential urban RDZ environment. Our simulations\nshow that FlexRDZ enables up to a 20 dBm reduction in mobile interference and a\nsignificant reduction in the total power of leaked transmissions while\npreserving the overall communication capabilities and uptime of test\ntransmitters. To our knowledge, FlexRDZ is the first autonomous system for RDZ\nmanagement.",
            "author": [
                "Aashish Gottipati",
                "Jacobus Van der Merwe"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01861v1",
                "http://arxiv.org/pdf/2309.01861v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01857v2",
            "title": "On non-degenerate Tur\u00e1n problems for expansion",
            "updated": "2023-09-06T19:01:06Z",
            "published": "2023-09-04T23:16:38Z",
            "summary": "The $r$-uniform expansion $F^{(r)+}$ of a graph $F$ is obtained by enlarging\neach edge with $r-2$ new vertices such that altogether we use $(r-2)|E(F)|$ new\nvertices. Two simple lower bounds on the largest number\n$\\mathrm{ex}_r(n,F^{(r)+})$ of $r$-edges in $F^{(r)+}$-free $r$-graphs are\n$\\Omega(n^{r-1})$ (in the case $F$ is not a star) and $\\mathrm{ex}(n,K_r,F)$,\nwhich is the largest number of $r$-cliques in $n$-vertex $F$-free graphs. We\nprove that $\\mathrm{ex}_r(n,F^{(r)+})=\\mathrm{ex}(n,K_r,F)+O(n^{r-1})$. The\nproof comes with a structure theorem that we use to determine\n$\\ex_r(n,F^{(r)+})$ exactly for some graphs $F$, every $r\\chi(F)$ and\nsufficiently large $n$.",
            "author": [
                "D\u00e1niel Gerbner"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01857v2",
                "http://arxiv.org/pdf/2309.01857v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01854v1",
            "title": "Dynamical Stability of Threshold Networks over Undirected Signed Graphs",
            "updated": "2023-09-04T23:02:40Z",
            "published": "2023-09-04T23:02:40Z",
            "summary": "In this paper we study the dynamic behavior of threshold networks on\nundirected signed graphs. While much attention has been given to the\nconvergence and long-term behavior of this model, an open question remains: How\ndoes the underlying graph structure influence network dynamics? While similar\npapers have been carried out for threshold networks (as well as for other\nnetworks) these have largely focused on unsigned networks. However, the signed\ngraph model finds applications in various real-world domains like gene\nregulation and social networks.\n  By studying a graph parameter that we call \"stability index,\" we search to\nestablish a connection between the structure and the dynamics of threshold\nnetwork. Interestingly, this parameter is related to the concepts of\nfrustration and balance in signed graphs. We show that graphs that present\nnegative stability index exhibit stable dynamics, meaning that the dynamics\nconverges to fixed points regardless of threshold parameters. Conversely, if at\nleast one subgraph has positive stability index, oscillations in long term\nbehavior may appear. Finally, we generalize the analysis to network dynamics\nunder periodic update schemes and we explore the case in which the stability\nindex is positive for some subgraph finding that attractors with\nsuperpolynomial period on the size of the network may appear.",
            "author": [
                "Eric Goles",
                "Pedro Montealegre",
                "Mart\u00edn R\u00edos-Wilson",
                "Sylvain Sen\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01854v1",
                "http://arxiv.org/pdf/2309.01854v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01852v1",
            "title": "Local Certification of Majority Dynamics",
            "updated": "2023-09-04T22:57:35Z",
            "published": "2023-09-04T22:57:35Z",
            "summary": "In majority voting dynamics, a group of $n$ agents in a social network are\nasked for their preferred candidate in a future election between two possible\nchoices. At each time step, a new poll is taken, and each agent adjusts their\nvote according to the majority opinion of their network neighbors. After $T$\ntime steps, the candidate with the majority of votes is the leading contender\nin the election. In general, it is very hard to predict who will be the leading\ncandidate after a large number of time-steps.\n  We study, from the perspective of local certification, the problem of\npredicting the leading candidate after a certain number of time-steps, which we\ncall Election-Prediction. We show that in graphs with sub-exponential growth\nElection-Prediction admits a proof labeling scheme of size $\\mathcal{O}(\\log\nn)$. We also find non-trivial upper bounds for graphs with a bounded degree, in\nwhich the size of the certificates are sub-linear in $n$.\n  Furthermore, we explore lower bounds for the unrestricted case, showing that\nlocally checkable proofs for Election-Prediction on arbitrary $n$-node graphs\nhave certificates on $\\Omega(n)$ bits. Finally, we show that our upper bounds\nare tight even for graphs of constant growth.",
            "author": [
                "Diego Maldonado",
                "Pedro Montealegre",
                "Mart\u00edn R\u00edos-Wilson",
                "Guillaume Theyssier"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01852v1",
                "http://arxiv.org/pdf/2309.01852v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01839v2",
            "title": "Designing a Security System Administration Course for Cybersecurity with\n  a Companion Project",
            "updated": "2023-10-14T02:55:31Z",
            "published": "2023-09-04T22:28:01Z",
            "summary": "In the past few years, an incident response-oriented cybersecurity program\nhas been constructed at University of Central Oklahoma. As a core course in the\nnewly-established curricula, Secure System Administration focuses on the\nessential knowledge and skill set for system administration. To enrich students\nwith hands-on experience, we also develop a companion coursework project, named\nPowerGrader. In this paper, we present the course structure as well as the\ncompanion project design. Additionally, we survey the pertinent criterion and\ncurriculum requirements from the widely recognized accreditation units. By this\nmeans, we demonstrate the importance of a secure system administration course\nwithin the context of cybersecurity education.",
            "author": [
                "Fei Zuo",
                "Junghwan Rhee",
                "Myungah Park",
                "Gang Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01839v2",
                "http://arxiv.org/pdf/2309.01839v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01837v1",
            "title": "Delegating Data Collection in Decentralized Machine Learning",
            "updated": "2023-09-04T22:16:35Z",
            "published": "2023-09-04T22:16:35Z",
            "summary": "Motivated by the emergence of decentralized machine learning ecosystems, we\nstudy the delegation of data collection. Taking the field of contract theory as\nour starting point, we design optimal and near-optimal contracts that deal with\ntwo fundamental machine learning challenges: lack of certainty in the\nassessment of model quality and lack of knowledge regarding the optimal\nperformance of any model. We show that lack of certainty can be dealt with via\nsimple linear contracts that achieve 1-1/e fraction of the first-best utility,\neven if the principal has a small test set. Furthermore, we give sufficient\nconditions on the size of the principal's test set that achieves a vanishing\nadditive approximation to the optimal utility. To address the lack of a priori\nknowledge regarding the optimal performance, we give a convex program that can\nadaptively and efficiently compute the optimal contract.",
            "author": [
                "Nivasini Ananthakrishnan",
                "Stephen Bates",
                "Michael I. Jordan",
                "Nika Haghtalab"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01837v1",
                "http://arxiv.org/pdf/2309.01837v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01825v3",
            "title": "LoopTune: Optimizing Tensor Computations with Reinforcement Learning",
            "updated": "2023-11-08T16:44:32Z",
            "published": "2023-09-04T21:30:15Z",
            "summary": "Advanced compiler technology is crucial for enabling machine learning\napplications to run on novel hardware, but traditional compilers fail to\ndeliver performance, popular auto-tuners have long search times and\nexpert-optimized libraries introduce unsustainable costs. To address this, we\ndeveloped LoopTune, a deep reinforcement learning compiler that optimizes\ntensor computations in deep learning models for the CPU. LoopTune optimizes\ntensor traversal order while using the ultra-fast lightweight code generator\nLoopNest to perform hardware-specific optimizations. With a novel graph-based\nrepresentation and action space, LoopTune speeds up LoopNest by 3.2x,\ngenerating an order of magnitude faster code than TVM, 2.8x faster than\nMetaSchedule, and 1.08x faster than AutoTVM, consistently performing at the\nlevel of the hand-tuned library Numpy. Moreover, LoopTune tunes code in order\nof seconds.",
            "author": [
                "Dejan Grubisic",
                "Bram Wasti",
                "Chris Cummins",
                "John Mellor-Crummey",
                "Aleksandar Zlateski"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01825v3",
                "http://arxiv.org/pdf/2309.01825v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01812v1",
            "title": "Into the Single Cell Multiverse: an End-to-End Dataset for Procedural\n  Knowledge Extraction in Biomedical Texts",
            "updated": "2023-09-04T21:02:36Z",
            "published": "2023-09-04T21:02:36Z",
            "summary": "Many of the most commonly explored natural language processing (NLP)\ninformation extraction tasks can be thought of as evaluations of declarative\nknowledge, or fact-based information extraction. Procedural knowledge\nextraction, i.e., breaking down a described process into a series of steps, has\nreceived much less attention, perhaps in part due to the lack of structured\ndatasets that capture the knowledge extraction process from end-to-end. To\naddress this unmet need, we present FlaMB\\'e (Flow annotations for Multiverse\nBiological entities), a collection of expert-curated datasets across a series\nof complementary tasks that capture procedural knowledge in biomedical texts.\nThis dataset is inspired by the observation that one ubiquitous source of\nprocedural knowledge that is described as unstructured text is within academic\npapers describing their methodology. The workflows annotated in FlaMB\\'e are\nfrom texts in the burgeoning field of single cell research, a research area\nthat has become notorious for the number of software tools and complexity of\nworkflows used. Additionally, FlaMB\\'e provides, to our knowledge, the largest\nmanually curated named entity recognition (NER) and disambiguation (NED)\ndatasets for tissue/cell type, a fundamental biological entity that is critical\nfor knowledge extraction in the biomedical research domain. Beyond providing a\nvaluable dataset to enable further development of NLP models for procedural\nknowledge extraction, automating the process of workflow mining also has\nimportant implications for advancing reproducibility in biomedical research.",
            "author": [
                "Ruth Dannenfelser",
                "Jeffrey Zhong",
                "Ran Zhang",
                "Vicky Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01812v1",
                "http://arxiv.org/pdf/2309.01812v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01811v2",
            "title": "Instant Continual Learning of Neural Radiance Fields",
            "updated": "2023-09-06T02:10:37Z",
            "published": "2023-09-04T21:01:55Z",
            "summary": "Neural radiance fields (NeRFs) have emerged as an effective method for\nnovel-view synthesis and 3D scene reconstruction. However, conventional\ntraining methods require access to all training views during scene\noptimization. This assumption may be prohibitive in continual learning\nscenarios, where new data is acquired in a sequential manner and a continuous\nupdate of the NeRF is desired, as in automotive or remote sensing applications.\nWhen naively trained in such a continual setting, traditional scene\nrepresentation frameworks suffer from catastrophic forgetting, where previously\nlearned knowledge is corrupted after training on new data. Prior works in\nalleviating forgetting with NeRFs suffer from low reconstruction quality and\nhigh latency, making them impractical for real-world application. We propose a\ncontinual learning framework for training NeRFs that leverages replay-based\nmethods combined with a hybrid explicit--implicit scene representation. Our\nmethod outperforms previous methods in reconstruction quality when trained in a\ncontinual setting, while having the additional benefit of being an order of\nmagnitude faster.",
            "author": [
                "Ryan Po",
                "Zhengyang Dong",
                "Alexander W. Bergman",
                "Gordon Wetzstein"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01811v2",
                "http://arxiv.org/pdf/2309.01811v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01808v2",
            "title": "DiscoverPath: A Knowledge Refinement and Retrieval System for\n  Interdisciplinarity on Biomedical Research",
            "updated": "2023-10-10T22:30:42Z",
            "published": "2023-09-04T20:52:33Z",
            "summary": "The exponential growth in scholarly publications necessitates advanced tools\nfor efficient article retrieval, especially in interdisciplinary fields where\ndiverse terminologies are used to describe similar research. Traditional\nkeyword-based search engines often fall short in assisting users who may not be\nfamiliar with specific terminologies. To address this, we present a knowledge\ngraph-based paper search engine for biomedical research to enhance the user\nexperience in discovering relevant queries and articles. The system, dubbed\nDiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS)\ntagging to extract terminologies and relationships from article abstracts to\ncreate a KG. To reduce information overload, DiscoverPath presents users with a\nfocused subgraph containing the queried entity and its neighboring nodes and\nincorporates a query recommendation system, enabling users to iteratively\nrefine their queries. The system is equipped with an accessible Graphical User\nInterface that provides an intuitive visualization of the KG, query\nrecommendations, and detailed article information, enabling efficient article\nretrieval, thus fostering interdisciplinary knowledge exploration. DiscoverPath\nis open-sourced at https://github.com/ynchuang/DiscoverPath.",
            "author": [
                "Yu-Neng Chuang",
                "Guanchu Wang",
                "Chia-Yuan Chang",
                "Kwei-Herng Lai",
                "Daochen Zha",
                "Ruixiang Tang",
                "Fan Yang",
                "Alfredo Costilla Reyes",
                "Kaixiong Zhou",
                "Xiaoqian Jiang",
                "Xia Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01808v2",
                "http://arxiv.org/pdf/2309.01808v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01798v1",
            "title": "New Qubit Codes from Multidimensional Circulant Graphs",
            "updated": "2023-09-04T20:24:17Z",
            "published": "2023-09-04T20:24:17Z",
            "summary": "Two new qubit stabilizer codes with parameters $[77, 0, 19]_2$ and $[90, 0,\n22]_2$ are constructed for the first time by employing additive symplectic\nself-dual $\\F_4$ codes from multidimensional circulant (MDC) graphs. We\ncompletely classify MDC graph codes for lengths $4\\le n \\le 40$ and show that\nmany optimal $\\dsb{\\ell, 0, d}$ qubit codes can be obtained from the MDC\nconstruction. Moreover, we prove that adjacency matrices of MDC graphs have\nnested block circulant structure and determine isomorphism properties of MDC\ngraphs.",
            "author": [
                "Padmapani Seneviratne",
                "Hannah Cuff",
                "Alexandra Koletsos",
                "Kerry Seekamp",
                "Adrian Thnanopavarn"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01798v1",
                "http://arxiv.org/pdf/2309.01798v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT",
                "94B05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01788v1",
            "title": "Hierarchical Grammar-Induced Geometry for Data-Efficient Molecular\n  Property Prediction",
            "updated": "2023-09-04T19:59:51Z",
            "published": "2023-09-04T19:59:51Z",
            "summary": "The prediction of molecular properties is a crucial task in the field of\nmaterial and drug discovery. The potential benefits of using deep learning\ntechniques are reflected in the wealth of recent literature. Still, these\ntechniques are faced with a common challenge in practice: Labeled data are\nlimited by the cost of manual extraction from literature and laborious\nexperimentation. In this work, we propose a data-efficient property predictor\nby utilizing a learnable hierarchical molecular grammar that can generate\nmolecules from grammar production rules. Such a grammar induces an explicit\ngeometry of the space of molecular graphs, which provides an informative prior\non molecular structural similarity. The property prediction is performed using\ngraph neural diffusion over the grammar-induced geometry. On both small and\nlarge datasets, our evaluation shows that this approach outperforms a wide\nspectrum of baselines, including supervised and pre-trained graph neural\nnetworks. We include a detailed ablation study and further analysis of our\nsolution, showing its effectiveness in cases with extremely limited data. Code\nis available at https://github.com/gmh14/Geo-DEG.",
            "author": [
                "Minghao Guo",
                "Veronika Thost",
                "Samuel W Song",
                "Adithya Balachandran",
                "Payel Das",
                "Jie Chen",
                "Wojciech Matusik"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01788v1",
                "http://arxiv.org/pdf/2309.01788v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01786v1",
            "title": "Safe and Robust Watermark Injection with a Single OoD Image",
            "updated": "2023-09-04T19:58:35Z",
            "published": "2023-09-04T19:58:35Z",
            "summary": "Training a high-performance deep neural network requires large amounts of\ndata and computational resources. Protecting the intellectual property (IP) and\ncommercial ownership of a deep model is challenging yet increasingly crucial. A\nmajor stream of watermarking strategies implants verifiable backdoor triggers\nby poisoning training samples, but these are often unrealistic due to data\nprivacy and safety concerns and are vulnerable to minor model changes such as\nfine-tuning. To overcome these challenges, we propose a safe and robust\nbackdoor-based watermark injection technique that leverages the diverse\nknowledge from a single out-of-distribution (OoD) image, which serves as a\nsecret key for IP verification. The independence of training data makes it\nagnostic to third-party promises of IP security. We induce robustness via\nrandom perturbation of model parameters during watermark injection to defend\nagainst common watermark removal attacks, including fine-tuning, pruning, and\nmodel extraction. Our experimental results demonstrate that the proposed\nwatermarking approach is not only time- and sample-efficient without training\ndata, but also robust against the watermark removal attacks above.",
            "author": [
                "Shuyang Yu",
                "Junyuan Hong",
                "Haobo Zhang",
                "Haotao Wang",
                "Zhangyang Wang",
                "Jiayu Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01786v1",
                "http://arxiv.org/pdf/2309.01786v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01762v1",
            "title": "Thresholds for Pebbling on Grids",
            "updated": "2023-09-04T18:43:42Z",
            "published": "2023-09-04T18:43:42Z",
            "summary": "Given a connected graph $G$ and a configuration of $t$ pebbles on the\nvertices of G, a $q$-pebbling step consists of removing $q$ pebbles from a\nvertex, and adding a single pebble to one of its neighbors. Given a vector\n$\\bf{q}=(q_1,\\ldots,q_d)$, $\\bf{q}$-pebbling consists of allowing\n$q_i$-pebbling in coordinate $i$. A distribution of pebbles is called solvable\nif it is possible to transfer at least one pebble to any specified vertex of\n$G$ via a finite sequence of pebbling steps.\n  In this paper, we determine the weak threshold for $\\bf{q}$-pebbling on the\nsequence of grids $[n]^d$ for fixed $d$ and $\\bf{q}$, as $n\\to\\infty$. Further,\nwe determine the strong threshold for $q$-pebbling on the sequence of paths of\nincreasing length. A fundamental tool in these proofs is a new notion of\ncentrality, and a sufficient condition for solvability based on the well used\npebbling weight functions; we believe this weight lemma to be the first result\nof its kind, and may be of independent interest.\n  These theorems improve recent results of Czygrinow and Hurlbert, and Godbole,\nJablonski, Salzman, and Wierman. They are the generalizations to the random\nsetting of much earlier results of Chung.\n  In addition, we give a short counterexample showing that the threshold\nversion of a well known conjecture of Graham does not hold. This uses a result\nfor hypercubes due to Czygrinow and Wagner.",
            "author": [
                "Neal Bushaw",
                "Nathan Kettle"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01762v1",
                "http://arxiv.org/pdf/2309.01762v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "05D40, O5C35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01736v2",
            "title": "Understanding and Optimizing Serverless Workloads in CXL-Enabled Tiered\n  Memory",
            "updated": "2023-09-22T18:08:05Z",
            "published": "2023-09-04T17:40:03Z",
            "summary": "Recent Serverless workloads tend to be largescaled/CPU-memory intensive, such\nas DL, graph applications, that require dynamic memory-to-compute resources\nprovisioning.\n  Meanwhile, recent solutions seek to design page management strategies for\nmulti-tiered memory systems, to efficiently run heavy workloads. Compute\nExpress Link (CXL) is an ideal platform for serverless workloads runtime that\noffers a holistic memory namespace thanks to its cache coherent feature and\nlarge memory capacity. However, naively offloading Serverless applications to\nCXL brings substantial latencies.\n  In this work, we first quantify CXL impacts on various Serverless\napplications. Second, we argue the opportunity of provisioning DRAM and CXL in\na fine-grained, application-specific manner to Serverless workloads, by\ncreating a shim layer to identify, and naively place hot regions to DRAM, while\nleaving cold/warm regions to CXL. Based on the observation, we finally propose\nthe prototype of Porter, a middleware in-between modern Serverless architecture\nand CXL-enabled tiered memory system, to efficiently utilize memory resources,\nwhile saving costs.",
            "author": [
                "Yuze Li",
                "Shunyu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01736v2",
                "http://arxiv.org/pdf/2309.01736v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01731v1",
            "title": "Intranasal Chemosensory Lateralization Through the Multi-electrode\n  Transcutaneous Electrical Nasal Bridge Stimulation",
            "updated": "2023-09-04T17:33:03Z",
            "published": "2023-09-04T17:33:03Z",
            "summary": "Numerous studies have been conducted on display techniques for intranasal\nchemosensory perception. However, a limited number of studies have focused on\nthe presentation of sensory spatial information. To artificially produce\nintranasal chemosensory spatial perception, we focused on a technique to induce\nintranasal chemosensation by transcutaneous electrical stimulation between the\nnasal bridge and the back of the neck. Whether this technique stimulates the\ntrigeminal nerve or the olfactory nerve remains debatable; if this method\nstimulates the trigeminal nerve, the differences in the amount of stimulation\nto the left and right trigeminal branches would evoke lateralization of\nintranasal chemosensory perception. Therefore, we propose a novel method to\nlateralize intranasal chemosensation by selectively stimulating the left or\nright trigeminal nerve branches through the shifting of an electrode on the\nnasal bridge to the left or right. Finite element simulations reveal that\nelectrical stimulation applied between the electrodes on the left/right nasal\nbridge and the back of the neck results in the construction of a high current\ndensity area on the left/right branch of the trigeminal nerve. The results of\ntwo psychophysical experiments reveal that intranasal chemosensation can be\nlateralized by using the proposed method. The results of our experiment also\nsuggest that lateralization is not the result of electrically induced tactile\nsensation of the skin surface but rather due to the distribution of stimuli to\nthe trigeminal nerves. To the best of our knowledge, this study is the first\nsuccessful lateralization of intranasal chemosensation that utilizes an\neasy-to-apply method without involving nostril blocking.",
            "author": [
                "Ayari Matsui",
                "Tomohiro Amemiya",
                "Takuji Narumi",
                "Kazuma Aoyama"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01731v1",
                "http://arxiv.org/pdf/2309.01731v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01730v1",
            "title": "Adaptive Resource Allocation for Virtualized Base Stations in O-RAN with\n  Online Learning",
            "updated": "2023-09-04T17:30:21Z",
            "published": "2023-09-04T17:30:21Z",
            "summary": "Open Radio Access Network systems, with their virtualized base stations\n(vBSs), offer operators the benefits of increased flexibility, reduced costs,\nvendor diversity, and interoperability. Optimizing the allocation of resources\nin a vBS is challenging since it requires knowledge of the environment, (i.e.,\n\"external'' information), such as traffic demands and channel quality, which is\ndifficult to acquire precisely over short intervals of a few seconds. To tackle\nthis problem, we propose an online learning algorithm that balances the\neffective throughput and vBS energy consumption, even under unforeseeable and\n\"challenging'' environments; for instance, non-stationary or adversarial\ntraffic demands. We also develop a meta-learning scheme, which leverages the\npower of other algorithmic approaches, tailored for more \"easy'' environments,\nand dynamically chooses the best performing one, thus enhancing the overall\nsystem's versatility and effectiveness. We prove the proposed solutions achieve\nsub-linear regret, providing zero average optimality gap even in challenging\nenvironments. The performance of the algorithms is evaluated with real-world\ndata and various trace-driven evaluations, indicating savings of up to 64.5% in\nthe power consumption of a vBS compared with state-of-the-art benchmarks.",
            "author": [
                "Michail Kalntis",
                "George Iosifidis",
                "Fernando A. Kuipers"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01730v1",
                "http://arxiv.org/pdf/2309.01730v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01717v2",
            "title": "Interdisciplinary Fairness in Imbalanced Research Proposal Topic\n  Inference: A Hierarchical Transformer-based Method with Selective\n  Interpolation",
            "updated": "2023-09-11T01:33:47Z",
            "published": "2023-09-04T16:54:49Z",
            "summary": "The objective of topic inference in research proposals aims to obtain the\nmost suitable disciplinary division from the discipline system defined by a\nfunding agency. The agency will subsequently find appropriate peer review\nexperts from their database based on this division. Automated topic inference\ncan reduce human errors caused by manual topic filling, bridge the knowledge\ngap between funding agencies and project applicants, and improve system\nefficiency. Existing methods focus on modeling this as a hierarchical\nmulti-label classification problem, using generative models to iteratively\ninfer the most appropriate topic information. However, these methods overlook\nthe gap in scale between interdisciplinary research proposals and\nnon-interdisciplinary ones, leading to an unjust phenomenon where the automated\ninference system categorizes interdisciplinary proposals as\nnon-interdisciplinary, causing unfairness during the expert assignment. How can\nwe address this data imbalance issue under a complex discipline system and\nhence resolve this unfairness? In this paper, we implement a topic label\ninference system based on a Transformer encoder-decoder architecture.\nFurthermore, we utilize interpolation techniques to create a series of\npseudo-interdisciplinary proposals from non-interdisciplinary ones during\ntraining based on non-parametric indicators such as cross-topic probabilities\nand topic occurrence probabilities. This approach aims to reduce the bias of\nthe system during model training. Finally, we conduct extensive experiments on\na real-world dataset to verify the effectiveness of the proposed method. The\nexperimental results demonstrate that our training strategy can significantly\nmitigate the unfairness generated in the topic inference task.",
            "author": [
                "Meng Xiao",
                "Min Wu",
                "Ziyue Qiao",
                "Yanjie Fu",
                "Zhiyuan Ning",
                "Yi Du",
                "Yuanchun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01717v2",
                "http://arxiv.org/pdf/2309.01717v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01706v2",
            "title": "On the Robustness of Post-hoc GNN Explainers to Label Noise",
            "updated": "2023-09-08T09:56:20Z",
            "published": "2023-09-04T16:35:04Z",
            "summary": "Proposed as a solution to the inherent black-box limitations of graph neural\nnetworks (GNNs), post-hoc GNN explainers aim to provide precise and insightful\nexplanations of the behaviours exhibited by trained GNNs. Despite their recent\nnotable advancements in academic and industrial contexts, the robustness of\npost-hoc GNN explainers remains unexplored when confronted with label noise. To\nbridge this gap, we conduct a systematic empirical investigation to evaluate\nthe efficacy of diverse post-hoc GNN explainers under varying degrees of label\nnoise. Our results reveal several key insights: Firstly, post-hoc GNN\nexplainers are susceptible to label perturbations. Secondly, even minor levels\nof label noise, inconsequential to GNN performance, harm the quality of\ngenerated explanations substantially. Lastly, we engage in a discourse\nregarding the progressive recovery of explanation effectiveness with escalating\nnoise levels.",
            "author": [
                "Zhiqiang Zhong",
                "Yangqianzi Jiang",
                "Davide Mottin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01706v2",
                "http://arxiv.org/pdf/2309.01706v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01682v1",
            "title": "Prior Knowledge Guided Network for Video Anomaly Detection",
            "updated": "2023-09-04T15:57:07Z",
            "published": "2023-09-04T15:57:07Z",
            "summary": "Video Anomaly Detection (VAD) involves detecting anomalous events in videos,\npresenting a significant and intricate task within intelligent video\nsurveillance. Existing studies often concentrate solely on features acquired\nfrom limited normal data, disregarding the latent prior knowledge present in\nextensive natural image datasets. To address this constraint, we propose a\nPrior Knowledge Guided Network(PKG-Net) for the VAD task. First, an\nauto-encoder network is incorporated into a teacher-student architecture to\nlearn two designated proxy tasks: future frame prediction and teacher network\nimitation, which can provide better generalization ability on unknown samples.\nSecond, knowledge distillation on proper feature blocks is also proposed to\nincrease the multi-scale detection ability of the model. In addition,\nprediction error and teacher-student feature inconsistency are combined to\nevaluate anomaly scores of inference samples more comprehensively. Experimental\nresults on three public benchmarks validate the effectiveness and accuracy of\nour method, which surpasses recent state-of-the-arts.",
            "author": [
                "Zhewen Deng",
                "Dongyue Chen",
                "Shizhuo Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01682v1",
                "http://arxiv.org/pdf/2309.01682v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01677v1",
            "title": "Ideals with componentwise linear powers",
            "updated": "2023-09-04T15:46:49Z",
            "published": "2023-09-04T15:46:49Z",
            "summary": "Let $S=K[x_1,\\ldots,x_n]$ be the polynomial ring over a field $K$, and let\n$A$ be a finitely generated standard graded $S$-algebra. We show that if the\ndefining ideal of $A$ has a quadratic initial ideal, then all the graded\ncomponents of $A$ are componentwise linear. Applying this result to the Rees\nring $\\mathcal{R}(I)$ of a graded ideal $I$ gives a criterion on $I$ to have\ncomponentwise linear powers. Moreover, for any given graph $G$, a construction\non $G$ is presented which produces graphs whose cover ideals $I_G$ have\ncomponentwise linear powers. This in particular implies that for any\nCohen-Macaulay Cameron-Walker graph $G$ all powers of $I_G$ have linear\nresolutions. Moreover, forming a cone on special graphs like unmixed chordal\ngraphs, path graphs and Cohen-Macaulay bipartite graphs produces cover ideals\nwith componentwise linear powers.",
            "author": [
                "Takayuki Hibi",
                "Somayeh Moradi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01677v1",
                "http://arxiv.org/pdf/2309.01677v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO",
                "13A02, 13P10, 05E40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01671v2",
            "title": "A Simple Pipeline for Orthogonal Graph Drawing",
            "updated": "2023-09-07T11:57:42Z",
            "published": "2023-09-04T15:35:23Z",
            "summary": "Orthogonal graph drawing has many applications, e.g., for laying out UML\ndiagrams or cableplans. In this paper, we present a new pipeline that draws\nmultigraphs orthogonally, using few bends, few crossings, and small area. Our\npipeline computes an initial graph layout, then removes overlaps between the\nrectangular nodes, routes the edges, orders the edges, and nudges them, that\nis, moves edge segments in order to balance the inter-edge distances. Our\npipeline is flexible and integrates well with existing approaches. Our main\ncontribution is (i) an effective edge-nudging algorithm that is based on linear\nprogramming, (ii) a selection of simple algorithms that together produce\ncompetitive results, and (iii) an extensive experimental comparison of our\npipeline with existing approaches using standard benchmark sets and metrics.",
            "author": [
                "Tim Hegemann",
                "Alexander Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01671v2",
                "http://arxiv.org/pdf/2309.01671v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01657v1",
            "title": "Locally Stationary Graph Processes",
            "updated": "2023-09-04T15:16:55Z",
            "published": "2023-09-04T15:16:55Z",
            "summary": "Stationary graph process models are commonly used in the analysis and\ninference of data sets collected on irregular network topologies. While most of\nthe existing methods represent graph signals with a single stationary process\nmodel that is globally valid on the entire graph, in many practical problems,\nthe characteristics of the process may be subject to local variations in\ndifferent regions of the graph. In this work, we propose a locally stationary\ngraph process (LSGP) model that aims to extend the classical concept of local\nstationarity to irregular graph domains. We characterize local stationarity by\nexpressing the overall process as the combination of a set of component\nprocesses such that the extent to which the process adheres to each component\nvaries smoothly over the graph. We propose an algorithm for computing LSGP\nmodels from realizations of the process, and also study the approximation of\nLSGPs locally with WSS processes. Experiments on signal interpolation problems\nshow that the proposed process model provides accurate signal representations\ncompetitive with the state of the art.",
            "author": [
                "Abdullah Canbolat",
                "Elif Vural"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01657v1",
                "http://arxiv.org/pdf/2309.01657v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01650v1",
            "title": "Response to \"The measurement postulates of quantum mechanics are not\n  redundant\"",
            "updated": "2023-09-04T15:03:50Z",
            "published": "2023-09-04T15:03:50Z",
            "summary": "Adrian Kent has recently presented a critique [arXiv:2307.06191] of our paper\n[Nat. Comms. 10, 1361 (2019)] in which he claims to refute our main result: the\nmeasurement postulates of quantum mechanics can be derived from the rest of\npostulates, once we assume that the set of mixed states of a finite-dimensional\nHilbert space is finite-dimensional. To construct his argument, Kent considers\ntheories resulting from supplementing quantum mechanics with hypothetical\n\"post-quantum\" measurement devices. We prove that each of these theories\ncontains pure states (i.e. states of maximal knowledge) which are not rays of\nthe Hilbert space, in contradiction with the \"pure state postulate\" of quantum\nmechanics. We also prove that these alternatives violate the\nfinite-dimensionality of mixed states. Each of these two facts separately\ninvalidates the refutation. In this note we also clarify the assumptions used\nin the above-cited paper and discuss the notions of pure state, physical\nsystem, and the sensitivity of the structure of the state space under\nmodifications of the measurements or the dynamics.",
            "author": [
                "Llu\u00eds Masanes",
                "Thomas D. Galley",
                "Markus P. M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01650v1",
                "http://arxiv.org/pdf/2309.01650v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01646v1",
            "title": "ReLoc-PDR: Visual Relocalization Enhanced Pedestrian Dead Reckoning via\n  Graph Optimization",
            "updated": "2023-09-04T14:54:47Z",
            "published": "2023-09-04T14:54:47Z",
            "summary": "Accurately and reliably positioning pedestrians in satellite-denied\nconditions remains a significant challenge. Pedestrian dead reckoning (PDR) is\ncommonly employed to estimate pedestrian location using low-cost inertial\nsensor. However, PDR is susceptible to drift due to sensor noise, incorrect\nstep detection, and inaccurate stride length estimation. This work proposes\nReLoc-PDR, a fusion framework combining PDR and visual relocalization using\ngraph optimization. ReLoc-PDR leverages time-correlated visual observations and\nlearned descriptors to achieve robust positioning in visually-degraded\nenvironments. A graph optimization-based fusion mechanism with the Tukey kernel\neffectively corrects cumulative errors and mitigates the impact of abnormal\nvisual observations. Real-world experiments demonstrate that our ReLoc-PDR\nsurpasses representative methods in accuracy and robustness, achieving accurte\nand robust pedestrian positioning results using only a smartphone in\nchallenging environments such as less-textured corridors and dark nighttime\nscenarios.",
            "author": [
                "Zongyang Chen",
                "Xianfei Pan",
                "Changhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01646v1",
                "http://arxiv.org/pdf/2309.01646v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01632v3",
            "title": "Representing Edge Flows on Graphs via Sparse Cell Complexes",
            "updated": "2023-11-02T08:26:48Z",
            "published": "2023-09-04T14:30:20Z",
            "summary": "Obtaining sparse, interpretable representations of observable data is crucial\nin many machine learning and signal processing tasks. For data representing\nflows along the edges of a graph, an intuitively interpretable way to obtain\nsuch representations is to lift the graph structure to a simplicial complex:\nThe eigenvectors of the associated Hodge-Laplacian, respectively the incidence\nmatrices of the corresponding simplicial complex then induce a Hodge\ndecomposition, which can be used to represent the observed data in terms of\ngradient, curl, and harmonic flows. In this paper, we generalize this approach\nto cellular complexes and introduce the flow representation learning problem,\ni.e., the problem of augmenting the observed graph by a set of cells, such that\nthe eigenvectors of the associated Hodge Laplacian provide a sparse,\ninterpretable representation of the observed edge flows on the graph. We show\nthat this problem is NP-hard and introduce an efficient approximation algorithm\nfor its solution. Experiments on real-world and synthetic data demonstrate that\nour algorithm outperforms state-of-the-art methods with respect to\napproximation error, while being computationally efficient.",
            "author": [
                "Josef Hoppe",
                "Michael T. Schaub"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01632v3",
                "http://arxiv.org/pdf/2309.01632v3"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01613v1",
            "title": "Stable configurations of entangled graphs and weaves with repulsive\n  interactions",
            "updated": "2023-09-04T13:53:28Z",
            "published": "2023-09-04T13:53:28Z",
            "summary": "Entangled objects such as entangled graphs and weaves are often seen in\nnature. In the present article, two identical graphs entangled, and weaves with\ntwo different color threads are studied. A method to identify stable\nconfigurations in the three dimensional space of a given topological entangled\nstructure, a planar graph with crossing information, is proposed by analyzing\nthe steepest descent flow of the energy functional with repulsive interactions.\nThe existence and uniqueness of a solution in the entangled case. In the\nuntangled case, a weave has a unique tangle decomposition with height order,\nwhose components are moving away each other in the order $t^{1/3}$ as time $t$\ngoes to the infinity.",
            "author": [
                "Motoko Kotani",
                "Hisashi Naito",
                "Eriko Shinkawa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01613v1",
                "http://arxiv.org/pdf/2309.01613v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01612v1",
            "title": "On the Query Strategies for Efficient Online Active Distillation",
            "updated": "2023-09-04T13:53:20Z",
            "published": "2023-09-04T13:53:20Z",
            "summary": "Deep Learning (DL) requires lots of time and data, resulting in high\ncomputational demands. Recently, researchers employ Active Learning (AL) and\nonline distillation to enhance training efficiency and real-time model\nadaptation. This paper evaluates a set of query strategies to achieve the best\ntraining results. It focuses on Human Pose Estimation (HPE) applications,\nassessing the impact of selected frames during training using two approaches: a\nclassical offline method and a online evaluation through a continual learning\napproach employing knowledge distillation, on a popular state-of-the-art HPE\ndataset. The paper demonstrates the possibility of enabling training at the\nedge lightweight models, adapting them effectively to new contexts in\nreal-time.",
            "author": [
                "Michele Boldo",
                "Enrico Martini",
                "Mirco De Marchi",
                "Stefano Aldegheri",
                "Nicola Bombieri"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01612v1",
                "http://arxiv.org/pdf/2309.01612v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03358v1",
            "title": "Towards Understanding and Analyzing Rationale in Commit Messages using a\n  Knowledge Graph Approach",
            "updated": "2023-09-04T13:28:18Z",
            "published": "2023-09-04T13:28:18Z",
            "summary": "Extracting rationale information from commit messages allows developers to\nbetter understand a system and its past development. Here we present our\nongoing work on the Kantara end-to-end rationale reconstruction pipeline to a)\nstructure rationale information in an ontologically-based knowledge graph, b)\nextract and classify this information from commits, and c) produce analysis\nreports and visualizations for developers. We also present our work on creating\na labelled dataset for our running example of the Out-of-Memory component of\nthe Linux kernel. This dataset is used as ground truth for our evaluation of\nNLP classification techniques which show promising results, especially the\nmulti-classification technique XGBoost.",
            "author": [
                "Mouna Dhaouadi",
                "Bentley James Oakes",
                "Michalis Famelis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03358v1",
                "http://arxiv.org/pdf/2311.03358v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01593v1",
            "title": "Deep Learning Overloaded Vehicle Identification for Long Span Bridges\n  Based on Structural Health Monitoring Data",
            "updated": "2023-09-04T13:24:54Z",
            "published": "2023-09-04T13:24:54Z",
            "summary": "Overloaded vehicles bring great harm to transportation infrastructures. BWIM\n(bridge weigh-in-motion) method for overloaded vehicle identification is\ngetting more popular because it can be implemented without interruption to the\ntraffic. However, its application is still limited because its effectiveness\nlargely depends on professional knowledge and extra information, and is\nsusceptible to occurrence of multiple vehicles. In this paper, a deep learning\nbased overloaded vehicle identification approach (DOVI) is proposed, with the\npurpose of overloaded vehicle identification for long-span bridges by the use\nof structural health monitoring data. The proposed DOVI model uses temporal\nconvolutional architectures to extract the spatial and temporal features of the\ninput sequence data, thus provides an end-to-end overloaded vehicle\nidentification solution which neither needs the influence line nor needs to\nobtain velocity and wheelbase information in advance and can be applied under\nthe occurrence of multiple vehicles. Model evaluations are conducted on a\nsimply supported beam and a long-span cable-stayed bridge under random traffic\nflow. Results demonstrate that the proposed deep-learning overloaded vehicle\nidentification approach has better effectiveness and robustness, compared with\nother machine learning and deep learning approaches.",
            "author": [
                "Yuqin Li",
                "Jun Liu",
                "Shengliang Zhong",
                "Licheng Zhou",
                "Shoubin Dong",
                "Zejia Liu",
                "Liqun Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01593v1",
                "http://arxiv.org/pdf/2309.01593v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01583v2",
            "title": "On graphs with maximum difference between game chromatic number and\n  chromatic number",
            "updated": "2023-09-21T13:04:48Z",
            "published": "2023-09-04T13:12:33Z",
            "summary": "In the vertex colouring game on a graph $G$, Maker and Breaker alternately\ncolour vertices of $G$ from a palette of $k$ colours, with no two adjacent\nvertices allowed the same colour. Maker seeks to colour the whole graph while\nBreaker seeks to make some vertex impossible to colour. The game chromatic\nnumber of $G$, $\\chi_g(G)$, is the minimal number $k$ of colours for which\nMaker has a winning strategy for the vertex colouring game.\n  Matsumoto proved in 2019 that $\\chi_g(G)-\\chi(G)\\leq\\lfloor n/2\\rfloor - 1$,\nand conjectured that the only equality cases are some graphs of small order and\nthe Tur\\'{a}n graph $T(2r,r)$ (i.e. $K_{2r}$ minus a perfect matching). We\nresolve this conjecture in the affirmative by considering a modification of the\nvertex colouring game wherein Breaker may remove a vertex instead of colouring\nit.\n  Matsumoto further asked whether a similar result could be proved for the\nvertex marking game, and we provide an example to show that no such nontrivial\nresult can exist.",
            "author": [
                "Lawrence Hollom"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01583v2",
                "http://arxiv.org/pdf/2309.01583v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C57"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01576v1",
            "title": "A Comparative Analysis of Pretrained Language Models for Text-to-Speech",
            "updated": "2023-09-04T13:02:27Z",
            "published": "2023-09-04T13:02:27Z",
            "summary": "State-of-the-art text-to-speech (TTS) systems have utilized pretrained\nlanguage models (PLMs) to enhance prosody and create more natural-sounding\nspeech. However, while PLMs have been extensively researched for natural\nlanguage understanding (NLU), their impact on TTS has been overlooked. In this\nstudy, we aim to address this gap by conducting a comparative analysis of\ndifferent PLMs for two TTS tasks: prosody prediction and pause prediction.\nFirstly, we trained a prosody prediction model using 15 different PLMs. Our\nfindings revealed a logarithmic relationship between model size and quality, as\nwell as significant performance differences between neutral and expressive\nprosody. Secondly, we employed PLMs for pause prediction and found that the\ntask was less sensitive to small models. We also identified a strong\ncorrelation between our empirical results and the GLUE scores obtained for\nthese language models. To the best of our knowledge, this is the first study of\nits kind to investigate the impact of different PLMs on TTS.",
            "author": [
                "Marcel Granero-Moya",
                "Penny Karanasou",
                "Sri Karlapati",
                "Bastian Schnell",
                "Nicole Peinelt",
                "Alexis Moinet",
                "Thomas Drugman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01576v1",
                "http://arxiv.org/pdf/2309.01576v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01565v1",
            "title": "Introducing the $\u03c3$-Cell: Unifying GARCH, Stochastic Fluctuations\n  and Evolving Mechanisms in RNN-based Volatility Forecasting",
            "updated": "2023-09-04T12:40:35Z",
            "published": "2023-09-04T12:40:35Z",
            "summary": "This paper introduces the $\\sigma$-Cell, a novel Recurrent Neural Network\n(RNN) architecture for financial volatility modeling. Bridging traditional\neconometric approaches like GARCH with deep learning, the $\\sigma$-Cell\nincorporates stochastic layers and time-varying parameters to capture dynamic\nvolatility patterns. Our model serves as a generative network, approximating\nthe conditional distribution of latent variables. We employ a\nlog-likelihood-based loss function and a specialized activation function to\nenhance performance. Experimental results demonstrate superior forecasting\naccuracy compared to traditional GARCH and Stochastic Volatility models, making\nthe next step in integrating domain knowledge with neural networks.",
            "author": [
                "German Rodikov",
                "Nino Antulov-Fantulin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01565v1",
                "http://arxiv.org/pdf/2309.01565v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01542v1",
            "title": "Hyperfine collisional excitation of ammonia by molecular hydrogen",
            "updated": "2023-09-04T11:52:49Z",
            "published": "2023-09-04T11:52:49Z",
            "summary": "Ammonia is one of the most widely observed molecules in space, and many\nobservations are able to resolve the hyperfine structure due to the electric\nquadrupole moment of the nitrogen nucleus. The observed spectra often display\nanomalies in the satellite components of the lines, which indicate substantial\ndeviations from the local thermodynamic equilibrium. The interpretation of the\nspectra thus requires the knowledge of the rate coefficients for the hyperfine\nexcitation of NH$_3$ induced by collisions with H$_2$ molecules, the dominant\ncollider in the cold interstellar medium. In this paper we present the first\nsuch calculations using a recoupling approach. The rate coefficients are\nobtained for all hyperfine levels within rotation-inversion levels up to $j=4$\nand temperatures up to 100 K by means of quantum scattering close-coupling\ncalculations on an accurate, five-dimensional, potential energy surface. We\nshow that the rate coefficients depart significantly from those obtained with\nthe statistical approach and that they do not conform to any simple propensity\nrules. Finally, we perform radiative transfer calculations to illustrate the\nimpact of our new rate coefficients by modelling the hyperfine line intensities\nof the inversion transition in ground state para-NH$_3$ ($j_k=1_1$) and of the\nrotational transition $1_0\\rightarrow 0_0$ in ortho-NH$_3$.",
            "author": [
                "J. Loreau",
                "A. Faure",
                "F. Lique",
                "S. Demes",
                "P. J. Dagdigian"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01542v1",
                "http://arxiv.org/pdf/2309.01542v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01538v2",
            "title": "ChatRule: Mining Logical Rules with Large Language Models for Knowledge\n  Graph Reasoning",
            "updated": "2023-09-13T13:00:23Z",
            "published": "2023-09-04T11:38:02Z",
            "summary": "Logical rules are essential for uncovering the logical connections between\nrelations, which could improve the reasoning performance and provide\ninterpretable results on knowledge graphs (KGs). Although there have been many\nefforts to mine meaningful logical rules over KGs, existing methods suffer from\nthe computationally intensive searches over the rule space and a lack of\nscalability for large-scale KGs. Besides, they often ignore the semantics of\nrelations which is crucial for uncovering logical connections. Recently, large\nlanguage models (LLMs) have shown impressive performance in the field of\nnatural language processing and various applications, owing to their emergent\nability and generalizability. In this paper, we propose a novel framework,\nChatRule, unleashing the power of large language models for mining logical\nrules over knowledge graphs. Specifically, the framework is initiated with an\nLLM-based rule generator, leveraging both the semantic and structural\ninformation of KGs to prompt LLMs to generate logical rules. To refine the\ngenerated rules, a rule ranking module estimates the rule quality by\nincorporating facts from existing KGs. Last, a rule validator harnesses the\nreasoning ability of LLMs to validate the logical correctness of ranked rules\nthrough chain-of-thought reasoning. ChatRule is evaluated on four large-scale\nKGs, w.r.t. different rule quality metrics and downstream tasks, showing the\neffectiveness and scalability of our method.",
            "author": [
                "Linhao Luo",
                "Jiaxin Ju",
                "Bo Xiong",
                "Yuan-Fang Li",
                "Gholamreza Haffari",
                "Shirui Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01538v2",
                "http://arxiv.org/pdf/2309.01538v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03104v1",
            "title": "Quid Manumit -- Freeing the Qubit for Art",
            "updated": "2023-09-04T11:19:51Z",
            "published": "2023-09-04T11:19:51Z",
            "summary": "This paper describes how to `Free the Qubit' for art, by creating standalone\nquantum musical effects and instruments. Previously released quantum simulator\ncode for an ARM-based Raspberry Pi Pico embedded microcontroller is utilised\nhere, and several examples are built demonstrating different methods of\nutilising embedded resources: The first is a Quantum MIDI processor that\ngenerates additional notes for accompaniment and unique quantum generated\ninstruments based on the input notes, decoded and passed through a quantum\ncircuit in an embedded simulator. The second is a Quantum Distortion module\nthat changes an instrument's raw sound according to a quantum circuit, which is\npresented in two forms; a self-contained Quantum Stylophone, and an effect\nmodule plugin called 'QubitCrusher' for the Korg Nu:Tekt NTS-1. This paper also\ndiscusses future work and directions for quantum instruments, and provides all\nexamples as open source. This is, to the author's knowledge, the first example\nof embedded Quantum Simulators for Instruments of Music (another QSIM).",
            "author": [
                "Mark Carney"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.10206737",
                "http://arxiv.org/abs/2309.03104v1",
                "http://arxiv.org/pdf/2309.03104v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET",
                "cs.HC",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01516v2",
            "title": "MultiWay-Adapater: Adapting large-scale multi-modal models for scalable\n  image-text retrieval",
            "updated": "2023-09-12T20:16:04Z",
            "published": "2023-09-04T10:48:29Z",
            "summary": "As the size of Large Multi-Modal Models (LMMs) increases consistently, the\nadaptation of these pre-trained models to specialized tasks has become a\ncomputationally and memory-intensive challenge. Traditional fine-tuning methods\nrequire isolated, exhaustive retuning for each new task, limiting the models'\nversatility. Moreover, current efficient adaptation techniques often overlook\nmodality alignment, focusing only on the knowledge extraction of new tasks. To\ntackle these issues, we introduce Multiway-Adapter, an innovative framework\nincorporating an 'Alignment Enhancer' to deepen modality alignment, enabling\nhigh transferability without tuning pre-trained parameters. Our method adds\nfewer than 1.25\\% of additional parameters to LMMs, exemplified by the BEiT-3\nmodel in our study. This leads to superior zero-shot image-text retrieval\nperformance compared to fully fine-tuned models, while achieving up to a 57\\%\nreduction in fine-tuning time. Our approach offers a resource-efficient and\neffective adaptation pathway for LMMs, broadening their applicability. The\nsource code is publicly available at:\n\\url{https://github.com/longkukuhi/MultiWay-Adapter}.",
            "author": [
                "Zijun Long",
                "George Killick",
                "Richard McCreadie",
                "Gerardo Aragon Camarasa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01516v2",
                "http://arxiv.org/pdf/2309.01516v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01513v1",
            "title": "RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the\n  Absence of First-order Echoes",
            "updated": "2023-09-04T10:45:53Z",
            "published": "2023-09-04T10:45:53Z",
            "summary": "Room geometry is important prior information for implementing realistic 3D\naudio rendering. For this reason, various room geometry inference (RGI) methods\nhave been developed by utilizing the time of arrival (TOA) or time difference\nof arrival (TDOA) information in room impulse responses. However, the\nconventional RGI technique poses several assumptions, such as convex room\nshapes, the number of walls known in priori, and the visibility of first-order\nreflections. In this work, we introduce the deep neural network (DNN), RGI-Net,\nwhich can estimate room geometries without the aforementioned assumptions.\nRGI-Net learns and exploits complex relationships between high-order\nreflections in room impulse responses (RIRs) and, thus, can estimate room\nshapes even when the shape is non-convex or first-order reflections are missing\nin the RIRs. The network takes RIRs measured from a compact audio device\nequipped with a circular microphone array and a single loudspeaker, which\ngreatly improves its practical applicability. RGI-Net includes the evaluation\nnetwork that separately evaluates the presence probability of walls, so the\ngeometry inference is possible without prior knowledge of the number of walls.",
            "author": [
                "Inmo Yeon",
                "Jung-Woo Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01513v1",
                "http://arxiv.org/pdf/2309.01513v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01504v1",
            "title": "Construction of perfect tensors using biunimodular vectors",
            "updated": "2023-09-04T10:24:09Z",
            "published": "2023-09-04T10:24:09Z",
            "summary": "Dual unitary gates are highly non-local two-qudit unitary gates that have\nbeen studied extensively in quantum many-body physics and quantum information\nin the recent past. A special subset of dual unitary gates consists of\nrank-four perfect tensors, which are equivalent to highly entangled\nmultipartite pure states called absolutely maximally entangled (AME) states. In\nthis work, numerical and analytical constructions of dual unitary gates and\nperfect tensors that are diagonal in a special maximally entangled basis are\npresented. The main ingredient in our construction is a phase-valued\n(unimodular) two-dimensional array whose discrete Fourier transform is also\nunimodular. We obtain perfect tensors for several local Hilbert space\ndimensions, particularly, in dimension six. A perfect tensor in local dimension\nsix is equivalent to an AME state of four qudits, denoted as AME(4,6), and such\na state cannot be constructed from existing constructions of AME states based\non error-correcting codes and graph states. The existence of AME(4,6) states\nfeatured in well-known open problem lists in quantum information, and was\nsettled positively in Phys. Rev. Lett. 128 080507 (2022). We provide an\nexplicit construction of perfect tensors in local dimension six that can be\nwritten in terms of controlled unitary gates in the computational basis, making\nthem amenable for quantum circuit implementations.",
            "author": [
                "Suhail Ahmad Rather"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01504v1",
                "http://arxiv.org/pdf/2309.01504v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01503v1",
            "title": "Layer-wise training for self-supervised learning on graphs",
            "updated": "2023-09-04T10:23:39Z",
            "published": "2023-09-04T10:23:39Z",
            "summary": "End-to-end training of graph neural networks (GNN) on large graphs presents\nseveral memory and computational challenges, and limits the application to\nshallow architectures as depth exponentially increases the memory and space\ncomplexities. In this manuscript, we propose Layer-wise Regularized Graph\nInfomax, an algorithm to train GNNs layer by layer in a self-supervised manner.\nWe decouple the feature propagation and feature transformation carried out by\nGNNs to learn node representations in order to derive a loss function based on\nthe prediction of future inputs. We evaluate the algorithm in inductive large\ngraphs and show similar performance to other end to end methods and a\nsubstantially increased efficiency, which enables the training of more\nsophisticated models in one single device. We also show that our algorithm\navoids the oversmoothing of the representations, another common challenge of\ndeep GNNs.",
            "author": [
                "Oscar Pina",
                "Ver\u00f3nica Vilaplana"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01503v1",
                "http://arxiv.org/pdf/2309.01503v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01491v1",
            "title": "Intermittency as a consequence of a stationarity constraint on the\n  energy flux",
            "updated": "2023-09-04T09:53:30Z",
            "published": "2023-09-04T09:53:30Z",
            "summary": "In his seminal work on turbulence, Kolmogorov made use of the stationary\nhypothesis to determine the Power Density Spectrum of the velocity field in\nturbulent flows. However to our knowledge, the constraints that stationary\nprocesses impose on the fluctuations of the energy flux have never been used in\nthe context of turbulence. Here we recall that the Power Density Spectra of the\nfluctuations of the injected power, the dissipated power and the energy flux\nhave to converge to a common value at vanishing frequency. Hence, we show that\nthe intermittent GOY--shell model fulfills these constraints. We argue that\nthey can be related to intermittency. Indeed, we find that the constraint on\nthe fluctuations of the energy flux implies a relation between the scaling\nexponents that characterize intermittency, which is verified by the GOY--shell\nmodel and in agreement with the She-Leveque formula. It also fixes the\nintermittency parameter of the log-normal model at a realistic value. The\nrelevance of these results for real turbulence is drawn in the concluding\nremarks.",
            "author": [
                "S\u00e9bastien Auma\u00eetre",
                "St\u00e9phan Fauve"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01491v1",
                "http://arxiv.org/pdf/2309.01491v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01482v2",
            "title": "Thick Forests",
            "updated": "2023-10-25T21:37:15Z",
            "published": "2023-09-04T09:36:51Z",
            "summary": "We consider classes of graphs, which we call thick graphs, that have their\nvertices replaced by cliques and their edges replaced by bipartite graphs. In\nparticular, we consider the case of thick forests, which are a subclass of\nperfect graphs. We show that this class can be recognised in polynomial time,\nand examine the complexity of counting independent sets and colourings for\ngraphs in the class. We consider some extensions of our results to thick graphs\nbeyond thick forests.",
            "author": [
                "Martin Dyer",
                "Haiko M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01482v2",
                "http://arxiv.org/pdf/2309.01482v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C85, 68R10",
                "F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01473v1",
            "title": "Twisted Equivariant Gromov-Witten Theory of the Classifying Space of a\n  Finite Group",
            "updated": "2023-09-04T09:30:16Z",
            "published": "2023-09-04T09:30:16Z",
            "summary": "For any finite group $G$, the equivariant Gromov-Witten invariants of\n$[\\mathbb{C}^r/G]$ can be viewed as a certain twisted Gromov-Witten invariants\nof the classifying stack $\\mathcal{B} G$. In this paper, we use Tseng's\norbifold quantum Riemann-Roch theorem to express the equivariant Gromov-Witten\ninvariants of $[\\mathbb{C}^r/G]$ as a sum over Feynman graphs, where the weight\nof each graph is expressed in terms of descendant integrals over moduli spaces\nof stable curves and representations of $G$.",
            "author": [
                "Zhuoming Lan",
                "Zhengyu Zong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01473v1",
                "http://arxiv.org/pdf/2309.01473v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01468v2",
            "title": "Surprising occurrences of order structures in mathematics",
            "updated": "2023-09-23T06:27:03Z",
            "published": "2023-09-04T09:25:53Z",
            "summary": "Order and symmetry are main structural principles in mathematics. We give\nfive examples where on the face of it order is not apparent, but deeper\ninvestigations reveal that they are governed by order structures. These\nexamples are finite topologies, associative algebras, subgroups of matrix\ngroups, ideals in polynomial rings, and classes of bipartite graphs.",
            "author": [
                "Gunnar Fl\u00f8ystad"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01468v2",
                "http://arxiv.org/pdf/2309.01468v2"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "math.AC",
                "math.CO",
                "math.CT",
                "math.RA",
                "Primary: 06-02, Secondary: 06A06, 13F55, 13F20, 16G99, 20G07, 54A99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01463v1",
            "title": "Mutual Witness Proximity Drawings of Isomorphic Trees",
            "updated": "2023-09-04T09:19:06Z",
            "published": "2023-09-04T09:19:06Z",
            "summary": "A pair $\\langle G_0, G_1 \\rangle$ of graphs admits a mutual witness proximity\ndrawing $\\langle \\Gamma_0, \\Gamma_1 \\rangle$ when: (i) $\\Gamma_i$ represents\n$G_i$, and (ii) there is an edge $(u,v)$ in $\\Gamma_i$ if and only if there is\nno vertex $w$ in $\\Gamma_{1-i}$ that is ``too close'' to both $u$ and $v$\n($i=0,1$). In this paper, we consider infinitely many definitions of closeness\nby adopting the $\\beta$-proximity rule for any $\\beta \\in [1,\\infty]$ and study\npairs of isomorphic trees that admit a mutual witness $\\beta$-proximity\ndrawing. Specifically, we show that every two isomorphic trees admit a mutual\nwitness $\\beta$-proximity drawing for any $\\beta \\in [1,\\infty]$. The\nconstructive technique can be made ``robust'': For some tree pairs we can\nsuitably prune linearly many leaves from one of the two trees and still retain\ntheir mutual witness $\\beta$-proximity drawability. Notably, in the special\ncase of isomorphic caterpillars and $\\beta=1$, we construct linearly separable\nmutual witness Gabriel drawings.",
            "author": [
                "Carolina Haase",
                "Philipp Kindermann",
                "William J. Lenhart",
                "Giuseppe Liotta"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01463v1",
                "http://arxiv.org/pdf/2309.01463v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01453v1",
            "title": "Interactive Graph Convolutional Filtering",
            "updated": "2023-09-04T09:02:31Z",
            "published": "2023-09-04T09:02:31Z",
            "summary": "Interactive Recommender Systems (IRS) have been increasingly used in various\ndomains, including personalized article recommendation, social media, and\nonline advertising. However, IRS faces significant challenges in providing\naccurate recommendations under limited observations, especially in the context\nof interactive collaborative filtering. These problems are exacerbated by the\ncold start problem and data sparsity problem. Existing Multi-Armed Bandit\nmethods, despite their carefully designed exploration strategies, often\nstruggle to provide satisfactory results in the early stages due to the lack of\ninteraction data. Furthermore, these methods are computationally intractable\nwhen applied to non-linear models, limiting their applicability. To address\nthese challenges, we propose a novel method, the Interactive Graph\nConvolutional Filtering model. Our proposed method extends interactive\ncollaborative filtering into the graph model to enhance the performance of\ncollaborative filtering between users and items. We incorporate variational\ninference techniques to overcome the computational hurdles posed by non-linear\nmodels. Furthermore, we employ Bayesian meta-learning methods to effectively\naddress the cold-start problem and derive theoretical regret bounds for our\nproposed method, ensuring a robust performance guarantee. Extensive\nexperimental results on three real-world datasets validate our method and\ndemonstrate its superiority over existing baselines.",
            "author": [
                "Jin Zhang",
                "Defu Lian",
                "Hong Xie",
                "Yawen Li",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01453v1",
                "http://arxiv.org/pdf/2309.01453v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.02460v2",
            "title": "Effective Multi-Graph Neural Networks for Illicit Account Detection on\n  Cryptocurrency Transaction Networks",
            "updated": "2023-10-28T07:26:14Z",
            "published": "2023-09-04T09:01:56Z",
            "summary": "We study illicit account detection on transaction networks of\ncryptocurrencies that are increasi_testngly important in online financial\nmarkets. The surge of illicit activities on cryptocurrencies has resulted in\nbillions of losses from normal users. Existing solutions either rely on tedious\nfeature engineering to get handcrafted features, or are inadequate to fully\nutilize the rich semantics of cryptocurrency transaction data, and\nconsequently, yield sub-optimal performance. In this paper, we formulate the\nillicit account detection problem as a classification task over directed\nmultigraphs with edge attributes, and present DIAM, a novel multi-graph neural\nnetwork model to effectively detect illicit accounts on large transaction\nnetworks. First, DIAM includes an Edge2Seq module that automatically learns\neffective node representations preserving intrinsic transaction patterns of\nparallel edges, by considering both edge attributes and directed edge sequence\ndependencies. Then utilizing the multigraph topology, DIAM employs a new\nMultigraph Discrepancy (MGD) module with a well-designed message passing\nmechanism to capture the discrepant features between normal and illicit nodes,\nsupported by an attention mechanism. Assembling all techniques, DIAM is trained\nin an end-to-end manner. Extensive experiments, comparing against 14 existing\nsolutions on 4 large cryptocurrency datasets of Bitcoin and Ethereum,\ndemonstrate that DIAM consistently achieves the best performance to accurately\ndetect illicit accounts, while being efficient. For instance, on a Bitcoin\ndataset with 20 million nodes and 203 million edges, DIAM achieves F1 score\n96.55%, significantly higher than the F1 score 83.92% of the best competitor.\nThe code is available at https://github.com/TommyDzh/DIAM.",
            "author": [
                "Zhihao Ding",
                "Jieming Shi",
                "Qing Li",
                "Jiannong Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.02460v2",
                "http://arxiv.org/pdf/2309.02460v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01449v3",
            "title": "Knowledge and ignorance in Belnap--Dunn logic",
            "updated": "2023-11-05T14:32:47Z",
            "published": "2023-09-04T09:00:32Z",
            "summary": "In this paper, we argue that the usual approach to modelling knowledge and\nbelief with the necessity modality $\\Box$ does not produce intuitive outcomes\nin the framework of the Belnap--Dunn logic ($\\mathsf{BD}$, alias $\\mathsf{FDE}$\n-- first-degree entailment). We then motivate and introduce a non\\-standard\nmodality $\\blacksquare$ that formalises knowledge and belief in $\\mathsf{BD}$\nand use $\\blacksquare$ to define $\\bullet$ and $\\blacktriangledown$ that\nformalise the \\emph{unknown truth} and ignorance as \\emph{not knowing whether},\nrespectively. Moreover, we introduce another modality $\\mathbf{I}$ that stands\nfor \\emph{factive ignorance} and show its connection with $\\blacksquare$.\n  We equip these modalities with Kripke-frame-based semantics and construct a\nsound and complete analytic cut system for $\\mathsf{BD}^\\blacksquare$ and\n$\\mathsf{BD}^\\mathbf{I}$ -- the expansions of $\\mathsf{BD}$ with $\\blacksquare$\nand $\\mathbf{I}$. In addition, we show that $\\Box$ as it is customarily defined\nin $\\mathsf{BD}$ cannot define any of the introduced modalities, nor,\nconversely, neither $\\blacksquare$ nor $\\mathbf{I}$ can define $\\Box$. We also\ndemonstrate that $\\blacksquare$ and $\\mathbf{I}$ are not interdefinable and\nestablish the definability of several important classes of frames using\n$\\blacksquare$.",
            "author": [
                "Daniil Kozhemiachenko",
                "Liubov Vashentseva"
            ],
            "link": [
                "http://dx.doi.org/10.1093/jigpal/jzad027",
                "http://arxiv.org/abs/2309.01449v3",
                "http://arxiv.org/pdf/2309.01449v3"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01446v3",
            "title": "Open Sesame! Universal Black Box Jailbreaking of Large Language Models",
            "updated": "2023-11-21T14:02:33Z",
            "published": "2023-09-04T08:54:20Z",
            "summary": "Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.",
            "author": [
                "Raz Lapid",
                "Ron Langberg",
                "Moshe Sipper"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01446v3",
                "http://arxiv.org/pdf/2309.01446v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01437v2",
            "title": "SememeASR: Boosting Performance of End-to-End Speech Recognition against\n  Domain and Long-Tailed Data Shift with Sememe Semantic Knowledge",
            "updated": "2023-10-07T04:30:26Z",
            "published": "2023-09-04T08:35:05Z",
            "summary": "Recently, excellent progress has been made in speech recognition. However,\npure data-driven approaches have struggled to solve the problem in\ndomain-mismatch and long-tailed data. Considering that knowledge-driven\napproaches can help data-driven approaches alleviate their flaws, we introduce\nsememe-based semantic knowledge information to speech recognition (SememeASR).\nSememe, according to the linguistic definition, is the minimum semantic unit in\na language and is able to represent the implicit semantic information behind\neach word very well. Our experiments show that the introduction of sememe\ninformation can improve the effectiveness of speech recognition. In addition,\nour further experiments show that sememe knowledge can improve the model's\nrecognition of long-tailed data and enhance the model's domain generalization\nability.",
            "author": [
                "Jiaxu Zhu",
                "Changhe Song",
                "Zhiyong Wu",
                "Helen Meng"
            ],
            "link": [
                "http://dx.doi.org/10.21437/Interspeech.2023-1432",
                "http://arxiv.org/abs/2309.01437v2",
                "http://arxiv.org/pdf/2309.01437v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01429v3",
            "title": "Adapting Segment Anything Model for Change Detection in HR Remote\n  Sensing Images",
            "updated": "2023-10-16T00:45:46Z",
            "published": "2023-09-04T08:23:31Z",
            "summary": "Vision Foundation Models (VFMs) such as the Segment Anything Model (SAM)\nallow zero-shot or interactive segmentation of visual contents, thus they are\nquickly applied in a variety of visual scenes. However, their direct use in\nmany Remote Sensing (RS) applications is often unsatisfactory due to the\nspecial imaging characteristics of RS images. In this work, we aim to utilize\nthe strong visual recognition capabilities of VFMs to improve the change\ndetection of high-resolution Remote Sensing Images (RSIs). We employ the visual\nencoder of FastSAM, an efficient variant of the SAM, to extract visual\nrepresentations in RS scenes. To adapt FastSAM to focus on some specific ground\nobjects in the RS scenes, we propose a convolutional adaptor to aggregate the\ntask-oriented change information. Moreover, to utilize the semantic\nrepresentations that are inherent to SAM features, we introduce a task-agnostic\nsemantic learning branch to model the semantic latent in bi-temporal RSIs. The\nresulting method, SAMCD, obtains superior accuracy compared to the SOTA methods\nand exhibits a sample-efficient learning ability that is comparable to\nsemi-supervised CD methods. To the best of our knowledge, this is the first\nwork that adapts VFMs for the CD of HR RSIs.",
            "author": [
                "Lei Ding",
                "Kun Zhu",
                "Daifeng Peng",
                "Hao Tang",
                "Kuiwu Yang",
                "Lorenzo Bruzzone"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01429v3",
                "http://arxiv.org/pdf/2309.01429v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01392v2",
            "title": "Differentiable Bayesian Structure Learning with Acyclicity Assurance",
            "updated": "2023-09-06T04:28:39Z",
            "published": "2023-09-04T06:44:46Z",
            "summary": "Score-based approaches in the structure learning task are thriving because of\ntheir scalability. Continuous relaxation has been the key reason for this\nadvancement. Despite achieving promising outcomes, most of these methods are\nstill struggling to ensure that the graphs generated from the latent space are\nacyclic by minimizing a defined score. There has also been another trend of\npermutation-based approaches, which concern the search for the topological\nordering of the variables in the directed acyclic graph in order to limit the\nsearch space of the graph. In this study, we propose an alternative approach\nfor strictly constraining the acyclicty of the graphs with an integration of\nthe knowledge from the topological orderings. Our approach can reduce inference\ncomplexity while ensuring the structures of the generated graphs to be acyclic.\nOur empirical experiments with simulated and real-world data show that our\napproach can outperform related Bayesian score-based approaches.",
            "author": [
                "Quang-Duy Tran",
                "Phuoc Nguyen",
                "Bao Duong",
                "Thin Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01392v2",
                "http://arxiv.org/pdf/2309.01392v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01384v1",
            "title": "Deep Learning Approach for Large-Scale, Real-Time Quantification of\n  Green Fluorescent Protein-Labeled Biological Samples in Microreactors",
            "updated": "2023-09-04T06:22:33Z",
            "published": "2023-09-04T06:22:33Z",
            "summary": "Absolute quantification of biological samples entails determining expression\nlevels in precise numerical copies, offering enhanced accuracy and superior\nperformance for rare templates. However, existing methodologies suffer from\nsignificant limitations: flow cytometers are both costly and intricate, while\nfluorescence imaging relying on software tools or manual counting is\ntime-consuming and prone to inaccuracies. In this study, we have devised a\ncomprehensive deep-learning-enabled pipeline that enables the automated\nsegmentation and classification of GFP (green fluorescent protein)-labeled\nmicroreactors, facilitating real-time absolute quantification. Our findings\ndemonstrate the efficacy of this technique in accurately predicting the sizes\nand occupancy status of microreactors using standard laboratory fluorescence\nmicroscopes, thereby providing precise measurements of template concentrations.\nNotably, our approach exhibits an analysis speed of quantifying over 2,000\nmicroreactors (across 10 images) within remarkably 2.5 seconds, and a dynamic\nrange spanning from 56.52 to 1569.43 copies per micron-liter. Furthermore, our\nDeep-dGFP algorithm showcases remarkable generalization capabilities, as it can\nbe directly applied to various GFP-labeling scenarios, including droplet-based,\nmicrowell-based, and agarose-based biological applications. To the best of our\nknowledge, this represents the first successful implementation of an all-in-one\nimage analysis algorithm in droplet digital PCR (polymerase chain reaction),\nmicrowell digital PCR, droplet single-cell sequencing, agarose digital PCR, and\nbacterial quantification, without necessitating any transfer learning steps,\nmodifications, or retraining procedures. We firmly believe that our Deep-dGFP\ntechnique will be readily embraced by biomedical laboratories and holds\npotential for further development in related clinical applications.",
            "author": [
                "Yuanyuan Wei",
                "Sai Mu Dalike Abaxi",
                "Nawaz Mehmood",
                "Luoquan Li",
                "Fuyang Qu",
                "Guangyao Cheng",
                "Dehua Hu",
                "Yi-Ping Ho",
                "Scott Wu Yuan",
                "Ho-Pui Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01384v1",
                "http://arxiv.org/pdf/2309.01384v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.SY",
                "eess.IV",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01370v1",
            "title": "ReOnto: A Neuro-Symbolic Approach for Biomedical Relation Extraction",
            "updated": "2023-09-04T05:36:58Z",
            "published": "2023-09-04T05:36:58Z",
            "summary": "Relation Extraction (RE) is the task of extracting semantic relationships\nbetween entities in a sentence and aligning them to relations defined in a\nvocabulary, which is generally in the form of a Knowledge Graph (KG) or an\nontology. Various approaches have been proposed so far to address this task.\nHowever, applying these techniques to biomedical text often yields\nunsatisfactory results because it is hard to infer relations directly from\nsentences due to the nature of the biomedical relations. To address these\nissues, we present a novel technique called ReOnto, that makes use of neuro\nsymbolic knowledge for the RE task. ReOnto employs a graph neural network to\nacquire the sentence representation and leverages publicly accessible\nontologies as prior knowledge to identify the sentential relation between two\nentities. The approach involves extracting the relation path between the two\nentities from the ontology. We evaluate the effect of using symbolic knowledge\nfrom ontologies with graph neural networks. Experimental results on two public\nbiomedical datasets, BioRel and ADE, show that our method outperforms all the\nbaselines (approximately by 3\\%).",
            "author": [
                "Monika Jain",
                "Kuldeep Singh",
                "Raghava Mutharaju"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01370v1",
                "http://arxiv.org/pdf/2309.01370v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01360v1",
            "title": "Random Projections of Sparse Adjacency Matrices",
            "updated": "2023-09-04T04:53:52Z",
            "published": "2023-09-04T04:53:52Z",
            "summary": "We analyze a random projection method for adjacency matrices, studying its\nutility in representing sparse graphs. We show that these random projections\nretain the functionality of their underlying adjacency matrices while having\nextra properties that make them attractive as dynamic graph representations. In\nparticular, they can represent graphs of different sizes and vertex sets in the\nsame space, allowing for the aggregation and manipulation of graphs in a\nunified manner. We also provide results on how the size of the projections need\nto scale in order to preserve accurate graph operations, showing that the size\nof the projections can scale linearly with the number of vertices while\naccurately retaining first-order graph information. We conclude by\ncharacterizing our random projection as a distance-preserving map of adjacency\nmatrices analogous to the usual Johnson-Lindenstrauss map.",
            "author": [
                "Frank Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01360v1",
                "http://arxiv.org/pdf/2309.01360v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML",
                "65F50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01358v1",
            "title": "Inertia and spectral symmetry of the eccentricity matrices of a class of\n  bi-block graphs",
            "updated": "2023-09-04T04:48:05Z",
            "published": "2023-09-04T04:48:05Z",
            "summary": "The eccentricity matrix of a simple connected graph G is obtained from the\ndistance matrix of G by retaining the largest non-zero distance in each row and\ncolumn, and the remaining entries are defined to be zero. A bi-block graph is a\nsimple connected graph whose blocks are all complete bipartite graphs with\npossibly different orders. In this paper, we study the eccentricity matrices of\na subclass B (which includes trees) of bi-block graphs. We first find the\ninertia of the eccentricity matrices of graphs in B, and thereby we\ncharacterize graphs in B with odd diameters. Precisely, if G in B with diameter\nof G greater than three, then we show that the eigenvalues of the eccentricity\nmatrix of G are symmetric with respect to the origin if and only if the\ndiameter of G is odd. Further, we prove that the eccentricity matrices of\ngraphs in B are irreducible.",
            "author": [
                "T. Divyadevi",
                "I. Jeyaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01358v1",
                "http://arxiv.org/pdf/2309.01358v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C12, 05C50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01352v1",
            "title": "Self-driven Grounding: Large Language Model Agents with Automatical\n  Language-aligned Skill Learning",
            "updated": "2023-09-04T04:31:24Z",
            "published": "2023-09-04T04:31:24Z",
            "summary": "Large language models (LLMs) show their powerful automatic reasoning and\nplanning capability with a wealth of semantic knowledge about the human world.\nHowever, the grounding problem still hinders the applications of LLMs in the\nreal-world environment. Existing studies try to fine-tune the LLM or utilize\npre-defined behavior APIs to bridge the LLMs and the environment, which not\nonly costs huge human efforts to customize for every single task but also\nweakens the generality strengths of LLMs. To autonomously ground the LLM onto\nthe environment, we proposed the Self-Driven Grounding (SDG) framework to\nautomatically and progressively ground the LLM with self-driven skill learning.\nSDG first employs the LLM to propose the hypothesis of sub-goals to achieve\ntasks and then verify the feasibility of the hypothesis via interacting with\nthe underlying environment. Once verified, SDG can then learn generalized\nskills with the guidance of these successfully grounded subgoals. These skills\ncan be further utilized to accomplish more complex tasks which fail to pass the\nverification phase. Verified in the famous instruction following task\nset-BabyAI, SDG achieves comparable performance in the most challenging tasks\ncompared with imitation learning methods that cost millions of demonstrations,\nproving the effectiveness of learned skills and showing the feasibility and\nefficiency of our framework.",
            "author": [
                "Shaohui Peng",
                "Xing Hu",
                "Qi Yi",
                "Rui Zhang",
                "Jiaming Guo",
                "Di Huang",
                "Zikang Tian",
                "Ruizhi Chen",
                "Zidong Du",
                "Qi Guo",
                "Yunji Chen",
                "Ling Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01352v1",
                "http://arxiv.org/pdf/2309.01352v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01339v1",
            "title": "UniSA: Unified Generative Framework for Sentiment Analysis",
            "updated": "2023-09-04T03:49:30Z",
            "published": "2023-09-04T03:49:30Z",
            "summary": "Sentiment analysis is a crucial task that aims to understand people's\nemotional states and predict emotional categories based on multimodal\ninformation. It consists of several subtasks, such as emotion recognition in\nconversation (ERC), aspect-based sentiment analysis (ABSA), and multimodal\nsentiment analysis (MSA). However, unifying all subtasks in sentiment analysis\npresents numerous challenges, including modality alignment, unified\ninput/output forms, and dataset bias. To address these challenges, we propose a\nTask-Specific Prompt method to jointly model subtasks and introduce a\nmultimodal generative framework called UniSA. Additionally, we organize the\nbenchmark datasets of main subtasks into a new Sentiment Analysis Evaluation\nbenchmark, SAEval. We design novel pre-training tasks and training methods to\nenable the model to learn generic sentiment knowledge among subtasks to improve\nthe model's multimodal sentiment perception ability. Our experimental results\nshow that UniSA performs comparably to the state-of-the-art on all subtasks and\ngeneralizes well to various subtasks in sentiment analysis.",
            "author": [
                "Zaijing Li",
                "Ting-En Lin",
                "Yuchuan Wu",
                "Meng Liu",
                "Fengxiao Tang",
                "Ming Zhao",
                "Yongbin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01339v1",
                "http://arxiv.org/pdf/2309.01339v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01332v1",
            "title": "Synchro: Block-generation Protocol to Synchronously Process Cross-shard\n  Transactions in State Sharding",
            "updated": "2023-09-04T03:20:49Z",
            "published": "2023-09-04T03:20:49Z",
            "summary": "Traditional blockchains cannot achieve the same transaction throughput as\nWeb2, so their use cases are limited. Therefore, state sharding has been\nproposed to improve transaction throughput by dividing the blockchain network\nand managing states and transactions in parallel. However, Nightshade in the\nNEAR Protocol, a type of state sharding, provides a rollback protocol to cancel\nthe generation of blocks containing inconsistent transaction results because\nprocessing cross-shard transactions (CSTXs) in a 2-phase commit may cause state\ninconsistency. We present a new attack that interferes with the generation of\nnew blocks by repeatedly executing CSTXs that certainly causes state\ninconsistency, causing continuous rollback. We also propose a block-generation\nprotocol called Synchro to incorporate all the state changes of each CSTX into\nthe same block by coordinating the block prior to approving transactions in\neach shard. Synchro eliminates the occurrence of the state inconsistency caused\nby the CSTXs and the necessity of the rollback protocol. We use zero-knowledge\nproof to make Synchro scalable in the global validation phase. Although the\nactual overhead of the zero-knowledge proof has not yet been evaluated, we show\nthat Synchro could achieve the same transaction throughput as Nightshade\ntheoretically, depending on the future innovations in zero-knowledge proof\ntechniques.",
            "author": [
                "Takaki Asanuma",
                "Takeshi Miyamae",
                "Yuji Yamaoka"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01332v1",
                "http://arxiv.org/pdf/2309.01332v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01324v1",
            "title": "SKoPe3D: A Synthetic Dataset for Vehicle Keypoint Perception in 3D from\n  Traffic Monitoring Cameras",
            "updated": "2023-09-04T02:57:30Z",
            "published": "2023-09-04T02:57:30Z",
            "summary": "Intelligent transportation systems (ITS) have revolutionized modern road\ninfrastructure, providing essential functionalities such as traffic monitoring,\nroad safety assessment, congestion reduction, and law enforcement. Effective\nvehicle detection and accurate vehicle pose estimation are crucial for ITS,\nparticularly using monocular cameras installed on the road infrastructure. One\nfundamental challenge in vision-based vehicle monitoring is keypoint detection,\nwhich involves identifying and localizing specific points on vehicles (such as\nheadlights, wheels, taillights, etc.). However, this task is complicated by\nvehicle model and shape variations, occlusion, weather, and lighting\nconditions. Furthermore, existing traffic perception datasets for keypoint\ndetection predominantly focus on frontal views from ego vehicle-mounted\nsensors, limiting their usability in traffic monitoring. To address these\nissues, we propose SKoPe3D, a unique synthetic vehicle keypoint dataset\ngenerated using the CARLA simulator from a roadside perspective. This\ncomprehensive dataset includes generated images with bounding boxes, tracking\nIDs, and 33 keypoints for each vehicle. Spanning over 25k images across 28\nscenes, SKoPe3D contains over 150k vehicle instances and 4.9 million keypoints.\nTo demonstrate its utility, we trained a keypoint R-CNN model on our dataset as\na baseline and conducted a thorough evaluation. Our experiments highlight the\ndataset's applicability and the potential for knowledge transfer between\nsynthetic and real-world data. By leveraging the SKoPe3D dataset, researchers\nand practitioners can overcome the limitations of existing datasets, enabling\nadvancements in vehicle keypoint detection for ITS.",
            "author": [
                "Himanshu Pahadia",
                "Duo Lu",
                "Bharatesh Chakravarthi",
                "Yezhou Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01324v1",
                "http://arxiv.org/pdf/2309.01324v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03227v1",
            "title": "Learning a Patent-Informed Biomedical Knowledge Graph Reveals\n  Technological Potential of Drug Repositioning Candidates",
            "updated": "2023-09-04T02:30:19Z",
            "published": "2023-09-04T02:30:19Z",
            "summary": "Drug repositioning-a promising strategy for discovering new therapeutic uses\nfor existing drugs-has been increasingly explored in the computational science\nliterature using biomedical databases. However, the technological potential of\ndrug repositioning candidates has often been overlooked. This study presents a\nnovel protocol to comprehensively analyse various sources such as\npharmaceutical patents and biomedical databases, and identify drug\nrepositioning candidates with both technological potential and scientific\nevidence. To this end, first, we constructed a scientific biomedical knowledge\ngraph (s-BKG) comprising relationships between drugs, diseases, and genes\nderived from biomedical databases. Our protocol involves identifying drugs that\nexhibit limited association with the target disease but are closely located in\nthe s-BKG, as potential drug candidates. We constructed a patent-informed\nbiomedical knowledge graph (p-BKG) by adding pharmaceutical patent information.\nFinally, we developed a graph embedding protocol to ascertain the structure of\nthe p-BKG, thereby calculating the relevance scores of those candidates with\ntarget disease-related patents to evaluate their technological potential. Our\ncase study on Alzheimer's disease demonstrates its efficacy and feasibility,\nwhile the quantitative outcomes and systematic methods are expected to bridge\nthe gap between computational discoveries and successful market applications in\ndrug repositioning research.",
            "author": [
                "Yongseung Jegal",
                "Jaewoong Choi",
                "Jiho Lee",
                "Ki-Su Park",
                "Seyoung Lee",
                "Janghyeok Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03227v1",
                "http://arxiv.org/pdf/2309.03227v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.09980v1",
            "title": "Code Representation Pre-training with Complements from Program\n  Executions",
            "updated": "2023-09-04T01:57:22Z",
            "published": "2023-09-04T01:57:22Z",
            "summary": "Large language models (LLMs) for natural language processing have been\ngrafted onto programming language modeling for advancing code intelligence.\nAlthough it can be represented in the text format, code is syntactically more\nrigorous in order to be properly compiled or interpreted to perform a desired\nset of behaviors given any inputs. In this case, existing works benefit from\nsyntactic representations to learn from code less ambiguously in the forms of\nabstract syntax tree, control-flow graph, etc. However, programs with the same\npurpose can be implemented in various ways showing different syntactic\nrepresentations while the ones with similar implementations can have distinct\nbehaviors. Though trivially demonstrated during executions, such semantics\nabout functionality are challenging to be learned directly from code,\nespecially in an unsupervised manner. Hence, in this paper, we propose\nFuzzPretrain to explore the dynamic information of programs revealed by their\ntest cases and embed it into the feature representations of code as\ncomplements. The test cases are obtained with the assistance of a customized\nfuzzer and are only required during pre-training. FuzzPretrain yielded more\nthan 6%/9% mAP improvements on code search over its counterparts trained with\nonly source code or AST, respectively. Our extensive experimental results show\nthe benefits of learning discriminative code representations with program\nexecutions.",
            "author": [
                "Jiabo Huang",
                "Jianyu Zhao",
                "Yuyang Rong",
                "Yiwen Guo",
                "Yifeng He",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.09980v1",
                "http://arxiv.org/pdf/2309.09980v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01309v2",
            "title": "Quantum Bruhat graphs and tilted Richardson varieties",
            "updated": "2023-09-09T01:30:14Z",
            "published": "2023-09-04T01:45:05Z",
            "summary": "Quantum Bruhat graph is a weighted directed graph on a finite Weyl group\nfirst defined by Brenti-Fomin-Postnikov. It encodes quantum Monk's rule and can\nbe utilized to study the $3$-point Gromov-Witten invariants of the flag\nvariety. In this paper, we provide an explicit formula for the minimal weights\nbetween any pair of permutations on the quantum Bruhat graph, and consequently\nobtain an Ehresmann-like characterization for the tilted Bruhat order.\nMoreover, for any ordered pair of permutations $u$ and $v$, we define the\ntilted Richardson variety $T_{u,v}$, with a stratification that gives a\ngeometric meaning to intervals in the tilted Bruhat order. We provide a few\nequivalent definitions to this new family of varieties that include Richardson\nvarieties, and establish some fundamental geometric properties including their\ndimensions and closure relations.",
            "author": [
                "Jiyang Gao",
                "Shiliang Gao",
                "Yibo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01309v2",
                "http://arxiv.org/pdf/2309.01309v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01301v2",
            "title": "T-Stochastic Graphs",
            "updated": "2023-09-30T05:54:19Z",
            "published": "2023-09-04T00:59:46Z",
            "summary": "Previous statistical approaches to hierarchical clustering for social network\nanalysis all construct an \"ultrametric\" hierarchy. While the assumption of\nultrametricity has been discussed and studied in the phylogenetics literature,\nit has not yet been acknowledged in the social network literature. We show that\n\"non-ultrametric structure\" in the network introduces significant instabilities\nin the existing top-down recovery algorithms. To address this issue, we\nintroduce an instability diagnostic plot and use it to examine a collection of\nempirical networks. These networks appear to violate the \"ultrametric\"\nassumption. We propose a deceptively simple and yet general class of\nprobabilistic models called $\\mathbb{T}$-Stochastic Graphs which impose no\ntopological restrictions on the latent hierarchy. To illustrate this model, we\npropose six alternative forms of hierarchical network models and then show that\nall six are equivalent to the $\\mathbb{T}$-Stochastic Graph model. These\nalternative models motivate a novel approach to hierarchical clustering that\ncombines spectral techniques with the well-known Neighbor-Joining algorithm\nfrom phylogenetic reconstruction. We prove this spectral approach is\nstatistically consistent.",
            "author": [
                "Sijia Fang",
                "Karl Rohe"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01301v2",
                "http://arxiv.org/pdf/2309.01301v2"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01270v2",
            "title": "COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action\n  Spotting using Transformers",
            "updated": "2023-10-26T09:58:37Z",
            "published": "2023-09-03T20:50:53Z",
            "summary": "We present COMEDIAN, a novel pipeline to initialize spatiotemporal\ntransformers for action spotting, which involves self-supervised learning and\nknowledge distillation. Action spotting is a timestamp-level temporal action\ndetection task. Our pipeline consists of three steps, with two initialization\nstages. First, we perform self-supervised initialization of a spatial\ntransformer using short videos as input. Additionally, we initialize a temporal\ntransformer that enhances the spatial transformer's outputs with global context\nthrough knowledge distillation from a pre-computed feature bank aligned with\neach short video segment. In the final step, we fine-tune the transformers to\nthe action spotting task. The experiments, conducted on the SoccerNet-v2\ndataset, demonstrate state-of-the-art performance and validate the\neffectiveness of COMEDIAN's pretraining paradigm. Our results highlight several\nadvantages of our pretraining pipeline, including improved performance and\nfaster convergence compared to non-pretrained models.",
            "author": [
                "Julien Denize",
                "Mykola Liashuha",
                "Jaonary Rabarisoa",
                "Astrid Orcesi",
                "Romain H\u00e9rault"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01270v2",
                "http://arxiv.org/pdf/2309.01270v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01264v1",
            "title": "Upward and Orthogonal Planarity are W[1]-hard Parameterized by Treewidth",
            "updated": "2023-09-03T20:09:52Z",
            "published": "2023-09-03T20:09:52Z",
            "summary": "Upward planarity testing and Rectilinear planarity testing are central\nproblems in graph drawing. It is known that they are both NP-complete, but XP\nwhen parameterized by treewidth. In this paper we show that these two problems\nare W[1]-hard parameterized by treewidth, which answers open problems posed in\ntwo earlier papers. The key step in our proof is an analysis of the\nAll-or-Nothing Flow problem, a generalization of which was used as an\nintermediate step in the NP-completeness proof for both planarity testing\nproblems. We prove that the flow problem is W[1]-hard parameterized by\ntreewidth on planar graphs, and that the existing chain of reductions to the\nplanarity testing problems can be adapted without blowing up the treewidth. Our\nreductions also show that the known $n^{O(tw)}$-time algorithms cannot be\nimproved to run in time $n^{o(tw)}$ unless ETH fails.",
            "author": [
                "Bart M. P. Jansen",
                "Liana Khazaliya",
                "Philipp Kindermann",
                "Giuseppe Liotta",
                "Fabrizio Montecchiani",
                "Kirill Simonov"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01264v1",
                "http://arxiv.org/pdf/2309.01264v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01249v1",
            "title": "Large AI Model Empowered Multimodal Semantic Communications",
            "updated": "2023-09-03T19:24:34Z",
            "published": "2023-09-03T19:24:34Z",
            "summary": "Multimodal signals, including text, audio, image and video, can be integrated\ninto Semantic Communication (SC) for providing an immersive experience with low\nlatency and high quality at the semantic level. However, the multimodal SC has\nseveral challenges, including data heterogeneity, semantic ambiguity, and\nsignal fading. Recent advancements in large AI models, particularly in\nMultimodal Language Model (MLM) and Large Language Model (LLM), offer potential\nsolutions for these issues. To this end, we propose a Large AI Model-based\nMultimodal SC (LAM-MSC) framework, in which we first present the MLM-based\nMultimodal Alignment (MMA) that utilizes the MLM to enable the transformation\nbetween multimodal and unimodal data while preserving semantic consistency.\nThen, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows\nusers to perform personalized semantic extraction or recovery through the LLM.\nThis effectively addresses the semantic ambiguity. Finally, we apply the\nConditional Generative adversarial networks-based channel Estimation (CGE) to\nobtain Channel State Information (CSI). This approach effectively mitigates the\nimpact of fading channels in SC. Finally, we conduct simulations that\ndemonstrate the superior performance of the LAM-MSC framework.",
            "author": [
                "Feibo Jiang",
                "Yubo Peng",
                "Li Dong",
                "Kezhi Wang",
                "Kun Yang",
                "Cunhua Pan",
                "Xiaohu You"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01249v1",
                "http://arxiv.org/pdf/2309.01249v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01230v1",
            "title": "lfads-torch: A modular and extensible implementation of latent factor\n  analysis via dynamical systems",
            "updated": "2023-09-03T17:33:24Z",
            "published": "2023-09-03T17:33:24Z",
            "summary": "Latent factor analysis via dynamical systems (LFADS) is an RNN-based\nvariational sequential autoencoder that achieves state-of-the-art performance\nin denoising high-dimensional neural activity for downstream applications in\nscience and engineering. Recently introduced variants and extensions continue\nto demonstrate the applicability of the architecture to a wide variety of\nproblems in neuroscience. Since the development of the original implementation\nof LFADS, new technologies have emerged that use dynamic computation graphs,\nminimize boilerplate code, compose model configuration files, and simplify\nlarge-scale training. Building on these modern Python libraries, we introduce\nlfads-torch -- a new open-source implementation of LFADS that unifies existing\nvariants and is designed to be easier to understand, configure, and extend.\nDocumentation, source code, and issue tracking are available at\nhttps://github.com/arsedler9/lfads-torch .",
            "author": [
                "Andrew R. Sedler",
                "Chethan Pandarinath"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01230v1",
                "http://arxiv.org/pdf/2309.01230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01219v2",
            "title": "Siren's Song in the AI Ocean: A Survey on Hallucination in Large\n  Language Models",
            "updated": "2023-09-24T16:03:24Z",
            "published": "2023-09-03T16:56:48Z",
            "summary": "While large language models (LLMs) have demonstrated remarkable capabilities\nacross a range of downstream tasks, a significant concern revolves around their\npropensity to exhibit hallucinations: LLMs occasionally generate content that\ndiverges from the user input, contradicts previously generated context, or\nmisaligns with established world knowledge. This phenomenon poses a substantial\nchallenge to the reliability of LLMs in real-world scenarios. In this paper, we\nsurvey recent efforts on the detection, explanation, and mitigation of\nhallucination, with an emphasis on the unique challenges posed by LLMs. We\npresent taxonomies of the LLM hallucination phenomena and evaluation\nbenchmarks, analyze existing approaches aiming at mitigating LLM hallucination,\nand discuss potential directions for future research.",
            "author": [
                "Yue Zhang",
                "Yafu Li",
                "Leyang Cui",
                "Deng Cai",
                "Lemao Liu",
                "Tingchen Fu",
                "Xinting Huang",
                "Enbo Zhao",
                "Yu Zhang",
                "Yulong Chen",
                "Longyue Wang",
                "Anh Tuan Luu",
                "Wei Bi",
                "Freda Shi",
                "Shuming Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01219v2",
                "http://arxiv.org/pdf/2309.01219v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01199v2",
            "title": "DKWS: A Distributed System for Keyword Search on Massive Graphs\n  (Complete Version)",
            "updated": "2023-09-09T08:41:30Z",
            "published": "2023-09-03T15:14:12Z",
            "summary": "Due to the unstructuredness and the lack of schemas of graphs, such as\nknowledge graphs, social networks, and RDF graphs, keyword search for querying\nsuch graphs has been proposed. As graphs have become voluminous, large-scale\ndistributed processing has attracted much interest from the database research\ncommunity. While there have been several distributed systems, distributed\nquerying techniques for keyword search are still limited. This paper proposes a\nnovel distributed keyword search system called $\\DKWS$. First, we\n\\revise{present} a {\\em monotonic} property with keyword search algorithms that\nguarantees correct parallelization. Second, we present a keyword search\nalgorithm as monotonic backward and forward search phases. Moreover, we propose\nnew tight bounds for pruning nodes being searched. Third, we propose a {\\em\nnotify-push} paradigm and $\\PINE$ {\\em programming model} of $\\DKWS$. The\nnotify-push paradigm allows {\\em asynchronously} exchanging the upper bounds of\nmatches across the workers and the coordinator in $\\DKWS$. The $\\PINE$\nprogramming model naturally fits keyword search algorithms, as they have\ndistinguished phases, to allow {\\em preemptive} searches to mitigate staleness\nin a distributed system. Finally, we investigate the performance and\neffectiveness of $\\DKWS$ through experiments using real-world datasets. We find\nthat $\\DKWS$ is up to two orders of magnitude faster than related techniques,\nand its communication costs are $7.6$ times smaller than those of other\ntechniques.",
            "author": [
                "Jiaxin Jiang",
                "Byron Choi",
                "Xin Huang",
                "Jianliang Xu",
                "Sourav S Bhowmick"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01199v2",
                "http://arxiv.org/pdf/2309.01199v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01195v1",
            "title": "A dispersive estimate of the $a_0(980)$ contribution to hadronic\n  light-by-light scattering in $(g-2)_\u03bc$",
            "updated": "2023-09-03T14:59:01Z",
            "published": "2023-09-03T14:59:01Z",
            "summary": "A dispersive implementation of the $a_0(980)$ resonance to $(g-2)_\\mu$\nrequires the knowledge of the double-virtual $S$-wave\n$\\gamma^*\\gamma^*\\to\\pi\\eta / K\\bar{K}_{I=1}$ amplitudes. To obtain these\namplitudes we used a modified coupled-channel Muskhelischvili-Omn\\`es\nformalism, with the input from the left-hand cuts and the hadronic Omn\\`es\nfunction. The latter were obtained using a data-driven $N/D$ method in which\nthe fits were performed to the different sets of experimental data on\ntwo-photon fusion processes with $\\pi\\eta$ and $K\\bar{K}$ final states. This\nyields the preliminary dispersive estimate\n$a_\\mu^{HLbL}[a_0(980)]_{resc.}=-0.46(2)\\times 10^{-11}$.",
            "author": [
                "Oleksandra Deineka",
                "Igor Danilkin",
                "Marc Vanderhaeghen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01195v1",
                "http://arxiv.org/pdf/2309.01195v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01194v1",
            "title": "A Survey on Service Route and Time Prediction in Instant Delivery:\n  Taxonomy, Progress, and Prospects",
            "updated": "2023-09-03T14:43:33Z",
            "published": "2023-09-03T14:43:33Z",
            "summary": "Instant delivery services, such as food delivery and package delivery, have\nachieved explosive growth in recent years by providing customers with\ndaily-life convenience. An emerging research area within these services is\nservice Route\\&Time Prediction (RTP), which aims to estimate the future service\nroute as well as the arrival time of a given worker. As one of the most crucial\ntasks in those service platforms, RTP stands central to enhancing user\nsatisfaction and trimming operational expenditures on these platforms. Despite\na plethora of algorithms developed to date, there is no systematic,\ncomprehensive survey to guide researchers in this domain. To fill this gap, our\nwork presents the first comprehensive survey that methodically categorizes\nrecent advances in service route and time prediction. We start by defining the\nRTP challenge and then delve into the metrics that are often employed.\nFollowing that, we scrutinize the existing RTP methodologies, presenting a\nnovel taxonomy of them. We categorize these methods based on three criteria:\n(i) type of task, subdivided into only-route prediction, only-time prediction,\nand joint route\\&time prediction; (ii) model architecture, which encompasses\nsequence-based and graph-based models; and (iii) learning paradigm, including\nSupervised Learning (SL) and Deep Reinforcement Learning (DRL). Conclusively,\nwe highlight the limitations of current research and suggest prospective\navenues. We believe that the taxonomy, progress, and prospects introduced in\nthis paper can significantly promote the development of this field.",
            "author": [
                "Haomin Wen",
                "Youfang Lin",
                "Lixia Wu",
                "Xiaowei Mao",
                "Tianyue Cai",
                "Yunfeng Hou",
                "Shengnan Guo",
                "Yuxuan Liang",
                "Guangyin Jin",
                "Yiji Zhao",
                "Roger Zimmermann",
                "Jieping Ye",
                "Huaiyu Wan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01194v1",
                "http://arxiv.org/pdf/2309.01194v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01189v1",
            "title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "updated": "2023-09-03T14:22:57Z",
            "published": "2023-09-03T14:22:57Z",
            "summary": "The increasing volume of log data produced by software-intensive systems\nmakes it impractical to analyze them manually. Many deep learning-based methods\nhave been proposed for log-based anomaly detection. These methods face several\nchallenges such as high-dimensional and noisy log data, class imbalance,\ngeneralization, and model interpretability. Recently, ChatGPT has shown\npromising results in various domains. However, there is still a lack of study\non the application of ChatGPT for log-based anomaly detection. In this work, we\nproposed LogGPT, a log-based anomaly detection framework based on ChatGPT. By\nleveraging the ChatGPT's language interpretation capabilities, LogGPT aims to\nexplore the transferability of knowledge from large-scale corpora to log-based\nanomaly detection. We conduct experiments to evaluate the performance of LogGPT\nand compare it with three deep learning-based methods on BGL and Spirit\ndatasets. LogGPT shows promising results and has good interpretability. This\nstudy provides preliminary insights into prompt-based models, such as ChatGPT,\nfor the log-based anomaly detection task.",
            "author": [
                "Jiaxing Qi",
                "Shaohan Huang",
                "Zhongzhi Luan",
                "Carol Fung",
                "Hailong Yang",
                "Depei Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01189v1",
                "http://arxiv.org/pdf/2309.01189v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01188v2",
            "title": "Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for\n  Recommendation Systems",
            "updated": "2023-09-29T15:54:33Z",
            "published": "2023-09-03T14:18:31Z",
            "summary": "Modern neural collaborative filtering techniques are critical to the success\nof e-commerce, social media, and content-sharing platforms. However, despite\ntechnical advances -- for every new application domain, we need to train an NCF\nmodel from scratch. In contrast, pre-trained vision and language models are\nroutinely applied to diverse applications directly (zero-shot) or with limited\nfine-tuning. Inspired by the impact of pre-trained models, we explore the\npossibility of pre-trained recommender models that support building recommender\nsystems in new domains, with minimal or no retraining, without the use of any\nauxiliary user or item information. Zero-shot recommendation without auxiliary\ninformation is challenging because we cannot form associations between users\nand items across datasets when there are no overlapping users or items. Our\nfundamental insight is that the statistical characteristics of the user-item\ninteraction matrix are universally available across different domains and\ndatasets. Thus, we use the statistical characteristics of the user-item\ninteraction matrix to identify dataset-independent representations for users\nand items. We show how to learn universal (i.e., supporting zero-shot\nadaptation without user or item auxiliary information) representations for\nnodes and edges from the bipartite user-item interaction graph. We learn\nrepresentations by exploiting the statistical properties of the interaction\ndata, including user and item marginals, and the size and density distributions\nof their clusters.",
            "author": [
                "Junting Wang",
                "Adit Krishnan",
                "Hari Sundaram",
                "Yunzhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01188v2",
                "http://arxiv.org/pdf/2309.01188v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01179v1",
            "title": "Cognition-Mode Aware Variational Representation Learning Framework for\n  Knowledge Tracing",
            "updated": "2023-09-03T13:51:06Z",
            "published": "2023-09-03T13:51:06Z",
            "summary": "The Knowledge Tracing (KT) task plays a crucial role in personalized\nlearning, and its purpose is to predict student responses based on their\nhistorical practice behavior sequence. However, the KT task suffers from data\nsparsity, which makes it challenging to learn robust representations for\nstudents with few practice records and increases the risk of model overfitting.\nTherefore, in this paper, we propose a Cognition-Mode Aware Variational\nRepresentation Learning Framework (CMVF) that can be directly applied to\nexisting KT methods. Our framework uses a probabilistic model to generate a\ndistribution for each student, accounting for uncertainty in those with limited\npractice records, and estimate the student's distribution via variational\ninference (VI). In addition, we also introduce a cognition-mode aware\nmultinomial distribution as prior knowledge that constrains the posterior\nstudent distributions learning, so as to ensure that students with similar\ncognition modes have similar distributions, avoiding overwhelming\npersonalization for students with few practice records. At last, extensive\nexperimental results confirm that CMVF can effectively aid existing KT methods\nin learning more robust student representations. Our code is available at\nhttps://github.com/zmy-9/CMVF.",
            "author": [
                "Moyu Zhang",
                "Xinning Zhu",
                "Chunhong Zhang",
                "Feng Pan",
                "Wenchen Qian",
                "Hui Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01179v1",
                "http://arxiv.org/pdf/2309.01179v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01174v1",
            "title": "A method based on hierarchical spatiotemporal features for trojan\n  traffic detection",
            "updated": "2023-09-03T13:35:49Z",
            "published": "2023-09-03T13:35:49Z",
            "summary": "Trojans are one of the most threatening network attacks currently. HTTP-based\nTrojan, in particular, accounts for a considerable proportion of them.\nMoreover, as the network environment becomes more complex, HTTP-based Trojan is\nmore concealed than others. At present, many intrusion detection systems (IDSs)\nare increasingly difficult to effectively detect such Trojan traffic due to the\ninherent shortcomings of the methods used and the backwardness of training\ndata. Classical anomaly detection and traditional machine learning-based\n(TML-based) anomaly detection are highly dependent on expert knowledge to\nextract features artificially, which is difficult to implement in HTTP-based\nTrojan traffic detection. Deep learning-based (DL-based) anomaly detection has\nbeen locally applied to IDSs, but it cannot be transplanted to HTTP-based\nTrojan traffic detection directly. To solve this problem, in this paper, we\npropose a neural network detection model (HSTF-Model) based on hierarchical\nspatiotemporal features of traffic. Meanwhile, we combine deep learning\nalgorithms with expert knowledge through feature encoders and statistical\ncharacteristics to improve the self-learning ability of the model. Experiments\nindicate that F1 of HSTF-Model can reach 99.4% in real traffic. In addition, we\npresent a dataset BTHT consisting of HTTP-based benign and Trojan traffic to\nfacilitate related research in the field.",
            "author": [
                "Jiang Xie",
                "Shuhao Li",
                "Yongzheng Zhang",
                "Xiaochun Yun",
                "Jia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01174v1",
                "http://arxiv.org/pdf/2309.01174v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01172v1",
            "title": "FusionAI: Decentralized Training and Deploying LLMs with Massive\n  Consumer-Level GPUs",
            "updated": "2023-09-03T13:27:56Z",
            "published": "2023-09-03T13:27:56Z",
            "summary": "The rapid growth of memory and computation requirements of large language\nmodels (LLMs) has outpaced the development of hardware, hindering people who\nlack large-scale high-end GPUs from training or deploying LLMs. However,\nconsumer-level GPUs, which constitute a larger market share, are typically\noverlooked in LLM due to their weaker computing performance, smaller storage\ncapacity, and lower communication bandwidth. Additionally, users may have\nprivacy concerns when interacting with remote LLMs. In this paper, we envision\na decentralized system unlocking the potential vast untapped consumer-level\nGPUs in pre-training, inference and fine-tuning of LLMs with privacy\nprotection. However, this system faces critical challenges, including limited\nCPU and GPU memory, low network bandwidth, the variability of peer and device\nheterogeneity. To address these challenges, our system design incorporates: 1)\na broker with backup pool to implement dynamic join and quit of computing\nproviders; 2) task scheduling with hardware performance to improve system\nefficiency; 3) abstracting ML procedures into directed acyclic graphs (DAGs) to\nachieve model and task universality; 4) abstracting intermediate represention\nand execution planes to ensure compatibility of various devices and deep\nlearning (DL) frameworks. Our performance analysis demonstrates that 50 RTX\n3080 GPUs can achieve throughputs comparable to those of 4 H100 GPUs, which are\nsignificantly more expensive.",
            "author": [
                "Zhenheng Tang",
                "Yuxin Wang",
                "Xin He",
                "Longteng Zhang",
                "Xinglin Pan",
                "Qiang Wang",
                "Rongfei Zeng",
                "Kaiyong Zhao",
                "Shaohuai Shi",
                "Bingsheng He",
                "Xiaowen Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01172v1",
                "http://arxiv.org/pdf/2309.01172v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01169v1",
            "title": "End-to-End Learning on Multimodal Knowledge Graphs",
            "updated": "2023-09-03T13:16:18Z",
            "published": "2023-09-03T13:16:18Z",
            "summary": "Knowledge graphs enable data scientists to learn end-to-end on heterogeneous\nknowledge. However, most end-to-end models solely learn from the relational\ninformation encoded in graphs' structure: raw values, encoded as literal nodes,\nare either omitted completely or treated as regular nodes without consideration\nfor their values. In either case we lose potentially relevant information which\ncould have otherwise been exploited by our learning methods. We propose a\nmultimodal message passing network which not only learns end-to-end from the\nstructure of graphs, but also from their possibly divers set of multimodal node\nfeatures. Our model uses dedicated (neural) encoders to naturally learn\nembeddings for node features belonging to five different types of modalities,\nincluding numbers, texts, dates, images and geometries, which are projected\ninto a joint representation space together with their relational information.\nWe implement and demonstrate our model on node classification and link\nprediction for artificial and real-worlds datasets, and evaluate the effect\nthat each modality has on the overall performance in an inverse ablation study.\nOur results indicate that end-to-end multimodal learning from any arbitrary\nknowledge graph is indeed possible, and that including multimodal information\ncan significantly affect performance, but that much depends on the\ncharacteristics of the data.",
            "author": [
                "W. X. Wilcke",
                "P. Bloem",
                "V. de Boer",
                "R. H. van t Veer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01169v1",
                "http://arxiv.org/pdf/2309.01169v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.6; I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01160v1",
            "title": "Oxygen Vacancy Formation Energy in Metal Oxides: High Throughput\n  Computational Studies and Machine Learning Predictions",
            "updated": "2023-09-03T12:42:36Z",
            "published": "2023-09-03T12:42:36Z",
            "summary": "The oxygen vacancy formation energy ($\\Delta E_{vf}$) governs defect dynamics\nand is a useful metric to perform materials selection for a variety of\napplications. However, density functional theory (DFT) calculations of $\\Delta\nE_{vf}$ come at a greater computational cost than the typical bulk calculations\navailable in materials databases due to the involvement of multiple\nvacancy-containing supercells. As a result, available repositories of direct\ncalculations of $\\Delta E_{vf}$ remain relatively scarce, and the development\nof machine learning models capable of delivering accurate predictions is of\ninterest. In the present, work we address both such points. We first report the\nresults of new high-throughput DFT calculations of oxygen vacancy formation\nenergies of the different unique oxygen sites in over 1000 different oxide\nmaterials, which together form the largest dataset of directly computed oxygen\nvacancy formation energies to date, to our knowledge. We then utilize the\nresulting dataset of $\\sim$2500 $\\Delta E_{vf}$ values to train random forest\nmodels with different sets of features, examining both novel features\nintroduced in this work and ones previously employed in the literature. We\ndemonstrate the benefits of including features that contain information\nspecific to the vacancy site and account for both cation identity and oxidation\nstate, and achieve a mean absolute error upon prediction of $\\sim$0.3 eV/O,\nwhich is comparable to the accuracy observed upon comparison of DFT\ncomputations of oxygen vacancy formation energy and experimental results.\nFinally, we demonstrate the predictive power of the developed models in the\nsearch for new compounds for solar-thermochemical water-splitting applications,\nfinding over 250 new AA$^{\\prime}$BB$^{\\prime}$O$_6$ double perovskite\ncandidates.",
            "author": [
                "Bianca Baldassarri",
                "Jiangang He",
                "Abhijith Gopakumar",
                "Sean Griesemer",
                "Adolfo J. A. Salgado-Casanova",
                "Tzu-Chen Liu",
                "Steven B. Torrisi",
                "Chris Wolverton"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01160v1",
                "http://arxiv.org/pdf/2309.01160v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01158v1",
            "title": "An Accurate Graph Generative Model with Tunable Features",
            "updated": "2023-09-03T12:34:15Z",
            "published": "2023-09-03T12:34:15Z",
            "summary": "A graph is a very common and powerful data structure used for modeling\ncommunication and social networks. Models that generate graphs with arbitrary\nfeatures are important basic technologies in repeated simulations of networks\nand prediction of topology changes. Although existing generative models for\ngraphs are useful for providing graphs similar to real-world graphs, graph\ngeneration models with tunable features have been less explored in the field.\nPreviously, we have proposed GraphTune, a generative model for graphs that\ncontinuously tune specific graph features of generated graphs while maintaining\nmost of the features of a given graph dataset. However, the tuning accuracy of\ngraph features in GraphTune has not been sufficient for practical applications.\nIn this paper, we propose a method to improve the accuracy of GraphTune by\nadding a new mechanism to feed back errors of graph features of generated\ngraphs and by training them alternately and independently. Experiments on a\nreal-world graph dataset showed that the features in the generated graphs are\naccurately tuned compared with conventional models.",
            "author": [
                "Takahiro Yokoyama",
                "Yoshiki Sato",
                "Sho Tsugawa",
                "Kohei Watabe"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICCCN58024.2023.10230174",
                "http://arxiv.org/abs/2309.01158v1",
                "http://arxiv.org/pdf/2309.01158v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01144v1",
            "title": "Distributed averaging for accuracy prediction in networked systems",
            "updated": "2023-09-03T11:36:12Z",
            "published": "2023-09-03T11:36:12Z",
            "summary": "Distributed averaging is among the most relevant cooperative control\nproblems, with applications in sensor and robotic networks, distributed signal\nprocessing, data fusion, and load balancing. Consensus and gossip algorithms\nhave been investigated and successfully deployed in multi-agent systems to\nperform distributed averaging in synchronous and asynchronous settings. This\nstudy proposes a heuristic approach to estimate the convergence rate of\naveraging algorithms in a distributed manner, relying on the computation and\npropagation of local graph metrics while entailing simple data elaboration and\nsmall message passing. The protocol enables nodes to predict the time (or the\nnumber of interactions) needed to estimate the global average with the desired\naccuracy. Consequently, nodes can make informed decisions on their use of\nmeasured and estimated data while gaining awareness of the global structure of\nthe network, as well as their role in it. The study presents relevant\napplications to outliers identification and performance evaluation in switching\ntopologies.",
            "author": [
                "Christel Sirocchi",
                "Alessandro Bogliolo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01144v1",
                "http://arxiv.org/pdf/2309.01144v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.DC",
                "cs.SY",
                "C.2.4; C.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01127v1",
            "title": "Financial Fraud Detection using Quantum Graph Neural Networks",
            "updated": "2023-09-03T09:42:49Z",
            "published": "2023-09-03T09:42:49Z",
            "summary": "Financial fraud detection is essential for preventing significant financial\nlosses and maintaining the reputation of financial institutions. However,\nconventional methods of detecting financial fraud have limited effectiveness,\nnecessitating the need for new approaches to improve detection rates. In this\npaper, we propose a novel approach for detecting financial fraud using Quantum\nGraph Neural Networks (QGNNs). QGNNs are a type of neural network that can\nprocess graph-structured data and leverage the power of Quantum Computing (QC)\nto perform computations more efficiently than classical neural networks. Our\napproach uses Variational Quantum Circuits (VQC) to enhance the performance of\nthe QGNN. In order to evaluate the efficiency of our proposed method, we\ncompared the performance of QGNNs to Classical Graph Neural Networks using a\nreal-world financial fraud detection dataset. The results of our experiments\nshowed that QGNNs achieved an AUC of $0.85$, which outperformed classical GNNs.\nOur research highlights the potential of QGNNs and suggests that QGNNs are a\npromising new approach for improving financial fraud detection.",
            "author": [
                "Nouhaila Innan",
                "Abhishek Sawaika",
                "Ashim Dhor",
                "Siddhant Dutta",
                "Sairupa Thota",
                "Husayn Gokal",
                "Nandan Patel",
                "Muhammad Al-Zafar Khan",
                "Ioannis Theodonis",
                "Mohamed Bennai"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01127v1",
                "http://arxiv.org/pdf/2309.01127v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01125v1",
            "title": "AutoML-GPT: Large Language Model for AutoML",
            "updated": "2023-09-03T09:39:49Z",
            "published": "2023-09-03T09:39:49Z",
            "summary": "With the emerging trend of GPT models, we have established a framework called\nAutoML-GPT that integrates a comprehensive set of tools and libraries. This\nframework grants users access to a wide range of data preprocessing techniques,\nfeature engineering methods, and model selection algorithms. Through a\nconversational interface, users can specify their requirements, constraints,\nand evaluation metrics. Throughout the process, AutoML-GPT employs advanced\ntechniques for hyperparameter optimization and model selection, ensuring that\nthe resulting model achieves optimal performance. The system effectively\nmanages the complexity of the machine learning pipeline, guiding users towards\nthe best choices without requiring deep domain knowledge. Through our\nexperimental results on diverse datasets, we have demonstrated that AutoML-GPT\nsignificantly reduces the time and effort required for machine learning tasks.\nIts ability to leverage the vast knowledge encoded in large language models\nenables it to provide valuable insights, identify potential pitfalls, and\nsuggest effective solutions to common challenges faced during model training.",
            "author": [
                "Yun-Da Tsai",
                "Yu-Che Tsai",
                "Bo-Wei Huang",
                "Chun-Pai Yang",
                "Shou-De Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01125v1",
                "http://arxiv.org/pdf/2309.01125v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01123v1",
            "title": "On the determinant of the $Q$-walk matrix of rooted product with a path",
            "updated": "2023-09-03T09:39:15Z",
            "published": "2023-09-03T09:39:15Z",
            "summary": "Let $G$ be an $n$-vertex graph and $Q(G)$ be its signless Laplacian matrix.\nThe $Q$-walk matrix of $G$, denoted by $W_Q(G)$, is\n$[e,Q(G)e,\\ldots,Q^{n-1}(G)e]$, where $e$ is the all-one vector. Let $G\\circ\nP_m$ be the graph obtained from $G$ and $n$ copies of the path $P_m$ by\nidentifying the $i$-th vertex of $G$ with an endvertex of the $i$-th copy of\n$P_m$ for each $i$. We prove that, $$\\det W_Q(G\\circ P_m)=\\pm (\\det\nQ(G))^{m-1}(\\det W_Q(G))^m$$ holds for any $m\\ge 2$. This gives a signless\nLaplacian counterpart of the following recently established identity [17]:\n$$\\det W_A(G\\circ P_m)=\\pm (\\det A(G))^{\\lfloor\\frac{m}{2}\\rfloor}(\\det\nW_A(G))^m,$$ where $A(G)$ is the adjacency matrix of $G$ and\n$W_A(G)=[e,A(G)e,\\ldots,A^{n-1}(G)e]$. We also propose a conjecture to unify\nthe above two equalities.",
            "author": [
                "Zhidan Yan",
                "Lihuan Mao",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01123v1",
                "http://arxiv.org/pdf/2309.01123v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01103v3",
            "title": "Multi-Relational Contrastive Learning for Recommendation",
            "updated": "2023-10-20T05:10:14Z",
            "published": "2023-09-03T06:56:45Z",
            "summary": "Personalized recommender systems play a crucial role in capturing users'\nevolving preferences over time to provide accurate and effective\nrecommendations on various online platforms. However, many recommendation\nmodels rely on a single type of behavior learning, which limits their ability\nto represent the complex relationships between users and items in real-life\nscenarios. In such situations, users interact with items in multiple ways,\nincluding clicking, tagging as favorite, reviewing, and purchasing. To address\nthis issue, we propose the Relation-aware Contrastive Learning (RCL) framework,\nwhich effectively models dynamic interaction heterogeneity. The RCL model\nincorporates a multi-relational graph encoder that captures short-term\npreference heterogeneity while preserving the dedicated relation semantics for\ndifferent types of user-item interactions. Moreover, we design a dynamic\ncross-relational memory network that enables the RCL model to capture users'\nlong-term multi-behavior preferences and the underlying evolving cross-type\nbehavior dependencies over time. To obtain robust and informative user\nrepresentations with both commonality and diversity across multi-behavior\ninteractions, we introduce a multi-relational contrastive learning paradigm\nwith heterogeneous short- and long-term interest modeling. Our extensive\nexperimental studies on several real-world datasets demonstrate the superiority\nof the RCL recommender system over various state-of-the-art baselines in terms\nof recommendation accuracy and effectiveness.",
            "author": [
                "Wei Wei",
                "Lianghao Xia",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01103v3",
                "http://arxiv.org/pdf/2309.01103v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01101v1",
            "title": "M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive\n  Learning",
            "updated": "2023-09-03T06:39:56Z",
            "published": "2023-09-03T06:39:56Z",
            "summary": "Inspired by the successful application of contrastive learning on graphs,\nresearchers attempt to impose graph contrastive learning approaches on\nheterogeneous information networks. Orthogonal to homogeneous graphs, the types\nof nodes and edges in heterogeneous graphs are diverse so that specialized\ngraph contrastive learning methods are required. Most existing methods for\nheterogeneous graph contrastive learning are implemented by transforming\nheterogeneous graphs into homogeneous graphs, which may lead to ramifications\nthat the valuable information carried by non-target nodes is undermined thereby\nexacerbating the performance of contrastive learning models. Additionally,\ncurrent heterogeneous graph contrastive learning methods are mainly based on\ninitial meta-paths given by the dataset, yet according to our deep-going\nexploration, we derive empirical conclusions: only initial meta-paths cannot\ncontain sufficiently discriminative information; and various types of\nmeta-paths can effectively promote the performance of heterogeneous graph\ncontrastive learning methods. To this end, we propose a new multi-scale\nmeta-path integrated heterogeneous graph contrastive learning (M2HGCL) model,\nwhich discards the conventional heterogeneity-homogeneity transformation and\nperforms the graph contrastive learning in a joint manner. Specifically, we\nexpand the meta-paths and jointly aggregate the direct neighbor information,\nthe initial meta-path neighbor information and the expanded meta-path neighbor\ninformation to sufficiently capture discriminative information. A specific\npositive sampling strategy is further imposed to remedy the intrinsic\ndeficiency of contrastive learning, i.e., the hard negative sample sampling\nissue. Through extensive experiments on three real-world datasets, we\ndemonstrate that M2HGCL outperforms the current state-of-the-art baseline\nmodels.",
            "author": [
                "Yuanyuan Guo",
                "Yu Xia",
                "Rui Wang",
                "Rongcheng Duan",
                "Lu Li",
                "Jiangmeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01101v1",
                "http://arxiv.org/pdf/2309.01101v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01098v2",
            "title": "martFL: Enabling Utility-Driven Data Marketplace with a Robust and\n  Verifiable Federated Learning Architecture",
            "updated": "2023-09-19T14:04:35Z",
            "published": "2023-09-03T06:32:50Z",
            "summary": "The development of machine learning models requires a large amount of\ntraining data. Data marketplaces are essential for trading high-quality,\nprivate-domain data not publicly available online. However, due to growing data\nprivacy concerns, direct data exchange is inappropriate. Federated Learning\n(FL) is a distributed machine learning paradigm that exchanges data utilities\n(in form of local models or gradients) among multiple parties without directly\nsharing the raw data. However, several challenges exist when applying existing\nFL architectures to construct a data marketplace: (i) In existing FL\narchitectures, Data Acquirers (DAs) cannot privately evaluate local models from\nData Providers (DPs) prior to trading; (ii) Model aggregation protocols in\nexisting FL designs struggle to exclude malicious DPs without \"overfitting\" to\nthe DA's (possibly biased) root dataset; (iii) Prior FL designs lack a proper\nbilling mechanism to enforce the DA to fairly allocate the reward according to\ncontributions made by different DPs. To address above challenges, we propose\nmartFL, the first federated learning architecture that is specifically designed\nto enable a secure utility-driven data marketplace. At a high level, martFL is\npowered by two innovative designs: (i) a quality-aware model aggregation\nprotocol that achieves robust local model aggregation even when the DA's root\ndataset is biased; (ii) a verifiable data transaction protocol that enables the\nDA to prove, both succinctly and in zero-knowledge, that it has faithfully\naggregates the local models submitted by different DPs according to the\ncommitted aggregation weights, based on which the DPs can unambiguously claim\nthe corresponding reward. We implement a prototype of martFL and evaluate it\nextensively over various tasks. The results show that martFL can improve the\nmodel accuracy by up to 25% while saving up to 64% data acquisition cost.",
            "author": [
                "Qi Li",
                "Zhuotao Liu",
                "Qi Li",
                "Ke Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01098v2",
                "http://arxiv.org/pdf/2309.01098v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01093v1",
            "title": "CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection",
            "updated": "2023-09-03T06:18:39Z",
            "published": "2023-09-03T06:18:39Z",
            "summary": "Task driven object detection aims to detect object instances suitable for\naffording a task in an image. Its challenge lies in object categories available\nfor the task being too diverse to be limited to a closed set of object\nvocabulary for traditional object detection. Simply mapping categories and\nvisual features of common objects to the task cannot address the challenge. In\nthis paper, we propose to explore fundamental affordances rather than object\ncategories, i.e., common attributes that enable different objects to accomplish\nthe same task. Moreover, we propose a novel multi-level chain-of-thought\nprompting (MLCoT) to extract the affordance knowledge from large language\nmodels, which contains multi-level reasoning steps from task to object examples\nto essential visual attributes with rationales. Furthermore, to fully exploit\nknowledge to benefit object recognition and localization, we propose a\nknowledge-conditional detection framework, namely CoTDet. It conditions the\ndetector from the knowledge to generate object queries and regress boxes.\nExperimental results demonstrate that our CoTDet outperforms state-of-the-art\nmethods consistently and significantly (+15.6 box AP and +14.8 mask AP) and can\ngenerate rationales for why objects are detected to afford the task.",
            "author": [
                "Jiajin Tang",
                "Ge Zheng",
                "Jingyi Yu",
                "Sibei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01093v1",
                "http://arxiv.org/pdf/2309.01093v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01092v1",
            "title": "Face Clustering for Connection Discovery from Event Images",
            "updated": "2023-09-03T06:06:43Z",
            "published": "2023-09-03T06:06:43Z",
            "summary": "Social graphs are very useful for many applications, such as recommendations\nand community detections. However, they are only accessible to big social\nnetwork operators due to both data availability and privacy concerns. Event\nimages also capture the interactions among the participants, from which social\nconnections can be discovered to form a social graph. Unlike online social\ngraphs, social connections carried by event images can be extracted without\nuser inputs, and hence many social graph-based applications become possible,\neven without access to online social graphs. This paper proposes a system to\ndiscover social connections from event images. By utilizing the social\ninformation from even images, such as co-occurrence, a face clustering method\nis proposed and implemented, and connections can be discovered without the\nidentity of the event participants. By collecting over 40000 faces from over\n3000 participants, it is shown that the faces can be well clustered with 80% in\nF1 score, and social graphs can be constructed. Utilizing offline event images\nmay create a long-term impact on social network analytics.",
            "author": [
                "Ming Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01092v1",
                "http://arxiv.org/pdf/2309.01092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01078v1",
            "title": "UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with\n  Geometric Topology Guidance",
            "updated": "2023-09-03T04:58:12Z",
            "published": "2023-09-03T04:58:12Z",
            "summary": "Object detection has long been a topic of high interest in computer vision\nliterature. Motivated by the fact that annotating data for the multi-object\ntracking (MOT) problem is immensely expensive, recent studies have turned their\nattention to the unsupervised learning setting. In this paper, we push forward\nthe state-of-the-art performance of unsupervised MOT methods by proposing\nUnsMOT, a novel framework that explicitly combines the appearance and motion\nfeatures of objects with geometric information to provide more accurate\ntracking. Specifically, we first extract the appearance and motion features\nusing CNN and RNN models, respectively. Then, we construct a graph of objects\nbased on their relative distances in a frame, which is fed into a GNN model\ntogether with CNN features to output geometric embedding of objects optimized\nusing an unsupervised loss function. Finally, associations between objects are\nfound by matching not only similar extracted features but also geometric\nembedding of detections and tracklets. Experimental results show remarkable\nperformance in terms of HOTA, IDF1, and MOTA metrics in comparison with\nstate-of-the-art methods.",
            "author": [
                "Son Tran",
                "Cong Tran",
                "Anh Tran",
                "Cuong Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01078v1",
                "http://arxiv.org/pdf/2309.01078v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01067v1",
            "title": "MQENet: A Mesh Quality Evaluation Neural Network Based on Dynamic Graph\n  Attention",
            "updated": "2023-09-03T03:38:23Z",
            "published": "2023-09-03T03:38:23Z",
            "summary": "With the development of computational fluid dynamics, the requirements for\nthe fluid simulation accuracy in industrial applications have also increased.\nThe quality of the generated mesh directly affects the simulation accuracy.\nHowever, previous mesh quality metrics and models cannot evaluate meshes\ncomprehensively and objectively. To this end, we propose MQENet, a structured\nmesh quality evaluation neural network based on dynamic graph attention. MQENet\ntreats the mesh evaluation task as a graph classification task for classifying\nthe quality of the input structured mesh. To make graphs generated from\nstructured meshes more informative, MQENet introduces two novel structured mesh\npreprocessing algorithms. These two algorithms can also improve the conversion\nefficiency of structured mesh data. Experimental results on the benchmark\nstructured mesh dataset NACA-Market show the effectiveness of MQENet in the\nmesh quality evaluation task.",
            "author": [
                "Haoxuan Zhang",
                "Haisheng Li",
                "Nan Li",
                "Xiaochuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01067v1",
                "http://arxiv.org/pdf/2309.01067v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01036v2",
            "title": "SEPAL: Spatial Gene Expression Prediction from Local Graphs",
            "updated": "2023-09-16T17:19:38Z",
            "published": "2023-09-02T23:24:02Z",
            "summary": "Spatial transcriptomics is an emerging technology that aligns histopathology\nimages with spatially resolved gene expression profiling. It holds the\npotential for understanding many diseases but faces significant bottlenecks\nsuch as specialized equipment and domain expertise. In this work, we present\nSEPAL, a new model for predicting genetic profiles from visual tissue\nappearance. Our method exploits the biological biases of the problem by\ndirectly supervising relative differences with respect to mean expression, and\nleverages local visual context at every coordinate to make predictions using a\ngraph neural network. This approach closes the gap between complete locality\nand complete globality in current methods. In addition, we propose a novel\nbenchmark that aims to better define the task by following current best\npractices in transcriptomics and restricting the prediction variables to only\nthose with clear spatial patterns. Our extensive evaluation in two different\nhuman breast cancer datasets indicates that SEPAL outperforms previous\nstate-of-the-art methods and other mechanisms of including spatial context.",
            "author": [
                "Gabriel Mejia",
                "Paula C\u00e1rdenas",
                "Daniela Ruiz",
                "Angela Castillo",
                "Pablo Arbel\u00e1ez"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01036v2",
                "http://arxiv.org/pdf/2309.01036v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01032v1",
            "title": "Hessian-aware Quantized Node Embeddings for Recommendation",
            "updated": "2023-09-02T22:34:26Z",
            "published": "2023-09-02T22:34:26Z",
            "summary": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nrecommender systems. Nevertheless, the process of searching and ranking from a\nlarge item corpus usually requires high latency, which limits the widespread\ndeployment of GNNs in industry-scale applications. To address this issue, many\nmethods compress user/item representations into the binary embedding space to\nreduce space requirements and accelerate inference. Also, they use the\nStraight-through Estimator (STE) to prevent vanishing gradients during\nback-propagation. However, the STE often causes the gradient mismatch problem,\nleading to sub-optimal results.\n  In this work, we present the Hessian-aware Quantized GNN (HQ-GNN) as an\neffective solution for discrete representations of users/items that enable fast\nretrieval. HQ-GNN is composed of two components: a GNN encoder for learning\ncontinuous node embeddings and a quantized module for compressing\nfull-precision embeddings into low-bit ones. Consequently, HQ-GNN benefits from\nboth lower memory requirements and faster inference speeds compared to vanilla\nGNNs. To address the gradient mismatch problem in STE, we further consider the\nquantized errors and its second-order derivatives for better stability. The\nexperimental results on several large-scale datasets show that HQ-GNN achieves\na good balance between latency and performance.",
            "author": [
                "Huiyuan Chen",
                "Kaixiong Zhou",
                "Kwei-Herng Lai",
                "Chin-Chia Michael Yeh",
                "Yan Zheng",
                "Xia Hu",
                "Hao Yang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604915.3608826",
                "http://arxiv.org/abs/2309.01032v1",
                "http://arxiv.org/pdf/2309.01032v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01029v3",
            "title": "Explainability for Large Language Models: A Survey",
            "updated": "2023-11-28T19:04:45Z",
            "published": "2023-09-02T22:14:26Z",
            "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language processing. However, their internal mechanisms are still\nunclear and this lack of transparency poses unwanted risks for downstream\napplications. Therefore, understanding and explaining these models is crucial\nfor elucidating their behaviors, limitations, and social impacts. In this\npaper, we introduce a taxonomy of explainability techniques and provide a\nstructured overview of methods for explaining Transformer-based language\nmodels. We categorize techniques based on the training paradigms of LLMs:\ntraditional fine-tuning-based paradigm and prompting-based paradigm. For each\nparadigm, we summarize the goals and dominant approaches for generating local\nexplanations of individual predictions and global explanations of overall model\nknowledge. We also discuss metrics for evaluating generated explanations, and\ndiscuss how explanations can be leveraged to debug models and improve\nperformance. Lastly, we examine key challenges and emerging opportunities for\nexplanation techniques in the era of LLMs in comparison to conventional machine\nlearning models.",
            "author": [
                "Haiyan Zhao",
                "Hanjie Chen",
                "Fan Yang",
                "Ninghao Liu",
                "Huiqi Deng",
                "Hengyi Cai",
                "Shuaiqiang Wang",
                "Dawei Yin",
                "Mengnan Du"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01029v3",
                "http://arxiv.org/pdf/2309.01029v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01025v1",
            "title": "Review: Artificial Intelligence for Liquid-Vapor Phase-Change Heat\n  Transfer",
            "updated": "2023-09-02T21:26:14Z",
            "published": "2023-09-02T21:26:14Z",
            "summary": "Artificial intelligence (AI) is shifting the paradigm of two-phase heat\ntransfer research. Recent innovations in AI and machine learning uniquely offer\nthe potential for collecting new types of physically meaningful features that\nhave not been addressed in the past, for making their insights available to\nother domains, and for solving for physical quantities based on first\nprinciples for phase-change thermofluidic systems. This review outlines core\nideas of current AI technologies connected to thermal energy science to\nillustrate how they can be used to push the limit of our knowledge boundaries\nabout boiling and condensation phenomena. AI technologies for meta-analysis,\ndata extraction, and data stream analysis are described with their potential\nchallenges, opportunities, and alternative approaches. Finally, we offer\noutlooks and perspectives regarding physics-centered machine learning,\nsustainable cyberinfrastructures, and multidisciplinary efforts that will help\nfoster the growing trend of AI for phase-change heat and mass transfer.",
            "author": [
                "Youngjoon Suh",
                "Aparna Chandramowlishwaran",
                "Yoonjin Won"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01025v1",
                "http://arxiv.org/pdf/2309.01025v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.01001v2",
            "title": "Cops and Robbers on 1-Planar Graphs",
            "updated": "2023-09-07T01:45:01Z",
            "published": "2023-09-02T18:05:33Z",
            "summary": "Cops and Robbers is a well-studied pursuit-evasion game in which a set of\ncops seeks to catch a robber in a graph G, where cops and robber move along\nedges of G. The cop number of G is the minimum number of cops that is\nsufficient to catch the robber. Every planar graph has cop number at most\nthree, and there are planar graphs for which three cops are necessary [Aigner\nand Fromme, DAM 1984]. We study the problem for beyond-planar graphs, that is,\ngraphs that can be drawn in the plane with few crossings. In particular, we\nfocus on 1-planar graphs, that is, graphs that can be drawn in the plane with\nat most one crossing per edge. In contrast to planar graphs, we show that some\n1-planar graphs have unbounded cop number. Meanwhile, for maximal 1-planar\ngraphs, we prove that three cops are always sufficient and sometimes necessary.\nIn addition, we characterize outer 1-planar graphs with respect to their cop\nnumber.",
            "author": [
                "Stephane Durocher",
                "Shahin Kamali",
                "Myroslav Kryven",
                "Fengyi Liu",
                "Amirhossein Mashghdoust",
                "Avery Miller",
                "Pouria Zamani Nezhad",
                "Ikaro Penha Costa",
                "Timothy Zapp"
            ],
            "link": [
                "http://arxiv.org/abs/2309.01001v2",
                "http://arxiv.org/pdf/2309.01001v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "68R10, 91A24"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00991v1",
            "title": "Pseudofiniteness and measurability of the everywhere infinite forest",
            "updated": "2023-09-02T17:02:28Z",
            "published": "2023-09-02T17:02:28Z",
            "summary": "In this paper we study the theories of the infinite-branching tree and the\n$r$-regular tree, and show that both of them are pseudofinite. Moreover, we\nshow that they can be realized by infinite ultraproducts of polynomial exact\nclasses of graphs, and so they are also generalised measurable.",
            "author": [
                "Dar\u00edo Garc\u00eda",
                "Melissa Robles"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00991v1",
                "http://arxiv.org/pdf/2309.00991v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "math.CO",
                "03C (Primary) 05C (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00989v2",
            "title": "Equitable list coloring of planar graphs with given maximum degree",
            "updated": "2023-09-07T15:18:40Z",
            "published": "2023-09-02T16:58:08Z",
            "summary": "If $L$ is a list assignment of $r$ colors to each vertex of an $n$-vertex\ngraph $G$, then an equitable $L$-coloring of $G$ is a proper coloring of\nvertices of $G$ from their lists such that no color is used more than $\\lceil\nn/r\\rceil$ times. A graph is equitably $r$-choosable if it has an equitable\n$L$-coloring for every $r$-list assignment $L$. In 2003, Kostochka, Pelsmajer\nand West (KPW) conjectured that an analog of the famous Hajnal-Szemer\\'edi\nTheorem on equitable coloring holds for equitable list coloring, namely, that\nfor each positive integer $r$ every graph $G$ with maximum degree at most $r-1$\nis equitably $r$-choosable.\n  The main result of this paper is that for each $r\\geq 9$ and each planar\ngraph $G$, a stronger statement holds: if the maximum degree of $G$ is at most\n$r$, then $G$ is equitably $r$-choosable. In fact, we prove the result for a\nbroader class of graphs -- the class ${\\mathcal{B}}$ of the graphs in which\neach bipartite subgraph $B$ with $|V(B)|\\ge3$ has at most $2|V(B)|-4$ edges.\nTogether with some known results, this implies that the KPW Conjecture holds\nfor all graphs in ${\\mathcal{B}}$, in particular, for all planar graphs.",
            "author": [
                "H. A. Kierstead",
                "Alexandr Kostochka",
                "Zimu Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00989v2",
                "http://arxiv.org/pdf/2309.00989v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C07, 05C10, 05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00986v1",
            "title": "ModelScope-Agent: Building Your Customizable Agent System with\n  Open-source Large Language Models",
            "updated": "2023-09-02T16:50:30Z",
            "published": "2023-09-02T16:50:30Z",
            "summary": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities to comprehend human intentions, engage in reasoning, and design\nplanning-like behavior. To further unleash the power of LLMs to accomplish\ncomplex tasks, there is a growing trend to build agent framework that equips\nLLMs, such as ChatGPT, with tool-use abilities to connect with massive external\nAPIs. In this work, we introduce ModelScope-Agent, a general and customizable\nagent framework for real-world applications, based on open-source LLMs as\ncontrollers. It provides a user-friendly system library, with customizable\nengine design to support model training on multiple open-source LLMs, while\nalso enabling seamless integration with both model APIs and common APIs in a\nunified way. To equip the LLMs with tool-use abilities, a comprehensive\nframework has been proposed spanning over tool-use data collection, tool\nretrieval, tool registration, memory control, customized model training, and\nevaluation for practical real-world applications. Finally, we showcase\nModelScopeGPT, a real-world intelligent assistant of ModelScope Community based\non the ModelScope-Agent framework, which is able to connect open-source LLMs\nwith more than 1000 public AI models and localized community knowledge in\nModelScope. The ModelScope-Agent\nlibrary\\footnote{https://github.com/modelscope/modelscope-agent} and online\ndemo\\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now\npublicly available.",
            "author": [
                "Chenliang Li",
                "Hehong Chen",
                "Ming Yan",
                "Weizhou Shen",
                "Haiyang Xu",
                "Zhikai Wu",
                "Zhicheng Zhang",
                "Wenmeng Zhou",
                "Yingda Chen",
                "Chen Cheng",
                "Hongzhu Shi",
                "Ji Zhang",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00986v1",
                "http://arxiv.org/pdf/2309.00986v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00976v2",
            "title": "Pure Message Passing Can Estimate Common Neighbor for Link Prediction",
            "updated": "2023-10-10T08:56:16Z",
            "published": "2023-09-02T16:20:41Z",
            "summary": "Message Passing Neural Networks (MPNNs) have emerged as the {\\em de facto}\nstandard in graph representation learning. However, when it comes to link\nprediction, they often struggle, surpassed by simple heuristics such as Common\nNeighbor (CN). This discrepancy stems from a fundamental limitation: while\nMPNNs excel in node-level representation, they stumble with encoding the joint\nstructural features essential to link prediction, like CN. To bridge this gap,\nwe posit that, by harnessing the orthogonality of input vectors, pure\nmessage-passing can indeed capture joint structural features. Specifically, we\nstudy the proficiency of MPNNs in approximating CN heuristics. Based on our\nfindings, we introduce the Message Passing Link Predictor (MPLP), a novel link\nprediction model. MPLP taps into quasi-orthogonal vectors to estimate\nlink-level structural features, all while preserving the node-level\ncomplexities. Moreover, our approach demonstrates that leveraging\nmessage-passing to capture structural features could offset MPNNs'\nexpressiveness limitations at the expense of estimation variance. We conduct\nexperiments on benchmark datasets from various domains, where our method\nconsistently outperforms the baseline methods.",
            "author": [
                "Kaiwen Dong",
                "Zhichun Guo",
                "Nitesh V. Chawla"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00976v2",
                "http://arxiv.org/pdf/2309.00976v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00974v1",
            "title": "Deep-Learning Framework for Optimal Selection of Soil Sampling Sites",
            "updated": "2023-09-02T16:19:21Z",
            "published": "2023-09-02T16:19:21Z",
            "summary": "This work leverages the recent advancements of deep learning in image\nprocessing to find optimal locations that present the important characteristics\nof a field. The data for training are collected at different fields in local\nfarms with five features: aspect, flow accumulation, slope, NDVI (normalized\ndifference vegetation index), and yield. The soil sampling dataset is\nchallenging because the ground truth is highly imbalanced binary images.\nTherefore, we approached the problem with two methods, the first approach\ninvolves utilizing a state-of-the-art model with the convolutional neural\nnetwork (CNN) backbone, while the second is to innovate a deep-learning design\ngrounded in the concepts of transformer and self-attention. Our framework is\nconstructed with an encoder-decoder architecture with the self-attention\nmechanism as the backbone. In the encoder, the self-attention mechanism is the\nkey feature extractor, which produces feature maps. In the decoder, we\nintroduce atrous convolution networks to concatenate, fuse the extracted\nfeatures, and then export the optimal locations for soil sampling. Currently,\nthe model has achieved impressive results on the testing dataset, with a mean\naccuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean\nDice Coefficient of 71.47%, while the performance metrics of the\nstate-of-the-art CNN-based model are 66.08%, 3.85%, and 1.98%, respectively.\nThis indicates that our proposed model outperforms the CNN-based method on the\nsoil-sampling dataset. To the best of our knowledge, our work is the first to\nprovide a soil-sampling dataset with multiple attributes and leverage deep\nlearning techniques to enable the automatic selection of soil-sampling sites.\nThis work lays a foundation for novel applications of data science and\nmachine-learning technologies to solve other emerging agricultural problems.",
            "author": [
                "Tan-Hanh Pham",
                "Praneel Acharya",
                "Sravanthi Bachina",
                "Kristopher Osterloh",
                "Kim-Doang Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00974v1",
                "http://arxiv.org/pdf/2309.00974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00966v1",
            "title": "Compositional Diffusion-Based Continuous Constraint Solvers",
            "updated": "2023-09-02T15:20:36Z",
            "published": "2023-09-02T15:20:36Z",
            "summary": "This paper introduces an approach for learning to solve continuous constraint\nsatisfaction problems (CCSP) in robotic reasoning and planning. Previous\nmethods primarily rely on hand-engineering or learning generators for specific\nconstraint types and then rejecting the value assignments when other\nconstraints are violated. By contrast, our model, the compositional diffusion\ncontinuous constraint solver (Diffusion-CCSP) derives global solutions to CCSPs\nby representing them as factor graphs and combining the energies of diffusion\nmodels trained to sample for individual constraint types. Diffusion-CCSP\nexhibits strong generalization to novel combinations of known constraints, and\nit can be integrated into a task and motion planner to devise long-horizon\nplans that include actions with both discrete and continuous parameters.\nProject site: https://diffusion-ccsp.github.io/",
            "author": [
                "Zhutian Yang",
                "Jiayuan Mao",
                "Yilun Du",
                "Jiajun Wu",
                "Joshua B. Tenenbaum",
                "Tom\u00e1s Lozano-P\u00e9rez",
                "Leslie Pack Kaelbling"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00966v1",
                "http://arxiv.org/pdf/2309.00966v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00960v1",
            "title": "Network Topology Inference with Sparsity and Laplacian Constraints",
            "updated": "2023-09-02T15:06:30Z",
            "published": "2023-09-02T15:06:30Z",
            "summary": "We tackle the network topology inference problem by utilizing Laplacian\nconstrained Gaussian graphical models, which recast the task as estimating a\nprecision matrix in the form of a graph Laplacian. Recent research\n\\cite{ying2020nonconvex} has uncovered the limitations of the widely used\n$\\ell_1$-norm in learning sparse graphs under this model: empirically, the\nnumber of nonzero entries in the solution grows with the regularization\nparameter of the $\\ell_1$-norm; theoretically, a large regularization parameter\nleads to a fully connected (densest) graph. To overcome these challenges, we\npropose a graph Laplacian estimation method incorporating the $\\ell_0$-norm\nconstraint. An efficient gradient projection algorithm is developed to solve\nthe resulting optimization problem, characterized by sparsity and Laplacian\nconstraints. Through numerical experiments with synthetic and financial\ntime-series datasets, we demonstrate the effectiveness of the proposed method\nin network topology inference.",
            "author": [
                "Jiaxi Ying",
                "Xi Han",
                "Rui Zhou",
                "Xiwen Wang",
                "Hing Cheung So"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00960v1",
                "http://arxiv.org/pdf/2309.00960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00958v2",
            "title": "Index-aware learning of circuits",
            "updated": "2023-10-07T13:18:03Z",
            "published": "2023-09-02T14:59:11Z",
            "summary": "Electrical circuits are present in a variety of technologies, making their\ndesign an important part of computer aided engineering. The growing number of\ntunable parameters that affect the final design leads to a need for new\napproaches of quantifying their impact. Machine learning may play a key role in\nthis regard, however current approaches often make suboptimal use of existing\nknowledge about the system at hand. In terms of circuits, their description via\nmodified nodal analysis is well-understood. This particular formulation leads\nto systems of differential-algebraic equations (DAEs) which bring with them a\nnumber of peculiarities, e.g. hidden constraints that the solution needs to\nfulfill. We aim to use the recently introduced dissection concept for DAEs that\ncan decouple a given system into ordinary differential equations, only\ndepending on differential variables, and purely algebraic equations that\ndescribe the relations between differential and algebraic variables. The idea\nthen is to only learn the differential variables and reconstruct the algebraic\nones using the relations from the decoupling. This approach guarantees that the\nalgebraic constraints are fulfilled up to the accuracy of the nonlinear system\nsolver, which represents the main benefit highlighted in this article.",
            "author": [
                "Idoia Cortes Garcia",
                "Peter F\u00f6rster",
                "Lennart Jansen",
                "Wil Schilders",
                "Sebastian Sch\u00f6ps"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00958v2",
                "http://arxiv.org/pdf/2309.00958v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG",
                "34A09, 65L80 (Primary)",
                "G.1.7; J.2; J.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00957v1",
            "title": "Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip\n  Segmentation in Robotic Surgeries",
            "updated": "2023-09-02T14:52:58Z",
            "published": "2023-09-02T14:52:58Z",
            "summary": "Accurate segmentation of surgical instrument tip is an important task for\nenabling downstream applications in robotic surgery, such as surgical skill\nassessment, tool-tissue interaction and deformation modeling, as well as\nsurgical autonomy. However, this task is very challenging due to the small\nsizes of surgical instrument tips, and significant variance of surgical scenes\nacross different procedures. Although much effort has been made on visual-based\nmethods, existing segmentation models still suffer from low robustness thus not\nusable in practice. Fortunately, kinematics data from the robotic system can\nprovide reliable prior for instrument location, which is consistent regardless\nof different surgery types. To make use of such multi-modal information, we\npropose a novel visual-kinematics graph learning framework to accurately\nsegment the instrument tip given various surgical procedures. Specifically, a\ngraph learning framework is proposed to encode relational features of\ninstrument parts from both image and kinematics. Next, a cross-modal\ncontrastive loss is designed to incorporate robust geometric prior from\nkinematics to image for tip segmentation. We have conducted experiments on a\nprivate paired visual-kinematics dataset including multiple procedures, i.e.,\nprostatectomy, total mesorectal excision, fundoplication and distal gastrectomy\non cadaver, and distal gastrectomy on porcine. The leave-one-procedure-out\ncross validation demonstrated that our proposed multi-modal segmentation method\nsignificantly outperformed current image-based state-of-the-art approaches,\nexceeding averagely 11.2% on Dice.",
            "author": [
                "Jiaqi Liu",
                "Yonghao Long",
                "Kai Chen",
                "Cheuk Hei Leung",
                "Zerui Wang",
                "Qi Dou"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00957v1",
                "http://arxiv.org/pdf/2309.00957v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00933v1",
            "title": "Two-in-One Depth: Bridging the Gap Between Monocular and Binocular\n  Self-supervised Depth Estimation",
            "updated": "2023-09-02T13:06:23Z",
            "published": "2023-09-02T13:06:23Z",
            "summary": "Monocular and binocular self-supervised depth estimations are two important\nand related tasks in computer vision, which aim to predict scene depths from\nsingle images and stereo image pairs respectively. In literature, the two tasks\nare usually tackled separately by two different kinds of models, and binocular\nmodels generally fail to predict depth from single images, while the prediction\naccuracy of monocular models is generally inferior to binocular models. In this\npaper, we propose a Two-in-One self-supervised depth estimation network, called\nTiO-Depth, which could not only compatibly handle the two tasks, but also\nimprove the prediction accuracy. TiO-Depth employs a Siamese architecture and\neach sub-network of it could be used as a monocular depth estimation model. For\nbinocular depth estimation, a Monocular Feature Matching module is proposed for\nincorporating the stereo knowledge between the two images, and the full\nTiO-Depth is used to predict depths. We also design a multi-stage\njoint-training strategy for improving the performances of TiO-Depth in both two\ntasks by combining the relative advantages of them. Experimental results on the\nKITTI, Cityscapes, and DDAD datasets demonstrate that TiO-Depth outperforms\nboth the monocular and binocular state-of-the-art methods in most cases, and\nfurther verify the feasibility of a two-in-one network for monocular and\nbinocular depth estimation. The code is available at\nhttps://github.com/ZM-Zhou/TiO-Depth_pytorch.",
            "author": [
                "Zhengming Zhou",
                "Qiulei Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00933v1",
                "http://arxiv.org/pdf/2309.00933v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00931v2",
            "title": "A Parametric Finite-Element Discretization of the Surface Stokes\n  Equations",
            "updated": "2023-12-07T14:20:35Z",
            "published": "2023-09-02T12:52:12Z",
            "summary": "We study a higher-order surface finite-element (SFEM) penalty-based\ndiscretization of the tangential surface Stokes problem. Several discrete\nformulations are investigated which are equivalent in the continuous setting.\nThe impact of the choice of discretization of the diffusion term and of the\ndivergence term on numerical accuracy and convergence, as well as on\nimplementation advantages, is discussed. We analyze the inf-sup stability of\nthe discrete scheme in a generic approach by lifting stable finite-element\npairs known from the literature. A discretization error analysis in tangential\nnorms then shows optimal order convergence of an isogeometric setting that\nrequires only geometric knowledge of the discrete surface.",
            "author": [
                "Hanne Hardering",
                "Simon Praetorius"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00931v2",
                "http://arxiv.org/pdf/2309.00931v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "76D07, 65N30, 65N12",
                "G.1.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00923v2",
            "title": "GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot\n  Learning",
            "updated": "2023-09-14T14:05:02Z",
            "published": "2023-09-02T12:07:21Z",
            "summary": "This paper investigates a challenging problem of zero-shot learning in the\nmulti-label scenario (MLZSL), wherein, the model is trained to recognize\nmultiple unseen classes within a sample (e.g., an image) based on seen classes\nand auxiliary knowledge, e.g., semantic information. Existing methods usually\nresort to analyzing the relationship of various seen classes residing in a\nsample from the dimension of spatial or semantic characteristics, and transfer\nthe learned model to unseen ones. But they ignore the effective integration of\nlocal and global features. That is, in the process of inferring unseen classes,\nglobal features represent the principal direction of the image in the feature\nspace, while local features should maintain uniqueness within a certain range.\nThis integrated neglect will make the model lose its grasp of the main\ncomponents of the image. Relying only on the local existence of seen classes\nduring the inference stage introduces unavoidable bias. In this paper, we\npropose a novel and effective group bi-enhancement framework for MLZSL, dubbed\nGBE-MLZSL, to fully make use of such properties and enable a more accurate and\nrobust visual-semantic projection. Specifically, we split the feature maps into\nseveral feature groups, of which each feature group can be trained\nindependently with the Local Information Distinguishing Module (LID) to ensure\nuniqueness. Meanwhile, a Global Enhancement Module (GEM) is designed to\npreserve the principal direction. Besides, a static graph structure is designed\nto construct the correlation of local features. Experiments on large-scale\nMLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the\nproposed GBE-MLZSL outperforms other state-of-the-art methods with large\nmargins.",
            "author": [
                "Ziming Liu",
                "Jingcai Guo",
                "Xiaocheng Lu",
                "Song Guo",
                "Peiran Dong",
                "Jiewei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00923v2",
                "http://arxiv.org/pdf/2309.00923v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00922v1",
            "title": "Resolving vertices of graphs with differences",
            "updated": "2023-09-02T12:05:58Z",
            "published": "2023-09-02T12:05:58Z",
            "summary": "The classical (vertex) metric dimension of a graph G is defined as the\ncardinality of a smallest set S in V (G) such that any two vertices x and y\nfrom G have different distances to least one vertex from S: The k-metric\ndimension is a generalization of that notion where it is required that any pair\nof vertices has different distances to at least k vertices from S: In this\npaper, we introduce the weak k-metric dimension of a graph G; which is defined\nas the cardinality of a smallest set of vertices S such that the sum of the\ndistance differences from any pair of vertices to all vertices of S is at least\nk: This dimension is \"stronger\" than the classical metric dimension, yet\n\"weaker\" than k-metric dimension, and it can be formulated as an ILP problem.\nThe maximum k for which the weak k-metric dimension is defined is denoted by\nkappa(G). We first prove several properties of the weak k-metric dimension\nregarding the presence of true or false twin vertices in a graph. Using those\nproperties, the kappa(G) is found for some basic graph classes, such as paths,\nstars, cycles, and complete (bipartite) graphs. We also find kappa(G) for trees\nand grid graphs using the observation that the distance difference increases by\nthe increase of the cardinality of a set S. For all these graph classes we\nfurther establish the exact value of the weak k-metric dimension for all k <=\nkappa(G).",
            "author": [
                "Iztok Peterina",
                "Jelena Sedlar",
                "Riste \u0160krekovski",
                "Ismael G. Yero"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00922v1",
                "http://arxiv.org/pdf/2309.00922v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C12"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00917v2",
            "title": "Knowledge Graph Embeddings for Multi-Lingual Structured Representations\n  of Radiology Reports",
            "updated": "2023-09-14T14:25:37Z",
            "published": "2023-09-02T11:46:41Z",
            "summary": "The way we analyse clinical texts has undergone major changes over the last\nyears. The introduction of language models such as BERT led to adaptations for\nthe (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on\nlarge databases of archived medical documents. While performing well in terms\nof accuracy, both the lack of interpretability and limitations to transfer\nacross languages limit their use in clinical setting. We introduce a novel\nlight-weight graph-based embedding method specifically catering radiology\nreports. It takes into account the structure and composition of the report,\nwhile also connecting medical terms in the report through the multi-lingual\nSNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers\nthe underlying relationships among clinical terms, achieving a representation\nthat is better understandable for clinicians and clinically more accurate,\nwithout reliance on large pre-training datasets. We show the use of this\nembedding on two tasks namely disease classification of X-ray reports and image\nclassification. For disease classification our model is competitive with its\nBERT-based counterparts, while being magnitudes smaller in size and training\ndata requirements. For image classification, we show the effectiveness of the\ngraph embedding leveraging cross-modal knowledge transfer and show how this\nmethod is usable across different languages.",
            "author": [
                "Tom van Sonsbeek",
                "Xiantong Zhen",
                "Marcel Worring"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00917v2",
                "http://arxiv.org/pdf/2309.00917v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00904v2",
            "title": "Developmental Scaffolding with Large Language Models",
            "updated": "2023-11-22T17:39:59Z",
            "published": "2023-09-02T10:58:09Z",
            "summary": "Exploratoration and self-observation are key mechanisms of infant\nsensorimotor development. These processes are further guided by parental\nscaffolding accelerating skill and knowledge acquisition. In developmental\nrobotics, this approach has been adopted often by having a human acting as the\nsource of scaffolding. In this study, we investigate whether Large Language\nModels (LLMs) can act as a scaffolding agent for a robotic system that aims to\nlearn to predict the effects of its actions. To this end, an object\nmanipulation setup is considered where one object can be picked and placed on\ntop of or in the vicinity of another object. The adopted LLM is asked to guide\nthe action selection process through algorithmically generated state\ndescriptions and action selection alternatives in natural language. The\nsimulation experiments that include cubes in this setup show that LLM-guided\n(GPT3.5-guided) learning yields significantly faster discovery of novel\nstructures compared to random exploration. However, we observed that GPT3.5\nfails to effectively guide the robot in generating structures with different\naffordances such as cubes and spheres. Overall, we conclude that even without\nfine-tuning, LLMs may serve as a moderate scaffolding agent for improving robot\nlearning, however, they still lack affordance understanding which limits the\napplicability of the current LLMs in robotic scaffolding tasks.",
            "author": [
                "Batuhan Celik",
                "Alper Ahmetoglu",
                "Emre Ugur",
                "Erhan Oztop"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00904v2",
                "http://arxiv.org/pdf/2309.00904v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00902v1",
            "title": "Characterising 4-tangles through a connectivity property",
            "updated": "2023-09-02T10:39:50Z",
            "published": "2023-09-02T10:39:50Z",
            "summary": "Every large $k$-connected graph-minor induces a $k$-tangle in its ambient\ngraph. The converse holds for $k\\le 3$, but fails for $k\\ge 4$. This raises the\nquestion whether `$k$-connected' can be relaxed to obtain a characterisation of\n$k$-tangles through highly cohesive graph-minors. We show that this can be\nachieved for $k=4$ by proving that internally 4-connected graphs have unique\n4-tangles, and that every graph with a 4-tangle $\\tau$ has an internally\n4-connected minor whose unique 4-tangle lifts to~$\\tau$.",
            "author": [
                "Johannes Carmesin",
                "Jan Kurkofka"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00902v1",
                "http://arxiv.org/pdf/2309.00902v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C83 (Primary), 05C40, 05C05, 05C10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00900v2",
            "title": "Large Process Models: Business Process Management in the Age of\n  Generative AI",
            "updated": "2023-09-11T21:25:06Z",
            "published": "2023-09-02T10:32:53Z",
            "summary": "The continued success of Large Language Models (LLMs) and other generative\nartificial intelligence approaches highlights the advantages that large\ninformation corpora can have over rigidly defined symbolic models, but also\nserves as a proof-point of the challenges that purely statistics-based\napproaches have in terms of safety and trustworthiness. As a framework for\ncontextualizing the potential, as well as the limitations of LLMs and other\nfoundation model-based technologies, we propose the concept of a Large Process\nModel (LPM) that combines the correlation power of LLMs with the analytical\nprecision and reliability of knowledge-based systems and automated reasoning\napproaches. LPMs are envisioned to directly utilize the wealth of process\nmanagement experience that experts have accumulated, as well as process\nperformance data of organizations with diverse characteristics, e.g., regarding\nsize, region, or industry. In this vision, the proposed LPM would allow\norganizations to receive context-specific (tailored) process and other business\nmodels, analytical deep-dives, and improvement recommendations. As such, they\nwould allow to substantially decrease the time and effort required for business\ntransformation, while also allowing for deeper, more impactful, and more\nactionable insights than previously possible. We argue that implementing an LPM\nis feasible, but also highlight limitations and research challenges that need\nto be solved to implement particular aspects of the LPM vision.",
            "author": [
                "Timotheus Kampik",
                "Christian Warmuth",
                "Adrian Rebmann",
                "Ron Agam",
                "Lukas N. P. Egger",
                "Andreas Gerber",
                "Johannes Hoffart",
                "Jonas Kolk",
                "Philipp Herzig",
                "Gero Decker",
                "Han van der Aa",
                "Artem Polyvyanyy",
                "Stefanie Rinderle-Ma",
                "Ingo Weber",
                "Matthias Weidlich"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00900v2",
                "http://arxiv.org/pdf/2309.00900v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00876v1",
            "title": "A Multiscale Method for Two-Component, Two-Phase Flow with a Neural\n  Network Surrogate",
            "updated": "2023-09-02T09:37:06Z",
            "published": "2023-09-02T09:37:06Z",
            "summary": "Understanding the dynamics of phase boundaries in fluids requires\nquantitative knowledge about the microscale processes at the interface. We\nconsider the sharp-interface motion of compressible two-component flow, and\npropose a heterogeneous multiscale method (HMM) to describe the flow fields\naccurately. The multiscale approach combines a hyperbolic system of balance\nlaws on the continuum scale with molecular-dynamics simulations on the\nmicroscale level. Notably, the multiscale approach is necessary to compute the\ninterface dynamics because there is -- at present -- no closed continuum-scale\nmodel. The basic HMM relies on a moving-mesh finite-volume method, and has been\nintroduced recently for compressible one-component flow with phase transitions\nin [Magiera and Rohde, JCP. 469 (2022)]. To overcome the numerical complexity\nof the molecular-dynamics microscale model a deep neural network is employed as\nan efficient surrogate model. The entire approach is finally applied to\nsimulate droplet dynamics for argon-methane mixtures in several\nspace-dimensions. Up to our knowledge such compressible two-phase dynamics\naccounting for microscale phase-change transfer rates have not yet been\ncomputed.",
            "author": [
                "Jim Magiera",
                "Christian Rohde"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00876v1",
                "http://arxiv.org/pdf/2309.00876v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "physics.comp-ph",
                "physics.flu-dyn",
                "76T10, 65Z05, 35L65"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00862v1",
            "title": "Big-model Driven Few-shot Continual Learning",
            "updated": "2023-09-02T08:39:46Z",
            "published": "2023-09-02T08:39:46Z",
            "summary": "Few-shot continual learning (FSCL) has attracted intensive attention and\nachieved some advances in recent years, but now it is difficult to again make a\nbig stride in accuracy due to the limitation of only few-shot incremental\nsamples. Inspired by distinctive human cognition ability in life learning, in\nthis work, we propose a novel Big-model driven Few-shot Continual Learning\n(B-FSCL) framework to gradually evolve the model under the traction of the\nworld's big-models (like human accumulative knowledge). Specifically, we\nperform the big-model driven transfer learning to leverage the powerful\nencoding capability of these existing big-models, which can adapt the continual\nmodel to a few of newly added samples while avoiding the over-fitting problem.\nConsidering that the big-model and the continual model may have different\nperceived results for the identical images, we introduce an instance-level\nadaptive decision mechanism to provide the high-level flexibility cognitive\nsupport adjusted to varying samples. In turn, the adaptive decision can be\nfurther adopted to optimize the parameters of the continual model, performing\nthe adaptive distillation of big-model's knowledge information. Experimental\nresults of our proposed B-FSCL on three popular datasets (including CIFAR100,\nminilmageNet and CUB200) completely surpass all state-of-the-art FSCL methods.",
            "author": [
                "Ziqi Gu",
                "Chunyan Xu",
                "Zihan Lu",
                "Xin Liu",
                "Anbo Dai",
                "Zhen Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00862v1",
                "http://arxiv.org/pdf/2309.00862v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00859v1",
            "title": "DeepScaler: Holistic Autoscaling for Microservices Based on\n  Spatiotemporal GNN with Adaptive Graph Learning",
            "updated": "2023-09-02T08:22:21Z",
            "published": "2023-09-02T08:22:21Z",
            "summary": "Autoscaling functions provide the foundation for achieving elasticity in the\nmodern cloud computing paradigm. It enables dynamic provisioning or\nde-provisioning resources for cloud software services and applications without\nhuman intervention to adapt to workload fluctuations. However, autoscaling\nmicroservice is challenging due to various factors. In particular, complex,\ntime-varying service dependencies are difficult to quantify accurately and can\nlead to cascading effects when allocating resources. This paper presents\nDeepScaler, a deep learning-based holistic autoscaling approach for\nmicroservices that focus on coping with service dependencies to optimize\nservice-level agreements (SLA) assurance and cost efficiency. DeepScaler\nemploys (i) an expectation-maximization-based learning method to adaptively\ngenerate affinity matrices revealing service dependencies and (ii) an\nattention-based graph convolutional network to extract spatio-temporal features\nof microservices by aggregating neighbors' information of graph-structural\ndata. Thus DeepScaler can capture more potential service dependencies and\naccurately estimate the resource requirements of all services under dynamic\nworkloads. It allows DeepScaler to reconfigure the resources of the interacting\nservices simultaneously in one resource provisioning operation, avoiding the\ncascading effect caused by service dependencies. Experimental results\ndemonstrate that our method implements a more effective autoscaling mechanism\nfor microservice that not only allocates resources accurately but also adapts\nto dependencies changes, significantly reducing SLA violations by an average of\n41% at lower costs.",
            "author": [
                "Chunyang Meng",
                "Shijie Song",
                "Haogang Tong",
                "Maolin Pan",
                "Yang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00859v1",
                "http://arxiv.org/pdf/2309.00859v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00855v3",
            "title": "DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource\n  Real Estate Appraisal",
            "updated": "2023-09-14T09:24:28Z",
            "published": "2023-09-02T08:01:32Z",
            "summary": "The marketplace system connecting demands and supplies has been explored to\ndevelop unbiased decision-making in valuing properties. Real estate appraisal\nserves as one of the high-cost property valuation tasks for financial\ninstitutions since it requires domain experts to appraise the estimation based\non the corresponding knowledge and the judgment of the market. Existing\nautomated valuation models reducing the subjectivity of domain experts require\na large number of transactions for effective evaluation, which is predominantly\nlimited to not only the labeling efforts of transactions but also the\ngeneralizability of new developing and rural areas. To learn representations\nfrom unlabeled real estate sets, existing self-supervised learning (SSL) for\ntabular data neglects various important features, and fails to incorporate\ndomain knowledge. In this paper, we propose DoRA, a Domain-based\nself-supervised learning framework for low-resource Real estate Appraisal. DoRA\nis pre-trained with an intra-sample geographic prediction as the pretext task\nbased on the metadata of the real estate for equipping the real estate\nrepresentations with prior domain knowledge. Furthermore, inter-sample\ncontrastive learning is employed to generalize the representations to be robust\nfor limited transactions of downstream tasks. Our benchmark results on three\nproperty types of real-world transactions show that DoRA significantly\noutperforms the SSL baselines for tabular data, the graph-based methods, and\nthe supervised approaches in the few-shot scenarios by at least 7.6% for MAPE,\n11.59% for MAE, and 3.34% for HR10%. We expect DoRA to be useful to other\nfinancial practitioners with similar marketplace applications who need general\nmodels for properties that are newly built and have limited records. The source\ncode is available at https://github.com/wwweiwei/DoRA.",
            "author": [
                "Wei-Wei Du",
                "Wei-Yao Wang",
                "Wen-Chih Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00855v3",
                "http://arxiv.org/pdf/2309.00855v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00834v1",
            "title": "Approximating Fair $k$-Min-Sum-Radii in $\\mathbb{R}^d$",
            "updated": "2023-09-02T06:01:59Z",
            "published": "2023-09-02T06:01:59Z",
            "summary": "The $k$-center problem is a classical clustering problem in which one is\nasked to find a partitioning of a point set $P$ into $k$ clusters such that the\nmaximum radius of any cluster is minimized. It is well-studied. But what if we\nadd up the radii of the clusters instead of only considering the cluster with\nmaximum radius? This natural variant is called the $k$-min-sum-radii problem.\nIt has become the subject of more and more interest in recent years, inspiring\nthe development of approximation algorithms for the $k$-min-sum-radii problem\nin its plain version as well as in constrained settings.\n  We study the problem for Euclidean spaces $\\mathbb{R}^d$ of arbitrary\ndimension but assume the number $k$ of clusters to be constant. In this case, a\nPTAS for the problem is known (see Bandyapadhyay, Lochet and Saurabh, SoCG,\n2023). Our aim is to extend the knowledge base for $k$-min-sum-radii to the\ndomain of fair clustering. We study several group fairness constraints, such as\nthe one introduced by Chierichetti et al. (NeurIPS, 2017). In this model, input\npoints have an additional attribute (e.g., colors such as red and blue), and\nclusters have to preserve the ratio between different attribute values (e.g.,\nhave the same fraction of red and blue points as the ground set). Different\nvariants of this general idea have been studied in the literature. To the best\nof our knowledge, no approximative results for the fair $k$-min-sum-radii\nproblem are known, despite the immense amount of work on the related fair\n$k$-center problem.\n  We propose a PTAS for the fair $k$-min-sum-radii problem in Euclidean spaces\nof arbitrary dimension for the case of constant $k$. To the best of our\nknowledge, this is the first PTAS for the problem. It works for different\nnotions of group fairness.",
            "author": [
                "Lukas Drexler",
                "Annika Hennes",
                "Abhiruk Lahiri",
                "Melanie Schmidt",
                "Julian Wargalla"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00834v1",
                "http://arxiv.org/pdf/2309.00834v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00829v1",
            "title": "Characterizing the forbidden pairs for graphs to be super-edge-connected",
            "updated": "2023-09-02T05:28:59Z",
            "published": "2023-09-02T05:28:59Z",
            "summary": "Let $\\mathcal{H}$ be a set of given connected graphs. A graph $G$ is said to\nbe $\\mathcal{H}$-free if $G$ contains no $H$ as an induced subgraph for any\n$H\\in \\mathcal{H}$. The graph $G$ is super-edge-connected if each minimum\nedge-cut isolates a vertex in $G$. In this paper, except for some special\ngraphs, we characterize all forbidden subgraph sets $\\mathcal{H}$ such that\nevery $\\mathcal{H}$-free is super-edge-connected for $|\\mathcal{H}|=1$ and $2$.",
            "author": [
                "Hazhe Ye",
                "Yingzhi Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00829v1",
                "http://arxiv.org/pdf/2309.00829v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00828v1",
            "title": "When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with\n  Weak-and-Noisy Supervision",
            "updated": "2023-09-02T05:17:03Z",
            "published": "2023-09-02T05:17:03Z",
            "summary": "Learning from bounding-boxes annotations has shown great potential in\nweakly-supervised 3D point cloud instance segmentation. However, we observed\nthat existing methods would suffer severe performance degradation with\nperturbed bounding box annotations. To tackle this issue, we propose a\ncomplementary image prompt-induced weakly-supervised point cloud instance\nsegmentation (CIP-WPIS) method. CIP-WPIS leverages pretrained knowledge\nembedded in the 2D foundation model SAM and 3D geometric prior to achieve\naccurate point-wise instance labels from the bounding box annotations.\nSpecifically, CP-WPIS first selects image views in which 3D candidate points of\nan instance are fully visible. Then, we generate complementary background and\nforeground prompts from projections to obtain SAM 2D instance mask predictions.\nAccording to these, we assign the confidence values to points indicating the\nlikelihood of points belonging to the instance. Furthermore, we utilize 3D\ngeometric homogeneity provided by superpoints to decide the final instance\nlabel assignments. In this fashion, we achieve high-quality 3D point-wise\ninstance labels. Extensive experiments on both Scannet-v2 and S3DIS benchmarks\ndemonstrate that our method is robust against noisy 3D bounding-box annotations\nand achieves state-of-the-art performance.",
            "author": [
                "Qingtao Yu",
                "Heming Du",
                "Chen Liu",
                "Xin Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00828v1",
                "http://arxiv.org/pdf/2309.00828v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00824v1",
            "title": "Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic\n  Retinopathy Detection",
            "updated": "2023-09-02T04:42:08Z",
            "published": "2023-09-02T04:42:08Z",
            "summary": "Diabetic Retinopathy (DR) is a significant cause of blindness globally,\nhighlighting the urgent need for early detection and effective treatment.\nRecent advancements in Machine Learning (ML) techniques have shown promise in\nDR detection, but the availability of labeled data often limits their\nperformance. This research proposes a novel Semi-Supervised Graph Learning SSGL\nalgorithm tailored for DR detection, which capitalizes on the relationships\nbetween labelled and unlabeled data to enhance accuracy. The work begins by\ninvestigating data augmentation and preprocessing techniques to address the\nchallenges of image quality and feature variations. Techniques such as image\ncropping, resizing, contrast adjustment, normalization, and data augmentation\nare explored to optimize feature extraction and improve the overall quality of\nretinal images. Moreover, apart from detection and diagnosis, this work delves\ninto applying ML algorithms for predicting the risk of developing DR or the\nlikelihood of disease progression. Personalized risk scores for individual\npatients are generated using comprehensive patient data encompassing\ndemographic information, medical history, and retinal images. The proposed\nSemi-Supervised Graph learning algorithm is rigorously evaluated on two\npublicly available datasets and is benchmarked against existing methods.\nResults indicate significant improvements in classification accuracy,\nspecificity, and sensitivity while demonstrating robustness against noise and\noutlie rs.Notably, the proposed algorithm addresses the challenge of imbalanced\ndatasets, common in medical image analysis, further enhancing its practical\napplicability.",
            "author": [
                "D. Dhinakaran",
                "L. Srinivasan",
                "D. Selvaraj",
                "S. M. Udhaya Sankar"
            ],
            "link": [
                "http://dx.doi.org/10.14445/23488549/IJECE-V10I8P102",
                "http://arxiv.org/abs/2309.00824v1",
                "http://arxiv.org/pdf/2309.00824v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00816v1",
            "title": "Trustworthiness-Driven Graph Convolutional Networks for Signed Network\n  Embedding",
            "updated": "2023-09-02T03:59:06Z",
            "published": "2023-09-02T03:59:06Z",
            "summary": "The problem of representing nodes in a signed network as low-dimensional\nvectors, known as signed network embedding (SNE), has garnered considerable\nattention in recent years. While several SNE methods based on graph\nconvolutional networks (GCN) have been proposed for this problem, we point out\nthat they significantly rely on the assumption that the decades-old balance\ntheory always holds in the real-world. To address this limitation, we propose a\nnovel GCN-based SNE approach, named as TrustSGCN, which corrects for incorrect\nembedding propagation in GCN by utilizing the trustworthiness on edge signs for\nhigh-order relationships inferred by the balance theory. The proposed approach\nconsists of three modules: (M1) generation of each node's extended ego-network;\n(M2) measurement of trustworthiness on edge signs; and (M3)\ntrustworthiness-aware propagation of embeddings. Furthermore, TrustSGCN learns\nthe node embeddings by leveraging two well-known societal theories, i.e.,\nbalance and status. The experiments on four real-world signed network datasets\ndemonstrate that TrustSGCN consistently outperforms five state-of-the-art\nGCN-based SNE methods. The code is available at\nhttps://github.com/kmj0792/TrustSGCN.",
            "author": [
                "Min-Jeong Kim",
                "Yeon-Chang Lee",
                "David Y. Kang",
                "Sang-Wook Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00816v1",
                "http://arxiv.org/pdf/2309.00816v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "68T01",
                "H.4.0; I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00790v1",
            "title": "PFL-LSTR: A privacy-preserving framework for driver intention inference\n  based on in-vehicle and out-vehicle information",
            "updated": "2023-09-02T01:51:41Z",
            "published": "2023-09-02T01:51:41Z",
            "summary": "Intelligent vehicle anticipation of the movement intentions of other drivers\ncan reduce collisions. Typically, when a human driver of another vehicle\n(referred to as the target vehicle) engages in specific behaviors such as\nchecking the rearview mirror prior to lane change, a valuable clue is therein\nprovided on the intentions of the target vehicle's driver. Furthermore, the\ntarget driver's intentions can be influenced and shaped by their driving\nenvironment. For example, if the target vehicle is too close to a leading\nvehicle, it may renege the lane change decision. On the other hand, a following\nvehicle in the target lane is too close to the target vehicle could lead to its\nreversal of the decision to change lanes. Knowledge of such intentions of all\nvehicles in a traffic stream can help enhance traffic safety. Unfortunately,\nsuch information is often captured in the form of images/videos. Utilization of\npersonally identifiable data to train a general model could violate user\nprivacy. Federated Learning (FL) is a promising tool to resolve this conundrum.\nFL efficiently trains models without exposing the underlying data. This paper\nintroduces a Personalized Federated Learning (PFL) model embedded a long\nshort-term transformer (LSTR) framework. The framework predicts drivers'\nintentions by leveraging in-vehicle videos (of driver movement, gestures, and\nexpressions) and out-of-vehicle videos (of the vehicle's surroundings -\nfrontal/rear areas). The proposed PFL-LSTR framework is trained and tested\nthrough real-world driving data collected from human drivers at Interstate 65\nin Indiana. The results suggest that the PFL-LSTR exhibits high adaptability\nand high precision, and that out-of-vehicle information (particularly, the\ndriver's rear-mirror viewing actions) is important because it helps reduce\nfalse positives and thereby enhances the precision of driver intention\ninference.",
            "author": [
                "Runjia Du",
                "Pei Li",
                "Sikai Chen",
                "Samuel Labi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00790v1",
                "http://arxiv.org/pdf/2309.00790v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00781v1",
            "title": "Structured Radial Basis Function Network: Modelling Diversity for\n  Multiple Hypotheses Prediction",
            "updated": "2023-09-02T01:27:53Z",
            "published": "2023-09-02T01:27:53Z",
            "summary": "Multi-modal regression is important in forecasting nonstationary processes or\nwith a complex mixture of distributions. It can be tackled with multiple\nhypotheses frameworks but with the difficulty of combining them efficiently in\na learning model. A Structured Radial Basis Function Network is presented as an\nensemble of multiple hypotheses predictors for regression problems. The\npredictors are regression models of any type that can form centroidal Voronoi\ntessellations which are a function of their losses during training. It is\nproved that this structured model can efficiently interpolate this tessellation\nand approximate the multiple hypotheses target distribution and is equivalent\nto interpolating the meta-loss of the predictors, the loss being a zero set of\nthe interpolation error. This model has a fixed-point iteration algorithm\nbetween the predictors and the centers of the basis functions. Diversity in\nlearning can be controlled parametrically by truncating the tessellation\nformation with the losses of individual predictors. A closed-form solution with\nleast-squares is presented, which to the authors knowledge, is the fastest\nsolution in the literature for multiple hypotheses and structured predictions.\nSuperior generalization performance and computational efficiency is achieved\nusing only two-layer neural networks as predictors controlling diversity as a\nkey component of success. A gradient-descent approach is introduced which is\nloss-agnostic regarding the predictors. The expected value for the loss of the\nstructured model with Gaussian basis functions is computed, finding that\ncorrelation between predictors is not an appropriate tool for diversification.\nThe experiments show outperformance with respect to the top competitors in the\nliterature.",
            "author": [
                "Alejandro Rodriguez Dominguez",
                "Muhammad Shahzad",
                "Xia Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00781v1",
                "http://arxiv.org/pdf/2309.00781v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "28-08, 28-11, 26B25, 26C15, 46A03, 46T12, 49Q05, 51-08, 60D05,\n  62J02, 62H10, 62-08, 68W25, 68T07, 68T20",
                "I.2.1; I.2.6; I.5.1; I.6.4; I.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00775v1",
            "title": "Contrastive Feature Masking Open-Vocabulary Vision Transformer",
            "updated": "2023-09-02T01:12:48Z",
            "published": "2023-09-02T01:12:48Z",
            "summary": "We present Contrastive Feature Masking Vision Transformer (CFM-ViT) - an\nimage-text pretraining methodology that achieves simultaneous learning of\nimage- and region-level representation for open-vocabulary object detection\n(OVD). Our approach combines the masked autoencoder (MAE) objective into the\ncontrastive learning objective to improve the representation for localization\ntasks. Unlike standard MAE, we perform reconstruction in the joint image-text\nembedding space, rather than the pixel space as is customary with the classical\nMAE method, which causes the model to better learn region-level semantics.\nMoreover, we introduce Positional Embedding Dropout (PED) to address scale\nvariation between image-text pretraining and detection finetuning by randomly\ndropping out the positional embeddings during pretraining. PED improves\ndetection performance and enables the use of a frozen ViT backbone as a region\nclassifier, preventing the forgetting of open-vocabulary knowledge during\ndetection finetuning. On LVIS open-vocabulary detection benchmark, CFM-ViT\nachieves a state-of-the-art 33.9 AP$r$, surpassing the best approach by 7.6\npoints and achieves better zero-shot detection transfer. Finally, CFM-ViT\nacquires strong image-level representation, outperforming the state of the art\non 8 out of 12 metrics on zero-shot image-text retrieval benchmarks.",
            "author": [
                "Dahun Kim",
                "Anelia Angelova",
                "Weicheng Kuo"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00775v1",
                "http://arxiv.org/pdf/2309.00775v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00768v1",
            "title": "Space-Time Block Preconditioning for Incompressible Resistive\n  Magnetohydrodynamics",
            "updated": "2023-09-02T00:26:12Z",
            "published": "2023-09-02T00:26:12Z",
            "summary": "This work develops a novel all-at-once space-time preconditioning approach\nfor resistive magnetohydrodynamics (MHD), with a focus on model problems\ntargeting fusion reactor design. We consider parallel-in-time due to the long\ntime domains required to capture the physics of interest, as well as the\ncomplexity of the underlying system and thereby computational cost of long-time\nintegration. To ameliorate this cost by using many processors, we thus develop\na novel approach to solving the whole space-time system that is parallelizable\nin both space and time. We develop a space-time block preconditioning for\nresistive MHD, following the space-time block preconditioning concept first\nintroduced by Danieli et al. in 2022 for incompressible flow, where an\neffective preconditioner for classic sequential time-stepping is extended to\nthe space-time setting. The starting point for our derivation is the continuous\nSchur complement preconditioner by Cyr et al. in 2021, which we proceed to\ngeneralise in order to produce, to our knowledge, the first space-time block\npreconditioning approach for the challenging equations governing incompressible\nresistive MHD. The numerical results are promising for the model problems of\nisland coalescence and tearing mode, with the overhead computational cost\nassociated with space-time preconditioning versus sequential time-stepping\nbeing modest and primarily in the range of 2x-5x, which is low for\nparallel-in-time schemes in general. Additionally, the scaling results for\ninner (linear) and outer (nonlinear) iterations are flat in the case of fixed\ntime-step size and only grow very slowly in the case of time-step refinement.",
            "author": [
                "Federico Danieli",
                "Ben S. Southworth",
                "Jacob B. Schroder"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00768v1",
                "http://arxiv.org/pdf/2309.00768v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65F08, 65Y05, 76W05, 65M60, 65M22"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00765v2",
            "title": "Sparse Graphical Designs via Linear Programming",
            "updated": "2023-09-15T04:57:00Z",
            "published": "2023-09-02T00:04:45Z",
            "summary": "Graphical designs are a framework for sampling and numerical integration of\nfunctions on graphs. In this note, we introduce a method to address the\ntrade-off between graphical design sparsity and accuracy. We show how to obtain\nsparse graphical designs via linear programming and design objective functions\nthat aim to maximize their accuracy. We showcase our approach using yellow\ntaxicab data from New York City.",
            "author": [
                "Hessa Al-Thani",
                "Catherine Babecki",
                "J. Carlos Mart\u00ednez Mori"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00765v2",
                "http://arxiv.org/pdf/2309.00765v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.CO",
                "90B80 (Primary), 90C27, 05C90 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00757v1",
            "title": "A Note on Hamiltonian-Intersecting Families of Graphs",
            "updated": "2023-09-01T23:07:39Z",
            "published": "2023-09-01T23:07:39Z",
            "summary": "How many graphs on an $n$-point set can we find such that any two have\nconnected intersection? Berger, Berkowitz, Devlin, Doppelt, Durham, Murthy and\nVemuri showed that the maximum is exactly $1/2^{n-1}$ of all graphs. Our aim in\nthis short note is to give a 'directed' version of this result; we show that a\nfamily of oriented graphs such that any two have strongly-connected\nintersection has size at most $1/3^n$ of all oriented graphs. We also show that\na family of graphs such that any two have Hamiltonian intersection has size at\nmost $1/2^n$ of all graphs, verifying a conjecture of the above authors.",
            "author": [
                "Imre Leader",
                "\u017darko Ran\u0111elovi\u0107",
                "Ta Sheng Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00757v1",
                "http://arxiv.org/pdf/2309.00757v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00738v2",
            "title": "Rethinking the Power of Graph Canonization in Graph Representation\n  Learning with Stability",
            "updated": "2023-11-03T19:44:04Z",
            "published": "2023-09-01T21:23:04Z",
            "summary": "The expressivity of Graph Neural Networks (GNNs) has been studied broadly in\nrecent years to reveal the design principles for more powerful GNNs. Graph\ncanonization is known as a typical approach to distinguish non-isomorphic\ngraphs, yet rarely adopted when developing expressive GNNs. This paper proposes\nto maximize the expressivity of GNNs by graph canonization, then the power of\nsuch GNNs is studies from the perspective of model stability. A stable GNN will\nmap similar graphs to close graph representations in the vectorial space, and\nthe stability of GNNs is critical to generalize their performance to unseen\ngraphs. We theoretically reveal the trade-off of expressivity and stability in\ngraph-canonization-enhanced GNNs. Then we introduce a notion of universal graph\ncanonization as the general solution to address the trade-off and characterize\na widely applicable sufficient condition to solve the universal graph\ncanonization. A comprehensive set of experiments demonstrates the effectiveness\nof the proposed method. In many popular graph benchmark datasets, graph\ncanonization successfully enhances GNNs and provides highly competitive\nperformance, indicating the capability and great potential of proposed method\nin general graph representation learning. In graph datasets where the\nsufficient condition holds, GNNs enhanced by universal graph canonization\nconsistently outperform GNN baselines and successfully improve the SOTA\nperformance up to $31\\%$, providing the optimal solution to numerous\nchallenging real-world graph analytical tasks like gene network representation\nlearning in bioinformatics.",
            "author": [
                "Zehao Dong",
                "Muhan Zhang",
                "Philip R. O. Payne",
                "Michael A Province",
                "Carlos Cruchaga",
                "Tianyu Zhao",
                "Fuhai Li",
                "Yixin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00738v2",
                "http://arxiv.org/pdf/2309.00738v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00724v1",
            "title": "Adaptive Gaussian Markov Random Fields for Child Mortality Estimation",
            "updated": "2023-09-01T20:15:56Z",
            "published": "2023-09-01T20:15:56Z",
            "summary": "The under-5 mortality rate (U5MR), a critical health indicator, is typically\nestimated from household surveys in lower and middle income countries.\nSpatio-temporal disaggregation of household survey data can lead to highly\nvariable estimates of U5MR, necessitating the usage of smoothing models which\nborrow information across space and time. The assumptions of common smoothing\nmodels may be unrealistic when certain time periods or regions are expected to\nhave shocks in mortality relative to their neighbors, which can lead to\noversmoothing of U5MR estimates. In this paper, we develop a spatial and\ntemporal smoothing approach based on Gaussian Markov random field models which\nincorporate knowledge of these expected shocks in mortality. We demonstrate the\npotential for these models to improve upon alternatives not incorporating\nknowledge of expected shocks in a simulation study. We apply these models to\nestimate U5MR in Rwanda at the national level from 1985-2019, a time period\nwhich includes the Rwandan civil war and genocide.",
            "author": [
                "Serge Aleshin-Guendel",
                "Jon Wakefield"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00724v1",
                "http://arxiv.org/pdf/2309.00724v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00709v1",
            "title": "Reinforcement Learning with Human Feedback for Realistic Traffic\n  Simulation",
            "updated": "2023-09-01T19:29:53Z",
            "published": "2023-09-01T19:29:53Z",
            "summary": "In light of the challenges and costs of real-world testing, autonomous\nvehicle developers often rely on testing in simulation for the creation of\nreliable systems. A key element of effective simulation is the incorporation of\nrealistic traffic models that align with human knowledge, an aspect that has\nproven challenging due to the need to balance realism and diversity. This works\naims to address this by developing a framework that employs reinforcement\nlearning with human preference (RLHF) to enhance the realism of existing\ntraffic models. This study also identifies two main challenges: capturing the\nnuances of human preferences on realism and the unification of diverse traffic\nsimulation models. To tackle these issues, we propose using human feedback for\nalignment and employ RLHF due to its sample efficiency. We also introduce the\nfirst dataset for realism alignment in traffic modeling to support such\nresearch. Our framework, named TrafficRLHF, demonstrates its proficiency in\ngenerating realistic traffic scenarios that are well-aligned with human\npreferences, as corroborated by comprehensive evaluations on the nuScenes\ndataset.",
            "author": [
                "Yulong Cao",
                "Boris Ivanovic",
                "Chaowei Xiao",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00709v1",
                "http://arxiv.org/pdf/2309.00709v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03083v1",
            "title": "Factoring complete graphs and hypergraphs into factors with few maximal\n  cliques",
            "updated": "2023-09-01T19:19:45Z",
            "published": "2023-09-01T19:19:45Z",
            "summary": "For integers $r,t\\geq2$ and $n\\geq1$ let $f_r(t,n)$ be the minimum, over all\nfactorizations of the complete $r$-uniform hypergraph of order $n$ into $t$\nfactors $H_1,\\dots,H_t$, of $\\sum_{i=1}^tc(H_i)$ where $c(H_i)$ is the number\nof maximal cliques in $H_i$. It is known that $f_2(2,n)=n+1$; in fact, if $G$\nis a graph of order $n$, then $c(G)+c(\\overline G)\\geq n+1$ with equality iff\n$\\omega(G)+\\alpha(G)=n+1$ where $\\omega$ is the clique number and $\\alpha$ the\nindependence number. In this paper we investigate $f_r(t,n)$ when $r>2$ or\n$t>2$. We also characterize graphs $G$ of order $n$ with $c(G)+c(\\overline\nG)=n+2$.",
            "author": [
                "Paul Erd\u0151s",
                "David P. Galvin",
                "Fred Galvin",
                "Michael M. Krieger"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03083v1",
                "http://arxiv.org/pdf/2309.03083v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C69 (Primary) 05C65 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00704v1",
            "title": "Nowhere-zero 8-flows in cyclically 5-edge-connected, flow-admissible\n  signed graphs",
            "updated": "2023-09-01T19:15:42Z",
            "published": "2023-09-01T19:15:42Z",
            "summary": "In 1983, Bouchet proved that every bidirected graph with a nowhere-zero\ninteger-flow has a nowhere-zero 216-flow, and conjectured that 216 could be\nreplaced with 6. This paper shows that for cyclically 5-edge-connected\nbidirected graphs that number can be replaced with 8.",
            "author": [
                "Matt DeVos",
                "Kathryn Nurse",
                "Robert S\u00e1mal"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00704v1",
                "http://arxiv.org/pdf/2309.00704v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00702v2",
            "title": "Accelerated Benders Decomposition and Local Branching for Dynamic\n  Maximum Covering Location Problems",
            "updated": "2023-10-25T21:44:42Z",
            "published": "2023-09-01T18:51:26Z",
            "summary": "The maximum covering location problem (MCLP) is a key problem in facility\nlocation, with many applications and variants. One such variant is the dynamic\n(or multi-period) MCLP, which considers the installation of facilities across\nmultiple time periods. To the best of our knowledge, no exact solution method\nhas been proposed to tackle large-scale instances of this problem. To that end,\nin this work, we expand upon the current state-of-the-art\nbranch-and-Benders-cut solution method in the static case, by exploring several\nacceleration techniques. Additionally, we propose a specialised local branching\nscheme, that uses a novel distance metric in its definition of subproblems and\nfeatures a new method for efficient and exact solving of the subproblems. These\nmethods are then compared through extensive computational experiments,\nhighlighting the strengths of the proposed methodologies.",
            "author": [
                "Steven Lamontagne",
                "Margarida Carvalho",
                "Ribal Atallah"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00702v2",
                "http://arxiv.org/pdf/2309.00702v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00700v1",
            "title": "Cross-temporal Detection of Novel Ransomware Campaigns: A Multi-Modal\n  Alert Approach",
            "updated": "2023-09-01T18:46:00Z",
            "published": "2023-09-01T18:46:00Z",
            "summary": "We present a novel approach to identify ransomware campaigns derived from\nattack timelines representations within victim networks. Malicious activity\nprofiles developed from multiple alert sources support the construction of\nalert graphs. This approach enables an effective and scalable representation of\nthe attack timelines where individual nodes represent malicious activity\ndetections with connections describing the potential attack paths. This work\ndemonstrates adaptability to different attack patterns through implementing a\nnovel method for parsing and classifying alert graphs while maintaining\nefficacy despite potentially low-dimension node features.",
            "author": [
                "Sathvik Murli",
                "Dhruv Nandakumar",
                "Prabhat Kumar Kushwaha",
                "Cheng Wang",
                "Christopher Redino",
                "Abdul Rahman",
                "Shalini Israni",
                "Tarun Singh",
                "Edward Bowen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00700v1",
                "http://arxiv.org/pdf/2309.00700v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00699v1",
            "title": "Geometric Deep Learning: a Temperature Based Analysis of Graph Neural\n  Networks",
            "updated": "2023-09-01T18:42:53Z",
            "published": "2023-09-01T18:42:53Z",
            "summary": "We examine a Geometric Deep Learning model as a thermodynamic system treating\nthe weights as non-quantum and non-relativistic particles. We employ the notion\nof temperature previously defined in [7] and study it in the various layers for\nGCN and GAT models. Potential future applications of our findings are\ndiscussed.",
            "author": [
                "M. Lapenna",
                "F. Faglioni",
                "F. Zanchetta",
                "R. Fioresi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00699v1",
                "http://arxiv.org/pdf/2309.00699v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00696v1",
            "title": "AAN: Attributes-Aware Network for Temporal Action Detection",
            "updated": "2023-09-01T18:35:31Z",
            "published": "2023-09-01T18:35:31Z",
            "summary": "The challenge of long-term video understanding remains constrained by the\nefficient extraction of object semantics and the modelling of their\nrelationships for downstream tasks. Although the CLIP visual features exhibit\ndiscriminative properties for various vision tasks, particularly in object\nencoding, they are suboptimal for long-term video understanding. To address\nthis issue, we present the Attributes-Aware Network (AAN), which consists of\ntwo key components: the Attributes Extractor and a Graph Reasoning block. These\ncomponents facilitate the extraction of object-centric attributes and the\nmodelling of their relationships within the video. By leveraging CLIP features,\nAAN outperforms state-of-the-art approaches on two popular action detection\ndatasets: Charades and Toyota Smarthome Untrimmed datasets.",
            "author": [
                "Rui Dai",
                "Srijan Das",
                "Michael S. Ryoo",
                "Francois Bremond"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00696v1",
                "http://arxiv.org/pdf/2309.00696v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00616v3",
            "title": "OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation",
            "updated": "2023-10-05T15:15:58Z",
            "published": "2023-09-01T17:59:56Z",
            "summary": "Current 3D open-vocabulary scene understanding methods mostly utilize\nwell-aligned 2D images as the bridge to learn 3D features with language.\nHowever, applying these approaches becomes challenging in scenarios where 2D\nimages are absent. In this work, we introduce a new pipeline, namely,\nOpenIns3D, which requires no 2D image inputs, for 3D open-vocabulary scene\nunderstanding at the instance level. The OpenIns3D framework employs a\n\"Mask-Snap-Lookup\" scheme. The \"Mask\" module learns class-agnostic mask\nproposals in 3D point clouds. The \"Snap\" module generates synthetic scene-level\nimages at multiple scales and leverages 2D vision language models to extract\ninteresting objects. The \"Lookup\" module searches through the outcomes of\n\"Snap\" with the help of Mask2Pixel maps, which contain the precise\ncorrespondence between 3D masks and synthetic images, to assign category names\nto the proposed masks. This 2D input-free and flexible approach achieves\nstate-of-the-art results on a wide range of indoor and outdoor datasets by a\nlarge margin. Moreover, OpenIns3D allows for effortless switching of 2D\ndetectors without re-training. When integrated with powerful 2D open-world\nmodels such as ODISE and GroundingDINO, excellent results were observed on\nopen-vocabulary instance segmentation. When integrated with LLM-powered 2D\nmodels like LISA, it demonstrates a remarkable capacity to process highly\ncomplex text queries which require intricate reasoning and world knowledge.\nProject page: https://zheninghuang.github.io/OpenIns3D/",
            "author": [
                "Zhening Huang",
                "Xiaoyang Wu",
                "Xi Chen",
                "Hengshuang Zhao",
                "Lei Zhu",
                "Joan Lasenby"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00616v3",
                "http://arxiv.org/pdf/2309.00616v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00588v1",
            "title": "Discrete Morphological Neural Networks",
            "updated": "2023-09-01T17:04:48Z",
            "published": "2023-09-01T17:04:48Z",
            "summary": "A classical approach to designing binary image operators is Mathematical\nMorphology (MM). We propose the Discrete Morphological Neural Networks (DMNN)\nfor binary image analysis to represent W-operators and estimate them via\nmachine learning. A DMNN architecture, which is represented by a Morphological\nComputational Graph, is designed as in the classical heuristic design of\nmorphological operators, in which the designer should combine a set of MM\noperators and Boolean operations based on prior information and theoretical\nknowledge. Then, once the architecture is fixed, instead of adjusting its\nparameters (i.e., structural elements or maximal intervals) by hand, we propose\na lattice gradient descent algorithm (LGDA) to train these parameters based on\na sample of input and output images under the usual machine learning approach.\nWe also propose a stochastic version of the LGDA that is more efficient, is\nscalable and can obtain small error in practical problems. The class\nrepresented by a DMNN can be quite general or specialized according to expected\nproperties of the target operator, i.e., prior information, and the semantic\nexpressed by algebraic properties of classes of operators is a differential\nrelative to other methods. The main contribution of this paper is the merger of\nthe two main paradigms for designing morphological operators: classical\nheuristic design and automatic design via machine learning. Thus, conciliating\nclassical heuristic morphological operator design with machine learning. We\napply the DMNN to recognize the boundary of digits with noise, and we discuss\nmany topics for future research.",
            "author": [
                "Diego Marcondes",
                "Junior Barrera"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00588v1",
                "http://arxiv.org/pdf/2309.00588v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00583v1",
            "title": "Geometry-Informed Neural Operator for Large-Scale 3D PDEs",
            "updated": "2023-09-01T16:59:21Z",
            "published": "2023-09-01T16:59:21Z",
            "summary": "We propose the geometry-informed neural operator (GINO), a highly efficient\napproach to learning the solution operator of large-scale partial differential\nequations with varying geometries. GINO uses a signed distance function and\npoint-cloud representations of the input shape and neural operators based on\ngraph and Fourier architectures to learn the solution operator. The graph\nneural operator handles irregular grids and transforms them into and from\nregular latent grids on which Fourier neural operator can be efficiently\napplied. GINO is discretization-convergent, meaning the trained model can be\napplied to arbitrary discretization of the continuous domain and it converges\nto the continuum operator as the discretization is refined. To empirically\nvalidate the performance of our method on large-scale simulation, we generate\nthe industry-standard aerodynamics dataset of 3D vehicle geometries with\nReynolds numbers as high as five million. For this large-scale 3D fluid\nsimulation, numerical methods are expensive to compute surface pressure. We\nsuccessfully trained GINO to predict the pressure on car surfaces using only\nfive hundred data points. The cost-accuracy experiments show a $26,000 \\times$\nspeed-up compared to optimized GPU-based computational fluid dynamics (CFD)\nsimulators on computing the drag coefficient. When tested on new combinations\nof geometries and boundary conditions (inlet velocities), GINO obtains a\none-fourth reduction in error rate compared to deep neural network approaches.",
            "author": [
                "Zongyi Li",
                "Nikola Borislavov Kovachki",
                "Chris Choy",
                "Boyi Li",
                "Jean Kossaifi",
                "Shourya Prakash Otta",
                "Mohammad Amin Nabian",
                "Maximilian Stadler",
                "Christian Hundt",
                "Kamyar Azizzadenesheli",
                "Anima Anandkumar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00583v1",
                "http://arxiv.org/pdf/2309.00583v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00564v2",
            "title": "Interpretation of High-Dimensional Linear Regression: Effects of\n  Nullspace and Regularization Demonstrated on Battery Data",
            "updated": "2023-09-06T17:35:10Z",
            "published": "2023-09-01T16:20:04Z",
            "summary": "High-dimensional linear regression is important in many scientific fields.\nThis article considers discrete measured data of underlying smooth latent\nprocesses, as is often obtained from chemical or biological systems.\nInterpretation in high dimensions is challenging because the nullspace and its\ninterplay with regularization shapes regression coefficients. The data's\nnullspace contains all coefficients that satisfy $\\mathbf{Xw}=\\mathbf{0}$, thus\nallowing very different coefficients to yield identical predictions. We\ndeveloped an optimization formulation to compare regression coefficients and\ncoefficients obtained by physical engineering knowledge to understand which\npart of the coefficient differences are close to the nullspace. This nullspace\nmethod is tested on a synthetic example and lithium-ion battery data. The case\nstudies show that regularization and z-scoring are design choices that, if\nchosen corresponding to prior physical knowledge, lead to interpretable\nregression results. Otherwise, the combination of the nullspace and\nregularization hinders interpretability and can make it impossible to obtain\nregression coefficients close to the true coefficients when there is a true\nunderlying linear model. Furthermore, we demonstrate that regression methods\nthat do not produce coefficients orthogonal to the nullspace, such as fused\nlasso, can improve interpretability. In conclusion, the insights gained from\nthe nullspace perspective help to make informed design choices for building\nregression models on high-dimensional data and reasoning about potential\nunderlying linear models, which are important for system optimization and\nimproving scientific understanding.",
            "author": [
                "Joachim Schaeffer",
                "Eric Lenz",
                "William C. Chueh",
                "Martin Z. Bazant",
                "Rolf Findeisen",
                "Richard D. Braatz"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.compchemeng.2023.108471",
                "http://arxiv.org/abs/2309.00564v2",
                "http://arxiv.org/pdf/2309.00564v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP",
                "stat.ME",
                "62J07, 62P99",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00563v1",
            "title": "Catalyst Property Prediction with CatBERTa: Unveiling Feature\n  Exploration Strategies through Large Language Models",
            "updated": "2023-09-01T16:18:55Z",
            "published": "2023-09-01T16:18:55Z",
            "summary": "Efficient catalyst screening necessitates predictive models for adsorption\nenergy, a key property of reactivity. However, prevailing methods, notably\ngraph neural networks (GNNs), demand precise atomic coordinates for\nconstructing graph representations, while integrating observable attributes\nremains challenging. This research introduces CatBERTa, an energy prediction\nTransformer model using textual inputs. Built on a pretrained Transformer\nencoder, CatBERTa processes human-interpretable text, incorporating target\nfeatures. Attention score analysis reveals CatBERTa's focus on tokens related\nto adsorbates, bulk composition, and their interacting atoms. Moreover,\ninteracting atoms emerge as effective descriptors for adsorption\nconfigurations, while factors such as bond length and atomic properties of\nthese atoms offer limited predictive contributions. By predicting adsorption\nenergy from the textual representation of initial structures, CatBERTa achieves\na mean absolute error (MAE) of 0.75 eV-comparable to vanilla Graph Neural\nNetworks (GNNs). Furthermore, the subtraction of the CatBERTa-predicted\nenergies effectively cancels out their systematic errors by as much as 19.3%\nfor chemically similar systems, surpassing the error reduction observed in\nGNNs. This outcome highlights its potential to enhance the accuracy of energy\ndifference predictions. This research establishes a fundamental framework for\ntext-based catalyst property prediction, without relying on graph\nrepresentations, while also unveiling intricate feature-property relationships.",
            "author": [
                "Janghoon Ock",
                "Chakradhar Guntuboina",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00563v1",
                "http://arxiv.org/pdf/2309.00563v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00550v1",
            "title": "NeMig -- A Bilingual News Collection and Knowledge Graph about Migration",
            "updated": "2023-09-01T15:59:14Z",
            "published": "2023-09-01T15:59:14Z",
            "summary": "News recommendation plays a critical role in shaping the public's worldviews\nthrough the way in which it filters and disseminates information about\ndifferent topics. Given the crucial impact that media plays in opinion\nformation, especially for sensitive topics, understanding the effects of\npersonalized recommendation beyond accuracy has become essential in today's\ndigital society. In this work, we present NeMig, a bilingual news collection on\nthe topic of migration, and corresponding rich user data. In comparison to\nexisting news recommendation datasets, which comprise a large variety of\nmonolingual news, NeMig covers articles on a single controversial topic,\npublished in both Germany and the US. We annotate the sentiment polarization of\nthe articles and the political leanings of the media outlets, in addition to\nextracting subtopics and named entities disambiguated through Wikidata. These\nfeatures can be used to analyze the effects of algorithmic news curation beyond\naccuracy-based performance, such as recommender biases and the creation of\nfilter bubbles. We construct domain-specific knowledge graphs from the news\ntext and metadata, thus encoding knowledge-level connections between articles.\nImportantly, while existing datasets include only click behavior, we collect\nuser socio-demographic and political information in addition to explicit click\nfeedback. We demonstrate the utility of NeMig through experiments on the tasks\nof news recommenders benchmarking, analysis of biases in recommenders, and news\ntrends analysis. NeMig aims to provide a useful resource for the news\nrecommendation community and to foster interdisciplinary research into the\nmultidimensional effects of algorithmic news curation.",
            "author": [
                "Andreea Iana",
                "Mehwish Alam",
                "Alexander Grote",
                "Nevena Nikolajevic",
                "Katharina Ludwig",
                "Philipp M\u00fcller",
                "Christof Weinhardt",
                "Heiko Paulheim"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00550v1",
                "http://arxiv.org/pdf/2309.00550v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00546v1",
            "title": "Bichromatic Perfect Matchings with Crossings",
            "updated": "2023-09-01T15:55:49Z",
            "published": "2023-09-01T15:55:49Z",
            "summary": "We consider bichromatic point sets with $n$ red and $n$ blue points and study\nstraight-line bichromatic perfect matchings on them. We show that every such\npoint set in convex position admits a matching with at least\n$\\frac{3n^2}{8}-\\frac{n}{2}+c$ crossings, for some $ -\\frac{1}{2} \\leq c \\leq\n\\frac{1}{8}$. This bound is tight since for any $k> \\frac{3n^2}{8}\n-\\frac{n}{2}+\\frac{1}{8}$ there exist bichromatic point sets that do not admit\nany perfect matching with $k$ crossings.",
            "author": [
                "Oswin Aichholzer",
                "Stefan Felsner",
                "Rosna Paul",
                "Manfred Scheucher",
                "Birgit Vogtenhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00546v1",
                "http://arxiv.org/pdf/2309.00546v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00524v1",
            "title": "On towers of Isogeny graphs with full level structure",
            "updated": "2023-09-01T15:25:47Z",
            "published": "2023-09-01T15:25:47Z",
            "summary": "Let $p,q,l$ be three distinct prime numbers and let $N$ be a positive integer\ncoprime to $pql$. For an integer $n\\ge 0$, we define the directed graph\n$X_l^q(p^nN)$ whose vertices are given by isomorphism classes of elliptic\ncurves over a finite field of characteristic $q$ equipped with a level $p^nN$\nstructure. The edges of $X_l^q(p^nN)$ are given by $l$-isogenies. We are\ninterested in when the connected components of $X_l^q(p^nN)$ give rise to a\ntower of Galois covers as $n$ varies. We show that only in the supersingular\ncase we do get a tower of Galois covers. We also study similar towers of\nisogeny graphs given by oriented supersingular curves, as introduced by\nCol\\`o-Kohel, enhanced with a level structure.",
            "author": [
                "Antonio Lei",
                "Katharina M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00524v1",
                "http://arxiv.org/pdf/2309.00524v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.CO",
                "05C25, 11G20, 11R23, 14G17, 14K02"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00519v2",
            "title": "Score and Rank Semi-Monotonicity for Closeness, Betweenness and Harmonic\n  Centrality",
            "updated": "2023-11-29T17:52:11Z",
            "published": "2023-09-01T15:17:29Z",
            "summary": "In the study of the behavior of centrality measures with respect to network\nmodifications, score monotonicity means that adding an arc increases the\ncentrality score of the target of the arc; rank monotonicity means that adding\nan arc improves the importance of the target of the arc relative to the\nremaining nodes. It is known that score and rank monotonicity hold in directed\ngraphs for almost all centrality measures. In undirected graphs one expects\nthat the corresponding properties (where both endpoints of the new edge enjoy\nthe increase in score/rank) hold when adding a new edge. However, recent\nresults have shown that in undirected networks this is not true: for many\ncentrality measures, it is possible to find situations where adding an edge\nreduces the rank of one of its two endpoints. In this paper we introduce a\nweaker condition for undirected networks, semi-monotonicity, in which just one\nof the endpoints of a new edge is required to enjoy score or rank monotonicity.\nWe show that this condition is satisfied by closeness and betweenness\ncentrality, and that harmonic centrality satisfies it in an even stronger\nsense.",
            "author": [
                "Paolo Boldi",
                "Davide D'Ascenzo",
                "Flavio Furia",
                "Sebastiano Vigna"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00519v2",
                "http://arxiv.org/pdf/2309.00519v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00513v1",
            "title": "A normative approach to radicalization in social networks",
            "updated": "2023-09-01T15:06:37Z",
            "published": "2023-09-01T15:06:37Z",
            "summary": "In recent decades, the massification of online social connections has made\ninformation globally accessible in a matter of seconds. Unfortunately, this has\nbeen accompanied by a dramatic surge in extreme opinions, without a clear\nsolution in sight. Using a model performing probabilistic inference in\nlarge-scale loopy graphs through exchange of messages between nodes, we show\nhow circularity in the social graph directly leads to radicalization and the\npolarization of opinions. We demonstrate that these detrimental effects could\nbe avoided by actively decorrelating the messages in social media feeds. This\napproach is based on an extension of Belief Propagation (BP) named Circular\nBelief Propagation (CBP) that can be trained to drastically improve inference\nwithin a cyclic graph. CBP was benchmarked using data from Facebook and\nTwitter. This approach could inspire new methods for preventing the viral\nspreading and amplification of misinformation online, improving the capacity of\nsocial networks to share knowledge globally without resorting to censorship.",
            "author": [
                "Vincent Bouttier",
                "Salom\u00e9 Leclercq",
                "Renaud Jardri",
                "Sophie Deneve"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00513v1",
                "http://arxiv.org/pdf/2309.00513v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00504v2",
            "title": "The Complexity of Cluster Vertex Splitting and Company",
            "updated": "2023-09-06T12:24:07Z",
            "published": "2023-09-01T14:51:28Z",
            "summary": "Clustering a graph when the clusters can overlap can be seen from three\ndifferent angles: We may look for cliques that cover the edges of the graph, we\nmay look to add or delete few edges to uncover the cluster structure, or we may\nsplit vertices to separate the clusters from each other. Splitting a vertex $v$\nmeans to remove it and to add two new copies of $v$ and to make each previous\nneighbor of $v$ adjacent with at least one of the copies. In this work, we\nstudy the underlying computational problems regarding the three angles to\noverlapping clusterings, in particular when the overlap is small. We show that\nthe above-mentioned covering problem, which also has been independently studied\nin different contexts,is NP-complete. Based on a previous so-called\ncritical-clique lemma, we leverage our hardness result to show that Cluster\nEditing with Vertex Splitting is also NP-complete, resolving an open question\nby Abu-Khzam et al. [ISCO 2018]. We notice, however, that the proof of the\ncritical-clique lemma is flawed and we give a counterexample. Our hardness\nresult also holds under a version of the critical-clique lemma to which we\ncurrently do not have a counterexample. On the positive side, we show that\nCluster Vertex Splitting admits a vertex-linear problem kernel with respect to\nthe number of splits.",
            "author": [
                "Alexander Firbas",
                "Alexander Dobler",
                "Fabian Holzer",
                "Jakob Schafellner",
                "Manuel Sorge",
                "Ana\u00efs Villedieu",
                "Monika Wi\u00dfmann"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00504v2",
                "http://arxiv.org/pdf/2309.00504v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00499v1",
            "title": "On the inversion of the momenta ray transform of symmetric tensors in\n  the plane",
            "updated": "2023-09-01T14:44:08Z",
            "published": "2023-09-01T14:44:08Z",
            "summary": "We present a reconstruction method which stably recovers some sufficiently\nsmooth, real valued, symmetric tensor fields compactly supported in the\nEuclidean plane, from knowledge of their non/attenuated momenta ray transform.\nThe reconstruction method extends Bukhgeim's $A$-analytic theory from an\nequation to a system.",
            "author": [
                "David Omogbhe",
                "Kamran Sadiq",
                "Alexandru Tamasan"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00499v1",
                "http://arxiv.org/pdf/2309.00499v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "Primary: 44A12, 35J56, Secondary: 45E05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00498v1",
            "title": "Application of Deep Learning Methods in Monitoring and Optimization of\n  Electric Power Systems",
            "updated": "2023-09-01T14:42:27Z",
            "published": "2023-09-01T14:42:27Z",
            "summary": "This PhD thesis thoroughly examines the utilization of deep learning\ntechniques as a means to advance the algorithms employed in the monitoring and\noptimization of electric power systems. The first major contribution of this\nthesis involves the application of graph neural networks to enhance power\nsystem state estimation. The second key aspect of this thesis focuses on\nutilizing reinforcement learning for dynamic distribution network\nreconfiguration. The effectiveness of the proposed methods is affirmed through\nextensive experimentation and simulations.",
            "author": [
                "Ognjen Kundacina"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00498v1",
                "http://arxiv.org/pdf/2309.00498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00493v1",
            "title": "Tensor products of multimatroids and a Brylawski-type formula for the\n  transition polynomial",
            "updated": "2023-09-01T14:37:58Z",
            "published": "2023-09-01T14:37:58Z",
            "summary": "Brylawski's tensor product formula expresses the Tutte polynomial of the\ntensor product of two graphs in terms of Tutte polynomials arising from the\ntensor factors. We are concerned with extensions of Brylawski's tensor product\nformula to the Bollobas-Riordan and transition polynomials of graphs embedded\nin surfaces. We give a tensor product formula for the multimatroid transition\npolynomial and show that Brylawski's formula and its topological analogues\narise as specialisations of this more general result.",
            "author": [
                "Iain Moffatt",
                "Steven Noble",
                "Maya Thompson"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00493v1",
                "http://arxiv.org/pdf/2309.00493v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00483v1",
            "title": "Geometry-aware Line Graph Transformer Pre-training for Molecular\n  Property Prediction",
            "updated": "2023-09-01T14:20:48Z",
            "published": "2023-09-01T14:20:48Z",
            "summary": "Molecular property prediction with deep learning has gained much attention\nover the past years. Owing to the scarcity of labeled molecules, there has been\ngrowing interest in self-supervised learning methods that learn generalizable\nmolecular representations from unlabeled data. Molecules are typically treated\nas 2D topological graphs in modeling, but it has been discovered that their 3D\ngeometry is of great importance in determining molecular functionalities. In\nthis paper, we propose the Geometry-aware line graph transformer (Galformer)\npre-training, a novel self-supervised learning framework that aims to enhance\nmolecular representation learning with 2D and 3D modalities. Specifically, we\nfirst design a dual-modality line graph transformer backbone to encode the\ntopological and geometric information of a molecule. The designed backbone\nincorporates effective structural encodings to capture graph structures from\nboth modalities. Then we devise two complementary pre-training tasks at the\ninter and intra-modality levels. These tasks provide properly supervised\ninformation and extract discriminative 2D and 3D knowledge from unlabeled\nmolecules. Finally, we evaluate Galformer against six state-of-the-art\nbaselines on twelve property prediction benchmarks via downstream fine-tuning.\nExperimental results show that Galformer consistently outperforms all baselines\non both classification and regression tasks, demonstrating its effectiveness.",
            "author": [
                "Peizhen Bai",
                "Xianyuan Liu",
                "Haiping Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00483v1",
                "http://arxiv.org/pdf/2309.00483v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00472v1",
            "title": "General and Practical Tuning Method for Off-the-Shelf Graph-Based Index:\n  SISAP Indexing Challenge Report by Team UTokyo",
            "updated": "2023-09-01T14:11:19Z",
            "published": "2023-09-01T14:11:19Z",
            "summary": "Despite the efficacy of graph-based algorithms for Approximate Nearest\nNeighbor (ANN) searches, the optimal tuning of such systems remains unclear.\nThis study introduces a method to tune the performance of off-the-shelf\ngraph-based indexes, focusing on the dimension of vectors, database size, and\nentry points of graph traversal. We utilize a black-box optimization algorithm\nto perform integrated tuning to meet the required levels of recall and Queries\nPer Second (QPS). We applied our approach to Task A of the SISAP 2023 Indexing\nChallenge and got second place in the 10M and 30M tracks. It improves\nperformance substantially compared to brute force methods. This research offers\na universally applicable tuning method for graph-based indexes, extending\nbeyond the specific conditions of the competition to broader uses.",
            "author": [
                "Yutaro Oguri",
                "Yusuke Matsui"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00472v1",
                "http://arxiv.org/pdf/2309.00472v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CV",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00462v1",
            "title": "New metrics for analyzing continual learners",
            "updated": "2023-09-01T13:53:33Z",
            "published": "2023-09-01T13:53:33Z",
            "summary": "Deep neural networks have shown remarkable performance when trained on\nindependent and identically distributed data from a fixed set of classes.\nHowever, in real-world scenarios, it can be desirable to train models on a\ncontinuous stream of data where multiple classification tasks are presented\nsequentially. This scenario, known as Continual Learning (CL) poses challenges\nto standard learning algorithms which struggle to maintain knowledge of old\ntasks while learning new ones. This stability-plasticity dilemma remains\ncentral to CL and multiple metrics have been proposed to adequately measure\nstability and plasticity separately. However, none considers the increasing\ndifficulty of the classification task, which inherently results in performance\nloss for any model. In that sense, we analyze some limitations of current\nmetrics and identify the presence of setup-induced forgetting. Therefore, we\npropose new metrics that account for the task's increasing difficulty. Through\nexperiments on benchmark datasets, we demonstrate that our proposed metrics can\nprovide new insights into the stability-plasticity trade-off achieved by models\nin the continual learning environment.",
            "author": [
                "Nicolas Michel",
                "Giovanni Chierchia",
                "Romain Negrel",
                "Jean-Fran\u00e7ois Bercher",
                "Toshihiko Yamasaki"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00462v1",
                "http://arxiv.org/pdf/2309.00462v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03092v1",
            "title": "Establishing Markov Equivalence in Cyclic Directed Graphs",
            "updated": "2023-09-01T13:44:39Z",
            "published": "2023-09-01T13:44:39Z",
            "summary": "We present a new, efficient procedure to establish Markov equivalence between\ndirected graphs that may or may not contain cycles under the\n\\textit{d}-separation criterion. It is based on the Cyclic Equivalence Theorem\n(CET) in the seminal works on cyclic models by Thomas Richardson in the mid\n'90s, but now rephrased from an ancestral perspective. The resulting\ncharacterization leads to a procedure for establishing Markov equivalence\nbetween graphs that no longer requires tests for d-separation, leading to a\nsignificantly reduced algorithmic complexity. The conceptually simplified\ncharacterization may help to reinvigorate theoretical research towards sound\nand complete cyclic discovery in the presence of latent confounders. This\nversion includes a correction to rule (iv) in Theorem 1, and the subsequent\nadjustment in part 2 of Algorithm 2.",
            "author": [
                "Tom Claassen",
                "Joris M. Mooij"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03092v1",
                "http://arxiv.org/pdf/2309.03092v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00456v2",
            "title": "Evaluating Animation Parameters for Morphing Edge Drawings",
            "updated": "2023-09-04T13:24:18Z",
            "published": "2023-09-01T13:39:34Z",
            "summary": "Partial edge drawings (PED) of graphs avoid edge crossings by subdividing\neach edge into three parts and representing only its stubs, i.e., the parts\nincident to the end-nodes. The morphing edge drawing model (MED) extends the\nPED drawing style by animations that smoothly morph each edge between its\nrepresentation as stubs and the one as a fully drawn segment while avoiding new\ncrossings. Participants of a previous study on MED (Misue and Akasaka, GD19)\nreported eye straining caused by the animation. We conducted a user study to\nevaluate how this effect is influenced by varying animation speed and animation\ndynamic by considering an easing technique that is commonly used in web design.\nOur results provide indications that the easing technique may help users in\nexecuting topology-based tasks accurately. The participants also expressed\nappreciation for the easing and a preference for a slow animation speed.",
            "author": [
                "Carla Binucci",
                "Henry F\u00f6rster",
                "Julia Katheder",
                "Alessandra Tappini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00456v2",
                "http://arxiv.org/pdf/2309.00456v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00438v1",
            "title": "A shape-based heuristic for the detection of urban block artifacts in\n  street networks",
            "updated": "2023-09-01T13:11:35Z",
            "published": "2023-09-01T13:11:35Z",
            "summary": "Street networks are ubiquitous components of cities, guiding their\ndevelopment and enabling movement from place to place; street networks are also\nthe critical components of many urban analytical methods. However, their graph\nrepresentation is often designed primarily for transportation purposes. This\nrepresentation is less suitable for other use cases where transportation\nnetworks need to be simplified as a mandatory pre-processing step, e.g., in the\ncase of morphological analysis, visual navigation, or drone flight routing.\nWhile the urgent demand for automated pre-processing methods comes from various\nfields, it is still an unsolved challenge. In this article, we tackle this\nchallenge by proposing a cheap computational heuristic for the identification\nof \"face artifacts\", i.e., geometries that are enclosed by transportation edges\nbut do not represent urban blocks. The heuristic is based on combining the\nfrequency distributions of shape compactness metrics and area measurements of\nstreet network face polygons. We test our method on 131 globally sampled large\ncities and show that it successfully identifies face artifacts in 89% of\nanalyzed cities. Our heuristic of detecting artifacts caused by data being\ncollected for another purpose is the first step towards an automated street\nnetwork simplification workflow. Moreover, the proposed face artifact index\nuncovers differences in structural rules guiding the development of cities in\ndifferent world regions.",
            "author": [
                "Martin Fleischmann",
                "Anastassia Vybornova"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00438v1",
                "http://arxiv.org/pdf/2309.00438v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00428v2",
            "title": "A Locality-based Neural Solver for Optical Motion Capture",
            "updated": "2023-09-04T09:21:14Z",
            "published": "2023-09-01T12:40:17Z",
            "summary": "We present a novel locality-based learning method for cleaning and solving\noptical motion capture data. Given noisy marker data, we propose a new\nheterogeneous graph neural network which treats markers and joints as different\ntypes of nodes, and uses graph convolution operations to extract the local\nfeatures of markers and joints and transform them to clean motions. To deal\nwith anomaly markers (e.g. occluded or with big tracking errors), the key\ninsight is that a marker's motion shows strong correlations with the motions of\nits immediate neighboring markers but less so with other markers, a.k.a.\nlocality, which enables us to efficiently fill missing markers (e.g. due to\nocclusion). Additionally, we also identify marker outliers due to tracking\nerrors by investigating their acceleration profiles. Finally, we propose a\ntraining regime based on representation learning and data augmentation, by\ntraining the model on data with masking. The masking schemes aim to mimic the\noccluded and noisy markers often observed in the real data. Finally, we show\nthat our method achieves high accuracy on multiple metrics across various\ndatasets. Extensive comparison shows our method outperforms state-of-the-art\nmethods in terms of prediction accuracy of occluded marker position error by\napproximately 20%, which leads to a further error reduction on the\nreconstructed joint rotations and positions by 30%. The code and data for this\npaper are available at https://github.com/non-void/LocalMoCap.",
            "author": [
                "Xiaoyu Pan",
                "Bowen Zheng",
                "Xinwei Jiang",
                "Guanglong Xu",
                "Xianli Gu",
                "Jingxiang Li",
                "Qilong Kou",
                "He Wang",
                "Tianjia Shao",
                "Kun Zhou",
                "Xiaogang Jin"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618148",
                "http://arxiv.org/abs/2309.00428v2",
                "http://arxiv.org/pdf/2309.00428v2"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00422v1",
            "title": "Declarative Reasoning on Explanations Using Constraint Logic Programming",
            "updated": "2023-09-01T12:31:39Z",
            "published": "2023-09-01T12:31:39Z",
            "summary": "Explaining opaque Machine Learning (ML) models is an increasingly relevant\nproblem. Current explanation in AI (XAI) methods suffer several shortcomings,\namong others an insufficient incorporation of background knowledge, and a lack\nof abstraction and interactivity with the user. We propose REASONX, an\nexplanation method based on Constraint Logic Programming (CLP). REASONX can\nprovide declarative, interactive explanations for decision trees, which can be\nthe ML models under analysis or global/local surrogate models of any black-box\nmodel. Users can express background or common sense knowledge using linear\nconstraints and MILP optimization over features of factual and contrastive\ninstances, and interact with the answer constraints at different levels of\nabstraction through constraint projection. We present here the architecture of\nREASONX, which consists of a Python layer, closer to the user, and a CLP layer.\nREASONX's core execution engine is a Prolog meta-program with declarative\nsemantics in terms of logic theories.",
            "author": [
                "Laura State",
                "Salvatore Ruggieri",
                "Franco Turini"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00422v1",
                "http://arxiv.org/pdf/2309.00422v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00386v1",
            "title": "Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals\n  Is PSPACE-Complete",
            "updated": "2023-09-01T10:49:19Z",
            "published": "2023-09-01T10:49:19Z",
            "summary": "We investigate the decidability of the ${0,\\infty}$ fragment of Timed\nPropositional Temporal Logic (TPTL). We show that the satisfiability checking\nof TPTL$^{0,\\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment\n(1-TPTL$^{0,\\infty}$) is strictly more expressive than Metric Interval Temporal\nLogic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we\nhave a strictly more expressive logic with computationally easier\nsatisfiability checking. To the best of our knowledge, TPTL$^{0,\\infty}$ is the\nfirst multi-variable fragment of TPTL for which satisfiability checking is\ndecidable without imposing any bounds/restrictions on the timed words (e.g.\nbounded variability, bounded time, etc.). The membership in PSPACE is obtained\nby a reduction to the emptiness checking problem for a new \"non-punctual\"\nsubclass of Alternating Timed Automata with multiple clocks called Unilateral\nVery Weak Alternating Timed Automata (VWATA$^{0,\\infty}$) which we prove to be\nin PSPACE. We show this by constructing a simulation equivalent\nnon-deterministic timed automata whose number of clocks is polynomial in the\nsize of the given VWATA$^{0,\\infty}$.",
            "author": [
                "Shankara Narayanan Krishna",
                "Khushraj Nanik Madnani",
                "Rupak Majumdar",
                "Paritosh K. Pandya"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00386v1",
                "http://arxiv.org/pdf/2309.00386v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CL",
                "cs.FL",
                "F.4; F.4.3; F.1.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00385v1",
            "title": "Dense Voxel 3D Reconstruction Using a Monocular Event Camera",
            "updated": "2023-09-01T10:46:57Z",
            "published": "2023-09-01T10:46:57Z",
            "summary": "Event cameras are sensors inspired by biological systems that specialize in\ncapturing changes in brightness. These emerging cameras offer many advantages\nover conventional frame-based cameras, including high dynamic range, high frame\nrates, and extremely low power consumption. Due to these advantages, event\ncameras have increasingly been adapted in various fields, such as frame\ninterpolation, semantic segmentation, odometry, and SLAM. However, their\napplication in 3D reconstruction for VR applications is underexplored. Previous\nmethods in this field mainly focused on 3D reconstruction through depth map\nestimation. Methods that produce dense 3D reconstruction generally require\nmultiple cameras, while methods that utilize a single event camera can only\nproduce a semi-dense result. Other single-camera methods that can produce dense\n3D reconstruction rely on creating a pipeline that either incorporates the\naforementioned methods or other existing Structure from Motion (SfM) or\nMulti-view Stereo (MVS) methods. In this paper, we propose a novel approach for\nsolving dense 3D reconstruction using only a single event camera. To the best\nof our knowledge, our work is the first attempt in this regard. Our preliminary\nresults demonstrate that the proposed method can produce visually\ndistinguishable dense 3D reconstructions directly without requiring pipelines\nlike those used by existing methods. Additionally, we have created a synthetic\ndataset with $39,739$ object scans using an event camera simulator. This\ndataset will help accelerate other relevant research in this field.",
            "author": [
                "Haodong Chen",
                "Vera Chung",
                "Li Tan",
                "Xiaoming Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICVR57957.2023.10169359",
                "http://arxiv.org/abs/2309.00385v1",
                "http://arxiv.org/pdf/2309.00385v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00384v2",
            "title": "BatchPrompt: Accomplish more with less",
            "updated": "2023-09-05T23:03:12Z",
            "published": "2023-09-01T10:44:36Z",
            "summary": "As the ever-increasing token limits of large language models (LLMs) have\nenabled long context as input, prompting with single data samples might no\nlonger an efficient way. A straightforward strategy improving efficiency is to\nbatch data within the token limit (e.g., 8k for gpt-3.5-turbo; 32k for GPT-4),\nwhich we call BatchPrompt. We have two initial observations for prompting with\nbatched data. First, we find that prompting with batched data in longer\ncontexts will inevitably lead to worse performance, compared to single-data\nprompting. Second, the performance of the language model is significantly\ncorrelated with the positions and order of the batched data, due to the\ncorresponding change in decoder context. To retain efficiency and overcome\nperformance loss, we propose Batch Permutation and Ensembling (BPE), and a\nnovel Self-reflection-guided EArly Stopping (SEAS) technique. Our comprehensive\nexperimental evaluation demonstrates that BPE can boost the performance of\nBatchPrompt with a striking margin on a range of popular NLP tasks, including\nquestion answering (Boolq), textual entailment (RTE), and duplicate questions\nidentification (QQP). These performances are even competitive with/higher than\nsingle-data prompting(SinglePrompt), while BatchPrompt requires much fewer LLM\ncalls and input tokens (For SinglePrompt v.s. BatchPrompt with batch size 32,\nusing just 9%-16% the number of LLM calls, Boolq accuracy 90.6% to 90.9% with\n27.4% tokens, QQP accuracy 87.2% to 88.4% with 18.6% tokens, RTE accuracy 91.5%\nto 91.1% with 30.8% tokens). To the best of our knowledge, this is the first\nwork to technically improve prompting efficiency of large language models. We\nhope our simple yet effective approach will shed light on the future research\nof large language models. The code will be released.",
            "author": [
                "Jianzhe Lin",
                "Maurice Diesendruck",
                "Liang Du",
                "Robin Abraham"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00384v2",
                "http://arxiv.org/pdf/2309.00384v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00382v2",
            "title": "Towards Cross-Provider Analysis of Transparency Information for Data\n  Protection",
            "updated": "2023-09-05T09:33:05Z",
            "published": "2023-09-01T10:36:09Z",
            "summary": "Transparency and accountability are indispensable principles for modern data\nprotection, from both, legal and technical viewpoints. Regulations such as the\nGDPR, therefore, require specific transparency information to be provided\nincluding, e.g., purpose specifications, storage periods, or legal bases for\npersonal data processing. However, it has repeatedly been shown that all too\noften, this information is practically hidden in legalese privacy policies,\nhindering data subjects from exercising their rights. This paper presents a\nnovel approach to enable large-scale transparency information analysis across\nservice providers, leveraging machine-readable formats and graph data science\nmethods. More specifically, we propose a general approach for building a\ntransparency analysis platform (TAP) that is used to identify data transfers\nempirically, provide evidence-based analyses of sharing clusters of more than\n70 real-world data controllers, or even to simulate network dynamics using\nsynthetic transparency information for large-scale data-sharing scenarios. We\nprovide the general approach for advanced transparency information analysis, an\nopen source architecture and implementation in the form of a queryable analysis\nplatform, and versatile analysis examples. These contributions pave the way for\nmore transparent data processing for data subjects, and evidence-based\nenforcement processes for data protection authorities. Future work can build\nupon our contributions to gain more insights into so-far hidden data-sharing\npractices.",
            "author": [
                "Elias Gr\u00fcnewald",
                "Johannes M. Halkenh\u00e4u\u00dfer",
                "Nicola Leschke",
                "Frank Pallas"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00382v2",
                "http://arxiv.org/pdf/2309.00382v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR",
                "cs.SE",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00378v1",
            "title": "Long-Term Memorability On Advertisements",
            "updated": "2023-09-01T10:27:04Z",
            "published": "2023-09-01T10:27:04Z",
            "summary": "Marketers spend billions of dollars on advertisements but to what end? At the\npurchase time, if customers cannot recognize a brand for which they saw an ad,\nthe money spent on the ad is essentially wasted. Despite its importance in\nmarketing, until now, there has been no study on the memorability of ads in the\nML literature. Most studies have been conducted on short-term recall (<5 mins)\non specific content types like object and action videos. On the other hand, the\nadvertising industry only cares about long-term memorability (a few hours or\nlonger), and advertisements are almost always highly multimodal, depicting a\nstory through its different modalities (text, images, and videos). With this\nmotivation, we conduct the first large scale memorability study consisting of\n1203 participants and 2205 ads covering 276 brands. Running statistical tests\nover different participant subpopulations and ad-types, we find many\ninteresting insights into what makes an ad memorable - both content and human\nfactors. For example, we find that brands which use commercials with fast\nmoving scenes are more memorable than those with slower scenes (p=8e-10) and\nthat people who use ad-blockers remember lower number of ads than those who\ndon't (p=5e-3). Further, with the motivation of simulating the memorability of\nmarketing materials for a particular audience, ultimately helping create one,\nwe present a novel model, Sharingan, trained to leverage real-world knowledge\nof LLMs and visual knowledge of visual encoders to predict the memorability of\na content. We test our model on all the prominent memorability datasets in\nliterature (both images and videos) and achieve state of the art across all of\nthem. We conduct extensive ablation studies across memory types, modality,\nbrand, and architectural choices to find insights into what drives memory.",
            "author": [
                "Harini S I",
                "Somesh Singh",
                "Yaman K Singla",
                "Aanisha Bhattacharyya",
                "Veeky Baths",
                "Changyou Chen",
                "Rajiv Ratn Shah",
                "Balaji Krishnamurthy"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00378v1",
                "http://arxiv.org/pdf/2309.00378v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00368v1",
            "title": "When Do Discourse Markers Affect Computational Sentence Understanding?",
            "updated": "2023-09-01T09:54:28Z",
            "published": "2023-09-01T09:54:28Z",
            "summary": "The capabilities and use cases of automatic natural language processing (NLP)\nhave grown significantly over the last few years. While much work has been\ndevoted to understanding how humans deal with discourse connectives, this\nphenomenon is understudied in computational systems. Therefore, it is important\nto put NLP models under the microscope and examine whether they can adequately\ncomprehend, process, and reason within the complexity of natural language. In\nthis chapter, we introduce the main mechanisms behind automatic sentence\nprocessing systems step by step and then focus on evaluating discourse\nconnective processing. We assess nine popular systems in their ability to\nunderstand English discourse connectives and analyze how context and language\nunderstanding tasks affect their connective comprehension. The results show\nthat NLP systems do not process all discourse connectives equally well and that\nthe computational processing complexity of different connective kinds is not\nalways consistently in line with the presumed complexity order found in human\nprocessing. In addition, while humans are more inclined to be influenced during\nthe reading procedure but not necessarily in the final comprehension\nperformance, discourse connectives have a significant impact on the final\naccuracy of NLP systems. The richer knowledge of connectives a system learns,\nthe more negative effect inappropriate connectives have on it. This suggests\nthat the correct explicitation of discourse connectives is important for\ncomputational natural language processing.",
            "author": [
                "Ruiqi Li",
                "Liesbeth Allein",
                "Damien Sileo",
                "Marie-Francine Moens"
            ],
            "link": [
                "http://dx.doi.org/10.1515/9783110790351",
                "http://arxiv.org/abs/2309.00368v1",
                "http://arxiv.org/pdf/2309.00368v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00367v2",
            "title": "Where Did the Gap Go? Reassessing the Long-Range Graph Benchmark",
            "updated": "2023-09-05T14:35:20Z",
            "published": "2023-09-01T09:47:33Z",
            "summary": "The recent Long-Range Graph Benchmark (LRGB, Dwivedi et al. 2022) introduced\na set of graph learning tasks strongly dependent on long-range interaction\nbetween vertices. Empirical evidence suggests that on these tasks Graph\nTransformers significantly outperform Message Passing GNNs (MPGNNs). In this\npaper, we carefully reevaluate multiple MPGNN baselines as well as the Graph\nTransformer GPS (Ramp\\'a\\v{s}ek et al. 2022) on LRGB. Through a rigorous\nempirical analysis, we demonstrate that the reported performance gap is\noverestimated due to suboptimal hyperparameter choices. It is noteworthy that\nacross multiple datasets the performance gap completely vanishes after basic\nhyperparameter optimization. In addition, we discuss the impact of lacking\nfeature normalization for LRGB's vision datasets and highlight a spurious\nimplementation of LRGB's link prediction metric. The principal aim of our paper\nis to establish a higher standard of empirical rigor within the graph machine\nlearning community.",
            "author": [
                "Jan T\u00f6nshoff",
                "Martin Ritzert",
                "Eran Rosenbluth",
                "Martin Grohe"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00367v2",
                "http://arxiv.org/pdf/2309.00367v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00361v1",
            "title": "Towards a \"Swiss Army Knife\" for Scalable User-Defined Temporal\n  $(k,\\mathcal{X})$-Core Analysis",
            "updated": "2023-09-01T09:37:18Z",
            "published": "2023-09-01T09:37:18Z",
            "summary": "Querying cohesive subgraphs on temporal graphs (e.g., social network, finance\nnetwork, etc.) with various conditions has attracted intensive research\ninterests recently. In this paper, we study a novel Temporal\n$(k,\\mathcal{X})$-Core Query (TXCQ) that extends a fundamental Temporal\n$k$-Core Query (TCQ) proposed in our conference paper by optimizing or\nconstraining an arbitrary metric $\\mathcal{X}$ of $k$-core, such as size,\nengagement, interaction frequency, time span, burstiness, periodicity, etc. Our\nobjective is to address specific TXCQ instances with conditions on different\n$\\mathcal{X}$ in a unified algorithm framework that guarantees scalability. For\nthat, this journal paper proposes a taxonomy of measurement\n$\\mathcal{X}(\\cdot)$ and achieve our objective using a two-phase framework\nwhile $\\mathcal{X}(\\cdot)$ is time-insensitive or time-monotonic. Specifically,\nPhase 1 still leverages the query processing algorithm of TCQ to induce all\ndistinct $k$-cores during a given time range, and meanwhile locates the \"time\nzones\" in which the cores emerge. Then, Phase 2 conducts fast local search and\n$\\mathcal{X}$ evaluation in each time zone with respect to the time\ninsensitivity or monotonicity of $\\mathcal{X}(\\cdot)$. By revealing two\ninsightful concepts named tightest time interval and loosest time interval that\nbound time zones, the redundant core induction and unnecessary $\\mathcal{X}$\nevaluation in a zone can be reduced dramatically. Our experimental results\ndemonstrate that TXCQ can be addressed as efficiently as TCQ, which achieves\nthe latest state-of-the-art performance, by using a general algorithm framework\nthat leaves $\\mathcal{X}(\\cdot)$ as a user-defined function.",
            "author": [
                "Ming Zhong",
                "Junyong Yang",
                "Yuanyuan Zhu",
                "Tieyun Qian",
                "Mengchi Liu",
                "Jeffrey Xu Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00361v1",
                "http://arxiv.org/pdf/2309.00361v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00349v1",
            "title": "Bespoke Nanoparticle Synthesis and Chemical Knowledge Discovery Via\n  Autonomous Experimentations",
            "updated": "2023-09-01T09:15:04Z",
            "published": "2023-09-01T09:15:04Z",
            "summary": "The optimization of nanomaterial synthesis using numerous synthetic variables\nis considered to be extremely laborious task because the conventional\ncombinatorial explorations are prohibitively expensive. In this work, we report\nan autonomous experimentation platform developed for the bespoke design of\nnanoparticles (NPs) with targeted optical properties. This platform operates in\na closed-loop manner between a batch synthesis module of NPs and a UV- Vis\nspectroscopy module, based on the feedback of the AI optimization modeling.\nWith silver (Ag) NPs as a representative example, we demonstrate that the\nBayesian optimizer implemented with the early stopping criterion can\nefficiently produce Ag NPs precisely possessing the desired absorption spectra\nwithin only 200 iterations (when optimizing among five synthetic reagents). In\naddition to the outstanding material developmental efficiency, the analysis of\nsynthetic variables further reveals a novel chemistry involving the effects of\ncitrate in Ag NP synthesis. The amount of citrate is a key to controlling the\ncompetitions between spherical and plate-shaped NPs and, as a result, affects\nthe shapes of the absorption spectra as well. Our study highlights both\ncapabilities of the platform to enhance search efficiencies and to provide a\nnovel chemical knowledge by analyzing datasets accumulated from the autonomous\nexperimentations.",
            "author": [
                "Hyuk Jun Yoo",
                "Nayeon Kim",
                "Heeseung Lee",
                "Daeho Kim",
                "Leslie Tiong Ching Ow",
                "Hyobin Nam",
                "Chansoo Kim",
                "Seung Yong Lee",
                "Kwan-Young Lee",
                "Donghun Kim",
                "Sang Soo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00349v1",
                "http://arxiv.org/pdf/2309.00349v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00343v2",
            "title": "Topological and nontopological degeneracies in generalized string-net\n  models",
            "updated": "2023-11-07T10:23:17Z",
            "published": "2023-09-01T09:02:46Z",
            "summary": "Generalized string-net models have been recently proposed in order to enlarge\nthe set of possible topological quantum phases emerging from the original\nstring-net construction. In the present work, we do not consider vertex\nexcitations and restrict to plaquette excitations, or fluxons, that satisfy\nimportant identities. We explain how to compute the energy-level degeneracies\nof the generalized string-net Hamiltonian associated to an arbitrary unitary\nfusion category. In contrast to the degeneracy of the ground state, which is\npurely topological, that of excited energy levels depends not only on the\nDrinfeld center of the category, but also on internal multiplicities obtained\nfrom the tube algebra defined from the category. For a noncommutative category,\nthese internal multiplicities result in extra nontopological degeneracies. Our\nresults are valid for any trivalent graph and any orientable surface. We\nillustrate our findings with nontrivial examples.",
            "author": [
                "Anna Ritz-Zwilling",
                "Jean-No\u00ebl Fuchs",
                "Steven H. Simon",
                "Julien Vidal"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00343v2",
                "http://arxiv.org/pdf/2309.00343v2"
            ],
            "primary_category": "cond-mat.other",
            "category": [
                "cond-mat.other",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00319v1",
            "title": "Analytical results for binary dynamics at the first post-Newtonian order\n  in Einstein-Cartan theory with the Weyssenhoff fluid",
            "updated": "2023-09-01T08:07:27Z",
            "published": "2023-09-01T08:07:27Z",
            "summary": "The quantum spin effects inside matter can be modeled via the Weyssenhoff\nfluid, which permits to unearth a formal analogy between general relativity and\nEinstein-Cartan theory at the first post-Newtonian order. In this framework, we\nprovide some analytical formulas pertaining to the dynamics of binary systems\nhaving the spins aligned perpendicular to the orbital plane. We derive the\nexpressions of the relative orbit and the coordinate time, which in turn allow\nto determine the gravitational waveform, and the energy and angular momentum\nfluxes. The potentialities of our results are presented in two astrophysical\napplications, where we compute: ($i$) the quantum spin contributions to the\nenergy flux and gravitational waveform during the inspiral phase; ($ii$) the\nmacroscopic angular momentum of one of the bodies starting from the\ntime-averaged energy flux and the knowledge of few timing parameters.",
            "author": [
                "Vittorio De Falco",
                "Emmanuele Battista"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevD.108.064032",
                "http://arxiv.org/abs/2309.00319v1",
                "http://arxiv.org/pdf/2309.00319v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        }
    }
]