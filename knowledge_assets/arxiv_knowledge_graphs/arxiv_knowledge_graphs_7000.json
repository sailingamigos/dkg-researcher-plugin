[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00313v1",
            "title": "Message Passing Based Block Sparse Signal Recovery for DOA Estimation\n  Using Large Arrays",
            "updated": "2023-09-01T07:53:51Z",
            "published": "2023-09-01T07:53:51Z",
            "summary": "This work deals with directional of arrival (DOA) estimation with a large\nantenna array. We first develop a novel signal model with a sparse system\ntransfer matrix using an inverse discrete Fourier transform (DFT) operation,\nwhich leads to the formulation of a structured block sparse signal recovery\nproblem with a sparse sensing matrix. This enables the development of a low\ncomplexity message passing based Bayesian algorithm with a factor graph\nrepresentation. Simulation results demonstrate the superior performance of the\nproposed method.",
            "author": [
                "Yiwen Mao",
                "Dawei Gao",
                "Qinghua Guo",
                "Ming Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00313v1",
                "http://arxiv.org/pdf/2309.00313v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00306v1",
            "title": "On the Aggregation of Rules for Knowledge Graph Completion",
            "updated": "2023-09-01T07:32:11Z",
            "published": "2023-09-01T07:32:11Z",
            "summary": "Rule learning approaches for knowledge graph completion are efficient,\ninterpretable and competitive to purely neural models. The rule aggregation\nproblem is concerned with finding one plausibility score for a candidate fact\nwhich was simultaneously predicted by multiple rules. Although the problem is\nubiquitous, as data-driven rule learning can result in noisy and large\nrulesets, it is underrepresented in the literature and its theoretical\nfoundations have not been studied before in this context. In this work, we\ndemonstrate that existing aggregation approaches can be expressed as marginal\ninference operations over the predicting rules. In particular, we show that the\ncommon Max-aggregation strategy, which scores candidates based on the rule with\nthe highest confidence, has a probabilistic interpretation. Finally, we propose\nan efficient and overlooked baseline which combines the previous strategies and\nis competitive to computationally more expensive approaches.",
            "author": [
                "Patrick Betz",
                "Stefan L\u00fcdtke",
                "Christian Meilicke",
                "Heiner Stuckenschmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00306v1",
                "http://arxiv.org/pdf/2309.00306v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00305v2",
            "title": "Efficient Surrogate Models for Materials Science Simulations: Machine\n  Learning-based Prediction of Microstructure Properties",
            "updated": "2023-11-14T10:44:15Z",
            "published": "2023-09-01T07:29:44Z",
            "summary": "Determining, understanding, and predicting the so-called structure-property\nrelation is an important task in many scientific disciplines, such as\nchemistry, biology, meteorology, physics, engineering, and materials science.\nStructure refers to the spatial distribution of, e.g., substances, material, or\nmatter in general, while property is a resulting characteristic that usually\ndepends in a non-trivial way on spatial details of the structure.\nTraditionally, forward simulations models have been used for such tasks.\nRecently, several machine learning algorithms have been applied in these\nscientific fields to enhance and accelerate simulation models or as surrogate\nmodels. In this work, we develop and investigate the applications of six\nmachine learning techniques based on two different datasets from the domain of\nmaterials science: data from a two-dimensional Ising model for predicting the\nformation of magnetic domains and data representing the evolution of dual-phase\nmicrostructures from the Cahn-Hilliard model. We analyze the accuracy and\nrobustness of all models and elucidate the reasons for the differences in their\nperformances. The impact of including domain knowledge through tailored\nfeatures is studied, and general recommendations based on the availability and\nquality of training data are derived from this.",
            "author": [
                "Binh Duong Nguyen",
                "Pavlo Potapenko",
                "Aytekin Dermici",
                "Kishan Govind",
                "S\u00e9bastien Bompas",
                "Stefan Sandfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00305v2",
                "http://arxiv.org/pdf/2309.00305v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00303v1",
            "title": "Optical Probing of Ultrafast Laser-Induced Solid-to-Overdense-Plasma\n  Transitions",
            "updated": "2023-09-01T07:26:52Z",
            "published": "2023-09-01T07:26:52Z",
            "summary": "Understanding the target dynamics during its interaction with a relativistic\nultrashort laser pulse is a challenging fundamental multi-physics problem\ninvolving at least atomic and solid-state physics, plasma physics, and laser\nphysics. Already, the properties of the so-called pre-plasma formed as the\nlaser pulse's rising edge ionizes the target are complicated to access in\nexperiments and modeling, and many aspects of this laser-induced transition\nfrom solid to overdense plasma over picosecond time scales are still open\nquestions. At the same time, applications like laser-driven ion acceleration\nrequire precise knowledge and control of the pre-plasma because the efficiency\nof the acceleration process itself crucially depends on the target properties\nat the arrival of the relativistic intensity peak of the pulse. By capturing\nthe dynamics of the initial stage of the interaction, we report on a detailed\nvisualization of the pre-plasma formation and evolution. Nanometer-thin\ndiamond-like carbon foils are shown to transition from solid to plasma during\nthe laser rising edge with intensities < 10^16 W/cm^2. Single-shot\nnear-infrared probe transmission measurements evidence sub-picosecond dynamics\nof an expanding plasma with densities above 10^23 cm^-3 (about 100 times the\ncritical plasma density). The complementarity of a solid-state interaction\nmodel and a kinetic plasma description provides deep insight into the interplay\nof ionization, collisions, and expansion.",
            "author": [
                "Yasmina Azamoum",
                "Georg Alexander Becker",
                "Sebastian Keppler",
                "Guillaume Duchateau",
                "Stefan Skupin",
                "Mickael Grech",
                "Fabrice Catoire",
                "Sebastian Hell",
                "Issa Tamer",
                "Marco Hornung",
                "Marco Hellwing",
                "Alexander Kessler",
                "Franck Schorcht",
                "Malte Christoph Kaluza"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00303v1",
                "http://arxiv.org/pdf/2309.00303v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00300v1",
            "title": "Identifiable Cognitive Diagnosis with Encoder-decoder for Modelling\n  Students' Performance",
            "updated": "2023-09-01T07:18:02Z",
            "published": "2023-09-01T07:18:02Z",
            "summary": "Cognitive diagnosis aims to diagnose students' knowledge proficiencies based\non their response scores on exam questions, which is the basis of many domains\nsuch as computerized adaptive testing. Existing cognitive diagnosis models\n(CDMs) follow a proficiency-response paradigm, which views diagnostic results\nas learnable embeddings that are the cause of students' responses and learns\nthe diagnostic results through optimization. However, such a paradigm can\neasily lead to unidentifiable diagnostic results and the explainability\noverfitting problem, which is harmful to the quantification of students'\nlearning performance. To address these problems, we propose a novel\nidentifiable cognitive diagnosis framework. Specifically, we first propose a\nflexible diagnostic module which directly diagnose identifiable and explainable\nexaminee traits and question features from response logs. Next, we leverage a\ngeneral predictive module to reconstruct response logs from the diagnostic\nresults to ensure the preciseness of the latter. We furthermore propose an\nimplementation of the framework, i.e., ID-CDM, to demonstrate the availability\nof the former. Finally, we demonstrate the identifiability, explainability and\npreciseness of diagnostic results of ID-CDM through experiments on four public\nreal-world datasets.",
            "author": [
                "Jiatong Li",
                "Qi Liu",
                "Fei Wang",
                "Jiayu Liu",
                "Zhenya Huang",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00300v1",
                "http://arxiv.org/pdf/2309.00300v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00298v1",
            "title": "Phenomenological models of Cosmic Ray transport in Galaxies",
            "updated": "2023-09-01T07:07:30Z",
            "published": "2023-09-01T07:07:30Z",
            "summary": "When examining the abundance of elements in the placid interstellar medium, a\ndeep hollow between helium and carbon becomes apparent. Notably, the fragile\nlight nuclei Lithium, Beryllium, and Boron (collectively known as LiBeB) are\nnot formed, with the exception of Li7, during the process of Big Bang\nnucleosynthesis, nor do they arise as byproducts of stellar lifecycles. In\ncontrast to the majority of elements, these species owe their existence to the\nmost energetic particles in the Universe. Cosmic rays, originating in the most\npowerful Milky Way's particle accelerators, reach the Earth after traversing\ntangled and lengthy paths spanning millions of years. During their journey,\nthese primary particles undergo transformations through collisions with\ninterstellar matter. This process, known as spallation, alters their\ncomposition and introduces secondary light elements in the cosmic-ray beam. In\nlight of this, the relatively large abundance of LiBeB in the cosmic radiation\nprovides remarkable insights into the mechanisms of particle acceleration, as\nwell as the micro-physics of confinement within galactic magnetic fields. These\nlecture notes are intended to equip readers with basic knowledge necessary for\nexamining the chemical and isotopic composition, as well as the energy spectra,\nof cosmic rays, finally fostering a more profound comprehension of the complex\nhigh-energy astrophysical processes occurring within our Galaxy.",
            "author": [
                "Carmelo Evoli",
                "Ulyana Dupletsa"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00298v1",
                "http://arxiv.org/pdf/2309.00298v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00289v1",
            "title": "A Spatial Sigma-Delta Approach to Mitigation of Power Amplifier\n  Distortions in Massive MIMO Downlink",
            "updated": "2023-09-01T06:52:00Z",
            "published": "2023-09-01T06:52:00Z",
            "summary": "In massive multiple-input multiple-output (MIMO) downlink systems, the\nphysical implementation of the base stations (BSs) requires the use of cheap\nand power-efficient power amplifiers (PAs) to avoid high hardware cost and high\npower consumption. However, such PAs usually have limited linear amplification\nranges. Nonlinear distortions arising from operation beyond the linear\namplification ranges can significantly degrade system performance. Existing\napproaches to handle the nonlinear distortions, such as digital predistortion\n(DPD), typically require accurate knowledge, or acquisition, of the PA transfer\nfunction. In this paper, we present a new concept for mitigation of the PA\ndistortions. Assuming a uniform linear array (ULA) at the BS, the idea is to\napply a Sigma-Delta ($\\Sigma \\Delta$) modulator to spatially shape the PA\ndistortions to the high-angle region. By having the system operating in the\nlow-angle region, the received signals are less affected by the PA distortions.\nTo demonstrate the potential of this spatial $\\Sigma \\Delta$ approach, we study\nthe application of our approach to the multi-user MIMO-orthogonal frequency\ndivision modulation (OFDM) downlink scenario. A symbol-level precoding (SLP)\nscheme and a zero-forcing (ZF) precoding scheme, with the new design\nrequirement by the spatial $\\Sigma \\Delta$ approach being taken into account,\nare developed. Numerical simulations are performed to show the effectiveness of\nthe developed $\\Sigma \\Delta$ precoding schemes.",
            "author": [
                "Yatao Liu",
                "Mingjie Shao",
                "Wing-Kin Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00289v1",
                "http://arxiv.org/pdf/2309.00289v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00284v1",
            "title": "Enhancing the vocal range of single-speaker singing voice synthesis with\n  melody-unsupervised pre-training",
            "updated": "2023-09-01T06:40:41Z",
            "published": "2023-09-01T06:40:41Z",
            "summary": "The single-speaker singing voice synthesis (SVS) usually underperforms at\npitch values that are out of the singer's vocal range or associated with\nlimited training samples. Based on our previous work, this work proposes a\nmelody-unsupervised multi-speaker pre-training method conducted on a\nmulti-singer dataset to enhance the vocal range of the single-speaker, while\nnot degrading the timbre similarity. This pre-training method can be deployed\nto a large-scale multi-singer dataset, which only contains audio-and-lyrics\npairs without phonemic timing information and pitch annotation. Specifically,\nin the pre-training step, we design a phoneme predictor to produce the\nframe-level phoneme probability vectors as the phonemic timing information and\na speaker encoder to model the timbre variations of different singers, and\ndirectly estimate the frame-level f0 values from the audio to provide the pitch\ninformation. These pre-trained model parameters are delivered into the\nfine-tuning step as prior knowledge to enhance the single speaker's vocal\nrange. Moreover, this work also contributes to improving the sound quality and\nrhythm naturalness of the synthesized singing voices. It is the first to\nintroduce a differentiable duration regulator to improve the rhythm naturalness\nof the synthesized voice, and a bi-directional flow model to improve the sound\nquality. Experimental results verify that the proposed SVS system outperforms\nthe baseline on both sound quality and naturalness.",
            "author": [
                "Shaohuan Zhou",
                "Xu Li",
                "Zhiyong Wu",
                "Ying Shan",
                "Helen Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00284v1",
                "http://arxiv.org/pdf/2309.00284v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00275v1",
            "title": "Technical Companion to Example-Based Procedural Modeling Using Graph\n  Grammars",
            "updated": "2023-09-01T06:10:57Z",
            "published": "2023-09-01T06:10:57Z",
            "summary": "This is a companion piece to my paper on \"Example-Based Procedural Modeling\nUsing Graph Grammars.\" This paper examines some of the theoretical issues in\nmore detail. This paper discusses some more complex parts of the\nimplementation, why certain algorithmic decisions were made, proves the\nalgorithm can solve certain classes of problems, and examines other interesting\ntheoretical questions.",
            "author": [
                "Paul Merrell"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00275v1",
                "http://arxiv.org/pdf/2309.00275v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00269v2",
            "title": "Co-Tuning of Cloud Infrastructure and Distributed Data Processing\n  Platforms",
            "updated": "2023-12-07T02:39:26Z",
            "published": "2023-09-01T06:00:46Z",
            "summary": "Distributed Data Processing Platforms (e.g., Hadoop, Spark, and Flink) are\nwidely used to store and process data in a cloud environment. These platforms\ndistribute the storage and processing of data among the computing nodes of a\ncloud. The efficient use of these platforms requires users to (i) configure the\ncloud i.e., determine the number and type of computing nodes, and (ii) tune the\nconfiguration parameters (e.g., data replication factor) of the platform.\nHowever, both these tasks require in-depth knowledge of the cloud\ninfrastructure and distributed data processing platforms. Therefore, in this\npaper, we first study the relationship between the configuration of the cloud\nand the configuration of distributed data processing platforms to determine how\ncloud configuration impacts platform configuration. After understanding the\nimpacts, we propose a co-tuning approach for recommending optimal\nco-configuration of cloud and distributed data processing platforms. The\nproposed approach utilizes machine learning and optimization techniques to\nmaximize the performance of the distributed data processing system deployed on\nthe cloud. We evaluated our approach for Hadoop, Spark, and Flink in a cluster\ndeployed on the OpenStack cloud. We used three benchmarking workloads\n(WordCount, Sort, and K-means) in our evaluation. Our results reveal that, in\ncomparison to default settings, our co-tuning approach reduces execution time\nby 17.5% and $ cost by 14.9% solely via configuration tuning.",
            "author": [
                "Isuru Dharmadasa",
                "Faheem Ullah"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00269v2",
                "http://arxiv.org/pdf/2309.00269v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00247v1",
            "title": "Further study on forbidden subgraphs of power graph",
            "updated": "2023-09-01T04:33:24Z",
            "published": "2023-09-01T04:33:24Z",
            "summary": "The undirected power graph (or simply power graph) of a group $G$, denoted by\n$P(G)$, is a graph whose vertices are the elements of the group $G$, in which\ntwo vertices $u$ and $v$ are adjacent if and only if either $u=v^m$ or $v=u^n$\nfor some positive integers $m$, $n$. Forbidden subgraph has a significant role\nin graph theory. In our previous work \\cite{cmm}, we consider five important\nclasses of forbidden subgraphs of power graph which include perfect graphs,\ncographs, chordal graphs, split graphs and threshold graphs. In this\ncommunication, we go even further in that way. This study, inspired by the\narticles \\cite{celmmp,dong,ck}, examines additional $4$ significant forbidden\nclasses, including chain graphs, diamond-free graphs, $\\{P_{5},\n\\overline{P_{5}}\\}$-free graphs and $\\{P_{2}\\cup P_{3}, \\overline{P_{2}\\cup\nP_{3}}\\}$-free graph. The finite groups whose power graphs are chain graphs,\ndiamond-free graphs, and $\\{P_{2}\\cup P_{3}, \\overline{P_{2}\\cup P_{3}}\\}$-free\ngraphs have been successfully identified in this work. In case of $\\{P_{5},\n\\overline{P_{5}}\\}$-free graphs, we completely determine all the nilpotent\ngroups, direct product of two groups, finite simple groups whose power graph is\n$\\{P_{5}, \\overline{P_{5}}\\}$-free.",
            "author": [
                "Santanu Mandal",
                "Pallabi Manna"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00247v1",
                "http://arxiv.org/pdf/2309.00247v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00246v1",
            "title": "Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep\n  Learning Techniques",
            "updated": "2023-09-01T04:30:59Z",
            "published": "2023-09-01T04:30:59Z",
            "summary": "Social media platforms have revolutionized traditional communication\ntechniques by enabling people globally to connect instantaneously, openly, and\nfrequently. People use social media to share personal stories and express their\nopinion. Negative emotions such as thoughts of death, self-harm, and hardship\nare commonly expressed on social media, particularly among younger generations.\nAs a result, using social media to detect suicidal thoughts will help provide\nproper intervention that will ultimately deter others from self-harm and\ncommitting suicide and stop the spread of suicidal ideation on social media. To\ninvestigate the ability to detect suicidal thoughts in Arabic tweets\nautomatically, we developed a novel Arabic suicidal tweets dataset, examined\nseveral machine learning models, including Na\\\"ive Bayes, Support Vector\nMachine, K-Nearest Neighbor, Random Forest, and XGBoost, trained on word\nfrequency and word embedding features, and investigated the ability of\npre-trained deep learning models, AraBert, AraELECTRA, and AraGPT2, to identify\nsuicidal thoughts in Arabic tweets. The results indicate that SVM and RF models\ntrained on character n-gram features provided the best performance in the\nmachine learning models, with 86% accuracy and an F1 score of 79%. The results\nof the deep learning models show that AraBert model outperforms other machine\nand deep learning models, achieving an accuracy of 91\\% and an F1-score of 88%,\nwhich significantly improves the detection of suicidal ideation in the Arabic\ntweets dataset. To the best of our knowledge, this is the first study to\ndevelop an Arabic suicidality detection dataset from Twitter and to use\ndeep-learning approaches in detecting suicidality in Arabic posts.",
            "author": [
                "Asma Abdulsalam",
                "Areej Alhothali",
                "Saleh Al-Ghamdi"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00246v1",
                "http://arxiv.org/pdf/2309.00246v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00240v1",
            "title": "FactLLaMA: Optimizing Instruction-Following Language Models with\n  External Knowledge for Automated Fact-Checking",
            "updated": "2023-09-01T04:14:39Z",
            "published": "2023-09-01T04:14:39Z",
            "summary": "Automatic fact-checking plays a crucial role in combating the spread of\nmisinformation. Large Language Models (LLMs) and Instruction-Following\nvariants, such as InstructGPT and Alpaca, have shown remarkable performance in\nvarious natural language processing tasks. However, their knowledge may not\nalways be up-to-date or sufficient, potentially leading to inaccuracies in\nfact-checking. To address this limitation, we propose combining the power of\ninstruction-following language models with external evidence retrieval to\nenhance fact-checking performance. Our approach involves leveraging search\nengines to retrieve relevant evidence for a given input claim. This external\nevidence serves as valuable supplementary information to augment the knowledge\nof the pretrained language model. Then, we instruct-tune an open-sourced\nlanguage model, called LLaMA, using this evidence, enabling it to predict the\nveracity of the input claim more accurately. To evaluate our method, we\nconducted experiments on two widely used fact-checking datasets: RAWFC and\nLIAR. The results demonstrate that our approach achieves state-of-the-art\nperformance in fact-checking tasks. By integrating external evidence, we bridge\nthe gap between the model's knowledge and the most up-to-date and sufficient\ncontext available, leading to improved fact-checking outcomes. Our findings\nhave implications for combating misinformation and promoting the dissemination\nof accurate information on online platforms. Our released materials are\naccessible at: https://thcheung.github.io/factllama.",
            "author": [
                "Tsun-Hin Cheung",
                "Kin-Man Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00240v1",
                "http://arxiv.org/pdf/2309.00240v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00232v1",
            "title": "The Existence of Hamilton Cycle in n-Balanced k-Partite Graphs",
            "updated": "2023-09-01T03:24:26Z",
            "published": "2023-09-01T03:24:26Z",
            "summary": "Let $G_{k,n}$ be the $n$-balanced $k$-partite graph, whose vertex set can be\npartitioned into $k$ parts, each has $n$ vertices. In this paper, we prove that\nif $k \\geq 2,n \\geq 1$, for the edge set $E(G)$ of $G_{k,n}$ $$|E(G)|\n\\geq\\left\\{\\begin{array}{cc} 1 & \\text { if } k=2, n=1 n^{2} C_{k}^{2}-(k-1)\nn+2 & \\text { other } \\end{array}\\right.$$ then $G_{k,n}$ is hamiltonian. And\nthe result may be the best.",
            "author": [
                "Zongyuan Yang",
                "Yi Zhang",
                "Shichang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00232v1",
                "http://arxiv.org/pdf/2309.00232v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00215v1",
            "title": "Towards Addressing the Misalignment of Object Proposal Evaluation for\n  Vision-Language Tasks via Semantic Grounding",
            "updated": "2023-09-01T02:19:41Z",
            "published": "2023-09-01T02:19:41Z",
            "summary": "Object proposal generation serves as a standard pre-processing step in\nVision-Language (VL) tasks (image captioning, visual question answering, etc.).\nThe performance of object proposals generated for VL tasks is currently\nevaluated across all available annotations, a protocol that we show is\nmisaligned - higher scores do not necessarily correspond to improved\nperformance on downstream VL tasks. Our work serves as a study of this\nphenomenon and explores the effectiveness of semantic grounding to mitigate its\neffects. To this end, we propose evaluating object proposals against only a\nsubset of available annotations, selected by thresholding an annotation\nimportance score. Importance of object annotations to VL tasks is quantified by\nextracting relevant semantic information from text describing the image. We\nshow that our method is consistent and demonstrates greatly improved alignment\nwith annotations selected by image captioning metrics and human annotation when\ncompared against existing techniques. Lastly, we compare current detectors used\nin the Scene Graph Generation (SGG) benchmark as a use case, which serves as an\nexample of when traditional object proposal evaluation techniques are\nmisaligned.",
            "author": [
                "Joshua Feinglass",
                "Yezhou Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00215v1",
                "http://arxiv.org/pdf/2309.00215v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00196v2",
            "title": "A Comparative Study of Reference Reliability in Multiple Language\n  Editions of Wikipedia",
            "updated": "2023-09-04T10:25:48Z",
            "published": "2023-09-01T01:19:59Z",
            "summary": "Information presented in Wikipedia articles must be attributable to reliable\npublished sources in the form of references. This study examines over 5 million\nWikipedia articles to assess the reliability of references in multiple language\neditions. We quantify the cross-lingual patterns of the perennial sources list,\na collection of reliability labels for web domains identified and\ncollaboratively agreed upon by Wikipedia editors. We discover that some sources\n(or web domains) deemed untrustworthy in one language (i.e., English) continue\nto appear in articles in other languages. This trend is especially evident with\nsources tailored for smaller communities. Furthermore, non-authoritative\nsources found in the English version of a page tend to persist in other\nlanguage versions of that page. We finally present a case study on the Chinese,\nRussian, and Swedish Wikipedias to demonstrate a discrepancy in reference\nreliability across cultures. Our finding highlights future challenges in\ncoordinating global knowledge on source reliability.",
            "author": [
                "Aitolkyn Baigutanova",
                "Diego Saez-Trumper",
                "Miriam Redi",
                "Meeyoung Cha",
                "Pablo Arag\u00f3n"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615254",
                "http://arxiv.org/abs/2309.00196v2",
                "http://arxiv.org/pdf/2309.00196v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00190v1",
            "title": "Sprinkling with random regular graphs",
            "updated": "2023-09-01T01:09:39Z",
            "published": "2023-09-01T01:09:39Z",
            "summary": "We conjecture that the distribution of the edge-disjoint union of two random\nregular graphs on the same vertex set is asymptotically equivalent to a random\nregular graph of the combined degree, provided that the combined degree and the\ncomplementary degrees are growing. We verify this conjecture for the cases when\nthe graphs are sufficiently dense or sparse. We also prove an asymptotic\nformula for the expected number of spanning regular subgraphs in a random\nregular graph.",
            "author": [
                "Mikhail Isaev",
                "Brendan D. McKay",
                "Angus Southwell",
                "Maksim Zhukovskii"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00190v1",
                "http://arxiv.org/pdf/2309.00190v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00182v1",
            "title": "Generalized Ramsey numbers at the linear and quadratic thresholds",
            "updated": "2023-09-01T00:26:44Z",
            "published": "2023-09-01T00:26:44Z",
            "summary": "The generalized Ramsey number $f(n, p, q)$ is the smallest number of colors\nneeded to color the edges of the complete graph $K_n$ so that every $p$-clique\nspans at least $q$ colors. Erd\\H{o}s and Gy\\'arf\\'as showed that $f(n, p, q)$\ngrows linearly in $n$ when $p$ is fixed and $q=q_{\\text{lin}}(p):=\\binom\np2-p+3$. Similarly they showed that $f(n, p, q)$ is quadratic in $n$ when $p$\nis fixed and $q=q_{\\text{quad}}(p):=\\binom p2-\\frac p2+2$. In this note we\nimprove on the known estimates for $f(n, p, q_{\\text{lin}})$ and $f(n, p,\nq_{\\text{quad}})$. Our proofs involve establishing a significant strengthening\nof a previously known connection between $f(n, p, q)$ and another extremal\nproblem first studied by Brown, Erd\\H{o}s and S\\'os, as well as building on\nsome recent progress on this extremal problem by Delcourt and Postle and by\nShangguan. Also, our upper bound on $f(n, p, q_{\\text{lin}})$ follows from an\napplication of the recent forbidden submatchings method of Delcourt and Postle.",
            "author": [
                "Patrick Bennett",
                "Ryan Cushman",
                "Andrzej Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00182v1",
                "http://arxiv.org/pdf/2309.00182v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00172v1",
            "title": "Detecting Evidence of Organization in groups by Trajectories",
            "updated": "2023-08-31T23:57:02Z",
            "published": "2023-08-31T23:57:02Z",
            "summary": "Effective detection of organizations is essential for fighting crime and\nmaintaining public safety, especially considering the limited human resources\nand tools to deal with each group that exhibits co-movement patterns. This\npaper focuses on solving the Network Structure Inference (NSI) challenge. Thus,\nwe introduce two new approaches to detect network structure inferences based on\nagent trajectories. The first approach is based on the evaluation of graph\nentropy, while the second considers the quality of clustering indices. To\nevaluate the effectiveness of the new approaches, we conducted experiments\nusing four scenario simulations based on the animal kingdom, available on the\nNetLogo platform: Ants, Wolf Sheep Predation, Flocking, and Ant Adaptation.\nFurthermore, we compare the results obtained with those of an approach\npreviously proposed in the literature, applying all methods to simulations of\nthe NetLogo platform. The results demonstrate that our new detection approaches\ncan more clearly identify the inferences of organizations or networks in the\nsimulated scenarios.",
            "author": [
                "T. F. Silva",
                "J. E. B. Maia"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00172v1",
                "http://arxiv.org/pdf/2309.00172v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00168v3",
            "title": "Pose-Graph Attentional Graph Neural Network for Lidar Place Recognition",
            "updated": "2023-11-23T01:42:12Z",
            "published": "2023-08-31T23:17:44Z",
            "summary": "This paper proposes a pose-graph attentional graph neural network, called\nP-GAT, which compares (key)nodes between sequential and non-sequential\nsub-graphs for place recognition tasks as opposed to a common frame-to-frame\nretrieval problem formulation currently implemented in SOTA place recognition\nmethods. P-GAT uses the maximum spatial and temporal information between\nneighbour cloud descriptors -- generated by an existing encoder -- utilising\nthe concept of pose-graph SLAM. Leveraging intra- and inter-attention and graph\nneural network, P-GAT relates point clouds captured in nearby locations in\nEuclidean space and their embeddings in feature space. Experimental results on\nthe large-scale publically available datasets demonstrate the effectiveness of\nour approach in scenes lacking distinct features and when training and testing\nenvironments have different distributions (domain adaptation). Further, an\nexhaustive comparison with the state-of-the-art shows improvements in\nperformance gains. Code is available at\nhttps://github.com/csiro-robotics/P-GAT.",
            "author": [
                "Milad Ramezani",
                "Liang Wang",
                "Joshua Knights",
                "Zhibin Li",
                "Pauline Pounds",
                "Peyman Moghadam"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00168v3",
                "http://arxiv.org/pdf/2309.00168v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00164v1",
            "title": "Optimal Conditions for Environment-Assisted Quantum Transport on the\n  Fully Connected Network",
            "updated": "2023-08-31T23:00:11Z",
            "published": "2023-08-31T23:00:11Z",
            "summary": "We present a theoretical analysis of the efficiency and rate of excitation\ntransport on a network described by a complete graph in which every site is\nconnected to every other. The long-time transport properties are analytically\ncalculated for networks of arbitrary size that are symmetric except for the\ntrapping site, start with a range of initial states, and are subject to\ndephasing and excitation decay. Conditions for which dephasing increases\ntransport are identified, and optimal conditions are found for various physical\nparameters. The optimal conditions demonstrate robustness and a convergence of\ntimescales previously observed in the context of light-harvesting complexes.",
            "author": [
                "Sam Alterman",
                "Justin Berman",
                "Frederick W. Strauch"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00164v1",
                "http://arxiv.org/pdf/2309.00164v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00160v1",
            "title": "A Task-Interdependency Model of Complex Collaboration Towards\n  Human-Centered Crowd Work",
            "updated": "2023-08-31T22:37:47Z",
            "published": "2023-08-31T22:37:47Z",
            "summary": "Models of crowdsourcing and human computation often assume that individuals\nindependently carry out small, modular tasks. However, while these models have\nsuccessfully shown how crowds can accomplish significant objectives, they can\ninadvertently advance a less than human view of crowd workers and fail to\ncapture the unique human capacity for complex collaborative work. We present a\nmodel centered on interdependencies -- a phenomenon well understood to be at\nthe core of collaboration -- that allows one to formally reason about diverse\nchallenges to complex collaboration. Our model represents tasks as an\ninterdependent collection of subtasks, formalized as a task graph. We use it to\nexplain challenges to scaling complex collaborative work, underscore the\nimportance of expert workers, reveal critical factors for learning on the job,\nand explore the relationship between coordination intensity and occupational\nwages. Using data from O*NET and the Bureau of Labor Statistics, we introduce\nan index of occupational coordination intensity to validate our theoretical\npredictions. We present preliminary evidence that occupations with greater\ncoordination intensity are less exposed to displacement by AI, and discuss\nopportunities for models that emphasize the collaborative capacities of human\nworkers, bridge models of crowd work and traditional work, and promote AI in\nroles augmenting human collaboration.",
            "author": [
                "David T. Lee",
                "Christos A. Makridis"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00160v1",
                "http://arxiv.org/pdf/2309.00160v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.MA",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00133v1",
            "title": "Distraction-free Embeddings for Robust VQA",
            "updated": "2023-08-31T21:02:25Z",
            "published": "2023-08-31T21:02:25Z",
            "summary": "The generation of effective latent representations and their subsequent\nrefinement to incorporate precise information is an essential prerequisite for\nVision-Language Understanding (VLU) tasks such as Video Question Answering\n(VQA). However, most existing methods for VLU focus on sparsely sampling or\nfine-graining the input information (e.g., sampling a sparse set of frames or\ntext tokens), or adding external knowledge. We present a novel \"DRAX:\nDistraction Removal and Attended Cross-Alignment\" method to rid our cross-modal\nrepresentations of distractors in the latent space. We do not exclusively\nconfine the perception of any input information from various modalities but\ninstead use an attention-guided distraction removal method to increase focus on\ntask-relevant information in latent embeddings. DRAX also ensures semantic\nalignment of embeddings during cross-modal fusions. We evaluate our approach on\na challenging benchmark (SUTD-TrafficQA dataset), testing the framework's\nabilities for feature and event queries, temporal relation understanding,\nforecasting, hypothesis, and causal analysis through extensive experiments.",
            "author": [
                "Atharvan Dogra",
                "Deeksha Varshney",
                "Ashwin Kalyan",
                "Ameet Deshpande",
                "Neeraj Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00133v1",
                "http://arxiv.org/pdf/2309.00133v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12353v1",
            "title": "How Beaufort, Neumann and Gates met? Subject integration with\n  spreadsheeting",
            "updated": "2023-08-31T20:02:42Z",
            "published": "2023-08-31T20:02:42Z",
            "summary": "Computational thinking should be the fourth fundamental skill, along with\nreading, writing, and arithmetic (3R). To reach the level where computational\nthinking skills, especially digital problem solving have their own schemata,\nthere is a long way to go. In the present paper, a novel approach is detailed\nto support subject integration and building digital schemata, on the well-known\nBeaufort scale. The conversion of a traditional, paper-based problem and a data\nretrieval process are presented within the frame of a Grade 8 action research\nstudy. It is found that both students content knowledge and their digital\nskills developed more efficiently than in traditional course book and\ndecontextualized digital environments. Furthermore, the method presented here\ncan be adapted to any paper-based problems whose solutions would be more\neffective in a digital environment and which offer various forms for building\nschemata both in the subject matter and informatics.",
            "author": [
                "Maria Csernoch",
                "Julia Csernoch"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12353v1",
                "http://arxiv.org/pdf/2309.12353v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00106v1",
            "title": "In-situ Thermophysical Measurement of Flowing Molten Chloride Salt Using\n  Modulated Photothermal Radiometry",
            "updated": "2023-08-31T19:54:59Z",
            "published": "2023-08-31T19:54:59Z",
            "summary": "Molten salts are a leading candidate for high-temperature heat transfer\nfluids (HTFs) for thermal energy storage and conversion systems in concentrated\nsolar power (CSP) and nuclear energy power plants. The ability to probe molten\nsalt thermal transport properties in both stationary and flowing status is\nimportant for the evaluation of their heat transfer performance under realistic\noperational conditions, including the temperature range and potential\ndegradation due to corrosion and contamination. However, accurate thermal\ntransport properties are usually challenging to obtain even for stagnant molten\nsalts due to different sources of errors from convection, radiation, and\ncorrosion, let alone flowing ones. To the best of authors' knowledge, there is\nno available in-situ technique for measuring flowing molten salt thermal\nconductivity. Here, we report the first in-situ flowing molten salt thermal\nconductivity measurement using modulated photothermal radiometry (MPR). We\ncould successfully perform the first in-situ thermal conductivity measurement\nof flowing molten $NaCl-KCl-MgCl_2$ in the typical operating temperature (520\nand 580 $^oC$) with flow velocities ranging from around 0.3 to 1.0 $m$$s^-1$.\nThe relative change of the molten salt thermal conductivity was measured.\nGnielinski's correlation was also used to estimate the heat transfer\ncoefficient h of the flowing $NaCl-KCl-MgCl_2$ in the given experimental\ncondition. The work showed the potential of the MPR technique serving as an\nin-situ diagnostics tool to evaluate the heat transfer performance of flowing\nmolten salts and other high-temperature HTFs.",
            "author": [
                "Ka Man Chung",
                "Ye Zhang",
                "Jian Zeng",
                "Fouad Haddad",
                "Sarath Reddy Adapa",
                "Tianshi Feng",
                "Peiwen Li",
                "Renkun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00106v1",
                "http://arxiv.org/pdf/2309.00106v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.app-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00101v1",
            "title": "Manganese Dissolution in alkaline medium with and without concurrent\n  oxygen evolution in LiMn$_2$O$_4$",
            "updated": "2023-08-31T19:41:55Z",
            "published": "2023-08-31T19:41:55Z",
            "summary": "Manganese dissolution during the oxygen evolution reaction (OER) has been a\npersistent challenge that impedes the practical implementation of Mn-based\nelectrocatalysts including the LiMn$_x$O$_4$ system in aqueous alkaline\nelectrolyte. The investigated LiMn$_2$O$_4$ particles exhibit two distinct Mn\ndissolution processes; one independent of OER and the other associated to OER.\nCombining the bulk sensitive X-ray absorption spectroscopy, surface sensitive\nX-ray photoelectron spectroscopy and electrochemical detection of Mn\ndissolution using rotating ring-disk electrode, we explore the less understood\nMn dissolution mechanism during OER. We correlate near-surface oxidation with\nthe charge attributed to dissolved Mn, which demonstrates increasing Mn\ndissolution with the formation of surface Mn4+ species under anodic potential.\nThe observed stronger dissolution during the OER is attributed to the formation\nof additional Mn$^{4+}$ from Mn$^{3+}$ during OER. We show that control over\nthe amount of Mn4+ in Li$_x$Mn2O$_4$ before the onset of the OER can partially\nmitigate the OER-triggered dissolution. Overall, our atomistic insights into\nthe Mn dissolution processes are crucial for knowledge-guided mitigation of\nelectrocatalyst degradation, which can be broadly extended to manganese-based\noxide systems.",
            "author": [
                "Omeshwari Bisen",
                "Max Baumung",
                "Cynthia A. Volkert",
                "Marcel Risch"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00101v1",
                "http://arxiv.org/pdf/2309.00101v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00098v2",
            "title": "Dually conformal hypergraphs",
            "updated": "2023-09-28T17:49:31Z",
            "published": "2023-08-31T19:37:27Z",
            "summary": "Given a hypergraph $\\mathcal{H}$, the dual hypergraph of $\\mathcal{H}$ is the\nhypergraph of all minimal transversals of $\\mathcal{H}$. The dual hypergraph is\nalways Sperner, that is, no hyperedge contains another. A special case of\nSperner hypergraphs are the conformal Sperner hypergraphs, which correspond to\nthe families of maximal cliques of graphs. All these notions play an important\nrole in many fields of mathematics and computer science, including\ncombinatorics, algebra, database theory, etc. In this paper we study\nconformality of dual hypergraphs. While we do not settle the computational\ncomplexity status of recognizing this property, we show that the problem is in\nco-NP and can be solved in polynomial time for hypergraphs of bounded\ndimension. In the special case of dimension $3$, we reduce the problem to\n$2$-Satisfiability. Our approach has an implication in algorithmic graph\ntheory: we obtain a polynomial-time algorithm for recognizing graphs in which\nall minimal transversals of maximal cliques have size at most $k$, for any\nfixed $k$.",
            "author": [
                "Endre Boros",
                "Vladimir Gurvich",
                "Martin Milani\u010d",
                "Yushi Uno"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00098v2",
                "http://arxiv.org/pdf/2309.00098v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.CC",
                "cs.DM",
                "cs.DS",
                "05C65 (Primary) 05D15, 05C69, 05C85, 68R10, 05-08 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00095v1",
            "title": "Experimenting with ChatGPT for Spreadsheet Formula Generation: Evidence\n  of Risk in AI Generated Spreadsheets",
            "updated": "2023-08-31T19:31:32Z",
            "published": "2023-08-31T19:31:32Z",
            "summary": "Large Language Models (LLM) have become sophisticated enough that complex\ncomputer programs can be created through interpretation of plain English\nsentences and implemented in a variety of modern languages such as Python, Java\nScript, C++ and Spreadsheets. These tools are powerful and relatively accurate\nand therefore provide broad access to computer programming regardless of the\nbackground or knowledge of the individual using them. This paper presents a\nseries of experiments with ChatGPT to explore the tool's ability to produce\nvalid spreadsheet formulae and related computational outputs in situations\nwhere ChatGPT has to deduce, infer and problem solve the answer. The results\nshow that in certain circumstances, ChatGPT can produce correct spreadsheet\nformulae with correct reasoning, deduction and inference. However, when\ninformation is limited, uncertain or the problem is too complex, the accuracy\nof ChatGPT breaks down as does its ability to reason, infer and deduce. This\ncan also result in false statements and \"hallucinations\" that all subvert the\nprocess of creating spreadsheet formulae.",
            "author": [
                "Simon Thorne"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00095v1",
                "http://arxiv.org/pdf/2309.00095v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00059v1",
            "title": "STint: Self-supervised Temporal Interpolation for Geospatial Data",
            "updated": "2023-08-31T18:04:50Z",
            "published": "2023-08-31T18:04:50Z",
            "summary": "Supervised and unsupervised techniques have demonstrated the potential for\ntemporal interpolation of video data. Nevertheless, most prevailing temporal\ninterpolation techniques hinge on optical flow, which encodes the motion of\npixels between video frames. On the other hand, geospatial data exhibits lower\ntemporal resolution while encompassing a spectrum of movements and deformations\nthat challenge several assumptions inherent to optical flow. In this work, we\npropose an unsupervised temporal interpolation technique, which does not rely\non ground truth data or require any motion information like optical flow, thus\noffering a promising alternative for better generalization across geospatial\ndomains. Specifically, we introduce a self-supervised technique of dual cycle\nconsistency. Our proposed technique incorporates multiple cycle consistency\nlosses, which result from interpolating two frames between consecutive input\nframes through a series of stages. This dual cycle consistent constraint causes\nthe model to produce intermediate frames in a self-supervised manner. To the\nbest of our knowledge, this is the first attempt at unsupervised temporal\ninterpolation without the explicit use of optical flow. Our experimental\nevaluations across diverse geospatial datasets show that STint significantly\noutperforms existing state-of-the-art methods for unsupervised temporal\ninterpolation.",
            "author": [
                "Nidhin Harilal",
                "Bri-Mathias Hodge",
                "Aneesh Subramanian",
                "Claire Monteleoni"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00059v1",
                "http://arxiv.org/pdf/2309.00059v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00058v1",
            "title": "Bellybutton: Accessible and Customizable Deep-Learning Image\n  Segmentation",
            "updated": "2023-08-31T18:04:09Z",
            "published": "2023-08-31T18:04:09Z",
            "summary": "The conversion of raw images into quantifiable data can be a major hurdle in\nexperimental research, and typically involves identifying region(s) of\ninterest, a process known as segmentation. Machine learning tools for image\nsegmentation are often specific to a set of tasks, such as tracking cells, or\nrequire substantial compute or coding knowledge to train and use. Here we\nintroduce an easy-to-use (no coding required), image segmentation method, using\na 15-layer convolutional neural network that can be trained on a laptop:\nBellybutton. The algorithm trains on user-provided segmentation of example\nimages, but, as we show, just one or even a portion of one training image can\nbe sufficient in some cases. We detail the machine learning method and give\nthree use cases where Bellybutton correctly segments images despite substantial\nlighting, shape, size, focus, and/or structure variation across the regions(s)\nof interest. Instructions for easy download and use, with further details and\nthe datasets used in this paper are available at\npypi.org/project/Bellybuttonseg.",
            "author": [
                "Sam Dillavou",
                "Jesse M. Hanlan",
                "Anthony T. Chieco",
                "Hongyi Xiao",
                "Sage Fulco",
                "Kevin T. Turner",
                "Douglas J. Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00058v1",
                "http://arxiv.org/pdf/2309.00058v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00050v1",
            "title": "Illuminating the Dark Side of Cosmic Star Formation II. A second date\n  with RS-NIRdark galaxies in COSMOS",
            "updated": "2023-08-31T18:00:03Z",
            "published": "2023-08-31T18:00:03Z",
            "summary": "About 12 billion years ago, the Universe was first experiencing light again\nafter the dark ages, and galaxies filled the environment with stars, metals and\ndust. How efficient was this process? How fast did these primordial galaxies\nform stars and dust? We can answer these questions by tracing the Star\nFormation Rate Density (SFRD) back to its widely unknown high redshift tail,\ntraditionally observed in the Near-InfraRed (NIR), Optical and UV bands. Thus,\nthe objects with a high amount of dust were missing. We aim to fill this\nknowledge gap by studying Radio Selected NIR-dark (\\textit{RS-NIRdark})\nsources, i.e. sources not having a counterpart at UV-to-NIR wavelengths. We\nwiden the sample by Talia et al. (2021) from 197 to 272 objects in the COSMic\nevolution Survey (COSMOS) field, including also photometrically contaminated\nsources, previously excluded. Another important step forward consists in the\nvisual inspection of each source in the bands from u* to MIPS-24$\\mu$m.\nAccording to their \"environment\" in the different bands, we are able to\nhighlight different cases of study and calibrate an appropriate photometric\nprocedure for the objects affected by confusion issues. We estimate that the\ncontribution of RS-NIRdark to the Cosmic SFRD at 3$<$z$<$5 is $\\sim$10--25$\\%$\nof that based on UV-selected galaxies.",
            "author": [
                "Meriem Behiri",
                "Margherita Talia",
                "Andrea Cimatti",
                "Andrea Lapi",
                "Marcella Massardi",
                "Andrea F. Enia",
                "Cristian Vignali",
                "Matthieu Bethermin",
                "Andreas L. Faisst",
                "Fabrizio Gentile",
                "Marika Giulietti",
                "Carlotta Gruppioni",
                "Francesca Pozzi",
                "Vernesa Smolcic",
                "Gianni Zamorani"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00050v1",
                "http://arxiv.org/pdf/2309.00050v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16905v1",
            "title": "InterDiff: Generating 3D Human-Object Interactions with Physics-Informed\n  Diffusion",
            "updated": "2023-08-31T17:59:08Z",
            "published": "2023-08-31T17:59:08Z",
            "summary": "This paper addresses a novel task of anticipating 3D human-object\ninteractions (HOIs). Most existing research on HOI synthesis lacks\ncomprehensive whole-body interactions with dynamic objects, e.g., often limited\nto manipulating small or static objects. Our task is significantly more\nchallenging, as it requires modeling dynamic objects with various shapes,\ncapturing whole-body motion, and ensuring physically valid interactions. To\nthis end, we propose InterDiff, a framework comprising two key steps: (i)\ninteraction diffusion, where we leverage a diffusion model to encode the\ndistribution of future human-object interactions; (ii) interaction correction,\nwhere we introduce a physics-informed predictor to correct denoised HOIs in a\ndiffusion step. Our key insight is to inject prior knowledge that the\ninteractions under reference with respect to contact points follow a simple\npattern and are easily predictable. Experiments on multiple human-object\ninteraction datasets demonstrate the effectiveness of our method for this task,\ncapable of producing realistic, vivid, and remarkably long-term 3D HOI\npredictions.",
            "author": [
                "Sirui Xu",
                "Zhengyuan Li",
                "Yu-Xiong Wang",
                "Liang-Yan Gui"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16905v1",
                "http://arxiv.org/pdf/2308.16905v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16880v1",
            "title": "Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details",
            "updated": "2023-08-31T17:37:23Z",
            "published": "2023-08-31T17:37:23Z",
            "summary": "We propose Text2Scene, a method to automatically create realistic textures\nfor virtual scenes composed of multiple objects. Guided by a reference image\nand text descriptions, our pipeline adds detailed texture on labeled 3D\ngeometries in the room such that the generated colors respect the hierarchical\nstructure or semantic parts that are often composed of similar materials.\nInstead of applying flat stylization on the entire scene at a single step, we\nobtain weak semantic cues from geometric segmentation, which are further\nclarified by assigning initial colors to segmented parts. Then we add texture\ndetails for individual objects such that their projections on image space\nexhibit feature embedding aligned with the embedding of the input. The\ndecomposition makes the entire pipeline tractable to a moderate amount of\ncomputation resources and memory. As our framework utilizes the existing\nresources of image and text embedding, it does not require dedicated datasets\nwith high-quality textures designed by skillful artists. To the best of our\nknowledge, it is the first practical and scalable approach that can create\ndetailed and realistic textures of the desired style that maintain structural\ncontext for scenes with multiple objects.",
            "author": [
                "Inwoo Hwang",
                "Hyeonwoo Kim",
                "Young Min Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16880v1",
                "http://arxiv.org/pdf/2308.16880v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07138v1",
            "title": "Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders",
            "updated": "2023-08-31T17:35:42Z",
            "published": "2023-08-31T17:35:42Z",
            "summary": "The task of blind source separation (BSS) involves separating sources from a\nmixture without prior knowledge of the sources or the mixing system. This is a\nchallenging problem that often requires making restrictive assumptions about\nboth the mixing system and the sources. In this paper, we propose a novel\nmethod for addressing BSS of non-linear mixtures by leveraging the natural\nfeature subspace specialization ability of multi-encoder autoencoders with\nfully self-supervised learning without strong priors. During the training\nphase, our method unmixes the input into the separate encoding spaces of the\nmulti-encoder network and then remixes these representations within the decoder\nfor a reconstruction of the input. Then to perform source inference, we\nintroduce a novel encoding masking technique whereby masking out all but one of\nthe encodings enables the decoder to estimate a source signal. To this end, we\nalso introduce a so-called pathway separation loss that encourages sparsity\nbetween the unmixed encoding spaces throughout the decoder's layers and a\nso-called zero reconstruction loss on the decoder for coherent source\nestimations. In order to carefully evaluate our method, we conduct experiments\non a toy dataset and with real-world biosignal recordings from a\npolysomnography sleep study for extracting respiration.",
            "author": [
                "Matthew B. Webster",
                "Joonnyong Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07138v1",
                "http://arxiv.org/pdf/2309.07138v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16870v1",
            "title": "Learning Driver Models for Automated Vehicles via Knowledge Sharing and\n  Personalization",
            "updated": "2023-08-31T17:18:15Z",
            "published": "2023-08-31T17:18:15Z",
            "summary": "This paper describes a framework for learning Automated Vehicles (AVs) driver\nmodels via knowledge sharing between vehicles and personalization. The innate\nvariability in the transportation system makes it exceptionally challenging to\nexpose AVs to all possible driving scenarios during empirical experimentation\nor testing. Consequently, AVs could be blind to certain encounters that are\ndeemed detrimental to their safe and efficient operation. It is then critical\nto share knowledge across AVs that increase exposure to driving scenarios\noccurring in the real world. This paper explores a method to collaboratively\ntrain a driver model by sharing knowledge and borrowing strength across\nvehicles while retaining a personalized model tailored to the vehicle's unique\nconditions and properties. Our model brings a federated learning approach to\ncollaborate between multiple vehicles while circumventing the need to share raw\ndata between them. We showcase our method's performance in experimental\nsimulations. Such an approach to learning finds several applications across\ntransportation engineering including intelligent transportation systems,\ntraffic management, and vehicle-to-vehicle communication. Code and sample\ndataset are made available at the project page https://github.com/wissamkontar.",
            "author": [
                "Wissam Kontar",
                "Xinzhi Zhong",
                "Soyoung Ahn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16870v1",
                "http://arxiv.org/pdf/2308.16870v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16869v1",
            "title": "Some spectral comparison results on infinite quantum graphs",
            "updated": "2023-08-31T17:09:59Z",
            "published": "2023-08-31T17:09:59Z",
            "summary": "In this paper we establish spectral comparison results for Schr\\\"odinger\noperators on a certain class of infinite quantum graphs, using recent results\nobtained in the finite setting. We also show that new features do appear on\ninfinite quantum graphs such as a modified local Weyl law. In this sense, we\nregard this paper as a starting point for a more thorough investigation of\nspectral comparison results on more general infinite metric graphs.",
            "author": [
                "Patrizio Bifulco",
                "Joachim Kerner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16869v1",
                "http://arxiv.org/pdf/2308.16869v1"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math-ph",
                "math.MP",
                "34L05, 81Q35, 34L15, 34L20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16864v1",
            "title": "Global Optimization-Based Calibration Algorithm for a 2D Distributed\n  Hydrologic-Hydrodynamic and Water Quality Model",
            "updated": "2023-08-31T17:06:26Z",
            "published": "2023-08-31T17:06:26Z",
            "summary": "Hydrodynamic models with rain-on-the-grid capabilities are usually\ncomputationally expensive. This makes the use of automatic calibration\nalgorithms hard to apply due to the large number of model runs. However, with\nthe recent advances in parallel processing, computational resources, and\nincreasing high-resolution climatologic and GIS data, high-resolution\nhydrodynamic models can be used for optimization-based calibration. This paper\npresents a global optimization-based algorithm to calibrate a fully distributed\nhydrologic-hydrodynamic and water quality model (HydroPol2D) using observed\ndata (i.e., discharge, or pollutant concentration) as input. The algorithm can\nfind a near-optimal set of parameters to explain observed gauged data. The\nmodeling framework presented here, although applied in a poorly-gauged\ncatchment, can be adapted for catchments with more detailed observations. We\napplied the algorithm in different cases of the V-Tilted Catchment, the\nWooden-Board catchment, and in an existing urban catchment with heterogeneous\ndata. The results of automatic calibration indicate $\\mathrm{NSE} = 0.99$ for\nthe V-Tilted catchment, $\\mathrm{RMSE} = 830~\\mathrm{mgL^{-1}}$ for salt\nconcentration pollutographs (i.e., 8.3% of the event mean concentration), and\n$\\mathrm{NSE} = 0.89$ for the urban catchment case study. This paper also\nexplores the issue of equifinality in modeling calibration (EqMC). Equifinality\nis defined as the set of different parameter combinations that can provide\nequally good or accepted results, within the physical parameter ranges. EqMC\ndecreases with the number of events and increases with the choice of partially\nor nonproducing runoff ones. Furthermore, results indicate that providing more\naccurate parameter ranges based on a priori knowledge of the catchment is\nfundamental to reduce the chances of finding a set of parameters with\nequifinality.",
            "author": [
                "Marcus N. Gomes Jr.",
                "Marcio H. Giacomoni",
                "Fabricio A. R. Navarro",
                "Eduardo M. Mendiondo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16864v1",
                "http://arxiv.org/pdf/2308.16864v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "math.OC",
                "nlin.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16863v1",
            "title": "Self-pruning Graph Neural Network for Predicting Inflammatory Disease\n  Activity in Multiple Sclerosis from Brain MR Images",
            "updated": "2023-08-31T17:05:14Z",
            "published": "2023-08-31T17:05:14Z",
            "summary": "Multiple Sclerosis (MS) is a severe neurological disease characterized by\ninflammatory lesions in the central nervous system. Hence, predicting\ninflammatory disease activity is crucial for disease assessment and treatment.\nHowever, MS lesions can occur throughout the brain and vary in shape, size and\ntotal count among patients. The high variance in lesion load and locations\nmakes it challenging for machine learning methods to learn a globally effective\nrepresentation of whole-brain MRI scans to assess and predict disease.\nTechnically it is non-trivial to incorporate essential biomarkers such as\nlesion load or spatial proximity. Our work represents the first attempt to\nutilize graph neural networks (GNN) to aggregate these biomarkers for a novel\nglobal representation. We propose a two-stage MS inflammatory disease activity\nprediction approach. First, a 3D segmentation network detects lesions, and a\nself-supervised algorithm extracts their image features. Second, the detected\nlesions are used to build a patient graph. The lesions act as nodes in the\ngraph and are initialized with image features extracted in the first stage.\nFinally, the lesions are connected based on their spatial proximity and the\ninflammatory disease activity prediction is formulated as a graph\nclassification task. Furthermore, we propose a self-pruning strategy to\nauto-select the most critical lesions for prediction. Our proposed method\noutperforms the existing baseline by a large margin (AUCs of 0.67 vs. 0.61 and\n0.66 vs. 0.60 for one-year and two-year inflammatory disease activity,\nrespectively). Finally, our proposed method enjoys inherent explainability by\nassigning an importance score to each lesion for the overall prediction. Code\nis available at https://github.com/chinmay5/ms_ida.git",
            "author": [
                "Chinmay Prabhakar",
                "Hongwei Bran Li",
                "Johannes C. Paetzold",
                "Timo Loehr",
                "Chen Niu",
                "Mark M\u00fchlau",
                "Daniel Rueckert",
                "Benedikt Wiestler",
                "Bjoern Menze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16863v1",
                "http://arxiv.org/pdf/2308.16863v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16859v1",
            "title": "Information Theoretically Optimal Sample Complexity of Learning\n  Dynamical Directed Acyclic Graphs",
            "updated": "2023-08-31T17:03:34Z",
            "published": "2023-08-31T17:03:34Z",
            "summary": "In this article, the optimal sample complexity of learning the underlying\ninteraction/dependencies of a Linear Dynamical System (LDS) over a Directed\nAcyclic Graph (DAG) is studied. The sample complexity of learning a DAG's\nstructure is well-studied for static systems, where the samples of nodal states\nare independent and identically distributed (i.i.d.). However, such a study is\nless explored for DAGs with dynamical systems, where the nodal states are\ntemporally correlated. We call such a DAG underlying an LDS as \\emph{dynamical}\nDAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are\ndriven by unobserved exogenous noise sources that are wide-sense stationary\n(WSS) in time but are mutually uncorrelated, and have the same {power spectral\ndensity (PSD)}. Inspired by the static settings, a metric and an algorithm\nbased on the PSD matrix of the observed time series are proposed to reconstruct\nthe DDAG. The equal noise PSD assumption can be relaxed such that\nidentifiability conditions for DDAG reconstruction are not violated. For the\nLDS with WSS (sub) Gaussian exogenous noise sources, it is shown that the\noptimal sample complexity (or length of state trajectory) needed to learn the\nDDAG is $n=\\Theta(q\\log(p/q))$, where $p$ is the number of nodes and $q$ is the\nmaximum number of parents per node. To prove the sample complexity upper bound,\na concentration bound for the PSD estimation is derived, under two different\nsampling strategies. A matching min-max lower bound using generalized Fano's\ninequality also is provided, thus showing the order optimality of the proposed\nalgorithm.",
            "author": [
                "Mishfad Shaikh Veedu",
                "Deepjyoti Deka",
                "Murti V. Salapaka"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16859v1",
                "http://arxiv.org/pdf/2308.16859v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16851v1",
            "title": "Stress-linked pairs of vertices and the generic stress matroid",
            "updated": "2023-08-31T16:47:19Z",
            "published": "2023-08-31T16:47:19Z",
            "summary": "Given a graph $G$ and a mapping $p : V(G) \\rightarrow \\mathbb{R}^d$, we say\nthat the pair $(G,p)$ is a ($d$-dimensional) realization of $G$. Two\nrealizations $(G,p)$ and $(G,q)$ are equivalent if each of the point pairs\ncorresponding to the edges of $G$ have the same distance under the embeddings\n$p$ and $q$. A pair of vertices $\\{u,v\\}$ is globally linked in $G$ in\n$\\mathbb{R}^d$ if for every generic realization $(G,p)$ and every equivalent\nrealization $(G,q)$, $(G+uv,p)$ and $(G+uv,q)$ are also equivalent.\n  In this paper we introduce the notion of $d$-stress-linked vertex pairs.\nRoughly speaking, a pair of vertices $\\{u,v\\}$ is $d$-stress-linked in $G$ if\nthe edge $uv$ is generically stressed in $G+uv$ and for every generic\n$d$-dimensional realization $(G,p)$, every configuration $q$ that satisfies all\nof the equilibrium stresses of $(G,p)$ also satisfies the equilibrium stresses\nof $(G+uv,p)$. Among other results, we show that $d$-stress-linked vertex pairs\nare globally linked in $\\mathbb{R}^d$, and we give a combinatorial\ncharacterization of $2$-stress-linked vertex pairs that matches the conjecture\nof Jackson et al. about the characterization of globally linked pairs in\n$\\mathbb{R}^2$.\n  As a key tool, we introduce and study the \"algebraic dual\" of the\n$d$-dimensional generic rigidity matroid of a graph, which we call the\n$d$-dimensional generic stress matroid of the graph. We believe that our\nresults about this matroid, which describes the global behaviour of equilibrium\nstresses of generic realizations of $G$, may be of independent interest.\n  We use our results to give positive answers to conjectures of Jord\\'an,\nConnelly, and Grasegger et al.",
            "author": [
                "D\u00e1niel Garamv\u00f6lgyi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16851v1",
                "http://arxiv.org/pdf/2308.16851v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG",
                "math.MG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16849v1",
            "title": "The construction of a $E_7$-like quantum subgroup of $SU(3)$",
            "updated": "2023-08-31T16:30:20Z",
            "published": "2023-08-31T16:30:20Z",
            "summary": "In this short note we construct an embedding of the planar algebra for\n$\\overline{\\operatorname{Rep}(U_q(sl_3))}$ at $q = e^{2\\pi i \\frac{1}{24}}$\ninto the graph planar algebra of di Francesco and Zuber's candidate graph\n$\\mathcal{E}_4^{12}$. Via the graph planar algebra embedding theorem we thus\nconstruct a rank 11 module category over\n$\\overline{\\operatorname{Rep}(U_q(sl_3))}$ whose graph for action by the vector\nrepresentation is $\\mathcal{E}_4^{12}$. This fills a small gap in the\nliterature on the construction of $\\overline{\\operatorname{Rep}(U_q(sl_3))}$\nmodule categories. As a consequence of our construction, we obtain the\nprincipal graphs of subfactors constructed abstractly by Evans and Pugh.",
            "author": [
                "Cain Edie-Michell",
                "Lance Marinelli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16849v1",
                "http://arxiv.org/pdf/2308.16849v1"
            ],
            "primary_category": "math.QA",
            "category": [
                "math.QA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16845v2",
            "title": "Weight 2 cohomology of graph complexes of cyclic operads and the\n  handlebody group",
            "updated": "2023-10-05T15:56:58Z",
            "published": "2023-08-31T16:24:03Z",
            "summary": "We compute the weight 2 (resp. top$-2$) cohomology of the Feynman transforms\nof the cyclic (co)operads $\\mathsf{BV}$, $D\\mathsf{BV}$, $\\mathsf{Grav}$ and\n$\\mathsf{HyCom}$. Using a result of Giansiracusa we compute in particular the\nweight top$-2$-cohomology of the handlebody group. We compare the result to the\nweight top$-2$ cohomology of the moduli space of curves $\\mathcal{M}_{g,n}$,\nrecently computed by Payne and the last-named author. We also provide another\nproof of a recent result of Hainaut-Petersen identifying the\ntop-weight-cohomology of the handlebody group with the Kontsevich graph\ncohomology.",
            "author": [
                "Michael Borinsky",
                "Benjamin Br\u00fcck",
                "Thomas Willwacher"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16845v2",
                "http://arxiv.org/pdf/2308.16845v2"
            ],
            "primary_category": "math.QA",
            "category": [
                "math.QA",
                "math.AT",
                "math.GR",
                "18G85, 18M85, 20J06 (Primary), 57S25 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16841v1",
            "title": "The degrees of the orientation-preserving automorphism groups of\n  toroidal maps and hypermaps",
            "updated": "2023-08-31T16:20:43Z",
            "published": "2023-08-31T16:20:43Z",
            "summary": "This paper is an exploration of the faithful transitive permutation\nrepresentations of the orientation-preserving automorphisms groups of highly\nsymmetric toroidal maps and hypermaps. The main theorems of this paper give a\nlist of all possible degrees of these specific groups. This extends prior\naccomplishments of the authors, wherein their focus was confined to the study\nof the automorphisms groups of toroidal regular maps and hypermaps.\n  In addition the authors bring out the recently developed {\\sc GAP} package\n{\\sc corefreesub} that can be used to find faithful transitive permutation\nrepresentations of any group. With the aid of this powerful tool, the authors\nshow how Schreier coset graphs of the automorphism groups of toroidal maps and\nhypermaps can be easily constructed.",
            "author": [
                "Maria Elisa Fernandes",
                "Claudio Alexandre Piedade"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16841v1",
                "http://arxiv.org/pdf/2308.16841v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO",
                "05E18, 20B25, 52B11"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16837v1",
            "title": "Limited packings: related vertex partitions and duality issues",
            "updated": "2023-08-31T16:12:59Z",
            "published": "2023-08-31T16:12:59Z",
            "summary": "A $k$-limited packing partition ($k$LP partition) of a graph $G$ is a\npartition of $V(G)$ into $k$-limited packing sets. We consider the $k$LP\npartitions with minimum cardinality (with emphasis on $k=2$). The minimum\ncardinality is called $k$LP partition number of $G$ and denoted by\n$\\chi_{\\times k}(G)$. This problem is the dual problem of $k$-tuple domatic\npartitioning as well as a generalization of the well-studied $2$-distance\ncoloring problem in graphs.\n  We give the exact value of $\\chi_{\\times2}$ for trees and bound it for\ngeneral graphs. A section of this paper is devoted to the dual of this problem,\nwhere we give a solution to an open problem posed in $1998$. We also revisit\nthe total limited packing number in this paper and prove that the problem of\ncomputing this parameter is NP-hard even for some special families of graphs.\nWe give some inequalities concerning this parameter and discuss the difference\nbetween $2$TLP number and $2$LP number with emphasis on trees.",
            "author": [
                "Azam Sadat Ahmadi",
                "Nasrin Soltankhah",
                "Babak Samadi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16837v1",
                "http://arxiv.org/pdf/2308.16837v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16831v1",
            "title": "Motor crosslinking augments elasticity in active nematics",
            "updated": "2023-08-31T16:05:29Z",
            "published": "2023-08-31T16:05:29Z",
            "summary": "In active materials, uncoordinated internal stresses lead to emergent\nlong-range flows. An understanding of how the behavior of active materials\ndepends on mesoscopic (hydrodynamic) parameters is developing, but there\nremains a gap in knowledge concerning how hydrodynamic parameters depend on the\nproperties of microscopic elements. In this work, we combine experiments and\nmultiscale modeling to relate the structure and dynamics of active nematics\ncomposed of biopolymer filaments and molecular motors to their microscopic\nproperties, in particular motor processivity, speed, and valency. We show that\ncrosslinking of filaments by both motors and passive crosslinkers not only\naugments the contributions to nematic elasticity from excluded volume effects\nbut dominates them. By altering motor kinetics we show that a competition\nbetween motor speed and crosslinking results in a nonmonotonic dependence of\nnematic flow on motor speed. By modulating passive filament crosslinking we\nshow that energy transfer into nematic flow is in large part dictated by\ncrosslinking. Thus motor proteins both generate activity and contribute to\nnematic elasticity. Our results provide new insights for rationally engineering\nactive materials.",
            "author": [
                "Steven A. Redford",
                "Jonathan Colen",
                "Jordan L. Shivers",
                "Sasha Zemsky",
                "Mehdi Molaei",
                "Carlos Floyd",
                "Paul V. Ruijgrok",
                "Vincenzo Vitelli",
                "Zev Bryant",
                "Aaron R. Dinner",
                "Margaret L. Gardel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16831v1",
                "http://arxiv.org/pdf/2308.16831v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16830v1",
            "title": "On the Randi\u0107 index and its variants of network data",
            "updated": "2023-08-31T16:03:51Z",
            "published": "2023-08-31T16:03:51Z",
            "summary": "Summary statistics play an important role in network data analysis. They can\nprovide us with meaningful insight into the structure of a network. The\nRandi\\'{c} index is one of the most popular network statistics that has been\nwidely used for quantifying information of biological networks, chemical\nnetworks, pharmacologic networks, etc. A topic of current interest is to find\nbounds or limits of the Randi\\'{c} index and its variants. A number of bounds\nof the indices are available in literature. Recently, there are several\nattempts to study the limits of the indices in the Erd\\H{o}s-R\\'{e}nyi random\ngraph by simulation. In this paper, we shall derive the limits of the\nRandi\\'{c} index and its variants of an inhomogeneous Erd\\H{o}s-R\\'{e}nyi\nrandom graph. Our results charaterize how network heterogeneity affects the\nindices and provide new insights about the Randi\\'{c} index and its variants.\nFinally we apply the indices to several real-world networks.",
            "author": [
                "Mingao Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16830v1",
                "http://arxiv.org/pdf/2308.16830v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16827v1",
            "title": "Using 1-Factorization from Graph Theory for Quantum Speedups on Clique\n  Problems",
            "updated": "2023-08-31T15:59:35Z",
            "published": "2023-08-31T15:59:35Z",
            "summary": "The clique problems, including $k$-CLIQUE and Triangle Finding, form an\nimportant class of computational problems; the former is an NP-complete\nproblem, while the latter directly gives lower bounds for Matrix\nMultiplication. A number of previous efforts have approached these problems\nwith Quantum Computing methods, such as Amplitude Amplification. In this paper,\nwe provide new Quantum oracle designs based on the 1-factorization of complete\ngraphs, all of which have depth $O(n)$ instead of the $O(n^2)$ presented in\nprevious studies. Also, we discuss the usage of one of these oracles in\nbringing the Triangle Finding time complexity down to $O(n^{2.25} poly(log\nn))$, compared to the $O(n^{2.38})$ classical record. Finally, we benchmark the\nnumber of required Amplitude Amplification iterations for another presented\noracle, for solving $k$-CLIQUE.",
            "author": [
                "Ali Hadizadeh Moghadam",
                "Payman Kazemikhah",
                "Hossein Aghababa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16827v1",
                "http://arxiv.org/pdf/2308.16827v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16826v1",
            "title": "Visual Orbits & Alignments of Planet Hosting Binary Systems",
            "updated": "2023-08-31T15:56:39Z",
            "published": "2023-08-31T15:56:39Z",
            "summary": "Roughly half of Solar-type planet hosts have stellar companions, so\nunderstanding how these binary companions affect the formation and evolution of\nplanets is an important component to understanding planetary systems overall.\nMeasuring the dynamical properties of planet host binaries enables a valuable\ntest of planet formation in multi-star systems and requires knowledge of the\nbinary orbital parameters. Using high resolution imaging, we have measured the\nrelative astrometry and visual orbits of 13 binary systems where one of the\nstars is known to host a transiting exoplanet. Our results indicate that the\nmutual inclination between the orbits of the binary hosts and the transiting\nplanets are well aligned. Our results for close binary systems (a<100 AU)\ncomplement past work for wide planet host binaries from Gaia.",
            "author": [
                "Kathryn Lester",
                "Steve Howell",
                "Rachel Matson",
                "Elise Furlan",
                "Crystal Gnilka",
                "Colin Littlefield",
                "David Ciardi",
                "Mark Everett",
                "Sergio Fajardo-Acosta",
                "Catherine Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16826v1",
                "http://arxiv.org/pdf/2308.16826v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16818v2",
            "title": "Irregular Traffic Time Series Forecasting Based on Asynchronous\n  Spatio-Temporal Graph Convolutional Network",
            "updated": "2023-09-01T07:27:52Z",
            "published": "2023-08-31T15:49:21Z",
            "summary": "Accurate traffic forecasting at intersections governed by intelligent traffic\nsignals is critical for the advancement of an effective intelligent traffic\nsignal control system. However, due to the irregular traffic time series\nproduced by intelligent intersections, the traffic forecasting task becomes\nmuch more intractable and imposes three major new challenges: 1) asynchronous\nspatial dependency, 2) irregular temporal dependency among traffic data, and 3)\nvariable-length sequence to be predicted, which severely impede the performance\nof current traffic forecasting methods. To this end, we propose an Asynchronous\nSpatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic\nstates of the lanes entering intelligent intersections in a future time window.\nSpecifically, by linking lanes via a traffic diffusion graph, we first propose\nan Asynchronous Graph Diffusion Network to model the asynchronous spatial\ndependency between the time-misaligned traffic state measurements of lanes.\nAfter that, to capture the temporal dependency within irregular traffic state\nsequence, a learnable personalized time encoding is devised to embed the\ncontinuous time for each lane. Then we propose a Transformable Time-aware\nConvolution Network that learns meta-filters to derive time-aware convolution\nfilters with transformable filter sizes for efficient temporal convolution on\nthe irregular sequence. Furthermore, a Semi-Autoregressive Prediction Network\nconsisting of a state evolution unit and a semiautoregressive predictor is\ndesigned to effectively and efficiently predict variable-length traffic state\nsequences. Extensive experiments on two real-world datasets demonstrate the\neffectiveness of ASeer in six metrics.",
            "author": [
                "Weijia Zhang",
                "Le Zhang",
                "Jindong Han",
                "Hao Liu",
                "Jingbo Zhou",
                "Yu Mei",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16818v2",
                "http://arxiv.org/pdf/2308.16818v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16809v1",
            "title": "Pseudofinite proofs of the stable graph regularity lemma",
            "updated": "2023-08-31T15:34:55Z",
            "published": "2023-08-31T15:34:55Z",
            "summary": "This expository article is based on two lectures given by the first author at\nthe Fields Institute in the Fall 2021 Thematic Program on Trends in Pure and\nApplied Model Theory.\n  We give a detailed proof of a qualitative version of the Mallaris-Shelah\nregularity lemma for stable graphs using only basic local stability theory and\nan ultraproduct construction. This proof strategy was first established by\nMalliaris and Pillay, and later simplified by Pillay. We provide some further\nsimplifications, and also explain how the pseudofinite approach can be used to\nobtain a qualitative strengthening (compared to previous proofs) in terms of\n\"functional error\". To illustrate the extra leverage obtained by functional\nerror, we give an elementary argument for extracting equipartitions from\narbitrary partitions.",
            "author": [
                "G. Conant",
                "C. Terry"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16809v1",
                "http://arxiv.org/pdf/2308.16809v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16808v3",
            "title": "Towards the Overfull Conjecture",
            "updated": "2023-09-20T02:08:12Z",
            "published": "2023-08-31T15:33:13Z",
            "summary": "Let $G$ be a simple graph with maximum degree denoted as $\\Delta(G)$. An\noverfull subgraph $H$ of $G$ is a subgraph satisfying the condition $|E(H)| >\n\\Delta(G)\\lfloor \\frac{1}{2}|V(H)| \\rfloor$. In 1986, Chetwynd and Hilton\nproposed the Overfull Conjecture, stating that a graph $G$ with maximum degree\n$\\Delta(G)> \\frac{1}{3}|V(G)|$ has chromatic index equal to $\\Delta(G)$ if and\nonly if it does not contain any overfull subgraph. The Overfull Conjecture has\nmany implications. For example, it implies a polynomial-time algorithm for\ndetermining the chromatic index of graphs $G$ with $\\Delta(G) >\n\\frac{1}{3}|V(G)|$, and implies several longstanding conjectures in the area of\ngraph edge colorings. In this paper, we make the first improvement towards the\nconjecture when not imposing a minimum degree condition on the graph: for any\n$0<\\varepsilon \\le \\frac{1}{22}$, there exists a positive integer $n_0$ such\nthat if $G$ is a graph on $n\\ge n_0$ vertices with $\\Delta(G) \\ge\n(1-\\varepsilon)n$, then the Overfull Conjecture holds for $G$. The previous\nbest result in this direction, due to Chetwynd and Hilton from 1989, asserts\nthe conjecture for graphs $G$ with $\\Delta(G) \\ge |V(G)|-3$.",
            "author": [
                "Songling Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16808v3",
                "http://arxiv.org/pdf/2308.16808v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16801v1",
            "title": "Multiscale Residual Learning of Graph Convolutional Sequence Chunks for\n  Human Motion Prediction",
            "updated": "2023-08-31T15:23:33Z",
            "published": "2023-08-31T15:23:33Z",
            "summary": "A new method is proposed for human motion prediction by learning temporal and\nspatial dependencies. Recently, multiscale graphs have been developed to model\nthe human body at higher abstraction levels, resulting in more stable motion\nprediction. Current methods however predetermine scale levels and combine\nspatially proximal joints to generate coarser scales based on human priors,\neven though movement patterns in different motion sequences vary and do not\nfully comply with a fixed graph of spatially connected joints. Another problem\nwith graph convolutional methods is mode collapse, in which predicted poses\nconverge around a mean pose with no discernible movements, particularly in\nlong-term predictions. To tackle these issues, we propose ResChunk, an\nend-to-end network which explores dynamically correlated body components based\non the pairwise relationships between all joints in individual sequences.\nResChunk is trained to learn the residuals between target sequence chunks in an\nautoregressive manner to enforce the temporal connectivities between\nconsecutive chunks. It is hence a sequence-to-sequence prediction network which\nconsiders dynamic spatio-temporal features of sequences at multiple levels. Our\nexperiments on two challenging benchmark datasets, CMU Mocap and Human3.6M,\ndemonstrate that our proposed method is able to effectively model the sequence\ninformation for motion prediction and outperform other techniques to set a new\nstate-of-the-art. Our code is available at\nhttps://github.com/MohsenZand/ResChunk.",
            "author": [
                "Mohsen Zand",
                "Ali Etemad",
                "Michael Greenspan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16801v1",
                "http://arxiv.org/pdf/2308.16801v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16800v1",
            "title": "Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural\n  Networks",
            "updated": "2023-08-31T15:22:31Z",
            "published": "2023-08-31T15:22:31Z",
            "summary": "Our study reveals new theoretical insights into over-smoothing and feature\nover-correlation in deep graph neural networks. We show the prevalence of\ninvariant subspaces, demonstrating a fixed relative behavior that is unaffected\nby feature transformations. Our work clarifies recent observations related to\nconvergence to a constant state and a potential over-separation of node states,\nas the amplification of subspaces only depends on the spectrum of the\naggregation function. In linear scenarios, this leads to node representations\nbeing dominated by a low-dimensional subspace with an asymptotic convergence\nrate independent of the feature transformations. This causes a rank collapse of\nthe node representations, resulting in over-smoothing when smooth vectors span\nthis subspace, and over-correlation even when over-smoothing is avoided. Guided\nby our theory, we propose a sum of Kronecker products as a beneficial property\nthat can provably prevent over-smoothing, over-correlation, and rank collapse.\nWe empirically extend our insights to the non-linear case, demonstrating the\ninability of existing models to capture linearly independent features.",
            "author": [
                "Andreas Roth",
                "Thomas Liebig"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16800v1",
                "http://arxiv.org/pdf/2308.16800v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16792v2",
            "title": "Lift-up and streak waviness drive the self-sustained process in\n  wall-bounded transition to turbulence",
            "updated": "2023-11-02T19:18:22Z",
            "published": "2023-08-31T15:09:23Z",
            "summary": "Flow field measurements from a Couette-Poiseuille experiment are used to\nexamine quantitatively certain steps of the self-sustained process (SSP) of\nwall-bounded transition to turbulence. Although the different parts of the SSP\nhave been discussed at large in the literature, direct measurements from\nexperiment are scarce and, to our knowledge, the present results are the first\nto show, using a local analysis of the turbulent patterns, that: (1) the\namplitude of streamwise rolls is related to streak waviness, bringing a\nquantitative picture to one of the main physical mechanisms of Waleffe's model\nof SSP ; and (2), at low waviness, direct measurements of the correlation\nbetween the streak and roll amplitudes, respectively probed by the streamwise\nand wall-normal velocity perturbations, quantify the lift-up effect.",
            "author": [
                "Tao Liu",
                "Beno\u00eet Semin",
                "Ramiro Godoy-Diana",
                "Jos\u00e9 Eduardo Wesfreid"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16792v2",
                "http://arxiv.org/pdf/2308.16792v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16789v1",
            "title": "Joint Semantic-Native Communication and Inference via Minimal Simplicial\n  Structures",
            "updated": "2023-08-31T15:04:28Z",
            "published": "2023-08-31T15:04:28Z",
            "summary": "In this work, we study the problem of semantic communication and inference,\nin which a student agent (i.e. mobile device) queries a teacher agent (i.e.\ncloud sever) to generate higher-order data semantics living in a simplicial\ncomplex. Specifically, the teacher first maps its data into a k-order\nsimplicial complex and learns its high-order correlations. For effective\ncommunication and inference, the teacher seeks minimally sufficient and\ninvariant semantic structures prior to conveying information. These minimal\nsimplicial structures are found via judiciously removing simplices selected by\nthe Hodge Laplacians without compromising the inference query accuracy.\nSubsequently, the student locally runs its own set of queries based on a masked\nsimplicial convolutional autoencoder (SCAE) leveraging both local and remote\nteacher's knowledge. Numerical results corroborate the effectiveness of the\nproposed approach in terms of improving inference query accuracy under\ndifferent channel conditions and simplicial structures. Experiments on a\ncoauthorship dataset show that removing simplices by ranking the Laplacian\nvalues yields a 85% reduction in payload size without sacrificing accuracy.\nJoint semantic communication and inference by masked SCAE improves query\naccuracy by 25% compared to local student based query and 15% compared to\nremote teacher based query. Finally, incorporating channel semantics is shown\nto effectively improve inference accuracy, notably at low SNR values.",
            "author": [
                "Qiyang Zhao",
                "Hang Zou",
                "Mehdi Bennis",
                "Merouane Debbah",
                "Ebtesam Almazrouei",
                "Faouzi Bader"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16789v1",
                "http://arxiv.org/pdf/2308.16789v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16781v4",
            "title": "StratMed: Relevance Stratification between Biomedical Entities for\n  Sparsity on Medication Recommendation",
            "updated": "2023-11-27T05:03:14Z",
            "published": "2023-08-31T14:59:32Z",
            "summary": "With the growing imbalance between limited medical resources and escalating\ndemands, AI-based clinical tasks have become paramount. As a sub-domain,\nmedication recommendation aims to amalgamate longitudinal patient history with\nmedical knowledge, assisting physicians in prescribing safer and more accurate\nmedication combinations. Existing works ignore the inherent long-tailed\ndistribution of medical data, have uneven learning strengths for hot and sparse\ndata, and fail to balance safety and accuracy. To address the above\nlimitations, we propose StratMed, which introduces a stratification strategy\nthat overcomes the long-tailed problem and achieves fuller learning of sparse\ndata. It also utilizes a dual-property network to address the issue of mutual\nconstraints on the safety and accuracy of medication combinations,\nsynergistically enhancing these two properties. Specifically, we construct a\npre-training method using deep learning networks to obtain medication and\ndisease representations. After that, we design a pyramid-like stratification\nmethod based on relevance to strengthen the expressiveness of sparse data.\nBased on this relevance, we design two graph structures to express medication\nsafety and precision at the same level to obtain patient representations.\nFinally, the patient's historical clinical information is fitted to generate\nmedication combinations for the current health condition. We employed the\nMIMIC-III dataset to evaluate our model against state-of-the-art methods in\nthree aspects comprehensively. Compared to the sub-optimal baseline model, our\nmodel reduces safety risk by 15.08\\%, improves accuracy by 0.36\\%, and reduces\ntraining time consumption by 81.66\\%.",
            "author": [
                "Xiang Li",
                "Shunpan Liang",
                "Yulei Hou",
                "Tengfei Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16781v4",
                "http://arxiv.org/pdf/2308.16781v4"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16775v3",
            "title": "Efficacy of Neural Prediction-Based Zero-Shot NAS",
            "updated": "2023-09-22T07:15:05Z",
            "published": "2023-08-31T14:54:06Z",
            "summary": "In prediction-based Neural Architecture Search (NAS), performance indicators\nderived from graph convolutional networks have shown remarkable success. These\nindicators, achieved by representing feed-forward structures as component\ngraphs through one-hot encoding, face a limitation: their inability to evaluate\narchitecture performance across varying search spaces. In contrast, handcrafted\nperformance indicators (zero-shot NAS), which use the same architecture with\nrandom initialization, can generalize across multiple search spaces. Addressing\nthis limitation, we propose a novel approach for zero-shot NAS using deep\nlearning. Our method employs Fourier sum of sines encoding for convolutional\nkernels, enabling the construction of a computational feed-forward graph with a\nstructure similar to the architecture under evaluation. These encodings are\nlearnable and offer a comprehensive view of the architecture's topological\ninformation. An accompanying multi-layer perceptron (MLP) then ranks these\narchitectures based on their encodings. Experimental results show that our\napproach surpasses previous methods using graph convolutional networks in terms\nof correlation on the NAS-Bench-201 dataset and exhibits a higher convergence\nrate. Moreover, our extracted feature representation trained on each NAS\nbenchmark is transferable to other NAS benchmarks, showing promising\ngeneralizability across multiple search spaces. The code is available at:\nhttps://github.com/minh1409/DFT-NPZS-NAS",
            "author": [
                "Minh Le",
                "Nhan Nguyen",
                "Ngoc Hoang Luong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16775v3",
                "http://arxiv.org/pdf/2308.16775v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16774v3",
            "title": "Toward Automatically Completing GitHub Workflows",
            "updated": "2023-09-06T09:33:29Z",
            "published": "2023-08-31T14:53:00Z",
            "summary": "Continuous integration and delivery (CI/CD) are nowadays at the core of\nsoftware development. Their benefits come at the cost of setting up and\nmaintaining the CI/CD pipeline, which requires knowledge and skills often\northogonal to those entailed in other software-related tasks. While several\nrecommender systems have been proposed to support developers across a variety\nof tasks, little automated support is available when it comes to setting up and\nmaintaining CI/CD pipelines. We present GH-WCOM (GitHub Workflow COMpletion), a\nTransformer-based approach supporting developers in writing a specific type of\nCI/CD pipelines, namely GitHub workflows. To deal with such a task, we designed\nan abstraction process to help the learning of the transformer while still\nmaking GH-WCOM able to recommend very peculiar workflow elements such as tool\noptions and scripting elements. Our empirical study shows that GH-WCOM provides\nup to 34.23% correct predictions, and the model's confidence is a reliable\nproxy for the recommendations' correctness likelihood.",
            "author": [
                "Antonio Mastropaolo",
                "Fiorella Zampetti",
                "Gabriele Bavota",
                "Massimiliano Di Penta"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16774v3",
                "http://arxiv.org/pdf/2308.16774v3"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16763v2",
            "title": "Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection",
            "updated": "2023-09-07T09:15:24Z",
            "published": "2023-08-31T14:31:48Z",
            "summary": "Stance detection aims to identify the attitude expressed in a document\ntowards a given target. Techniques such as Chain-of-Thought (CoT) prompting\nhave advanced this task, enhancing a model's reasoning capabilities through the\nderivation of intermediate rationales. However, CoT relies primarily on a\nmodel's pre-trained internal knowledge during reasoning, thereby neglecting the\nvaluable external information that is previously unknown to the model. This\nomission, especially within the unsupervised reasoning process, can affect the\nmodel's overall performance. Moreover, while CoT enhances Large Language Models\n(LLMs), smaller LMs, though efficient operationally, face challenges in\ndelivering nuanced reasoning. In response to these identified gaps, we\nintroduce the Ladder-of-Thought (LoT) for the stance detection task.\nConstructed through a dual-phase Progressive Optimization Framework, LoT\ndirects the small LMs to assimilate high-quality external knowledge, refining\nthe intermediate rationales produced. These bolstered rationales subsequently\nserve as the foundation for more precise predictions - akin to how a ladder\nfacilitates reaching elevated goals. LoT achieves a balance between efficiency\nand performance. Our empirical evaluations underscore LoT's efficacy, marking a\n16% improvement over GPT-3.5 and a 10% enhancement compared to GPT-3.5 with CoT\non stance detection task.",
            "author": [
                "Kairui Hu",
                "Ming Yan",
                "Joey Tianyi Zhou",
                "Ivor W. Tsang",
                "Wen Haw Chong",
                "Yong Keong Yap"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16763v2",
                "http://arxiv.org/pdf/2308.16763v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16759v1",
            "title": "Constructing Indoor Region-based Radio Map without Location Labels",
            "updated": "2023-08-31T14:27:36Z",
            "published": "2023-08-31T14:27:36Z",
            "summary": "Radio map construction requires a large amount of radio measurement data with\nlocation labels, which imposes a high deployment cost. This paper develops a\nregion-based radio map from received signal strength (RSS) measurements without\nlocation labels. The construction is based on a set of blindly collected RSS\nmeasurement data from a device that visits each region in an indoor area\nexactly once, where the footprints and timestamps are not recorded. The main\nchallenge is to cluster the RSS data and match clusters with the physical\nregions. Classical clustering algorithms fail to work as the RSS data naturally\nappears as non-clustered due to multipaths and noise. In this paper, a signal\nsubspace model with a sequential prior is constructed for the RSS data, and an\nintegrated segmentation and clustering algorithm is developed, which is shown\nto find the globally optimal solution in a special case. Furthermore, the\nclustered data is matched with the physical regions using a graph-based\napproach. Based on real measurements from an office space, the proposed scheme\nreduces the region localization error by roughly 50% compared to a weighted\ncentroid localization (WCL) baseline, and it even outperforms some supervised\nlocalization schemes, including k-nearest neighbor (KNN), support vector\nmachine (SVM), and deep neural network (DNN), which require labeled data for\ntraining.",
            "author": [
                "Zheng Xing",
                "Junting Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16759v1",
                "http://arxiv.org/pdf/2308.16759v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16757v1",
            "title": "Universal Approach to Critical Percolation",
            "updated": "2023-08-31T14:26:02Z",
            "published": "2023-08-31T14:26:02Z",
            "summary": "Percolation problems appear in a large variety of different contexts ranging\nfrom the design of composite materials to vaccination strategies on community\nnetworks. The key observable for many applications is the percolation\nthreshold. Unlike the universal critical exponents, the percolation threshold\ndepends explicitly on the specific system properties. As a consequence,\ntheoretical approaches to the percolation threshold are rare and generally\ntailored to the specific application.\n  Yet, any percolating cluster forms a discrete network the emergence of which\ncan be cast as a graph problem and analyzed using branching processes. We\npropose a general mapping of any kind of percolation problem onto a branching\nprocess which provides rigorous lower bounds of the percolation threshold.\nThese bounds progressively tighten as we incorporate more information into the\ntheory. We showcase our approach for different continuum problems finding\naccurate predictions with almost no effort. Our approach is based on first\nprinciples and does not require fitting parameters. As such it offers an\nimportant theoretical reference in a field that is dominated by simulation\nstudies and heuristic fit functions.",
            "author": [
                "Fabian Coupette",
                "Tanja Schilling"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16757v1",
                "http://arxiv.org/pdf/2308.16757v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16750v2",
            "title": "The non-two-primes graph of a finite group",
            "updated": "2023-09-11T11:24:20Z",
            "published": "2023-08-31T14:12:06Z",
            "summary": "To any finite group $G$, we may associate a graph whose vertices are the\nelements of $G$ and where two distinct vertices $x$ and $y$ are adjacent if and\nonly if the order of the subgroup $\\langle x, y\\rangle$ is divisible by at\nleast 3 distinct primes. We prove that the subgraph of this graph induced by\nthe non-isolated vertices is connected and has diameter at most 5.",
            "author": [
                "Karmele Garatea-Zaballa",
                "Andrea Lucchini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16750v2",
                "http://arxiv.org/pdf/2308.16750v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16744v1",
            "title": "MS-BioGraphs: Sequence Similarity Graph Datasets",
            "updated": "2023-08-31T14:04:28Z",
            "published": "2023-08-31T14:04:28Z",
            "summary": "Progress in High-Performance Computing in general, and High-Performance Graph\nProcessing in particular, is highly dependent on the availability of\npublicly-accessible, relevant, and realistic data sets.\n  To ensure continuation of this progress, we (i) investigate and optimize the\nprocess of generating large sequence similarity graphs as an HPC challenge and\n(ii) demonstrate this process in creating MS-BioGraphs, a new family of\npublicly available real-world edge-weighted graph datasets with up to $2.5$\ntrillion edges, that is, $6.6$ times greater than the largest graph published\nrecently. The largest graph is created by matching (i.e., all-to-all similarity\naligning) $1.7$ billion protein sequences. The MS-BioGraphs family includes\nalso seven subgraphs with different sizes and direction types.\n  We describe two main challenges we faced in generating large graph datasets\nand our solutions, that are, (i) optimizing data structures and algorithms for\nthis multi-step process and (ii) WebGraph parallel compression technique. We\npresent a comparative study of structural characteristics of MS-BioGraphs.\n  The datasets are available online on\nhttps://blogs.qub.ac.uk/DIPSA/MS-BioGraphs .",
            "author": [
                "Mohsen Koohi Esfahani",
                "Paolo Boldi",
                "Hans Vandierendonck",
                "Peter Kilpatrick",
                "Sebastiano Vigna"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16744v1",
                "http://arxiv.org/pdf/2308.16744v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AR",
                "cs.CE",
                "cs.DM",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16739v1",
            "title": "Parsing is All You Need for Accurate Gait Recognition in the Wild",
            "updated": "2023-08-31T13:57:38Z",
            "published": "2023-08-31T13:57:38Z",
            "summary": "Binary silhouettes and keypoint-based skeletons have dominated human gait\nrecognition studies for decades since they are easy to extract from video\nframes. Despite their success in gait recognition for in-the-lab environments,\nthey usually fail in real-world scenarios due to their low information entropy\nfor gait representations. To achieve accurate gait recognition in the wild,\nthis paper presents a novel gait representation, named Gait Parsing Sequence\n(GPS). GPSs are sequences of fine-grained human segmentation, i.e., human\nparsing, extracted from video frames, so they have much higher information\nentropy to encode the shapes and dynamics of fine-grained human parts during\nwalking. Moreover, to effectively explore the capability of the GPS\nrepresentation, we propose a novel human parsing-based gait recognition\nframework, named ParsingGait. ParsingGait contains a Convolutional Neural\nNetwork (CNN)-based backbone and two light-weighted heads. The first head\nextracts global semantic features from GPSs, while the other one learns mutual\ninformation of part-level features through Graph Convolutional Networks to\nmodel the detailed dynamics of human walking. Furthermore, due to the lack of\nsuitable datasets, we build the first parsing-based dataset for gait\nrecognition in the wild, named Gait3D-Parsing, by extending the large-scale and\nchallenging Gait3D dataset. Based on Gait3D-Parsing, we comprehensively\nevaluate our method and existing gait recognition methods. The experimental\nresults show a significant improvement in accuracy brought by the GPS\nrepresentation and the superiority of ParsingGait. The code and dataset are\navailable at https://gait3d.github.io/gait3d-parsing-hp .",
            "author": [
                "Jinkai Zheng",
                "Xinchen Liu",
                "Shuai Wang",
                "Lihao Wang",
                "Chenggang Yan",
                "Wu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16739v1",
                "http://arxiv.org/pdf/2308.16739v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16728v1",
            "title": "Forbidden subgraphs and complete partitions",
            "updated": "2023-08-31T13:46:39Z",
            "published": "2023-08-31T13:46:39Z",
            "summary": "A graph is called an $(r,k)$-graph if its vertex set can be partitioned into\n$r$ parts of size at most $k$ with at least one edge between any two parts. Let\n$f(r,H)$ be the minimum $k$ for which there exists an $H$-free $(r,k)$-graph.\nIn this paper we build on the work of Axenovich and Martin, obtaining improved\nbounds on this function when $H$ is a complete bipartite graph, even cycle, or\ntree. Some of these bounds are best possible up to a constant factor and\nconfirm a conjecture of Axenovich and Martin in several cases. We also\ngeneralize this extremal problem to uniform hypergraphs and prove some initial\nresults in that setting.",
            "author": [
                "John Byrne",
                "Michael Tait",
                "Craig Timmons"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16728v1",
                "http://arxiv.org/pdf/2308.16728v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16711v1",
            "title": "Lower Bounds on the Complexity of Mixed-Integer Programs for Stable Set\n  and Knapsack",
            "updated": "2023-08-31T13:25:13Z",
            "published": "2023-08-31T13:25:13Z",
            "summary": "Standard mixed-integer programming formulations for the stable set problem on\n$n$-node graphs require $n$ integer variables. We prove that this is almost\noptimal: We give a family of $n$-node graphs for which every polynomial-size\nMIP formulation requires $\\Omega(n/\\log^2 n)$ integer variables. By a\npolyhedral reduction we obtain an analogous result for $n$-item knapsack\nproblems. In both cases, this improves the previously known bounds of\n$\\Omega(\\sqrt{n}/\\log n)$ by Cevallos, Weltge & Zenklusen (SODA 2018).\n  To this end, we show that there exists a family of $n$-node graphs whose\nstable set polytopes satisfy the following: any $(1+\\varepsilon/n)$-approximate\nextended formulation for these polytopes, for some constant $\\varepsilon > 0$,\nhas size $2^{\\Omega(n/\\log n)}$. Our proof extends and simplifies the\ninformation-theoretic methods due to G\\\"o\\\"os, Jain & Watson (FOCS 2016, SIAM\nJ. Comput. 2018) who showed the same result for the case of exact extended\nformulations (i.e. $\\varepsilon = 0$).",
            "author": [
                "Jamico Schade",
                "Makrand Sinha",
                "Stefan Weltge"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16711v1",
                "http://arxiv.org/pdf/2308.16711v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16700v1",
            "title": "Exact and Efficient Bayesian Inference for Privacy Risk Quantification\n  (Extended Version)",
            "updated": "2023-08-31T13:04:04Z",
            "published": "2023-08-31T13:04:04Z",
            "summary": "Data analysis has high value both for commercial and research purposes.\nHowever, disclosing analysis results may pose severe privacy risk to\nindividuals. Privug is a method to quantify privacy risks of data analytics\nprograms by analyzing their source code. The method uses probability\ndistributions to model attacker knowledge and Bayesian inference to update said\nknowledge based on observable outputs. Currently, Privug uses Markov Chain\nMonte Carlo (MCMC) to perform inference, which is a flexible but approximate\nsolution. This paper presents an exact Bayesian inference engine based on\nmultivariate Gaussian distributions to accurately and efficiently quantify\nprivacy risks. The inference engine is implemented for a subset of Python\nprograms that can be modeled as multivariate Gaussian models. We evaluate the\nmethod by analyzing privacy risks in programs to release public statistics. The\nevaluation shows that our method accurately and efficiently analyzes privacy\nrisks, and outperforms existing methods. Furthermore, we demonstrate the use of\nour engine to analyze the effect of differential privacy in public statistics.",
            "author": [
                "Rasmus C. R\u00f8nneberg",
                "Ra\u00fal Pardo",
                "Andrzej W\u0105sowski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16700v1",
                "http://arxiv.org/pdf/2308.16700v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16688v1",
            "title": "Using Large Language Models to Automate Category and Trend Analysis of\n  Scientific Articles: An Application in Ophthalmology",
            "updated": "2023-08-31T12:45:53Z",
            "published": "2023-08-31T12:45:53Z",
            "summary": "Purpose: In this paper, we present an automated method for article\nclassification, leveraging the power of Large Language Models (LLM). The\nprimary focus is on the field of ophthalmology, but the model is extendable to\nother fields. Methods: We have developed a model based on Natural Language\nProcessing (NLP) techniques, including advanced LLMs, to process and analyze\nthe textual content of scientific papers. Specifically, we have employed\nzero-shot learning (ZSL) LLM models and compared against Bidirectional and\nAuto-Regressive Transformers (BART) and its variants, and Bidirectional Encoder\nRepresentations from Transformers (BERT), and its variant such as distilBERT,\nSciBERT, PubmedBERT, BioBERT. Results: The classification results demonstrate\nthe effectiveness of LLMs in categorizing large number of ophthalmology papers\nwithout human intervention. Results: To evalute the LLMs, we compiled a dataset\n(RenD) of 1000 ocular disease-related articles, which were expertly annotated\nby a panel of six specialists into 15 distinct categories. The model achieved\nmean accuracy of 0.86 and mean F1 of 0.85 based on the RenD dataset.\nConclusion: The proposed framework achieves notable improvements in both\naccuracy and efficiency. Its application in the domain of ophthalmology\nshowcases its potential for knowledge organization and retrieval in other\ndomains too. We performed trend analysis that enables the researchers and\nclinicians to easily categorize and retrieve relevant papers, saving time and\neffort in literature review and information gathering as well as identification\nof emerging scientific trends within different disciplines. Moreover, the\nextendibility of the model to other scientific fields broadens its impact in\nfacilitating research and trend analysis across diverse disciplines.",
            "author": [
                "Hina Raja",
                "Asim Munawar",
                "Mohammad Delsoz",
                "Mohammad Elahi",
                "Yeganeh Madadi",
                "Amr Hassan",
                "Hashem Abu Serhan",
                "Onur Inam",
                "Luis Hermandez",
                "Sang Tran",
                "Wuqas Munir",
                "Alaa Abd-Alrazaq",
                "Hao Chen",
                "SiamakYousefi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16688v1",
                "http://arxiv.org/pdf/2308.16688v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16684v2",
            "title": "Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor\n  Attack",
            "updated": "2023-09-03T13:36:49Z",
            "published": "2023-08-31T12:38:29Z",
            "summary": "The vulnerabilities to backdoor attacks have recently threatened the\ntrustworthiness of machine learning models in practical applications.\nConventional wisdom suggests that not everyone can be an attacker since the\nprocess of designing the trigger generation algorithm often involves\nsignificant effort and extensive experimentation to ensure the attack's\nstealthiness and effectiveness. Alternatively, this paper shows that there\nexists a more severe backdoor threat: anyone can exploit an easily-accessible\nalgorithm for silent backdoor attacks. Specifically, this attacker can employ\nthe widely-used lossy image compression from a plethora of compression tools to\neffortlessly inject a trigger pattern into an image without leaving any\nnoticeable trace; i.e., the generated triggers are natural artifacts. One does\nnot require extensive knowledge to click on the \"convert\" or \"save as\" button\nwhile using tools for lossy image compression. Via this attack, the adversary\ndoes not need to design a trigger generator as seen in prior works and only\nrequires poisoning the data. Empirically, the proposed attack consistently\nachieves 100% attack success rate in several benchmark datasets such as MNIST,\nCIFAR-10, GTSRB and CelebA. More significantly, the proposed attack can still\nachieve almost 100% attack success rate with very small (approximately 10%)\npoisoning rates in the clean label setting. The generated trigger of the\nproposed attack using one lossy compression algorithm is also transferable\nacross other related compression algorithms, exacerbating the severity of this\nbackdoor threat. This work takes another crucial step toward understanding the\nextensive risks of backdoor attacks in practice, urging practitioners to\ninvestigate similar attacks and relevant backdoor mitigation methods.",
            "author": [
                "Sze Jue Yang",
                "Quang Nguyen",
                "Chee Seng Chan",
                "Khoa D. Doan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16684v2",
                "http://arxiv.org/pdf/2308.16684v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16680v1",
            "title": "Branches of a Tree: Taking Derivatives of Programs with Discrete and\n  Branching Randomness in High Energy Physics",
            "updated": "2023-08-31T12:32:34Z",
            "published": "2023-08-31T12:32:34Z",
            "summary": "We propose to apply several gradient estimation techniques to enable the\ndifferentiation of programs with discrete randomness in High Energy Physics.\nSuch programs are common in High Energy Physics due to the presence of\nbranching processes and clustering-based analysis. Thus differentiating such\nprograms can open the way for gradient based optimization in the context of\ndetector design optimization, simulator tuning, or data analysis and\nreconstruction optimization. We discuss several possible gradient estimation\nstrategies, including the recent Stochastic AD method, and compare them in\nsimplified detector design experiments. In doing so we develop, to the best of\nour knowledge, the first fully differentiable branching program.",
            "author": [
                "Michael Kagan",
                "Lukas Heinrich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16680v1",
                "http://arxiv.org/pdf/2308.16680v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "hep-ex",
                "hep-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16679v1",
            "title": "Distance-regular graphs with classical parameters that support a uniform\n  structure: case $q \\ge 2$",
            "updated": "2023-08-31T12:29:40Z",
            "published": "2023-08-31T12:29:40Z",
            "summary": "Let $\\Gamma=(X,\\mathcal{R})$ denote a finite, simple, connected, and\nundirected non-bipartite graph with vertex set $X$ and edge set $\\mathcal{R}$.\nFix a vertex $x \\in X$, and define $\\mathcal{R}_f = \\mathcal{R} \\setminus \\{yz\n\\mid \\partial(x,y) = \\partial(x,z)\\}$, where $\\partial$ denotes the path-length\ndistance in $\\Gamma$. Observe that the graph $\\Gamma_f=(X,\\mathcal{R}_f)$ is\nbipartite. We say that $\\Gamma$ supports a uniform structure with respect to\n$x$ whenever $\\Gamma_f$ has a uniform structure with respect to $x$ in the\nsense of Miklavi\\v{c} and Terwilliger \\cite{MikTer}.\n  Assume that $\\Gamma$ is a distance-regular graph with classical parameters\n$(D,q,\\alpha,\\beta)$ and diameter $D\\geq 4$. Recall that $q$ is an integer such\nthat $q \\not \\in \\{-1,0\\}$. The purpose of this paper is to study when $\\Gamma$\nsupports a uniform structure with respect to $x$. We studied the case $q \\le 1$\nin \\cite{FMMM}, and so in this paper we assume $q \\geq 2$. Let $T=T(x)$ denote\nthe Terwilliger algebra of $\\Gamma$ with respect to $x$. Under an additional\nassumption that every irreducible $T$-module with endpoint $1$ is thin, we show\nthat if $\\Gamma$ supports a uniform structure with respect to $x$, then either\n$\\alpha = 0$ or $\\alpha=q$, $\\beta=q^2(q^D-1)/(q-1)$, and $D \\equiv 0\n\\pmod{6}$.",
            "author": [
                "Blas Fern\u00e1ndez",
                "Roghayeh Maleki",
                "\u0160tefko Miklavi\u010d",
                "Giusy Monzillo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16679v1",
                "http://arxiv.org/pdf/2308.16679v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05E99, 05C50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16666v1",
            "title": "Study of Zero-Knowledge protocols and Elliptic Curve Cryptography and\n  their implementation in Smart Card environments using Java Card",
            "updated": "2023-08-31T12:15:03Z",
            "published": "2023-08-31T12:15:03Z",
            "summary": "This paper studies the problem of Zero-Knowledge Protocol (ZKP) and elliptic\ncurve cryptographic implementation in a computationally limited environment,\nsuch as, the smart cards, using Java Card. Besides that, it is explained how\nthe zero-knowledge protocol was selected to implement it on a smart card and\nhow the benchmarking was conducted to select this protocol. The paper also\nshows a theoretical development to implement the ZKP protocol using elliptic\ncurve cryptography. Keywords: Authentication; Zero-knowledge; Cryptography;\nElliptic Curve; Java card; Smart cards",
            "author": [
                "Carlos Andres Agudelo Serna"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16666v1",
                "http://arxiv.org/pdf/2308.16666v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00024v1",
            "title": "Efficient Multi-View Graph Clustering with Local and Global Structure\n  Preservation",
            "updated": "2023-08-31T12:12:30Z",
            "published": "2023-08-31T12:12:30Z",
            "summary": "Anchor-based multi-view graph clustering (AMVGC) has received abundant\nattention owing to its high efficiency and the capability to capture\ncomplementary structural information across multiple views. Intuitively, a\nhigh-quality anchor graph plays an essential role in the success of AMVGC.\nHowever, the existing AMVGC methods only consider single-structure information,\ni.e., local or global structure, which provides insufficient information for\nthe learning task. To be specific, the over-scattered global structure leads to\nlearned anchors failing to depict the cluster partition well. In contrast, the\nlocal structure with an improper similarity measure results in potentially\ninaccurate anchor assignment, ultimately leading to sub-optimal clustering\nperformance. To tackle the issue, we propose a novel anchor-based multi-view\ngraph clustering framework termed Efficient Multi-View Graph Clustering with\nLocal and Global Structure Preservation (EMVGC-LG). Specifically, a unified\nframework with a theoretical guarantee is designed to capture local and global\ninformation. Besides, EMVGC-LG jointly optimizes anchor construction and graph\nlearning to enhance the clustering quality. In addition, EMVGC-LG inherits the\nlinear complexity of existing AMVGC methods respecting the sample number, which\nis time-economical and scales well with the data size. Extensive experiments\ndemonstrate the effectiveness and efficiency of our proposed method.",
            "author": [
                "Yi Wen",
                "Suyuan Liu",
                "Xinhang Wan",
                "Siwei Wang",
                "Ke Liang",
                "Xinwang Liu",
                "Xihong Yang",
                "Pei Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611986",
                "http://arxiv.org/abs/2309.00024v1",
                "http://arxiv.org/pdf/2309.00024v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16661v1",
            "title": "Context based learning: a survey of contextual indicators for\n  personalized and adaptive learning recommendations. A pedagogical and\n  technical perspective",
            "updated": "2023-08-31T12:00:03Z",
            "published": "2023-08-31T12:00:03Z",
            "summary": "Learning personalization has proven its effectiveness in enhancing learner\nperformance. Therefore, modern digital learning platforms have been\nincreasingly depending on recommendation systems to offer learners personalized\nsuggestions of learning materials. Learners can utilize those recommendations\nto acquire certain skills for the labor market or for their formal education.\nPersonalization can be based on several factors, such as personal preference,\nsocial connections or learning context. In an educational environment, the\nlearning context plays an important role in generating sound recommendations,\nwhich not only fulfill the preferences of the learner, but also correspond to\nthe pedagogical goals of the learning process. This is because a learning\ncontext describes the actual situation of the learner at the moment of\nrequesting a learning recommendation. It provides information about the learner\ncurrent state of knowledge, goal orientation, motivation, needs, available\ntime, and other factors that reflect their status and may influence how\nlearning recommendations are perceived and utilized. Context aware recommender\nsystems have the potential to reflect the logic that a learning expert may\nfollow in recommending materials to students with respect to their status and\nneeds. In this paper, we review the state-of-the-art approaches for defining a\nuser learning-context. We provide an overview of the definitions available, as\nwell as the different factors that are considered when defining a context.\nMoreover, we further investigate the links between those factors and their\npedagogical foundations in learning theories. We aim to provide a comprehensive\nunderstanding of contextualized learning from both pedagogical and technical\npoints of view. By combining those two viewpoints, we aim to bridge a gap\nbetween both domains, in terms of contextualizing learning recommendations.",
            "author": [
                "Hasan Abu-Rasheed",
                "Christian Weber",
                "Madjid Fathi"
            ],
            "link": [
                "http://dx.doi.org/10.3389/feduc.2023.1210968",
                "http://arxiv.org/abs/2308.16661v1",
                "http://arxiv.org/pdf/2308.16661v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16639v1",
            "title": "Security Allocation in Networked Control Systems under Stealthy Attacks",
            "updated": "2023-08-31T11:16:56Z",
            "published": "2023-08-31T11:16:56Z",
            "summary": "This paper considers the problem of security allocation in a networked\ncontrol system under stealthy attacks in which the system is comprised of\ninterconnected subsystems represented by vertices. A malicious adversary\nselects a single vertex on which to conduct a stealthy data injection attack to\nmaximally disrupt the local performance while remaining undetected. On the\nother hand, a defender selects several vertices on which to allocate defense\nresources against the adversary. First, the objectives of the adversary and the\ndefender with uncertain targets are formulated in probabilistic ways, resulting\nin an expected worst-case impact of stealthy attacks. Next, we provide a\ngraph-theoretic necessary and sufficient condition under which the cost for the\ndefender and the expected worst-case impact of stealthy attacks are bounded.\nThis condition enables the defender to restrict the admissible actions to a\nsubset of available vertex sets. Then, we cast the problem of security\nallocation in a Stackelberg game-theoretic framework. Finally, the contribution\nof this paper is highlighted by utilizing the proposed admissible actions of\nthe defender in the context of large-scale networks. A numerical example of a\n50-vertex networked control system is presented to validate the obtained\nresults.",
            "author": [
                "Anh Tung Nguyen",
                "Andr\u00e9 M. H. Teixeira",
                "Alexander Medvedev"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16639v1",
                "http://arxiv.org/pdf/2308.16639v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00023v1",
            "title": "Continual Learning From a Stream of APIs",
            "updated": "2023-08-31T11:16:00Z",
            "published": "2023-08-31T11:16:00Z",
            "summary": "Continual learning (CL) aims to learn new tasks without forgetting previous\ntasks. However, existing CL methods require a large amount of raw data, which\nis often unavailable due to copyright considerations and privacy risks.\nInstead, stakeholders usually release pre-trained machine learning models as a\nservice (MLaaS), which users can access via APIs. This paper considers two\npractical-yet-novel CL settings: data-efficient CL (DECL-APIs) and data-free CL\n(DFCL-APIs), which achieve CL from a stream of APIs with partial or no raw\ndata. Performing CL under these two new settings faces several challenges:\nunavailable full raw data, unknown model parameters, heterogeneous models of\narbitrary architecture and scale, and catastrophic forgetting of previous APIs.\nTo overcome these issues, we propose a novel data-free cooperative continual\ndistillation learning framework that distills knowledge from a stream of APIs\ninto a CL model by generating pseudo data, just by querying APIs. Specifically,\nour framework includes two cooperative generators and one CL model, forming\ntheir training as an adversarial game. We first use the CL model and the\ncurrent API as fixed discriminators to train generators via a derivative-free\nmethod. Generators adversarially generate hard and diverse synthetic data to\nmaximize the response gap between the CL model and the API. Next, we train the\nCL model by minimizing the gap between the responses of the CL model and the\nblack-box API on synthetic data, to transfer the API's knowledge to the CL\nmodel. Furthermore, we propose a new regularization term based on network\nsimilarity to prevent catastrophic forgetting of previous APIs.Our method\nperforms comparably to classic CL with full raw data on the MNIST and SVHN in\nthe DFCL-APIs setting. In the DECL-APIs setting, our method achieves 0.97x,\n0.75x and 0.69x performance of classic CL on CIFAR10, CIFAR100, and\nMiniImageNet.",
            "author": [
                "Enneng Yang",
                "Zhenyi Wang",
                "Li Shen",
                "Nan Yin",
                "Tongliang Liu",
                "Guibing Guo",
                "Xingwei Wang",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00023v1",
                "http://arxiv.org/pdf/2309.00023v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16637v1",
            "title": "Learning Channel Importance for High Content Imaging with Interpretable\n  Deep Input Channel Mixing",
            "updated": "2023-08-31T11:11:38Z",
            "published": "2023-08-31T11:11:38Z",
            "summary": "Uncovering novel drug candidates for treating complex diseases remain one of\nthe most challenging tasks in early discovery research. To tackle this\nchallenge, biopharma research established a standardized high content imaging\nprotocol that tags different cellular compartments per image channel. In order\nto judge the experimental outcome, the scientist requires knowledge about the\nchannel importance with respect to a certain phenotype for decoding the\nunderlying biology. In contrast to traditional image analysis approaches, such\nexperiments are nowadays preferably analyzed by deep learning based approaches\nwhich, however, lack crucial information about the channel importance. To\novercome this limitation, we present a novel approach which utilizes\nmulti-spectral information of high content images to interpret a certain aspect\nof cellular biology. To this end, we base our method on image blending concepts\nwith alpha compositing for an arbitrary number of channels. More specifically,\nwe introduce DCMIX, a lightweight, scaleable and end-to-end trainable mixing\nlayer which enables interpretable predictions in high content imaging while\nretaining the benefits of deep learning based methods. We employ an extensive\nset of experiments on both MNIST and RXRX1 datasets, demonstrating that DCMIX\nlearns the biologically relevant channel importance without scarifying\nprediction performance.",
            "author": [
                "Daniel Siegismund",
                "Mario Wieser",
                "Stephan Heyse",
                "Stephan Steigele"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16637v1",
                "http://arxiv.org/pdf/2308.16637v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16627v2",
            "title": "Thermodynamic Properties of Regular Phantom Black Hole",
            "updated": "2023-09-02T05:45:02Z",
            "published": "2023-08-31T10:49:19Z",
            "summary": "The Regular Phantom Black Holes (RPBH)s are of theoretical and observational\nimportance, and some properties have been studied. In this work, we study some\nof the thermodynamical properties such as entropy, and temperature, ... in\nthree asymptotically spacetimes: flat, de--Sitter (dS), and Anti-de Sitter\n(AdS). Many of the RPBH properties, including horizon radius, are (directly or\nindirectly) dependent on a scale parameter b. Due to the slightly different\nstructure from Schwarzschild--metrics, the method to express relations between\nthermodynamical variables requires a new function of the scale parameter. We\nalso imply the local and global thermodynamic stability through the Heat\nCapacity (HC) and Gibbs Energy (GB), respectively. The calculations and graphs\nshow the results, in the flat background, are very similar to Schwarzschild\nones. Also, some results show that the asymptotically AdS-RPBH is more\ncompatible with physical laws than the dS and flat backgrounds.",
            "author": [
                "Maryam Haditale",
                "Behrooz Malekolkalami"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16627v2",
                "http://arxiv.org/pdf/2308.16627v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16622v1",
            "title": "Developing a Scalable Benchmark for Assessing Large Language Models in\n  Knowledge Graph Engineering",
            "updated": "2023-08-31T10:31:19Z",
            "published": "2023-08-31T10:31:19Z",
            "summary": "As the field of Large Language Models (LLMs) evolves at an accelerated pace,\nthe critical need to assess and monitor their performance emerges. We introduce\na benchmarking framework focused on knowledge graph engineering (KGE)\naccompanied by three challenges addressing syntax and error correction, facts\nextraction and dataset generation. We show that while being a useful tool, LLMs\nare yet unfit to assist in knowledge graph generation with zero-shot prompting.\nConsequently, our LLM-KG-Bench framework provides automatic evaluation and\nstorage of LLM responses as well as statistical data and visualization tools to\nsupport tracking of prompt engineering and model performance.",
            "author": [
                "Lars-Peter Meyer",
                "Johannes Frey",
                "Kurt Junghanns",
                "Felix Brei",
                "Kirill Bulert",
                "Sabine Gr\u00fcnder-Fahrer",
                "Michael Martin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16622v1",
                "http://arxiv.org/pdf/2308.16622v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16614v2",
            "title": "Character varieties on a four-holed sphere",
            "updated": "2023-10-30T16:49:02Z",
            "published": "2023-08-31T10:20:09Z",
            "summary": "For each $k\\in\\mathbb{A}^4(\\mathbb{C})$, consider the character variety $X_k$\non a four-holed sphere. We prove that it is decidable whether or not any two\nintegral solutions of $X_k$ are in the same mapping class group orbit. For\nthis, using a delta map and Vieta maps, we will introduce graphs corresponding\nto the orbits and observe the properties of vertices on the graph.",
            "author": [
                "Eunju Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16614v2",
                "http://arxiv.org/pdf/2308.16614v2"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16609v2",
            "title": "Towards Long-Tailed Recognition for Graph Classification via\n  Collaborative Experts",
            "updated": "2023-09-05T14:46:38Z",
            "published": "2023-08-31T10:12:32Z",
            "summary": "Graph classification, aiming at learning the graph-level representations for\neffective class assignments, has received outstanding achievements, which\nheavily relies on high-quality datasets that have balanced class distribution.\nIn fact, most real-world graph data naturally presents a long-tailed form,\nwhere the head classes occupy much more samples than the tail classes, it thus\nis essential to study the graph-level classification over long-tailed data\nwhile still remaining largely unexplored. However, most existing long-tailed\nlearning methods in visions fail to jointly optimize the representation\nlearning and classifier training, as well as neglect the mining of the\nhard-to-classify classes. Directly applying existing methods to graphs may lead\nto sub-optimal performance, since the model trained on graphs would be more\nsensitive to the long-tailed distribution due to the complex topological\ncharacteristics. Hence, in this paper, we propose a novel long-tailed\ngraph-level classification framework via Collaborative Multi-expert Learning\n(CoMe) to tackle the problem. To equilibrate the contributions of head and tail\nclasses, we first develop balanced contrastive learning from the view of\nrepresentation learning, and then design an individual-expert classifier\ntraining based on hard class mining. In addition, we execute gated fusion and\ndisentangled knowledge distillation among the multiple experts to promote the\ncollaboration in a multi-expert framework. Comprehensive experiments are\nperformed on seven widely-used benchmark datasets to demonstrate the\nsuperiority of our method CoMe over state-of-the-art baselines.",
            "author": [
                "Siyu Yi",
                "Zhengyang Mao",
                "Wei Ju",
                "Yongdao Zhou",
                "Luchen Liu",
                "Xiao Luo",
                "Ming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16609v2",
                "http://arxiv.org/pdf/2308.16609v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16596v1",
            "title": "The Quest of Finding the Antidote to Sparse Double Descent",
            "updated": "2023-08-31T09:56:40Z",
            "published": "2023-08-31T09:56:40Z",
            "summary": "In energy-efficient schemes, finding the optimal size of deep learning models\nis very important and has a broad impact. Meanwhile, recent studies have\nreported an unexpected phenomenon, the sparse double descent: as the model's\nsparsity increases, the performance first worsens, then improves, and finally\ndeteriorates. Such a non-monotonic behavior raises serious questions about the\noptimal model's size to maintain high performance: the model needs to be\nsufficiently over-parametrized, but having too many parameters wastes training\nresources.\n  In this paper, we aim to find the best trade-off efficiently. More precisely,\nwe tackle the occurrence of the sparse double descent and present some\nsolutions to avoid it. Firstly, we show that a simple $\\ell_2$ regularization\nmethod can help to mitigate this phenomenon but sacrifices the\nperformance/sparsity compromise. To overcome this problem, we then introduce a\nlearning scheme in which distilling knowledge regularizes the student model.\nSupported by experimental results achieved using typical image classification\nsetups, we show that this approach leads to the avoidance of such a phenomenon.",
            "author": [
                "Victor Qu\u00e9tu",
                "Marta Milovanovi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16596v1",
                "http://arxiv.org/pdf/2308.16596v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16586v2",
            "title": "Learning to Represent Patches",
            "updated": "2023-10-03T23:00:33Z",
            "published": "2023-08-31T09:34:38Z",
            "summary": "Patch representation is crucial in automating various software engineering\ntasks, like determining patch accuracy or summarizing code changes. While\nrecent research has employed deep learning for patch representation, focusing\non token sequences or Abstract Syntax Trees (ASTs), they often miss the\nchange's semantic intent and the context of modified lines. To bridge this gap,\nwe introduce a novel method, Patcherizer. It delves into the intentions of\ncontext and structure, merging the surrounding code context with two innovative\nrepresentations. These capture the intention in code changes and the intention\nin AST structural modifications pre and post-patch. This holistic\nrepresentation aptly captures a patch's underlying intentions. Patcherizer\nemploys graph convolutional neural networks for structural intention graph\nrepresentation and transformers for intention sequence representation. We\nevaluated Patcherizer's embeddings' versatility in three areas: (1) Patch\ndescription generation, (2) Patch accuracy prediction, and (3) Patch intention\nidentification. Our experiments demonstrate the representation's efficacy\nacross all tasks, outperforming state-of-the-art methods. For example, in patch\ndescription generation, Patcherizer excels, showing an average boost of 19.39%\nin BLEU, 8.71% in ROUGE-L, and 34.03% in METEOR scores.",
            "author": [
                "Xunzhu Tang",
                "Haoye Tian",
                "Zhenghan Chen",
                "Weiguo Pian",
                "Saad Ezzini",
                "Abdoul Kader Kabore",
                "Andrew Habib",
                "Jacques Klein",
                "Tegawende F. Bissyande"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16586v2",
                "http://arxiv.org/pdf/2308.16586v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16561v1",
            "title": "MoMA: Momentum Contrastive Learning with Multi-head Attention-based\n  Knowledge Distillation for Histopathology Image Analysis",
            "updated": "2023-08-31T08:54:59Z",
            "published": "2023-08-31T08:54:59Z",
            "summary": "There is no doubt that advanced artificial intelligence models and high\nquality data are the keys to success in developing computational pathology\ntools. Although the overall volume of pathology data keeps increasing, a lack\nof quality data is a common issue when it comes to a specific task due to\nseveral reasons including privacy and ethical issues with patient data. In this\nwork, we propose to exploit knowledge distillation, i.e., utilize the existing\nmodel to learn a new, target model, to overcome such issues in computational\npathology. Specifically, we employ a student-teacher framework to learn a\ntarget model from a pre-trained, teacher model without direct access to source\ndata and distill relevant knowledge via momentum contrastive learning with\nmulti-head attention mechanism, which provides consistent and context-aware\nfeature representations. This enables the target model to assimilate\ninformative representations of the teacher model while seamlessly adapting to\nthe unique nuances of the target data. The proposed method is rigorously\nevaluated across different scenarios where the teacher model was trained on the\nsame, relevant, and irrelevant classification tasks with the target model.\nExperimental results demonstrate the accuracy and robustness of our approach in\ntransferring knowledge to different domains and tasks, outperforming other\nrelated methods. Moreover, the results provide a guideline on the learning\nstrategy for different types of tasks and scenarios in computational pathology.\nCode is available at: \\url{https://github.com/trinhvg/MoMA}.",
            "author": [
                "Trinh Thi Le Vuong",
                "Jin Tae Kwak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16561v1",
                "http://arxiv.org/pdf/2308.16561v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16559v1",
            "title": "VisAhoi: Towards a Library to Generate and Integrate Visualization\n  Onboarding Using High-level Visualization Grammars",
            "updated": "2023-08-31T08:49:15Z",
            "published": "2023-08-31T08:49:15Z",
            "summary": "Visualization onboarding supports users in reading, interpreting, and\nextracting information from visual data representations. General-purpose\nonboarding tools and libraries are applicable for explaining a wide range of\ngraphical user interfaces but cannot handle specific visualization\nrequirements. This paper describes a first step towards developing an\nonboarding library called VisAhoi, which is easy to integrate, extend,\nsemi-automate, reuse, and customize. VisAhoi supports the creation of\nonboarding elements for different visualization types and datasets. We\ndemonstrate how to extract and describe onboarding instructions using three\nwell-known high-level descriptive visualization grammars - Vega-Lite,\nPlotly.js, and ECharts. We show the applicability of our library by performing\ntwo usage scenarios that describe the integration of VisAhoi into a VA tool for\nthe analysis of high-throughput screening (HTS) data and, second, into a\nFlourish template to provide an authoring tool for data journalists for a\ntreemap visualization. We provide a supplementary website that demonstrates the\napplicability of VisAhoi to various visualizations, including a bar chart, a\nhorizon graph, a change matrix or heatmap, a scatterplot, and a treemap\nvisualization.",
            "author": [
                "Christina Stoiber",
                "Daniela Moitzi",
                "Holger Stitz",
                "Florian Grassinger",
                "Anto Silviya Geo Prakash",
                "Dominic Girardi",
                "Marc Streit",
                "Wolfgang Aigner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16559v1",
                "http://arxiv.org/pdf/2308.16559v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16553v1",
            "title": "The seating couple problem in even case",
            "updated": "2023-08-31T08:44:22Z",
            "published": "2023-08-31T08:44:22Z",
            "summary": "In this paper we consider the seating couple problem with an even number of\nseats, which, using graph theory terminology, can be stated as follows. Given a\npositive even integer $v=2n$ and a list $L$ containing $n$ positive integers\nnot exceeding $n$, is it always possible to find a perfect matching of $K_v$\nwhose list of edge-lengths is $L$? Up to now a (non-constructive) solution is\nknown only when all the edge-lengths are coprime with $v$. In this paper we\nfirstly present some necessary conditions for the existence of a solution.\nThen, we give a complete constructive solution when the list consists of one or\ntwo distinct elements, and when the list consists of consecutive integers\n$1,2,\\ldots,x$, each one appearing with the same multiplicity. Finally, we\npropose a conjecture and some open problems.",
            "author": [
                "M. Meszka",
                "A. Pasotti",
                "M. A. Pellegrini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16553v1",
                "http://arxiv.org/pdf/2308.16553v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C70, 05A17"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16544v1",
            "title": "Forecasting Emergency Department Crowding with Advanced Machine Learning\n  Models and Multivariable Input",
            "updated": "2023-08-31T08:34:20Z",
            "published": "2023-08-31T08:34:20Z",
            "summary": "Emergency department (ED) crowding is a significant threat to patient safety\nand it has been repeatedly associated with increased mortality. Forecasting\nfuture service demand has the potential patient outcomes. Despite active\nresearch on the subject, several gaps remain: 1) proposed forecasting models\nhave become outdated due to quick influx of advanced machine learning models\n(ML), 2) amount of multivariable input data has been limited and 3) discrete\nperformance metrics have been rarely reported. In this study, we document the\nperformance of a set of advanced ML models in forecasting ED occupancy 24 hours\nahead. We use electronic health record data from a large, combined ED with an\nextensive set of explanatory variables, including the availability of beds in\ncatchment area hospitals, traffic data from local observation stations, weather\nvariables, etc. We show that N-BEATS and LightGBM outpeform benchmarks with 11\n% and 9 % respective improvements and that DeepAR predicts next day crowding\nwith an AUC of 0.76 (95 % CI 0.69-0.84). To the best of our knowledge, this is\nthe first study to document the superiority of LightGBM and N-BEATS over\nstatistical benchmarks in the context of ED forecasting.",
            "author": [
                "Jalmari Tuominen",
                "Eetu Pulkkinen",
                "Jaakko Peltonen",
                "Juho Kanniainen",
                "Niku Oksala",
                "Ari Palom\u00e4ki",
                "Antti Roine"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16544v1",
                "http://arxiv.org/pdf/2308.16544v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16541v1",
            "title": "Scalable Incomplete Multi-View Clustering with Structure Alignment",
            "updated": "2023-08-31T08:30:26Z",
            "published": "2023-08-31T08:30:26Z",
            "summary": "The success of existing multi-view clustering (MVC) relies on the assumption\nthat all views are complete. However, samples are usually partially available\ndue to data corruption or sensor malfunction, which raises the research of\nincomplete multi-view clustering (IMVC). Although several anchor-based IMVC\nmethods have been proposed to process the large-scale incomplete data, they\nstill suffer from the following drawbacks: i) Most existing approaches neglect\nthe inter-view discrepancy and enforce cross-view representation to be\nconsistent, which would corrupt the representation capability of the model; ii)\nDue to the samples disparity between different views, the learned anchor might\nbe misaligned, which we referred as the Anchor-Unaligned Problem for Incomplete\ndata (AUP-ID). Such the AUP-ID would cause inaccurate graph fusion and degrades\nclustering performance. To tackle these issues, we propose a novel incomplete\nanchor graph learning framework termed Scalable Incomplete Multi-View\nClustering with Structure Alignment (SIMVC-SA). Specially, we construct the\nview-specific anchor graph to capture the complementary information from\ndifferent views. In order to solve the AUP-ID, we propose a novel structure\nalignment module to refine the cross-view anchor correspondence. Meanwhile, the\nanchor graph construction and alignment are jointly optimized in our unified\nframework to enhance clustering quality. Through anchor graph construction\ninstead of full graphs, the time and space complexity of the proposed SIMVC-SA\nis proven to be linearly correlated with the number of samples. Extensive\nexperiments on seven incomplete benchmark datasets demonstrate the\neffectiveness and efficiency of our proposed method. Our code is publicly\navailable at https://github.com/wy1019/SIMVC-SA.",
            "author": [
                "Yi Wen",
                "Siwei Wang",
                "Ke Liang",
                "Weixuan Liang",
                "Xinhang Wan",
                "Xinwang Liu",
                "Suyuan Liu",
                "Jiyuan Liu",
                "En Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611981",
                "http://arxiv.org/abs/2308.16541v1",
                "http://arxiv.org/pdf/2308.16541v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16530v1",
            "title": "Privacy-Preserving Medical Image Classification through Deep Learning\n  and Matrix Decomposition",
            "updated": "2023-08-31T08:21:09Z",
            "published": "2023-08-31T08:21:09Z",
            "summary": "Deep learning (DL)-based solutions have been extensively researched in the\nmedical domain in recent years, enhancing the efficacy of diagnosis, planning,\nand treatment. Since the usage of health-related data is strictly regulated,\nprocessing medical records outside the hospital environment for developing and\nusing DL models demands robust data protection measures. At the same time, it\ncan be challenging to guarantee that a DL solution delivers a minimum level of\nperformance when being trained on secured data, without being specifically\ndesigned for the given task. Our approach uses singular value decomposition\n(SVD) and principal component analysis (PCA) to obfuscate the medical images\nbefore employing them in the DL analysis. The capability of DL algorithms to\nextract relevant information from secured data is assessed on a task of\nangiographic view classification based on obfuscated frames. The security level\nis probed by simulated artificial intelligence (AI)-based reconstruction\nattacks, considering two threat actors with different prior knowledge of the\ntargeted data. The degree of privacy is quantitatively measured using\nsimilarity indices. Although a trade-off between privacy and accuracy should be\nconsidered, the proposed technique allows for training the angiographic view\nclassifier exclusively on secured data with satisfactory performance and with\nno computational overhead, model adaptation, or hyperparameter tuning. While\nthe obfuscated medical image content is well protected against human\nperception, the hypothetical reconstruction attack proved that it is also\ndifficult to recover the complete information of the original frames.",
            "author": [
                "Andreea Bianca Popescu",
                "Cosmin Ioan Nita",
                "Ioana Antonia Taca",
                "Anamaria Vizitiu",
                "Lucian Mihai Itu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MED59994.2023.10185748",
                "http://arxiv.org/abs/2308.16530v1",
                "http://arxiv.org/pdf/2308.16530v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16527v1",
            "title": "Unsupervised Recognition of Unknown Objects for Open-World Object\n  Detection",
            "updated": "2023-08-31T08:17:29Z",
            "published": "2023-08-31T08:17:29Z",
            "summary": "Open-World Object Detection (OWOD) extends object detection problem to a\nrealistic and dynamic scenario, where a detection model is required to be\ncapable of detecting both known and unknown objects and incrementally learning\nnewly introduced knowledge. Current OWOD models, such as ORE and OW-DETR, focus\non pseudo-labeling regions with high objectness scores as unknowns, whose\nperformance relies heavily on the supervision of known objects. While they can\ndetect the unknowns that exhibit similar features to the known objects, they\nsuffer from a severe label bias problem that they tend to detect all regions\n(including unknown object regions) that are dissimilar to the known objects as\npart of the background. To eliminate the label bias, this paper proposes a\nnovel approach that learns an unsupervised discriminative model to recognize\ntrue unknown objects from raw pseudo labels generated by unsupervised region\nproposal methods. The resulting model can be further refined by a\nclassification-free self-training method which iteratively extends pseudo\nunknown objects to the unlabeled regions. Experimental results show that our\nmethod 1) significantly outperforms the prior SOTA in detecting unknown objects\nwhile maintaining competitive performance of detecting known object classes on\nthe MS COCO dataset, and 2) achieves better generalization ability on the LVIS\nand Objects365 datasets.",
            "author": [
                "Ruohuan Fang",
                "Guansong Pang",
                "Lei Zhou",
                "Xiao Bai",
                "Jin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16527v1",
                "http://arxiv.org/pdf/2308.16527v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03219v1",
            "title": "Companion Animal Disease Diagnostics based on Literal-aware Medical\n  Knowledge Graph Representation Learning",
            "updated": "2023-08-31T08:14:07Z",
            "published": "2023-08-31T08:14:07Z",
            "summary": "Knowledge graph (KG) embedding has been used to benefit the diagnosis of\nanimal diseases by analyzing electronic medical records (EMRs), such as notes\nand veterinary records. However, learning representations to capture entities\nand relations with literal information in KGs is challenging as the KGs show\nheterogeneous properties and various types of literal information. Meanwhile,\nthe existing methods mostly aim to preserve graph structures surrounding target\nnodes without considering different types of literals, which could also carry\nsignificant information. In this paper, we propose a knowledge graph embedding\nmodel for the efficient diagnosis of animal diseases, which could learn various\ntypes of literal information and graph structure and fuse them into unified\nrepresentations, namely LiteralKG. Specifically, we construct a knowledge graph\nthat is built from EMRs along with literal information collected from various\nanimal hospitals. We then fuse different types of entities and node feature\ninformation into unified vector representations through gate networks. Finally,\nwe propose a self-supervised learning task to learn graph structure in pretext\ntasks and then towards various downstream tasks. Experimental results on link\nprediction tasks demonstrate that our model outperforms the baselines that\nconsist of state-of-the-art models. The source code is available at\nhttps://github.com/NSLab-CUK/LiteralKG.",
            "author": [
                "Van Thuy Hoang",
                "Sang Thanh Nguyen",
                "Sangmyeong Lee",
                "Jooho Lee",
                "Luong Vuong Nguyen",
                "O-Joun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03219v1",
                "http://arxiv.org/pdf/2309.03219v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16522v1",
            "title": "Graph-based SLAM-Aware Exploration with Prior Topo-Metric Information",
            "updated": "2023-08-31T08:11:48Z",
            "published": "2023-08-31T08:11:48Z",
            "summary": "Autonomous exploration requires the robot to explore an unknown environment\nwhile constructing an accurate map with the SLAM (Simultaneous Localization and\nMapping) techniques. Without prior information, the exploratory performance is\nusually conservative due to the limited planning horizon. This paper exploits a\nprior topo-metric graph of the environment to benefit both the exploration\nefficiency and the pose graph accuracy in SLAM. Based on recent advancements in\nrelating pose graph reliability with graph topology, we are able to formulate\nboth objectives into a SLAM-aware path planning problem over the prior graph,\nwhich finds a fast exploration path with informative loop closures that\nglobally stabilize the pose graph. Furthermore, we derive theoretical\nthresholds to speed up the greedy algorithm to the problem, which significantly\nprune non-optimal loop closures in iterations. The proposed planner is\nincorporated into a hierarchical exploration framework, with flexible features\nincluding path replanning and online prior map update that adds additional\ninformation to the prior graph. Extensive experiments indicate that our method\nhas comparable exploration efficiency to others while consistently maintaining\nhigher mapping accuracy in various environments. Our implementations will be\nopen-source on GitHub.",
            "author": [
                "Ruofei Bai",
                "Hongliang Guo",
                "Wei-Yun Yau",
                "Lihua Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16522v1",
                "http://arxiv.org/pdf/2308.16522v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16516v1",
            "title": "Curvature-based Pooling within Graph Neural Networks",
            "updated": "2023-08-31T08:00:08Z",
            "published": "2023-08-31T08:00:08Z",
            "summary": "Over-squashing and over-smoothing are two critical issues, that limit the\ncapabilities of graph neural networks (GNNs). While over-smoothing eliminates\nthe differences between nodes making them indistinguishable, over-squashing\nrefers to the inability of GNNs to propagate information over long distances,\nas exponentially many node states are squashed into fixed-size representations.\nBoth phenomena share similar causes, as both are largely induced by the graph\ntopology. To mitigate these problems in graph classification tasks, we propose\nCurvPool, a novel pooling method. CurvPool exploits the notion of curvature of\na graph to adaptively identify structures responsible for both over-smoothing\nand over-squashing. By clustering nodes based on the Balanced Forman curvature,\nCurvPool constructs a graph with a more suitable structure, allowing deeper\nmodels and the combination of distant information. We compare it to other\nstate-of-the-art pooling approaches and establish its competitiveness in terms\nof classification accuracy, computational complexity, and flexibility. CurvPool\noutperforms several comparable methods across all considered tasks. The most\nconsistent results are achieved by pooling densely connected clusters using the\nsum aggregation, as this allows additional information about the size of each\npool.",
            "author": [
                "Cedric Sanders",
                "Andreas Roth",
                "Thomas Liebig"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16516v1",
                "http://arxiv.org/pdf/2308.16516v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16515v1",
            "title": "A Discharging Method: Improved Kernels for Edge Triangle Packing and\n  Covering",
            "updated": "2023-08-31T07:57:56Z",
            "published": "2023-08-31T07:57:56Z",
            "summary": "\\textsc{Edge Triangle Packing} and \\textsc{Edge Triangle Covering} are dual\nproblems extensively studied in the field of parameterized complexity.\n  Given a graph $G$ and an integer $k$, \\textsc{Edge Triangle Packing} seeks to\ndetermine whether there exists a set of at least $k$ edge-disjoint triangles in\n$G$,\n  while \\textsc{Edge Triangle Covering} aims to find out whether there exists a\nset of at most $k$ edges that intersects all triangles in $G$.\n  Previous research has shown that \\textsc{Edge Triangle Packing} has a kernel\nof $(3+\\epsilon)k$ vertices, while \\textsc{Edge Triangle Covering} has a kernel\nof $6k$ vertices.\n  In this paper, we show that the two problems allow kernels of $3k$ vertices,\nimproving all previous results. A significant contribution of our work is the\nutilization of a novel discharging method for analyzing kernel size, which\nexhibits potential for analyzing other kernel algorithms.",
            "author": [
                "Zimo Sheng",
                "Mingyu Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16515v1",
                "http://arxiv.org/pdf/2308.16515v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16506v2",
            "title": "Characterisations for the depletion of reactant in a one-dimensional\n  dynamic combustion model",
            "updated": "2023-09-12T04:32:07Z",
            "published": "2023-08-31T07:37:09Z",
            "summary": "In this paper, a novel observation is made on a one-dimensional compressible\nNavier--Stokes model for the dynamic combustion of a reacting mixture of\n$\\gamma$-law gases ($\\gamma>1$) with discontinuous Arrhenius reaction rate\nfunction, on both bounded and unbounded domains. We show that the mass fraction\nof the reactant (denoted as $Z$) satisfies a weighted gradient estimate $Z_y/\n\\sqrt{Z} \\in L^\\infty_t L^2_y$, provided that at time zero the density is\nLipschitz continuous and bounded strictly away from zero and infinity.\nConsequently, the graph of $Z$ cannot form cusps or corners near the points\nwhere the reactant in the combustion process is completely depleted at any\ninstant, and the entropy of $Z$ is bounded from above. The key ingredient of\nthe proof is a new estimate based on the Fisher information, first exploited by\n[2, 7] with applications to PDEs in chemorepulsion and thermoelasticity. Along\nthe way, we also establish a Lipschitz estimate for the density.",
            "author": [
                "Siran Li",
                "Jianing Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16506v2",
                "http://arxiv.org/pdf/2308.16506v2"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16505v2",
            "title": "Recommender AI Agent: Integrating Large Language Models for Interactive\n  Recommendations",
            "updated": "2023-09-01T15:40:16Z",
            "published": "2023-08-31T07:36:44Z",
            "summary": "Recommender models excel at providing domain-specific item recommendations by\nleveraging extensive user behavior data. Despite their ability to act as\nlightweight domain experts, they struggle to perform versatile tasks such as\nproviding explanations and engaging in conversations. On the other hand, large\nlanguage models (LLMs) represent a significant step towards artificial general\nintelligence, showcasing remarkable capabilities in instruction comprehension,\ncommonsense reasoning, and human interaction. However, LLMs lack the knowledge\nof domain-specific item catalogs and behavioral patterns, particularly in areas\nthat diverge from general world knowledge, such as online e-commerce.\nFinetuning LLMs for each domain is neither economic nor efficient.\n  In this paper, we bridge the gap between recommender models and LLMs,\ncombining their respective strengths to create a versatile and interactive\nrecommender system. We introduce an efficient framework called InteRecAgent,\nwhich employs LLMs as the brain and recommender models as tools. We first\noutline a minimal set of essential tools required to transform LLMs into\nInteRecAgent. We then propose an efficient workflow within InteRecAgent for\ntask execution, incorporating key components such as a memory bus, dynamic\ndemonstration-augmented task planning, and reflection. InteRecAgent enables\ntraditional recommender systems, such as those ID-based matrix factorization\nmodels, to become interactive systems with a natural language interface through\nthe integration of LLMs. Experimental results on several public datasets show\nthat InteRecAgent achieves satisfying performance as a conversational\nrecommender system, outperforming general-purpose LLMs.",
            "author": [
                "Xu Huang",
                "Jianxun Lian",
                "Yuxuan Lei",
                "Jing Yao",
                "Defu Lian",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16505v2",
                "http://arxiv.org/pdf/2308.16505v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16497v1",
            "title": "Moore-Penrose Dagger Categories",
            "updated": "2023-08-31T07:00:02Z",
            "published": "2023-08-31T07:00:02Z",
            "summary": "The notion of a Moore-Penrose inverse (M-P inverse) was introduced by Moore\nin 1920 and rediscovered by Penrose in 1955. The M-P inverse of a complex\nmatrix is a special type of inverse which is unique, always exists, and can be\ncomputed using singular value decomposition. In a series of papers in the\n1980s, Puystjens and Robinson studied M-P inverses more abstractly in the\ncontext of dagger categories. Despite the fact that dagger categories are now a\nfundamental notion in categorical quantum mechanics, the notion of a M-P\ninverse has not (to our knowledge) been revisited since their work. One purpose\nof this paper is, thus, to renew the study of M-P inverses in dagger\ncategories.\n  Here we introduce the notion of a Moore-Penrose dagger category and provide\nmany examples including complex matrices, finite Hilbert spaces, dagger\ngroupoids, and inverse categories. We also introduce generalized versions of\nsingular value decomposition, compact singular value decomposition, and polar\ndecomposition for maps in a dagger category, and show how, having such a\ndecomposition is equivalent to having M-P inverses. This allows us to provide\nprecise characterizations of which maps have M-P inverses in a dagger\nidempotent complete category, a dagger kernel category with dagger biproducts\n(and negatives), and a dagger category with unique square roots.",
            "author": [
                "Robin Cockett",
                "Jean-Simon Pacaud Lemay"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.384.10",
                "http://arxiv.org/abs/2308.16497v1",
                "http://arxiv.org/pdf/2308.16497v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "F.4.1; G.1.3;"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16481v2",
            "title": "Point-TTA: Test-Time Adaptation for Point Cloud Registration Using\n  Multitask Meta-Auxiliary Learning",
            "updated": "2023-09-01T18:13:58Z",
            "published": "2023-08-31T06:32:11Z",
            "summary": "We present Point-TTA, a novel test-time adaptation framework for point cloud\nregistration (PCR) that improves the generalization and the performance of\nregistration models. While learning-based approaches have achieved impressive\nprogress, generalization to unknown testing environments remains a major\nchallenge due to the variations in 3D scans. Existing methods typically train a\ngeneric model and the same trained model is applied on each instance during\ntesting. This could be sub-optimal since it is difficult for the same model to\nhandle all the variations during testing. In this paper, we propose a test-time\nadaptation approach for PCR. Our model can adapt to unseen distributions at\ntest-time without requiring any prior knowledge of the test data. Concretely,\nwe design three self-supervised auxiliary tasks that are optimized jointly with\nthe primary PCR task. Given a test instance, we adapt our model using these\nauxiliary tasks and the updated model is used to perform the inference. During\ntraining, our model is trained using a meta-auxiliary learning approach, such\nthat the adapted model via auxiliary tasks improves the accuracy of the primary\ntask. Experimental results demonstrate the effectiveness of our approach in\nimproving generalization of point cloud registration and outperforming other\nstate-of-the-art approaches.",
            "author": [
                "Ahmed Hatem",
                "Yiming Qian",
                "Yang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16481v2",
                "http://arxiv.org/pdf/2308.16481v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16470v2",
            "title": "Domain-adaptive Message Passing Graph Neural Network",
            "updated": "2023-10-17T04:57:23Z",
            "published": "2023-08-31T05:26:08Z",
            "summary": "Cross-network node classification (CNNC), which aims to classify nodes in a\nlabel-deficient target network by transferring the knowledge from a source\nnetwork with abundant labels, draws increasing attention recently. To address\nCNNC, we propose a domain-adaptive message passing graph neural network\n(DM-GNN), which integrates graph neural network (GNN) with conditional\nadversarial domain adaptation. DM-GNN is capable of learning informative\nrepresentations for node classification that are also transferrable across\nnetworks. Firstly, a GNN encoder is constructed by dual feature extractors to\nseparate ego-embedding learning from neighbor-embedding learning so as to\njointly capture commonality and discrimination between connected nodes.\nSecondly, a label propagation node classifier is proposed to refine each node's\nlabel prediction by combining its own prediction and its neighbors' prediction.\nIn addition, a label-aware propagation scheme is devised for the labeled source\nnetwork to promote intra-class propagation while avoiding inter-class\npropagation, thus yielding label-discriminative source embeddings. Thirdly,\nconditional adversarial domain adaptation is performed to take the\nneighborhood-refined class-label information into account during adversarial\ndomain adaptation, so that the class-conditional distributions across networks\ncan be better matched. Comparisons with eleven state-of-the-art methods\ndemonstrate the effectiveness of the proposed DM-GNN.",
            "author": [
                "Xiao Shen",
                "Shirui Pan",
                "Kup-Sze Choi",
                "Xi Zhou"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.neunet.2023.04.038",
                "http://arxiv.org/abs/2308.16470v2",
                "http://arxiv.org/pdf/2308.16470v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16469v2",
            "title": "Link Prediction for Wikipedia Articles as a Natural Language Inference\n  Task",
            "updated": "2023-09-05T09:34:55Z",
            "published": "2023-08-31T05:25:04Z",
            "summary": "Link prediction task is vital to automatically understanding the structure of\nlarge knowledge bases. In this paper, we present our system to solve this task\nat the Data Science and Advanced Analytics 2023 Competition \"Efficient and\nEffective Link Prediction\" (DSAA-2023 Competition) with a corpus containing\n948,233 training and 238,265 for public testing. This paper introduces an\napproach to link prediction in Wikipedia articles by formulating it as a\nnatural language inference (NLI) task. Drawing inspiration from recent\nadvancements in natural language processing and understanding, we cast link\nprediction as an NLI task, wherein the presence of a link between two articles\nis treated as a premise, and the task is to determine whether this premise\nholds based on the information presented in the articles. We implemented our\nsystem based on the Sentence Pair Classification for Link Prediction for the\nWikipedia Articles task. Our system achieved 0.99996 Macro F1-score and 1.00000\nMacro F1-score for the public and private test sets, respectively. Our team\nUIT-NLP ranked 3rd in performance on the private test set, equal to the scores\nof the first and second places. Our code is publicly for research purposes.",
            "author": [
                "Chau-Thang Phan",
                "Quoc-Nam Nguyen",
                "Kiet Van Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16469v2",
                "http://arxiv.org/pdf/2308.16469v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16458v4",
            "title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual\n  Pragmatic Knowledge",
            "updated": "2023-12-04T11:05:29Z",
            "published": "2023-08-31T04:52:58Z",
            "summary": "Pre-trained large language models have significantly improved code\ngeneration. As these models scale up, there is an increasing need for the\noutput to handle more intricate tasks and to be appropriately specialized to\nparticular domains. Here, we target bioinformatics due to the amount of\nspecialized domain knowledge, algorithms, and data operations this discipline\nrequires. We present BioCoder, a benchmark developed to evaluate large language\nmodels (LLMs) in generating bioinformatics-specific code. BioCoder spans a\nbroad spectrum of the field and covers cross-file dependencies, class\ndeclarations, and global variables. It incorporates 1026 Python functions and\n1243 Java methods extracted from GitHub, along with 253 examples from the\nRosalind Project, all pertaining to bioinformatics. Using topic modeling we\nshow that overall coverage of the included code is representative of the full\nspectrum of bioinformatics calculations. BioCoder incorporates a fuzz-testing\nframework for evaluation. We have applied it to evaluate many models including\nInCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+, InstructCodeT5+,\nGPT-3.5, and GPT-4. Furthermore, we finetuned StarCoder, demonstrating how our\ndataset can effectively enhance the performance of LLMs on our benchmark (by\n>15% in terms of Pass@K in certain prompt configurations and always >3%). The\nresults highlight two key aspects of successful models: (1) Successful models\naccommodate a long prompt (> ~2600 tokens) with full context, for functional\ndependencies. (2) They contain specific domain knowledge of bioinformatics,\nbeyond just general coding knowledge. This is evident from the performance gain\nof GPT-3.5/4 compared to the smaller models on the benchmark (50% vs up to\n~25%). Our dataset, benchmark, Docker images, and scripts required for testing\nare all available at https://github.com/gersteinlab/biocoder.",
            "author": [
                "Xiangru Tang",
                "Bill Qian",
                "Rick Gao",
                "Jiakang Chen",
                "Xinyun Chen",
                "Mark Gerstein"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16458v4",
                "http://arxiv.org/pdf/2308.16458v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16454v1",
            "title": "Adversarial Finetuning with Latent Representation Constraint to Mitigate\n  Accuracy-Robustness Tradeoff",
            "updated": "2023-08-31T04:46:12Z",
            "published": "2023-08-31T04:46:12Z",
            "summary": "This paper addresses the tradeoff between standard accuracy on clean examples\nand robustness against adversarial examples in deep neural networks (DNNs).\nAlthough adversarial training (AT) improves robustness, it degrades the\nstandard accuracy, thus yielding the tradeoff. To mitigate this tradeoff, we\npropose a novel AT method called ARREST, which comprises three components: (i)\nadversarial finetuning (AFT), (ii) representation-guided knowledge distillation\n(RGKD), and (iii) noisy replay (NR). AFT trains a DNN on adversarial examples\nby initializing its parameters with a DNN that is standardly pretrained on\nclean examples. RGKD and NR respectively entail a regularization term and an\nalgorithm to preserve latent representations of clean examples during AFT. RGKD\npenalizes the distance between the representations of the standardly pretrained\nand AFT DNNs. NR switches input adversarial examples to nonadversarial ones\nwhen the representation changes significantly during AFT. By combining these\ncomponents, ARREST achieves both high standard accuracy and robustness.\nExperimental results demonstrate that ARREST mitigates the tradeoff more\neffectively than previous AT-based methods do.",
            "author": [
                "Satoshi Suzuki",
                "Shin'ya Yamaguchi",
                "Shoichiro Takeda",
                "Sekitoshi Kanai",
                "Naoki Makishima",
                "Atsushi Ando",
                "Ryo Masumura"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16454v1",
                "http://arxiv.org/pdf/2308.16454v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16441v1",
            "title": "Contrastive Representation Learning Based on Multiple Node-centered\n  Subgraphs",
            "updated": "2023-08-31T04:04:09Z",
            "published": "2023-08-31T04:04:09Z",
            "summary": "As the basic element of graph-structured data, node has been recognized as\nthe main object of study in graph representation learning. A single node\nintuitively has multiple node-centered subgraphs from the whole graph (e.g.,\none person in a social network has multiple social circles based on his\ndifferent relationships). We study this intuition under the framework of graph\ncontrastive learning, and propose a multiple node-centered subgraphs\ncontrastive representation learning method to learn node representation on\ngraphs in a self-supervised way. Specifically, we carefully design a series of\nnode-centered regional subgraphs of the central node. Then, the mutual\ninformation between different subgraphs of the same node is maximized by\ncontrastive loss. Experiments on various real-world datasets and different\ndownstream tasks demonstrate that our model has achieved state-of-the-art\nresults.",
            "author": [
                "Dong Li",
                "Wenjun Wang",
                "Minglai Shao",
                "Chen Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16441v1",
                "http://arxiv.org/pdf/2308.16441v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16426v1",
            "title": "Enumerating minimal vertex covers and dominating sets with capacity\n  and/or connectivity constraints",
            "updated": "2023-08-31T03:30:43Z",
            "published": "2023-08-31T03:30:43Z",
            "summary": "In this paper, we consider the problems of enumerating minimal vertex covers\nand minimal dominating sets with capacity and/or connectivity constraints. We\ndevelop polynomial-delay enumeration algorithms for these problems on\nbounded-degree graphs. For the case of minimal connected vertex cover, our\nalgorithm runs in polynomial delay even on the class of $d$-claw free graphs,\nwhich extends the result on bounded-degree graphs. To complement these\nalgorithmic results, we show that the problems of enumerating minimal connected\nvertex covers and minimal capacitated vertex covers in bipartite graphs are at\nleast as hard as enumerating minimal transversals in hypergraphs.",
            "author": [
                "Yasuaki Kobayashi",
                "Kazuhiro Kurita",
                "Yasuko Matsui",
                "Hirotaka Ono"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16426v1",
                "http://arxiv.org/pdf/2308.16426v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16415v1",
            "title": "Knowledge Distillation from Non-streaming to Streaming ASR Encoder using\n  Auxiliary Non-streaming Layer",
            "updated": "2023-08-31T02:58:33Z",
            "published": "2023-08-31T02:58:33Z",
            "summary": "Streaming automatic speech recognition (ASR) models are restricted from\naccessing future context, which results in worse performance compared to the\nnon-streaming models. To improve the performance of streaming ASR, knowledge\ndistillation (KD) from the non-streaming to streaming model has been studied,\nmainly focusing on aligning the output token probabilities. In this paper, we\npropose a layer-to-layer KD from the teacher encoder to the student encoder. To\nensure that features are extracted using the same context, we insert auxiliary\nnon-streaming branches to the student and perform KD from the non-streaming\nteacher layer to the non-streaming auxiliary layer. We design a special KD loss\nthat leverages the autoregressive predictive coding (APC) mechanism to\nencourage the streaming model to predict unseen future contexts. Experimental\nresults show that the proposed method can significantly reduce the word error\nrate compared to previous token probability distillation methods.",
            "author": [
                "Kyuhong Shim",
                "Jinkyu Lee",
                "Simyung Chang",
                "Kyuwoong Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16415v1",
                "http://arxiv.org/pdf/2308.16415v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16406v1",
            "title": "CktGNN: Circuit Graph Neural Network for Electronic Design Automation",
            "updated": "2023-08-31T02:20:25Z",
            "published": "2023-08-31T02:20:25Z",
            "summary": "The electronic design automation of analog circuits has been a longstanding\nchallenge in the integrated circuit field due to the huge design space and\ncomplex design trade-offs among circuit specifications. In the past decades,\nintensive research efforts have mostly been paid to automate the transistor\nsizing with a given circuit topology. By recognizing the graph nature of\ncircuits, this paper presents a Circuit Graph Neural Network (CktGNN) that\nsimultaneously automates the circuit topology generation and device sizing\nbased on the encoder-dependent optimization subroutines. Particularly, CktGNN\nencodes circuit graphs using a two-level GNN framework (of nested GNN) where\ncircuits are represented as combinations of subgraphs in a known subgraph\nbasis. In this way, it significantly improves design efficiency by reducing the\nnumber of subgraphs to perform message passing. Nonetheless, another critical\nroadblock to advancing learning-assisted circuit design automation is a lack of\npublic benchmarks to perform canonical assessment and reproducible research. To\ntackle the challenge, we introduce Open Circuit Benchmark (OCB), an\nopen-sourced dataset that contains $10$K distinct operational amplifiers with\ncarefully-extracted circuit specifications. OCB is also equipped with\ncommunicative circuit generation and evaluation capabilities such that it can\nhelp to generalize CktGNN to design various analog circuits by producing\ncorresponding datasets. Experiments on OCB show the extraordinary advantages of\nCktGNN through representation-based optimization frameworks over other recent\npowerful GNN baselines and human experts' manual designs. Our work paves the\nway toward a learning-based open-sourced design automation for analog circuits.\nOur source code is available at \\url{https://github.com/zehao-dong/CktGNN}.",
            "author": [
                "Zehao Dong",
                "Weidong Cao",
                "Muhan Zhang",
                "Dacheng Tao",
                "Yixin Chen",
                "Xuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16406v1",
                "http://arxiv.org/pdf/2308.16406v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16404v1",
            "title": "Deformation Robust Text Spotting with Geometric Prior",
            "updated": "2023-08-31T02:13:15Z",
            "published": "2023-08-31T02:13:15Z",
            "summary": "The goal of text spotting is to perform text detection and recognition in an\nend-to-end manner. Although the diversity of luminosity and orientation in\nscene texts has been widely studied, the font diversity and shape variance of\nthe same character are ignored in recent works, since most characters in\nnatural images are rendered in standard fonts. To solve this problem, we\npresent a Chinese Artistic Dataset, termed as ARText, which contains 33,000\nartistic images with rich shape deformation and font diversity. Based on this\ndatabase, we develop a deformation robust text spotting method (DR TextSpotter)\nto solve the recognition problem of complex deformation of characters in\ndifferent fonts. Specifically, we propose a geometric prior module to highlight\nthe important features based on the unsupervised landmark detection\nsub-network. A graph convolution network is further constructed to fuse the\ncharacter features and landmark features, and then performs semantic reasoning\nto enhance the discrimination for different characters. The experiments are\nconducted on ARText and IC19-ReCTS datasets. Our results demonstrate the\neffectiveness of our proposed method.",
            "author": [
                "Xixuan Hao",
                "Aozhong Zhang",
                "Xianze Meng",
                "Bin Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16404v1",
                "http://arxiv.org/pdf/2308.16404v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16403v2",
            "title": "Balancing between the Local and Global Structures (LGS) in Graph\n  Embedding",
            "updated": "2023-09-02T00:11:42Z",
            "published": "2023-08-31T02:12:46Z",
            "summary": "We present a method for balancing between the Local and Global Structures\n(LGS) in graph embedding, via a tunable parameter. Some embedding methods aim\nto capture global structures, while others attempt to preserve local\nneighborhoods. Few methods attempt to do both, and it is not always possible to\ncapture well both local and global information in two dimensions, which is\nwhere most graph drawing live. The choice of using a local or a global\nembedding for visualization depends not only on the task but also on the\nstructure of the underlying data, which may not be known in advance. For a\ngiven graph, LGS aims to find a good balance between the local and global\nstructure to preserve. We evaluate the performance of LGS with synthetic and\nreal-world datasets and our results indicate that it is competitive with the\nstate-of-the-art methods, using established quality metrics such as stress and\nneighborhood preservation. We introduce a novel quality metric, cluster\ndistance preservation, to assess intermediate structure capture. All\nsource-code, datasets, experiments and analysis are available online.",
            "author": [
                "Jacob Miller",
                "Vahan Huroyan",
                "Stephen Kobourov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16403v2",
                "http://arxiv.org/pdf/2308.16403v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CG",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16402v1",
            "title": "GDD type Spanning Bipartite Block Designs",
            "updated": "2023-08-31T02:12:08Z",
            "published": "2023-08-31T02:12:08Z",
            "summary": "There is a one-to-one correspondence between the point set of a group\ndivisible design (GDD) with $v_1$ groups of $v_2$ points and the edge set of a\ncomplete bipartite graph $K_{v_1,v_2}$. A block of GDD corresponds to a\nsubgraph of $K_{v_1,v_2}$. A set of subgraphs of $K_{v_1,v_2}$ is constructed\nfrom a block set of GDDs. If the GDD satisfies the $\\lambda_1, \\lambda_2$\nconcurrence condition, then the set of subgraphs also satisfies the spanning\nbipartite block design (SBBD) conditions. We also propose a method to construct\nSBBD directly from an $(r,\\lambda)$-design and a difference matrix over a\ngroup. Suppose the $(r,\\lambda)$-design consists of $v_2$ points and $v_1$\nblocks. When $v_1 >> v_2$, we show a method to construct a SBBD with $v_1$ is\nclose to $v_2$ by partitioning the block set.",
            "author": [
                "Shoko Chisaki",
                "Ryoh Fuji-Hara",
                "Nobuko Miyamoto"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16402v1",
                "http://arxiv.org/pdf/2308.16402v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05B05, 05B10, 51E30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16401v1",
            "title": "Optimality and Constructions of Spanning Bipartite Block Designs",
            "updated": "2023-08-31T02:11:51Z",
            "published": "2023-08-31T02:11:51Z",
            "summary": "We consider a statistical problem to estimate variables (effects) that are\nassociated with the edges of a complete bipartite graph $K_{v_1, v_2}=(V_1, V_2\n\\, ; E)$. Each data is obtained as a sum of selected effects, a subset of $E$.\nIn order to estimate efficiently, we propose a design called Spanning Bipartite\nBlock Design (SBBD). For SBBDs such that the effects are estimable, we proved\nthat the estimators have the same variance (variance balanced). If each block\n(a subgraph of $K_{v_1, v_2}$) of SBBD is a semi-regular or a regular bipartite\ngraph, we show that the design is A-optimum. We also show a construction of\nSBBD using an ($r,\\lambda$)-design and an ordered design. A BIBD with prime\npower blocks gives an A-optimum semi-regular or regular SBBD. At last, we\nmention that this SBBD is able to use for deep learning.",
            "author": [
                "Shoko Chisaki",
                "Ryoh Fuji-Hara",
                "Nobuko Miyamoto"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16401v1",
                "http://arxiv.org/pdf/2308.16401v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.ST",
                "stat.TH",
                "62K05, 62K10, 05B05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16388v1",
            "title": "Is 'being above the median' a noise sensitive property?",
            "updated": "2023-08-31T01:42:29Z",
            "published": "2023-08-31T01:42:29Z",
            "summary": "Assign independent weights to the edges of the square lattice, from the\nuniform distribution on $\\{a,b\\}$ for some $0<a<b<\\infty$. The weighted graph\ninduces a random metric on $\\mathbb{Z}^2$. Let $T_n$ denote the distance\nbetween $(0,0)$ and $(n,0)$ in this metric. The distribution of $T_n$ has a\nwell-defined median. Itai Benjamini asked in 2011 if the sequence of Boolean\nfunctions encoding whether $T_n$ exceeds its median is noise sensitive? In this\npaper we present the first progress on Benjamini's problem. More precisely, we\nstudy the minimal weight along any path crossing an $n\\times n$-square\nhorizontally and whose vertical fluctuation is smaller than $n^{1/22}$, and\nshow that for this observable, 'being above the median' is a noise sensitive\nproperty.",
            "author": [
                "Daniel Ahlberg",
                "Daniel de la Riva"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16388v1",
                "http://arxiv.org/pdf/2308.16388v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16386v1",
            "title": "RGB-T Tracking via Multi-Modal Mutual Prompt Learning",
            "updated": "2023-08-31T01:13:01Z",
            "published": "2023-08-31T01:13:01Z",
            "summary": "Object tracking based on the fusion of visible and thermal im-ages, known as\nRGB-T tracking, has gained increasing atten-tion from researchers in recent\nyears. How to achieve a more comprehensive fusion of information from the two\nmodalities with fewer computational costs has been a problem that re-searchers\nhave been exploring. Recently, with the rise of prompt learning in computer\nvision, we can better transfer knowledge from visual large models to downstream\ntasks. Considering the strong complementarity between visible and thermal\nmodalities, we propose a tracking architecture based on mutual prompt learning\nbetween the two modalities. We also design a lightweight prompter that\nincorporates attention mechanisms in two dimensions to transfer information\nfrom one modality to the other with lower computational costs, embedding it\ninto each layer of the backbone. Extensive ex-periments have demonstrated that\nour proposed tracking ar-chitecture is effective and efficient, achieving\nstate-of-the-art performance while maintaining high running speeds.",
            "author": [
                "Yang Luo",
                "Xiqing Guo",
                "Hui Feng",
                "Lei Ao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16386v1",
                "http://arxiv.org/pdf/2308.16386v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16385v1",
            "title": "BenchTemp: A General Benchmark for Evaluating Temporal Graph Neural\n  Networks",
            "updated": "2023-08-31T01:03:27Z",
            "published": "2023-08-31T01:03:27Z",
            "summary": "To handle graphs in which features or connectivities are evolving over time,\na series of temporal graph neural networks (TGNNs) have been proposed. Despite\nthe success of these TGNNs, the previous TGNN evaluations reveal several\nlimitations regarding four critical issues: 1) inconsistent datasets, 2)\ninconsistent evaluation pipelines, 3) lacking workload diversity, and 4)\nlacking efficient comparison. Overall, there lacks an empirical study that puts\nTGNN models onto the same ground and compares them comprehensively. To this\nend, we propose BenchTemp, a general benchmark for evaluating TGNN models on\nvarious workloads. BenchTemp provides a set of benchmark datasets so that\ndifferent TGNN models can be fairly compared. Further, BenchTemp engineers a\nstandard pipeline that unifies the TGNN evaluation. With BenchTemp, we\nextensively compare the representative TGNN models on different tasks (e.g.,\nlink prediction and node classification) and settings (transductive and\ninductive), w.r.t. both effectiveness and efficiency metrics. We have made\nBenchTemp publicly available at https://github.com/qianghuangwhu/benchtemp.",
            "author": [
                "Qiang Huang",
                "Jiawei Jiang",
                "Xi Susie Rao",
                "Ce Zhang",
                "Zhichao Han",
                "Zitao Zhang",
                "Xin Wang",
                "Yongjun He",
                "Quanqing Xu",
                "Yang Zhao",
                "Chuang Hu",
                "Shuo Shang",
                "Bo Du"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16385v1",
                "http://arxiv.org/pdf/2308.16385v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16378v1",
            "title": "Unexpected Averages of Mixing Matrices",
            "updated": "2023-08-31T00:44:58Z",
            "published": "2023-08-31T00:44:58Z",
            "summary": "The (standard) average mixing matrix of a continuous-time quantum walk is\ncomputed by taking the expected value of the mixing matrices of the walk under\nthe uniform sampling distribution on the real line. In this paper we consider\nalternative probability distributions, either discrete or continuous, and first\nwe show that several algebraic properties that hold for the average mixing\nmatrix still stand for this more general setting. Then, we provide examples of\ngraphs and choices of distributions where the average mixing matrix behaves in\nan unexpected way: for instance, we show that there are probability\ndistributions for which the average mixing matrices of the paths on three or\nfour vertices have constant entries, opening a significant line of\ninvestigation about how to use classical probability distributions to sample\nquantum walks and obtain desired quantum effects. We present results connecting\nthe trace of the average mixing matrix and quantum walk properties, and we show\nthat the Gram matrix of average states is the average mixing matrix of a\ncertain related distribution. Throughout the text, we employ concepts of\nclassical probability theory not usually seen in texts about quantum walks.",
            "author": [
                "Pedro Baptista",
                "Gabriel Coutinho",
                "Vitor Marques"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16378v1",
                "http://arxiv.org/pdf/2308.16378v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.CO",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16375v3",
            "title": "A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and\n  Applications",
            "updated": "2023-09-19T15:00:52Z",
            "published": "2023-08-31T00:31:08Z",
            "summary": "Graph Neural Networks (GNNs) have gained significant attention owing to their\nability to handle graph-structured data and the improvement in practical\napplications. However, many of these models prioritize high utility\nperformance, such as accuracy, with a lack of privacy consideration, which is a\nmajor concern in modern society where privacy attacks are rampant. To address\nthis issue, researchers have started to develop privacy-preserving GNNs.\nDespite this progress, there is a lack of a comprehensive overview of the\nattacks and the techniques for preserving privacy in the graph domain. In this\nsurvey, we aim to address this gap by summarizing the attacks on graph data\naccording to the targeted information, categorizing the privacy preservation\ntechniques in GNNs, and reviewing the datasets and applications that could be\nused for analyzing/solving privacy issues in GNNs. We also outline potential\ndirections for future research in order to build better privacy-preserving\nGNNs.",
            "author": [
                "Yi Zhang",
                "Yuying Zhao",
                "Zhaoqing Li",
                "Xueqi Cheng",
                "Yu Wang",
                "Olivera Kotevska",
                "Philip S. Yu",
                "Tyler Derr"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16375v3",
                "http://arxiv.org/pdf/2308.16375v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16354v1",
            "title": "Catalog Phrase Grounding (CPG): Grounding of Product Textual Attributes\n  in Product Images for e-commerce Vision-Language Applications",
            "updated": "2023-08-30T23:02:26Z",
            "published": "2023-08-30T23:02:26Z",
            "summary": "We present Catalog Phrase Grounding (CPG), a model that can associate product\ntextual data (title, brands) into corresponding regions of product images\n(isolated product region, brand logo region) for e-commerce vision-language\napplications. We use a state-of-the-art modulated multimodal transformer\nencoder-decoder architecture unifying object detection and phrase-grounding. We\ntrain the model in self-supervised fashion with 2.3 million image-text pairs\nsynthesized from an e-commerce site. The self-supervision data is annotated\nwith high-confidence pseudo-labels generated with a combination of teacher\nmodels: a pre-trained general domain phrase grounding model (e.g. MDETR) and a\nspecialized logo detection model. This allows CPG, as a student model, to\nbenefit from transfer knowledge from these base models combining general-domain\nknowledge and specialized knowledge. Beyond immediate catalog phrase grounding\ntasks, we can benefit from CPG representations by incorporating them as ML\nfeatures into downstream catalog applications that require deep semantic\nunderstanding of products. Our experiments on product-brand matching, a\nchallenging e-commerce application, show that incorporating CPG representations\ninto the existing production ensemble system leads to on average 5% recall\nimprovement across all countries globally (with the largest lift of 11% in a\nsingle country) at fixed 95% precision, outperforming other alternatives\nincluding a logo detection teacher model and ResNet50.",
            "author": [
                "Wenyi Wu",
                "Karim Bouyarmane",
                "Ismail Tutar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16354v1",
                "http://arxiv.org/pdf/2308.16354v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16339v1",
            "title": "Open and Closed-Loop Weight Selection for Pattern Control of\n  Paraboloidal Reflector Antennas with Reconfigurable Rim Scattering",
            "updated": "2023-08-30T22:19:21Z",
            "published": "2023-08-30T22:19:21Z",
            "summary": "It has been demonstrated that modifying the rim scattering of a paraboloidal\nreflector antenna through the use of reconfigurable elements along the rim\nfacilitates sidelobe modification including cancelling sidelobes. In this work\nwe investigate techniques for determining unit-modulus weights (i.e., weights\nwhich modify the phase of the scattered electric field) to accomplish sidelobe\ncancellation at arbitrary angles from the reflector axis. Specifically, it is\nshown that despite the large search space and the non-convexity of the cost\nfunction, weights can be found with reasonable complexity which provide\nsignificant cancellation capability. It is demonstrated that this can be done\nusing open-loop (i.e., with pattern knowledge), closed-loop (without pattern\nknowledge), or hybrid (with inexact pattern knowledge) techniques. Initially,\nwe examine the use of unconstrained weights. A primary finding is that\nsufficiently deep nulls are possible with essentially no change in the main\nlobe with practical (binary or quaternary) phase-only weights. The initial\nalgorithms require a knowledge of the antenna pattern (what we term an\n``open-loop'' approach). However, since perfect knowledge of the pattern is not\ntypically available, we also develop closed-loop approaches which require no\nknowledge of the antenna pattern. It is found that these closed-loop approaches\nprovide similar performance. We demonstrate the time-varying performance of\nclosed-loop approaches by simulating an interfering source which moves across\nthe field of view of the antenna. Finally, we leverage the advantages of both\nopen-loop and closed-loop approaches in a hybrid technique that exploits\ninexact knowledge of the pattern by seeding a closed-loop optimization with an\nopen-loop solution as its starting point.",
            "author": [
                "R. Michael Buehrer",
                "William W. Howard",
                "Steven Ellingson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16339v1",
                "http://arxiv.org/pdf/2308.16339v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16309v1",
            "title": "Inferring Compensatory Kinase Networks in Yeast using Prolog",
            "updated": "2023-08-30T20:29:41Z",
            "published": "2023-08-30T20:29:41Z",
            "summary": "Signalling pathways are conserved across different species, therefore making\nyeast a model organism to study these via disruption of kinase activity. Yeast\nhas 159 genes that encode protein kinases and phosphatases, and 136 of these\nhave counterparts in humans. Therefore any insight in this model organism could\npotentially offer indications of mechanisms of action in the human kinome. The\nstudy utilises a Prolog-based approach, data from a yeast kinase deletions\nstrains study and publicly available kinase-protein associations. Prolog, a\nprogramming language that is well-suited for symbolic reasoning is used to\nreason over the data and infer compensatory kinase networks. This approach is\nbased on the idea that when a kinase is knocked out, other kinases may\ncompensate for this loss of activity. Background knowledge on kinases targeting\nproteins is used to guide the analysis. This knowledge is used to infer the\npotential compensatory interactions between kinases based on the changes in\nphosphorylation observed in the phosphoproteomics data from the yeast study.\nThe results demonstrate the effectiveness of the Prolog-based approach in\nanalysing complex cell signalling mechanisms in yeast. The inferred\ncompensatory kinase networks provide new insights into the regulation of cell\nsignalling in yeast and may aid in the identification of potential therapeutic\ntargets for modulating signalling pathways in yeast and other organisms.",
            "author": [
                "George A. Elder",
                "Conrad Bessant"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.26",
                "http://arxiv.org/abs/2308.16309v1",
                "http://arxiv.org/pdf/2308.16309v1"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.05667v3",
            "title": "Maxwell's Current in Mitochondria and Nerve",
            "updated": "2023-09-28T15:17:10Z",
            "published": "2023-08-30T20:14:35Z",
            "summary": "Maxwell defined true current in a way not widely used today. He said that\n\"... true electric current ... is not the same thing as the current of\nconduction but that the time-variation of the electric displacement must be\ntaken into account in estimating the total movement of electricity\". We show\nthat true current is a universal property independent of properties of matter,\nshown using mathematics without approximate dielectric constants. The resulting\nMaxwell Current Law is a generalization of the Kirchhoff Law of Current of\ncircuits, that also includes displacement current. Engineers introduce\ndisplacement current through supplementary 'stray capacitances'. The Maxwell\nCurrent Law does not require currents to be confined to circuits. It can be\napplied to three dimensional systems like mitochondria and nerve cells. The\nMaxwell Current Law clarifies the flow of electrons, protons, and ions in\nmitochondria that generate ATP, the molecule used to store chemical energy\nthroughout life. The currents are globally coupled because mitochondria are\nshort. The Maxwell Current Law approach reinterprets the classical chemiosmotic\nhypothesis of ATP production. The conduction current of protons in mitochondria\nis driven by the protonmotive force including its component electrical\npotential, just as in the classical chemiosmotic hypothesis. Conduction current\nis, however, just a part of the true current analyzed by Maxwell. Maxwell's\ncurrent does not accumulate, in contrast to the conduction current of protons\nwhich does accumulate. Details of accumulation do not appear in the true\ncurrent.\n  The treatment here allows the chemiosmotic hypothesis to take advantage of\nknowledge of current flow in physical and engineering sciences, particularly\nKirchhoff and Maxwell Current Laws. Knowing the current means knowing an\nimportant part of the mechanism of ATP synthesis.",
            "author": [
                "Robert S. Eisenberg"
            ],
            "link": [
                "http://arxiv.org/abs/2309.05667v3",
                "http://arxiv.org/pdf/2309.05667v3"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "physics.class-ph",
                "physics.hist-ph",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12350v2",
            "title": "Exploring Internet of Things Adoption Challenges in Manufacturing Firms:\n  A Fuzzy Analytical Hierarchy Process Approach",
            "updated": "2023-10-15T13:25:48Z",
            "published": "2023-08-30T18:58:33Z",
            "summary": "Innovation is crucial for sustainable success in today's fiercely competitive\nglobal manufacturing landscape. Bangladesh's manufacturing sector must embrace\ntransformative technologies like the Internet of Things (IoT) to thrive in this\nenvironment. This article addresses the vital task of identifying and\nevaluating barriers to IoT adoption in Bangladesh's manufacturing industry.\nThrough synthesizing expert insights and carefully reviewing contemporary\nliterature, we explore the intricate landscape of IoT adoption challenges. Our\nmethodology combines the Delphi and Fuzzy Analytical Hierarchy Process,\nsystematically analyzing and prioritizing these challenges. This approach\nharnesses expert knowledge and uses fuzzy logic to handle uncertainties. Our\nfindings highlight key obstacles, with \"Lack of top management commitment to\nnew technology\" (B10), \"High initial implementation costs\" (B9), and \"Risks in\nadopting a new business model\" (B7) standing out as significant challenges that\ndemand immediate attention. These insights extend beyond academia, offering\npractical guidance to industry leaders. With the knowledge gained from this\nstudy, managers can develop tailored strategies, set informed priorities, and\nembark on a transformative journey toward leveraging IoT's potential in\nBangladesh's industrial sector. This article provides a comprehensive\nunderstanding of IoT adoption challenges and equips industry leaders to\nnavigate them effectively. This strategic navigation, in turn, enhances the\ncompetitiveness and sustainability of Bangladesh's manufacturing sector in the\nIoT era.",
            "author": [
                "Hasan Shahriar",
                "Md. Saiful Islam",
                "Md Abrar Jahin",
                "Istiyaque Ahmed Ridoy",
                "Taro Suzuki",
                "Jungpil Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12350v2",
                "http://arxiv.org/pdf/2309.12350v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16269v1",
            "title": "Can Prompt Learning Benefit Radiology Report Generation?",
            "updated": "2023-08-30T18:58:32Z",
            "published": "2023-08-30T18:58:32Z",
            "summary": "Radiology report generation aims to automatically provide clinically\nmeaningful descriptions of radiology images such as MRI and X-ray. Although\ngreat success has been achieved in natural scene image captioning tasks,\nradiology report generation remains challenging and requires prior medical\nknowledge. In this paper, we propose PromptRRG, a method that utilizes prompt\nlearning to activate a pretrained model and incorporate prior knowledge. Since\nprompt learning for radiology report generation has not been explored before,\nwe begin with investigating prompt designs and categorise them based on varying\nlevels of knowledge: common, domain-specific and disease-enriched prompts.\nAdditionally, we propose an automatic prompt learning mechanism to alleviate\nthe burden of manual prompt engineering. This is the first work to\nsystematically examine the effectiveness of prompt learning for radiology\nreport generation. Experimental results on the largest radiology report\ngeneration benchmark, MIMIC-CXR, demonstrate that our proposed method achieves\nstate-of-the-art performance. Code will be available upon the acceptance.",
            "author": [
                "Jun Wang",
                "Lixing Zhu",
                "Abhir Bhalerao",
                "Yulan He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16269v1",
                "http://arxiv.org/pdf/2308.16269v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16257v1",
            "title": "On extremal factors of de Bruijn-like graphs",
            "updated": "2023-08-30T18:26:52Z",
            "published": "2023-08-30T18:26:52Z",
            "summary": "In 1972 Mykkeltveit proved that the maximum number of vertex-disjoint cycles\nin the de Bruijn graphs of order $n$ is attained by the pure cycling register\nrule, as conjectured by Golomb. We generalize this result to the tensor product\nof the de Bruijn graph of order $n$ and a simple cycle of size $k$, when $n$\ndivides $k$ or vice versa. We also develop counting formulae for a large family\nof cycling register rules, including the linear register rules proposed by\nGolomb.",
            "author": [
                "Nicol\u00e1s \u00c1lvarez",
                "Ver\u00f3nica Becher",
                "Mart\u00edn Mereb",
                "Ivo Pajor",
                "Carlos Miguel Soto"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16257v1",
                "http://arxiv.org/pdf/2308.16257v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C35, 05C45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16250v1",
            "title": "It Takes a Village: Multidisciplinarity and Collaboration for the\n  Development of Embodied Conversational Agents",
            "updated": "2023-08-30T18:14:30Z",
            "published": "2023-08-30T18:14:30Z",
            "summary": "Embodied conversational agent (ECA) development is a time-consuming and\ncostly process that calls for knowledge in a plethora of different and not\nnecessarily adjacent disciplines. Engaging in activities outside of one's core\nresearch to acquire peripheral skills can impede innovation and potentially\nrestrict the outcomes within the boundaries of those acquired skills. A\nproposal to tackle this challenge is creating collaborative communities of\nexperts from the contributing disciplines to the field of ECAs that via clearly\ndefined roles, expectations and communication channels can help extend the\nfield of ECA research.",
            "author": [
                "Danai Korre"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16250v1",
                "http://arxiv.org/pdf/2308.16250v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.MM",
                "H.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16248v1",
            "title": "Augmented Reality in Higher Education: a Case Study in Medical Education",
            "updated": "2023-08-30T18:11:58Z",
            "published": "2023-08-30T18:11:58Z",
            "summary": "During lockdown, we piloted a variety of augmented reality (AR) experiences\nin collaboration with subject matter experts from different fields aiming at\ncreating remote teaching and training experiences. In this paper, we present a\ncase study on how AR can be used as a teaching aid for medical education with\npertinent focus on remote and social distanced learning. We describe the\nprocess of creating an AR experience that can enhance the knowledge and\nunderstanding of anatomy for medical students. The Anatomy Experience is an AR\nenhanced learning experience developed in collaboration with the Medical School\nof the University of Edinburgh aiming to assist medical students understand the\ncomplex geometry of different parts of the human body. After conducting a focus\ngroup study with medical students, trainees, and trainers, we received very\npositive feedback on the Anatomy Experience and its effects on understanding\nanatomy, enriching the learning process, and using it as a tool for anatomy\nteaching.",
            "author": [
                "Danai Korre",
                "Andrew Sherlock"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16248v1",
                "http://arxiv.org/pdf/2308.16248v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.ET",
                "K.3.1; H.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16246v1",
            "title": "Active Neural Mapping",
            "updated": "2023-08-30T18:07:30Z",
            "published": "2023-08-30T18:07:30Z",
            "summary": "We address the problem of active mapping with a continually-learned neural\nscene representation, namely Active Neural Mapping. The key lies in actively\nfinding the target space to be explored with efficient agent movement, thus\nminimizing the map uncertainty on-the-fly within a previously unseen\nenvironment. In this paper, we examine the weight space of the\ncontinually-learned neural field, and show empirically that the neural\nvariability, the prediction robustness against random weight perturbation, can\nbe directly utilized to measure the instant uncertainty of the neural map.\nTogether with the continuous geometric information inherited in the neural map,\nthe agent can be guided to find a traversable path to gradually gain knowledge\nof the environment. We present for the first time an active mapping system with\na coordinate-based implicit neural representation for online scene\nreconstruction. Experiments in the visually-realistic Gibson and Matterport3D\nenvironment demonstrate the efficacy of the proposed method.",
            "author": [
                "Zike Yan",
                "Haoxiang Yang",
                "Hongbin Zha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16246v1",
                "http://arxiv.org/pdf/2308.16246v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16177v1",
            "title": "General Purpose Audio Effect Removal",
            "updated": "2023-08-30T17:55:28Z",
            "published": "2023-08-30T17:55:28Z",
            "summary": "Although the design and application of audio effects is well understood, the\ninverse problem of removing these effects is significantly more challenging and\nfar less studied. Recently, deep learning has been applied to audio effect\nremoval; however, existing approaches have focused on narrow formulations\nconsidering only one effect or source type at a time. In realistic scenarios,\nmultiple effects are applied with varying source content. This motivates a more\ngeneral task, which we refer to as general purpose audio effect removal. We\ndeveloped a dataset for this task using five audio effects across four\ndifferent sources and used it to train and evaluate a set of existing\narchitectures. We found that no single model performed optimally on all effect\ntypes and sources. To address this, we introduced RemFX, an approach designed\nto mirror the compositionality of applied effects. We first trained a set of\nthe best-performing effect-specific removal models and then leveraged an audio\neffect classification model to dynamically construct a graph of our models at\ninference. We found our approach to outperform single model baselines, although\nexamples with many effects present remain challenging.",
            "author": [
                "Matthew Rice",
                "Christian J. Steinmetz",
                "George Fazekas",
                "Joshua D. Reiss"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16177v1",
                "http://arxiv.org/pdf/2308.16177v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16163v1",
            "title": "The extremal number of cycles with all diagonals",
            "updated": "2023-08-30T17:32:57Z",
            "published": "2023-08-30T17:32:57Z",
            "summary": "In 1975, Erd\\H{o}s asked the following natural question: What is the maximum\nnumber of edges that an $n$-vertex graph can have without containing a cycle\nwith all diagonals? Erd\\H{o}s observed that the upper bound $O(n^{5/3})$ holds\nsince the complete bipartite graph $K_{3,3}$ can be viewed as a cycle of length\nsix with all diagonals.\n  In this paper, we resolve this old problem. We prove that there exists a\nconstant $C$ such that every $n$-vertex with $Cn^{3/2}$ edges contains a cycle\nwith all diagonals. Since any cycle with all diagonals contains cycles of\nlength four, this bound is best possible using well-known constructions of\ngraphs without a four-cycle based on finite geometry.\n  Among other ideas, our proof involves a novel lemma about finding an\n`almost-spanning' robust expander which might be of independent interest.",
            "author": [
                "Domagoj Brada\u010d",
                "Abhishek Methuku",
                "Benny Sudakov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16163v1",
                "http://arxiv.org/pdf/2308.16163v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16158v1",
            "title": "Utilizing smartphone sensors for accurate solar irradiance measurement\n  and educational purposes",
            "updated": "2023-08-30T17:23:07Z",
            "published": "2023-08-30T17:23:07Z",
            "summary": "The global transition towards cleaner and more sustainable energy production\nis a major challenge. We present an innovative solution by utilizing smartphone\nlight sensors to measure direct normal solar irradiance, the primary component\nof ground-level solar radiation. We provide comprehensive guidelines for\ncalibrating the sensor using two methods: a professional reference measurement\nand clear-sky satellite estimates. The latter method is particularly\nadvantageous in resource-constrained environments. Once calibrated, the\nsmartphone becomes a valuable tool for measuring the solar resource. We propose\nan instructional laboratory focusing on the physics of solar radiation and its\ninteraction with the Earth's atmosphere, exploring solar variations across\nlocations, cloud conditions, and time scales. By integrating irradiance values\nmeasured throughout a day the daily irradiation can be estimated. This approach\nenhances students' understanding of solar radiation attenuation and its\nrelationship with atmospheric interactions. This method offers a practical and\neducational solution for promoting renewable energy knowledge and addressing\nthe challenges of the energy transition.",
            "author": [
                "Jos\u00e9 Luis Di Laccio",
                "Andr\u00e9s Monetta",
                "Rodrigo Alonso-Su\u00e1rez",
                "Mart\u00edn Monteiro",
                "Arturo C. Marti"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16158v1",
                "http://arxiv.org/pdf/2308.16158v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16149v2",
            "title": "Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open\n  Generative Large Language Models",
            "updated": "2023-09-29T11:51:51Z",
            "published": "2023-08-30T17:07:17Z",
            "summary": "We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric\nfoundation and instruction-tuned open generative large language models (LLMs).\nThe models are based on the GPT-3 decoder-only architecture and are pretrained\non a mixture of Arabic and English texts, including source code in various\nprogramming languages. With 13 billion parameters, they demonstrate better\nknowledge and reasoning capabilities in Arabic than any existing open Arabic\nand multilingual models by a sizable margin, based on extensive evaluation.\nMoreover, the models are competitive in English compared to English-centric\nopen models of similar size, despite being trained on much less English data.\nWe provide a detailed description of the training, the tuning, the safety\nalignment, and the evaluation of the models. We release two open versions of\nthe model -- the foundation Jais model, and an instruction-tuned Jais-chat\nvariant -- with the aim of promoting research on Arabic LLMs. Available at\nhttps://huggingface.co/inception-mbzuai/jais-13b-chat",
            "author": [
                "Neha Sengupta",
                "Sunil Kumar Sahu",
                "Bokang Jia",
                "Satheesh Katipomu",
                "Haonan Li",
                "Fajri Koto",
                "William Marshall",
                "Gurpreet Gosal",
                "Cynthia Liu",
                "Zhiming Chen",
                "Osama Mohammed Afzal",
                "Samta Kamboj",
                "Onkar Pandit",
                "Rahul Pal",
                "Lalit Pradhan",
                "Zain Muhammad Mujahid",
                "Massa Baali",
                "Xudong Han",
                "Sondos Mahmoud Bsharat",
                "Alham Fikri Aji",
                "Zhiqiang Shen",
                "Zhengzhong Liu",
                "Natalia Vassilieva",
                "Joel Hestness",
                "Andy Hock",
                "Andrew Feldman",
                "Jonathan Lee",
                "Andrew Jackson",
                "Hector Xuguang Ren",
                "Preslav Nakov",
                "Timothy Baldwin",
                "Eric Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16149v2",
                "http://arxiv.org/pdf/2308.16149v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T50",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16122v1",
            "title": "Spatial Graph Coarsening: Weather and Weekday Prediction with London's\n  Bike-Sharing Service using GNN",
            "updated": "2023-08-30T16:21:02Z",
            "published": "2023-08-30T16:21:02Z",
            "summary": "This study introduced the use of Graph Neural Network (GNN) for predicting\nthe weather and weekday of a day in London, from the dataset of Santander\nCycles bike-sharing system as a graph classification task. The proposed GNN\nmodels newly introduced (i) a concatenation operator of graph features with\ntrained node embeddings and (ii) a graph coarsening operator based on\ngeographical contiguity, namely \"Spatial Graph Coarsening\". With the node\nfeatures of land-use characteristics and number of households around the bike\nstations and graph features of temperatures in the city, our proposed models\noutperformed the baseline model in cross-entropy loss and accuracy of the\nvalidation dataset.",
            "author": [
                "Yuta Sato",
                "Pak Hei Lam",
                "Shruti Gupta",
                "Fareesah Hussain"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16122v1",
                "http://arxiv.org/pdf/2308.16122v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16114v1",
            "title": "Revisiting Hyperbit Limitations unveils Quantum Communication Advantages",
            "updated": "2023-08-30T16:14:44Z",
            "published": "2023-08-30T16:14:44Z",
            "summary": "Paw\\l owski and Winter's Hyperbit Theory, proposed in 2012, presented itself\nas a captivating alternative to quantum theory, suggesting novel ways of\nredefining entanglement and classical communication paradigms. This research\nundertakes a meticulous reevaluation of Hyperbit Theory, uncovering significant\noperational constraints that question its equivalence with quantum mechanics.\nCrucially, the supposition that Hyperbit Theory and Quantum Theory are\nequivalent relies on the receiver having unattainable additional knowledge\nabout the sender's laboratory, indicating that the work by Paw\\l owski and\nWinter is incorrect. This study accentuates the constraints of hyperbits in\ninformation processing and sheds light on the superiority of quantum\ncommunication, thereby advancing the investigation at the intersection of\nclassical and quantum communication.",
            "author": [
                "Giovanni Scala",
                "Seyed Arash Ghoreishi",
                "Marcin Paw\u0142owski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16114v1",
                "http://arxiv.org/pdf/2308.16114v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16111v2",
            "title": "Behavior of the Minimum Degree Throughout the $d$-process",
            "updated": "2023-09-08T21:11:03Z",
            "published": "2023-08-30T16:13:16Z",
            "summary": "The $d$-process generates a graph at random by starting with an empty graph\nwith $n$ vertices, then adding edges one at a time uniformly at random among\nall pairs of vertices which have degrees at most $d-1$ and are not mutually\njoined. We show that, in the evolution of a random graph with $n$ vertices\nunder the $d$-process, with high probability, for each $j \\in\n\\{0,1,\\dots,d-2\\}$, the minimum degree jumps from $j$ to $j+1$ when there are\n$\\Theta(\\ln(n)^{d-j-1})$ steps left. This answers a question of Ruci\\'nski and\nWormald. More specifically, we show that, when the last vertex of degree $j$\ndisappears, the number of steps left divided by $\\ln(n)^{d-j-1}$ converges in\ndistribution to the exponential random variable of mean $\\frac{j!}{2(d-1)!}$;\nfurthermore, these $d-1$ distributions are independent.",
            "author": [
                "Jakob Hofstad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16111v2",
                "http://arxiv.org/pdf/2308.16111v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "05C80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16089v1",
            "title": "Application of Zone Method based Machine Learning and Physics-Informed\n  Neural Networks in Reheating Furnaces",
            "updated": "2023-08-30T15:26:35Z",
            "published": "2023-08-30T15:26:35Z",
            "summary": "Despite the high economic relevance of Foundation Industries, certain\ncomponents like Reheating furnaces within their manufacturing chain are\nenergy-intensive. Notable energy consumption reduction could be obtained by\nreducing the overall heating time in furnaces. Computer-integrated Machine\nLearning (ML) and Artificial Intelligence (AI) powered control systems in\nfurnaces could be enablers in achieving the Net-Zero goals in Foundation\nIndustries for sustainable manufacturing.\n  In this work, due to the infeasibility of achieving good quality data in\nscenarios like reheating furnaces, classical Hottel's zone method based\ncomputational model has been used to generate data for ML and Deep Learning\n(DL) based model training via regression. It should be noted that the zone\nmethod provides an elegant way to model the physical phenomenon of Radiative\nHeat Transfer (RHT), the dominating heat transfer mechanism in high-temperature\nprocesses inside heating furnaces. Using this data, an extensive comparison\namong a wide range of state-of-the-art, representative ML and DL methods has\nbeen made against their temperature prediction performances in varying furnace\nenvironments. Owing to their holistic balance among inference times and model\nperformance, DL stands out among its counterparts. To further enhance the\nOut-Of-Distribution (OOD) generalization capability of the trained DL models,\nwe propose a Physics-Informed Neural Network (PINN) by incorporating prior\nphysical knowledge using a set of novel Energy-Balance regularizers. Our setup\nis a generic framework, is geometry-agnostic of the 3D structure of the\nunderlying furnace, and as such could accommodate any standard ML regression\nmodel, to serve as a Digital Twin of the underlying physical processes, for\ntransitioning Foundation Industries towards Industry 4.0.",
            "author": [
                "Ujjal Kr Dutta",
                "Aldo Lipani",
                "Chuan Wang",
                "Yukun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16089v1",
                "http://arxiv.org/pdf/2308.16089v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16060v1",
            "title": "Text-to-OverpassQL: A Natural Language Interface for Complex Geodata\n  Querying of OpenStreetMap",
            "updated": "2023-08-30T14:33:25Z",
            "published": "2023-08-30T14:33:25Z",
            "summary": "We present Text-to-OverpassQL, a task designed to facilitate a natural\nlanguage interface for querying geodata from OpenStreetMap (OSM). The Overpass\nQuery Language (OverpassQL) allows users to formulate complex database queries\nand is widely adopted in the OSM ecosystem. Generating Overpass queries from\nnatural language input serves multiple use-cases. It enables novice users to\nutilize OverpassQL without prior knowledge, assists experienced users with\ncrafting advanced queries, and enables tool-augmented large language models to\naccess information stored in the OSM database. In order to assess the\nperformance of current sequence generation models on this task, we propose\nOverpassNL, a dataset of 8,352 queries with corresponding natural language\ninputs. We further introduce task specific evaluation metrics and ground the\nevaluation of the Text-to-OverpassQL task by executing the queries against the\nOSM database. We establish strong baselines by finetuning sequence-to-sequence\nmodels and adapting large language models with in-context examples. The\ndetailed evaluation reveals strengths and weaknesses of the considered learning\nstrategies, laying the foundations for further research into the\nText-to-OverpassQL task.",
            "author": [
                "Michael Staniek",
                "Raphael Schumann",
                "Maike Z\u00fcfle",
                "Stefan Riezler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16060v1",
                "http://arxiv.org/pdf/2308.16060v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.DB",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16055v1",
            "title": "AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with\n  Auxiliary Relations",
            "updated": "2023-08-30T14:24:16Z",
            "published": "2023-08-30T14:24:16Z",
            "summary": "Knowledge graph entity typing (KGET) is a task to predict the missing entity\ntypes in knowledge graphs (KG). Previously, KG embedding (KGE) methods tried to\nsolve the KGET task by introducing an auxiliary relation, 'hasType', to model\nthe relationship between entities and their types. However, a single auxiliary\nrelation has limited expressiveness for diverse entity-type patterns. We\nimprove the expressiveness of KGE methods by introducing multiple auxiliary\nrelations in this work. Similar entity types are grouped to reduce the number\nof auxiliary relations and improve their capability to model entity-type\npatterns with different granularities. With the presence of multiple auxiliary\nrelations, we propose a method adopting an Asynchronous learning scheme for\nEntity Typing, named AsyncET, which updates the entity and type embeddings\nalternatively to keep the learned entity embedding up-to-date and informative\nfor entity type prediction. Experiments are conducted on two commonly used KGET\ndatasets to show that the performance of KGE methods on the KGET task can be\nsubstantially improved by the proposed multiple auxiliary relations and\nasynchronous embedding learning. Furthermore, our method has a significant\nadvantage over state-of-the-art methods in model sizes and time complexity.",
            "author": [
                "Yun-Cheng Wang",
                "Xiou Ge",
                "Bin Wang",
                "C. -C. Jay Kuo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16055v1",
                "http://arxiv.org/pdf/2308.16055v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16054v1",
            "title": "Capital Structure Dynamics and Financial Performance in Indian Banks (An\n  Analysis of Mergers and Acquisitions)",
            "updated": "2023-08-30T14:22:42Z",
            "published": "2023-08-30T14:22:42Z",
            "summary": "This research investigates the multifaceted relationship underlying capital\nstructure dynamics along with financial performance as a result of mergers and\nacquisitions, or M&As, in Indian banks. In the face of increasing competition,\nbanks have deliberately embraced M&A as a strategy of improving commercial\nprospects and maintaining financial stability. The primary goal of this study\nis to examine the changes in the capital framework and financial results of\nbanks before and after M&A transactions. The investigation, which employs a\npaired t-test as a method of statistical analysis, is based on a review of\nannual reports from selected banks over a two-year period before and after M&A\ntransactions. The paired t-test approach allows for a thorough statistical\nanalysis of interconnected datasets, revealing the subtle influence of M&A\nattempts on both bank financial performance as well as capital structure\ndynamics. The study's findings have the potential to add to the current body of\nknowledge on organisational planning, managing finances, and capital structure\noptimisation. The research has practical significance for financial companies,\nlegislators, and scholars interested in understanding the profound effects of\nM&A inside the arena of financial institutions that operate within fiercely\ncompetitive landscapes because it provides comprehensive insights regarding the\ncomplex consequences of banking merger and acquisition (M&A) deals on capital\nstructure as well as financial performance. Finally, the goal of this research\nis to provide the banking sector with educated decision-making capabilities and\nstrategic guidance to businesses facing heightened competition while coping\nwith the complexities of capital structure.",
            "author": [
                "Kurada T S S Satyanarayana",
                "Addada Narasimha Rao",
                "Kumpatla jaya surya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16054v1",
                "http://arxiv.org/pdf/2308.16054v1"
            ],
            "primary_category": "q-fin.GN",
            "category": [
                "q-fin.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16039v1",
            "title": "A Continuous Non-ergodic Theory for the Wave Set-up",
            "updated": "2023-08-30T13:56:32Z",
            "published": "2023-08-30T13:56:32Z",
            "summary": "Inhomogeneities in the wave field due to wave groups, currents, and shoaling\namong other ocean processes can affect the mean water level. In this work, the\nclassical and unsolved problem of continuously computing the set-down and the\nfollowing set-up induced by wave breaking on a shoal of constant finite slope\nis tackled. This is possible by using available theoretical knowledge on how to\napproximate the distribution of wave random phases in finite depth. Then, the\nnon-homogeneous spectral analysis of the wave field allows the computation of\nthe ensemble average by means of the phase distribution and the inversion of\nthe integral of the second moment for the special case of a shoaling process\nwith uniform phase distribution. In doing so, I am able to obtain a direct\neffect of the slope magnitude on the phases distribution. Therefore, an\nanalytical and slope-dependent mean water level with continuity over the entire\nrange of water depth is provided.",
            "author": [
                "Saulo Mendes"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16039v1",
                "http://arxiv.org/pdf/2308.16039v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16037v1",
            "title": "Decomposing random regular graphs into stars",
            "updated": "2023-08-30T13:50:20Z",
            "published": "2023-08-30T13:50:20Z",
            "summary": "We study $k$-star decompositions, that is, partitions of the edge set into\ndisjoint stars with $k$ edges, in the uniformly random $d$-regular graph model\n$\\mathcal{G}_{n,d}$. We prove an existence result for such decompositions for\nall $d,k$ such that $d/2 < k \\leq d/2 + \\max\\{1,\\frac{1}{6}\\log d\\}$. More\ngenerally, we give a sufficient existence condition that can be checked\nnumerically for any given values of $d$ and $k$. Complementary negative results\nare obtained using the independence ratio of random regular graphs. Our results\nestablish an existence threshold for $k$-star decompositions in\n$\\mathcal{G}_{n,d}$ for all $d\\leq 100$ and $k > d/2$, and strongly suggest the\na.a.s. existence of such decompositions is equivalent to the a.a.s. existence\nof independent sets of size $(2k-d)n/(2k)$, subject to the necessary\ndivisibility conditions on the number of vertices.\n  For smaller values of $k$, the connection between $k$-star decompositions and\n$\\beta$-orientations allows us to apply results of Thomassen (2012) and\nLov\\'asz, Thomassen, Wu and Zhang (2013). We prove that random $d$-regular\ngraphs satisfy their assumptions with high probability, thus establishing\na.a.s. existence of $k$-star decompositions (i) when $2k^2+k\\leq d$, and (ii)\nwhen $k$ is odd and $k < d/2$.",
            "author": [
                "Michelle Delcourt",
                "Catherine Greenhill",
                "Mikhail Isaev",
                "Bernard Lidick\u00fd",
                "Luke Postle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16037v1",
                "http://arxiv.org/pdf/2308.16037v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16033v1",
            "title": "Independent set in $k$-Claw-Free Graphs: Conditional $\u03c7$-boundedness\n  and the Power of LP/SDP Relaxations",
            "updated": "2023-08-30T13:47:25Z",
            "published": "2023-08-30T13:47:25Z",
            "summary": "This paper studies $k$-claw-free graphs, exploring the connection between an\nextremal combinatorics question and the power of a convex program in\napproximating the maximum-weight independent set in this graph class. For the\nextremal question, we consider the notion, that we call \\textit{conditional\n$\\chi$-boundedness} of a graph: Given a graph $G$ that is assumed to contain an\nindependent set of a certain (constant) size, we are interested in upper\nbounding the chromatic number in terms of the clique number of $G$. This\nquestion, besides being interesting on its own, has algorithmic implications\n(which have been relatively neglected in the literature) on the performance of\nSDP relaxations in estimating the value of maximum-weight independent set.\n  For $k=3$, Chudnovsky and Seymour (JCTB 2010) prove that any $3$-claw-free\ngraph $G$ with an independent set of size three must satisfy $\\chi(G) \\leq 2\n\\omega(G)$. Their result implies a factor $2$-estimation algorithm for the\nmaximum weight independent set via an SDP relaxation (providing the first\nnon-trivial result for maximum-weight independent set in such graphs via a\nconvex relaxation). An obvious open question is whether a similar conditional\n$\\chi$-boundedness phenomenon holds for any $k$-claw-free graph. Our main\nresult answers this question negatively. We further present some evidence that\nour construction could be useful in studying more broadly the power of convex\nrelaxations in the context of approximating maximum weight independent set in\n$k$-claw free graphs. In particular, we prove a lower bound on families of\nconvex programs that are stronger than known convex relaxations used\nalgorithmically in this context.",
            "author": [
                "Parinya Chalermsook",
                "Ameet Gadekar",
                "Kamyar Khodamoradi",
                "Joachim Spoerhase"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16033v1",
                "http://arxiv.org/pdf/2308.16033v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16020v1",
            "title": "Decomposing Triangulations into 4-Connected Components",
            "updated": "2023-08-30T13:21:36Z",
            "published": "2023-08-30T13:21:36Z",
            "summary": "A connected graph is 4-connected if it contains at least five vertices and\nremoving any three of them does not disconnect it. A frequent preprocessing\nstep in graph drawing is to decompose a plane graph into its 4-connected\ncomponents and to determine their nesting structure. A linear-time algorithm\nfor this problem was already proposed by Kant. However, using common graph data\nstructures, we found the subroutine dealing with triangulated graphs difficult\nto implement in such a way that it actually runs in linear time. As a drop-in\nreplacement, we provide a different, easy-to-implement linear-time algorithm\nthat decomposes a triangulated graph into its 4-connected components and\ncomputes the respective nesting structure. The algorithm is based on\ndepth-first search.",
            "author": [
                "Sabine Cornelsen",
                "Gregor Diatzko"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16020v1",
                "http://arxiv.org/pdf/2308.16020v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16018v3",
            "title": "SiT-MLP: A Simple MLP with Point-wise Topology Feature Learning for\n  Skeleton-based Action Recognition",
            "updated": "2023-09-27T02:44:12Z",
            "published": "2023-08-30T13:20:54Z",
            "summary": "Graph convolution networks (GCNs) have achieved remarkable performance in\nskeleton-based action recognition. However, previous GCN-based methods rely on\nelaborate human priors excessively and construct complex feature aggregation\nmechanisms, which limits the generalizability and effectiveness of networks. To\nsolve these problems, we propose a novel Spatial Topology Gating Unit (STGU),\nan MLP-based variant without extra priors, to capture the co-occurrence\ntopology features that encode the spatial dependency across all joints. In\nSTGU, to learn the point-wise topology features, a new gate-based feature\ninteraction mechanism is introduced to activate the features point-to-point by\nthe attention map generated from the input sample. Based on the STGU, we\npropose the first MLP-based model, SiTMLP, for skeleton-based action\nrecognition in this work. Compared with previous methods on three large-scale\ndatasets, SiTMLP achieves competitive performance. In addition, SiT-MLP reduces\nthe parameters by up to 62.5% with favorable results. The code will be\navailable at https://github.com/BUPTSJZhang/SiTMLP.",
            "author": [
                "Shaojie Zhang",
                "Jianqin Yin",
                "Yonghao Dang",
                "Jiajun Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16018v3",
                "http://arxiv.org/pdf/2308.16018v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16000v1",
            "title": "Hypothesis-driven mediation analysis for compositional data: an\n  application to gut microbiome",
            "updated": "2023-08-30T12:39:02Z",
            "published": "2023-08-30T12:39:02Z",
            "summary": "Biological sequencing data consist of read counts, e.g. of specified taxa and\noften exhibit sparsity (zero-count inflation) and overdispersion (extra-Poisson\nvariability). As most sequencing techniques provide an arbitrary total count,\ntaxon-specific counts should ideally be treated as proportions under the\ncompositional data-analytic framework. There is increasing interest in the role\nof the gut microbiome composition in mediating the effects of different\nexposures on health outcomes. Most previous approaches to compositional\nmediation have addressed the problem of identifying potentially mediating taxa\namong a large number of candidates. We here consider causal inference in\ncompositional mediation when a priori knowledge is available about the\nhierarchy for a restricted number of taxa, building on a single hypothesis\nstructured in terms of contrasts between appropriate sub-compositions. Based on\nthe theory on multiple contemporaneous mediators and the assumed causal graph,\nwe define non-parametric estimands for overall and coordinate-wise mediation\neffects, and show how these indirect effects can be estimated from empirical\ndata based on simple parametric linear models. The mediators have\nstraightforward and coherent interpretations, related to specific causal\nquestions about the interrelationships between the sub-compositions. We perform\na simulation study focusing on the impact of sparsity and overdispersion on\nestimation of mediation. While unbiased, the precision of the estimators\ndepends, for any given magnitude of indirect effect, on sparsity and the\nrelative magnitudes of exposure-to-mediator and mediator-to-outcome effects in\na complex manner. We demonstrate the approach on empirical data, finding an\ninverse association of fibre intake on insulin level, mainly attributable to\ndirect rather than indirect effects.",
            "author": [
                "Noora Kartiosuo",
                "Jaakko Nevalainen",
                "Olli Raitakari",
                "Katja Pahkala",
                "Kari Auranen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16000v1",
                "http://arxiv.org/pdf/2308.16000v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15992v2",
            "title": "AI-powered Fraud Detection in Decentralized Finance: A Project Life\n  Cycle Perspective",
            "updated": "2023-09-02T01:54:54Z",
            "published": "2023-08-30T12:24:55Z",
            "summary": "In recent years, blockchain technology has introduced decentralized finance\n(DeFi) as an alternative to traditional financial systems. DeFi aims to create\na transparent and efficient financial ecosystem using smart contracts and\nemerging decentralized applications. However, the growing popularity of DeFi\nhas made it a target for fraudulent activities, resulting in losses of billions\nof dollars due to various types of frauds. To address these issues, researchers\nhave explored the potential of artificial intelligence (AI) approaches to\ndetect such fraudulent activities. Yet, there is a lack of a systematic survey\nto organize and summarize those existing works and to identify the future\nresearch opportunities. In this survey, we provide a systematic taxonomy of\nvarious frauds in the DeFi ecosystem, categorized by the different stages of a\nDeFi project's life cycle: project development, introduction, growth, maturity,\nand decline. This taxonomy is based on our finding: many frauds have strong\ncorrelations in the stage of the DeFi project. According to the taxonomy, we\nreview existing AI-powered detection methods, including statistical modeling,\nnatural language processing and other machine learning techniques, etc. We find\nthat fraud detection in different stages employs distinct types of methods and\nobserve the commendable performance of tree-based and graph-related models in\ntackling fraud detection tasks. By analyzing the challenges and trends, we\npresent the findings to provide proactive suggestion and guide future research\nin DeFi fraud detection. We believe that this survey is able to support\nresearchers, practitioners, and regulators in establishing a secure and\ntrustworthy DeFi ecosystem.",
            "author": [
                "Bingqiao Luo",
                "Zhen Zhang",
                "Qian Wang",
                "Anli Ke",
                "Shengliang Lu",
                "Bingsheng He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15992v2",
                "http://arxiv.org/pdf/2308.15992v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15984v2",
            "title": "Learning Structure-from-Motion with Graph Attention Networks",
            "updated": "2023-12-04T08:50:31Z",
            "published": "2023-08-30T12:13:13Z",
            "summary": "In this paper we tackle the problem of learning Structure-from-Motion (SfM)\nthrough the use of graph attention networks. SfM is a classic computer vision\nproblem that is solved though iterative minimization of reprojection errors,\nreferred to as Bundle Adjustment (BA), starting from a good initialization. In\norder to obtain a good enough initialization to BA, conventional methods rely\non a sequence of sub-problems (such as pairwise pose estimation, pose averaging\nor triangulation) which provides an initial solution that can then be refined\nusing BA. In this work we replace these sub-problems by learning a model that\ntakes as input the 2D keypoints detected across multiple views, and outputs the\ncorresponding camera poses and 3D keypoint coordinates. Our model takes\nadvantage of graph neural networks to learn SfM-specific primitives, and we\nshow that it can be used for fast inference of the reconstruction for new and\nunseen sequences. The experimental results show that the proposed model\noutperforms competing learning-based methods, and challenges COLMAP while\nhaving lower runtime.",
            "author": [
                "Lucas Brynte",
                "Jos\u00e9 Pedro Iglesias",
                "Carl Olsson",
                "Fredrik Kahl"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15984v2",
                "http://arxiv.org/pdf/2308.15984v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15980v1",
            "title": "Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems",
            "updated": "2023-08-30T12:09:18Z",
            "published": "2023-08-30T12:09:18Z",
            "summary": "In sequential recommendation, multi-modal information (e.g., text or image)\ncan provide a more comprehensive view of an item's profile. The optimal stage\n(early or late) to fuse modality features into item representations is still\ndebated. We propose a graph-based approach (named MMSR) to fuse modality\nfeatures in an adaptive order, enabling each modality to prioritize either its\ninherent sequential nature or its interplay with other modalities. MMSR\nrepresents each user's history as a graph, where the modality features of each\nitem in a user's history sequence are denoted by cross-linked nodes. The edges\nbetween homogeneous nodes represent intra-modality sequential relationships,\nand the ones between heterogeneous nodes represent inter-modality\ninterdependence relationships. During graph propagation, MMSR incorporates dual\nattention, differentiating homogeneous and heterogeneous neighbors. To\nadaptively assign nodes with distinct fusion orders, MMSR allows each node's\nrepresentation to be asynchronously updated through an update gate. In\nscenarios where modalities exhibit stronger sequential relationships, the\nupdate gate prioritizes updates among homogeneous nodes. Conversely, when the\ninterdependent relationships between modalities are more pronounced, the update\ngate prioritizes updates among heterogeneous nodes. Consequently, MMSR\nestablishes a fusion order that spans a spectrum from early to late modality\nfusion. In experiments across six datasets, MMSR consistently outperforms\nstate-of-the-art models, and our graph propagation methods surpass other graph\nneural networks. Additionally, MMSR naturally manages missing modalities.",
            "author": [
                "Hengchang Hu",
                "Wei Guo",
                "Yong Liu",
                "Min-Yen Kan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15980v1",
                "http://arxiv.org/pdf/2308.15980v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15972v3",
            "title": "A Neural-enhanced Factor Graph-based Algorithm for Robust Positioning in\n  Obstructed LOS Situations",
            "updated": "2023-11-29T11:57:07Z",
            "published": "2023-08-30T11:50:22Z",
            "summary": "This paper presents a neural-enhanced probabilistic model and corresponding\nfactor graph-based sum-product algorithm for robust localization and tracking\nin multipath-prone environments. The introduced hybrid probabilistic model\nconsists of physics-based and data-driven measurement models capturing the\ninformation contained in both, the line-of-sight (LOS) component as well as in\nmultipath components (NLOS components). The physics-based and data-driven\nmodels are embedded in a joint Bayesian framework allowing to derive from first\nprinciples a factor graph-based algorithm that fuses the information of these\nmodels. The proposed algorithm uses radio signal measurements from multiple\nbase stations to robustly estimate the mobile agent's position together with\nall model parameters. It provides high localization accuracy by exploiting the\nposition-related information of the LOS component via the physics-based model\nand robustness by exploiting the geometric imprint of multipath components\nindependent of the propagation channel via the data-driven model. In a\nchallenging numerical experiment involving obstructed LOS situations to all\nanchors, we show that the proposed sequential algorithm significantly\noutperforms state-of-the-art methods and attains the posterior Cramer-Rao lower\nbound even with training data limited to local regions.",
            "author": [
                "Alexander Venus",
                "Erik Leitinger",
                "Stefan Tertinek",
                "Klaus Witrisal"
            ],
            "link": [
                "http://dx.doi.org/10.1109/OJSP.2023.3338113",
                "http://arxiv.org/abs/2308.15972v3",
                "http://arxiv.org/pdf/2308.15972v3"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15964v1",
            "title": "Specx: a C++ task-based runtime system for heterogeneous distributed\n  architectures",
            "updated": "2023-08-30T11:41:30Z",
            "published": "2023-08-30T11:41:30Z",
            "summary": "Parallelization is needed everywhere, from laptops and mobile phones to\nsupercomputers. Among parallel programming models, task-based programming has\ndemonstrated a powerful potential and is widely used in high-performance\nscientific computing. Not only does it allow for efficient parallelization\nacross distributed heterogeneous computing nodes, but it also allows for\nelegant source code structuring by describing hardware-independent algorithms.\nIn this paper, we present Specx, a task-based runtime system written in modern\nC++. Specx supports distributed heterogeneous computing by simultaneously\nexploiting CPUs and GPUs (CUDA/HIP) and incorporating communication into the\ntask graph. We describe the specificities of Specx and demonstrate its\npotential by running parallel applications.",
            "author": [
                "Paul Cardosi",
                "B\u00e9renger Bramas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15964v1",
                "http://arxiv.org/pdf/2308.15964v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15936v1",
            "title": "Jaccard-constrained dense subgraph discovery",
            "updated": "2023-08-30T10:33:02Z",
            "published": "2023-08-30T10:33:02Z",
            "summary": "Finding dense subgraphs is a core problem in graph mining with many\napplications in diverse domains. At the same time many real-world networks vary\nover time, that is, the dataset can be represented as a sequence of graph\nsnapshots. Hence, it is natural to consider the question of finding dense\nsubgraphs in a temporal network that are allowed to vary over time to a certain\ndegree. In this paper, we search for dense subgraphs that have large pairwise\nJaccard similarity coefficients. More formally, given a set of graph snapshots\nand a weight $\\lambda$, we find a collection of dense subgraphs such that the\nsum of densities of the induced subgraphs plus the sum of Jaccard indices,\nweighted by $\\lambda$, is maximized. We prove that this problem is NP-hard. To\ndiscover dense subgraphs with good objective value, we present an iterative\nalgorithm which runs in $\\mathcal{O}(n^2k^2 + m \\log n + k^3 n)$ time per\nsingle iteration, and a greedy algorithm which runs in $\\mathcal{O}(n^2k^2 + m\n\\log n + k^3 n)$ time, where $k$ is the length of the graph sequence and $n$\nand $m$ denote number of nodes and total number of edges respectively. We show\nexperimentally that our algorithms are efficient, they can find ground truth in\nsynthetic datasets and provide interpretable results from real-world datasets.\nFinally, we present a case study that shows the usefulness of our problem.",
            "author": [
                "Chamalee Wickrama Arachchi",
                "Nikolaj Tatti"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15936v1",
                "http://arxiv.org/pdf/2308.15936v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15928v1",
            "title": "Sorting Signed Permutations by Reversals in Nearly-Linear Time",
            "updated": "2023-08-30T10:09:26Z",
            "published": "2023-08-30T10:09:26Z",
            "summary": "Given a signed permutation on $n$ elements, we need to sort it with the\nfewest reversals. This is a fundamental algorithmic problem motivated by\napplications in comparative genomics, as it allows to accurately model\nrearrangements in small genomes. The first polynomial-time algorithm was given\nin the foundational work of Hannenhalli and Pevzner [J. ACM'99]. Their approach\nwas later streamlined and simplified by Kaplan, Shamir, and Tarjan [SIAM J.\nComput.'99] and their framework has eventually led to an algorithm that works\nin $\\mathcal{O}(n^{3/2}\\sqrt{\\log n})$ time given by Tannier, Bergeron, and\nSagot [Discr. Appl. Math.'07]. However, the challenge of finding a\nnearly-linear time algorithm remained unresolved. In this paper, we show how to\nleverage the results on dynamic graph connectivity to obtain a surprisingly\nsimple $\\mathcal{O}(n \\log^2 n / \\log \\log n)$ time algorithm for this problem.",
            "author": [
                "Bart\u0142omiej Dudek",
                "Pawe\u0142 Gawrychowski",
                "Tatiana Starikovskaya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15928v1",
                "http://arxiv.org/pdf/2308.15928v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15909v1",
            "title": "An Approach to Evaluate User Interfaces in a Scholarly Knowledge\n  Communication Domain",
            "updated": "2023-08-30T09:36:35Z",
            "published": "2023-08-30T09:36:35Z",
            "summary": "The amount of research articles produced every day is overwhelming: scholarly\nknowledge is getting harder to communicate and easier to get lost. A possible\nsolution is to represent the information in knowledge graphs: structures\nrepresenting knowledge in networks of entities, their semantic types, and\nrelationships between them. But this solution has its own drawback: given its\nvery specific task, it requires new methods for designing and evaluating user\ninterfaces. In this paper, we propose an approach for user interface evaluation\nin the knowledge communication domain. We base our methodology on the\nwell-established Cognitive Walkthough approach but employ a different set of\nquestions, tailoring the method towards domain-specific needs. We demonstrate\nour approach on a scholarly knowledge graph implementation called Open Research\nKnowledge Graph (ORKG).",
            "author": [
                "Denis Obrezkov",
                "Allard Oelen",
                "S\u00f6ren Auer"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-42293-5_44",
                "http://arxiv.org/abs/2308.15909v1",
                "http://arxiv.org/pdf/2308.15909v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15904v1",
            "title": "Forbidden patterns of graphs 12-representable by pattern-avoiding words",
            "updated": "2023-08-30T09:14:42Z",
            "published": "2023-08-30T09:14:42Z",
            "summary": "A graph $G = (\\{1, 2, \\ldots, n\\}, E)$ is $12$-representable if there is a\nword $w$ over $\\{1, 2, \\ldots, n\\}$ such that two vertices $i$ and $j$ with $i\n< j$ are adjacent if and only if every $j$ occurs before every $i$ in $w$.\nThese graphs have been shown to be equivalent to the complements of\nsimple-triangle graphs. This equivalence provides a characterization in terms\nof forbidden patterns in vertex orderings as well as a polynomial-time\nrecognition algorithm. The class of $12$-representable graphs was introduced by\nJones et al. (2015) as a variant of word-representable graphs. A general\nresearch direction for word-representable graphs suggested by Kitaev and Lozin\n(2015) is to study graphs representable by some specific types of words. For\ninstance, Gao, Kitaev, and Zhang (2017) and Mandelshtam (2019) investigated\nword-representable graphs represented by pattern-avoiding words. Following this\nresearch direction, this paper studies $12$-representable graphs represented by\nwords that avoid a pattern $p$. Such graphs are trivial when $p$ is of length\n$2$. When $p = 111$, $121$, $231$, and $321$, the classes of such graphs are\nequivalent to well-known classes, such as trivially perfect graphs and\nbipartite permutation graphs. For the cases where $p = 123$, $132$, and $211$,\nthis paper provides forbidden pattern characterizations.",
            "author": [
                "Asahi Takaoka"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15904v1",
                "http://arxiv.org/pdf/2308.15904v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C62 (Primary) 05C75, 68R15 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15901v1",
            "title": "Explainable Answer-set Programming",
            "updated": "2023-08-30T09:09:57Z",
            "published": "2023-08-30T09:09:57Z",
            "summary": "The interest in explainability in artificial intelligence (AI) is growing\nvastly due to the near ubiquitous state of AI in our lives and the increasing\ncomplexity of AI systems. Answer-set Programming (ASP) is used in many areas,\namong them are industrial optimisation, knowledge management or life sciences,\nand thus of great interest in the context of explainability. To ensure the\nsuccessful application of ASP as a problem-solving paradigm in the future, it\nis thus crucial to investigate explanations for ASP solutions. Such an\nexplanation generally tries to give an answer to the question of why something\nis, respectively is not, part of the decision produced or solution to the\nformulated problem. Although several explanation approaches for ASP exist,\nalmost all of them lack support for certain language features that are used in\npractice. Most notably, this encompasses the various ASP extensions that have\nbeen developed in the recent years to enable reasoning over theories, external\ncomputations, or neural networks. This project aims to fill some of these gaps\nand contribute to the state of the art in explainable ASP. We tackle this by\nextending the language support of existing approaches but also by the\ndevelopment of novel explanation formalisms, like contrastive explanations.",
            "author": [
                "Tobias Geibinger"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.52",
                "http://arxiv.org/abs/2308.15901v1",
                "http://arxiv.org/pdf/2308.15901v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15900v1",
            "title": "Data reduction for directed feedback vertex set on graphs without long\n  induced cycles",
            "updated": "2023-08-30T09:09:52Z",
            "published": "2023-08-30T09:09:52Z",
            "summary": "We study reduction rules for Directed Feedback Vertex Set (DFVS) on instances\nwithout long cycles. A DFVS instance without cycles longer than $d$ naturally\ncorresponds to an instance of $d$-Hitting Set, however, enumerating all cycles\nin an $n$-vertex graph and then kernelizing the resulting $d$-Hitting Set\ninstance can be too costly, as already enumerating all cycles can take time\n$\\Omega(n^d)$. We show how to compute a kernel with at most $2^dk^d$ vertices\nand at most $d^{3d}k^d$ induced cycles of length at most $d$ (which however,\ncannot be enumerated efficiently), where $k$ is the size of a minimum directed\nfeedback vertex set. We then study classes of graphs whose underlying\nundirected graphs have bounded expansion or are nowhere dense; these are very\ngeneral classes of sparse graphs, containing e.g. classes excluding a minor or\na topological minor. We prove that for such classes without induced cycles of\nlength greater than $d$ we can compute a kernel with $O_d(k)$ and\n$O_{d,\\epsilon}(k^{1+\\epsilon})$ vertices for any $\\epsilon>0$, respectively,\nin time $O_d(n^{O(1)})$ and $O_{d,\\epsilon}(n^{O(1)})$, respectively. The most\nrestricted classes we consider are strongly connected planar graphs without any\n(induced or non-induced) long cycles. We show that these have bounded treewidth\nand hence DFVS on planar graphs without cycles of length greater than $d$ can\nbe solved in time $2^{O(d)}\\cdot n^{O(1)}$. We finally present a new data\nreduction rule for general DFVS and prove that the rule together with a few\nstandard rules subsumes all the rules applied by Bergougnoux et al. to obtain a\npolynomial kernel for DFVS[FVS], i.e., DFVS parameterized by the feedback\nvertex set number of the underlying (undirected) graph. We conclude by studying\nthe LP-based approximation of DFVS.",
            "author": [
                "Jona Dirks",
                "Enna Gerhard",
                "Mario Grobler",
                "Amer E. Mouawad",
                "Sebastian Siebertz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15900v1",
                "http://arxiv.org/pdf/2308.15900v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15899v1",
            "title": "Beyond Traditional Neural Networks: Toward adding Reasoning and Learning\n  Capabilities through Computational Logic Techniques",
            "updated": "2023-08-30T09:09:42Z",
            "published": "2023-08-30T09:09:42Z",
            "summary": "Deep Learning (DL) models have become popular for solving complex problems,\nbut they have limitations such as the need for high-quality training data, lack\nof transparency, and robustness issues. Neuro-Symbolic AI has emerged as a\npromising approach combining the strengths of neural networks and symbolic\nreasoning. Symbolic knowledge injection (SKI) techniques are a popular method\nto incorporate symbolic knowledge into sub-symbolic systems. This work proposes\nsolutions to improve the knowledge injection process and integrate elements of\nML and logic into multi-agent systems (MAS).",
            "author": [
                "Andrea Rafanelli"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.51",
                "http://arxiv.org/abs/2308.15899v1",
                "http://arxiv.org/pdf/2308.15899v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.LO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15897v1",
            "title": "Nemo: First Glimpse of a New Rule Engine",
            "updated": "2023-08-30T09:08:28Z",
            "published": "2023-08-30T09:08:28Z",
            "summary": "This system demonstration presents Nemo, a new logic programming engine with\na focus on reliability and performance. Nemo is built for data-centric analytic\ncomputations, modelled in a fully declarative Datalog dialect. Its scalability\nfor these tasks matches or exceeds that of leading Datalog systems. We\ndemonstrate uses in reasoning with knowledge graphs and ontologies with 10^5 to\n10^8 input facts, all on a laptop. Nemo is written in Rust and available as a\nfree and open source tool.",
            "author": [
                "Alex Ivliev",
                "Stefan Ellmauthaler",
                "Lukas Gerlach",
                "Maximilian Marx",
                "Matthias Mei\u00dfner",
                "Simon Meusel",
                "Markus Kr\u00f6tzsch"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.35",
                "http://arxiv.org/abs/2308.15897v1",
                "http://arxiv.org/pdf/2308.15897v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DB",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15892v1",
            "title": "A Logic Programming Approach to Global Logistics in a Co-Design\n  Environment",
            "updated": "2023-08-30T09:06:34Z",
            "published": "2023-08-30T09:06:34Z",
            "summary": "In a co-design environment changes need to be integrated quickly and in an\nautomated manner. This paper considers the challenge of creating and optimizing\na global logistics system for the construction of a passenger aircraft within a\nco-design approach with respect to key performance indicators (like cost, time\nor resilience). The product in question is an aircraft, comprised of multiple\ncomponents, manufactured at multiple sites worldwide. The goal is to find an\noptimal way to build the aircraft taking into consideration the requirements\nfor its industrial system. The main motivation for approaching this challenge\nis to develop the industrial system in tandem with the product and making it\nmore resilient against unforeseen events, reducing the risks of bottlenecks in\nthe supply chain. This risk reduction ensures continued efficiency and\noperational success. To address this challenging and complex task we have\nchosen Answer Set Programming (ASP) as the modeling language, formalizing the\nrelevant requirements of the investigated industrial system. The approach\npresented in this paper covers three main aspects: the extraction of the\nrelevant information from a knowledge graph, the translation into logic\nprograms and the computation of existing configurations guided by optimization\ncriteria. Finally we visualize the results for an effortless evaluation of\nthese models. Internal results seem promising and yielded several new research\nquestions for future improvements of the discussed use case.",
            "author": [
                "Emmanuelle Dietz",
                "Tobias Philipp",
                "Gerrit Schramm",
                "Andreas Zindel"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.23",
                "http://arxiv.org/abs/2308.15892v1",
                "http://arxiv.org/pdf/2308.15892v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DB",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15885v1",
            "title": "Towards One-Shot Learning for Text Classification using Inductive Logic\n  Programming",
            "updated": "2023-08-30T09:04:06Z",
            "published": "2023-08-30T09:04:06Z",
            "summary": "With the ever-increasing potential of AI to perform personalised tasks, it is\nbecoming essential to develop new machine learning techniques which are\ndata-efficient and do not require hundreds or thousands of training data. In\nthis paper, we explore an Inductive Logic Programming approach for one-shot\ntext classification. In particular, we explore the framework of\nMeta-Interpretive Learning (MIL), along with using common-sense background\nknowledge extracted from ConceptNet. Results indicate that MIL can learn text\nclassification rules from a small number of training examples. Moreover, the\nhigher complexity of chosen examples, the higher accuracy of the outcome.",
            "author": [
                "Ghazal Afroozi Milani",
                "Daniel Cyrus",
                "Alireza Tamaddoni-Nezhad"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.9",
                "http://arxiv.org/abs/2308.15885v1",
                "http://arxiv.org/pdf/2308.15885v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15879v1",
            "title": "Explanations for Answer Set Programming",
            "updated": "2023-08-30T09:03:07Z",
            "published": "2023-08-30T09:03:07Z",
            "summary": "The paper presents an enhancement of xASP, a system that generates\nexplanation graphs for Answer Set Programming (ASP). Different from xASP, the\nnew system, xASP2, supports different clingo constructs like the choice rules,\nthe constraints, and the aggregates such as #sum, #min. This work formalizes\nand presents an explainable artificial intelligence system for a broad fragment\nof ASP, capable of shrinking as much as possible the set of assumptions and\npresenting explanations in terms of directed acyclic graphs.",
            "author": [
                "Mario Alviano",
                "Ly Ly Trieu",
                "Tran Cao Son",
                "Marcello Balduccini"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.4",
                "http://arxiv.org/abs/2308.15879v1",
                "http://arxiv.org/pdf/2308.15879v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15878v1",
            "title": "Benchmarking for Integrating Logic Rules with Everything Else",
            "updated": "2023-08-30T09:02:46Z",
            "published": "2023-08-30T09:02:46Z",
            "summary": "Integrating logic rules with other language features is increasingly sought\nafter for advanced applications that require knowledge-base capabilities. To\naddress this demand, increasingly more languages and extensions for such\nintegration have been developed. How to evaluate such languages?\n  This paper describes a set of programming and performance benchmarks for\nevaluating languages supporting integrated use of rules and other features, and\nthe results of evaluating such an integrated language together with logic\nlanguages and languages not supporting logic rules.",
            "author": [
                "Yanhong A. Liu",
                "Scott D. Stoller",
                "Yi Tong",
                "K. Tuncay Tekle"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.3",
                "http://arxiv.org/abs/2308.15878v1",
                "http://arxiv.org/pdf/2308.15878v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LO",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15877v1",
            "title": "ABA Learning via ASP",
            "updated": "2023-08-30T09:02:29Z",
            "published": "2023-08-30T09:02:29Z",
            "summary": "Recently, ABA Learning has been proposed as a form of symbolic machine\nlearning for drawing Assumption-Based Argumentation frameworks from background\nknowledge and positive and negative examples. We propose a novel method for\nimplementing ABA Learning using Answer Set Programming as a way to help guide\nRote Learning and generalisation in ABA Learning.",
            "author": [
                "Emanuele De Angelis",
                "Maurizio Proietti",
                "Francesca Toni"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.1",
                "http://arxiv.org/abs/2308.15877v1",
                "http://arxiv.org/pdf/2308.15877v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15875v1",
            "title": "Frequency-comb-linearized, widely tunable lasers for coherent ranging",
            "updated": "2023-08-30T08:58:35Z",
            "published": "2023-08-30T08:58:35Z",
            "summary": "Tunable lasers, with the ability to continuously adjust their emission\nwavelengths, have found widespread applications across various fields such as\nbiomedical imaging, coherent ranging, optical communications and spectroscopy.\nIn these applications, a wide chirp range is advantageous for large spectral\ncoverage and high frequency resolution. Besides, the frequency accuracy and\nprecision also depend critically on the chirp linearity of the laser. While\nextensive efforts have been made on the development of many kinds of\nfrequency-agile, widely tunable, narrow-linewidth lasers, wideband yet precise\nmethods to characterize and to linearize laser chirp dynamics are also\ndemanded. Here we present an approach to characterize laser chirp dynamics\nusing an optical frequency comb. The instantaneous laser frequency is tracked\nover terahertz bandwidth with 1 MHz interval. Using this approach we calibrate\nthe chirp performance of twelve tunable lasers from Toptica, Santec, New Focus,\nEXFO and NKT that are commonly used in fiber optics and integrated photonics.\nIn addition, with acquired knowledge on laser chirp dynamics, we demonstrate a\nsimple frequency-linearization scheme that enables coherent ranging without any\noptical or electronic linearization units. Our approach not only presents a\nnovel wideband, high-resolution laser spectroscopy, but is also critical for\nsensing applications with ever-increasing requirements on performance.",
            "author": [
                "Baoqi Shi",
                "Yi-Han Luo",
                "Wei Sun",
                "Yue Hu",
                "Jinbao Long",
                "Xue Bai",
                "Anting Wang",
                "Junqiu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15875v1",
                "http://arxiv.org/pdf/2308.15875v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15865v1",
            "title": "On the Independencies Hidden in the Structure of a Probabilistic Logic\n  Program",
            "updated": "2023-08-30T08:55:55Z",
            "published": "2023-08-30T08:55:55Z",
            "summary": "Pearl and Verma developed d-separation as a widely used graphical criterion\nto reason about the conditional independencies that are implied by the causal\nstructure of a Bayesian network. As acyclic ground probabilistic logic programs\ncorrespond to Bayesian networks on their dependency graph, we can compute\nconditional independencies from d-separation in the latter.\n  In the present paper, we generalize the reasoning above to the non-ground\ncase. First, we abstract the notion of a probabilistic logic program away from\nexternal databases and probabilities to obtain so-called program structures. We\nthen present a correct meta-interpreter that decides whether a certain\nconditional independence statement is implied by a program structure on a given\nexternal database. Finally, we give a fragment of program structures for which\nwe obtain a completeness statement of our conditional independence oracle. We\nclose with an experimental evaluation of our approach revealing that our\nmeta-interpreter performs significantly faster than checking the definition of\nindependence using exact inference in ProbLog 2.",
            "author": [
                "Kilian R\u00fcckschlo\u00df",
                "Felix Weitk\u00e4mper"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.385.17",
                "http://arxiv.org/abs/2308.15865v1",
                "http://arxiv.org/pdf/2308.15865v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15853v2",
            "title": "Weak$^*$ degeneracy and weak$^*$ $k$-truncated-degree-degenerate graphs",
            "updated": "2023-09-19T09:22:23Z",
            "published": "2023-08-30T08:39:13Z",
            "summary": "This paper introduces the concept of weak$^*$ degeneracy of a graph that\nshares many nice properties of degeneracy. Using this concept, we derive upper\nbounds for many colouring parameter. In particular, combined with an earlier\nresult, the upper bounds imply that planar graphs of girth 5 are 3-AT, which\nstrengthens Thomassen's result that planar graphs of girth 5 are 3-choosable.\nLet $k$ be a positive integer and let $f(v)=\\min\\{d_G(v), k\\}$ for each vertex\n$v$ of $G$. If $G$ is $f$-choosable, then we say $G$ is\n$k$-truncated-degree-choosable. Richtor asked whether every 3-connected\nnon-complete planar graph is $6$-truncated-degree-choosable. We construct a\n3-connected non-complete planar graph which is not\n$7$-truncated-degree-choosable, so the answer to Richtor's question is negative\neven if 6 is replaced by 7. Then we prove that every 3-connected non-complete\nplanar graph is $16$-truncated-degree-choosable. For an arbitrary proper minor\nclosed family ${\\mathcal G}$ of graphs, let $s$ be the minimum integer such\nthat $K_{s,t} \\notin \\mathcal{G}$ for some $t$. We prove that there is a\nconstant $k$ such that every $s$-connected non-complete graph $G \\in {\\mathcal\nG}$ is $k$-truncated-degree-choosable.\n  In particular, for any surface $\\Sigma$, there is a constant $k$ such that\nevery 3-connected non-complete graph embeddable on $\\Sigma$ is\n$k$-truncated-degree-choosable. The choosability results are proved via\nweak$^*$-degeneracy, and hence remain true when choosable is replaced by\nDP-colourable or paintable or DP-paintable or AT.",
            "author": [
                "Huan Zhou",
                "Jialu Zhu",
                "Xuding Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15853v2",
                "http://arxiv.org/pdf/2308.15853v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15851v1",
            "title": "Prompting Vision Language Model with Knowledge from Large Language Model\n  for Knowledge-Based VQA",
            "updated": "2023-08-30T08:35:31Z",
            "published": "2023-08-30T08:35:31Z",
            "summary": "Knowledge-based visual question answering is a very challenging and widely\nconcerned task. Previous methods adopts the implicit knowledge in large\nlanguage models (LLM) to achieve excellent results, but we argue that existing\nmethods may suffer from biasing understanding of the image and insufficient\nknowledge to solve the problem. In this paper, we propose PROOFREAD -PROmpting\nvision language model with knOwledge From laRgE lAnguage moDel, a novel,\nlightweight and efficient kowledge-based VQA framework, which make the vision\nlanguage model and the large language model cooperate to give full play to\ntheir respective strengths and bootstrap each other. In detail, our proposed\nmethod uses LLM to obtain knowledge explicitly, uses the vision language model\nwhich can see the image to get the knowledge answer, and introduces knowledge\nperceiver to filter out knowledge that is harmful for getting the correct final\nanswer. Experimental results on two datasets prove the effectiveness of our\napproach. Our method outperforms all state-of-the-art methods on the A-OKVQA\ndataset in two settings and also achieves relatively good performance on the\nOKVQA dataset.",
            "author": [
                "Yang Zhou",
                "Pengfei Cao",
                "Yubo Chen",
                "Kang Liu",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15851v1",
                "http://arxiv.org/pdf/2308.15851v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15846v1",
            "title": "Exploring Multi-Modal Contextual Knowledge for Open-Vocabulary Object\n  Detection",
            "updated": "2023-08-30T08:33:13Z",
            "published": "2023-08-30T08:33:13Z",
            "summary": "In this paper, we for the first time explore helpful multi-modal contextual\nknowledge to understand novel categories for open-vocabulary object detection\n(OVD). The multi-modal contextual knowledge stands for the joint relationship\nacross regions and words. However, it is challenging to incorporate such\nmulti-modal contextual knowledge into OVD. The reason is that previous\ndetection frameworks fail to jointly model multi-modal contextual knowledge, as\nobject detectors only support vision inputs and no caption description is\nprovided at test time. To this end, we propose a multi-modal contextual\nknowledge distillation framework, MMC-Det, to transfer the learned contextual\nknowledge from a teacher fusion transformer with diverse multi-modal masked\nlanguage modeling (D-MLM) to a student detector. The diverse multi-modal masked\nlanguage modeling is realized by an object divergence constraint upon\ntraditional multi-modal masked language modeling (MLM), in order to extract\nfine-grained region-level visual contexts, which are vital to object detection.\nExtensive experiments performed upon various detection datasets show the\neffectiveness of our multi-modal context learning strategy, where our approach\nwell outperforms the recent state-of-the-art methods.",
            "author": [
                "Yifan Xu",
                "Mengdan Zhang",
                "Xiaoshan Yang",
                "Changsheng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15846v1",
                "http://arxiv.org/pdf/2308.15846v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15842v1",
            "title": "On Colorful Vertex and Edge Cover Problems",
            "updated": "2023-08-30T08:27:09Z",
            "published": "2023-08-30T08:27:09Z",
            "summary": "In this paper, we study two generalizations of Vertex Cover and Edge Cover,\nnamely Colorful Vertex Cover and Colorful Edge Cover. In the Colorful Vertex\nCover problem, given an $n$-vertex edge-colored graph $G$ with colors from\n$\\{1, \\ldots, \\omega\\}$ and coverage requirements $r_1, r_2, \\ldots, r_\\omega$,\nthe goal is to find a minimum-sized set of vertices that are incident on at\nleast $r_i$ edges of color $i$, for each $1 \\le i \\le \\omega$, i.e., we need to\ncover at least $r_i$ edges of color $i$. Colorful Edge Cover is similar to\nColorful Vertex Cover, except here we are given a vertex-colored graph and the\ngoal is to cover at least $r_i$ vertices of color $i$, for each $1 \\le i \\le\n\\omega$, by a minimum-sized set of edges. These problems have several\napplications in fair covering and hitting of geometric set systems involving\npoints and lines that are divided into multiple groups. Here, fairness ensures\nthat the coverage (resp. hitting) requirement of every group is fully\nsatisfied.\n  We obtain a $(2+\\epsilon)$-approximation for the Colorful Vertex Cover\nproblem in time $n^{O(\\omega/\\epsilon)}$. Thus, for a constant number of\ncolors, the problem admits a $(2+\\epsilon)$-approximation in polynomial time.\nNext, for the Colorful Edge Cover problem, we design an $O(\\omega n^3)$ time\nexact algorithm, via a chain of reductions to a matching problem. For all\nintermediate problems in this chain of reductions, we design polynomial-time\nalgorithms, which might be of independent interest.",
            "author": [
                "Sayan Bandyapadhyay",
                "Aritra Banik",
                "Sujoy Bhore"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15842v1",
                "http://arxiv.org/pdf/2308.15842v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15841v1",
            "title": "QUIC Library Hunter: Identifying Server Libraries Across the Internet",
            "updated": "2023-08-30T08:22:05Z",
            "published": "2023-08-30T08:22:05Z",
            "summary": "The new QUIC protocol can be implemented in user space, and various\nimplementations already exist. While they follow the same specification and\ngeneral interoperability is given, differences in performance, functionality,\nbut also security (e.g., due to bugs) can be expected. Therefore, knowledge\nabout the implementation of an endpoint on the Internet can help researchers,\noperators and users to better analyze connections, evaluations and findings.\n  We provide an approach to identify used libraries of QUIC servers based on\nCONNECTION_CLOSE frames and transport parameter orders. We apply our\nmethodology to Internet-wide scans and identify at least one deployment for 18\nQUIC libraries. In total, we can identify the library of 8.8 M IPv4 and 2.5 M\nIPv6 addresses.",
            "author": [
                "Johannes Zirngibl",
                "Florian Gebauer",
                "Patrick Sattler",
                "Markus Sosnowski",
                "Georg Carle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15841v1",
                "http://arxiv.org/pdf/2308.15841v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15840v1",
            "title": "MSGNN: Multi-scale Spatio-temporal Graph Neural Network for Epidemic\n  Forecasting",
            "updated": "2023-08-30T08:21:56Z",
            "published": "2023-08-30T08:21:56Z",
            "summary": "Infectious disease forecasting has been a key focus and proved to be crucial\nin controlling epidemic. A recent trend is to develop forecast-ing models based\non graph neural networks (GNNs). However, existing GNN-based methods suffer\nfrom two key limitations: (1) Current models broaden receptive fields by\nscaling the depth of GNNs, which is insuffi-cient to preserve the semantics of\nlong-range connectivity between distant but epidemic related areas. (2)\nPrevious approaches model epidemics within single spatial scale, while ignoring\nthe multi-scale epidemic pat-terns derived from different scales. To address\nthese deficiencies, we devise the Multi-scale Spatio-temporal Graph Neural\nNetwork (MSGNN) based on an innovative multi-scale view. To be specific, in the\nproposed MSGNN model, we first devise a novel graph learning module, which\ndirectly captures long-range connectivity from trans-regional epidemic signals\nand integrates them into a multi-scale graph. Based on the learned multi-scale\ngraph, we utilize a newly designed graph convolution module to exploit\nmulti-scale epidemic patterns. This module allows us to facilitate multi-scale\nepidemic modeling by mining both scale-shared and scale-specific pat-terns.\nExperimental results on forecasting new cases of COVID-19 in United State\ndemonstrate the superiority of our method over state-of-arts. Further analyses\nand visualization also show that MSGNN offers not only accurate, but also\nrobust and interpretable forecasting result.",
            "author": [
                "Mingjie Qiu",
                "Zhiyi Tan",
                "Bing-kun Bao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15840v1",
                "http://arxiv.org/pdf/2308.15840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.soc-ph",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12349v1",
            "title": "On the culture of open access: the Sci-hub paradox",
            "updated": "2023-08-30T07:50:56Z",
            "published": "2023-08-30T07:50:56Z",
            "summary": "Shadow libraries, also known as ''pirate libraries'', are online collections\nof copyrighted publications that have been made available for free without the\npermission of the copyright holders. They have gradually become key players of\nscientific knowledge dissemination, despite their illegality in most countries\nof the world. Many publishers and scientist-editors decry such libraries for\ntheir copyright infringement and loss of publication usage information, while\nsome scholars and institutions support them, sometimes in a roundabout way, for\ntheir role in reducing inequalities of access to knowledge, particularly in\nlow-income countries. Although there is a wealth of literature on shadow\nlibraries, none of this have focused on its potential role in knowledge\ndissemination, through the open access movement. Here we analyze how shadow\nlibraries can affect researchers' citation practices, highlighting some\ncounter-intuitive findings about their impact on the Open Access Citation\nAdvantage (OACA). Based on a large randomized sample, this study first shows\nthat OA publications, including those in fully OA journals, receive more\ncitations than their subscription-based counterparts do. However, the OACA has\nslightly decreased over the seven last years. The introduction of a distinction\nbetween those accessible or not via the Scihub platform among\nsubscription-based suggest that the generalization of its use cancels the\npositive effect of OA publishing. The results show that publications in fully\nOA journals are victims of the success of Sci-hub. Thus, paradoxically,\nalthough Sci-hub may seem to facilitate access to scientific knowledge, it\nnegatively affects the OA movement as a whole, by reducing the comparative\nadvantage of OA publications in terms of visibility for researchers. The\ndemocratization of the use of Sci-hub may therefore lead to a vicious cycle,\nhindering efforts to develop full OA strategies without proposing a credible\nand sustainable alternative model for the dissemination of scientific\nknowledge.",
            "author": [
                "Abdelghani Maddi",
                "David Sapinho"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s11192-023-04792-5",
                "http://arxiv.org/abs/2309.12349v1",
                "http://arxiv.org/pdf/2309.12349v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15813v1",
            "title": "Knowledge-grounded Natural Language Recommendation Explanation",
            "updated": "2023-08-30T07:36:12Z",
            "published": "2023-08-30T07:36:12Z",
            "summary": "Explanations accompanied by a recommendation can assist users in\nunderstanding the decision made by recommendation systems, which in turn\nincreases a user's confidence and trust in the system. Recently, research has\nfocused on generating natural language explanations in a human-readable format.\nThus far, the proposed approaches leverage item reviews written by users, which\nare often subjective, sparse in language, and unable to account for new items\nthat have not been purchased or reviewed before. Instead, we aim to generate\nfact-grounded recommendation explanations that are objectively described with\nitem features while implicitly considering a user's preferences, based on the\nuser's purchase history. To achieve this, we propose a knowledge graph (KG)\napproach to natural language explainable recommendation. Our approach draws on\nuser-item features through a novel collaborative filtering-based KG\nrepresentation to produce fact-grounded, personalized explanations, while\njointly learning user-item representations for recommendation scoring.\nExperimental results show that our approach consistently outperforms previous\nstate-of-the-art models on natural language explainable recommendation.",
            "author": [
                "Anthony Colas",
                "Jun Araki",
                "Zhengyu Zhou",
                "Bingqing Wang",
                "Zhe Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15813v1",
                "http://arxiv.org/pdf/2308.15813v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15809v1",
            "title": "Maximin-Aware Allocations of Indivisible Chores with Symmetric and\n  Asymmetric Agents",
            "updated": "2023-08-30T07:29:50Z",
            "published": "2023-08-30T07:29:50Z",
            "summary": "The real-world deployment of fair allocation algorithms usually involves a\nheterogeneous population of users, which makes it challenging for the users to\nget complete knowledge of the allocation except for their own bundles. Chan et\nal. [IJCAI 2019] proposed a new fairness notion, maximin-awareness (MMA), which\nguarantees that every agent is not the worst-off one, no matter how the items\nthat are not allocated to her are distributed. We adapt and generalize this\nnotion to the case of indivisible chores and when the agents may have arbitrary\nweights. Due to the inherent difficulty of MMA, we also consider its up to one\nand up to any relaxations. A string of results on the existence and computation\nof MMA related fair allocations, and their connections to existing fairness\nconcepts is given.",
            "author": [
                "Tianze Wei",
                "Bo Li",
                "Minming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15809v1",
                "http://arxiv.org/pdf/2308.15809v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15804v1",
            "title": "Securing Blockchain Systems: A Novel Collaborative Learning Framework to\n  Detect Attacks in Transactions and Smart Contracts",
            "updated": "2023-08-30T07:17:20Z",
            "published": "2023-08-30T07:17:20Z",
            "summary": "With the escalating prevalence of malicious activities exploiting\nvulnerabilities in blockchain systems, there is an urgent requirement for\nrobust attack detection mechanisms. To address this challenge, this paper\npresents a novel collaborative learning framework designed to detect attacks in\nblockchain transactions and smart contracts by analyzing transaction features.\nOur framework exhibits the capability to classify various types of blockchain\nattacks, including intricate attacks at the machine code level (e.g., injecting\nmalicious codes to withdraw coins from users unlawfully), which typically\nnecessitate significant time and security expertise to detect. To achieve that,\nthe proposed framework incorporates a unique tool that transforms transaction\nfeatures into visual representations, facilitating efficient analysis and\nclassification of low-level machine codes. Furthermore, we propose a customized\ncollaborative learning model to enable real-time detection of diverse attack\ntypes at distributed mining nodes. In order to create a comprehensive dataset,\nwe deploy a pilot system based on a private Ethereum network and conduct\nmultiple attack scenarios. To the best of our knowledge, our dataset is the\nmost comprehensive and diverse collection of transactions and smart contracts\nsynthesized in a laboratory for cyberattack detection in blockchain systems.\nOur framework achieves a detection accuracy of approximately 94\\% through\nextensive simulations and real-time experiments with a throughput of over 1,100\ntransactions per second. These compelling results validate the efficacy of our\nframework and showcase its adaptability in addressing real-world cyberattack\nscenarios.",
            "author": [
                "Tran Viet Khoa",
                "Do Hai Son",
                "Chi-Hieu Nguyen",
                "Dinh Thai Hoang",
                "Diep N. Nguyen",
                "Nguyen Linh Trung",
                "Tran Thi Thuy Quynh",
                "Trong-Minh Hoang",
                "Nguyen Viet Ha",
                "Eryk Dutkiewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15804v1",
                "http://arxiv.org/pdf/2308.15804v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15790v2",
            "title": "Translators invariant under hyperpolar actions",
            "updated": "2023-10-13T02:18:14Z",
            "published": "2023-08-30T06:47:16Z",
            "summary": "In this paper, we consider translators (for the mean curvature flow) given by\na graph of a function on a symmetric space $G/K$ of compact type which is\ninvariant under a hyperpolar action on $G/K$. First, in the case of\n$G/K=SO(n+1)/SO(n)$, $SU(n+1)/S(U(1)\\times U(n))$, $Sp(n+1)/(Sp(1)\\times\nSp(n))$ or $F_4/{\\rm Spin}(9)$, we classify the shapes of translators in\n$G/K\\times\\mathbb R$ given by the graphs of functions on $G/K$ which are\ninvariant under the isotropy action $K\\curvearrowright G/K$. Next, in the case\nwhere $G/K$ is of higher rank, we investigate translators in $G/K\\times\\mathbb\nR$ given by the graphs of functions on $G/K$ which are invariant under a\nhyperpolar action $H\\curvearrowright G/K$ of cohomogeneity two.",
            "author": [
                "Tomoki Fujii",
                "Naoyuki Koike"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15790v2",
                "http://arxiv.org/pdf/2308.15790v2"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15786v1",
            "title": "FedCiR: Client-Invariant Representation Learning for Federated Non-IID\n  Features",
            "updated": "2023-08-30T06:36:32Z",
            "published": "2023-08-30T06:36:32Z",
            "summary": "Federated learning (FL) is a distributed learning paradigm that maximizes the\npotential of data-driven models for edge devices without sharing their raw\ndata. However, devices often have non-independent and identically distributed\n(non-IID) data, meaning their local data distributions can vary significantly.\nThe heterogeneity in input data distributions across devices, commonly referred\nto as the feature shift problem, can adversely impact the training convergence\nand accuracy of the global model. To analyze the intrinsic causes of the\nfeature shift problem, we develop a generalization error bound in FL, which\nmotivates us to propose FedCiR, a client-invariant representation learning\nframework that enables clients to extract informative and client-invariant\nfeatures. Specifically, we improve the mutual information term between\nrepresentations and labels to encourage representations to carry essential\nclassification knowledge, and diminish the mutual information term between the\nclient set and representations conditioned on labels to promote representations\nof clients to be client-invariant. We further incorporate two regularizers into\nthe FL framework to bound the mutual information terms with an approximate\nglobal representation distribution to compensate for the absence of the\nground-truth global representation distribution, thus achieving informative and\nclient-invariant feature extraction. To achieve global representation\ndistribution approximation, we propose a data-free mechanism performed by the\nserver without compromising privacy. Extensive experiments demonstrate the\neffectiveness of our approach in achieving client-invariant representation\nlearning and solving the data heterogeneity issue.",
            "author": [
                "Zijian Li",
                "Zehong Lin",
                "Jiawei Shao",
                "Yuyi Mao",
                "Jun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15786v1",
                "http://arxiv.org/pdf/2308.15786v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15785v1",
            "title": "Collaborative, Code-Proximal Dynamic Software Visualization within Code\n  Editors",
            "updated": "2023-08-30T06:35:40Z",
            "published": "2023-08-30T06:35:40Z",
            "summary": "Software visualizations are usually realized as standalone and isolated tools\nthat use embedded code viewers within the visualization. In the context of\nprogram comprehension, only few approaches integrate visualizations into code\neditors, such as integrated development environments. This is surprising since\nprofessional developers consider reading source code as one of the most\nimportant ways to understand software, therefore spend a lot of time with code\neditors. In this paper, we introduce the design and proof-of-concept\nimplementation for a software visualization approach that can be embedded into\ncode editors. Our contribution differs from related work in that we use dynamic\nanalysis of a software system's runtime behavior. Additionally, we incorporate\ndistributed tracing. This enables developers to understand how, for example,\nthe currently handled source code behaves as a fully deployed, distributed\nsoftware system. Our visualization approach enhances common remote pair\nprogramming tools and is collaboratively usable by employing shared code\ncities. As a result, user interactions are synchronized between code editor and\nvisualization, as well as broadcasted to collaborators. To the best of our\nknowledge, this is the first approach that combines code editors with\ncollaboratively usable code cities. Therefore, we conducted a user study to\ncollect first-time feedback regarding the perceived usefulness and perceived\nusability of our approach. We additionally collected logging information to\nprovide more data regarding time spent in code cities that are embedded in code\neditors. Seven teams with two students each participated in that study. The\nresults show that the majority of participants find our approach useful and\nwould employ it for their own use. We provide each participant's video\nrecording, raw results, and all steps to reproduce our experiment as\nsupplementary package.",
            "author": [
                "Alexander Krause-Glau",
                "Wilhelm Hasselbring"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15785v1",
                "http://arxiv.org/pdf/2308.15785v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15765v3",
            "title": "Cryptanalysis of a Cayley Hash Function Based on Affine Maps in one\n  Variable over a Finite Field",
            "updated": "2023-09-04T18:16:23Z",
            "published": "2023-08-30T05:13:55Z",
            "summary": "Cayley hash functions are cryptographic hashes constructed from Cayley graphs\nof groups. The hash function proposed by Shpilrain and Sosnovski (2016), based\non linear functions over a finite field, was proven insecure. This paper shows\nthat the proposal by Ghaffari and Mostaghim (2018) that uses the Shpilrain and\nSosnovski's hash in its construction is also insecure. We demonstrate its\nsecurity vulnerability by constructing collisions.",
            "author": [
                "Bianca Sosnovski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15765v3",
                "http://arxiv.org/pdf/2308.15765v3"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "math.GR",
                "20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15737v1",
            "title": "Mosaics for immersed surface-links",
            "updated": "2023-08-30T03:30:59Z",
            "published": "2023-08-30T03:30:59Z",
            "summary": "The concept of a knot mosaic was introduced by Lomonaco and Kauffman as a\nmeans to construct a quantum knot system. The mosaic number of a given knot $K$\nis defined as the minimum integer $n$ that allows the representation of $K$ on\nan $n \\times n$ mosaic board. Building upon this, the first author and Nelson\nextended the knot mosaic system to encompass surface-links through the\nutilization of marked graph diagrams and established both lower and upper\nbounds for the mosaic number of the surface-links presented in Yoshikawa's\ntable. In this paper, we establish a mosaic system for immersed surface-links\nby using singular marked graph diagrams. We also provide the definition and\ndiscussion on the mosaic number for immersed surface-links.",
            "author": [
                "Seonmi Choi",
                "Jieon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15737v1",
                "http://arxiv.org/pdf/2308.15737v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "57K12, 57K45, 81P99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15734v2",
            "title": "Efficient and Explainable Graph Neural Architecture Search via\n  Monte-Carlo Tree Search",
            "updated": "2023-09-01T01:10:06Z",
            "published": "2023-08-30T03:21:45Z",
            "summary": "Graph neural networks (GNNs) are powerful tools for performing data science\ntasks in various domains. Although we use GNNs in wide application scenarios,\nit is a laborious task for researchers and practitioners to design/select\noptimal GNN architectures in diverse graphs. To save human efforts and\ncomputational costs, graph neural architecture search (Graph NAS) has been used\nto search for a sub-optimal GNN architecture that combines existing components.\nHowever, there are no existing Graph NAS methods that satisfy explainability,\nefficiency, and adaptability to various graphs. Therefore, we propose an\nefficient and explainable Graph NAS method, called ExGNAS, which consists of\n(i) a simple search space that can adapt to various graphs and (ii) a search\nalgorithm that makes the decision process explainable. The search space\nincludes only fundamental functions that can handle homophilic and heterophilic\ngraphs. The search algorithm efficiently searches for the best GNN architecture\nvia Monte-Carlo tree search without neural models. The combination of our\nsearch space and algorithm achieves finding accurate GNN models and the\nimportant functions within the search space. We comprehensively evaluate our\nmethod compared with twelve hand-crafted GNN architectures and three Graph NAS\nmethods in four graphs. Our experimental results show that ExGNAS increases AUC\nup to 3.6 and reduces run time up to 78\\% compared with the state-of-the-art\nGraph NAS methods. Furthermore, we show ExGNAS is effective in analyzing the\ndifference between GNN architectures in homophilic and heterophilic graphs.",
            "author": [
                "Yuya Sasaki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15734v2",
                "http://arxiv.org/pdf/2308.15734v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15721v1",
            "title": "Clustered Colouring of Odd-$H$-Minor-Free Graphs",
            "updated": "2023-08-30T02:53:20Z",
            "published": "2023-08-30T02:53:20Z",
            "summary": "The clustered chromatic number of a graph class $\\mathcal{G}$ is the minimum\ninteger $c$ such that every graph $G\\in\\mathcal{G}$ has a $c$-colouring where\neach monochromatic component in $G$ has bounded size. We study the clustered\nchromatic number of graph classes $\\mathcal{G}_H^{\\text{odd}}$ defined by\nexcluding a graph $H$ as an odd-minor. How does the structure of $H$ relate to\nthe clustered chromatic number of $\\mathcal{G}_H^{\\text{odd}}$? Using a proof\nmethod by Norin, Scott, Seymour and Wood (2019), we show that the clustered\nchromatic number of $\\mathcal{G}_H^{\\text{odd}}$ is tied to the tree-depth of\n$H$.",
            "author": [
                "Robert Hickingbotham",
                "Raphael Steiner",
                "David R. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15721v1",
                "http://arxiv.org/pdf/2308.15721v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15715v2",
            "title": "Dynamic properties of double porosity/permeability model",
            "updated": "2023-11-19T16:04:06Z",
            "published": "2023-08-30T02:32:29Z",
            "summary": "Understanding fluid movement in multi-pored materials is vital for energy\nsecurity and physiology. For instance, shale (a geological material) and bone\n(a biological material) exhibit multiple pore networks. Double\nporosity/permeability models provide a mechanics-based approach to describe\nhydrodynamics in aforesaid porous materials. However, current theoretical\nresults primarily address state-state response, and their counterparts in the\ntransient regime are still wanting. The primary aim of this paper is to fill\nthis knowledge gap. We present three principal properties -- with rigorous\nmathematical arguments -- that the solutions under the double\nporosity/permeability model satisfy in the transient regime: backward-in-time\nuniqueness, reciprocity, and a variational principle. We employ the ``energy\nmethod'' -- by exploiting the physical total kinetic energy of the flowing\nfluid -- to establish the first property and Cauchy-Riemann convolutions to\nprove the next two. The results reported in this paper -- that qualitatively\ndescribe the dynamics of fluid flow in double-pored media -- have (a)\ntheoretical significance, (b) practical applications, and (c) considerable\npedagogical value. In particular, these results will benefit practitioners and\ncomputational scientists in checking the accuracy of numerical simulators. The\nbackward-in-time uniqueness lays a firm theoretical foundation for pursuing\ninverse problems in which one predicts the prescribed initial conditions based\non data available about the solution at a later instance.",
            "author": [
                "K. B. Nakshatrala"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15715v2",
                "http://arxiv.org/pdf/2308.15715v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math-ph",
                "math.AP",
                "math.MP",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15714v1",
            "title": "A constant factor approximation for the (p,3)-flexible graph\n  connectivity problem",
            "updated": "2023-08-30T02:31:33Z",
            "published": "2023-08-30T02:31:33Z",
            "summary": "In this article we provide a constant factor approximation for the\n$(p,3)$-flexible graph connectivity problem, improving on the previous best\nknown $O(p)$-approximation.",
            "author": [
                "Ishan Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15714v1",
                "http://arxiv.org/pdf/2308.15714v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15713v2",
            "title": "Absolute value measurement of ion-scale turbulence by two-dimensional\n  phase contrast imaging in Large Helical Device",
            "updated": "2023-10-26T07:26:07Z",
            "published": "2023-08-30T02:24:45Z",
            "summary": "Absolute value measurements of turbulence amplitude in magnetically confined\nhigh-temperature plasmas can effectively explain turbulence-driven transport\ncharacteristics and their role in plasma confinements. Two-dimensional phase\ncontrast imaging (2D-PCI) is a technique to evaluate the space-time spectrum of\nion-scale electron density fluctuation. However, absolute value measurement of\nturbulence amplitude has not been conducted owing to the nonlinearity of the\ndetector. In this study, the absolute measurement method proposed in the\nprevious study is applied to turbulence measurement results in the large\nhelical device. As a result, the localized turbulence amplitude at\n$n_e=1.5\\times 10^{19}$m$^{-3}$ is approximately $3.5\\times 10^{15}$m$^{-3}$,\nwhich is 0.02\\% of the electron density. In addition, the evaluated poloidal\nwavenumber spectrum is almost consistent, within a certain error range, the\nspectrum being calculated using a nonlinear gyrokinetic simulation. This result\nis the first to the best of our knowledge to quantitatively evaluate turbulence\namplitudes measured by 2D-PCI and compare with simulations.",
            "author": [
                "T. Kinoshita",
                "K. Tanaka",
                "H. Sakai",
                "R. Yanai",
                "M. Nunami",
                "C. A. Michael"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15713v2",
                "http://arxiv.org/pdf/2308.15713v2"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15711v1",
            "title": "Optimizing Factual Accuracy in Text Generation through Dynamic Knowledge\n  Selection",
            "updated": "2023-08-30T02:22:40Z",
            "published": "2023-08-30T02:22:40Z",
            "summary": "Language models (LMs) have revolutionized the way we interact with\ninformation, but they often generate nonfactual text, raising concerns about\ntheir reliability. Previous methods use external knowledge as references for\ntext generation to enhance factuality but often struggle with the knowledge\nmix-up(e.g., entity mismatch) of irrelevant references. Besides,as the length\nof the output text grows, the randomness of sampling can escalate,\ndetrimentally impacting the factual accuracy of the generated text. In this\npaper, we present DKGen, which divide the text generation process into an\niterative process. In each iteration, DKGen takes the input query, the\npreviously generated text and a subset of the reference passages as input to\ngenerate short text. During the process, the subset is dynamically selected\nfrom the full passage set based on their relevance to the previously generated\ntext and the query, largely eliminating the irrelevant references from input.\nTo further enhance DKGen's ability to correctly use these external knowledge,\nDKGen distills the relevance order of reference passages to the cross-attention\ndistribution of decoder. We train and evaluate DKGen on a large-scale benchmark\ndataset. Experiment results show that DKGen outperforms all baseline models.",
            "author": [
                "Hongjin Qian",
                "Zhicheng Dou",
                "Jiejun Tan",
                "Haonan Chen",
                "Haoqi Gu",
                "Ruofei Lai",
                "Xinyu Zhang",
                "Zhao Cao",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15711v1",
                "http://arxiv.org/pdf/2308.15711v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15706v1",
            "title": "Representing the Disciplinary Structure of Physics: A Comparative\n  Evaluation of Graph and Text Embedding Methods",
            "updated": "2023-08-30T02:08:52Z",
            "published": "2023-08-30T02:08:52Z",
            "summary": "Recent advances in machine learning offer new ways to represent and study\nscholarly works and the space of knowledge. Graph and text embeddings provide a\nconvenient vector representation of scholarly works based on citations and\ntext. Yet, it is unclear whether their representations are consistent or\nprovide different views of the structure of science. Here, we compare graph and\ntext embedding by testing their ability to capture the hierarchical structure\nof the Physics and Astronomy Classification Scheme (PACS) of papers published\nby the American Physical Society (APS). We also provide a qualitative\ncomparison of the overall structure of the graph and text embeddings for\nreference. We find that neural network-based methods outperform traditional\nmethods and graph embedding methods such as node2vec are better than other\nmethods at capturing the PACS structure. Our results call for further\ninvestigations into how different contexts of scientific papers are captured by\ndifferent methods, and how we can combine and leverage such information in an\ninterpretable manner.",
            "author": [
                "Isabel Constantino",
                "Sadamori Kojaku",
                "Santo Fortunato",
                "Yong-Yeol Ahn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15706v1",
                "http://arxiv.org/pdf/2308.15706v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15700v1",
            "title": "Training Towards Critical Use: Learning to Situate AI Predictions\n  Relative to Human Knowledge",
            "updated": "2023-08-30T01:54:31Z",
            "published": "2023-08-30T01:54:31Z",
            "summary": "A growing body of research has explored how to support humans in making\nbetter use of AI-based decision support, including via training and onboarding.\nExisting research has focused on decision-making tasks where it is possible to\nevaluate \"appropriate reliance\" by comparing each decision against a ground\ntruth label that cleanly maps to both the AI's predictive target and the human\ndecision-maker's goals. However, this assumption does not hold in many\nreal-world settings where AI tools are deployed today (e.g., social work,\ncriminal justice, and healthcare). In this paper, we introduce a\nprocess-oriented notion of appropriate reliance called critical use that\ncenters the human's ability to situate AI predictions against knowledge that is\nuniquely available to them but unavailable to the AI model. To explore how\ntraining can support critical use, we conduct a randomized online experiment in\na complex social decision-making setting: child maltreatment screening. We find\nthat, by providing participants with accelerated, low-stakes opportunities to\npractice AI-assisted decision-making in this setting, novices came to exhibit\npatterns of disagreement with AI that resemble those of experienced workers. A\nqualitative examination of participants' explanations for their AI-assisted\ndecisions revealed that they drew upon qualitative case narratives, to which\nthe AI model did not have access, to learn when (not) to rely on AI\npredictions. Our findings open new questions for the study and design of\ntraining for real-world AI-assisted decision-making.",
            "author": [
                "Anna Kawakami",
                "Luke Guerdan",
                "Yanghuidi Cheng",
                "Matthew Lee",
                "Scott Carter",
                "Nikos Arechiga",
                "Kate Glazko",
                "Haiyi Zhu",
                "Kenneth Holstein"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15700v1",
                "http://arxiv.org/pdf/2308.15700v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15697v1",
            "title": "Segmenting mechanically heterogeneous domains via unsupervised learning",
            "updated": "2023-08-30T01:40:38Z",
            "published": "2023-08-30T01:40:38Z",
            "summary": "From biological organs to soft robotics, highly deformable materials are\nessential components of natural and engineered systems. These highly deformable\nmaterials can have heterogeneous material properties, and can experience\nheterogeneous deformations with or without underlying material heterogeneity.\nMany recent works have established that computational modeling approaches are\nwell suited for understanding and predicting the consequences of material\nheterogeneity and for interpreting observed heterogeneous strain fields. In\nparticular, there has been significant work towards developing inverse analysis\napproaches that can convert observed kinematic quantities (e.g., displacement,\nstrain) to material properties and mechanical state. Despite the success of\nthese approaches, they are not necessarily generalizable and often rely on\ntight control and knowledge of boundary conditions. Here, we will build on the\nrecent advances (and ubiquity) of machine learning approaches to explore\nalternative approaches to detect patterns in heterogeneous material properties\nand mechanical behavior. Specifically, we will explore unsupervised learning\napproaches to clustering and ensemble clutering to identify heterogeneous\nregions. Overall, we find that these approaches are effective, yet limited in\ntheir abilities. Through this initial exploration (where all data and code is\npublished alongside this manuscript), we set the stage for future studies that\nmore specifically adapt these methods to mechanical data.",
            "author": [
                "Quan Nguyen",
                "Emma Lejeune"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15697v1",
                "http://arxiv.org/pdf/2308.15697v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.data-an",
                "q-bio.TO",
                "74E05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15694v1",
            "title": "Quasiprimitive groups with a biregular dihedral subgroup,and\n  arc-transitive bidihedrants",
            "updated": "2023-08-30T01:24:24Z",
            "published": "2023-08-30T01:24:24Z",
            "summary": "A semiregular permutation group on a set $\\Ome$ is called {\\em bi-regular} if\nit has two orbits. A classification is given of quasiprimitive permutation\ngroups with a biregular dihedral subgroup. This is then used to characterize\nthe family of arc-transitive graphs whose automorphism groups containing a\nbi-regular dihedral subgroup. We first show that every such graph is a normal\n$r$-cover of an arc-transitive graph whose automorphism group is either\nquasiprimitive or bi-quasiprimitive on its vertices, and then classify all such\nquasiprimitive or bi-quasiprimitive arc-transitive graphs.",
            "author": [
                "Jiangmin Pan",
                "Fu-Gang Yin",
                "Jin-Xin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15694v1",
                "http://arxiv.org/pdf/2308.15694v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15674v1",
            "title": "Predict And Prevent DDOS Attacks Using Machine Learning and Statistical\n  Algorithms",
            "updated": "2023-08-30T00:03:32Z",
            "published": "2023-08-30T00:03:32Z",
            "summary": "A malicious attempt to exhaust a victim's resources to cause it to crash or\nhalt its services is known as a distributed denial-of-service (DDoS) attack.\nDDOS attacks stop authorized users from accessing specific services available\non the Internet. It targets varying components of a network layer and it is\nbetter to stop into layer 4 (transport layer) of the network before approaching\na higher layer. This study uses several machine learning and statistical models\nto detect DDoS attacks from traces of traffic flow and suggests a method to\nprevent DDOS attacks. For this purpose, we used logistic regression, CNN,\nXGBoost, naive Bayes, AdaBoostClassifier, KNN, and random forest ML algorithms.\nIn addition, data preprocessing was performed using three methods to identify\nthe most relevant features. This paper explores the issue of improving the DDOS\nattack detection accuracy using the latest dataset named CICDDoS2019, which has\nover 50 million records. Because we employed an extensive dataset for this\ninvestigation, our findings are trustworthy and practical. Our target class\n(attack class) was imbalanced. Therefore, we used two techniques to deal with\nimbalanced data in machine learning. The XGboost machine learning model\nprovided the best detection accuracy of (99.9999%) after applying the SMOTE\napproach to the target class, outperforming recently developed DDoS detection\nsystems. To the best of our knowledge, no other research has worked on the most\nrecent dataset with over 50 million records, addresses the statistical\ntechnique to select the most significant feature, has this high accuracy, and\nsuggests ways to avoid DDOS attackI.",
            "author": [
                "Azadeh Golduzian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15674v1",
                "http://arxiv.org/pdf/2308.15674v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15673v2",
            "title": "MDTD: A Multi Domain Trojan Detector for Deep Neural Networks",
            "updated": "2023-09-03T01:59:49Z",
            "published": "2023-08-30T00:03:03Z",
            "summary": "Machine learning models that use deep neural networks (DNNs) are vulnerable\nto backdoor attacks. An adversary carrying out a backdoor attack embeds a\npredefined perturbation called a trigger into a small subset of input samples\nand trains the DNN such that the presence of the trigger in the input results\nin an adversary-desired output class. Such adversarial retraining however needs\nto ensure that outputs for inputs without the trigger remain unaffected and\nprovide high classification accuracy on clean samples. In this paper, we\npropose MDTD, a Multi-Domain Trojan Detector for DNNs, which detects inputs\ncontaining a Trojan trigger at testing time. MDTD does not require knowledge of\ntrigger-embedding strategy of the attacker and can be applied to a pre-trained\nDNN model with image, audio, or graph-based inputs. MDTD leverages an insight\nthat input samples containing a Trojan trigger are located relatively farther\naway from a decision boundary than clean samples. MDTD estimates the distance\nto a decision boundary using adversarial learning methods and uses this\ndistance to infer whether a test-time input sample is Trojaned or not. We\nevaluate MDTD against state-of-the-art Trojan detection methods across five\nwidely used image-based datasets: CIFAR100, CIFAR10, GTSRB, SVHN, and\nFlowers102; four graph-based datasets: AIDS, WinMal, Toxicant, and COLLAB; and\nthe SpeechCommand audio dataset. MDTD effectively identifies samples that\ncontain different types of Trojan triggers. We evaluate MDTD against adaptive\nattacks where an adversary trains a robust DNN to increase (decrease) distance\nof benign (Trojan) inputs from a decision boundary.",
            "author": [
                "Arezoo Rajabi",
                "Surudhi Asokraj",
                "Fengqing Jiang",
                "Luyao Niu",
                "Bhaskar Ramasubramanian",
                "Jim Ritcey",
                "Radha Poovendran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15673v2",
                "http://arxiv.org/pdf/2308.15673v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15671v1",
            "title": "Lower Bound for Independence Covering in $C_4$-Free Graphs",
            "updated": "2023-08-29T23:46:16Z",
            "published": "2023-08-29T23:46:16Z",
            "summary": "An independent set in a graph $G$ is a set $S$ of pairwise non-adjacent\nvertices in $G$. A family $\\mathcal{F}$ of independent sets in $G$ is called a\n$k$-independence covering family if for every independent set $I$ in $G$ of\nsize at most $k$, there exists an $S \\in \\mathcal{F}$ such that $I \\subseteq\nS$.\n  Lokshtanov et al. [ACM Transactions on Algorithms, 2018] showed that graphs\nof degeneracy $d$ admit $k$-independence covering families of size\n$\\binom{k(d+1)}{k} \\cdot 2^{o(kd)} \\cdot \\log n$, and used this result to\ndesign efficient parameterized algorithms for a number of problems, including\nSTABLE ODD CYCLE TRANSVERSAL and STABLE MULTICUT.\n  In light of the results of Lokshtanov et al. it is quite natural to ask\nwhether even more general families of graphs admit $k$-independence covering\nfamilies of size $f(k)n^{O(1)}$.\n  Graphs that exclude a complete bipartite graph $K_{d+1,d+1}$ with $d+1$\nvertices on both sides as a subgraph, called $K_{d+1,d+1}$-free graphs, are a\nfrequently considered generalization of $d$-degenerate graphs.\n  This motivates the question whether $K_{d,d}$-free graphs admit\n$k$-independence covering families of size $f(k,d)n^{O(1)}$. Our main result is\na resounding \"no\" to this question -- specifically we prove that even\n$K_{2,2}$-free graphs (or equivalently $C_4$-free graphs) do not admit\n$k$-independence covering families of size $f(k)n^{\\frac{k}{4}-\\epsilon}$.",
            "author": [
                "Michael Kuhn",
                "Daniel Lokshtanov",
                "Zachary Miller"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15671v1",
                "http://arxiv.org/pdf/2308.15671v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO",
                "68R10 (Primary) 68R05 (Secondary)",
                "G.2.1; F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15669v1",
            "title": "ACER: An AST-based Call Graph Generator Framework",
            "updated": "2023-08-29T23:44:35Z",
            "published": "2023-08-29T23:44:35Z",
            "summary": "We introduce ACER, an AST-based call graph generator framework. ACER\nleverages tree-sitter to interface with any language. We opted to focus on\ngenerators that operate on abstract syntax trees (ASTs) due to their speed and\nsimplicitly in certain scenarios; however, a fully quantified intermediate\nrepresentation usually provides far better information at the cost of requiring\ncompilation. To evaluate our framework, we created two context-insensitive Java\ngenerators and compared them to existing open-source Java generators.",
            "author": [
                "Andrew Chen",
                "Yanfu Yan",
                "Denys Poshyvanyk"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15669v1",
                "http://arxiv.org/pdf/2308.15669v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15654v1",
            "title": "Injective edge colorings of degenerate graphs and the oriented chromatic\n  number",
            "updated": "2023-08-29T22:21:10Z",
            "published": "2023-08-29T22:21:10Z",
            "summary": "Given a graph $G$, an injective edge-coloring of $G$ is a function $\\psi:E(G)\n\\rightarrow \\mathbb N$ such that if $\\psi(e) = \\psi(e')$, then no third edge\njoins an endpoint of $e$ and an endpoint of $e'$. The injective chromatic index\nof a graph $G$, written $\\chi_{inj}'(G)$, is the minimum number of colors\nneeded for an injective edge coloring of $G$. In this paper, we investigate the\ninjective chromatic index of certain classes of degenerate graphs. First, we\nshow that if $G$ is a $d$-degenerate graph of maximum degree $\\Delta$, then\n$\\chi_{inj}'(G) = O(d^3 \\log \\Delta)$. Next, we show that if $G$ is a graph of\nEuler genus $g$, then $\\chi_{inj}'(G) \\leq (3+o(1))g$, which is tight when $G$\nis a clique. Finally, we show that the oriented chromatic number of a graph is\nat most exponential in its injective chromatic index. Using this fact, we prove\nthat the oriented chromatic number of a graph embedded on a surface of Euler\ngenus $g$ has oriented chromatic number at most $O(g^{6400})$, improving the\npreviously known upper bound of $2^{O(g^{\\frac{1}{2} + \\epsilon})}$ and\nresolving a conjecture of Aravind and Subramanian.",
            "author": [
                "Peter Bradshaw",
                "Alexander Clow",
                "Jingwei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15654v1",
                "http://arxiv.org/pdf/2308.15654v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15652v1",
            "title": "BubbleDet: A Python package to compute functional determinants for\n  bubble nucleation",
            "updated": "2023-08-29T22:06:23Z",
            "published": "2023-08-29T22:06:23Z",
            "summary": "We present a Python package, BubbleDet, for computing one-loop functional\ndeterminants around spherically symmetric background fields. This gives the\nnext-to-leading order correction to both the vacuum decay rate, at zero\ntemperature, and to the bubble nucleation rate in first-order phase transitions\nat finite temperature. For predictions of gravitational wave signals from\ncosmological phase transitions, this is expected to remove one of the leading\nsources of theoretical uncertainty. BubbleDet is applicable to arbitrary scalar\npotentials and in any dimension up to seven. It has methods for fluctuations of\nscalar fields, including Goldstone bosons, and for gauge fields, but is limited\nto cases where the determinant factorises into a product of separate\ndeterminants, one for each field degree of freedom. To our knowledge, BubbleDet\nis the first package dedicated to calculating functional determinants in\nspherically symmetric background",
            "author": [
                "Andreas Ekstedt",
                "Oliver Gould",
                "Joonas Hirvonen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15652v1",
                "http://arxiv.org/pdf/2308.15652v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15648v2",
            "title": "Universal framework for simultaneous tomography of quantum states and\n  SPAM noise",
            "updated": "2023-08-31T02:36:19Z",
            "published": "2023-08-29T21:49:28Z",
            "summary": "We present a general denoising algorithm for performing simultaneous\ntomography of quantum states and measurement noise. This algorithm allows us to\nfully characterize state preparation and measurement (SPAM) errors present in\nany quantum system. Our method is based on the analysis of the properties of\nthe linear operator space induced by unitary operations. Given any quantum\nsystem with a noisy measurement apparatus, our method can output the quantum\nstate and the noise matrix of the detector up to a single gauge degree of\nfreedom. We show that this gauge freedom is unavoidable in the general case,\nbut this degeneracy can be generally broken using prior knowledge on the state\nor noise properties, thus fixing the gauge for several types of state-noise\ncombinations with no assumptions about noise strength. Such combinations\ninclude pure quantum states with arbitrarily correlated errors, and arbitrary\nstates with block independent errors. This framework can further use available\nprior information about the setting to systematically reduce the number of\nobservations and measurements required for state and noise detection. Our\nmethod effectively generalizes existing approaches to the problem, and includes\nas special cases common settings considered in the literature requiring an\nuncorrelated or invertible noise matrix, or specific probe states.",
            "author": [
                "Abhijith Jayakumar",
                "Stefano Chessa",
                "Carleton Coffrin",
                "Andrey Y. Lokhov",
                "Marc Vuffray",
                "Sidhant Misra"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15648v2",
                "http://arxiv.org/pdf/2308.15648v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15642v1",
            "title": "Clustering Without an Eigengap",
            "updated": "2023-08-29T21:27:21Z",
            "published": "2023-08-29T21:27:21Z",
            "summary": "We study graph clustering in the Stochastic Block Model (SBM) in the presence\nof both large clusters and small, unrecoverable clusters. Previous approaches\nachieving exact recovery do not allow any small clusters of size $o(\\sqrt{n})$,\nor require a size gap between the smallest recovered cluster and the largest\nnon-recovered cluster. We provide an algorithm based on semidefinite\nprogramming (SDP) which removes these requirements and provably recovers large\nclusters regardless of the remaining cluster sizes. Mid-sized clusters pose\nunique challenges to the analysis, since their proximity to the recovery\nthreshold makes them highly sensitive to small noise perturbations and\nprecludes a closed-form candidate solution. We develop novel techniques,\nincluding a leave-one-out-style argument which controls the correlation between\nSDP solutions and noise vectors even when the removal of one row of noise can\ndrastically change the SDP solution. We also develop improved eigenvalue\nperturbation bounds of potential independent interest. Using our gap-free\nclustering procedure, we obtain efficient algorithms for the problem of\nclustering with a faulty oracle with superior query complexities, notably\nachieving $o(n^2)$ sample complexity even in the presence of a large number of\nsmall clusters. Our gap-free clustering procedure also leads to improved\nalgorithms for recursive clustering. Our results extend to certain\nheterogeneous probability settings that are challenging for alternative\nalgorithms.",
            "author": [
                "Matthew Zurek",
                "Yudong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15642v1",
                "http://arxiv.org/pdf/2308.15642v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "cs.IT",
                "math.IT",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15639v1",
            "title": "Hyperbolic Convolutional Neural Networks",
            "updated": "2023-08-29T21:20:16Z",
            "published": "2023-08-29T21:20:16Z",
            "summary": "Deep Learning is mostly responsible for the surge of interest in Artificial\nIntelligence in the last decade. So far, deep learning researchers have been\nparticularly successful in the domain of image processing, where Convolutional\nNeural Networks are used. Although excelling at image classification,\nConvolutional Neural Networks are quite naive in that no inductive bias is set\non the embedding space for images. Similar flaws are also exhibited by another\ntype of Convolutional Networks - Graph Convolutional Neural Networks. However,\nusing non-Euclidean space for embedding data might result in more robust and\nexplainable models. One example of such a non-Euclidean space is hyperbolic\nspace. Hyperbolic spaces are particularly useful due to their ability to fit\nmore data in a low-dimensional space and tree-likeliness properties. These\nattractive properties have been previously used in multiple papers which\nindicated that they are beneficial for building hierarchical embeddings using\nshallow models and, recently, using MLPs and RNNs.\n  However, no papers have yet suggested a general approach to using Hyperbolic\nConvolutional Neural Networks for structured data processing, although these\nare the most common examples of data used. Therefore, the goal of this work is\nto devise a general recipe for building Hyperbolic Convolutional Neural\nNetworks. We hypothesize that ability of hyperbolic space to capture hierarchy\nin the data would lead to better performance. This ability should be\nparticularly useful in cases where data has a tree-like structure. Since this\nis the case for many existing datasets \\citep{wordnet, imagenet, fb15k}, we\nargue that such a model would be advantageous both in terms of applications and\nfuture research prospects.",
            "author": [
                "Andrii Skliar",
                "Maurice Weiler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15639v1",
                "http://arxiv.org/pdf/2308.15639v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15635v1",
            "title": "Parameterized and Approximation Algorithms for the Maximum Bimodal\n  Subgraph Problem",
            "updated": "2023-08-29T21:01:31Z",
            "published": "2023-08-29T21:01:31Z",
            "summary": "A vertex of a plane digraph is bimodal if all its incoming edges (and hence\nall its outgoing edges) are consecutive in the cyclic order around it. A plane\ndigraph is bimodal if all its vertices are bimodal. Bimodality is at the heart\nof many types of graph layouts, such as upward drawings, level-planar drawings,\nand L-drawings. If the graph is not bimodal, the Maximum Bimodal Subgraph (MBS)\nproblem asks for an embedding-preserving bimodal subgraph with the maximum\nnumber of edges. We initiate the study of the MBS problem from the\nparameterized complexity perspective with two main results: (i) we describe an\nFPT algorithm parameterized by the branchwidth (and hence by the treewidth) of\nthe graph; (ii) we establish that MBS parameterized by the number of\nnon-bimodal vertices admits a polynomial kernel. As the byproduct of these\nresults, we obtain a subexponential FPT algorithm and an efficient\npolynomial-time approximation scheme for MBS.",
            "author": [
                "Walter Didimo",
                "Fedor V. Fomin",
                "Petr A. Golovach",
                "Tanmay Inamdar",
                "Stephen Kobourov",
                "Marie Diana Sieper"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15635v1",
                "http://arxiv.org/pdf/2308.15635v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15629v1",
            "title": "Dynamic random intersection graph: Dynamic local convergence and giant\n  structure",
            "updated": "2023-08-29T20:55:48Z",
            "published": "2023-08-29T20:55:48Z",
            "summary": "Random intersection graphs containing an underlying community structure are a\npopular choice for modelling real-world networks. Given the group memberships,\nthe classical random intersection graph is obtained by connecting individuals\nwhen they share at least one group. We extend this approach and make the\ncommunities dynamic by letting them alternate between an active and inactive\nphase. We analyse the new model, delivering results on degree distribution,\nlocal convergence, giant component, and maximum group size, paying particular\nattention to the dynamic description of these properties. We also describe the\nconnection between our model and the bipartite configuration model, which is of\nindependent interest.",
            "author": [
                "Marta Milewska",
                "Remco van der Hofstad",
                "Bert Zwart"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15629v1",
                "http://arxiv.org/pdf/2308.15629v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15620v1",
            "title": "Intelligent System for Assessing University Student Personality\n  Development and Career Readiness",
            "updated": "2023-08-29T20:32:58Z",
            "published": "2023-08-29T20:32:58Z",
            "summary": "While academic metrics such as transcripts and GPA are commonly used to\nevaluate students' knowledge acquisition, there is a lack of comprehensive\nmetrics to measure their preparedness for the challenges of post-graduation\nlife. This research paper explores the impact of various factors on university\nstudents' readiness for change and transition, with a focus on their\npreparedness for careers. The methodology employed in this study involves\ndesigning a survey based on Paul J. Mayer's \"The Balance Wheel\" to capture\nstudents' sentiments on various life aspects, including satisfaction with the\neducational process and expectations of salary. The collected data from a KBTU\nstudent survey (n=47) were processed through machine learning models: Linear\nRegression, Support Vector Regression (SVR), Random Forest Regression.\nSubsequently, an intelligent system was built using these models and fuzzy\nsets. The system is capable of evaluating graduates' readiness for their future\ncareers and demonstrates a high predictive power. The findings of this research\nhave practical implications for educational institutions. Such an intelligent\nsystem can serve as a valuable tool for universities to assess and enhance\nstudents' preparedness for post-graduation challenges. By recognizing the\nfactors contributing to students' readiness for change, universities can refine\ncurricula and processes to better prepare students for their career journeys.",
            "author": [
                "Izbassar Assylzhan",
                "Muragul Muratbekova",
                "Daniyar Amangeldi",
                "Nazzere Oryngozha",
                "Anna Ogorodova",
                "Pakizar Shamoi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15620v1",
                "http://arxiv.org/pdf/2308.15620v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15618v1",
            "title": "RACR-MIL: Weakly Supervised Skin Cancer Grading using Rank-Aware\n  Contextual Reasoning on Whole Slide Images",
            "updated": "2023-08-29T20:25:49Z",
            "published": "2023-08-29T20:25:49Z",
            "summary": "Cutaneous squamous cell cancer (cSCC) is the second most common skin cancer\nin the US. It is diagnosed by manual multi-class tumor grading using a tissue\nwhole slide image (WSI), which is subjective and suffers from inter-pathologist\nvariability. We propose an automated weakly-supervised grading approach for\ncSCC WSIs that is trained using WSI-level grade and does not require\nfine-grained tumor annotations. The proposed model, RACR-MIL, transforms each\nWSI into a bag of tiled patches and leverages attention-based multiple-instance\nlearning to assign a WSI-level grade. We propose three key innovations to\naddress general as well as cSCC-specific challenges in tumor grading. First, we\nleverage spatial and semantic proximity to define a WSI graph that encodes both\nlocal and non-local dependencies between tumor regions and leverage graph\nattention convolution to derive contextual patch features. Second, we introduce\na novel ordinal ranking constraint on the patch attention network to ensure\nthat higher-grade tumor regions are assigned higher attention. Third, we use\ntumor depth as an auxiliary task to improve grade classification in a multitask\nlearning framework. RACR-MIL achieves 2-9% improvement in grade classification\nover existing weakly-supervised approaches on a dataset of 718 cSCC tissue\nimages and localizes the tumor better. The model achieves 5-20% higher accuracy\nin difficult-to-classify high-risk grade classes and is robust to class\nimbalance.",
            "author": [
                "Anirudh Choudhary",
                "Angelina Hwang",
                "Jacob Kechter",
                "Krishnakant Saboo",
                "Blake Bordeaux",
                "Puneet Bhullar",
                "Nneka Comfere",
                "David DiCaudo",
                "Steven Nelson",
                "Emma Johnson",
                "Leah Swanson",
                "Dennis Murphree",
                "Aaron Mangold",
                "Ravishankar K. Iyer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15618v1",
                "http://arxiv.org/pdf/2308.15618v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15617v1",
            "title": "Streaming, Local, and Multi-Level (Hyper)Graph Decomposition",
            "updated": "2023-08-29T20:24:49Z",
            "published": "2023-08-29T20:24:49Z",
            "summary": "(Hyper)Graph decomposition is a family of problems that aim to break down\nlarge (hyper)graphs into smaller sub(hyper)graphs for easier analysis. The\nimportance of this lies in its ability to enable efficient computation on large\nand complex (hyper)graphs, such as social networks, chemical compounds, and\ncomputer networks. This dissertation explores several types of (hyper)graph\ndecomposition problems, including graph partitioning, hypergraph partitioning,\nlocal graph clustering, process mapping, and signed graph clustering. Our main\nfocus is on streaming algorithms, local algorithms and multilevel algorithms.\nIn terms of streaming algorithms, we make contributions with highly efficient\nand effective algorithms for (hyper)graph partitioning and process mapping. In\nterms of local algorithms, we propose sub-linear algorithms which are effective\nin detecting high-quality local communities around a given seed node in a graph\nbased on the distribution of a given motif. In terms of multilevel algorithms,\nwe engineer high-quality multilevel algorithms for process mapping and signed\ngraph clustering. We provide a thorough discussion of each algorithm along with\nexperimental results demonstrating their superiority over existing\nstate-of-the-art techniques. The results show that the proposed algorithms\nachieve improved performance and better solutions in various metrics, making\nthem highly promising for practical applications. Overall, this dissertation\nshowcases the effectiveness of advanced combinatorial algorithmic techniques in\nsolving challenging (hyper)graph decomposition problems.",
            "author": [
                "Marcelo Fonseca Faraj"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15617v1",
                "http://arxiv.org/pdf/2308.15617v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15614v1",
            "title": "Everything Perturbed All at Once: Enabling Differentiable Graph Attacks",
            "updated": "2023-08-29T20:14:42Z",
            "published": "2023-08-29T20:14:42Z",
            "summary": "As powerful tools for representation learning on graphs, graph neural\nnetworks (GNNs) have played an important role in applications including social\nnetworks, recommendation systems, and online web services. However, GNNs have\nbeen shown to be vulnerable to adversarial attacks, which can significantly\ndegrade their effectiveness. Recent state-of-the-art approaches in adversarial\nattacks rely on gradient-based meta-learning to selectively perturb a single\nedge with the highest attack score until they reach the budget constraint.\nWhile effective in identifying vulnerable links, these methods are plagued by\nhigh computational costs. By leveraging continuous relaxation and\nparameterization of the graph structure, we propose a novel attack method\ncalled Differentiable Graph Attack (DGA) to efficiently generate effective\nattacks and meanwhile eliminate the need for costly retraining. Compared to the\nstate-of-the-art, DGA achieves nearly equivalent attack performance with 6\ntimes less training time and 11 times smaller GPU memory footprint on different\nbenchmark datasets. Additionally, we provide extensive experimental analyses of\nthe transferability of the DGA among different graph models, as well as its\nrobustness against widely-used defense mechanisms.",
            "author": [
                "Haoran Liu",
                "Bokun Wang",
                "Jianling Wang",
                "Xiangjue Dong",
                "Tianbao Yang",
                "James Caverlee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15614v1",
                "http://arxiv.org/pdf/2308.15614v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15611v1",
            "title": "Laplacian $\\{-1,0,1\\}$- and $\\{-1,1\\}$-diagonalizable graphs",
            "updated": "2023-08-29T20:10:25Z",
            "published": "2023-08-29T20:10:25Z",
            "summary": "A graph is called \"Laplacian integral\" if the eigenvalues of its Laplacian\nmatrix are all integers. We investigate the subset of these graphs whose\nLaplacian is furthermore diagonalized by a matrix with entries coming from a\nfixed set, with particular emphasis on the sets $\\{-1,0,1\\}$ or $\\{-1,1\\}$.\nSuch graphs include as special cases the recently-investigated families of\n\"Hadamard-diagonalizable\" and \"weakly Hadamard-diagonalizable\" graphs. As a\ncombinatorial tool to aid in our investigation, we introduce a family of\nvectors that we call \"balanced\", which generalize totally balanced partitions,\nregular sequences, and complete partitions. We show that balanced vectors\ncompletely characterize which graph complements and complete multipartite\ngraphs are $\\{-1,0,1\\}$-diagonalizable, and we furthermore prove results on\ndiagonalizability of the Cartesian product, disjoint union, and join of graphs.\nParticular attention is paid to the $\\{-1,0,1\\}$- and\n$\\{-1,1\\}$-diagonalizability of the complete graphs and complete multipartite\ngraphs. Finally, we provide a complete list of all simple, connected graphs on\nnine or fewer vertices that are $\\{-1,0,1\\}$- or $\\{-1,1\\}$-diagonalizable.",
            "author": [
                "Nathaniel Johnston",
                "Sarah Plosker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15611v1",
                "http://arxiv.org/pdf/2308.15611v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 15A18"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15603v1",
            "title": "$k$-tuple domination on Kneser graphs",
            "updated": "2023-08-29T19:50:17Z",
            "published": "2023-08-29T19:50:17Z",
            "summary": "In this paper, we continue the study of different types of dominating sets in\nKneser graphs. We focus on $k$-tuple dominating sets, $2$-packings and the\nassociated graph parameters $k$-tuple domination number and $2$-packing number.\nIn particular, we determine the Kneser graphs $K(n,r)$ with $k$-tuple\ndomination number exactly $k+r$ and find all the minimum sized $k$-tuple\ndominating sets for these graphs, which generalize results for dominating sets\nin Kneser graphs. Besides, we give a characterization of the $k$-tuple\ndominating sets of $K(n,2)$ in terms of the occurrences of the elements in\n$[n]$, which allows us to obtain minimum sized $k$-tuple dominating sets for\nalmost all positive integers $n\\geq 4$. Finally, we compute both parameters for\ncertain Kneser graphs, and specifically in odd graphs we show that these\ninvariants are extremely related with perfect $1$-codes and Steiner systems.\n  Keywords: Kneser graphs, $k$-tuple dominating set.",
            "author": [
                "Mar\u00eda Gracia Cornet",
                "Pablo Torres"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15603v1",
                "http://arxiv.org/pdf/2308.15603v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15602v1",
            "title": "An Experimental Comparison of Partitioning Strategies for Distributed\n  Graph Neural Network Training",
            "updated": "2023-08-29T19:47:31Z",
            "published": "2023-08-29T19:47:31Z",
            "summary": "Recently, graph neural networks (GNNs) have gained much attention as a\ngrowing area of deep learning capable of learning on graph-structured data.\nHowever, the computational and memory requirements for training GNNs on\nlarge-scale graphs can exceed the capabilities of single machines or GPUs,\nmaking distributed GNN training a promising direction for large-scale GNN\ntraining. A prerequisite for distributed GNN training is to partition the input\ngraph into smaller parts that are distributed among multiple machines of a\ncompute cluster. Although graph partitioning has been extensively studied with\nregard to graph analytics and graph databases, its effect on GNN training\nperformance is largely unexplored.\n  In this paper, we study the effectiveness of graph partitioning for\ndistributed GNN training. Our study aims to understand how different factors\nsuch as GNN parameters, mini-batch size, graph type, features size, and\nscale-out factor influence the effectiveness of graph partitioning. We conduct\nexperiments with two different GNN systems using vertex and edge partitioning.\nWe found that graph partitioning is a crucial pre-processing step that can\nheavily reduce the training time and memory footprint. Furthermore, our results\nshow that invested partitioning time can be amortized by reduced GNN training,\nmaking it a relevant optimization.",
            "author": [
                "Nikolai Merkel",
                "Daniel Stoll",
                "Ruben Mayer",
                "Hans-Arno Jacobsen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15602v1",
                "http://arxiv.org/pdf/2308.15602v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15601v1",
            "title": "Cognitive dissonance or p-prims? Towards identifying the best way to\n  overcome misconceptions in physics",
            "updated": "2023-08-29T19:46:38Z",
            "published": "2023-08-29T19:46:38Z",
            "summary": "In this classroom-based action-research project, I compared the following two\napproaches to check their effectiveness in helping students overcome physics\nmisconceptions: Inducing cognitive dissonance or gradually building on\nstudents' previous knowledge activating the relevant phenomenological\nprimitives (p-prims). This took place over a two-lesson sequence (each an hour\nlong) using year 8 (12 years old) and year 9 (13 years old) top set students\n(N=87 in total), in the context of Newton's first law. Results were better for\nboth year groups when inducing cognitive dissonance, which seems to be more\neffective not only with surface-level learning, but deep-learning as well.",
            "author": [
                "Panagiotis Athanasopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15601v1",
                "http://arxiv.org/pdf/2308.15601v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15590v1",
            "title": "String graphs with precise number of intersections",
            "updated": "2023-08-29T19:36:02Z",
            "published": "2023-08-29T19:36:02Z",
            "summary": "A string graph is an intersection graph of curves in the plane. A $k$-string\ngraph is a graph with a string representation in which every pair of curves\nintersects in at most $k$ points. We introduce the class of $(=k)$-string\ngraphs as a further restriction of $k$-string graphs by requiring that every\ntwo curves intersect in either zero or precisely $k$ points. We study the\nhierarchy of these graphs, showing that for any $k\\geq 1$, $(=k)$-string graphs\nare a subclass of $(=k+2)$-string graphs as well as of $(=4k)$-string graphs;\nhowever, there are no other inclusions between the classes of $(=k)$-string and\n$(=\\ell)$-string graphs apart from those that are implied by the above rules.\nIn particular, the classes of $(=k)$-string graphs and $(=k+1)$-string graphs\nare incomparable by inclusion for any $k$, and the class of $(=2)$-string\ngraphs is not contained in the class of $(=2\\ell+1)$-string graphs for any\n$\\ell$.",
            "author": [
                "Petr Chmel",
                "V\u00edt Jel\u00ednek"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15590v1",
                "http://arxiv.org/pdf/2308.15590v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15588v3",
            "title": "On Edge Coloring of Multigraphs",
            "updated": "2023-11-28T01:55:45Z",
            "published": "2023-08-29T19:32:21Z",
            "summary": "Let $\\Delta(G)$ and $\\chi'(G)$ be the maximum degree and chromatic index of a\ngraph $G$, respectively.\n  Appearing in different format, Gupta\\,(1967), Goldberg\\,(1973),\nAndersen\\,(1977), and Seymour\\,(1979) made the following conjecture: Every\nmultigraph $G$ satisfies $\\chi'(G) \\le \\max\\{ \\Delta(G) + 1, \\Gamma(G) \\}$,\nwhere $\\Gamma(G) = \\max_{H \\subseteq G} \\left\\lceil \\frac{ |E(H)| }{ \\lfloor\n\\tfrac{1}{2} |V(H)| \\rfloor} \\right\\rceil$ is the density of $G$. In this\npaper, we present a polynomial-time algorithm for coloring any multigraph with\n$\\max\\{ \\Delta(G) + 1, \\Gamma(G) \\}$ many colors, confirming the conjecture\nalgorithmically. Since $\\chi'(G)\\geq \\max\\{ \\Delta(G), \\Gamma(G) \\}$, this\nalgorithm gives a proper edge coloring that uses at most one more color than\nthe optimum. As determining the chromatic index of an arbitrary graph is\n$NP$-hard, the $\\max\\{ \\Delta(G) + 1, \\Gamma(G) \\}$ bound is best possible for\nefficient proper edge coloring algorithms on general multigraphs, unless\n$P=NP$.",
            "author": [
                "Guangming Jing"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15588v3",
                "http://arxiv.org/pdf/2308.15588v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15568v5",
            "title": "Over-Squashing in Graph Neural Networks: A Comprehensive survey",
            "updated": "2023-11-28T11:03:06Z",
            "published": "2023-08-29T18:46:15Z",
            "summary": "Graph Neural Networks (GNNs) revolutionize machine learning for\ngraph-structured data, effectively capturing complex relationships. They\ndisseminate information through interconnected nodes, but long-range\ninteractions face challenges known as \"over-squashing\". This survey delves into\nthe challenge of over-squashing in Graph Neural Networks (GNNs), where\nlong-range information dissemination is hindered, impacting tasks reliant on\nintricate long-distance interactions. It comprehensively explores the causes,\nconsequences, and mitigation strategies for over-squashing. Various\nmethodologies are reviewed, including graph rewiring, novel normalization,\nspectral analysis, and curvature-based strategies, with a focus on their\ntrade-offs and effectiveness. The survey also discusses the interplay between\nover-squashing and other GNN limitations, such as over-smoothing, and provides\na taxonomy of models designed to address these issues in node and graph-level\ntasks. Benchmark datasets for performance evaluation are also detailed, making\nthis survey a valuable resource for researchers and practitioners in the GNN\nfield.",
            "author": [
                "Singh Akansha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15568v5",
                "http://arxiv.org/pdf/2308.15568v5"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15561v1",
            "title": "Toward Direct Numerical Simulation of Turbulent and Transitional Flow in\n  Hexagonal Subchannels for Helium Conditions",
            "updated": "2023-08-29T18:32:40Z",
            "published": "2023-08-29T18:32:40Z",
            "summary": "Understanding the coolant thermal hydraulics in rod bundles is essential to\nthe design of nuclear reactors. However, flows with low Reynolds numbers\npresent serious modeling challenges, especially in heat transfer and natural\nconvection. They are difficult to analyze through standard Computational Fluid\nDynamics (CFD) tools. High-fidelity simulations, such as Direct Numerical\nSimulations (DNS), can provide invaluable insight into flow physics, supporting\nexperiments in developing a deeper understanding and eventually enabling the\naccurate simulation of this class of flows. Data generated from these\nhigh-fidelity methods can then be used to benchmark available turbulence models\nand deliver cheap, faster running methods. In the present work, the convective\nheat transfer in hexagonal subchannels was studied through a DNS approach,\nusing the high-order spectral element method code Nek5000, developed at Argonne\nNational Laboratory. First, the geometric model composed of two hexagonal\narrayed rod bundle subchannels with a pitch-to-diameter ratio of 1.5 is built,\nand then, the mesh is generated. These unusually high P/D and low Reynolds\nnumbers represent conditions of interest for gas-fast reactors (GFRs). To our\nknowledge, there is no available dataset in these conditions. In this work, we\ndetailed the development of the numerical benchmark and a series of preliminary\nLES simulations. Periodic boundary conditions are applied in the streamwise and\nspanwise directions and non-slip boundary conditions at the wall. Four cases\nare studied, with Reynolds of Re=2500, 5000, 7500, and 10000. All calculations\nhave been performed with the Prandtl number of 0.61, corresponding to helium\nconditions of interest for Gas Fast Reactor applications. The results are\nanalyzed with a polynomial-order convergence study, and the Reynolds stresses,\nand the turbulent kinetic budgets are presented and discussed.",
            "author": [
                "Carolina Bourdot Dutra",
                "Elia Merzari"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15561v1",
                "http://arxiv.org/pdf/2308.15561v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15559v1",
            "title": "Glocal Explanations of Expected Goal Models in Soccer",
            "updated": "2023-08-29T18:29:56Z",
            "published": "2023-08-29T18:29:56Z",
            "summary": "The expected goal models have gained popularity, but their interpretability\nis often limited, especially when trained using black-box methods. Explainable\nartificial intelligence tools have emerged to enhance model transparency and\nextract descriptive knowledge for a single observation or for all observations.\nHowever, explaining black-box models for a specific group of observations may\nbe more useful in some domains. This paper introduces the glocal explanations\n(between local and global levels) of the expected goal models to enable\nperformance analysis at the team and player levels by proposing the use of\naggregated versions of the SHAP values and partial dependence profiles. This\nallows knowledge to be extracted from the expected goal model for a player or\nteam rather than just a single shot. In addition, we conducted real-data\napplications to illustrate the usefulness of aggregated SHAP and aggregated\nprofiles. The paper concludes with remarks on the potential of these\nexplanations for performance analysis in soccer analytics.",
            "author": [
                "Mustafa Cavus",
                "Adrian Stando",
                "Przemyslaw Biecek"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15559v1",
                "http://arxiv.org/pdf/2308.15559v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15546v1",
            "title": "FPT Approximation and Subexponential Algorithms for Covering Few or Many\n  Edges",
            "updated": "2023-08-29T18:11:03Z",
            "published": "2023-08-29T18:11:03Z",
            "summary": "We study the \\textsc{$\\alpha$-Fixed Cardinality Graph Partitioning\n($\\alpha$-FCGP)} problem, the generic local graph partitioning problem\nintroduced by Bonnet et al. [Algorithmica 2015]. In this problem, we are given\na graph $G$, two numbers $k,p$ and $0\\leq\\alpha\\leq 1$, the question is whether\nthere is a set $S\\subseteq V$ of size $k$ with a specified coverage function\n$cov_{\\alpha}(S)$ at least $p$ (or at most $p$ for the minimization version).\nThe coverage function $cov_{\\alpha}(\\cdot)$ counts edges with exactly one\nendpoint in $S$ with weight $\\alpha$ and edges with both endpoints in $S$ with\nweight $1 - \\alpha$. $\\alpha$-FCGP generalizes a number of fundamental graph\nproblems such as \\textsc{Densest $k$-Subgraph}, \\textsc{Max $k$-Vertex Cover},\nand \\textsc{Max $(k,n-k)$-Cut}.\n  A natural question in the study of $\\alpha$-FCGP is whether the algorithmic\nresults known for its special cases, like \\textsc{Max $k$-Vertex Cover}, could\nbe extended to more general settings. One of the simple but powerful methods\nfor obtaining parameterized approximation [Manurangsi, SOSA 2019] and\nsubexponential algorithms [Fomin et al. IPL 2011] for \\textsc{Max $k$-Vertex\nCover} is based on the greedy vertex degree orderings. The main insight of our\nwork is that the idea of greed vertex degree ordering could be used to design\nfixed-parameter approximation schemes (FPT-AS) for $\\alpha > 0$ and the\nsubexponential-time algorithms for the problem on apex-minor free graphs for\nmaximization with $\\alpha > 1/3$ and minimization with $\\alpha < 1/3$.",
            "author": [
                "Fedor V. Fomin",
                "Petr A. Golovach",
                "Tanmay Inamdar",
                "Tomohiro Koana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15546v1",
                "http://arxiv.org/pdf/2308.15546v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15539v2",
            "title": "Surpassing millisecond coherence times in on-chip superconducting\n  quantum memories by optimizing materials, processes, and circuit design",
            "updated": "2023-09-14T22:06:02Z",
            "published": "2023-08-29T18:01:08Z",
            "summary": "The performance of superconducting quantum circuits for quantum computing has\nadvanced tremendously in recent decades; however, a comprehensive understanding\nof relaxation mechanisms does not yet exist. In this work, we utilize a\nmultimode approach to characterizing energy losses in superconducting quantum\ncircuits, with the goals of predicting device performance and improving\ncoherence through materials, process, and circuit design optimization. Using\nthis approach, we measure significant reductions in surface and bulk dielectric\nlosses by employing a tantalum-based materials platform and annealed sapphire\nsubstrates. With this knowledge we predict and experimentally verify the\nrelaxation times of aluminum- and tantalum-based transmon qubits. We\nadditionally optimize device geometry to maximize coherence within a coaxial\ntunnel architecture, and realize on-chip quantum memories with single-photon\nRamsey times of 2.0$-$2.7 ms, limited by their energy relaxation times of\n1.0$-$1.4 ms. To our knowledge this is the highest coherence achieved in an\non-chip quantum memory, and demonstrates an advancement towards a more modular\nand compact coaxial circuit architecture for bosonic qubits with reproducibly\nhigh coherence.",
            "author": [
                "Suhas Ganjam",
                "Yanhao Wang",
                "Yao Lu",
                "Archan Banerjee",
                "Chan U Lei",
                "Lev Krayzman",
                "Kim Kisslinger",
                "Chenyu Zhou",
                "Ruoshui Li",
                "Yichen Jia",
                "Mingzhao Liu",
                "Luigi Frunzio",
                "Robert J. Schoelkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15539v2",
                "http://arxiv.org/pdf/2308.15539v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15473v1",
            "title": "Graph Theory and its Uses in Graph Algorithms and Beyond",
            "updated": "2023-08-29T17:51:51Z",
            "published": "2023-08-29T17:51:51Z",
            "summary": "Graphs are fundamental objects that find widespread applications across\ncomputer science and beyond. Graph Theory has yielded deep insights about\nstructural properties of various families of graphs, which are leveraged in the\ndesign and analysis of algorithms for graph optimization problems and other\ncomputational optimization problems. These insights have also proved helpful in\nunderstanding the limits of efficient computation by providing constructions of\nhard problem instances. At the same time, algorithmic tools and techniques\nprovide a fresh perspective on graph theoretic problems, often leading to novel\ndiscoveries. In this thesis, we exploit this symbiotic relationship between\ngraph theory and algorithms for graph optimization problems and beyond. This\nthesis consists of three parts.\n  In the first part, we study a graph routing problem called the Node-Disjoint\nPaths (NDP) problem. Given a graph and a set of source-destination pairs of its\nvertices, the goal is to route the maximum number of pairs via node-disjoint\npaths. We come close to resolving the approximability of NDP by showing that it\nis $n^{\\Omega(1/poly\\log\\log n)}$-hard to approximate, even on grid graphs,\nwhere n is the number of vertices. In the second part of this thesis, we use\ngraph decomposition techniques developed for efficient algorithms to derive a\ngraph theoretic result. We show that for every n-vertex expander graph G, if H\nis any graph with at most $O(n/\\log n)$ vertices and edges, then H is a minor\nof G. In the last part, we show that the graph theoretic tools and graph\nalgorithmic techniques can shed light on problems seemingly unrelated to\ngraphs. We show that the randomized space complexity of the Longest Increasing\nSubsequence (LIS) problem in the streaming model is intrinsically tied to the\nquery-complexity of the Non-Crossing Matching problem on graphs in a new model\nof computation that we define.",
            "author": [
                "Rachit Nimavat"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15473v1",
                "http://arxiv.org/pdf/2308.15473v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15464v1",
            "title": "A Comparative Study of Loss Functions: Traffic Predictions in Regular\n  and Congestion Scenarios",
            "updated": "2023-08-29T17:44:02Z",
            "published": "2023-08-29T17:44:02Z",
            "summary": "Spatiotemporal graph neural networks have achieved state-of-the-art\nperformance in traffic forecasting. However, they often struggle to forecast\ncongestion accurately due to the limitations of traditional loss functions.\nWhile accurate forecasting of regular traffic conditions is crucial, a reliable\nAI system must also accurately forecast congestion scenarios to maintain safe\nand efficient transportation. In this paper, we explore various loss functions\ninspired by heavy tail analysis and imbalanced classification problems to\naddress this issue. We evaluate the efficacy of these loss functions in\nforecasting traffic speed, with an emphasis on congestion scenarios. Through\nextensive experiments on real-world traffic datasets, we discovered that when\noptimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function stands\nout as the most effective. When optimizing Mean Squared Error (MSE), Gumbel\nLoss proves to be the superior choice. These choices effectively forecast\ntraffic congestion events without compromising the accuracy of regular traffic\nspeed forecasts. This research enhances deep learning models' capabilities in\nforecasting sudden speed changes due to congestion and underscores the need for\nmore research in this direction. By elevating the accuracy of congestion\nforecasting, we advocate for AI systems that are reliable, secure, and\nresilient in practical traffic management scenarios.",
            "author": [
                "Yangxinyu Xie",
                "Tanwi Mallick"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15464v1",
                "http://arxiv.org/pdf/2308.15464v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15458v1",
            "title": "Meta-learning for model-reference data-driven control",
            "updated": "2023-08-29T17:35:46Z",
            "published": "2023-08-29T17:35:46Z",
            "summary": "One-shot direct model-reference control design techniques, like the Virtual\nReference Feedback Tuning (VRFT) approach, offer time-saving solutions for the\ncalibration of fixed-structure controllers for dynamic systems. Nonetheless,\nsuch methods are known to be highly sensitive to the quality of the available\ndata, often requiring long and costly experiments to attain acceptable\nclosed-loop performance. These features might prevent the widespread adoption\nof such techniques, especially in low-data regimes. In this paper, we argue\nthat the inherent similarity of many industrially relevant systems may come at\nhand, offering additional information from plants that are similar (yet not\nequal) to the system one aims to control. Assuming that this supplementary\ninformation is available, we propose a novel, direct design approach that\nleverages the data from similar plants, the knowledge of controllers calibrated\non them, and the corresponding closed-loop performance to enhance\nmodel-reference control design. More specifically, by constructing the new\ncontroller as a combination of the available ones, our approach exploits all\nthe available priors following a meta-learning philosophy, while ensuring\nnon-decreasing performance. An extensive numerical analysis supports our\nclaims, highlighting the effectiveness of the proposed method in achieving\nperformance comparable to iterative approaches, while at the same time\nretaining the efficiency of one-shot direct data-driven methods like VRFT.",
            "author": [
                "Riccardo Busetto",
                "Valentina Breschi",
                "Simone Formentin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15458v1",
                "http://arxiv.org/pdf/2308.15458v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15444v1",
            "title": "On the hardness of inclusion-wise minimal separators enumeration",
            "updated": "2023-08-29T17:11:55Z",
            "published": "2023-08-29T17:11:55Z",
            "summary": "Enumeration problems are often encountered as key subroutines in the exact\ncomputation of graph parameters such as chromatic number, treewidth, or\ntreedepth. In the case of treedepth computation, the enumeration of\ninclusion-wise minimal separators plays a crucial role. However and quite\nsurprisingly, the complexity status of this problem has not been settled since\nit has been posed as an open direction by Kloks and Kratsch in 1998. Recently\nat the PACE 2020 competition dedicated to treedepth computation, solvers have\nbeen circumventing that by listing all minimal $a$-$b$ separators and filtering\nout those that are not inclusion-wise minimal, at the cost of efficiency.\nNaturally, having an efficient algorithm for listing inclusion-wise minimal\nseparators would drastically improve such practical algorithms. In this note,\nhowever, we show that no efficient algorithm is to be expected from an\noutput-sensitive perspective, namely, we prove that there is no\noutput-polynomial time algorithm for inclusion-wise minimal separators\nenumeration unless P = NP.",
            "author": [
                "Caroline Brosse",
                "Oscar Defrain",
                "Kazuhiro Kurita",
                "Vincent Limouzy",
                "Takeaki Uno",
                "Kunihiro Wasa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15444v1",
                "http://arxiv.org/pdf/2308.15444v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15517v1",
            "title": "Document AI: A Comparative Study of Transformer-Based, Graph-Based\n  Models, and Convolutional Neural Networks For Document Layout Analysis",
            "updated": "2023-08-29T16:58:03Z",
            "published": "2023-08-29T16:58:03Z",
            "summary": "Document AI aims to automatically analyze documents by leveraging natural\nlanguage processing and computer vision techniques. One of the major tasks of\nDocument AI is document layout analysis, which structures document pages by\ninterpreting the content and spatial relationships of layout, image, and text.\nThis task can be image-centric, wherein the aim is to identify and label\nvarious regions such as authors and paragraphs, or text-centric, where the\nfocus is on classifying individual words in a document. Although there are\nincreasingly sophisticated methods for improving layout analysis, doubts remain\nabout the extent to which their findings can be generalized to a broader\ncontext. Specifically, prior work developed systems based on very different\narchitectures, such as transformer-based, graph-based, and CNNs. However, no\nwork has mentioned the effectiveness of these models in a comparative analysis.\nMoreover, while language-independent Document AI models capable of knowledge\ntransfer have been developed, it remains to be investigated to what degree they\ncan effectively transfer knowledge. In this study, we aim to fill these gaps by\nconducting a comparative evaluation of state-of-the-art models in document\nlayout analysis and investigating the potential of cross-lingual layout\nanalysis by utilizing machine translation techniques.",
            "author": [
                "Sotirios Kastanas",
                "Shaomu Tan",
                "Yi He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15517v1",
                "http://arxiv.org/pdf/2308.15517v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15433v1",
            "title": "Continuum limit for interacting systems on adaptive networks",
            "updated": "2023-08-29T16:54:03Z",
            "published": "2023-08-29T16:54:03Z",
            "summary": "The article considers systems of interacting particles on networks with\nadaptively coupled dynamics. Such processes appear frequently in natural\nprocesses and applications. Relying on the notion of graph convergence, we\nprove that for large systems the dynamics can be approximated by the\ncorresponding continuum limit. Well-posedness of the latter is also\nestablished.",
            "author": [
                "Sebastian Throm"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15433v1",
                "http://arxiv.org/pdf/2308.15433v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15515v2",
            "title": "Finding Optimal 2-Packing Sets on Arbitrary Graphs at Scale",
            "updated": "2023-10-18T08:39:58Z",
            "published": "2023-08-29T16:45:30Z",
            "summary": "A 2-packing set for an undirected graph $G=(V,E)$ is a subset $\\mathcal{S}\n\\subset V$ such that any two vertices $v_1,v_2 \\in \\mathcal{S}$ have no common\nneighbors. Finding a 2-packing set of maximum cardinality is a NP-hard problem.\nWe develop a new approach to solve this problem on arbitrary graphs using its\nclose relation to the independent set problem. Thereby, our algorithm red2pack\nuses new data reduction rules specific to the 2-packing set problem as well as\na graph transformation. Our experiments show that we outperform the\nstate-of-the-art for arbitrary graphs with respect to solution quality and also\nare able to compute solutions multiple orders of magnitude faster than\npreviously possible. For example, we are able to solve 63% of our graphs to\noptimality in less than a second while the competitor for arbitrary graphs can\nonly solve 5% of the graphs in the data set to optimality even with a 10 hour\ntime limit. Moreover, our approach can solve a wide range of large instances\nthat have previously been unsolved.",
            "author": [
                "Jannick Borowitz",
                "Ernestine Gro\u00dfmann",
                "Christian Schulz",
                "Dominik Schweisgut"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15515v2",
                "http://arxiv.org/pdf/2308.15515v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15429v1",
            "title": "Only YOU Can Make IEEE VIS Environmentally Sustainable",
            "updated": "2023-08-29T16:43:43Z",
            "published": "2023-08-29T16:43:43Z",
            "summary": "The IEEE VIS Conference (or VIS) hosts more than 1000 people annually. It\nbrings together visualization researchers and practitioners from across the\nworld to share new research and knowledge. Behind the scenes, a team of\nvolunteers puts together the entire conference and makes sure it runs smoothly.\nOrganizing involves logistics of the conference, ensuring that the attendees\nhave an enjoyable time, allocating rooms to multiple concurrent tracks, and\nkeeping the conference within budget. In recent years, the COVID-19 pandemic\nhas abruptly disrupted plans, forcing organizers to switch to virtual, hybrid,\nand satellite formats. These alternatives offer many benefits: fewer costs\n(e.g., travel, venue, institutional), greater accessibility (who can physically\ntravel, who can get visas, who can get child care), and a lower carbon\nfootprint (as people do not need to fly to attend). As many conferences begin\nto revert to the pre-pandemic status quo of primarily in-person conferences, we\nsuggest that it is an opportune moment to reflect on the benefits and drawbacks\nof lower-carbon conference formats. To learn more about the logistics of\nconference organizing, we talked to 6 senior executive-level VIS organizers. We\nreview some of the many considerations that go into planning, particularly with\nregard to how they influence decisions about alternative formats. We aim to\nstart a discussion about the sustainability of VIS -- including sustainability\nfor finance, volunteers, and, central to this work, the environment -- for the\nnext three years and the next three hundred years.",
            "author": [
                "Elsie Lee-Robbins",
                "Andrew McNutt"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15429v1",
                "http://arxiv.org/pdf/2308.15429v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15416v2",
            "title": "The Parametrized Complexity of the Segment Number",
            "updated": "2023-09-01T06:35:15Z",
            "published": "2023-08-29T16:21:08Z",
            "summary": "Given a straight-line drawing of a graph, a {\\em segment} is a maximal set of\nedges that form a line segment. Given a planar graph $G$, the {\\em segment\nnumber} of $G$ is the minimum number of segments that can be achieved by any\nplanar straight-line drawing of $G$. The {\\em line cover number} of $G$ is the\nminimum number of lines that support all the edges of a planar straight-line\ndrawing of $G$. Computing the segment number or the line cover number of a\nplanar graph is $\\exists\\mathbb{R}$-complete and, thus, NP-hard.\n  We study the problem of computing the segment number from the perspective of\nparameterized complexity. We show that this problem is fixed-parameter\ntractable with respect to each of the following parameters: the vertex cover\nnumber, the segment number, and the line cover number. We also consider colored\nversions of the segment and the line cover number.",
            "author": [
                "Sabine Cornelsen",
                "Giordano Da Lozzo",
                "Luca Grilli",
                "Siddharth Gupta",
                "Jan Kratochv\u00edl",
                "Alexander Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15416v2",
                "http://arxiv.org/pdf/2308.15416v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15413v1",
            "title": "WrappingNet: Mesh Autoencoder via Deep Sphere Deformation",
            "updated": "2023-08-29T16:13:04Z",
            "published": "2023-08-29T16:13:04Z",
            "summary": "There have been recent efforts to learn more meaningful representations via\nfixed length codewords from mesh data, since a mesh serves as a complete model\nof underlying 3D shape compared to a point cloud. However, the mesh\nconnectivity presents new difficulties when constructing a deep learning\npipeline for meshes. Previous mesh unsupervised learning approaches typically\nassume category-specific templates, e.g., human face/body templates. It\nrestricts the learned latent codes to only be meaningful for objects in a\nspecific category, so the learned latent spaces are unable to be used across\ndifferent types of objects. In this work, we present WrappingNet, the first\nmesh autoencoder enabling general mesh unsupervised learning over heterogeneous\nobjects. It introduces a novel base graph in the bottleneck dedicated to\nrepresenting mesh connectivity, which is shown to facilitate learning a shared\nlatent space representing object shape. The superiority of WrappingNet mesh\nlearning is further demonstrated via improved reconstruction quality and\ncompetitive classification compared to point cloud learning, as well as latent\ninterpolation between meshes of different categories.",
            "author": [
                "Eric Lei",
                "Muhammad Asad Lodhi",
                "Jiahao Pang",
                "Junghyun Ahn",
                "Dong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15413v1",
                "http://arxiv.org/pdf/2308.15413v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15409v2",
            "title": "An Incremental SVD Method for Non-Fickian Flows in Porous Media:\n  Addressing Storage and Computational Challenges",
            "updated": "2023-08-30T01:24:27Z",
            "published": "2023-08-29T16:09:48Z",
            "summary": "It is well known that the numerical solution of the Non-Fickian flows at the\ncurrent stage depends on all previous time instances. Consequently, the storage\nrequirement increases linearly, while the computational complexity grows\nquadratically with the number of time steps. This presents a significant\nchallenge for numerical simulations, and to the best of our knowledge, it\nremains an unresolved issue. In this paper, we make the assumption that the\nsolution data exhibits approximate low rank. Here, we present a memory-free\nalgorithm, based on the incremental SVD technique, that exhibits only linear\ngrowth in computational complexity as the number of time steps increases. We\nprove that the error between the solutions generated by the conventional\nalgorithm and our innovative approach lies within the scope of machine error.\nNumerical experiments are showcased to affirm the accuracy and efficiency gains\nin terms of both memory usage and computational expenses.",
            "author": [
                "Gang Chen",
                "Yangwen Zhang",
                "Dujin Zuo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15409v2",
                "http://arxiv.org/pdf/2308.15409v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15406v2",
            "title": "On the existence of small strictly Neumaier graphs",
            "updated": "2023-10-26T13:26:46Z",
            "published": "2023-08-29T16:07:29Z",
            "summary": "A Neumaier graph is a non-complete edge-regular graph containing a regular\nclique. In this work, we prove several results on the existence of small\nstrictly Neumaier graphs. In particular, we present a theoretical proof of the\nuniqueness of the smallest Neumaier graphs with parameters $(16,9,4;2,4)$, we\nestablish the existence of $(25,12,5;2,5)$, and we disprove the existence of\nNeumaier graphs with parameters $(25,16,9;3,5)$, $(28,18,11;4,7)$,\n$(33,24,17;6,9)$, $(35,22,12;3,5)$ and $(55,34,18;3,5)$. Our proofs use\ncombinatorial techniques and a novel application of integer programming\nmethods.",
            "author": [
                "Aida Abiad",
                "Maarten De Boeck",
                "Sjanne Zeijlemaker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15406v2",
                "http://arxiv.org/pdf/2308.15406v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15386v1",
            "title": "Shape-Margin Knowledge Augmented Network for Thyroid Nodule Segmentation\n  and Diagnosis",
            "updated": "2023-08-29T15:29:06Z",
            "published": "2023-08-29T15:29:06Z",
            "summary": "Thyroid nodule segmentation is a crucial step in the diagnostic procedure of\nphysicians and computer-aided diagnosis systems. Mostly, current studies treat\nsegmentation and diagnosis as independent tasks without considering the\ncorrelation between these tasks. The sequence steps of these independent tasks\nin computer-aided diagnosis systems may lead to the accumulation of errors.\nTherefore, it is worth combining them as a whole through exploring the\nrelationship between thyroid nodule segmentation and diagnosis. According to\nthe thyroid imaging reporting and data system (TI-RADS), the assessment of\nshape and margin characteristics is the prerequisite for the discrimination of\nbenign and malignant thyroid nodules. These characteristics can be observed in\nthe thyroid nodule segmentation masks. Inspired by the diagnostic procedure of\nTI-RADS, this paper proposes a shape-margin knowledge augmented network\n(SkaNet) for simultaneously thyroid nodule segmentation and diagnosis. Due to\nthe similarity in visual features between segmentation and diagnosis, SkaNet\nshares visual features in the feature extraction stage and then utilizes a\ndual-branch architecture to perform thyroid nodule segmentation and diagnosis\ntasks simultaneously. To enhance effective discriminative features, an\nexponential mixture module is devised, which incorporates convolutional feature\nmaps and self-attention maps by exponential weighting. Then, SkaNet is jointly\noptimized by a knowledge augmented multi-task loss function with a constraint\npenalty term. It embeds shape and margin characteristics through numerical\ncomputation and models the relationship between the thyroid nodule diagnosis\nresults and segmentation masks.",
            "author": [
                "Weihua Liu",
                "Chaochao Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15386v1",
                "http://arxiv.org/pdf/2308.15386v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15366v3",
            "title": "AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language\n  Models",
            "updated": "2023-09-13T14:58:14Z",
            "published": "2023-08-29T15:02:53Z",
            "summary": "Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have\ndemonstrated the capability of understanding images and achieved remarkable\nperformance in various visual tasks. Despite their strong abilities in\nrecognizing common objects due to extensive training datasets, they lack\nspecific domain knowledge and have a weaker understanding of localized details\nwithin objects, which hinders their effectiveness in the Industrial Anomaly\nDetection (IAD) task. On the other hand, most existing IAD methods only provide\nanomaly scores and necessitate the manual setting of thresholds to distinguish\nbetween normal and abnormal samples, which restricts their practical\nimplementation. In this paper, we explore the utilization of LVLM to address\nthe IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM. We\ngenerate training data by simulating anomalous images and producing\ncorresponding textual descriptions for each image. We also employ an image\ndecoder to provide fine-grained semantic and design a prompt learner to\nfine-tune the LVLM using prompt embeddings. Our AnomalyGPT eliminates the need\nfor manual threshold adjustments, thus directly assesses the presence and\nlocations of anomalies. Additionally, AnomalyGPT supports multi-turn dialogues\nand exhibits impressive few-shot in-context learning capabilities. With only\none normal shot, AnomalyGPT achieves the state-of-the-art performance with an\naccuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3%\non the MVTec-AD dataset. Code is available at\nhttps://github.com/CASIA-IVA-Lab/AnomalyGPT.",
            "author": [
                "Zhaopeng Gu",
                "Bingke Zhu",
                "Guibo Zhu",
                "Yingying Chen",
                "Ming Tang",
                "Jinqiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15366v3",
                "http://arxiv.org/pdf/2308.15366v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15365v1",
            "title": "Flexible parametrization of graph-theoretical features from\n  individual-specific networks for prediction",
            "updated": "2023-08-29T15:02:23Z",
            "published": "2023-08-29T15:02:23Z",
            "summary": "Statistical techniques are needed to analyse data structures with complex\ndependencies such that clinically useful information can be extracted.\nIndividual-specific networks, which capture dependencies in complex biological\nsystems, are often summarized by graph-theoretical features. These features,\nwhich lend themselves to outcome modelling, can be subject to high variability\ndue to arbitrary decisions in network inference and noise. Correlation-based\nadjacency matrices often need to be sparsified before meaningful\ngraph-theoretical features can be extracted, requiring the data analysts to\ndetermine an optimal threshold.. To address this issue, we propose to\nincorporate a flexible weighting function over the full range of possible\nthresholds to capture the variability of graph-theoretical features over the\nthreshold domain. The potential of this approach, which extends concepts from\nfunctional data analysis to a graph-theoretical setting, is explored in a\nplasmode simulation study using real functional magnetic resonance imaging\n(fMRI) data from the Autism Brain Imaging Data Exchange (ABIDE) Preprocessed\ninitiative. The simulations show that our modelling approach yields accurate\nestimates of the functional form of the weight function, improves inference\nefficiency, and achieves a comparable or reduced root mean square prediction\nerror compared to competitor modelling approaches. This assertion holds true in\nsettings where both complex functional forms underlie the outcome-generating\nprocess and a universal threshold value is employed. We demonstrate the\npractical utility of our approach by using resting-state fMRI data to predict\nbiological age in children. Our study establishes the flexible modelling\napproach as a statistically principled, serious competitor to ad-hoc methods\nwith superior performance.",
            "author": [
                "Mariella Gregorich",
                "Sean L. Simpson",
                "Georg Heinze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15365v1",
                "http://arxiv.org/pdf/2308.15365v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15345v1",
            "title": "IndGIC: Supervised Action Recognition under Low Illumination",
            "updated": "2023-08-29T14:41:10Z",
            "published": "2023-08-29T14:41:10Z",
            "summary": "Technologies of human action recognition in the dark are gaining more and\nmore attention as huge demand in surveillance, motion control and\nhuman-computer interaction. However, because of limitation in image enhancement\nmethod and low-lighting video datasets, e.g. labeling cost, existing methods\nmeet some problems. Some video-based approached are effect and efficient in\nspecific datasets but cannot generalize to most cases while others methods\nusing multiple sensors rely heavily to prior knowledge to deal with noisy\nnature from video stream. In this paper, we proposes action recognition method\nusing deep multi-input network. Furthermore, we proposed a Independent Gamma\nIntensity Corretion (Ind-GIC) to enhance poor-illumination video, generating\none gamma for one frame to increase enhancement performance. To prove our\nmethod is effective, there is some evaluation and comparison between our method\nand existing methods. Experimental results show that our model achieves high\naccuracy in on ARID dataset.",
            "author": [
                "Jingbo Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15345v1",
                "http://arxiv.org/pdf/2308.15345v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15510v1",
            "title": "Improving homology-directed repair by small molecule agents for genetic\n  engineering in unconventional yeast? -- Learning from the engineering of\n  mammalian systems",
            "updated": "2023-08-29T14:26:13Z",
            "published": "2023-08-29T14:26:13Z",
            "summary": "The ability to precisely edit genomes by deleting or adding genetic\ninformation enables the study of biological functions and the building of\nefficient cell factories. In many unconventional yeasts, such as promising new\nhosts for cell factory design but also human pathogenic yeasts and food\nspoilers, this progress has been limited by the fact that most yeasts favor\nnon-homologous end joining (NHEJ) over homologous recombination (HR) as DNA\nrepair mechanism, impairing genetic access to these hosts. In mammalian cells,\nsmall molecules that either inhibit proteins involved in NHEJ, enhance protein\nfunction in HR, or molecules that arrest the cell cycle in HR-dominant phases\nare regarded as promising agents for the simple and transient increase of\nHR-mediated genome editing without the need for a priori host engineering. Only\na few of these chemicals have been applied to the engineering of yeast although\nthe targeted proteins are mostly conserved; making chemical agents a yet\nunderexplored area in enhancing yeast engineering. Here, we consolidate\nknowledge of available small molecules that have been used to improve HR\nefficiency in mammalian cells and the few ones that have been used in yeast. We\ninclude available high throughput (HTP)-compatible NHEJ/HR quantification\nassays that could be used to screen for and isolate yeast-specific inhibitors.",
            "author": [
                "Min Lu",
                "Sonja Billerbeck"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15510v1",
                "http://arxiv.org/pdf/2308.15510v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15326v2",
            "title": "Dynamical heterogeneity and universality of power-grids",
            "updated": "2023-09-13T15:50:56Z",
            "published": "2023-08-29T14:21:58Z",
            "summary": "While weak, tuned asymmetry can improve, strong heterogeneity destroys\nsynchronization in the electric power system. We study the level of\nheterogeneity, by comparing large high voltage (HV) power-grids of Europe and\nNorth America. We provide an analysis of power capacities and loads of various\nenergy sources from the databases and found heavy tailed distributions with\nsimilar characteristics. Graph topological measures, community structures also\nexhibit strong similarities, while the cable admittance distributions can be\nwell fitted with the same power-laws (PL), related to the length distributions.\nThe community detection analysis shows the level of synchronization in\ndifferent domains of the European HV power grids, by solving a set of swing\nequations. We provide numerical evidence for frustrated synchronization and\nChimera states and point out the relation of topology and level of\nsynchronization in the subsystems. We also provide empirical data analysis of\nthe frequency heterogeneities within the Hungarian HV network and find\nq-Gaussian distributions related to super-statistics of time-lagged\nfluctuations, which agree well with former results on the Nordic Grid.",
            "author": [
                "B\u00e1lint Hartmann",
                "G\u00e9za \u00d3dor",
                "Istv\u00e1n Papp",
                "Krist\u00f3f Benedek",
                "Shengfeng Deng",
                "Jeffrey Kelling"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15326v2",
                "http://arxiv.org/pdf/2308.15326v2"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cond-mat.stat-mech",
                "nlin.CD",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15324v1",
            "title": "FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt\n  Selection for Large Language Models",
            "updated": "2023-08-29T14:20:17Z",
            "published": "2023-08-29T14:20:17Z",
            "summary": "Leveraging ``chain-of-thought (CoT)'' reasoning to elicit rapid and precise\nresponses from large language models (LLMs) is rapidly attracting research\ninterest. A notable challenge here is how to design or select optimal prompts.\nThe process of prompt selection relies on trial and error, involving continuous\nadjustments and combinations of input prompts by users based on the\ncorresponding new responses generated from LLMs. Furthermore, minimal research\nhas been conducted to explore how LLMs employ the mathematical problem-solving\ncapabilities learned from user interactions to address issues in narrative\nwriting. To improve interpretability and explore the balance principle between\ngenerality and personalization under a multi-domain CoT prompt selection\nscenario, we propose the Federated Logic rule learning approach (FedLogic). We\nintroduce a theoretical formalization and interactive emulation of the\nmulti-domain CoT prompt selection dilemma in the context of federated LLMs. We\ncast the problem of joint probability modeling as a bilevel program, where the\nCoT prompt selection intricacy can be likened to a fuzzy score-based rule\nselection with the LLMs function as rule generators. FedLogic solves this\nproblem through variational expectation maximization (V-EM). In addition, we\nincorporate two KL-divergence constraints within this probabilistic modeling\nframework to surmount the intricacies of managing extensive search spaces and\naccomplishing cross-domain personalization of CoTs. To the best of our\nknowledge, FedLogic is the first interpretable and principled federated\nmulti-domain CoT prompt selection approach for LLMs.",
            "author": [
                "Pengwei Xing",
                "Songtao Lu",
                "Han Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15324v1",
                "http://arxiv.org/pdf/2308.15324v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15316v2",
            "title": "3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking",
            "updated": "2023-09-22T09:00:03Z",
            "published": "2023-08-29T14:02:27Z",
            "summary": "Markerless methods for animal posture tracking have been developing recently,\nbut frameworks and benchmarks for tracking large animal groups in 3D are still\nlacking. To overcome this gap in the literature, we present 3D-MuPPET, a\nframework to estimate and track 3D poses of up to 10 pigeons at interactive\nspeed using multiple-views. We train a pose estimator to infer 2D keypoints and\nbounding boxes of multiple pigeons, then triangulate the keypoints to 3D. For\ncorrespondence matching, we first dynamically match 2D detections to global\nidentities in the first frame, then use a 2D tracker to maintain\ncorrespondences accross views in subsequent frames. We achieve comparable\naccuracy to a state of the art 3D pose estimator for Root Mean Square Error\n(RMSE) and Percentage of Correct Keypoints (PCK). We also showcase a novel use\ncase where our model trained with data of single pigeons provides comparable\nresults on data containing multiple pigeons. This can simplify the domain shift\nto new species because annotating single animal data is less labour intensive\nthan multi-animal data. Additionally, we benchmark the inference speed of\n3D-MuPPET, with up to 10 fps in 2D and 1.5 fps in 3D, and perform quantitative\ntracking evaluation, which yields encouraging results. Finally, we show that\n3D-MuPPET also works in natural environments without model fine-tuning on\nadditional annotations. To the best of our knowledge we are the first to\npresent a framework for 2D/3D posture and trajectory tracking that works in\nboth indoor and outdoor environments.",
            "author": [
                "Urs Waldmann",
                "Alex Hoi Hang Chan",
                "Hemal Naik",
                "M\u00e1t\u00e9 Nagy",
                "Iain D. Couzin",
                "Oliver Deussen",
                "Bastian Goldluecke",
                "Fumihiro Kano"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15316v2",
                "http://arxiv.org/pdf/2308.15316v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15313v1",
            "title": "Spatio-temporal MLP-graph network for 3D human pose estimation",
            "updated": "2023-08-29T14:00:55Z",
            "published": "2023-08-29T14:00:55Z",
            "summary": "Graph convolutional networks and their variants have shown significant\npromise in 3D human pose estimation. Despite their success, most of these\nmethods only consider spatial correlations between body joints and do not take\ninto account temporal correlations, thereby limiting their ability to capture\nrelationships in the presence of occlusions and inherent ambiguity. To address\nthis potential weakness, we propose a spatio-temporal network architecture\ncomposed of a joint-mixing multi-layer perceptron block that facilitates\ncommunication among different joints and a graph weighted Jacobi network block\nthat enables communication among various feature channels. The major novelty of\nour approach lies in a new weighted Jacobi feature propagation rule obtained\nthrough graph filtering with implicit fairing. We leverage temporal information\nfrom the 2D pose sequences, and integrate weight modulation into the model to\nenable untangling of the feature transformations of distinct nodes. We also\nemploy adjacency modulation with the aim of learning meaningful correlations\nbeyond defined linkages between body joints by altering the graph topology\nthrough a learnable modulation matrix. Extensive experiments on two benchmark\ndatasets demonstrate the effectiveness of our model, outperforming recent\nstate-of-the-art methods for 3D human pose estimation.",
            "author": [
                "Tanvir Hassan",
                "A. Ben Hamza"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15313v1",
                "http://arxiv.org/pdf/2308.15313v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03212v1",
            "title": "Improving the State of the Art for Training Human-AI Teams: Technical\n  Report #2 -- Results of Researcher Knowledge Elicitation Survey",
            "updated": "2023-08-29T13:54:32Z",
            "published": "2023-08-29T13:54:32Z",
            "summary": "A consensus report produced for the Air Force Research Laboratory (AFRL) by\nthe National Academies of Sciences, Engineering, and Mathematics documented a\nprevalent and increasing desire to support human-Artificial Intelligence (AI)\nteaming across military service branches. Sonalysts has begun an internal\ninitiative to explore the training of Human-AI teams. The first step in this\neffort is to develop a Synthetic Task Environment (STE) that is capable of\nfacilitating research on Human-AI teams. Our goal is to create a STE that\noffers a task environment that could support the breadth of research that\nstakeholders plan to perform within this domain. As a result, we wanted to\nsample the priorities of the relevant research community broadly, and the\neffort documented in this report is our initial attempt to do so. We created a\nsurvey that featured two types of questions. The first asked respondents to\nreport their agreement with STE features that we anticipated might be\nimportant. The second represented open-ended questions that asked respondents\nto specify their priorities within several dimensions of the anticipated STE.\nThe research team invited nineteen researchers from academic and Government\nlabs to participate, and 11 were able to complete the survey. The team analyzed\ntheir responses to identify themes that emerged and topics that would benefit\nfrom further analysis. The most significant finding of the survey was that a\nnumber of researchers felt that various open-source STEs that would meet our\nneeds already exist. Researchers also emphasized the need for automated\ntranscription and coding tools to ease the burden of assessing inter-team\ncommunications; the importance of robust data capture and export capabilities;\nand the desirability of extensive flexibility across many aspects of the tool.",
            "author": [
                "James E. McCarthy",
                "Lillian Asiala",
                "LeeAnn Maryeski",
                "Dawn Sillars"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03212v1",
                "http://arxiv.org/pdf/2309.03212v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15308v1",
            "title": "On-Device Learning with Binary Neural Networks",
            "updated": "2023-08-29T13:48:35Z",
            "published": "2023-08-29T13:48:35Z",
            "summary": "Existing Continual Learning (CL) solutions only partially address the\nconstraints on power, memory and computation of the deep learning models when\ndeployed on low-power embedded CPUs. In this paper, we propose a CL solution\nthat embraces the recent advancements in CL field and the efficiency of the\nBinary Neural Networks (BNN), that use 1-bit for weights and activations to\nefficiently execute deep learning models. We propose a hybrid quantization of\nCWR* (an effective CL approach) that considers differently forward and backward\npass in order to retain more precision during gradient update step and at the\nsame time minimizing the latency overhead. The choice of a binary network as\nbackbone is essential to meet the constraints of low power devices and, to the\nbest of authors' knowledge, this is the first attempt to prove on-device\nlearning with BNN. The experimental validation carried out confirms the\nvalidity and the suitability of the proposed method.",
            "author": [
                "Lorenzo Vorabbi",
                "Davide Maltoni",
                "Stefano Santi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15308v1",
                "http://arxiv.org/pdf/2308.15308v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03211v1",
            "title": "Improving the State of the Art for Training Human-AI Teams: Technical\n  Report #1 -- Results of Subject-Matter Expert Knowledge Elicitation Survey",
            "updated": "2023-08-29T13:42:52Z",
            "published": "2023-08-29T13:42:52Z",
            "summary": "A consensus report produced for the Air Force Research Laboratory by the\nNational Academies of Sciences, Engineering, and Mathematics documented a\nprevalent and increasing desire to support human-Artificial Intelligence (AI)\nteaming across military service branches. Sonalysts has begun an internal\ninitiative to explore the training of human-AI teams. The first step in this\neffort is to develop a Synthetic Task Environment (STE) that is capable of\nfacilitating research on human-AI teams. We decided to use Joint All-Domain\nCommand and Control (JADC2) as a focus point for developing the STE because the\nvolume of sensor inputs and decision options within the JADC2 concept likely\nrequires the use of AI systems to enable timely decisions. Given this focus, we\nengaged a number of Subject-Matter Experts (SMEs) with Command and Control\nexperience to gain insight into developing a STE that embodied the teaming\nchallenges associated with JADC2. This report documents our initial engagement\nwith those stakeholders. The research team identified thirteen Sonalysts\nemployees with military backgrounds and Command and Control experience, and\ninvited them to participate. Twelve respondents completed the survey. The team\nthen analyzed the responses to identify themes that emerged and topics that\nwould benefit from further analysis. The results indicated that our SMEs were\namenable to research using tasks that were analogous to those encountered in\nmilitary environments, as long as they required teams to process a great deal\nof incoming data to arrive at complex decisions. The SMEs felt that the testbed\nshould support 'teams of teams\" that represented a matrixed organization, and\nthat it should support a robust array to spoken, text-based, and face-to-face\ncommunications.",
            "author": [
                "James E. McCarthy",
                "Lillian Asiala",
                "LeeAnn Maryeski",
                "Nyla Warren"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03211v1",
                "http://arxiv.org/pdf/2309.03211v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15305v1",
            "title": "Calligraphs and sphere realizations",
            "updated": "2023-08-29T13:41:55Z",
            "published": "2023-08-29T13:41:55Z",
            "summary": "We introduce a recursive procedure for computing the number of realizations\nof a minimally rigid graph on the sphere up to rotations. We accomplish this by\ncombining two ingredients. The first is a framework that allows us to think of\nsuch realizations as of elements of a moduli space of stable rational curves\nwith marked points. The second is the idea of splitting a minimally rigid graph\ninto two subgraphs, called calligraphs, that admit one degree of freedom and\nthat share only a single edge and a further vertex. This idea has been recently\nemployed for realizations of graphs in the plane up to isometries. The key\nresult is that we can associate to a calligraph a triple of natural numbers\nwith a special property: whenever a minimally rigid graph is split into two\ncalligraphs, the number of realizations of the former equals the product of the\ntwo triples of the latter, where this product is specified by a fixed quadratic\nform. These triples and quadratic form codify the fact that we express\nrealizations as intersections of two curves on the blowup of a sphere along two\npairs of complex conjugate points.",
            "author": [
                "Matteo Gallet",
                "Georg Grasegger",
                "Niels Lubbes",
                "Josef Schicho"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15305v1",
                "http://arxiv.org/pdf/2308.15305v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG",
                "52C25, 70B15, 14C17, 14H10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15507v1",
            "title": "unORANIC: Unsupervised Orthogonalization of Anatomy and\n  Image-Characteristic Features",
            "updated": "2023-08-29T13:37:13Z",
            "published": "2023-08-29T13:37:13Z",
            "summary": "We introduce unORANIC, an unsupervised approach that uses an adapted loss\nfunction to drive the orthogonalization of anatomy and image-characteristic\nfeatures. The method is versatile for diverse modalities and tasks, as it does\nnot require domain knowledge, paired data samples, or labels. During test time\nunORANIC is applied to potentially corrupted images, orthogonalizing their\nanatomy and characteristic components, to subsequently reconstruct\ncorruption-free images, showing their domain-invariant anatomy only. This\nfeature orthogonalization further improves generalization and robustness\nagainst corruptions. We confirm this qualitatively and quantitatively on 5\ndistinct datasets by assessing unORANIC's classification accuracy, corruption\ndetection and revision capabilities. Our approach shows promise for enhancing\nthe generalizability and robustness of practical applications in medical image\nanalysis. The source code is available at\nhttps://github.com/sdoerrich97/unORANIC.",
            "author": [
                "Sebastian Doerrich",
                "Francesco Di Salvo",
                "Christian Ledig"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15507v1",
                "http://arxiv.org/pdf/2308.15507v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15299v1",
            "title": "TaskLAMA: Probing the Complex Task Understanding of Language Models",
            "updated": "2023-08-29T13:36:45Z",
            "published": "2023-08-29T13:36:45Z",
            "summary": "Structured Complex Task Decomposition (SCTD) is the problem of breaking down\na complex real-world task (such as planning a wedding) into a directed acyclic\ngraph over individual steps that contribute to achieving the task, with edges\nspecifying temporal dependencies between them. SCTD is an important component\nof assistive planning tools, and a challenge for commonsense reasoning systems.\nWe probe how accurately SCTD can be done with the knowledge extracted from\nLarge Language Models (LLMs). We introduce a high-quality human-annotated\ndataset for this problem and novel metrics to fairly assess performance of LLMs\nagainst several baselines. Our experiments reveal that LLMs are able to\ndecompose complex tasks into individual steps effectively, with a relative\nimprovement of 15% to 280% over the best baseline. We also propose a number of\napproaches to further improve their performance, with a relative improvement of\n7% to 37% over the base model. However, we find that LLMs still struggle to\npredict pairwise temporal dependencies, which reveals a gap in their\nunderstanding of complex tasks.",
            "author": [
                "Quan Yuan",
                "Mehran Kazemi",
                "Xin Xu",
                "Isaac Noble",
                "Vaiva Imbrasaite",
                "Deepak Ramachandran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15299v1",
                "http://arxiv.org/pdf/2308.15299v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15298v1",
            "title": "KGConv, a Conversational Corpus grounded in Wikidata",
            "updated": "2023-08-29T13:35:51Z",
            "published": "2023-08-29T13:35:51Z",
            "summary": "We present KGConv, a large, conversational corpus of 71k conversations where\neach question-answer pair is grounded in a Wikidata fact. Conversations contain\non average 8.6 questions and for each Wikidata fact, we provide multiple\nvariants (12 on average) of the corresponding question using templates, human\nannotations, hand-crafted rules and a question rewriting neural model. We\nprovide baselines for the task of Knowledge-Based, Conversational Question\nGeneration. KGConv can further be used for other generation and analysis tasks\nsuch as single-turn question generation from Wikidata triples, question\nrewriting, question answering from conversation or from knowledge graphs and\nquiz generation.",
            "author": [
                "Quentin Brabant",
                "Gwenole Lecorve",
                "Lina M. Rojas-Barahona",
                "Claire Gardent"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15298v1",
                "http://arxiv.org/pdf/2308.15298v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15293v1",
            "title": "A Hybrid Membership Latent Distance Model for Unsigned and Signed\n  Integer Weighted Networks",
            "updated": "2023-08-29T13:30:48Z",
            "published": "2023-08-29T13:30:48Z",
            "summary": "Graph representation learning (GRL) has become a prominent tool for\nfurthering the understanding of complex networks providing tools for network\nembedding, link prediction, and node classification. In this paper, we propose\nthe Hybrid Membership-Latent Distance Model (HM-LDM) by exploring how a Latent\nDistance Model (LDM) can be constrained to a latent simplex. By controlling the\nedge lengths of the corners of the simplex, the volume of the latent space can\nbe systematically controlled. Thereby communities are revealed as the space\nbecomes more constrained, with hard memberships being recovered as the simplex\nvolume goes to zero. We further explore a recent likelihood formulation for\nsigned networks utilizing the Skellam distribution to account for signed\nweighted networks and extend the HM-LDM to the signed Hybrid Membership-Latent\nDistance Model (sHM-LDM). Importantly, the induced likelihood function\nexplicitly attracts nodes with positive links and deters nodes from having\nnegative interactions. We demonstrate the utility of HM-LDM and sHM-LDM on\nseveral real networks. We find that the procedures successfully identify\nprominent distinct structures, as well as how nodes relate to the extracted\naspects providing favorable performances in terms of link prediction when\ncompared to prominent baselines. Furthermore, the learned soft memberships\nenable easily interpretable network visualizations highlighting distinct\npatterns.",
            "author": [
                "Nikolaos Nakis",
                "Abdulkadir \u00c7elikkanat",
                "Morten M\u00f8rup"
            ],
            "link": [
                "http://dx.doi.org/10.1142/S0219525923400027",
                "http://arxiv.org/abs/2308.15293v1",
                "http://arxiv.org/pdf/2308.15293v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15283v2",
            "title": "Structural Node Embeddings with Homomorphism Counts",
            "updated": "2023-11-20T15:03:58Z",
            "published": "2023-08-29T13:14:53Z",
            "summary": "Graph homomorphism counts, first explored by Lov\\'asz in 1967, have recently\ngarnered interest as a powerful tool in graph-based machine learning. Grohe\n(PODS 2020) proposed the theoretical foundations for using homomorphism counts\nin machine learning on graph level as well as node level tasks. By their very\nnature, these capture local structural information, which enables the creation\nof robust structural embeddings. While a first approach for graph level tasks\nhas been made by Nguyen and Maehara (ICML 2020), we experimentally show the\neffectiveness of homomorphism count based node embeddings. Enriched with node\nlabels, node weights, and edge weights, these offer an interpretable\nrepresentation of graph data, allowing for enhanced explainability of machine\nlearning models.\n  We propose a theoretical framework for isomorphism-invariant homomorphism\ncount based embeddings which lend themselves to a wide variety of downstream\ntasks. Our approach capitalises on the efficient computability of graph\nhomomorphism counts for bounded treewidth graph classes, rendering it a\npractical solution for real-world applications. We demonstrate their\nexpressivity through experiments on benchmark datasets. Although our results do\nnot match the accuracy of state-of-the-art neural architectures, they are\ncomparable to other advanced graph learning models. Remarkably, our approach\ndemarcates itself by ensuring explainability for each individual feature. By\nintegrating interpretable machine learning algorithms like SVMs or Random\nForests, we establish a seamless, end-to-end explainable pipeline. Our study\ncontributes to the advancement of graph-based techniques that offer both\nperformance and interpretability.",
            "author": [
                "Hinrikus Wolf",
                "Luca Oeljeklaus",
                "Pascal K\u00fchner",
                "Martin Grohe"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15283v2",
                "http://arxiv.org/pdf/2308.15283v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15272v3",
            "title": "Empowering LLM to use Smartphone for Intelligent Task Automation",
            "updated": "2023-09-09T14:08:32Z",
            "published": "2023-08-29T13:02:30Z",
            "summary": "Mobile task automation is an attractive technique that aims to enable\nvoice-based hands-free user interaction with smartphones. However, existing\napproaches suffer from poor scalability due to the limited language\nunderstanding ability and the non-trivial manual efforts required from\ndevelopers or end-users. The recent advance of large language models (LLMs) in\nlanguage understanding and reasoning inspires us to rethink the problem from a\nmodel-centric perspective, where task preparation, comprehension, and execution\nare handled by a unified language model. In this work, we introduce AutoDroid,\na mobile task automation system that can handle arbitrary tasks on any Android\napplication without manual efforts. The key insight is to combine the\ncommonsense knowledge of LLMs and domain-specific knowledge of apps through\nautomated dynamic analysis. The main components include a functionality-aware\nUI representation method that bridges the UI with the LLM, exploration-based\nmemory injection techniques that augment the app-specific domain knowledge of\nLLM, and a multi-granularity query optimization module that reduces the cost of\nmodel inference. We integrate AutoDroid with off-the-shelf LLMs including\nonline GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a\nnew benchmark for memory-augmented Android task automation with 158 common\ntasks. The results demonstrated that AutoDroid is able to precisely generate\nactions with an accuracy of 90.9%, and complete tasks with a success rate of\n71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo,\nbenchmark suites, and source code of AutoDroid will be released at\nurl{https://autodroid-sys.github.io/}.",
            "author": [
                "Hao Wen",
                "Yuanchun Li",
                "Guohong Liu",
                "Shanhui Zhao",
                "Tao Yu",
                "Toby Jia-Jun Li",
                "Shiqi Jiang",
                "Yunhao Liu",
                "Yaqin Zhang",
                "Yunxin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15272v3",
                "http://arxiv.org/pdf/2308.15272v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15267v1",
            "title": "Trustless Privacy-Preserving Data Aggregation on Ethereum with Hypercube\n  Network Topology",
            "updated": "2023-08-29T12:51:26Z",
            "published": "2023-08-29T12:51:26Z",
            "summary": "The privacy-preserving data aggregation is a critical problem for many\napplications where multiple parties need to collaborate with each other\nprivately to arrive at certain results. Blockchain, as a database shared across\nthe network, provides an underlying platform on which such aggregations can be\ncarried out with a decentralized manner. Therefore, in this paper, we have\nproposed a scalable privacy-preserving data aggregation protocol for summation\non the Ethereum blockchain by integrating several cryptographic primitives\nincluding commitment scheme, asymmetric encryption and zero-knowledge proof\nalong with the hypercube network topology. The protocol consists of four stages\nas contract deployment, user registration, private submission and proof\nverification. The analysis of the protocol is made with respect to two main\nperspectives as security and scalability including computational,\ncommunicational and storage overheads. In the paper, the zero-knowledge proof,\nsmart contract and web user interface models for the protocol are provided. We\nhave performed an experimental study in order to identify the required gas\ncosts per individual and per system. The general formulation is provided to\ncharacterize the changes in gas costs for the increasing number of users. The\nzero-knowledge proof generation and verification times are also measured.",
            "author": [
                "Goshgar Ismayilov",
                "Can Ozturan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15267v1",
                "http://arxiv.org/pdf/2308.15267v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15263v1",
            "title": "Asymptotic Plateau problem via equidistant hyperplanes",
            "updated": "2023-08-29T12:43:07Z",
            "published": "2023-08-29T12:43:07Z",
            "summary": "We show the existence of a complete, strictly locally convex hypersurface\nwithin $\\mathbb{H}^{n+1}$ that adheres to a curvature equation applicable to a\nbroad range of curvature functions. This hypersurface possesses a prescribed\nasymptotic boundary at infinity and takes the form of a geodesic graph over a\nsmooth bounded domain $\\Omega$ at infinity. It is approximated by the shape of\ngeodesic graphs whose boundaries rest upon equidistant hyperplanes. Through\nthis procedure, we establish an alternative method for constructing solutions\nto the asymptotic Plateau problem. The resulting solutions may differ from the\nclassical ones, particularly in cases where uniqueness cannot be assured.",
            "author": [
                "Han Hong",
                "Haizhong Li",
                "Meng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15263v1",
                "http://arxiv.org/pdf/2308.15263v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15249v1",
            "title": "A pulsed optically pumped Rb clock with a frequency stability below\n  10-15",
            "updated": "2023-08-29T12:15:57Z",
            "published": "2023-08-29T12:15:57Z",
            "summary": "We present the frequency stability performances of a vapor cell Rb clock\nbased on the pulsed optically pumping (POP) technique. The clock has been\ndeveloped in the frame of a collaboration between INRIM and Leonardo SpA,\naiming to realize a space-qualified POP frequency standard. The results here\nreported were obtained with an engineered physics package, specifically\ndesigned for space applications, joint to laboratory-grade optics and\nelectronics. The measured frequency stability expressed in terms of Allan\ndeviation is $1.2 \\times 10^{-13}$ at 1 s and achieves the value of $6 \\times\n10^{-16}$ for integration times of 40000 s (drift removed). This is, to our\nknowledge, a record result for a vapor-cell frequency standard. In the paper,\nwe show that in order to get this result, a careful stabilization of microwave\nand laser pulses is required.",
            "author": [
                "Michele Gozzelino",
                "Salvatore Micalizio",
                "Claudio E. Calosso",
                "Jacopo Belfi",
                "Adalberto Sapia",
                "Marina Gioia",
                "Filippo Levi"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-39942-5",
                "http://arxiv.org/abs/2308.15249v1",
                "http://arxiv.org/pdf/2308.15249v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph",
                "physics.ins-det",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15248v1",
            "title": "On the chromatic number of some ($P_3\\cup P_2$)-free graphs",
            "updated": "2023-08-29T12:14:06Z",
            "published": "2023-08-29T12:14:06Z",
            "summary": "A hereditary class $\\cal G$ of graphs is {\\em $\\chi$-bounded} if there is a\n{\\em $\\chi$-binding function}, say $f$, such that $\\chi(G)\\le f(\\omega(G))$ for\nevery $G\\in\\cal G$, where $\\chi(G)(\\omega(G))$ denotes the chromatic (clique)\nnumber of $G$. It is known that for every $(P_3\\cup P_2)$-free graph $G$,\n$\\chi(G)\\le \\frac{1}{6}\\omega(G)(\\omega(G)+1)(\\omega(G)+2)$ \\cite{BA18}, and\nthe class of $(2K_2, 3K_1)$-free graphs does not admit a linear $\\chi$-binding\nfunction\\cite{BBS19}. In this paper, we prove that (\\romannumeral 1)\n$\\chi(G)\\le2\\omega(G)$ if $G$ is ($P_3\\cup P_2$, kite)-free, (\\romannumeral 2)\n$\\chi(G)\\le\\omega^2(G)$ if $G$ is ($P_3\\cup P_2$, hammer)-free, (\\romannumeral\n3) $\\chi(G)\\le\\frac{3\\omega^2(G)+\\omega(G)}{2}$ if $G$ is ($P_3\\cup P_2,\nC_5$)-free. Furthermore, we also discuss $\\chi$-binding functions for $(P_3\\cup\nP_2, K_4)$-free graphs.",
            "author": [
                "Rui Li",
                "Jinfeng Li",
                "Di Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15248v1",
                "http://arxiv.org/pdf/2308.15248v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15244v1",
            "title": "Knowledge-based Multiple Adaptive Spaces Fusion for Recommendation",
            "updated": "2023-08-29T12:11:16Z",
            "published": "2023-08-29T12:11:16Z",
            "summary": "Since Knowledge Graphs (KGs) contain rich semantic information, recently\nthere has been an influx of KG-enhanced recommendation methods. Most of\nexisting methods are entirely designed based on euclidean space without\nconsidering curvature. However, recent studies have revealed that a tremendous\ngraph-structured data exhibits highly non-euclidean properties. Motivated by\nthese observations, in this work, we propose a knowledge-based multiple\nadaptive spaces fusion method for recommendation, namely MCKG. Unlike existing\nmethods that solely adopt a specific manifold, we introduce the unified space\nthat is compatible with hyperbolic, euclidean and spherical spaces.\nFurthermore, we fuse the multiple unified spaces in an attention manner to\nobtain the high-quality embeddings for better knowledge propagation. In\naddition, we propose a geometry-aware optimization strategy which enables the\npull and push processes benefited from both hyperbolic and spherical spaces.\nSpecifically, in hyperbolic space, we set smaller margins in the area near to\nthe origin, which is conducive to distinguishing between highly similar\npositive items and negative ones. At the same time, we set larger margins in\nthe area far from the origin to ensure the model has sufficient error\ntolerance. The similar manner also applies to spherical spaces. Extensive\nexperiments on three real-world datasets demonstrate that the MCKG has a\nsignificant improvement over state-of-the-art recommendation methods. Further\nablation experiments verify the importance of multi-space fusion and\ngeometry-aware optimization strategy, justifying the rationality and\neffectiveness of MCKG.",
            "author": [
                "Meng Yuan",
                "Fuzhen Zhuang",
                "Zhao Zhang",
                "Deqing Wang",
                "Jin Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15244v1",
                "http://arxiv.org/pdf/2308.15244v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15242v1",
            "title": "Distance Labeling for Families of Cycles",
            "updated": "2023-08-29T12:06:48Z",
            "published": "2023-08-29T12:06:48Z",
            "summary": "For an arbitrary finite family of graphs, the distance labeling problem asks\nto assign labels to all nodes of every graph in the family in a way that allows\none to recover the distance between any two nodes of any graph from their\nlabels. The main goal is to minimize the number of unique labels used. We study\nthis problem for the families $\\mathcal{C}_n$ consisting of cycles of all\nlengths between 3 and $n$. We observe that the exact solution for directed\ncycles is straightforward and focus on the undirected case. We design a\nlabeling scheme requiring $\\frac{n\\sqrt{n}}{\\sqrt{6}}+O(n)$ labels, which is\nalmost twice less than is required by the earlier known scheme. Using the\ncomputer search, we find an optimal labeling for each $n\\le 17$, showing that\nour scheme gives the results that are very close to the optimum.",
            "author": [
                "Arseny M. Shur",
                "Mikhail Rubinchik"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15242v1",
                "http://arxiv.org/pdf/2308.15242v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DS",
                "68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15235v1",
            "title": "PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences",
            "updated": "2023-08-29T11:46:27Z",
            "published": "2023-08-29T11:46:27Z",
            "summary": "Flip through any book or listen to any song lyrics, and you will come across\npronouns that, in certain cases, can hinder meaning comprehension, especially\nfor machines. As the role of having cognitive machines becomes pervasive in our\nlives, numerous systems have been developed to resolve pronouns under various\nchallenges. Commensurate with this, it is believed that having systems able to\ndisambiguate pronouns in sentences will help towards the endowment of machines\nwith commonsense and reasoning abilities like those found in humans. However,\none problem these systems face with modern English is the lack of gender\npronouns, where people try to alternate by using masculine, feminine, or plural\nto avoid the whole issue. Since humanity aims to the building of systems in the\nfull-bodied sense we usually reserve for people, what happens when pronouns in\nwritten text, like plural or epicene ones, refer to unspecified entities whose\ngender is not necessarily known? Wouldn't that put extra barriers to existing\ncoreference resolution systems? Towards answering those questions, through the\nimplementation of a neural-symbolic system that utilizes the best of both\nworlds, we are employing PronounFlow, a system that reads any English sentence\nwith pronouns and entities, identifies which of them are not tied to each\nother, and makes suggestions on which to use to avoid biases. Undertaken\nexperiments show that PronounFlow not only alternates pronouns in sentences\nbased on the collective human knowledge around us but also considerably helps\ncoreference resolution systems with the pronoun disambiguation process.",
            "author": [
                "Nicos Isaak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15235v1",
                "http://arxiv.org/pdf/2308.15235v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.0; I.2.3; I.2.7; I.5.1; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15226v1",
            "title": "CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for\n  Multimodal Machine Translation",
            "updated": "2023-08-29T11:29:43Z",
            "published": "2023-08-29T11:29:43Z",
            "summary": "There has been a growing interest in developing multimodal machine\ntranslation (MMT) systems that enhance neural machine translation (NMT) with\nvisual knowledge. This problem setup involves using images as auxiliary\ninformation during training, and more recently, eliminating their use during\ninference. Towards this end, previous works face a challenge in training\npowerful MMT models from scratch due to the scarcity of annotated multilingual\nvision-language data, especially for low-resource languages. Simultaneously,\nthere has been an influx of multilingual pre-trained models for NMT and\nmultimodal pre-trained models for vision-language tasks, primarily in English,\nwhich have shown exceptional generalisation ability. However, these are not\ndirectly applicable to MMT since they do not provide aligned multimodal\nmultilingual features for generative tasks. To alleviate this issue, instead of\ndesigning complex modules for MMT, we propose CLIPTrans, which simply adapts\nthe independently pre-trained multimodal M-CLIP and the multilingual mBART. In\norder to align their embedding spaces, mBART is conditioned on the M-CLIP\nfeatures by a prefix sequence generated through a lightweight mapping network.\nWe train this in a two-stage pipeline which warms up the model with image\ncaptioning before the actual translation task. Through experiments, we\ndemonstrate the merits of this framework and consequently push forward the\nstate-of-the-art across standard benchmarks by an average of +2.67 BLEU. The\ncode can be found at www.github.com/devaansh100/CLIPTrans.",
            "author": [
                "Devaansh Gupta",
                "Siddhant Kharbanda",
                "Jiawei Zhou",
                "Wanhua Li",
                "Hanspeter Pfister",
                "Donglai Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15226v1",
                "http://arxiv.org/pdf/2308.15226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15502v1",
            "title": "On the Steganographic Capacity of Selected Learning Models",
            "updated": "2023-08-29T10:41:34Z",
            "published": "2023-08-29T10:41:34Z",
            "summary": "Machine learning and deep learning models are potential vectors for various\nattack scenarios. For example, previous research has shown that malware can be\nhidden in deep learning models. Hiding information in a learning model can be\nviewed as a form of steganography. In this research, we consider the general\nquestion of the steganographic capacity of learning models. Specifically, for a\nwide range of models, we determine the number of low-order bits of the trained\nparameters that can be overwritten, without adversely affecting model\nperformance. For each model considered, we graph the accuracy as a function of\nthe number of low-order bits that have been overwritten, and for selected\nmodels, we also analyze the steganographic capacity of individual layers. The\nmodels that we test include the classic machine learning techniques of Linear\nRegression (LR) and Support Vector Machine (SVM); the popular general deep\nlearning models of Multilayer Perceptron (MLP) and Convolutional Neural Network\n(CNN); the highly-successful Recurrent Neural Network (RNN) architecture of\nLong Short-Term Memory (LSTM); the pre-trained transfer learning-based models\nVGG16, DenseNet121, InceptionV3, and Xception; and, finally, an Auxiliary\nClassifier Generative Adversarial Network (ACGAN). In all cases, we find that a\nmajority of the bits of each trained parameter can be overwritten before the\naccuracy degrades. Of the models tested, the steganographic capacity ranges\nfrom 7.04 KB for our LR experiments, to 44.74 MB for InceptionV3. We discuss\nthe implications of our results and consider possible avenues for further\nresearch.",
            "author": [
                "Rishit Agrawal",
                "Kelvin Jou",
                "Tanush Obili",
                "Daksh Parikh",
                "Samarth Prajapati",
                "Yash Seth",
                "Charan Sridhar",
                "Nathan Zhang",
                "Mark Stamp"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15502v1",
                "http://arxiv.org/pdf/2308.15502v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15202v1",
            "title": "Benchmarking the Generation of Fact Checking Explanations",
            "updated": "2023-08-29T10:40:46Z",
            "published": "2023-08-29T10:40:46Z",
            "summary": "Fighting misinformation is a challenging, yet crucial, task. Despite the\ngrowing number of experts being involved in manual fact-checking, this activity\nis time-consuming and cannot keep up with the ever-increasing amount of Fake\nNews produced daily. Hence, automating this process is necessary to help curb\nmisinformation. Thus far, researchers have mainly focused on claim veracity\nclassification. In this paper, instead, we address the generation of\njustifications (textual explanation of why a claim is classified as either true\nor false) and benchmark it with novel datasets and advanced baselines. In\nparticular, we focus on summarization approaches over unstructured knowledge\n(i.e. news articles) and we experiment with several extractive and abstractive\nstrategies. We employed two datasets with different styles and structures, in\norder to assess the generalizability of our findings. Results show that in\njustification production summarization benefits from the claim information,\nand, in particular, that a claim-driven extractive step improves abstractive\nsummarization performances. Finally, we show that although cross-dataset\nexperiments suffer from performance degradation, a unique model trained on a\ncombination of the two datasets is able to retain style information in an\nefficient manner.",
            "author": [
                "Daniel Russo",
                "Serra Sinem Tekiroglu",
                "Marco Guerini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15202v1",
                "http://arxiv.org/pdf/2308.15202v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15191v1",
            "title": "State of the Art Report: Verified Computation",
            "updated": "2023-08-29T10:17:35Z",
            "published": "2023-08-29T10:17:35Z",
            "summary": "This report describes the state of the art in verifiable computation. The\nproblem being solved is the following:\n  The Verifiable Computation Problem (Verifiable Computing Problem) Suppose we\nhave two computing agents. The first agent is the verifier, and the second\nagent is the prover. The verifier wants the prover to perform a computation.\nThe verifier sends a description of the computation to the prover. Once the\nprover has completed the task, the prover returns the output to the verifier.\nThe output will contain proof. The verifier can use this proof to check if the\nprover computed the output correctly. The check is not required to verify the\nalgorithm used in the computation. Instead, it is a check that the prover\ncomputed the output using the computation specified by the verifier. The effort\nrequired for the check should be much less than that required to perform the\ncomputation.\n  This state-of-the-art report surveys 128 papers from the literature\ncomprising more than 4,000 pages. Other papers and books were surveyed but were\nomitted. The papers surveyed were overwhelmingly mathematical. We have\nsummarised the major concepts that form the foundations for verifiable\ncomputation. The report contains two main sections. The first, larger section\ncovers the theoretical foundations for probabilistically checkable and\nzero-knowledge proofs. The second section contains a description of the current\npractice in verifiable computation. Two further reports will cover (i) military\napplications of verifiable computation and (ii) a collection of technical\ndemonstrators. The first of these is intended to be read by those who want to\nknow what applications are enabled by the current state of the art in\nverifiable computation. The second is for those who want to see practical tools\nand conduct experiments themselves.",
            "author": [
                "Jim Woodcock",
                "Mikkel Schimdt Andersen",
                "Diego F. Aranha",
                "Stefan Hallerstede",
                "Simon Thrane Hansen",
                "Nikolaj Kuhne Jakobsen",
                "Tomas Kulik",
                "Peter Gorm Larsen",
                "Hugo Daniel Macedo",
                "Carlos Ignacio Isasa Martin",
                "Victor Alexander Mtsimbe Norrild"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15191v1",
                "http://arxiv.org/pdf/2308.15191v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15189v1",
            "title": "The extended Hausdorff dimension spectrum of a conformal iterated\n  function system is maximal",
            "updated": "2023-08-29T10:16:50Z",
            "published": "2023-08-29T10:16:50Z",
            "summary": "For any conformal iterated function system (CIFS) consisting of finitely or\ncountably many maps, and any closed shift-invariant set of right-infinite\nsequences of such maps, one can associate a limit set, which we call a\nshift-generated conformal iterated construction. We define the extended\nHausdorff dimension spectrum of a CIFS to be the set of Hausdorff dimensions of\nall such limit sets. We prove that for any CIFS with finitely or countably many\nmaps, the extended Hausdorff dimension spectrum is maximal, i.e. all\nnonnegative dimensions less than or equal to the dimension of the limit set of\nthe CIFS are realized. We also prove a version of this result even for\nso-called conformal graph directed Markov systems, obtained via\nnearest-neighbor restrictions on the CIFS. %when there are nearest-neighbor\nrestrictions on the CIFS (similar to those in the so-called conformal graph\ndirected Markov systems).\n  The main step of the proof is to show that for the family $(X_\\beta)$ of\nso-called $\\beta$-shifts, the Hausdorff dimension of the limit set associated\nto $X_\\beta$ varies continuously as a function of $\\beta$.",
            "author": [
                "Andrei E. Ghenciu",
                "Ronnie Pavlov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15189v1",
                "http://arxiv.org/pdf/2308.15189v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15169v1",
            "title": "Uncovering the Unseen: Discover Hidden Intentions by Micro-Behavior\n  Graph Reasoning",
            "updated": "2023-08-29T09:52:32Z",
            "published": "2023-08-29T09:52:32Z",
            "summary": "This paper introduces a new and challenging Hidden Intention Discovery (HID)\ntask. Unlike existing intention recognition tasks, which are based on obvious\nvisual representations to identify common intentions for normal behavior, HID\nfocuses on discovering hidden intentions when humans try to hide their\nintentions for abnormal behavior. HID presents a unique challenge in that\nhidden intentions lack the obvious visual representations to distinguish them\nfrom normal intentions. Fortunately, from a sociological and psychological\nperspective, we find that the difference between hidden and normal intentions\ncan be reasoned from multiple micro-behaviors, such as gaze, attention, and\nfacial expressions. Therefore, we first discover the relationship between\nmicro-behavior and hidden intentions and use graph structure to reason about\nhidden intentions. To facilitate research in the field of HID, we also\nconstructed a seminal dataset containing a hidden intention annotation of a\ntypical theft scenario for HID. Extensive experiments show that the proposed\nnetwork improves performance on the HID task by 9.9\\% over the state-of-the-art\nmethod SBP.",
            "author": [
                "Zhuo Zhou",
                "Wenxuan Liu",
                "Danni Xu",
                "Zheng Wang",
                "Jian Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15169v1",
                "http://arxiv.org/pdf/2308.15169v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15168v1",
            "title": "Ontologies in Digital Twins: A Systematic Literature Review",
            "updated": "2023-08-29T09:52:21Z",
            "published": "2023-08-29T09:52:21Z",
            "summary": "Digital Twins (DT) facilitate monitoring and reasoning processes in\ncyber-physical systems. They have progressively gained popularity over the past\nyears because of intense research activity and industrial advancements.\nCognitive Twins is a novel concept, recently coined to refer to the involvement\nof Semantic Web technology in DTs. Recent studies address the relevance of\nontologies and knowledge graphs in the context of DTs, in terms of knowledge\nrepresentation, interoperability and automatic reasoning. However, there is no\ncomprehensive analysis of how semantic technologies, and specifically\nontologies, are utilized within DTs. This Systematic Literature Review (SLR) is\nbased on the analysis of 82 research articles, that either propose or benefit\nfrom ontologies with respect to DT. The paper uses different analysis\nperspectives, including a structural analysis based on a reference DT\narchitecture, and an application-specific analysis to specifically address the\ndifferent domains, such as Manufacturing and Infrastructure. The review also\nidentifies open issues and possible research directions on the usage of\nontologies and knowledge graphs in DTs.",
            "author": [
                "Erkan Karabulut",
                "Salvatore F. Pileggi",
                "Paul Groth",
                "Victoria Degeler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15168v1",
                "http://arxiv.org/pdf/2308.15168v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15143v1",
            "title": "Lifelike Agility and Play on Quadrupedal Robots using Reinforcement\n  Learning and Generative Pre-trained Models",
            "updated": "2023-08-29T09:22:12Z",
            "published": "2023-08-29T09:22:12Z",
            "summary": "Summarizing knowledge from animals and human beings inspires robotic\ninnovations. In this work, we propose a framework for driving legged robots act\nlike real animals with lifelike agility and strategy in complex environments.\nInspired by large pre-trained models witnessed with impressive performance in\nlanguage and image understanding, we introduce the power of advanced deep\ngenerative models to produce motor control signals stimulating legged robots to\nact like real animals. Unlike conventional controllers and end-to-end RL\nmethods that are task-specific, we propose to pre-train generative models over\nanimal motion datasets to preserve expressive knowledge of animal behavior. The\npre-trained model holds sufficient primitive-level knowledge yet is\nenvironment-agnostic. It is then reused for a successive stage of learning to\nalign with the environments by traversing a number of challenging obstacles\nthat are rarely considered in previous approaches, including creeping through\nnarrow spaces, jumping over hurdles, freerunning over scattered blocks, etc.\nFinally, a task-specific controller is trained to solve complex downstream\ntasks by reusing the knowledge from previous stages. Enriching the knowledge\nregarding each stage does not affect the usage of other levels of knowledge.\nThis flexible framework offers the possibility of continual knowledge\naccumulation at different levels. We successfully apply the trained multi-level\ncontrollers to the MAX robot, a quadrupedal robot developed in-house, to mimic\nanimals, traverse complex obstacles, and play in a designed challenging\nmulti-agent Chase Tag Game, where lifelike agility and strategy emerge on the\nrobots. The present research pushes the frontier of robot control with new\ninsights on reusing multi-level pre-trained knowledge and solving highly\ncomplex downstream tasks in the real world.",
            "author": [
                "Lei Han",
                "Qingxu Zhu",
                "Jiapeng Sheng",
                "Chong Zhang",
                "Tingguang Li",
                "Yizheng Zhang",
                "He Zhang",
                "Yuzhen Liu",
                "Cheng Zhou",
                "Rui Zhao",
                "Jie Li",
                "Yufeng Zhang",
                "Rui Wang",
                "Wanchao Chi",
                "Xiong Li",
                "Yonghui Zhu",
                "Lingzhu Xiang",
                "Xiao Teng",
                "Zhengyou Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15143v1",
                "http://arxiv.org/pdf/2308.15143v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15139v1",
            "title": "PTTS: Zero-Knowledge Proof-based Private Token Transfer System on\n  Ethereum Blockchain and its Network Flow Based Balance Range Privacy Attack\n  Analysis",
            "updated": "2023-08-29T09:13:31Z",
            "published": "2023-08-29T09:13:31Z",
            "summary": "Blockchains are decentralized and immutable databases that are shared among\nthe nodes of the network. Although blockchains have attracted a great scale of\nattention in the recent years by disrupting the traditional financial systems,\nthe transaction privacy is still a challenging issue that needs to be addressed\nand analysed. We propose a Private Token Transfer System (PTTS) for the\nEthereum public blockchain in the first part of this paper. For the proposed\nframework, zero-knowledge based protocol has been designed using Zokrates and\nintegrated into our private token smart contract. With the help of web user\ninterface designed, the end users can interact with the smart contract without\nany third-party setup. In the second part of the paper, we provide security and\nprivacy analysis including the replay attack and the balance range privacy\nattack which has been modelled as a network flow problem. It is shown that in\ncase some balance ranges are deliberately leaked out to particular\norganizations or adversial entities, it is possible to extract meaningful\ninformation about the user balances by employing minimum cost flow network\nalgorithms that have polynomial complexity. The experimental study reports the\nEthereum gas consumption and proof generation times for the proposed framework.\nIt also reports network solution times and goodness rates for a subset of\naddresses under the balance range privacy attack with respect to number of\naddresses, number of transactions and ratio of leaked transfer transaction\namounts.",
            "author": [
                "Goshgar Ismayilov",
                "Can Ozturan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15139v1",
                "http://arxiv.org/pdf/2308.15139v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15138v1",
            "title": "Unraveling the Complexity of Metal Ion Dissolution: Insights from Hybrid\n  First-Principles/Continuum Calculations",
            "updated": "2023-08-29T09:13:29Z",
            "published": "2023-08-29T09:13:29Z",
            "summary": "The study of ion dissolution from metal surfaces has a long-standing history,\nwherein the gradual dissolution of solute atoms with increasing electrode\npotential, leading to their existence as ions in the electrolyte with integer\ncharges, is well-known. However, our present work reveals a more intricate and\nnuanced physical perspective based on comprehensive first-principles/continuum\ncalculations. We investigate the dissolution and deposition processes of 22\nmetal elements across a range of applied electrode potentials, unveiling\ndiverse dissolution models. By analyzing the energy profiles and valence states\nof solute atoms as a function of the distance between the solute atom and metal\nsurface, we identify three distinct dissolution models for different metals.\nFirstly, solute atoms exhibit an integer valence state following an\ninteger-valence jump, aligning with classical understandings. Secondly, solute\natoms attain an eventual integer valence, yet their valence state increases in\na non-integer manner during dissolution. Lastly, we observe solute atoms\nexhibiting a non-integer valence state, challenging classical understandings.\nFurthermore, we propose a theoretical criterion for determining the selection\nof ion valence during electrode dissolution under applied potential. These\nfindings not only contribute to a deeper understanding of the dissolution\nprocess but also offer valuable insights into the complex dynamics governing\nmetal ion dissolution at the atomic level. Such knowledge has the potential to\nadvance the design of more efficient electrochemical systems and open new\navenues for controlling dissolution processes in various applications.",
            "author": [
                "Mingqing Liu",
                "Tong-Yi Zhang",
                "Sheng Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15138v1",
                "http://arxiv.org/pdf/2308.15138v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15136v1",
            "title": "CAGRA: Highly Parallel Graph Construction and Approximate Nearest\n  Neighbor Search for GPUs",
            "updated": "2023-08-29T09:10:53Z",
            "published": "2023-08-29T09:10:53Z",
            "summary": "Approximate Nearest Neighbor Search (ANNS) plays a critical role in various\ndisciplines spanning data mining and artificial intelligence, from information\nretrieval and computer vision to natural language processing and recommender\nsystems. Data volumes have soared in recent years and the computational cost of\nan exhaustive exact nearest neighbor search is often prohibitive, necessitating\nthe adoption of approximate techniques. The balanced performance and recall of\ngraph-based approaches have more recently garnered significant attention in\nANNS algorithms, however, only a few studies have explored harnessing the power\nof GPUs and multi-core processors despite the widespread use of massively\nparallel and general-purpose computing. To bridge this gap, we introduce a\nnovel parallel computing hardware-based proximity graph and search algorithm.\nBy leveraging the high-performance capabilities of modern hardware, our\napproach achieves remarkable efficiency gains. In particular, our method\nsurpasses existing CPU and GPU-based methods in constructing the proximity\ngraph, demonstrating higher throughput in both large- and small-batch searches\nwhile maintaining compatible accuracy. In graph construction time, our method,\nCAGRA, is 2.2~27x faster than HNSW, which is one of the CPU SOTA\nimplementations. In large-batch query throughput in the 90% to 95% recall\nrange, our method is 33~77x faster than HNSW, and is 3.8~8.8x faster than the\nSOTA implementations for GPU. For a single query, our method is 3.4~53x faster\nthan HNSW at 95% recall.",
            "author": [
                "Hiroyuki Ootomo",
                "Akira Naruse",
                "Corey Nolet",
                "Ray Wang",
                "Tamas Feher",
                "Yong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15136v1",
                "http://arxiv.org/pdf/2308.15136v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CV",
                "cs.DB",
                "cs.DC",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15122v3",
            "title": "SpikeBERT: A Language Spikformer Learned from BERT with Knowledge\n  Distillation",
            "updated": "2023-10-07T10:08:43Z",
            "published": "2023-08-29T08:41:16Z",
            "summary": "Spiking neural networks (SNNs) offer a promising avenue to implement deep\nneural networks in a more energy-efficient way. However, the network\narchitectures of existing SNNs for language tasks are still simplistic and\nrelatively shallow, and deep architectures have not been fully explored,\nresulting in a significant performance gap compared to mainstream\ntransformer-based networks such as BERT. To this end, we improve a\nrecently-proposed spiking Transformer (i.e., Spikformer) to make it possible to\nprocess language tasks and propose a two-stage knowledge distillation method\nfor training it, which combines pre-training by distilling knowledge from BERT\nwith a large collection of unlabelled texts and fine-tuning with task-specific\ninstances via knowledge distillation again from the BERT fine-tuned on the same\ntraining examples. Through extensive experimentation, we show that the models\ntrained with our method, named SpikeBERT, outperform state-of-the-art SNNs and\neven achieve comparable results to BERTs on text classification tasks for both\nEnglish and Chinese with much less energy consumption. Our code is available at\nhttps://github.com/Lvchangze/SpikeBERT.",
            "author": [
                "Changze Lv",
                "Tianlong Li",
                "Jianhan Xu",
                "Chenxi Gu",
                "Zixuan Ling",
                "Cenyuan Zhang",
                "Xiaoqing Zheng",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15122v3",
                "http://arxiv.org/pdf/2308.15122v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15121v1",
            "title": "Diffusion rate in non-generic directions in the wind-tree model",
            "updated": "2023-08-29T08:40:02Z",
            "published": "2023-08-29T08:40:02Z",
            "summary": "We show that any real number in [0,1) is a diffusion rate for the wind-tree\nmodel with rational parameters. We will also provide a criterion in order to\ndescribe the shape of the Lyapunov spectrum of cocycles obtained as suspension\nof a representation. As an application, we exhibit an infinite family of\nwind-tree billiards for which the interior of the Lyapunov spectrum is a big as\npossible: this is the full square (0,1)^2. To the best of the knowledge of the\nauthors, these are the first complete descriptions where the interior of the\nLyapunov spectrum is known explicitly in dimension two, even for general\nFuchsian groups.",
            "author": [
                "Sylvain Crovisier",
                "Pascal Hubert",
                "Erwan Lanneau",
                "Angel Pardo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15121v1",
                "http://arxiv.org/pdf/2308.15121v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.GT",
                "37E05, 37D40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15114v1",
            "title": "2-Coupon Coloring of Cubic Graphs Containing 3-Cycle or 4-Cycle",
            "updated": "2023-08-29T08:27:38Z",
            "published": "2023-08-29T08:27:38Z",
            "summary": "Let $G$ be a graph. A total dominating set in a graph $G$ is a set $S$ of\nvertices of $G$ such that every vertex in $G$ is adjacent to a vertex in $S$.\nRecently, the following question was proposed: \"Is it true that every connected\ncubic graph containing a $3$-cycle has two vertex disjoint total dominating\nsets?\" In this paper, we give a negative answer to this question. Moreover, we\nprove that if we replace $3$-cycle with $4$-cycle the answer is affirmative.\nThis implies every connected cubic graph containing a diamond (the complete\ngraph of order $4$ minus one edge) as a subgraph can be partitioned into two\ntotal dominating sets, a result that was proved in 2017.",
            "author": [
                "S. Akbari",
                "M. Azimian",
                "A. Fazli Khani",
                "B. Samimi",
                "E. Zahiri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15114v1",
                "http://arxiv.org/pdf/2308.15114v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15107v1",
            "title": "Stochastic Graph Bandit Learning with Side-Observations",
            "updated": "2023-08-29T08:14:19Z",
            "published": "2023-08-29T08:14:19Z",
            "summary": "In this paper, we investigate the stochastic contextual bandit with general\nfunction space and graph feedback. We propose an algorithm that addresses this\nproblem by adapting to both the underlying graph structures and reward gaps. To\nthe best of our knowledge, our algorithm is the first to provide a\ngap-dependent upper bound in this stochastic setting, bridging the research gap\nleft by the work in [35]. In comparison to [31,33,35], our method offers\nimproved regret upper bounds and does not require knowledge of graphical\nquantities. We conduct numerical experiments to demonstrate the computational\nefficiency and effectiveness of our approach in terms of regret upper bounds.\nThese findings highlight the significance of our algorithm in advancing the\nfield of stochastic contextual bandits with graph feedback, opening up avenues\nfor practical applications in various domains.",
            "author": [
                "Xueping Gong",
                "Jiheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15107v1",
                "http://arxiv.org/pdf/2308.15107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15099v1",
            "title": "Probabilistic Dataset Reconstruction from Interpretable Models",
            "updated": "2023-08-29T08:10:09Z",
            "published": "2023-08-29T08:10:09Z",
            "summary": "Interpretability is often pointed out as a key requirement for trustworthy\nmachine learning. However, learning and releasing models that are inherently\ninterpretable leaks information regarding the underlying training data. As such\ndisclosure may directly conflict with privacy, a precise quantification of the\nprivacy impact of such breach is a fundamental problem. For instance, previous\nwork have shown that the structure of a decision tree can be leveraged to build\na probabilistic reconstruction of its training dataset, with the uncertainty of\nthe reconstruction being a relevant metric for the information leak. In this\npaper, we propose of a novel framework generalizing these probabilistic\nreconstructions in the sense that it can handle other forms of interpretable\nmodels and more generic types of knowledge. In addition, we demonstrate that\nunder realistic assumptions regarding the interpretable models' structure, the\nuncertainty of the reconstruction can be computed efficiently. Finally, we\nillustrate the applicability of our approach on both decision trees and rule\nlists, by comparing the theoretical information leak associated to either exact\nor heuristic learning algorithms. Our results suggest that optimal\ninterpretable models are often more compact and leak less information regarding\ntheir training data than greedily-built ones, for a given accuracy level.",
            "author": [
                "Julien Ferry",
                "Ulrich A\u00efvodji",
                "S\u00e9bastien Gambs",
                "Marie-Jos\u00e9 Huguet",
                "Mohamed Siala"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15099v1",
                "http://arxiv.org/pdf/2308.15099v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15096v1",
            "title": "How Faithful are Self-Explainable GNNs?",
            "updated": "2023-08-29T08:04:45Z",
            "published": "2023-08-29T08:04:45Z",
            "summary": "Self-explainable deep neural networks are a recent class of models that can\noutput ante-hoc local explanations that are faithful to the model's reasoning,\nand as such represent a step forward toward filling the gap between\nexpressiveness and interpretability. Self-explainable graph neural networks\n(GNNs) aim at achieving the same in the context of graph data. This begs the\nquestion: do these models fulfill their implicit guarantees in terms of\nfaithfulness? In this extended abstract, we analyze the faithfulness of several\nself-explainable GNNs using different measures of faithfulness, identify\nseveral limitations -- both in the models themselves and in the evaluation\nmetrics -- and outline possible ways forward.",
            "author": [
                "Marc Christiansen",
                "Lea Villadsen",
                "Zhiqiang Zhong",
                "Stefano Teso",
                "Davide Mottin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15096v1",
                "http://arxiv.org/pdf/2308.15096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15095v1",
            "title": "FedChain: An Efficient and Secure Consensus Protocol based on Proof of\n  Useful Federated Learning for Blockchain",
            "updated": "2023-08-29T08:04:07Z",
            "published": "2023-08-29T08:04:07Z",
            "summary": "Blockchain has become a popular decentralized paradigm for various\napplications in the zero-trust environment. The core of the blockchain is the\nconsensus protocol, which establishes consensus among all the participants. PoW\n(Proof-of-Work) is one of the most popular consensus protocols. However, the\nPoW consensus protocol which incentives the participants to use their computing\npower to solve a meaningless hash puzzle is continuously questioned as\nenergy-wasting. To address these issues, we propose an efficient and secure\nconsensus protocol based on proof of useful federated learning for blockchain\n(called FedChain). We first propose a secure and robust blockchain architecture\nthat takes federated learning tasks as proof of work. Then a pool aggregation\nmechanism is integrated to improve the efficiency of the FedChain architecture.\nTo protect model parameter privacy for each participant within a mining pool, a\nsecret sharing-based ring-all reduce architecture is designed. We also\nintroduce a data distribution-based federated learning model optimization\nalgorithm to improve the model performance of FedChain. At last, a\nzero-knowledge proof-based federated learning model verification is introduced\nto preserve the privacy of federated learning participants while proving the\nmodel performance of federated learning participants. Our approach has been\ntested and validated through extensive experiments, demonstrating its\nperformance.",
            "author": [
                "Peiran Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15095v1",
                "http://arxiv.org/pdf/2308.15095v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15080v1",
            "title": "A representation of a set of maps as a ribbon bipartite graph",
            "updated": "2023-08-29T07:29:03Z",
            "published": "2023-08-29T07:29:03Z",
            "summary": "In this purely experimental work we try to represent the set of plane maps\nwith 3 vertices and 3 faces as a bipartite ribbon graph. In particular, this\nconstruction allows one to estimate the genus of the initial set.",
            "author": [
                "Yury Kochetkov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15080v1",
                "http://arxiv.org/pdf/2308.15080v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.08612v1",
            "title": "Explaining Vision and Language through Graphs of Events in Space and\n  Time",
            "updated": "2023-08-29T07:25:06Z",
            "published": "2023-08-29T07:25:06Z",
            "summary": "Artificial Intelligence makes great advances today and starts to bridge the\ngap between vision and language. However, we are still far from understanding,\nexplaining and controlling explicitly the visual content from a linguistic\nperspective, because we still lack a common explainable representation between\nthe two domains. In this work we come to address this limitation and propose\nthe Graph of Events in Space and Time (GEST), by which we can represent, create\nand explain, both visual and linguistic stories. We provide a theoretical\njustification of our model and an experimental validation, which proves that\nGEST can bring a solid complementary value along powerful deep learning models.\nIn particular, GEST can help improve at the content-level the generation of\nvideos from text, by being easily incorporated into our novel video generation\nengine. Additionally, by using efficient graph matching techniques, the GEST\ngraphs can also improve the comparisons between texts at the semantic level.",
            "author": [
                "Mihai Masala",
                "Nicolae Cudlenco",
                "Traian Rebedea",
                "Marius Leordeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.08612v1",
                "http://arxiv.org/pdf/2309.08612v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15065v1",
            "title": "An Efficient Construction of Yao-Graph in Data-Distributed Settings",
            "updated": "2023-08-29T06:59:10Z",
            "published": "2023-08-29T06:59:10Z",
            "summary": "A sparse graph that preserves an approximation of the shortest paths between\nall pairs of points in a plane is called a geometric spanner. Using range trees\nof sublinear size, we design an algorithm in massively parallel computation\n(MPC) model for constructing a geometric spanner known as Yao-graph. This\nimproves the total time and the total memory of existing algorithms for\ngeometric spanners from subquadratic to near-linear.",
            "author": [
                "Sepideh Aghamolaei",
                "Mohammad Ghodsi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15065v1",
                "http://arxiv.org/pdf/2308.15065v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15060v1",
            "title": "Summary of the 4th International Workshop on Requirements Engineering\n  and Testing (RET 2017)",
            "updated": "2023-08-29T06:47:44Z",
            "published": "2023-08-29T06:47:44Z",
            "summary": "The RET (Requirements Engineering and Testing) workshop series provides a\nmeeting point for researchers and practitioners from the two separate fields of\nRequirements Engineering (RE) and Testing. The long term aim is to build a\ncommunity and a body of knowledge within the intersection of RE and Testing,\ni.e., RET. The 4th workshop was co-located with the 25th International\nRequirements Engineering Conference (RE'17) in Lisbon, Portugal and attracted\nabout 20 participants. In line with the previous workshop instances, RET 2017 o\nered an interactive setting with a keynote, an invited talk, paper\npresentations, and a concluding hands-on exercise.",
            "author": [
                "Markus Borg",
                "Elizabeth Bjarnason",
                "Michael Unterkalmsteiner",
                "Tingting Yu",
                "Gregory Gay",
                "Michael Felderer"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3149485.3149522",
                "http://arxiv.org/abs/2308.15060v1",
                "http://arxiv.org/pdf/2308.15060v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15047v1",
            "title": "Large language models converge toward human-like concept organization",
            "updated": "2023-08-29T06:09:47Z",
            "published": "2023-08-29T06:09:47Z",
            "summary": "Large language models show human-like performance in knowledge extraction,\nreasoning and dialogue, but it remains controversial whether this performance\nis best explained by memorization and pattern matching, or whether it reflects\nhuman-like inferential semantics and world knowledge. Knowledge bases such as\nWikiData provide large-scale, high-quality representations of inferential\nsemantics and world knowledge. We show that large language models learn to\norganize concepts in ways that are strikingly similar to how concepts are\norganized in such knowledge bases. Knowledge bases model collective,\ninstitutional knowledge, and large language models seem to induce such\nknowledge from raw text. We show that bigger and better models exhibit more\nhuman-like concept organization, across four families of language models and\nthree knowledge graph embeddings.",
            "author": [
                "Mathias Lykke Gammelgaard",
                "Jonathan Gabel Christiansen",
                "Anders S\u00f8gaard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15047v1",
                "http://arxiv.org/pdf/2308.15047v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15028v2",
            "title": "Entanglement Routing over Networks with Time Multiplexed Repeaters",
            "updated": "2023-11-15T16:57:32Z",
            "published": "2023-08-29T05:21:54Z",
            "summary": "Quantum networks will be able to service consumers with long distance\nentanglement by use of repeater nodes that can both generate external Bell\npairs with their neighbors, iid with probability $p$, as well as perform\ninternal Bell State Measurements (BSMs) which succeed with some probability\n$q$. The actual values of these probabilities is dependent upon the\nexperimental parameters of the network in question. While global link state\nknowledge is needed to maximize the rate of entanglement generation between any\ntwo consumers, this may be an unreasonable request due to the dynamic nature of\nthe network. This work evaluates a local link state knowledge, multi-path\nrouting protocol that works with time multiplexed repeaters that are able to\nperform BSMs across different time steps. This study shows that the average\nrate increases with the time multiplexing block length, $k$, although the\ninitial latency also increases. When a step function memory decoherence model\nis introduced so that qubits are held in the quantum memory for a time\nexponentially distributed with mean $\\mu$, an optimal $k$ ($k_\\text{opt}$)\nvalue appears. As $p$ decreases or $\\mu$ increases the value of $k_\\text{opt}$\nincreases. This value is such that the benefits from time multiplexing are\nbalanced with the increased risk of losing a previously established entangled\npair.",
            "author": [
                "Emily A Van Milligen",
                "Eliana Jacobson",
                "Ashlesha Patil",
                "Gayane Vardoyan",
                "Don Towsley",
                "Saikat Guha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15028v2",
                "http://arxiv.org/pdf/2308.15028v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15021v1",
            "title": "A general formula for the index of depth stability of edge ideals",
            "updated": "2023-08-29T04:57:08Z",
            "published": "2023-08-29T04:57:08Z",
            "summary": "By a classical result of Brodmann, the function $\\operatorname{depth} R/I^t$\nis asymptotically a constant, i.e. there is a number $s$ such that\n$\\operatorname{depth} R/I^t = \\operatorname{depth} R/I^s$ for $t > s$. One\ncalls the smallest number $s$ with this property the index of depth stability\nof $I$ and denotes it by $\\operatorname{dstab}(I)$. This invariant remains\nmysterious til now. The main result of this paper gives an explicit formula for\n$\\operatorname{dstab}(I)$ when $I$ is an arbitrary ideal generated by\nsquarefree monomials of degree 2. That is the first general case where one can\ncharacterize $\\operatorname{dstab}(I)$ explicitly. The formula expresses\n$\\operatorname{dstab}(I)$ in terms of the associated graph. The proof involves\nnew techniques which relate different topics such as simplicial complexes,\nsystems of linear inequalities, graph parallelizations, and ear decompositions.\nIt provides an effective method for the study of powers of edge ideals.",
            "author": [
                "Ha Minh Lam",
                "Ngo Viet Trung",
                "Tran Nam Trung"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15021v1",
                "http://arxiv.org/pdf/2308.15021v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO",
                "13C05, 13C15 (Primary) 05C70, 05E40 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15014v1",
            "title": "CAPS: A Practical Partition Index for Filtered Similarity Search",
            "updated": "2023-08-29T04:34:32Z",
            "published": "2023-08-29T04:34:32Z",
            "summary": "With the surging popularity of approximate near-neighbor search (ANNS),\ndriven by advances in neural representation learning, the ability to serve\nqueries accompanied by a set of constraints has become an area of intense\ninterest. While the community has recently proposed several algorithms for\nconstrained ANNS, almost all of these methods focus on integration with\ngraph-based indexes, the predominant class of algorithms achieving\nstate-of-the-art performance in latency-recall tradeoffs. In this work, we take\na different approach and focus on developing a constrained ANNS algorithm via\nspace partitioning as opposed to graphs. To that end, we introduce Constrained\nApproximate Partitioned Search (CAPS), an index for ANNS with filters via space\npartitions that not only retains the benefits of a partition-based algorithm\nbut also outperforms state-of-the-art graph-based constrained search techniques\nin recall-latency tradeoffs, with only 10% of the index size.",
            "author": [
                "Gaurav Gupta",
                "Jonah Yi",
                "Benjamin Coleman",
                "Chen Luo",
                "Vihan Lakshman",
                "Anshumali Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15014v1",
                "http://arxiv.org/pdf/2308.15014v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15010v1",
            "title": "TransPrompt v2: A Transferable Prompting Framework for Cross-task Text\n  Classification",
            "updated": "2023-08-29T04:16:57Z",
            "published": "2023-08-29T04:16:57Z",
            "summary": "Text classification is one of the most imperative tasks in natural language\nprocessing (NLP). Recent advances with pre-trained language models (PLMs) have\nshown remarkable success on this task. However, the satisfying results obtained\nby PLMs heavily depend on the large amounts of task-specific labeled data,\nwhich may not be feasible in many application scenarios due to data access and\nprivacy constraints. The recently-proposed prompt-based fine-tuning paradigm\nimproves the performance of PLMs for few-shot text classification with\ntask-specific templates. Yet, it is unclear how the prompting knowledge can be\ntransferred across tasks, for the purpose of mutual reinforcement. We propose\nTransPrompt v2, a novel transferable prompting framework for few-shot learning\nacross similar or distant text classification tasks. For learning across\nsimilar tasks, we employ a multi-task meta-knowledge acquisition (MMA)\nprocedure to train a meta-learner that captures the cross-task transferable\nknowledge. For learning across distant tasks, we further inject the task type\ndescriptions into the prompt, and capture the intra-type and inter-type prompt\nembeddings among multiple distant tasks. Additionally, two de-biasing\ntechniques are further designed to make the trained meta-learner more\ntask-agnostic and unbiased towards any tasks. After that, the meta-learner can\nbe adapted to each specific task with better parameters initialization.\nExtensive experiments show that TransPrompt v2 outperforms single-task and\ncross-task strong baselines over multiple NLP tasks and datasets. We further\nshow that the meta-learner can effectively improve the performance of PLMs on\npreviously unseen tasks. In addition, TransPrompt v2 also outperforms strong\nfine-tuning baselines when learning with full training sets.",
            "author": [
                "Jianing Wang",
                "Chengyu Wang",
                "Cen Chen",
                "Ming Gao",
                "Jun Huang",
                "Aoying Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15010v1",
                "http://arxiv.org/pdf/2308.15010v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15002v1",
            "title": "Exploring the Limits of Historical Information for Temporal Knowledge\n  Graph Extrapolation",
            "updated": "2023-08-29T03:26:38Z",
            "published": "2023-08-29T03:26:38Z",
            "summary": "Temporal knowledge graphs, representing the dynamic relationships and\ninteractions between entities over time, have been identified as a promising\napproach for event forecasting. However, a limitation of most temporal\nknowledge graph reasoning methods is their heavy reliance on the recurrence or\nperiodicity of events, which brings challenges to inferring future events\nrelated to entities that lack historical interaction. In fact, the current\nstate of affairs is often the result of a combination of historical information\nand underlying factors that are not directly observable. To this end, we\ninvestigate the limits of historical information for temporal knowledge graph\nextrapolation and propose a new event forecasting model called Contrastive\nEvent Network (CENET) based on a novel training framework of historical\ncontrastive learning. CENET learns both the historical and non-historical\ndependency to distinguish the most potential entities that best match the given\nquery. Simultaneously, by launching contrastive learning, it trains\nrepresentations of queries to probe whether the current moment is more\ndependent on historical or non-historical events. These representations further\nhelp train a binary classifier, whose output is a boolean mask, indicating the\nrelated entities in the search space. During the inference process, CENET\nemploys a mask-based strategy to generate the final results. We evaluate our\nproposed model on five benchmark graphs. The results demonstrate that CENET\nsignificantly outperforms all existing methods in most metrics, achieving at\nleast 8.3% relative improvement of Hits@1 over previous state-of-the-art\nbaselines on event-based datasets.",
            "author": [
                "Yi Xu",
                "Junjie Ou",
                "Hui Xu",
                "Luoyi Fu",
                "Lei Zhou",
                "Xinbing Wang",
                "Chenghu Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15002v1",
                "http://arxiv.org/pdf/2308.15002v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14981v1",
            "title": "Sub-universal variational circuits for combinatorial optimization\n  problems",
            "updated": "2023-08-29T02:16:48Z",
            "published": "2023-08-29T02:16:48Z",
            "summary": "Quantum variational circuits have gained significant attention due to their\napplications in the quantum approximate optimization algorithm and quantum\nmachine learning research. This work introduces a novel class of classical\nprobabilistic circuits designed for generating approximate solutions to\ncombinatorial optimization problems constructed using two-bit stochastic\nmatrices. Through a numerical study, we investigate the performance of our\nproposed variational circuits in solving the Max-Cut problem on various graphs\nof increasing sizes. Our classical algorithm demonstrates improved performance\nfor several graph types to the quantum approximate optimization algorithm. Our\nfindings suggest that evaluating the performance of quantum variational\ncircuits against variational circuits with sub-universal gate sets is a\nvaluable benchmark for identifying areas where quantum variational circuits can\nexcel.",
            "author": [
                "Gal Weitz",
                "Lirand\u00eb Pira",
                "Chris Ferrie",
                "Joshua Combes"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14981v1",
                "http://arxiv.org/pdf/2308.14981v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14971v1",
            "title": "Distributed multi-agent target search and tracking with Gaussian process\n  and reinforcement learning",
            "updated": "2023-08-29T01:53:14Z",
            "published": "2023-08-29T01:53:14Z",
            "summary": "Deploying multiple robots for target search and tracking has many practical\napplications, yet the challenge of planning over unknown or partially known\ntargets remains difficult to address. With recent advances in deep learning,\nintelligent control techniques such as reinforcement learning have enabled\nagents to learn autonomously from environment interactions with little to no\nprior knowledge. Such methods can address the exploration-exploitation tradeoff\nof planning over unknown targets in a data-driven manner, eliminating the\nreliance on heuristics typical of traditional approaches and streamlining the\ndecision-making pipeline with end-to-end training. In this paper, we propose a\nmulti-agent reinforcement learning technique with target map building based on\ndistributed Gaussian process. We leverage the distributed Gaussian process to\nencode belief over the target locations and efficiently plan over unknown\ntargets. We evaluate the performance and transferability of the trained policy\nin simulation and demonstrate the method on a swarm of micro unmanned aerial\nvehicles with hardware experiments.",
            "author": [
                "Jigang Kim",
                "Dohyun Jang",
                "H. Jin Kim"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s12555-022-0555-0",
                "http://arxiv.org/abs/2308.14971v1",
                "http://arxiv.org/pdf/2308.14971v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14968v1",
            "title": "Continual Learning for Generative Retrieval over Dynamic Corpora",
            "updated": "2023-08-29T01:46:06Z",
            "published": "2023-08-29T01:46:06Z",
            "summary": "Generative retrieval (GR) directly predicts the identifiers of relevant\ndocuments (i.e., docids) based on a parametric model. It has achieved solid\nperformance on many ad-hoc retrieval tasks. So far, these tasks have assumed a\nstatic document collection. In many practical scenarios, however, document\ncollections are dynamic, where new documents are continuously added to the\ncorpus. The ability to incrementally index new documents while preserving the\nability to answer queries with both previously and newly indexed relevant\ndocuments is vital to applying GR models. In this paper, we address this\npractical continual learning problem for GR. We put forward a novel\nContinual-LEarner for generatiVE Retrieval (CLEVER) model and make two major\ncontributions to continual learning for GR: (i) To encode new documents into\ndocids with low computational cost, we present Incremental Product\nQuantization, which updates a partial quantization codebook according to two\nadaptive thresholds; and (ii) To memorize new documents for querying without\nforgetting previous knowledge, we propose a memory-augmented learning\nmechanism, to form meaningful connections between old and new documents.\nEmpirical results demonstrate the effectiveness and efficiency of the proposed\nmodel.",
            "author": [
                "Jiangui Chen",
                "Ruqing Zhang",
                "Jiafeng Guo",
                "Maarten de Rijke",
                "Wei Chen",
                "Yixing Fan",
                "Xueqi Cheng"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614821",
                "http://arxiv.org/abs/2308.14968v1",
                "http://arxiv.org/pdf/2308.14968v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14954v2",
            "title": "Transitioning ECP Software Technology into a Foundation for Sustainable\n  Research Software",
            "updated": "2023-08-30T19:47:03Z",
            "published": "2023-08-29T01:03:12Z",
            "summary": "Research software plays a crucial role in advancing scientific knowledge, but\nensuring its sustainability, maintainability, and long-term viability is an\nongoing challenge. The Sustainable Research Software Institute (SRSI) Model has\nbeen designed to address the concerns, and presents a comprehensive framework\ndesigned to promote sustainable practices in the research software community.\nHowever the SRSI Model does not address the transitional requirements for the\nExascale Computing Project (ECP) Software Technology (ECP-ST) focus area\nspecifically. This white paper provides an overview and detailed description of\nhow ECP-ST will transition into the SRSI in a compressed time frame that a)\nmeets the needs of the ECP end-of-technical-activities deadline; and b) ensures\nthe continuity of the sustainability efforts that are already underway.",
            "author": [
                "Gregory R. Watson",
                "Addi Malviya-Thakur",
                "Daniel S. Katz",
                "Elaine M. Raybourn",
                "Bill Hoffman",
                "Dana Robinson",
                "John Kellerman",
                "Clark Roundy"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14954v2",
                "http://arxiv.org/pdf/2308.14954v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14953v2",
            "title": "An Open Community-Driven Model For Sustainable Research Software:\n  Sustainable Research Software Institute",
            "updated": "2023-08-30T19:45:32Z",
            "published": "2023-08-29T01:00:32Z",
            "summary": "Research software plays a crucial role in advancing scientific knowledge, but\nensuring its sustainability, maintainability, and long-term viability is an\nongoing challenge. To address these concerns, the Sustainable Research Software\nInstitute (SRSI) Model presents a comprehensive framework designed to promote\nsustainable practices in the research software community. This white paper\nprovides an in-depth overview of the SRSI Model, outlining its objectives,\nservices, funding mechanisms, collaborations, and the significant potential\nimpact it could have on the research software community. It explores the wide\nrange of services offered, diverse funding sources, extensive collaboration\nopportunities, and the transformative influence of the SRSI Model on the\nresearch software landscape",
            "author": [
                "Gregory R. Watson",
                "Addi Malviya-Thakur",
                "Daniel S. Katz",
                "Elaine M. Raybourn",
                "Bill Hoffman",
                "Dana Robinson",
                "John Kellerman",
                "Clark Roundy"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14953v2",
                "http://arxiv.org/pdf/2308.14953v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14949v1",
            "title": "Low-bit Quantization for Deep Graph Neural Networks with\n  Smoothness-aware Message Propagation",
            "updated": "2023-08-29T00:25:02Z",
            "published": "2023-08-29T00:25:02Z",
            "summary": "Graph Neural Network (GNN) training and inference involve significant\nchallenges of scalability with respect to both model sizes and number of\nlayers, resulting in degradation of efficiency and accuracy for large and deep\nGNNs. We present an end-to-end solution that aims to address these challenges\nfor efficient GNNs in resource constrained environments while avoiding the\noversmoothing problem in deep GNNs. We introduce a quantization based approach\nfor all stages of GNNs, from message passing in training to node\nclassification, compressing the model and enabling efficient processing. The\nproposed GNN quantizer learns quantization ranges and reduces the model size\nwith comparable accuracy even under low-bit quantization. To scale with the\nnumber of layers, we devise a message propagation mechanism in training that\ncontrols layer-wise changes of similarities between neighboring nodes. This\nobjective is incorporated into a Lagrangian function with constraints and a\ndifferential multiplier method is utilized to iteratively find optimal\nembeddings. This mitigates oversmoothing and suppresses the quantization error\nto a bound. Significant improvements are demonstrated over state-of-the-art\nquantization methods and deep GNN approaches in both full-precision and\nquantized models. The proposed quantizer demonstrates superior performance in\nINT2 configurations across all stages of GNN, achieving a notable level of\naccuracy. In contrast, existing quantization approaches fail to generate\nsatisfactory accuracy levels. Finally, the inference with INT2 and INT4\nrepresentations exhibits a speedup of 5.11 $\\times$ and 4.70 $\\times$ compared\nto full precision counterparts, respectively.",
            "author": [
                "Shuang Wang",
                "Bahaeddin Eravci",
                "Rustam Guliyev",
                "Hakan Ferhatosmanoglu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614955",
                "http://arxiv.org/abs/2308.14949v1",
                "http://arxiv.org/pdf/2308.14949v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T07",
                "I.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14941v1",
            "title": "Borel versions of the Local Lemma and LOCAL algorithms for graphs of\n  finite asymptotic separation index",
            "updated": "2023-08-28T23:39:57Z",
            "published": "2023-08-28T23:39:57Z",
            "summary": "Asymptotic separation index is a parameter that measures how easily a Borel\ngraph can be approximated by its subgraphs with finite components. In contrast\nto the more classical notion of hyperfiniteness, asymptotic separation index is\nwell-suited for combinatorial applications in the Borel setting. The main\nresult of this paper is a Borel version of the Lov\\'asz Local Lemma -- a\npowerful general-purpose tool in probabilistic combinatorics -- under a finite\nasymptotic separation index assumption. As a consequence, we show that locally\ncheckable labeling problems that are solvable by efficient randomized\ndistributed algorithms admit Borel solutions on bounded degree Borel graphs\nwith finite asymptotic separation index. From this we derive a number of\ncorollaries, for example a Borel version of Brooks's theorem for graphs with\nfinite asymptotic separation index.",
            "author": [
                "Anton Bernshteyn",
                "Felix Weilacher"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14941v1",
                "http://arxiv.org/pdf/2308.14941v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "cs.DC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14940v1",
            "title": "DoubleCheck: Designing Community-based Assessability for Historical\n  Person Identification",
            "updated": "2023-08-28T23:38:58Z",
            "published": "2023-08-28T23:38:58Z",
            "summary": "Historical photos are valuable for their cultural and economic significance,\nbut can be difficult to identify accurately due to various challenges such as\nlow-quality images, lack of corroborating evidence, and limited research\nresources. Misidentified photos can have significant negative consequences,\nincluding lost economic value, incorrect historical records, and the spread of\nmisinformation that can lead to perpetuating conspiracy theories. To accurately\nassess the credibility of a photo identification (ID), it may be necessary to\nconduct investigative research, use domain knowledge, and consult experts. In\nthis paper, we introduce DoubleCheck, a quality assessment framework for\nverifying historical photo IDs on Civil War Photo Sleuth (CWPS), a popular\nonline platform for identifying American Civil War-era photos using facial\nrecognition and crowdsourcing. DoubleCheck focuses on improving CWPS's user\nexperience and system architecture to display information useful for assessing\nthe quality of historical photo IDs on CWPS. In a mixed-methods evaluation of\nDoubleCheck, we found that users contributed a wide diversity of sources for\nphoto IDs, which helped facilitate the community's assessment of these IDs\nthrough DoubleCheck's provenance visualizations. Further, DoubleCheck's quality\nassessment badges and visualizations supported users in making accurate\nassessments of photo IDs, even in cases involving ID conflicts.",
            "author": [
                "Vikram Mohanty",
                "Kurt Luther"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3625303",
                "http://arxiv.org/abs/2308.14940v1",
                "http://arxiv.org/pdf/2308.14940v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14936v2",
            "title": "Auto-Prompting SAM for Mobile Friendly 3D Medical Image Segmentation",
            "updated": "2023-11-21T21:29:37Z",
            "published": "2023-08-28T23:23:53Z",
            "summary": "Segment Anything Model (SAM) has rapidly been adopted for segmenting a wide\nrange of natural images. However, recent studies have indicated that SAM\nexhibits subpar performance on 3D medical image segmentation tasks. In addition\nto the domain gaps between natural and medical images, disparities in the\nspatial arrangement between 2D and 3D images, the substantial computational\nburden imposed by powerful GPU servers, and the time-consuming manual prompt\ngeneration impede the extension of SAM to a broader spectrum of medical image\nsegmentation applications. To mitigate these challenges, we introduce a novel\nmethod, AutoSAM Adapter, designed specifically for 3D multi-organ CT-based\nsegmentation. This approach utilizes parameter-efficient adaptation techniques\nand an automatic prompt learning paradigm, transforming SAM's capabilities for\n3D medical image segmentation. It eliminates the need for manual prompts and\nachieves SOTA performance in CT-based multi-organ segmentation tasks.\nFurthermore, we successfully transfer the acquired knowledge of the AutoSAM\nAdapter to other lightweight models tailored for 3D medical image analysis with\nenhanced performance. Through extensive experiments, the AutoSAM Adapter has\nbeen demonstrated as an effective method to adapt the foundational SAM-based 2D\nnatural image segmentation model for 3D medical image segmentation tasks.",
            "author": [
                "Chengyin Li",
                "Prashant Khanduri",
                "Yao Qiang",
                "Rafi Ibn Sultan",
                "Indrin Chetty",
                "Dongxiao Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14936v2",
                "http://arxiv.org/pdf/2308.14936v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14920v1",
            "title": "Matbench Discovery -- An evaluation framework for machine learning\n  crystal stability prediction",
            "updated": "2023-08-28T22:29:57Z",
            "published": "2023-08-28T22:29:57Z",
            "summary": "Matbench Discovery simulates the deployment of machine learning (ML) energy\nmodels in a high-throughput search for stable inorganic crystals. We address\nthe disconnect between (i) thermodynamic stability and formation energy and\n(ii) in-domain vs out-of-distribution performance. Alongside this paper, we\npublish a Python package to aid with future model submissions and a growing\nonline leaderboard with further insights into trade-offs between various\nperformance metrics. To answer the question which ML methodology performs best\nat materials discovery, our initial release explores a variety of models\nincluding random forests, graph neural networks (GNN), one-shot predictors,\niterative Bayesian optimizers and universal interatomic potentials (UIP).\nRanked best-to-worst by their test set F1 score on thermodynamic stability\nprediction, we find CHGNet > M3GNet > MACE > ALIGNN > MEGNet > CGCNN > CGCNN+P\n> Wrenformer > BOWSR > Voronoi tessellation fingerprints with random forest.\nThe top 3 models are UIPs, the winning methodology for ML-guided materials\ndiscovery, achieving F1 scores of ~0.6 for crystal stability classification and\ndiscovery acceleration factors (DAF) of up to 5x on the first 10k most stable\npredictions compared to dummy selection from our test set. We also highlight a\nsharp disconnect between commonly used global regression metrics and more\ntask-relevant classification metrics. Accurate regressors are susceptible to\nunexpectedly high false-positive rates if those accurate predictions lie close\nto the decision boundary at 0 eV/atom above the convex hull where most\nmaterials are. Our results highlight the need to focus on classification\nmetrics that actually correlate with improved stability hit rate.",
            "author": [
                "Janosh Riebesell",
                "Rhys E. A. Goodall",
                "Anubhav Jain",
                "Philipp Benner",
                "Kristin A. Persson",
                "Alpha A. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14920v1",
                "http://arxiv.org/pdf/2308.14920v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14919v2",
            "title": "On Reward Structures of Markov Decision Processes",
            "updated": "2023-08-31T22:16:43Z",
            "published": "2023-08-28T22:29:16Z",
            "summary": "A Markov decision process can be parameterized by a transition kernel and a\nreward function. Both play essential roles in the study of reinforcement\nlearning as evidenced by their presence in the Bellman equations. In our\ninquiry of various kinds of \"costs\" associated with reinforcement learning\ninspired by the demands in robotic applications, rewards are central to\nunderstanding the structure of a Markov decision process and reward-centric\nnotions can elucidate important concepts in reinforcement learning.\n  Specifically, we study the sample complexity of policy evaluation and develop\na novel estimator with an instance-specific error bound of\n$\\tilde{O}(\\sqrt{\\frac{\\tau_s}{n}})$ for estimating a single state value. Under\nthe online regret minimization setting, we refine the transition-based MDP\nconstant, diameter, into a reward-based constant, maximum expected hitting\ncost, and with it, provide a theoretical explanation for how a well-known\ntechnique, potential-based reward shaping, could accelerate learning with\nexpert knowledge. In an attempt to study safe reinforcement learning, we model\nhazardous environments with irrecoverability and proposed a quantitative notion\nof safe learning via reset efficiency. In this setting, we modify a classic\nalgorithm to account for resets achieving promising preliminary numerical\nresults. Lastly, for MDPs with multiple reward functions, we develop a planning\nalgorithm that computationally efficiently finds Pareto-optimal stochastic\npolicies.",
            "author": [
                "Falcon Z. Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14919v2",
                "http://arxiv.org/pdf/2308.14919v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14916v1",
            "title": "RecRec: Algorithmic Recourse for Recommender Systems",
            "updated": "2023-08-28T22:26:50Z",
            "published": "2023-08-28T22:26:50Z",
            "summary": "Recommender systems play an essential role in the choices people make in\ndomains such as entertainment, shopping, food, news, employment, and education.\nThe machine learning models underlying these recommender systems are often\nenormously large and black-box in nature for users, content providers, and\nsystem developers alike. It is often crucial for all stakeholders to understand\nthe model's rationale behind making certain predictions and recommendations.\nThis is especially true for the content providers whose livelihoods depend on\nthe recommender system. Drawing motivation from the practitioners' need, in\nthis work, we propose a recourse framework for recommender systems, targeted\ntowards the content providers. Algorithmic recourse in the recommendation\nsetting is a set of actions that, if executed, would modify the recommendations\n(or ranking) of an item in the desired manner. A recourse suggests actions of\nthe form: \"if a feature changes X to Y, then the ranking of that item for a set\nof users will change to Z.\" Furthermore, we demonstrate that RecRec is highly\neffective in generating valid, sparse, and actionable recourses through an\nempirical evaluation of recommender systems trained on three real-world\ndatasets. To the best of our knowledge, this work is the first to conceptualize\nand empirically test a generalized framework for generating recourses for\nrecommender systems.",
            "author": [
                "Sahil Verma",
                "Ashudeep Singh",
                "Varich Boonsanong",
                "John P. Dickerson",
                "Chirag Shah"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615181",
                "http://arxiv.org/abs/2308.14916v1",
                "http://arxiv.org/pdf/2308.14916v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14903v1",
            "title": "MEMORY-VQ: Compression for Tractable Internet-Scale Memory",
            "updated": "2023-08-28T21:11:18Z",
            "published": "2023-08-28T21:11:18Z",
            "summary": "Retrieval augmentation is a powerful but expensive method to make language\nmodels more knowledgeable about the world. Memory-based methods like LUMEN\npre-compute token representations for retrieved passages to drastically speed\nup inference. However, memory also leads to much greater storage requirements\nfrom storing pre-computed representations.\n  We propose MEMORY-VQ, a new method to reduce storage requirements of\nmemory-augmented models without sacrificing performance. Our method uses a\nvector quantization variational autoencoder (VQ-VAE) to compress token\nrepresentations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a\nmemory model that achieves a 16x compression rate with comparable performance\non the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even\nfor extremely large retrieval corpora.",
            "author": [
                "Yury Zemlyanskiy",
                "Michiel de Jong",
                "Luke Vilnis",
                "Santiago Onta\u00f1\u00f3n",
                "William W. Cohen",
                "Sumit Sanghai",
                "Joshua Ainslie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14903v1",
                "http://arxiv.org/pdf/2308.14903v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14899v1",
            "title": "RobustCLEVR: A Benchmark and Framework for Evaluating Robustness in\n  Object-centric Learning",
            "updated": "2023-08-28T20:52:18Z",
            "published": "2023-08-28T20:52:18Z",
            "summary": "Object-centric representation learning offers the potential to overcome\nlimitations of image-level representations by explicitly parsing image scenes\ninto their constituent components. While image-level representations typically\nlack robustness to natural image corruptions, the robustness of object-centric\nmethods remains largely untested. To address this gap, we present the\nRobustCLEVR benchmark dataset and evaluation framework. Our framework takes a\nnovel approach to evaluating robustness by enabling the specification of causal\ndependencies in the image generation process grounded in expert knowledge and\ncapable of producing a wide range of image corruptions unattainable in existing\nrobustness evaluations. Using our framework, we define several causal models of\nthe image corruption process which explicitly encode assumptions about the\ncausal relationships and distributions of each corruption type. We generate\ndataset variants for each causal model on which we evaluate state-of-the-art\nobject-centric methods. Overall, we find that object-centric methods are not\ninherently robust to image corruptions. Our causal evaluation approach exposes\nmodel sensitivities not observed using conventional evaluation processes,\nyielding greater insight into robustness differences across algorithms. Lastly,\nwhile conventional robustness evaluations view corruptions as\nout-of-distribution, we use our causal framework to show that even training on\nin-distribution image corruptions does not guarantee increased model\nrobustness. This work provides a step towards more concrete and substantiated\nunderstanding of model performance and deterioration under complex corruption\nprocesses of the real-world.",
            "author": [
                "Nathan Drenkow",
                "Mathias Unberath"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14899v1",
                "http://arxiv.org/pdf/2308.14899v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14852v1",
            "title": "SynthDistill: Face Recognition with Knowledge Distillation from\n  Synthetic Data",
            "updated": "2023-08-28T19:15:27Z",
            "published": "2023-08-28T19:15:27Z",
            "summary": "State-of-the-art face recognition networks are often computationally\nexpensive and cannot be used for mobile applications. Training lightweight face\nrecognition models also requires large identity-labeled datasets. Meanwhile,\nthere are privacy and ethical concerns with collecting and using large face\nrecognition datasets. While generating synthetic datasets for training face\nrecognition models is an alternative option, it is challenging to generate\nsynthetic data with sufficient intra-class variations. In addition, there is\nstill a considerable gap between the performance of models trained on real and\nsynthetic data. In this paper, we propose a new framework (named SynthDistill)\nto train lightweight face recognition models by distilling the knowledge of a\npretrained teacher face recognition model using synthetic data. We use a\npretrained face generator network to generate synthetic face images and use the\nsynthesized images to learn a lightweight student network. We use synthetic\nface images without identity labels, mitigating the problems in the intra-class\nvariation generation of synthetic datasets. Instead, we propose a novel dynamic\nsampling strategy from the intermediate latent space of the face generator\nnetwork to include new variations of the challenging images while further\nexploring new face images in the training batch. The results on five different\nface recognition datasets demonstrate the superiority of our lightweight model\ncompared to models trained on previous synthetic datasets, achieving a\nverification accuracy of 99.52% on the LFW dataset with a lightweight network.\nThe results also show that our proposed framework significantly reduces the gap\nbetween training with real and synthetic data. The source code for replicating\nthe experiments is publicly released.",
            "author": [
                "Hatef Otroshi Shahreza",
                "Anjith George",
                "S\u00e9bastien Marcel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14852v1",
                "http://arxiv.org/pdf/2308.14852v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14841v1",
            "title": "Toward Optimized VR/AR Ergonomics: Modeling and Predicting User Neck\n  Muscle Contraction",
            "updated": "2023-08-28T18:58:01Z",
            "published": "2023-08-28T18:58:01Z",
            "summary": "Ergonomic efficiency is essential to the mass and prolonged adoption of VR/AR\nexperiences. While VR/AR head-mounted displays unlock users' natural wide-range\nhead movements during viewing, their neck muscle comfort is inevitably\ncompromised by the added hardware weight. Unfortunately, little quantitative\nknowledge for understanding and addressing such an issue is available so far.\n  Leveraging electromyography devices, we measure, model, and predict VR users'\nneck muscle contraction levels (MCL) while they move their heads to interact\nwith the virtual environment. Specifically, by learning from collected\nphysiological data, we develop a bio-physically inspired computational model to\npredict neck MCL under diverse head kinematic states. Beyond quantifying the\ncumulative MCL of completed head movements, our model can also predict\npotential MCL requirements with target head poses only. A series of objective\nevaluations and user studies demonstrate its prediction accuracy and\ngenerality, as well as its ability in reducing users' neck discomfort by\noptimizing the layout of visual targets. We hope this research will motivate\nnew ergonomic-centered designs for VR/AR and interactive graphics applications.\nSource code is released at:\nhttps://github.com/NYU-ICL/xr-ergonomics-neck-comfort.",
            "author": [
                "Yunxiang Zhang",
                "Kenneth Chen",
                "Qi Sun"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3588432.3591495",
                "http://arxiv.org/abs/2308.14841v1",
                "http://arxiv.org/pdf/2308.14841v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14834v1",
            "title": "Graph Analytics on Evolving Data (Abstract)",
            "updated": "2023-08-28T18:45:35Z",
            "published": "2023-08-28T18:45:35Z",
            "summary": "We consider the problem of graph analytics on evolving graphs. In this\nscenario, a query typically needs to be applied to different snapshots of the\ngraph over an extended time window. We propose CommonGraph, an approach for\nefficient processing of queries on evolving graphs. We first observe that edge\ndeletions are significantly more expensive than addition operations.\nCommonGraph converts all deletions to additions by finding a common graph that\nexists across all snapshots. After computing the query on this graph, to reach\nany snapshot, we simply need to add the missing edges and incrementally update\nthe query results. CommonGraph also allows sharing of common additions among\nsnapshots that require them, and breaks the sequential dependency inherent in\nthe traditional streaming approach where snapshots are processed in sequence,\nenabling additional opportunities for parallelism. We incorporate the\nCommonGraph approach by extending the KickStarter streaming framework.\nCommonGraph achieves 1.38x-8.17x improvement in performance over Kickstarter\nacross multiple benchmarks.",
            "author": [
                "Mahbod Afarin",
                "Chao Gao",
                "Shafiur Rahman",
                "Nael Abu-Ghazaleh",
                "Rajiv Gupta"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3597635.3598022",
                "http://arxiv.org/abs/2308.14834v1",
                "http://arxiv.org/pdf/2308.14834v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14831v2",
            "title": "Continual Learning with Dynamic Sparse Training: Exploring Algorithms\n  for Effective Model Updates",
            "updated": "2023-12-04T14:52:08Z",
            "published": "2023-08-28T18:31:09Z",
            "summary": "Continual learning (CL) refers to the ability of an intelligent system to\nsequentially acquire and retain knowledge from a stream of data with as little\ncomputational overhead as possible. To this end; regularization, replay,\narchitecture, and parameter isolation approaches were introduced to the\nliterature. Parameter isolation using a sparse network which enables to\nallocate distinct parts of the neural network to different tasks and also\nallows to share of parameters between tasks if they are similar. Dynamic Sparse\nTraining (DST) is a prominent way to find these sparse networks and isolate\nthem for each task. This paper is the first empirical study investigating the\neffect of different DST components under the CL paradigm to fill a critical\nresearch gap and shed light on the optimal configuration of DST for CL if it\nexists. Therefore, we perform a comprehensive study in which we investigate\nvarious DST components to find the best topology per task on well-known\nCIFAR100 and miniImageNet benchmarks in a task-incremental CL setup since our\nprimary focus is to evaluate the performance of various DST criteria, rather\nthan the process of mask selection. We found that, at a low sparsity level,\nErdos-R\\'enyi Kernel (ERK) initialization utilizes the backbone more\nefficiently and allows to effectively learn increments of tasks. At a high\nsparsity level, unless it is extreme, uniform initialization demonstrates a\nmore reliable and robust performance. In terms of growth strategy; performance\nis dependent on the defined initialization strategy and the extent of sparsity.\nFinally, adaptivity within DST components is a promising way for better\ncontinual learners.",
            "author": [
                "Murat Onur Yildirim",
                "Elif Ceren Gok Yildirim",
                "Ghada Sokar",
                "Decebal Constantin Mocanu",
                "Joaquin Vanschoren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14831v2",
                "http://arxiv.org/pdf/2308.14831v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14802v1",
            "title": "Nonanalyticity and On-Shell Factorization of Inflation Correlators at\n  All Loop Orders",
            "updated": "2023-08-28T18:00:05Z",
            "published": "2023-08-28T18:00:05Z",
            "summary": "The dynamics of quantum fields during cosmic inflation can be probed via\ntheir late-time boundary correlators. The analytic structure of these boundary\ncorrelators contains rich physical information of bulk dynamics, and is also\nclosely related to cosmological collider observables. In this work, we study a\nparticular type of nonanalytic behavior, called nonlocal signals, for inflation\ncorrelators with massive exchanges at arbitrary loop orders. We propose a\nsignal-detection algorithm to identify all possible sources of nonlocal signals\nin an arbitrary loop graph, and prove that the algorithm is exhaustive. We then\npresent several versions of the on-shell factorization theorem for the leading\nnonlocal signal in graphs with arbitrary number of loops, and provide the\nexplicit analytical expression for the leading nonlocal signal. We also\ngeneralize the nonlocal-signal cutting rule to arbitrary loop graphs. Finally,\nwe provide many explicit examples to demonstrate the use of our results,\nincluding an n-loop melon graph and a variety of 2-loop graphs.",
            "author": [
                "Zhehan Qin",
                "Zhong-Zhi Xianyu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14802v1",
                "http://arxiv.org/pdf/2308.14802v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "astro-ph.CO",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14750v1",
            "title": "Ultrahigh Photoresponsivity of Gold Nanodisk Array/CVD MoS$_2$-based\n  Hybrid Phototransistor",
            "updated": "2023-08-28T17:57:32Z",
            "published": "2023-08-28T17:57:32Z",
            "summary": "Owing to its atomically thin thickness, layer-dependent tunable band gap,\nflexibility, and CMOS compatibility, MoS$_2$ is a promising candidate for\nphotodetection. However, mono-layer MoS2-based photodetectors typically show\npoor optoelectronic performances, mainly limited by their low optical\nabsorption. In this work, we hybridized CVD-grown monolayer MoS$_2$ with a gold\nnanodisk (AuND) array to demonstrate a superior visible photodetector through a\nsynergetic effect. It is evident from our experimental results that there is a\nstrong light-matter interaction between AuNDs and monolayer MoS$_2$, which\nresults in better photodetection due to a surface trap state passivation with a\nlonger charge carrier lifetime compared to pristine MoS$_2$. In particular, the\nAuND/MoS$_2$ system demonstrated a photoresponsivity of $8.7 \\times 10^{4}$\nA/W, specific detectivity of $6.9 \\times 10^{13}$ Jones, and gain $1.7 \\times\n10^{5}$ at $31.84 \\mu W/cm^{2}$ illumination power density of 632 nm wavelength\nwith an applied voltage of 4.0 V for an AuND/MoS$_2$-based photodetector. To\nour knowledge, these optoelectronic responses are one order higher than\nreported results for CVD MoS$_2$-based photodetector in the literature.",
            "author": [
                "Shyam Narayan Singh Yadav",
                "Po-Liang Chen",
                "Yu-Chi Yao",
                "Yen-Yu Wang",
                "Der-Hsien Lien",
                "Yu-Jung Lu",
                "Ya-Ping Hsieh",
                "Chang-Hua Liu",
                "Ta-Jen Yen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14750v1",
                "http://arxiv.org/pdf/2308.14750v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14747v1",
            "title": "Enhanced quantum transport in chiral quantum walks",
            "updated": "2023-08-28T17:56:15Z",
            "published": "2023-08-28T17:56:15Z",
            "summary": "Quantum transport across discrete structures is a relevant topic of solid\nstate physics and quantum information science, which can be suitably studied in\nthe context of continuous-time quantum walks. The addition of phases degrees of\nfreedom, leading to chiral quantum walks, can also account for directional\ntransport on graphs with loops. We discuss criteria for quantum transport and\nstudy the enhancement that can be achieved with chiral quantum walks on\nchain-like graphs, exploring different topologies for the chain units and\noptimizing over the phases. We select three candidate structures with optimal\nperformance and investigate their transport behaviour with Krylov reduction.\nWhile one of them can be reduced to a weighted line with minor couplings\nmodulation, the other two are truly chiral quantum walks, with enhanced\ntransport probability over long chain structures.",
            "author": [
                "Emilio Annoni",
                "Massimo Frigerio",
                "Matteo G. A. Paris"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14747v1",
                "http://arxiv.org/pdf/2308.14747v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14731v1",
            "title": "Distilled GPT for Source Code Summarization",
            "updated": "2023-08-28T17:34:07Z",
            "published": "2023-08-28T17:34:07Z",
            "summary": "A code summary is a brief natural language description of source code.\nSummaries are usually only a single sentence long, and yet form the backbone of\ndeveloper documentation. A short descriptions such as \"changes all visible\npolygons to the color blue\" can give a programmer a high-level idea of what\ncode does without the effort of reading the code itself. Recently, products\nbased on Large Language Models such as ChatGPT have demonstrated a strong\nability to write these descriptions automatically. However, to use these tools,\nprogrammers must send their code to untrusted third parties for processing\n(e.g., via an API call). This loss of custody is not acceptable to many\norganizations. In this paper, we present an alternative: we train an open\nsource model using sample output generated by GPT-3.5 in a process related to\nknowledge distillation. Our model is small enough (350m parameters) to be run\non a single 16gb GPU, yet we show in our evaluation that it is large enough to\nmimic GPT-3.5 on this task.",
            "author": [
                "Chia-Yi Su",
                "Collin McMillan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14731v1",
                "http://arxiv.org/pdf/2308.14731v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14727v1",
            "title": "Faster Min-Cost Flow on Bounded Treewidth Graphs",
            "updated": "2023-08-28T17:30:44Z",
            "published": "2023-08-28T17:30:44Z",
            "summary": "We present a $\\widetilde{O}(m\\sqrt{\\tau}+n\\tau)$ time algorithm for finding a\nminimum-cost flow in graphs with $n$ vertices and $m$ edges, given a tree\ndecomposition of width $\\tau$ and polynomially bounded integer costs and\ncapacities. This improves upon the current best algorithms for general linear\nprograms bounded by treewidth which run in $\\widetilde{O}(m\n\\tau^{(\\omega+1)/2})$ time by [Dong-Lee-Ye,21] and [Gu-Song,22], where $\\omega\n\\approx 2.37$ is the matrix multiplication exponent. Our approach leverages\nrecent advances in structured linear program solvers and robust interior point\nmethods.\n  As a corollary, for any graph $G$ with $n$ vertices, $m$ edges, and treewidth\n$\\tau$, we obtain a $\\widetilde{O}(\\tau^3 \\cdot m)$ time algorithm to compute a\ntree decomposition of $G$ with width $O(\\tau \\cdot \\log n)$.",
            "author": [
                "Sally Dong",
                "Guanghao Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14727v1",
                "http://arxiv.org/pdf/2308.14727v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14726v1",
            "title": "PanoSwin: a Pano-style Swin Transformer for Panorama Understanding",
            "updated": "2023-08-28T17:30:14Z",
            "published": "2023-08-28T17:30:14Z",
            "summary": "In panorama understanding, the widely used equirectangular projection (ERP)\nentails boundary discontinuity and spatial distortion. It severely deteriorates\nthe conventional CNNs and vision Transformers on panoramas. In this paper, we\npropose a simple yet effective architecture named PanoSwin to learn panorama\nrepresentations with ERP. To deal with the challenges brought by\nequirectangular projection, we explore a pano-style shift windowing scheme and\nnovel pitch attention to address the boundary discontinuity and the spatial\ndistortion, respectively. Besides, based on spherical distance and Cartesian\ncoordinates, we adapt absolute positional embeddings and relative positional\nbiases for panoramas to enhance panoramic geometry information. Realizing that\nplanar image understanding might share some common knowledge with panorama\nunderstanding, we devise a novel two-stage learning framework to facilitate\nknowledge transfer from the planar images to panoramas. We conduct experiments\nagainst the state-of-the-art on various panoramic tasks, i.e., panoramic object\ndetection, panoramic classification, and panoramic layout estimation. The\nexperimental results demonstrate the effectiveness of PanoSwin in panorama\nunderstanding.",
            "author": [
                "Zhixin Ling",
                "Zhen Xing",
                "Xiangdong Zhou",
                "Manliang Cao",
                "Guichun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14726v1",
                "http://arxiv.org/pdf/2308.14726v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14724v1",
            "title": "Conceptual articles may disrupt the field of marketing but continue to\n  decline in numbers: Evidence from a GPT-assisted study",
            "updated": "2023-08-28T17:29:28Z",
            "published": "2023-08-28T17:29:28Z",
            "summary": "The present paper addresses if and how an article's academic impact varies by\nknowledge development approaches. Specifically, it classifies conceptual and\nempirical articles published in four marketing journals - Journal of Marketing,\nJournal of Marketing Research, Journal of Consumer Research, and Marketing\nScience - with the aid of a large language model, GPT. The Kolmogorov-Smirnov\n(KS) test is implemented for each journal to compare the disruption scores of\nconceptual and empirical articles. The results show that conceptual research is\nmore likely to disrupt the field of marketing while it tends to decline in its\npublication quantity. Our paper highlights the importance of conceptual\narticles and contributes to the understanding of how marketing articles are\ndeveloped and disseminated to advance knowledge.",
            "author": [
                "Jennifer JooYeon Lee",
                "Hyunuk Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14724v1",
                "http://arxiv.org/pdf/2308.14724v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14716v2",
            "title": "Local Lipschitz Filters for Bounded-Range Functions with Applications to\n  Arbitrary Real-Valued Functions",
            "updated": "2023-11-20T17:42:00Z",
            "published": "2023-08-28T17:16:37Z",
            "summary": "We study local filters for the Lipschitz property of real-valued functions\n$f: V \\to [0,r]$, where the Lipschitz property is defined with respect to an\narbitrary undirected graph $G=(V,E)$. We give nearly optimal local Lipschitz\nfilters both with respect to $\\ell_1$-distance and $\\ell_0$-distance. Previous\nwork only considered unbounded-range functions over $[n]^d$. Jha and\nRaskhodnikova (SICOMP `13) gave an algorithm for such functions with lookup\ncomplexity exponential in $d$, which Awasthi et al. (ACM Trans. Comput. Theory)\nshowed was necessary in this setting. We demonstrate that important\napplications of local Lipschitz filters can be accomplished with filters for\nfunctions with bounded-range. For functions $f: [n]^d\\to [0,r]$, we circumvent\nthe lower bound and achieve running time $(d^r\\log n)^{O(\\log r)}$ for the\n$\\ell_1$-respecting filter and $d^{O(r)}\\text{polylog } n$ for the\n$\\ell_0$-respecting filter. Our local filters provide a novel Lipschitz\nextension that can be implemented locally. Furthermore, we show that our\nalgorithms have nearly optimal dependence on $r$ for the domain $\\{0,1\\}^d$. In\naddition, our lower bound resolves an open question of Awasthi et al., removing\none of the conditions necessary for their lower bound for general range. We\nprove our lower bound via a reduction from distribution-free Lipschitz testing\nand a new technique for proving hardness for {\\em adaptive} algorithms. We\nprovide two applications of our local filters to arbitrary real-valued\nfunctions. In the first application, we use them in conjunction with the\nLaplace mechanism for differential privacy and noisy binary search to provide\nmechanisms for privately releasing outputs of black-box functions, even in the\npresence of malicious clients. In the second application, we use our local\nfilters to obtain the first nontrivial tolerant tester for the Lipschitz\nproperty.",
            "author": [
                "Jane Lange",
                "Ephraim Linder",
                "Sofya Raskhodnikova",
                "Arsen Vasilyan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14716v2",
                "http://arxiv.org/pdf/2308.14716v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14714v3",
            "title": "A Stochastic Surveillance Stackelberg Game: Co-Optimizing Defense\n  Placement and Patrol Strategy",
            "updated": "2023-11-13T01:15:47Z",
            "published": "2023-08-28T17:14:16Z",
            "summary": "Stochastic patrol routing is known to be advantageous in adversarial\nsettings; however, the optimal choice of stochastic routing strategy is\ndependent on a model of the adversary. We adopt a worst-case omniscient\nadversary model from the literature and extend the formulation to accommodate\nheterogeneous defenses at the various nodes of the graph. Introducing this\nheterogeneity leads to interesting new patrol strategies. We identify efficient\nmethods for computing these strategies in certain classes of graphs. We assess\nthe effectiveness of these strategies via comparison to an upper bound on the\nvalue of the game. Finally, we leverage the heterogeneous defense formulation\nto develop novel defense placement algorithms that complement the patrol\nstrategies.",
            "author": [
                "Yohan John",
                "Gilberto Diaz-Garcia",
                "Xiaoming Duan",
                "Jason R. Marden",
                "Francesco Bullo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14714v3",
                "http://arxiv.org/pdf/2308.14714v3"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.GT",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14712v1",
            "title": "Loss of Detailed Balance in Equilibrium due to Partial Quantum\n  Decoherence: A Quantum Graph Analogue",
            "updated": "2023-08-28T17:11:56Z",
            "published": "2023-08-28T17:11:56Z",
            "summary": "We explore the physics of quantum systems that suffer from partial\ndecoherence, in the intermediate range between coherent quantum evolution and\nincoherent classical physics. It has been predicted that new physics and\ntechnology are enabled in this intermediate regime. In particular we explore\nthe asymmetric transmission through an Aharonov-Bohm (AB) ring that supports a\n3:1 asymmetry in transmission times, augmented with de-phasing features that\nact preferentially on the longer-lingering quantum waves. Such a device is\nrealized as a microwave analogue quantum graph utilizing a gyrator to create\nthe 3:1 transmission time delay asymmetry, along with both homogeneous and\nlocalized losses to mimic the effects of de-phasing in the analogous mesoscopic\nelectron system. Measurements and simulations of this device demonstrate the\nrequired non-reciprocal transmission time delay, as well as an asymmetry in\ntransmission probability. The measurements and simulations are performed in\nboth the frequency domain, and in the time domain using wave packets. We\ndemonstrate asymmetric transmission through the AB-ring graph as a function of\nloss/de-phasing in both simulation and experiment, in both the frequency- and\ntime-domains, and compare to expectations for the corresponding quantum system.\nThe results are consistent with the hypothesis that the transmission asymmetry\nand loss of detailed balance is an equilibrium property of the analogous\nmesoscopic quantum graph.",
            "author": [
                "Lei Chen",
                "Isabella L. Giovannelli",
                "Nadav Shaibe",
                "Steven M. Anlage"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14712v1",
                "http://arxiv.org/pdf/2308.14712v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other",
                "nlin.CD",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14691v1",
            "title": "Scalar Field Dark Matter: Impact of Supernovae-driven blowouts on the\n  soliton structure of low mass dark matter halos",
            "updated": "2023-08-28T16:32:45Z",
            "published": "2023-08-28T16:32:45Z",
            "summary": "We present the first study on the gravitational impact of supernova feedback\nin an isolated soliton and a spherically symmetric dwarf SFDM halo of virial\nmass $1\\times 10^{10}\\mathrm{M_\\odot}$. We use a boson mass\n$m=10^{-22}\\mathrm{eV/c^2}$ and a soliton core $r_c \\approx 0.7$kpc, comparable\nto typical half-light radii of Local Group dwarf galaxies. We simulate the\nrapid gas removal from the center of the soliton by a concentric external\ntime-dependent Hernquist potential. We explore two scenarios of feedback\nblowouts: i) a massive single burst, and ii) multiple consecutive blowouts\ninjecting the same total energy to the system, including various magnitudes for\nthe blowouts in both scenarios. In all cases, we find one single blowout has a\nstronger effect on reducing the soliton central density. Feedback leads to\ncentral soliton densities that oscillate quasi-periodically for an isolated\nsoliton and stochastically for a SFDM halo. The range in the density amplitude\ndepends on the strength of the blowout, however we observe typical variations\nof a factor of $\\geqslant$2. One important consequence of the stochastic\nfluctuating densities is that, if we had no prior knowledge of the system\nevolution, we can only know the configuration profile at a specific time within\nsome accuracy. By fitting soliton profiles at different times to our simulated\nstructures, we found the (1-$\\sigma$) scatter of their time-dependent density\nprofiles. For configurations within the 1$\\sigma$ range, we find the inferred\nboson mass is typically less than 20\\% different from the real value used in\nour simulations. Finally, we compare the observed dynamical masses of field\ndwarf galaxies in our Local Group with the implied range of viable solitons\nfrom our simulations and find good agreement.",
            "author": [
                "Victor H. Robles",
                "J. L. Zagorac",
                "N. Padmanabhan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14691v1",
                "http://arxiv.org/pdf/2308.14691v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14677v2",
            "title": "Twin-width of graphs with tree-structured decompositions",
            "updated": "2023-09-06T19:50:50Z",
            "published": "2023-08-28T16:13:24Z",
            "summary": "The twin-width of a graph measures its distance to co-graphs and generalizes\nclassical width concepts such as tree-width or rank-width. Since its\nintroduction in 2020 (Bonnet et. al. 2020), a mass of new results has appeared\nrelating twin width to group theory, model theory, combinatorial optimization,\nand structural graph theory.\n  We take a detailed look at the interplay between the twin-width of a graph\nand the twin-width of its components under tree-structured decompositions: We\nprove that the twin-width of a graph is at most twice its strong tree-width,\ncontrasting nicely with the result of (Bonnet and D\\'epr\\'es 2022), which\nstates that twin-width can be exponential in tree-width. Further, we employ the\nfundamental concept from structural graph theory of decomposing a graph into\nhighly connected components, in order to obtain an optimal linear bound on the\ntwin-width of a graph given the widths of its biconnected components. For\ntriconnected components we obtain a linear upper bound if we add red edges to\nthe components indicating the splits which led to the components. Extending\nthis approach to quasi-4-connectivity, we obtain a quadratic upper bound.\nFinally, we investigate how the adhesion of a tree decomposition influences the\ntwin-width of the decomposed graph.",
            "author": [
                "Irene Heinrich",
                "Simon Ra\u00dfmann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14677v2",
                "http://arxiv.org/pdf/2308.14677v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C40, 05C05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14659v2",
            "title": "RESTORE: Graph Embedding Assessment Through Reconstruction",
            "updated": "2023-09-05T15:00:23Z",
            "published": "2023-08-28T15:41:30Z",
            "summary": "Following the success of Word2Vec embeddings, graph embeddings (GEs) have\ngained substantial traction. GEs are commonly generated and evaluated\nextrinsically on downstream applications, but intrinsic evaluations of the\noriginal graph properties in terms of topological structure and semantic\ninformation have been lacking. Understanding these will help identify the\ndeficiency of the various families of GE methods when vectorizing graphs in\nterms of preserving the relevant knowledge or learning incorrect knowledge. To\naddress this, we propose RESTORE, a framework for intrinsic GEs assessment\nthrough graph reconstruction. We show that reconstructing the original graph\nfrom the underlying GEs yields insights into the relative amount of information\npreserved in a given vector form. We first introduce the graph reconstruction\ntask. We generate GEs from three GE families based on factorization methods,\nrandom walks, and deep learning (with representative algorithms from each\nfamily) on the CommonSense Knowledge Graph (CSKG). We analyze their\neffectiveness in preserving the (a) topological structure of node-level graph\nreconstruction with an increasing number of hops and (b) semantic information\non various word semantic and analogy tests. Our evaluations show deep\nlearning-based GE algorithm (SDNE) is overall better at preserving (a) with a\nmean average precision (mAP) of 0.54 and 0.35 for 2 and 3-hop reconstruction\nrespectively, while the factorization-based algorithm (HOPE) is better at\nencapsulating (b) with an average Euclidean distance of 0.14, 0.17, and 0.11\nfor 1, 2, and 3-hop reconstruction respectively. The modest performance of\nthese GEs leaves room for further research avenues on better graph\nrepresentation learning.",
            "author": [
                "Hong Yung Yip",
                "Chidaksh Ravuru",
                "Neelabha Banerjee",
                "Shashwat Jha",
                "Amit Sheth",
                "Aman Chadha",
                "Amitava Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14659v2",
                "http://arxiv.org/pdf/2308.14659v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14647v1",
            "title": "Edge Generation Scheduling for DAG Tasks using Deep Reinforcement\n  Learning",
            "updated": "2023-08-28T15:19:18Z",
            "published": "2023-08-28T15:19:18Z",
            "summary": "Directed acyclic graph (DAG) tasks are currently adopted in the real-time\ndomain to model complex applications from the automotive, avionics, and\nindustrial domain that implement their functionalities through chains of\nintercommunicating tasks. This paper studies the problem of scheduling\nreal-time DAG tasks by presenting a novel schedulability test based on the\nconcept of trivial schedulability. Using this schedulability test, we propose a\nnew DAG scheduling framework (edge generation scheduling -- EGS) that attempts\nto minimize the DAG width by iteratively generating edges while guaranteeing\nthe deadline constraint. We study how to efficiently solve the problem of\ngenerating edges by developing a deep reinforcement learning algorithm combined\nwith a graph representation neural network to learn an efficient edge\ngeneration policy for EGS. We evaluate the effectiveness of the proposed\nalgorithm by comparing it with state-of-the-art DAG scheduling heuristics and\nan optimal mixed-integer linear programming baseline. Experimental results show\nthat the proposed algorithm outperforms the state-of-the-art by requiring fewer\nprocessors to schedule the same DAG tasks.",
            "author": [
                "Binqi Sun",
                "Mirco Theile",
                "Ziyuan Qin",
                "Daniele Bernardini",
                "Debayan Roy",
                "Andrea Bastoni",
                "Marco Caccamo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14647v1",
                "http://arxiv.org/pdf/2308.14647v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.DM",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14636v1",
            "title": "Towards Standardized Disturbance Rejection Testing of Legged Robot\n  Locomotion with Linear Impactor: A Preliminary Study, Observations, and\n  Implications",
            "updated": "2023-08-28T15:04:32Z",
            "published": "2023-08-28T15:04:32Z",
            "summary": "Dynamic locomotion in legged robots is close to industrial collaboration, but\na lack of standardized testing obstructs commercialization. The issues are not\nmerely political, theoretical, or algorithmic but also physical, indicating\nlimited studies and comprehension regarding standard testing infrastructure and\nequipment. For decades, the approaches we have been testing legged robots were\nrarely standardizable with hand-pushing, foot-kicking, rope-dragging,\nstick-poking, and ball-swinging. This paper aims to bridge the gap by proposing\nthe use of the linear impactor, a well-established tool in other standardized\ntesting disciplines, to serve as an adaptive, repeatable, and fair disturbance\nrejection testing equipment for legged robots. A pneumatic linear impactor is\nalso adopted for the case study involving the humanoid robot Digit. Three\nlocomotion controllers are examined, including a commercial one, using a\nwalking-in-place task against frontal impacts. The statistically best\ncontroller was able to withstand the impact momentum (26.376 kg$\\cdot$m/s) on\npar with a reported average effective momentum from straight punches by Olympic\nboxers (26.506 kg$\\cdot$m/s). Moreover, the case study highlights other\nanti-intuitive observations, demonstrations, and implications that, to the best\nof the authors' knowledge, are first-of-its-kind revealed in real-world testing\nof legged robots.",
            "author": [
                "Bowen Weng",
                "Guillermo A. Castillo",
                "Yun-Seok Kang",
                "Ayonga Hereid"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14636v1",
                "http://arxiv.org/pdf/2308.14636v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14626v1",
            "title": "VesselShot: Few-shot learning for cerebral blood vessel segmentation",
            "updated": "2023-08-28T14:48:49Z",
            "published": "2023-08-28T14:48:49Z",
            "summary": "Angiography is widely used to detect, diagnose, and treat cerebrovascular\ndiseases. While numerous techniques have been proposed to segment the vascular\nnetwork from different imaging modalities, deep learning (DL) has emerged as a\npromising approach. However, existing DL methods often depend on proprietary\ndatasets and extensive manual annotation. Moreover, the availability of\npre-trained networks specifically for medical domains and 3D volumes is\nlimited. To overcome these challenges, we propose a few-shot learning approach\ncalled VesselShot for cerebrovascular segmentation. VesselShot leverages\nknowledge from a few annotated support images and mitigates the scarcity of\nlabeled data and the need for extensive annotation in cerebral blood vessel\nsegmentation. We evaluated the performance of VesselShot using the publicly\navailable TubeTK dataset for the segmentation task, achieving a mean Dice\ncoefficient (DC) of 0.62(0.03).",
            "author": [
                "Mumu Aktar",
                "Hassan Rivaz",
                "Marta Kersten-Oertel",
                "Yiming Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14626v1",
                "http://arxiv.org/pdf/2308.14626v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15494v1",
            "title": "Parallel Unconstrained Local Search for Partitioning Irregular Graphs",
            "updated": "2023-08-28T14:33:03Z",
            "published": "2023-08-28T14:33:03Z",
            "summary": "We present new refinement heuristics for the balanced graph partitioning\nproblem that break with an age-old rule. Traditionally, local search only\npermits moves that keep the block sizes balanced (below a size constraint). In\nthis work, we demonstrate that admitting large temporary balance violations\ndrastically improves solution quality. The effects are particularly strong on\nirregular instances such as social networks. Designing efficient\nimplementations of this general idea involves both careful selection of\ncandidates for unconstrained moves as well as algorithms for rebalancing the\nsolution later on. We explore a wide array of design choices to achieve this,\nin addition to our third goal of high parallel scalability. We present\ncompelling experimental results, demonstrating that our parallel unconstrained\nlocal search techniques outperform the prior state of the art by a substantial\nmargin. Compared with four state-of-the-art solvers, our new technique finds\n91% of the best solutions on irregular graphs. We achieve a 13.8% improvement\nin edge cut over the next best competitor, while being only 11.4% slower in the\ngeometric mean.",
            "author": [
                "Nikolai Maas",
                "Lars Gottesb\u00fcren",
                "Daniel Seemaier"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15494v1",
                "http://arxiv.org/pdf/2308.15494v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14613v1",
            "title": "MS-Net: A Multi-modal Self-supervised Network for Fine-Grained\n  Classification of Aircraft in SAR Images",
            "updated": "2023-08-28T14:28:50Z",
            "published": "2023-08-28T14:28:50Z",
            "summary": "Synthetic aperture radar (SAR) imaging technology is commonly used to provide\n24-hour all-weather earth observation. However, it still has some drawbacks in\nSAR target classification, especially in fine-grained classification of\naircraft: aircrafts in SAR images have large intra-class diversity and\ninter-class similarity; the number of effective samples is insufficient and\nit's hard to annotate. To address these issues, this article proposes a novel\nmulti-modal self-supervised network (MS-Net) for fine-grained classification of\naircraft. Firstly, in order to entirely exploit the potential of multi-modal\ninformation, a two-sided path feature extraction network (TSFE-N) is\nconstructed to enhance the image feature of the target and obtain the domain\nknowledge feature of text mode. Secondly, a contrastive self-supervised\nlearning (CSSL) framework is employed to effectively learn useful\nlabel-independent feature from unbalanced data, a similarity per-ception loss\n(SPloss) is proposed to avoid network overfitting. Finally, TSFE-N is used as\nthe encoder of CSSL to obtain the classification results. Through a large\nnumber of experiments, our MS-Net can effectively reduce the difficulty of\nclassifying similar types of aircrafts. In the case of no label, the proposed\nalgorithm achieves an accuracy of 88.46% for 17 types of air-craft\nclassification task, which has pioneering significance in the field of\nfine-grained classification of aircraft in SAR images.",
            "author": [
                "Bingying Yue",
                "Jianhao Li",
                "Hao Shi",
                "Yupei Wang",
                "Honghu Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14613v1",
                "http://arxiv.org/pdf/2308.14613v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14608v1",
            "title": "AI in the Gray: Exploring Moderation Policies in Dialogic Large Language\n  Models vs. Human Answers in Controversial Topics",
            "updated": "2023-08-28T14:23:04Z",
            "published": "2023-08-28T14:23:04Z",
            "summary": "The introduction of ChatGPT and the subsequent improvement of Large Language\nModels (LLMs) have prompted more and more individuals to turn to the use of\nChatBots, both for information and assistance with decision-making. However,\nthe information the user is after is often not formulated by these ChatBots\nobjectively enough to be provided with a definite, globally accepted answer.\n  Controversial topics, such as \"religion\", \"gender identity\", \"freedom of\nspeech\", and \"equality\", among others, can be a source of conflict as partisan\nor biased answers can reinforce preconceived notions or promote disinformation.\nBy exposing ChatGPT to such debatable questions, we aim to understand its level\nof awareness and if existing models are subject to socio-political and/or\neconomic biases. We also aim to explore how AI-generated answers compare to\nhuman ones. For exploring this, we use a dataset of a social media platform\ncreated for the purpose of debating human-generated claims on polemic subjects\namong users, dubbed Kialo.\n  Our results show that while previous versions of ChatGPT have had important\nissues with controversial topics, more recent versions of ChatGPT\n(gpt-3.5-turbo) are no longer manifesting significant explicit biases in\nseveral knowledge areas. In particular, it is well-moderated regarding economic\naspects. However, it still maintains degrees of implicit libertarian leaning\ntoward right-winged ideals which suggest the need for increased moderation from\nthe socio-political point of view. In terms of domain knowledge on\ncontroversial topics, with the exception of the \"Philosophical\" category,\nChatGPT is performing well in keeping up with the collective human level of\nknowledge. Finally, we see that sources of Bing AI have slightly more tendency\nto the center when compared to human answers. All the analyses we make are\ngeneralizable to other types of biases and domains.",
            "author": [
                "Vahid Ghafouri",
                "Vibhor Agarwal",
                "Yong Zhang",
                "Nishanth Sastry",
                "Jose Such",
                "Guillermo Suarez-Tangil"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614777",
                "http://arxiv.org/abs/2308.14608v1",
                "http://arxiv.org/pdf/2308.14608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14601v1",
            "title": "Fairness Through Domain Awareness: Mitigating Popularity Bias For Music\n  Discovery",
            "updated": "2023-08-28T14:12:25Z",
            "published": "2023-08-28T14:12:25Z",
            "summary": "As online music platforms grow, music recommender systems play a vital role\nin helping users navigate and discover content within their vast musical\ndatabases. At odds with this larger goal, is the presence of popularity bias,\nwhich causes algorithmic systems to favor mainstream content over, potentially\nmore relevant, but niche items. In this work we explore the intrinsic\nrelationship between music discovery and popularity bias. To mitigate this\nissue we propose a domain-aware, individual fairness-based approach which\naddresses popularity bias in graph neural network (GNNs) based recommender\nsystems. Our approach uses individual fairness to reflect a ground truth\nlistening experience, i.e., if two songs sound similar, this similarity should\nbe reflected in their representations. In doing so, we facilitate meaningful\nmusic discovery that is robust to popularity bias and grounded in the music\ndomain. We apply our BOOST methodology to two discovery based tasks, performing\nrecommendations at both the playlist level and user level. Then, we ground our\nevaluation in the cold start setting, showing that our approach outperforms\nexisting fairness benchmarks in both performance and recommendation of\nlesser-known content. Finally, our analysis explains why our proposed\nmethodology is a novel and promising approach to mitigating popularity bias and\nimproving the discovery of new and niche content in music recommender systems.",
            "author": [
                "Rebecca Salganik",
                "Fernando Diaz",
                "Golnoosh Farnadi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14601v1",
                "http://arxiv.org/pdf/2308.14601v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14597v1",
            "title": "Adversarial Attacks on Foundational Vision Models",
            "updated": "2023-08-28T14:09:02Z",
            "published": "2023-08-28T14:09:02Z",
            "summary": "Rapid progress is being made in developing large, pretrained, task-agnostic\nfoundational vision models such as CLIP, ALIGN, DINOv2, etc. In fact, we are\napproaching the point where these models do not have to be finetuned\ndownstream, and can simply be used in zero-shot or with a lightweight probing\nhead. Critically, given the complexity of working at this scale, there is a\nbottleneck where relatively few organizations in the world are executing the\ntraining then sharing the models on centralized platforms such as HuggingFace\nand torch.hub. The goal of this work is to identify several key adversarial\nvulnerabilities of these models in an effort to make future designs more\nrobust. Intuitively, our attacks manipulate deep feature representations to\nfool an out-of-distribution (OOD) detector which will be required when using\nthese open-world-aware models to solve closed-set downstream tasks. Our methods\nreliably make in-distribution (ID) images (w.r.t. a downstream task) be\npredicted as OOD and vice versa while existing in extremely\nlow-knowledge-assumption threat models. We show our attacks to be potent in\nwhitebox and blackbox settings, as well as when transferred across foundational\nmodel types (e.g., attack DINOv2 with CLIP)! This work is only just the\nbeginning of a long journey towards adversarially robust foundational vision\nmodels.",
            "author": [
                "Nathan Inkawhich",
                "Gwendolyn McDonald",
                "Ryan Luley"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14597v1",
                "http://arxiv.org/pdf/2308.14597v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14593v1",
            "title": "Skip, Skip, Skip, Accept!!!: A Study on the Usability of Smartphone\n  Manufacturer Provided Default Features and User Privacy",
            "updated": "2023-08-28T14:00:09Z",
            "published": "2023-08-28T14:00:09Z",
            "summary": "Smartphone manufacturer provided default features (e.g., default location\nservices, iCloud, Google Assistant, ad tracking) enhance the usability and\nextend the functionality of these devices. Prior studies have highlighted\nsmartphone vulnerabilities and how users' data can be harvested without their\nknowledge. However, little is known about manufacturer provided default\nfeatures in this regard -- their usability concerning configuring them during\nusage, and how users perceive them with regards to privacy. To bridge this gap,\nwe conducted a task-based study with 27 Android and iOS smartphone users in\norder to learn about their perceptions, concerns and practices, and to\nunderstand the usability of these features with regards to privacy. We explored\nthe following: users' awareness of these features, why and when do they change\nthe settings of these features, the challenges they face while configuring\nthese features, and finally the mitigation strategies they adopt. Our findings\nreveal that users of both platforms have limited awareness of these features\nand their privacy implications. Awareness of these features does not imply that\na user can easily locate and adjust them when needed.\n  Furthermore, users attribute their failure to configure default features to\nhidden controls and insufficient knowledge on how to configure them. To cope\nwith difficulties of finding controls, users employ various coping strategies,\nsome of which are platform specific but most often applicable to both\nplatforms. However, some of these coping strategies leave users vulnerable.",
            "author": [
                "Kopo M. Ramokapane",
                "Anthony C. Mazeli",
                "Awais Rashid"
            ],
            "link": [
                "http://dx.doi.org/10.2478/popets-2019-0027",
                "http://arxiv.org/abs/2308.14593v1",
                "http://arxiv.org/pdf/2308.14593v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14778v1",
            "title": "A precise condition for independent transversals in bipartite covers",
            "updated": "2023-08-28T13:34:50Z",
            "published": "2023-08-28T13:34:50Z",
            "summary": "Given a bipartite graph $H=(V=V_A\\cup V_B,E)$ in which any vertex in $V_A$\n(resp. $V_B$) has degree at most $D_A$ (resp. $D_B$), suppose there is a\npartition of $V$ that is a refinement of the bipartition $V_A\\cup V_B$ such\nthat the parts in $V_A$ (resp. $V_B$) have size at least $k_A$ (resp. $k_B$).\nWe prove that the condition $D_A/k_A+D_B/k_B\\le 1$ is sufficient for the\nexistence of an independent set of vertices of $H$ that is simultaneously\ntransversal to the partition, and show moreover that this condition is sharp.\nThis result is a bipartite refinement of two well-known results on independent\ntransversals, one due to the second author the other due to Szab\\'o and Tardos.",
            "author": [
                "Stijn Cambie",
                "Penny Haxell",
                "Ross J. Kang",
                "Ronen Wdowinski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14778v1",
                "http://arxiv.org/pdf/2308.14778v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C69, 05D15, 05C15, 05C35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14558v1",
            "title": "Storage codes and recoverable systems on lines and grids",
            "updated": "2023-08-28T13:20:00Z",
            "published": "2023-08-28T13:20:00Z",
            "summary": "A storage code is an assignment of symbols to the vertices of a connected\ngraph $G(V,E)$ with the property that the value of each vertex is a function of\nthe values of its neighbors, or more generally, of a certain neighborhood of\nthe vertex in $G$. In this work we introduce a new construction method of\nstorage codes, enabling one to construct new codes from known ones via an\ninterleaving procedure driven by resolvable designs. We also study storage\ncodes on $\\mathbb Z$ and ${\\mathbb Z}^2$ (lines and grids), finding closed-form\nexpressions for the capacity of several one and two-dimensional systems\ndepending on their recovery set, using connections between storage codes,\ngraphs, anticodes, and difference-avoiding sets.",
            "author": [
                "Alexander Barg",
                "Ohad Elishco",
                "Ryan Gabrys",
                "Geyang Wang",
                "Eitan Yaakobi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14558v1",
                "http://arxiv.org/pdf/2308.14558v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.CO",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14554v2",
            "title": "A comprehensive characterization of Property A and almost finiteness",
            "updated": "2023-08-29T19:08:30Z",
            "published": "2023-08-28T13:16:05Z",
            "summary": "Three important properties of groups, amenability, Property A and almost\nfiniteness, are in our focus, in the wider context of general countable bounded\ndegree graphs. A graph is almost finite if it has a tiling with isomorphic\ncopies of finitely many F\\o lner sets, and we call it strongly almost finite,\nif the tiling can be randomized so that the probability that a vertex is on the\nboundary of a tile is uniformly small. We give various equivalents for Property\nA and for strong almost finiteness. In particular, we prove that Property A\ntogether with a uniform version of amenability is equivalent to strong almost\nfiniteness. Using these characterizations, we show that graphs of\nsubexponential growth and Schreier graphs of amenable groups are always\nstrongly almost finite, generalizing the celebrated result of Downarowicz,\nHuczek and Zhang about amenable Cayley graphs, based on graph theoretic rather\nthan group theoretic principles. We also show that if a sequence of graphs of\nProperty A (in a uniform sense) converges to a graph $G$ in the neighborhood\ndistance (a purely combinatorial analogue of the classical Benjamini-Schramm\ndistance), then their Laplacian spectra converge to the Laplacian spectrum of\n$G$ in the Hausdorff distance. Finally, we apply the previous theory to\nconstruct a new and rich class of classifiable $C^{\\star}$-algebras. Namely, we\nshow that for any minimal strongly almost finite graph $G$ there are naturally\nassociated simple, nuclear, stably finite $C^{\\star}$-algebras that are\nclassifiable by their Elliott invariants.",
            "author": [
                "G\u00e1bor Elek",
                "\u00c1d\u00e1m Tim\u00e1r"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14554v2",
                "http://arxiv.org/pdf/2308.14554v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.DS",
                "math.MG",
                "math.OA",
                "43A07, 05C63, 46L35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14547v1",
            "title": "Deep graphical regression for jointly moderate and extreme Australian\n  wildfires",
            "updated": "2023-08-28T13:04:52Z",
            "published": "2023-08-28T13:04:52Z",
            "summary": "Recent wildfires in Australia have led to considerable economic loss and\nproperty destruction, and there is increasing concern that climate change may\nexacerbate their intensity, duration, and frequency. hazard quantification for\nextreme wildfires is an important component of wildfire management, as it\nfacilitates efficient resource distribution, adverse effect mitigation, and\nrecovery efforts. However, although extreme wildfires are typically the most\nimpactful, both small and moderate fires can still be devastating to local\ncommunities and ecosystems. Therefore, it is imperative to develop robust\nstatistical methods to reliably model the full distribution of wildfire spread.\nWe do so for a novel dataset of Australian wildfires from 1999 to 2019, and\nanalyse monthly spread over areas approximately corresponding to Statistical\nAreas Level 1 and 2 (SA1/SA2) regions. Given the complex nature of wildfire\nignition and spread, we exploit recent advances in statistical deep learning\nand extreme value theory to construct a parametric regression model using graph\nconvolutional neural networks and the extended generalized Pareto distribution,\nwhich allows us to model wildfire spread observed on an irregular spatial\ndomain. We highlight the efficacy of our newly proposed model and perform a\nwildfire hazard assessment for Australia and population-dense communities,\nnamely Tasmania, Sydney, Melbourne, and Perth.",
            "author": [
                "Daniela Cisneros",
                "Jordan Richards",
                "Ashok Dahal",
                "Luigi Lombardo",
                "Rapha\u00ebl Huser"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14547v1",
                "http://arxiv.org/pdf/2308.14547v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14536v1",
            "title": "Spoken Language Intelligence of Large Language Models for Language\n  Learning",
            "updated": "2023-08-28T12:47:41Z",
            "published": "2023-08-28T12:47:41Z",
            "summary": "People have long hoped for a conversational system that can assist in\nreal-life situations, and recent progress on large language models (LLMs) is\nbringing this idea closer to reality. While LLMs are often impressive in\nperformance, their efficacy in real-world scenarios that demand expert\nknowledge remains unclear. LLMs are believed to hold the most potential and\nvalue in education, especially in the development of Artificial intelligence\n(AI) based virtual teachers capable of facilitating language learning. Our\nfocus is centered on evaluating the efficacy of LLMs in the realm of education,\nspecifically in the areas of spoken language learning which encompass\nphonetics, phonology, and second language acquisition. We introduce a new\nmultiple-choice question dataset to evaluate the effectiveness of LLMs in the\naforementioned scenarios, including understanding and application of spoken\nlanguage knowledge. In addition, we investigate the influence of various\nprompting techniques such as zero- and few-shot method (prepending the question\nwith question-answer exemplars), chain-of-thought (CoT, think step-by-step),\nin-domain exampler and external tools (Google, Wikipedia). We conducted\nlarge-scale evaluation on popular LLMs (20 distinct models) using these\nmethods. We achieved significant performance improvements compared to the\nzero-shot baseline in the practical questions reasoning (GPT-3.5, 49.1% ->\n63.1%; LLaMA2-70B-Chat, 42.2% -> 48.6%). We found that models of different\nsizes have good understanding of concepts in phonetics, phonology, and second\nlanguage acquisition, but show limitations in reasoning for real-world\nproblems. Additionally, we also explore preliminary findings on conversational\ncommunication.",
            "author": [
                "Linkai Peng",
                "Baorian Nuchged",
                "Yingming Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14536v1",
                "http://arxiv.org/pdf/2308.14536v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14527v1",
            "title": "MDS Array Codes With Small Sub-packetization Levels and Small Repair\n  Degrees",
            "updated": "2023-08-28T12:29:01Z",
            "published": "2023-08-28T12:29:01Z",
            "summary": "High-rate minimum storage regenerating (MSR) codes are known to require a\nlarge sub-packetization level, which can make meta-data management difficult\nand hinder implementation in practical systems. A few maximum distance\nseparable (MDS) array code constructions have been proposed to attain a much\nsmaller sub-packetization level by sacrificing a bit of repair bandwidth.\nHowever, to the best of our knowledge, only one construction by Guruswami et\nal. can support the repair of a failed node without contacting all the\nsurviving nodes. This construction is certainly of theoretical interest but not\nyet practical due to its requirement for very large code parameters. In this\npaper, we propose a generic transformation that can convert any $(\\overline{n},\n\\overline{k})$ MSR code with a repair degree of $\\overline{d}<\\overline{n}-1$\ninto another $(n=s\\overline{n},k)$ MDS array code that supports $d<n-1$ with a\nsmall sub-packetization level and $(1+\\epsilon)$-optimal repair bandwidth\n(i.e., $1+\\epsilon$ times the optimal value) under a specific condition. We\nobtain three MDS array codes with small sub-packetization levels and\n$(1+\\epsilon)$-optimal repair bandwidth by applying this transformation to\nthree known MSR codes. All the new MDS array codes have a small repair degree\nof $d<n-1$ and work for both small and large code parameters.",
            "author": [
                "Jie Li",
                "Yi Liu",
                "Xiaohu Tang",
                "Yunghsiang S. Han",
                "Bo Bai",
                "Gong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14527v1",
                "http://arxiv.org/pdf/2308.14527v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14525v1",
            "title": "Semi-Supervised Learning for Visual Bird's Eye View Semantic\n  Segmentation",
            "updated": "2023-08-28T12:23:36Z",
            "published": "2023-08-28T12:23:36Z",
            "summary": "Visual bird's eye view (BEV) semantic segmentation helps autonomous vehicles\nunderstand the surrounding environment only from images, including static\nelements (e.g., roads) and dynamic elements (e.g., vehicles, pedestrians).\nHowever, the high cost of annotation procedures of full-supervised methods\nlimits the capability of the visual BEV semantic segmentation, which usually\nneeds HD maps, 3D object bounding boxes, and camera extrinsic matrixes. In this\npaper, we present a novel semi-supervised framework for visual BEV semantic\nsegmentation to boost performance by exploiting unlabeled images during the\ntraining. A consistency loss that makes full use of unlabeled data is then\nproposed to constrain the model on not only semantic prediction but also the\nBEV feature. Furthermore, we propose a novel and effective data augmentation\nmethod named conjoint rotation which reasonably augments the dataset while\nmaintaining the geometric relationship between the front-view images and the\nBEV semantic segmentation. Extensive experiments on the nuScenes and Argoverse\ndatasets show that our semi-supervised framework can effectively improve\nprediction accuracy. To the best of our knowledge, this is the first work that\nexplores improving visual BEV semantic segmentation performance using unlabeled\ndata. The code will be publicly available.",
            "author": [
                "Junyu Zhu",
                "Lina Liu",
                "Yu Tang",
                "Feng Wen",
                "Wanlong Li",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14525v1",
                "http://arxiv.org/pdf/2308.14525v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14523v1",
            "title": "Deep Reinforcement Learning for Uplink Scheduling in NOMA-URLLC Networks",
            "updated": "2023-08-28T12:18:02Z",
            "published": "2023-08-28T12:18:02Z",
            "summary": "This article addresses the problem of Ultra Reliable Low Latency\nCommunications (URLLC) in wireless networks, a framework with particularly\nstringent constraints imposed by many Internet of Things (IoT) applications\nfrom diverse sectors. We propose a novel Deep Reinforcement Learning (DRL)\nscheduling algorithm, named NOMA-PPO, to solve the Non-Orthogonal Multiple\nAccess (NOMA) uplink URLLC scheduling problem involving strict deadlines. The\nchallenge of addressing uplink URLLC requirements in NOMA systems is related to\nthe combinatorial complexity of the action space due to the possibility to\nschedule multiple devices, and to the partial observability constraint that we\nimpose to our algorithm in order to meet the IoT communication constraints and\nbe scalable. Our approach involves 1) formulating the NOMA-URLLC problem as a\nPartially Observable Markov Decision Process (POMDP) and the introduction of an\nagent state, serving as a sufficient statistic of past observations and\nactions, enabling a transformation of the POMDP into a Markov Decision Process\n(MDP); 2) adapting the Proximal Policy Optimization (PPO) algorithm to handle\nthe combinatorial action space; 3) incorporating prior knowledge into the\nlearning agent with the introduction of a Bayesian policy. Numerical results\nreveal that not only does our approach outperform traditional multiple access\nprotocols and DRL benchmarks on 3GPP scenarios, but also proves to be robust\nunder various channel and traffic configurations, efficiently exploiting\ninherent time correlations.",
            "author": [
                "Beno\u00eet-Marie Robaglia",
                "Marceau Coupechoux",
                "Dimitrios Tsilimantos"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14523v1",
                "http://arxiv.org/pdf/2308.14523v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14522v2",
            "title": "Graph Meets LLMs: Towards Large Graph Models",
            "updated": "2023-11-11T15:49:17Z",
            "published": "2023-08-28T12:17:51Z",
            "summary": "Large models have emerged as the most recent groundbreaking achievements in\nartificial intelligence, and particularly machine learning. However, when it\ncomes to graphs, large models have not achieved the same level of success as in\nother fields, such as natural language processing and computer vision. In order\nto promote applying large models for graphs forward, we present a perspective\npaper to discuss the challenges and opportunities associated with developing\nlarge graph models. First, we discuss the desired characteristics of large\ngraph models. Then, we present detailed discussions from three key\nperspectives: representation basis, graph data, and graph models. In each\ncategory, we provide a brief overview of recent advances and highlight the\nremaining challenges together with our visions. Finally, we discuss valuable\napplications of large graph models. We believe this perspective can encourage\nfurther investigations into large graph models, ultimately pushing us one step\ncloser towards artificial general intelligence (AGI). We are the first to\ncomprehensively study large graph models, to the best of our knowledge.",
            "author": [
                "Ziwei Zhang",
                "Haoyang Li",
                "Zeyang Zhang",
                "Yijian Qin",
                "Xin Wang",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14522v2",
                "http://arxiv.org/pdf/2308.14522v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14521v2",
            "title": "Context-Aware Composition of Agent Policies by Markov Decision Process\n  Entity Embeddings and Agent Ensembles",
            "updated": "2023-08-30T11:56:45Z",
            "published": "2023-08-28T12:13:36Z",
            "summary": "Computational agents support humans in many areas of life and are therefore\nfound in heterogeneous contexts. This means they operate in rapidly changing\nenvironments and can be confronted with huge state and action spaces. In order\nto perform services and carry out activities in a goal-oriented manner, agents\nrequire prior knowledge and therefore have to develop and pursue\ncontext-dependent policies. However, prescribing policies in advance is limited\nand inflexible, especially in dynamically changing environments. Moreover, the\ncontext of an agent determines its choice of actions. Since the environments\ncan be stochastic and complex in terms of the number of states and feasible\nactions, activities are usually modelled in a simplified way by Markov decision\nprocesses so that, e.g., agents with reinforcement learning are able to learn\npolicies, that help to capture the context and act accordingly to optimally\nperform activities. However, training policies for all possible contexts using\nreinforcement learning is time-consuming. A requirement and challenge for\nagents is to learn strategies quickly and respond immediately in cross-context\nenvironments and applications, e.g., the Internet, service robotics,\ncyber-physical systems. In this work, we propose a novel simulation-based\napproach that enables a) the representation of heterogeneous contexts through\nknowledge graphs and entity embeddings and b) the context-aware composition of\npolicies on demand by ensembles of agents running in parallel. The evaluation\nwe conducted with the \"Virtual Home\" dataset indicates that agents with a need\nto switch seamlessly between different contexts, can request on-demand composed\npolicies that lead to the successful completion of context-appropriate\nactivities without having to learn these policies in lengthy training steps and\nepisodes, in contrast to agents that use reinforcement learning.",
            "author": [
                "Nicole Merkle",
                "Ralf Mikut"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14521v2",
                "http://arxiv.org/pdf/2308.14521v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.PF",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14518v2",
            "title": "Hoeffding-type decomposition for $U$-statistics on bipartite networks",
            "updated": "2023-08-29T06:23:01Z",
            "published": "2023-08-28T12:09:24Z",
            "summary": "We consider a broad class of random bipartite networks, the distribution of\nwhich is invariant under permutation within each type of nodes. We are\ninterested in $U$-statistics defined on the adjacency matrix of such a network,\nfor which we define a new type of Hoeffding decomposition. This decomposition\nenables us to characterize non-degenerate $U$-statistics -- which are then\nasymptotically normal -- and provides us with a natural and easy-to-implement\nestimator of their asymptotic variance. \\\\ We illustrate the use of this\ngeneral approach on some typical random graph models and use it to estimate or\ntest some quantities characterizing the topology of the associated network. We\nalso assess the accuracy and the power of the proposed estimates or tests, via\na simulation study.",
            "author": [
                "T\u00e2m Le Minh",
                "Sophie Donnet",
                "Fran\u00e7ois Massol",
                "St\u00e9phane Robin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14518v2",
                "http://arxiv.org/pdf/2308.14518v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14493v1",
            "title": "Efficient Batch Dynamic Graphlet Counting",
            "updated": "2023-08-28T11:11:28Z",
            "published": "2023-08-28T11:11:28Z",
            "summary": "Graphlet counting is an important problem as it has numerous applications in\nseveral fields, including social network analysis, biological network analysis,\ntransaction network analysis, etc. Most of the practical networks are dynamic.\nA graphlet is a subgraph with a fixed number of vertices and can be induced or\nnon-induced. There are several works for counting graphlets in a static network\nwhere graph topology never changes. Surprisingly, there have been no scalable\nand practical algorithms for maintaining all fixed-sized graphlets in a dynamic\nnetwork where the graph topology changes over time. We are the first to propose\nan efficient algorithm for maintaining graphlets in a fully dynamic network.\nOur algorithm is efficient because (1) we consider only the region of changes\nin the graph for updating the graphlet count, and (2) we use an efficient\nalgorithm for counting graphlets in the region of change. We show by\nexperimental evaluation that our technique is more than 10x faster than the\nbaseline approach.",
            "author": [
                "Hriday G",
                "Pranav Saikiran Sista",
                "Apurba Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14493v1",
                "http://arxiv.org/pdf/2308.14493v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14491v3",
            "title": "Closeness of Some Graph Operations",
            "updated": "2023-11-21T08:18:41Z",
            "published": "2023-08-28T11:08:26Z",
            "summary": "Closeness is an important measure of network centrality. In this article we\nwill calculate the closeness of graphs, created by using operations on graphs.\nWe will prove a formula for the closeness of shadow graphs. We will calculate\nthe closeness of line graphs of some wellknown graphs (like path, star, cycle,\nand complete graphs) and the closeness of line graphs of two of these graphs,\nconnected by a bridge (like lollipop, tadpole, broom, and bistar graphs).",
            "author": [
                "Chavdar Dangalchev"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14491v3",
                "http://arxiv.org/pdf/2308.14491v3"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "05C35, 90C35",
                "G.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14484v1",
            "title": "Multimodal Detection of Social Spambots in Twitter using Transformers",
            "updated": "2023-08-28T10:51:11Z",
            "published": "2023-08-28T10:51:11Z",
            "summary": "Although not all bots are malicious, the vast majority of them are\nresponsible for spreading misinformation and manipulating the public opinion\nabout several issues, i.e., elections and many more. Therefore, the early\ndetection of social spambots is crucial. Although there have been proposed\nmethods for detecting bots in social media, there are still substantial\nlimitations. For instance, existing research initiatives still extract a large\nnumber of features and train traditional machine learning algorithms or use\nGloVe embeddings and train LSTMs. However, feature extraction is a tedious\nprocedure demanding domain expertise. Also, language models based on\ntransformers have been proved to be better than LSTMs. Other approaches create\nlarge graphs and train graph neural networks requiring in this way many hours\nfor training and access to computational resources. To tackle these\nlimitations, this is the first study employing only the user description field\nand images of three channels denoting the type and content of tweets posted by\nthe users. Firstly, we create digital DNA sequences, transform them to 3d\nimages, and apply pretrained models of the vision domain, including\nEfficientNet, AlexNet, VGG16, etc. Next, we propose a multimodal approach,\nwhere we use TwHIN-BERT for getting the textual representation of the user\ndescription field and employ VGG16 for acquiring the visual representation for\nthe image modality. We propose three different fusion methods, namely\nconcatenation, gated multimodal unit, and crossmodal attention, for fusing the\ndifferent modalities and compare their performances. Extensive experiments\nconducted on the Cresci '17 dataset demonstrate valuable advantages of our\nintroduced approaches over state-of-the-art ones reaching Accuracy up to\n99.98%.",
            "author": [
                "Loukas Ilias",
                "Ioannis Michail Kazelidis",
                "Dimitris Askounis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14484v1",
                "http://arxiv.org/pdf/2308.14484v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14475v1",
            "title": "Interactive Multi Interest Process Pattern Discovery",
            "updated": "2023-08-28T10:26:37Z",
            "published": "2023-08-28T10:26:37Z",
            "summary": "Process pattern discovery methods (PPDMs) aim at identifying patterns of\ninterest to users. Existing PPDMs typically are unsupervised and focus on a\nsingle dimension of interest, such as discovering frequent patterns. We present\nan interactive multi interest driven framework for process pattern discovery\naimed at identifying patterns that are optimal according to a multi-dimensional\nanalysis goal. The proposed approach is iterative and interactive, thus taking\nexperts knowledge into account during the discovery process. The paper focuses\non a concrete analysis goal, i.e., deriving process patterns that affect the\nprocess outcome. We evaluate the approach on real world event logs in both\ninteractive and fully automated settings. The approach extracted meaningful\npatterns validated by expert knowledge in the interactive setting. Patterns\nextracted in the automated settings consistently led to prediction performance\ncomparable to or better than patterns derived considering single interest\ndimensions without requiring user defined thresholds.",
            "author": [
                "Mozhgan Vazifehdoostirani",
                "Laura Genga",
                "Xixi Lu",
                "Rob Verhoeven",
                "Hanneke van Laarhoven",
                "Remco Dijkman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14475v1",
                "http://arxiv.org/pdf/2308.14475v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14443v1",
            "title": "Mutual visibility in hypercube-like graphs",
            "updated": "2023-08-28T09:30:28Z",
            "published": "2023-08-28T09:30:28Z",
            "summary": "Let $G$ be a graph and $X\\subseteq V(G)$. Then, vertices $x$ and $y$ of $G$\nare $X$-visible if there exists a shortest $u,v$-path where no internal\nvertices belong to $X$. The set $X$ is a mutual-visibility set of $G$ if every\ntwo vertices of $X$ are $X$-visible, while $X$ is a total mutual-visibility set\nif any two vertices from $V(G)$ are $X$-visible. The cardinality of a largest\nmutual-visibility set (resp. total mutual-visibility set) is the\nmutual-visibility number (resp. total mutual-visibility number) $\\mu(G)$ (resp.\n$\\mu_t(G)$) of $G$. It is known that computing $\\mu(G)$ is an NP-complete\nproblem, as well as $\\mu_t(G)$. In this paper, we study the (total)\nmutual-visibility in hypercube-like networks (namely, hypercubes,\ncube-connected cycles, and butterflies). Concerning computing $\\mu(G)$, we\nprovide approximation algorithms for both hypercubes and cube-connected cycles,\nwhile we give an exact formula for butterflies. Concerning computing $\\mu_t(G)$\n(in the literature, already studied in hypercubes), we provide exact formulae\nfor both cube-connected cycles and butterflies.",
            "author": [
                "Serafino Cicerone",
                "Alessia Di Fonso",
                "Gabriele Di Stefano",
                "Alfredo Navarra",
                "Francesco Piselli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14443v1",
                "http://arxiv.org/pdf/2308.14443v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DS",
                "G.2.2, F.2.2, G.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14436v1",
            "title": "Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware\n  Pre-training for KBQA",
            "updated": "2023-08-28T09:22:02Z",
            "published": "2023-08-28T09:22:02Z",
            "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions with factual information such as entities and relations in KBs.\nHowever, traditional Pre-trained Language Models (PLMs) are directly\npre-trained on large-scale natural language corpus, which poses challenges for\nthem in understanding and representing complex subgraphs in structured KBs. To\nbridge the gap between texts and structured KBs, we propose a Structured\nKnowledge-aware Pre-training method (SKP). In the pre-training stage, we\nintroduce two novel structured knowledge-aware tasks, guiding the model to\neffectively learn the implicit relationship and better representations of\ncomplex subgraphs. In downstream KBQA task, we further design an efficient\nlinearization strategy and an interval attention mechanism, which assist the\nmodel to better encode complex subgraphs and shield the interference of\nirrelevant subgraphs during reasoning respectively. Detailed experiments and\nanalyses on WebQSP verify the effectiveness of SKP, especially the significant\nimprovement in subgraph retrieval (+4.08% H@10).",
            "author": [
                "Guanting Dong",
                "Rumei Li",
                "Sirui Wang",
                "Yupeng Zhang",
                "Yunsen Xian",
                "Weiran Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14436v1",
                "http://arxiv.org/pdf/2308.14436v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14430v1",
            "title": "TextrolSpeech: A Text Style Control Speech Corpus With Codec Language\n  Text-to-Speech Models",
            "updated": "2023-08-28T09:06:32Z",
            "published": "2023-08-28T09:06:32Z",
            "summary": "Recently, there has been a growing interest in the field of controllable\nText-to-Speech (TTS). While previous studies have relied on users providing\nspecific style factor values based on acoustic knowledge or selecting reference\nspeeches that meet certain requirements, generating speech solely from natural\ntext prompts has emerged as a new challenge for researchers. This challenge\narises due to the scarcity of high-quality speech datasets with natural text\nstyle prompt and the absence of advanced text-controllable TTS models. In light\nof this, 1) we propose TextrolSpeech, which is the first large-scale speech\nemotion dataset annotated with rich text attributes. The dataset comprises\n236,220 pairs of style prompt in natural text descriptions with five style\nfactors and corresponding speech samples. Through iterative experimentation, we\nintroduce a multi-stage prompt programming approach that effectively utilizes\nthe GPT model for generating natural style descriptions in large volumes. 2)\nFurthermore, to address the need for generating audio with greater style\ndiversity, we propose an efficient architecture called Salle. This architecture\ntreats text controllable TTS as a language model task, utilizing audio codec\ncodes as an intermediate representation to replace the conventional\nmel-spectrogram. Finally, we successfully demonstrate the ability of the\nproposed model by showing a comparable performance in the controllable TTS\ntask. Audio samples are available at https://sall-e.github.io/",
            "author": [
                "Shengpeng Ji",
                "Jialong Zuo",
                "Minghui Fang",
                "Ziyue Jiang",
                "Feiyang Chen",
                "Xinyu Duan",
                "Baoxing Huai",
                "Zhou Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14430v1",
                "http://arxiv.org/pdf/2308.14430v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14429v1",
            "title": "Biomedical Entity Linking with Triple-aware Pre-Training",
            "updated": "2023-08-28T09:06:28Z",
            "published": "2023-08-28T09:06:28Z",
            "summary": "Linking biomedical entities is an essential aspect in biomedical natural\nlanguage processing tasks, such as text mining and question answering. However,\na difficulty of linking the biomedical entities using current large language\nmodels (LLM) trained on a general corpus is that biomedical entities are\nscarcely distributed in texts and therefore have been rarely seen during\ntraining by the LLM. At the same time, those LLMs are not aware of high level\nsemantic connection between different biomedical entities, which are useful in\nidentifying similar concepts in different textual contexts. To cope with\naforementioned problems, some recent works focused on injecting knowledge graph\ninformation into LLMs. However, former methods either ignore the relational\nknowledge of the entities or lead to catastrophic forgetting. Therefore, we\npropose a novel framework to pre-train the powerful generative LLM by a corpus\nsynthesized from a KG. In the evaluations we are unable to confirm the benefit\nof including synonym, description or relational information.",
            "author": [
                "Xi Yan",
                "Cedric M\u00f6ller",
                "Ricardo Usbeck"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14429v1",
                "http://arxiv.org/pdf/2308.14429v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14423v1",
            "title": "GADePo: Graph-Assisted Declarative Pooling Transformers for\n  Document-Level Relation Extraction",
            "updated": "2023-08-28T09:04:03Z",
            "published": "2023-08-28T09:04:03Z",
            "summary": "Document-level relation extraction aims to identify relationships between\nentities within a document. Current methods rely on text-based encoders and\nemploy various hand-coded pooling heuristics to aggregate information from\nentity mentions and associated contexts. In this paper, we replace these rigid\npooling functions with explicit graph relations by leveraging the intrinsic\ngraph processing capabilities of the Transformer model. We propose a joint\ntext-graph Transformer model, and a graph-assisted declarative pooling (GADePo)\nspecification of the input which provides explicit and high-level instructions\nfor information aggregation. This allows the pooling process to be guided by\ndomain-specific knowledge or desired outcomes but still learned by the\nTransformer, leading to more flexible and customizable pooling strategies. We\nextensively evaluate our method across diverse datasets and models, and show\nthat our approach yields promising results that are comparable to those\nachieved by the hand-coded pooling functions.",
            "author": [
                "Andrei C. Coman",
                "Christos Theodoropoulos",
                "Marie-Francine Moens",
                "James Henderson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14423v1",
                "http://arxiv.org/pdf/2308.14423v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14419v1",
            "title": "Graph-based Asynchronous Event Processing for Rapid Object Recognition",
            "updated": "2023-08-28T08:59:57Z",
            "published": "2023-08-28T08:59:57Z",
            "summary": "Different from traditional video cameras, event cameras capture asynchronous\nevents stream in which each event encodes pixel location, trigger time, and the\npolarity of the brightness changes. In this paper, we introduce a novel\ngraph-based framework for event cameras, namely SlideGCN. Unlike some recent\ngraph-based methods that use groups of events as input, our approach can\nefficiently process data event-by-event, unlock the low latency nature of\nevents data while still maintaining the graph's structure internally. For fast\ngraph construction, we develop a radius search algorithm, which better exploits\nthe partial regular structure of event cloud against k-d tree based generic\nmethods. Experiments show that our method reduces the computational complexity\nup to 100 times with respect to current graph-based methods while keeping\nstate-of-the-art performance on object recognition. Moreover, we verify the\nsuperiority of event-wise processing with our method. When the state becomes\nstable, we can give a prediction with high confidence, thus making an early\nrecognition. Project page: \\url{https://zju3dv.github.io/slide_gcn/}.",
            "author": [
                "Yijin Li",
                "Han Zhou",
                "Bangbang Yang",
                "Ye Zhang",
                "Zhaopeng Cui",
                "Hujun Bao",
                "Guofeng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14419v1",
                "http://arxiv.org/pdf/2308.14419v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14416v1",
            "title": "On the Statistical Relation of Ultra-Reliable Wireless and Location\n  Estimation",
            "updated": "2023-08-28T08:52:35Z",
            "published": "2023-08-28T08:52:35Z",
            "summary": "Location information is often used as a proxy to guarantee the performance of\na wireless communication link. However, localization errors can result in a\nsignificant mismatch with the guarantees, particularly detrimental to users\noperating the ultra-reliable low-latency communication (URLLC) regime. This\npaper unveils the fundamental statistical relations between location estimation\nuncertainty and wireless link reliability, specifically in the context of rate\nselection for ultra-reliable communication. We start with a simple\none-dimensional narrowband Rayleigh fading scenario and build towards a\ntwo-dimensional scenario in a rich scattering environment. The wireless link\nreliability is characterized by the meta-probability, the probability with\nrespect to localization error of exceeding the outage capacity, and by removing\nother sources of errors in the system, we show that reliability is sensitive to\nlocalization errors. The $\\epsilon$-outage coherence radius is defined and\nshown to provide valuable insight into the problem of location-based rate\nselection. However, it is generally challenging to guarantee reliability\nwithout accurate knowledge of the propagation environment. Finally, several\nrate-selection schemes are proposed, showcasing the problem's dynamics and\nrevealing that properly accounting for the localization error is critical to\nensure good performance in terms of reliability and achievable throughput.",
            "author": [
                "Tobias Kallehauge",
                "Martin Voigt Vejling",
                "Pablo Ram\u00ecrez-Espinosa",
                "Kimmo Kansanen",
                "Henk Wymeersch",
                "Petar Popovski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14416v1",
                "http://arxiv.org/pdf/2308.14416v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14390v1",
            "title": "ASCAPE: An open AI ecosystem to support the quality of life of cancer\n  patients",
            "updated": "2023-08-28T08:14:12Z",
            "published": "2023-08-28T08:14:12Z",
            "summary": "The latest cancer statistics indicate a decrease in cancer-related mortality.\nHowever, due to the growing and ageing population, the absolute number of\npeople living with cancer is set to keep increasing. This paper presents\nASCAPE, an open AI infrastructure that takes advantage of the recent advances\nin Artificial Intelligence (AI) and Machine Learning (ML) to support cancer\npatients quality of life (QoL). With ASCAPE health stakeholders (e.g.\nhospitals) can locally process their private medical data and then share the\nproduced knowledge (ML models) through the open AI infrastructure.",
            "author": [
                "Konstantinos Lampropoulos",
                "Thanos Kosmidis",
                "Serge Autexier",
                "Milos Savic",
                "Manos Athanatos",
                "Miltiadis Kokkonidis",
                "Tzortzia Koutsouri",
                "Anamaria Vizitiu",
                "Antonios Valachis",
                "Miriam Quintero Padron"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICHI52183.2021.00054",
                "http://arxiv.org/abs/2308.14390v1",
                "http://arxiv.org/pdf/2308.14390v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14384v1",
            "title": "On the identification of ARMA graphical models",
            "updated": "2023-08-28T07:59:40Z",
            "published": "2023-08-28T07:59:40Z",
            "summary": "The paper considers the problem to estimate a graphical model corresponding\nto an autoregressive moving-average (ARMA) Gaussian stochastic process. We\npropose a new maximum entropy covariance and cepstral extension problem and we\nshow that the problem admits an approximate solution which represents an ARMA\ngraphical model whose topology is determined by the selected entries of the\ncovariance lags considered in the extension problem. Then, we show how the\ncorresponding dual problem is connected with the maximum likelihood principle.\nSuch connection allows to design a Bayesian model and characterize an\napproximate maximum a posteriori estimator of the ARMA graphical model in the\ncase the graph topology is unknown. We test the performance of the proposed\nmethod through some numerical experiments.",
            "author": [
                "Mattia Zorzi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14384v1",
                "http://arxiv.org/pdf/2308.14384v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14378v1",
            "title": "GKGNet: Group K-Nearest Neighbor based Graph Convolutional Network for\n  Multi-Label Image Recognition",
            "updated": "2023-08-28T07:50:04Z",
            "published": "2023-08-28T07:50:04Z",
            "summary": "Multi-Label Image Recognition (MLIR) is a challenging task that aims to\npredict multiple object labels in a single image while modeling the complex\nrelationships between labels and image regions. Although convolutional neural\nnetworks and vision transformers have succeeded in processing images as regular\ngrids of pixels or patches, these representations are sub-optimal for capturing\nirregular and discontinuous regions of interest. In this work, we present the\nfirst fully graph convolutional model, Group K-nearest neighbor based Graph\nconvolutional Network (GKGNet), which models the connections between semantic\nlabel embeddings and image patches in a flexible and unified graph structure.\nTo address the scale variance of different objects and to capture information\nfrom multiple perspectives, we propose the Group KGCN module for dynamic graph\nconstruction and message passing. Our experiments demonstrate that GKGNet\nachieves state-of-the-art performance with significantly lower computational\ncosts on the challenging multi-label datasets, \\ie MS-COCO and VOC2007\ndatasets. We will release the code and models to facilitate future research in\nthis area.",
            "author": [
                "Ruijie Yao",
                "Sheng Jin",
                "Lumin Xu",
                "Wang Zeng",
                "Wentao Liu",
                "Chen Qian",
                "Ping Luo",
                "Ji Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14378v1",
                "http://arxiv.org/pdf/2308.14378v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14377v1",
            "title": "Meta Attentive Graph Convolutional Recurrent Network for Traffic\n  Forecasting",
            "updated": "2023-08-28T07:49:30Z",
            "published": "2023-08-28T07:49:30Z",
            "summary": "Traffic forecasting is a fundamental problem in intelligent transportation\nsystems. Existing traffic predictors are limited by their expressive power to\nmodel the complex spatial-temporal dependencies in traffic data, mainly due to\nthe following limitations. Firstly, most approaches are primarily designed to\nmodel the local shared patterns, which makes them insufficient to capture the\nspecific patterns associated with each node globally. Hence, they fail to learn\neach node's unique properties and diversified patterns. Secondly, most existing\napproaches struggle to accurately model both short- and long-term dependencies\nsimultaneously. In this paper, we propose a novel traffic predictor, named Meta\nAttentive Graph Convolutional Recurrent Network (MAGCRN). MAGCRN utilizes a\nGraph Convolutional Recurrent Network (GCRN) as a core module to model local\ndependencies and improves its operation with two novel modules: 1) a\nNode-Specific Meta Pattern Learning (NMPL) module to capture node-specific\npatterns globally and 2) a Node Attention Weight Generation Module (NAWG)\nmodule to capture short- and long-term dependencies by connecting the\nnode-specific features with the ones learned initially at each time step during\nGCRN operation. Experiments on six real-world traffic datasets demonstrate that\nNMPL and NAWG together enable MAGCRN to outperform state-of-the-art baselines\non both short- and long-term predictions.",
            "author": [
                "Adnan Zeb",
                "Yongchao Ye",
                "Shiyao Zhang",
                "James J. Q. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14377v1",
                "http://arxiv.org/pdf/2308.14377v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14374v1",
            "title": "Online Continual Learning on Hierarchical Label Expansion",
            "updated": "2023-08-28T07:42:26Z",
            "published": "2023-08-28T07:42:26Z",
            "summary": "Continual learning (CL) enables models to adapt to new tasks and environments\nwithout forgetting previously learned knowledge. While current CL setups have\nignored the relationship between labels in the past task and the new task with\nor without small task overlaps, real-world scenarios often involve hierarchical\nrelationships between old and new tasks, posing another challenge for\ntraditional CL approaches. To address this challenge, we propose a novel\nmulti-level hierarchical class incremental task configuration with an online\nlearning constraint, called hierarchical label expansion (HLE). Our\nconfiguration allows a network to first learn coarse-grained classes, with data\nlabels continually expanding to more fine-grained classes in various hierarchy\ndepths. To tackle this new setup, we propose a rehearsal-based method that\nutilizes hierarchy-aware pseudo-labeling to incorporate hierarchical class\ninformation. Additionally, we propose a simple yet effective memory management\nand sampling strategy that selectively adopts samples of newly encountered\nclasses. Our experiments demonstrate that our proposed method can effectively\nuse hierarchy on our HLE setup to improve classification accuracy across all\nlevels of hierarchies, regardless of depth and class imbalance ratio,\noutperforming prior state-of-the-art works by significant margins while also\noutperforming them on the conventional disjoint, blurry and i-Blurry CL setups.",
            "author": [
                "Byung Hyun Lee",
                "Okchul Jung",
                "Jonghyun Choi",
                "Se Young Chun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14374v1",
                "http://arxiv.org/pdf/2308.14374v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14368v1",
            "title": "Distance-regular Cayley graphs over\n  $\\mathbb{Z}_{p^s}\\oplus\\mathbb{Z}_{p}$",
            "updated": "2023-08-28T07:35:10Z",
            "published": "2023-08-28T07:35:10Z",
            "summary": "In [Distrance-regular Cayley graphs on dihedral groups, J. Combin. Theory Ser\nB 97 (2007) 14--33], Miklavi\\v{c} and Poto\\v{c}nik proposed the problem of\ncharacterizing distance-regular Cayley graphs, which can be viewed as an\nextension of the problem of identifying strongly regular Cayley graphs, or\nequivalently, regular partial difference sets. In this paper, all\ndistance-regular Cayley graphs over $\\mathbb{Z}_{p^s}\\oplus\\mathbb{Z}_{p}$ with\n$p$ being an odd prime are determined. It is shown that every such graph is\nisomorphic to a complete graph, a complete multipartite graph, or the line\ngraph of a transversal design $TD(r,p)$ with $2\\leq r\\leq p-1$.",
            "author": [
                "Xiongfeng Zhan",
                "Lu Lu",
                "Xueyi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14368v1",
                "http://arxiv.org/pdf/2308.14368v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05E30, 05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14364v1",
            "title": "Target-independent XLA optimization using Reinforcement Learning",
            "updated": "2023-08-28T07:23:03Z",
            "published": "2023-08-28T07:23:03Z",
            "summary": "An important challenge in Machine Learning compilers like XLA is multi-pass\noptimization and analysis. There has been recent interest chiefly in XLA\ntarget-dependent optimization on the graph-level, subgraph-level, and\nkernel-level phases. We specifically focus on target-independent optimization\nXLA HLO pass ordering: our approach aims at finding the optimal sequence of\ncompiler optimization passes, which is decoupled from target-dependent\noptimization. However, there is little domain specific study in pass ordering\nfor XLA HLO. To this end, we propose introducing deep Reinforcement Learning\n(RL) based search for optimal XLA HLO pass ordering. We also propose\nenhancements to the deep RL algorithms to further improve optimal search\nperformance and open the research direction for domain-specific guidance for\nRL. We create an XLA Gym experimentation framework as a tool to enable RL\nalgorithms to interact with the compiler for passing optimizations and thereby\ntrain agents. Overall, in our experimentation we observe an average of $13.3\\%$\nimprovement in operation count reduction on a benchmark of GPT-2 training\ngraphs and $10.4\\%$ improvement on a diverse benchmark including GPT-2, BERT,\nand ResNet graphs using the proposed approach over the compiler's default phase\nordering.",
            "author": [
                "Milan Ganai",
                "Haichen Li",
                "Theodore Enns",
                "Yida Wang",
                "Randy Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14364v1",
                "http://arxiv.org/pdf/2308.14364v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14356v2",
            "title": "A Transmit-Receive Parameter Separable Electromagnetic Channel Model for\n  LoS Holographic MIMO",
            "updated": "2023-08-29T16:08:39Z",
            "published": "2023-08-28T07:04:30Z",
            "summary": "To support the extremely high spectral efficiency and energy efficiency\nrequirements, and emerging applications of future wireless communications,\nholographic multiple-input multiple-output (H-MIMO) technology is envisioned as\none of the most promising enablers. It can potentially bring extra\ndegrees-of-freedom for communications and signal processing, including spatial\nmultiplexing in line-of-sight (LoS) channels and electromagnetic (EM) field\nprocessing performed using specialized devices, to attain the fundamental\nlimits of wireless communications. In this context, EM-domain channel modeling\nis critical to harvest the benefits offered by H-MIMO. Existing EM-domain\nchannel models are built based on the tensor Green function, which require\nprior knowledge of the global position and/or the relative distances and\ndirections of the transmit/receive antenna elements. Such knowledge may be\ndifficult to acquire in real-world applications due to extensive measurements\nneeded for obtaining this data. To overcome this limitation, we propose a\ntransmit-receive parameter separable channel model methodology in which the\nEM-domain (or holographic) channel can be simply acquired from the\ndistance/direction measured between the center-points between the transmit and\nreceive surfaces, and the local positions between the transmit and receive\nelements, thus avoiding extensive global parameter measurements. Analysis and\nnumerical results showcase the effectiveness of the proposed channel modeling\napproach in approximating the H-MIMO channel, and achieving the theoretical\nchannel capacity.",
            "author": [
                "Tierui Gong",
                "Chongwen Huang",
                "Jiguang He",
                "Marco Di Renzo",
                "M\u00e9rouane Debbah",
                "Chau Yuen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14356v2",
                "http://arxiv.org/pdf/2308.14356v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14355v1",
            "title": "Can Transformer and GNN Help Each Other?",
            "updated": "2023-08-28T07:03:08Z",
            "published": "2023-08-28T07:03:08Z",
            "summary": "Although Transformer has achieved great success in natural language process\nand computer vision, it has difficulty generalizing to medium and large-scale\ngraph data for two important reasons: (i) High complexity. (ii) Failing to\ncapture the complex and entangled structure information. In graph\nrepresentation learning, Graph Neural Networks(GNNs) can fuse the graph\nstructure and node attributes but have limited receptive fields. Therefore, we\nquestion whether can we combine Transformers and GNNs to help each other. In\nthis paper, we propose a new model named TransGNN where the Transformer layer\nand GNN layer are used alternately to improve each other. Specifically, to\nexpand the receptive field and disentangle the information aggregation from\nedges, we propose using Transformer to aggregate more relevant nodes'\ninformation to improve the message passing of GNNs. Besides, to capture the\ngraph structure information, we utilize positional encoding and make use of the\nGNN layer to fuse the structure into node attributes, which improves the\nTransformer in graph data. We also propose to sample the most relevant nodes\nfor Transformer and two efficient samples update strategies to lower the\ncomplexity. At last, we theoretically prove that TransGNN is more expressive\nthan GNNs only with extra linear complexity. The experiments on eight datasets\ncorroborate the effectiveness of TransGNN on node and graph classification\ntasks.",
            "author": [
                "Peiyan Zhang",
                "Yuchen Yan",
                "Chaozhuo Li",
                "Senzhang Wang",
                "Xing Xie",
                "Sunghun Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14355v1",
                "http://arxiv.org/pdf/2308.14355v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR",
                "H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14353v1",
            "title": "ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large\n  Language Models",
            "updated": "2023-08-28T06:56:44Z",
            "published": "2023-08-28T06:56:44Z",
            "summary": "The unprecedented performance of large language models (LLMs) requires\ncomprehensive and accurate evaluation. We argue that for LLMs evaluation,\nbenchmarks need to be comprehensive and systematic. To this end, we propose the\nZhuJiu benchmark, which has the following strengths: (1) Multi-dimensional\nability coverage: We comprehensively evaluate LLMs across 7 ability dimensions\ncovering 51 tasks. Especially, we also propose a new benchmark that focuses on\nknowledge ability of LLMs. (2) Multi-faceted evaluation methods collaboration:\nWe use 3 different yet complementary evaluation methods to comprehensively\nevaluate LLMs, which can ensure the authority and accuracy of the evaluation\nresults. (3) Comprehensive Chinese benchmark: ZhuJiu is the pioneering\nbenchmark that fully assesses LLMs in Chinese, while also providing equally\nrobust evaluation abilities in English. (4) Avoiding potential data leakage: To\navoid data leakage, we construct evaluation data specifically for 37 tasks. We\nevaluate 10 current mainstream LLMs and conduct an in-depth discussion and\nanalysis of their results. The ZhuJiu benchmark and open-participation\nleaderboard are publicly released at http://www.zhujiu-benchmark.com/ and we\nalso provide a demo video at https://youtu.be/qypkJ89L1Ic.",
            "author": [
                "Baoli Zhang",
                "Haining Xie",
                "Pengfan Du",
                "Junhao Chen",
                "Pengfei Cao",
                "Yubo Chen",
                "Shengping Liu",
                "Kang Liu",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14353v1",
                "http://arxiv.org/pdf/2308.14353v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14346v1",
            "title": "DISC-MedLLM: Bridging General Large Language Models and Real-World\n  Medical Consultation",
            "updated": "2023-08-28T06:41:49Z",
            "published": "2023-08-28T06:41:49Z",
            "summary": "We propose DISC-MedLLM, a comprehensive solution that leverages Large\nLanguage Models (LLMs) to provide accurate and truthful medical response in\nend-to-end conversational healthcare services. To construct high-quality\nSupervised Fine-Tuning (SFT) datasets, we employ three strategies: utilizing\nmedical knowledge-graphs, reconstructing real-world dialogues, and\nincorporating human-guided preference rephrasing. These datasets are\ninstrumental in training DISC-MedLLM, surpassing existing medical LLMs in both\nsingle-turn and multi-turn consultation scenarios. Extensive experimental\nresults demonstrate the effectiveness of the proposed model in bridging the gap\nbetween general language models and real-world medical consultation.\nAdditionally, we release the constructed dataset and model weights to further\ncontribute to research and development. Further details and resources can be\nfound at https://github.com/FudanDISC/DISC-MedLLM",
            "author": [
                "Zhijie Bao",
                "Wei Chen",
                "Shengze Xiao",
                "Kuang Ren",
                "Jiaao Wu",
                "Cheng Zhong",
                "Jiajie Peng",
                "Xuanjing Huang",
                "Zhongyu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14346v1",
                "http://arxiv.org/pdf/2308.14346v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14343v1",
            "title": "Buy when? Survival machine learning model comparison for purchase timing",
            "updated": "2023-08-28T06:40:02Z",
            "published": "2023-08-28T06:40:02Z",
            "summary": "The value of raw data is unlocked by converting it into information and\nknowledge that drives decision-making. Machine Learning (ML) algorithms are\ncapable of analysing large datasets and making accurate predictions. Market\nsegmentation, client lifetime value, and marketing techniques have all made use\nof machine learning. This article examines marketing machine learning\ntechniques such as Support Vector Machines, Genetic Algorithms, Deep Learning,\nand K-Means. ML is used to analyse consumer behaviour, propose items, and make\nother customer choices about whether or not to purchase a product or service,\nbut it is seldom used to predict when a person will buy a product or a basket\nof products. In this paper, the survival models Kernel SVM, DeepSurv, Survival\nRandom Forest, and MTLR are examined to predict tine-purchase individual\ndecisions. Gender, Income, Location, PurchaseHistory, OnlineBehavior,\nInterests, PromotionsDiscounts and CustomerExperience all have an influence on\npurchasing time, according to the analysis. The study shows that the DeepSurv\nmodel predicted purchase completion the best. These insights assist marketers\nin increasing conversion rates.",
            "author": [
                "Diego Vallarino"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14343v1",
                "http://arxiv.org/pdf/2308.14343v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14340v1",
            "title": "HRGCN: Heterogeneous Graph-level Anomaly Detection with Hierarchical\n  Relation-augmented Graph Neural Networks",
            "updated": "2023-08-28T06:32:09Z",
            "published": "2023-08-28T06:32:09Z",
            "summary": "This work considers the problem of heterogeneous graph-level anomaly\ndetection. Heterogeneous graphs are commonly used to represent behaviours\nbetween different types of entities in complex industrial systems for capturing\nas much information about the system operations as possible. Detecting\nanomalous heterogeneous graphs from a large set of system behaviour graphs is\ncrucial for many real-world applications like online web/mobile service and\ncloud access control. To address the problem, we propose HRGCN, an unsupervised\ndeep heterogeneous graph neural network, to model complex heterogeneous\nrelations between different entities in the system for effectively identifying\nthese anomalous behaviour graphs. HRGCN trains a hierarchical\nrelation-augmented Heterogeneous Graph Neural Network (HetGNN), which learns\nbetter graph representations by modelling the interactions among all the system\nentities and considering both source-to-destination entity (node) types and\ntheir relation (edge) types. Extensive evaluation on two real-world application\ndatasets shows that HRGCN outperforms state-of-the-art competing anomaly\ndetection approaches. We further present a real-world industrial case study to\njustify the effectiveness of HRGCN in detecting anomalous (e.g., congested)\nnetwork devices in a mobile communication service. HRGCN is available at\nhttps://github.com/jiaxililearn/HRGCN.",
            "author": [
                "Jiaxi Li",
                "Guansong Pang",
                "Ling Chen",
                "Mohammad-Reza Namazi-Rad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14340v1",
                "http://arxiv.org/pdf/2308.14340v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14338v1",
            "title": "Fair Few-shot Learning with Auxiliary Sets",
            "updated": "2023-08-28T06:31:37Z",
            "published": "2023-08-28T06:31:37Z",
            "summary": "Recently, there has been a growing interest in developing machine learning\n(ML) models that can promote fairness, i.e., eliminating biased predictions\ntowards certain populations (e.g., individuals from a specific demographic\ngroup). Most existing works learn such models based on well-designed fairness\nconstraints in optimization. Nevertheless, in many practical ML tasks, only\nvery few labeled data samples can be collected, which can lead to inferior\nfairness performance. This is because existing fairness constraints are\ndesigned to restrict the prediction disparity among different sensitive groups,\nbut with few samples, it becomes difficult to accurately measure the disparity,\nthus rendering ineffective fairness optimization. In this paper, we define the\nfairness-aware learning task with limited training samples as the \\emph{fair\nfew-shot learning} problem. To deal with this problem, we devise a novel\nframework that accumulates fairness-aware knowledge across different\nmeta-training tasks and then generalizes the learned knowledge to meta-test\ntasks. To compensate for insufficient training samples, we propose an essential\nstrategy to select and leverage an auxiliary set for each meta-test task. These\nauxiliary sets contain several labeled training samples that can enhance the\nmodel performance regarding fairness in meta-test tasks, thereby allowing for\nthe transfer of learned useful fairness-oriented knowledge to meta-test tasks.\nFurthermore, we conduct extensive experiments on three real-world datasets to\nvalidate the superiority of our framework against the state-of-the-art\nbaselines.",
            "author": [
                "Song Wang",
                "Jing Ma",
                "Lu Cheng",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14338v1",
                "http://arxiv.org/pdf/2308.14338v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14334v2",
            "title": "MetaWeather: Few-Shot Weather-Degraded Image Restoration via Degradation\n  Pattern Matching",
            "updated": "2023-09-05T07:35:58Z",
            "published": "2023-08-28T06:25:40Z",
            "summary": "Real-world vision tasks frequently suffer from the appearance of adverse\nweather conditions including rain, fog, snow, and raindrops in captured images.\nRecently, several generic methods for restoring weather-degraded images have\nbeen proposed, aiming to remove multiple types of adverse weather effects\npresent in the images. However, these methods have considered weather as\ndiscrete and mutually exclusive variables, leading to failure in generalizing\nto unforeseen weather conditions beyond the scope of the training data, such as\nthe co-occurrence of rain, fog, and raindrops. To this end, weather-degraded\nimage restoration models should have flexible adaptability to the current\nunknown weather condition to ensure reliable and optimal performance. The\nadaptation method should also be able to cope with data scarcity for real-world\nadaptation. This paper proposes MetaWeather, a few-shot weather-degraded image\nrestoration method for arbitrary weather conditions. For this, we devise the\ncore piece of MetaWeather, coined Degradation Pattern Matching Module (DPMM),\nwhich leverages representations from a few-shot support set by matching\nfeatures between input and sample images under new weather conditions. In\naddition, we build meta-knowledge with episodic meta-learning on top of our\nMetaWeather architecture to provide flexible adaptability. In the meta-testing\nphase, we adopt a parameter-efficient fine-tuning method to preserve the\nprebuilt knowledge and avoid the overfitting problem. Experiments on the BID\nTask II.A dataset show our method achieves the best performance on PSNR and\nSSIM compared to state-of-the-art image restoration methods. Code is available\nat (TBA).",
            "author": [
                "Youngrae Kim",
                "Younggeol Cho",
                "Thanh-Tung Nguyen",
                "Dongman Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14334v2",
                "http://arxiv.org/pdf/2308.14334v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14332v1",
            "title": "Attention-Guided Lidar Segmentation and Odometry Using Image-to-Point\n  Cloud Saliency Transfer",
            "updated": "2023-08-28T06:22:10Z",
            "published": "2023-08-28T06:22:10Z",
            "summary": "LiDAR odometry estimation and 3D semantic segmentation are crucial for\nautonomous driving, which has achieved remarkable advances recently. However,\nthese tasks are challenging due to the imbalance of points in different\nsemantic categories for 3D semantic segmentation and the influence of dynamic\nobjects for LiDAR odometry estimation, which increases the importance of using\nrepresentative/salient landmarks as reference points for robust feature\nlearning. To address these challenges, we propose a saliency-guided approach\nthat leverages attention information to improve the performance of LiDAR\nodometry estimation and semantic segmentation models. Unlike in the image\ndomain, only a few studies have addressed point cloud saliency information due\nto the lack of annotated training data. To alleviate this, we first present a\nuniversal framework to transfer saliency distribution knowledge from color\nimages to point clouds, and use this to construct a pseudo-saliency dataset\n(i.e. FordSaliency) for point clouds. Then, we adopt point cloud-based\nbackbones to learn saliency distribution from pseudo-saliency labels, which is\nfollowed by our proposed SalLiDAR module. SalLiDAR is a saliency-guided 3D\nsemantic segmentation model that integrates saliency information to improve\nsegmentation performance. Finally, we introduce SalLONet, a self-supervised\nsaliency-guided LiDAR odometry network that uses the semantic and saliency\npredictions of SalLiDAR to achieve better odometry estimation. Our extensive\nexperiments on benchmark datasets demonstrate that the proposed SalLiDAR and\nSalLONet models achieve state-of-the-art performance against existing methods,\nhighlighting the effectiveness of image-to-LiDAR saliency knowledge transfer.\nSource code will be available at https://github.com/nevrez/SalLONet.",
            "author": [
                "Guanqun Ding",
                "Nevrez Imamoglu",
                "Ali Caglayan",
                "Masahiro Murakawa",
                "Ryosuke Nakamura"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14332v1",
                "http://arxiv.org/pdf/2308.14332v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14326v1",
            "title": "Towards solving ontological dissonance using network graphs",
            "updated": "2023-08-28T06:10:26Z",
            "published": "2023-08-28T06:10:26Z",
            "summary": "Data Spaces are an emerging concept for the trusted implementation of\ndata-based applications and business models, offering a high degree of\nflexibility and sovereignty to all stakeholders. As Data Spaces are currently\nemerging in different domains such as mobility, health or food, semantic\ninterfaces need to be identified and implemented to ensure the technical\ninteroperability of these Data Spaces. This paper consolidates data models from\n13 different domains and analyzes the ontological dissonance of these domains.\nUsing a network graph, central data models and ontology attributes are\nidentified, while the semantic heterogeneity of these domains is described\nqualitatively. The research outlook describes how these results help to connect\ndifferent Data Spaces across domains.",
            "author": [
                "Maximilian Staebler",
                "Frank Koester",
                "Christoph Schlueter-Langdon"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14326v1",
                "http://arxiv.org/pdf/2308.14326v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14323v1",
            "title": "Institutional mapping and causal analysis of avalanche vulnerable areas\n  based on multi-source data",
            "updated": "2023-08-28T06:06:38Z",
            "published": "2023-08-28T06:06:38Z",
            "summary": "Avalanche disaster is a major natural disaster that seriously threatens the\nnational infrastructure and personnel's life safety. For a long time, the\nresearch of avalanche disaster prediction in the world is insufficient, there\nare only some basic models and basic conditions of occurrence, and there is no\nlong series and wide range of avalanche disaster prediction products. Based on\n7 different bands and different types of multi-source remote sensing data,this\nstudy combined with existing avalanche occurrence models, field investigation\nand statistical data to analyze the causes of avalanche. The U-net\nconvolutional neural network and threshold analysis were used to extract the\ndistribution of long time series avalanch-prone areas in two study areas,\nHeiluogou in Sichuan Province and along the Zangpo River in Palong, Tibet\nAutonomous Region. In addition, the relationship between earthquake magnitude\nand spatial distribution and avalanche occurrence is also analyzed in this\nstudy. This study will also continue to build a prior knowledge base of\navalanche occurrence conditions, improve the prediction accuracy of the two\nmethods, and produce products in long time series interannual avalanch-prone\nareas in southwest China, including Sichuan Province, Yunnan Province, and\nTibet Autonomous Region. The resulting products will provide high-precision\navalanche prediction and safety assurance for engineering construction and\nmountaineering activities in Southwest China.",
            "author": [
                "Zexuan Zhou",
                "Bingqi Ma",
                "Jianwei Zhu",
                "Zhizhong Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14323v1",
                "http://arxiv.org/pdf/2308.14323v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14322v1",
            "title": "Machine Unlearning Methodology base on Stochastic Teacher Network",
            "updated": "2023-08-28T06:05:23Z",
            "published": "2023-08-28T06:05:23Z",
            "summary": "The rise of the phenomenon of the \"right to be forgotten\" has prompted\nresearch on machine unlearning, which grants data owners the right to actively\nwithdraw data that has been used for model training, and requires the\nelimination of the contribution of that data to the model. A simple method to\nachieve this is to use the remaining data to retrain the model, but this is not\nacceptable for other data owners who continue to participate in training.\nExisting machine unlearning methods have been found to be ineffective in\nquickly removing knowledge from deep learning models. This paper proposes using\na stochastic network as a teacher to expedite the mitigation of the influence\ncaused by forgotten data on the model. We performed experiments on three\ndatasets, and the findings demonstrate that our approach can efficiently\nmitigate the influence of target data on the model within a single epoch. This\nallows for one-time erasure and reconstruction of the model, and the\nreconstruction model achieves the same performance as the retrained model.",
            "author": [
                "Xulong Zhang",
                "Jianzong Wang",
                "Ning Cheng",
                "Yifu Sun",
                "Chuanyao Zhang",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14322v1",
                "http://arxiv.org/pdf/2308.14322v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14321v1",
            "title": "Leveraging A Medical Knowledge Graph into Large Language Models for\n  Diagnosis Prediction",
            "updated": "2023-08-28T06:05:18Z",
            "published": "2023-08-28T06:05:18Z",
            "summary": "Electronic Health Records (EHRs) and routine documentation practices play a\nvital role in patients' daily care, providing a holistic record of health,\ndiagnoses, and treatment. However, complex and verbose EHR narratives overload\nhealthcare providers, risking diagnostic inaccuracies. While Large Language\nModels (LLMs) have showcased their potential in diverse language tasks, their\napplication in the healthcare arena needs to ensure the minimization of\ndiagnostic errors and the prevention of patient harm. In this paper, we outline\nan innovative approach for augmenting the proficiency of LLMs in the realm of\nautomated diagnosis generation, achieved through the incorporation of a medical\nknowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the\nclinical diagnostic reasoning process. We derive the KG from the National\nLibrary of Medicine's Unified Medical Language System (UMLS), a robust\nrepository of biomedical knowledge. Our method negates the need for\npre-training and instead leverages the KG as an auxiliary instrument aiding in\nthe interpretation and summarization of complex medical concepts. Using\nreal-world hospital datasets, our experimental results demonstrate that the\nproposed approach of combining LLMs with KG has the potential to improve the\naccuracy of automated diagnosis generation. More importantly, our approach\noffers an explainable diagnostic pathway, edging us closer to the realization\nof AI-augmented diagnostic decision support systems.",
            "author": [
                "Yanjun Gao",
                "Ruizhe Li",
                "John Caskey",
                "Dmitriy Dligach",
                "Timothy Miller",
                "Matthew M. Churpek",
                "Majid Afshar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14321v1",
                "http://arxiv.org/pdf/2308.14321v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14316v1",
            "title": "UniPT: Universal Parallel Tuning for Transfer Learning with Efficient\n  Parameter and Memory",
            "updated": "2023-08-28T05:38:43Z",
            "published": "2023-08-28T05:38:43Z",
            "summary": "Fine-tuning pre-trained models has emerged as a powerful technique in\nnumerous domains, owing to its ability to leverage enormous pre-existing\nknowledge and achieve remarkable performance on downstream tasks. However,\nupdating the parameters of entire networks is computationally intensive.\nAlthough state-of-the-art parameter-efficient transfer learning (PETL) methods\nsignificantly reduce the trainable parameters and storage demand, almost all of\nthem still need to back-propagate the gradients through large pre-trained\nnetworks. This memory-extensive characteristic extremely limits the\napplicability of PETL methods in real-world scenarios. To this end, we propose\na new memory-efficient PETL strategy, dubbed Universal Parallel Tuning (UniPT).\nSpecifically, we facilitate the transfer process via a lightweight learnable\nparallel network, which consists of two modules: 1) A parallel interaction\nmodule that decouples the inherently sequential connections and processes the\nintermediate activations detachedly of the pre-trained network. 2) A confidence\naggregation module that learns optimal strategies adaptively for integrating\ncross-layer features. We evaluate UniPT with different backbones (e.g.,\nVSE$\\infty$, CLIP4Clip, Clip-ViL, and MDETR) on five challenging\nvision-and-language tasks (i.e., image-text retrieval, video-text retrieval,\nvisual question answering, compositional question answering, and visual\ngrounding). Extensive ablations on ten datasets have validated that our UniPT\ncan not only dramatically reduce memory consumption and outperform the best\nmemory-efficient competitor, but also achieve higher performance than existing\nPETL methods in a low-memory scenario on different architectures. Our code is\npublicly available at: https://github.com/Paranioar/UniPT.",
            "author": [
                "Haiwen Diao",
                "Bo Wan",
                "Ying Zhang",
                "Xu Jia",
                "Huchuan Lu",
                "Long Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14316v1",
                "http://arxiv.org/pdf/2308.14316v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14311v3",
            "title": "Spread Control Method on Unknown Networks Based on Hierarchical\n  Reinforcement Learning",
            "updated": "2023-10-12T08:26:55Z",
            "published": "2023-08-28T05:29:49Z",
            "summary": "Epidemics such as COVID-19 pose serious threats to public health and our\nsociety, and it is critical to investigate effective methods to control the\nspread of epidemics over networks. Prior works on epidemic control often assume\ncomplete knowledge of network structures, a presumption seldom valid in\nreal-world situations. In this paper, we study epidemic control on networks\nwith unknown structures, and propose a hierarchical reinforcement learning\nframework for joint network structure exploration and epidemic control. To\nreduce the action space and achieve computation tractability, our proposed\nframework contains three modules: the Policy Selection Module, which determines\nwhether to explore the structure or remove nodes to control the epidemic; the\nExplore Module, responsible for selecting nodes to explore; and the Remove\nModule, which decides which nodes to remove to stop the epidemic spread.\nSimulation results show that our proposed method outperforms baseline methods.",
            "author": [
                "Wenxiang Dong",
                "Zhanjiang Chen",
                "H. Vicky Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14311v3",
                "http://arxiv.org/pdf/2308.14311v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14307v1",
            "title": "How much Training is Needed in Downlink Cell-Free mMIMO under LoS/NLoS\n  channels?",
            "updated": "2023-08-28T04:57:29Z",
            "published": "2023-08-28T04:57:29Z",
            "summary": "The assumption that no LoS channels exist between wireless access\npoints~(APs) and user equipments~(UEs) becomes questionable in the context of\nthe recent developments in the direction of cell free massive multiple input\nmultiple output MIMO~(CF-mMIMO) systems. In CF-mMIMO systems, the access point\ndensity is assumed to be comparable to, or much larger than the the user\ndensity, thereby leading to the possibility of existence of LoS links between\nthe UEs and the APs, depending on the local propagation conditions. In this\npaper, we compare the rates achievable by CF-mMIMO systems under probabilistic\nLoS/ NLos channels, with and without acquiring the channel state\ninformation~(CSI) of the fast fading components. We show that, under\nsufficiently large AP densities, statistical beamforming that does not require\nthe knowledge about the fast fading components of the channels, performs almost\nat par with full beamforming, utilizing the information about the fast fading\nchannel coefficients, thus potentially avoiding the need for training during\nevery frame. We validate our results via detailed Monte Carlo simulations, and\nalso elaborate the conditions under which statistical beamforming can be\nsuccessfully employed in massive MIMO systems with LoS/ NLoS channels.",
            "author": [
                "Sai Manikanta Rishi Rani",
                "Ribhu Chopra",
                "Kumar Appaiah"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14307v1",
                "http://arxiv.org/pdf/2308.14307v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14296v1",
            "title": "RecMind: Large Language Model Powered Agent For Recommendation",
            "updated": "2023-08-28T04:31:04Z",
            "published": "2023-08-28T04:31:04Z",
            "summary": "Recent advancements in instructing Large Language Models (LLMs) to utilize\nexternal tools and execute multi-step plans have significantly enhanced their\nability to solve intricate tasks, ranging from mathematical problems to\ncreative writing. Yet, there remains a notable gap in studying the capacity of\nLLMs in responding to personalized queries such as a recommendation request. To\nbridge this gap, we have designed an LLM-powered autonomous recommender agent,\nRecMind, which is capable of providing precise personalized recommendations\nthrough careful planning, utilizing tools for obtaining external knowledge, and\nleveraging individual data. We propose a novel algorithm, Self-Inspiring, to\nimprove the planning ability of the LLM agent. At each intermediate planning\nstep, the LLM 'self-inspires' to consider all previously explored states to\nplan for next step. This mechanism greatly improves the model's ability to\ncomprehend and utilize historical planning information for recommendation. We\nevaluate RecMind's performance in various recommendation scenarios, including\nrating prediction, sequential recommendation, direct recommendation,\nexplanation generation, and review summarization. Our experiment shows that\nRecMind outperforms existing zero/few-shot LLM-based recommendation methods in\ndifferent recommendation tasks and achieves competitive performance to a recent\nmodel P5, which requires fully pre-train for the recommendation tasks.",
            "author": [
                "Yancheng Wang",
                "Ziyan Jiang",
                "Zheng Chen",
                "Fan Yang",
                "Yingxue Zhou",
                "Eunah Cho",
                "Xing Fan",
                "Xiaojiang Huang",
                "Yanbin Lu",
                "Yingzhen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14296v1",
                "http://arxiv.org/pdf/2308.14296v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.15492v1",
            "title": "Deep Learning and Bayesian inference for Inverse Problems",
            "updated": "2023-08-28T04:27:45Z",
            "published": "2023-08-28T04:27:45Z",
            "summary": "Inverse problems arise anywhere we have indirect measurement. As, in general\nthey are ill-posed, to obtain satisfactory solutions for them needs prior\nknowledge. Classically, different regularization methods and Bayesian inference\nbased methods have been proposed. As these methods need a great number of\nforward and backward computations, they become costly in computation, in\nparticular, when the forward or generative models are complex and the\nevaluation of the likelihood becomes very costly. Using Deep Neural Network\nsurrogate models and approximate computation can become very helpful. However,\naccounting for the uncertainties, we need first understand the Bayesian Deep\nLearning and then, we can see how we can use them for inverse problems. In this\nwork, we focus on NN, DL and more specifically the Bayesian DL particularly\nadapted for inverse problems. We first give details of Bayesian DL approximate\ncomputations with exponential families, then we will see how we can use them\nfor inverse problems. We consider two cases: First the case where the forward\noperator is known and used as physics constraint, the second more general data\ndriven DL methods. keyword: Neural Network, Variational Bayesian inference,\nBayesian Deep Learning (DL), Inverse problems, Physics based DL.",
            "author": [
                "Ali Mohammad-Djafari",
                "Ning Chu",
                "Li Wang",
                "Liang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15492v1",
                "http://arxiv.org/pdf/2308.15492v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04485v1",
            "title": "An 852 nm Faraday laser with 8 kHz linewidth based on corner-cube\n  retroreflector",
            "updated": "2023-08-28T04:09:24Z",
            "published": "2023-08-28T04:09:24Z",
            "summary": "A single-mode Cs atom 852 nm Faraday laser based on the corner-cube reflector\nfeedback is first demonstrated to our best knowledge. Using the corner-cube\nreflector as external cavity feedback in Faraday laser, the robustness can be\ngreatly improved. This Faraday laser can always achieve laser oscillation\nunless the angle between incident light and the optical axis of corner-cube\nretroreflector is beyond the plus or minus 3{\\deg} range. Furthermore, the\nFaraday laser achieves single-mode operation within the current range of 100 mA\n, and its output wavelength is automatically limited to the vicinity of the Cs\natomic transition lines. The wavelength fluctuation range is limited to plus or\nminus 1.2 pm within 9 hours under +3{\\deg} rotation angle. Moreover, the most\nprobable linewidth is 7.97 kHz measured by heterodyne beating. The Faraday\nlaser with high robustness as well as narrow linewidth can be widely used in\nquantum precision measurement fields including quantum optics, atomic clocks,\natomic magnetometers, cold atoms, and atomic gravimeters, etc.",
            "author": [
                "Zhiyang Wang",
                "Zijie Liu",
                "Jianxiang Miao",
                "Hangbo Shi",
                "Xiaomin Qin",
                "Xiaolei Guan",
                "Zhihong Gao",
                "Tiantian Shi",
                "Jingbiao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04485v1",
                "http://arxiv.org/pdf/2309.04485v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14287v1",
            "title": "Halin's Infinite Ray Theorems: Complexity and Reverse Mathematics:\n  Version E",
            "updated": "2023-08-28T03:57:42Z",
            "published": "2023-08-28T03:57:42Z",
            "summary": "Halin [1965] proved that if a graph has $n$ many pairwise disjoint rays for\neach $n$ then it has infinitely many pairwise disjoint rays. We analyze the\ncomplexity of this and other similar results in terms of computable and proof\ntheoretic complexity. The statement of Halin's theorem and the construction\nproving it seem very much like standard versions of compactness arguments such\nas K\\\"{o}nig's Lemma. Those results, while not computable, are relatively\nsimple. They only use arithmetic procedures or, equivalently, finitely many\niterations of the Turing jump. We show that several Halin type theorems are\nmuch more complicated. They are among the theorems of hyperarithmetic analysis.\nSuch theorems imply the ability to iterate the Turing jump along any computable\nwell ordering. Several important logical principles in this class have been\nextensively studied beginning with work of Kreisel, H. Friedman, Steel and\nothers in the 1960s and 1970s. Until now, only one purely mathematical example\nwas known. Our work provides many more and so answers Question 30 of\nMontalb\\'{a}n's Open Questions in Reverse Mathematics [2011]. Some of these\ntheorems including ones in Halin [1965] are also shown to have unusual proof\ntheoretic strength as well.",
            "author": [
                "James S. Barnes",
                "Jun Le Goh",
                "Richard A. Shore"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14287v1",
                "http://arxiv.org/pdf/2308.14287v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "math.CO",
                "05C63, 03D55, 03B30 (Primary) 03D80, 03F35, 05C38, 05C69, 05C70\n  (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14286v1",
            "title": "Bridging Cross-task Protocol Inconsistency for Distillation in Dense\n  Object Detection",
            "updated": "2023-08-28T03:57:37Z",
            "published": "2023-08-28T03:57:37Z",
            "summary": "Knowledge distillation (KD) has shown potential for learning compact models\nin dense object detection. However, the commonly used softmax-based\ndistillation ignores the absolute classification scores for individual\ncategories. Thus, the optimum of the distillation loss does not necessarily\nlead to the optimal student classification scores for dense object detectors.\nThis cross-task protocol inconsistency is critical, especially for dense object\ndetectors, since the foreground categories are extremely imbalanced. To address\nthe issue of protocol differences between distillation and classification, we\npropose a novel distillation method with cross-task consistent protocols,\ntailored for the dense object detection. For classification distillation, we\naddress the cross-task protocol inconsistency problem by formulating the\nclassification logit maps in both teacher and student models as multiple\nbinary-classification maps and applying a binary-classification distillation\nloss to each map. For localization distillation, we design an IoU-based\nLocalization Distillation Loss that is free from specific network structures\nand can be compared with existing localization distillation losses. Our\nproposed method is simple but effective, and experimental results demonstrate\nits superiority over existing methods. Code is available at\nhttps://github.com/TinyTigerPan/BCKD.",
            "author": [
                "Longrong Yang",
                "Xianpan Zhou",
                "Xuewei Li",
                "Liang Qiao",
                "Zheyang Li",
                "Ziwei Yang",
                "Gaoang Wang",
                "Xi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14286v1",
                "http://arxiv.org/pdf/2308.14286v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14284v3",
            "title": "LLM Powered Sim-to-real Transfer for Traffic Signal Control",
            "updated": "2023-10-26T02:15:31Z",
            "published": "2023-08-28T03:49:13Z",
            "summary": "Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks\naiming to provide efficient transportation and mitigate congestion waste. In\nrecent, promising results have been attained by Reinforcement Learning (RL)\nmethods through trial and error in simulators, bringing confidence in solving\ncities' congestion headaches. However, there still exist performance gaps when\nsimulator-trained policies are deployed to the real world. This issue is mainly\nintroduced by the system dynamic difference between the training simulator and\nthe real-world environments. The Large Language Models (LLMs) are trained on\nmass knowledge and proved to be equipped with astonishing inference abilities.\nIn this work, we leverage LLMs to understand and profile the system dynamics by\na prompt-based grounded action transformation. Accepting the cloze prompt\ntemplate, and then filling in the answer based on accessible context, the\npre-trained LLM's inference ability is exploited and applied to understand how\nweather conditions, traffic states, and road types influence traffic dynamics,\nbeing aware of this, the policies' action is taken and grounded based on\nrealistic dynamics, thus help the agent learn a more realistic policy. We\nconduct experiments using DQN to show the effectiveness of the proposed\nPromptGAT's ability in mitigating the performance gap from simulation to\nreality (sim-to-real).",
            "author": [
                "Longchao Da",
                "Minchiuan Gao",
                "Hao Mei",
                "Hua Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14284v3",
                "http://arxiv.org/pdf/2308.14284v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "H.4.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14279v3",
            "title": "Sampling unknown large networks restricted by low sampling rates",
            "updated": "2023-09-13T07:03:19Z",
            "published": "2023-08-28T03:26:21Z",
            "summary": "Graph sampling plays an important role in data mining for large networks.\nSpecifically, larger networks often correspond to lower sampling rates. Under\nthe situation, traditional traversal-based samplings for large networks usually\nhave an excessive preference for densely-connected network core nodes. Aim at\nthis issue, this paper proposes a sampling method for unknown networks at low\nsampling rates, called SLSR, which first adopts a random node sampling to\nevaluate a degree threshold, utilized to distinguish the core from periphery,\nand the average degree in unknown networks, and then runs a double-layer\nsampling strategy on the core and periphery. SLSR is simple that results in a\nhigh time efficiency, but experimental evaluation confirms that the proposed\nmethod can accurately preserve many critical structures of unknown large\nnetworks at sampling rates not exceeding 10%.",
            "author": [
                "Bo Jiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14279v3",
                "http://arxiv.org/pdf/2308.14279v3"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14280v2",
            "title": "FonMTL: Towards Multitask Learning for the Fon Language",
            "updated": "2023-09-11T22:51:25Z",
            "published": "2023-08-28T03:26:21Z",
            "summary": "The Fon language, spoken by an average 2 million of people, is a truly\nlow-resourced African language, with a limited online presence, and existing\ndatasets (just to name but a few). Multitask learning is a learning paradigm\nthat aims to improve the generalization capacity of a model by sharing\nknowledge across different but related tasks: this could be prevalent in very\ndata-scarce scenarios. In this paper, we present the first explorative approach\nto multitask learning, for model capabilities enhancement in Natural Language\nProcessing for the Fon language. Specifically, we explore the tasks of Named\nEntity Recognition (NER) and Part of Speech Tagging (POS) for Fon. We leverage\ntwo language model heads as encoders to build shared representations for the\ninputs, and we use linear layers blocks for classification relative to each\ntask. Our results on the NER and POS tasks for Fon, show competitive (or\nbetter) performances compared to several multilingual pretrained language\nmodels finetuned on single tasks. Additionally, we perform a few ablation\nstudies to leverage the efficiency of two different loss combination strategies\nand find out that the equal loss weighting approach works best in our case. Our\ncode is open-sourced at https://github.com/bonaventuredossou/multitask_fon.",
            "author": [
                "Bonaventure F. P. Dossou",
                "Iffanice Houndayi",
                "Pamely Zantou",
                "Gilles Hacheme"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14280v2",
                "http://arxiv.org/pdf/2308.14280v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14269v1",
            "title": "Utilizing Mood-Inducing Background Music in Human-Robot Interaction",
            "updated": "2023-08-28T02:54:05Z",
            "published": "2023-08-28T02:54:05Z",
            "summary": "Past research has clearly established that music can affect mood and that\nmood affects emotional and cognitive processing, and thus decision-making. It\nfollows that if a robot interacting with a person needs to predict the person's\nbehavior, knowledge of the music the person is listening to when acting is a\npotentially relevant feature. To date, however, there has not been any concrete\nevidence that a robot can improve its human-interactive decision-making by\ntaking into account what the person is listening to. This research fills this\ngap by reporting the results of an experiment in which human participants were\nrequired to complete a task in the presence of an autonomous agent while\nlistening to background music. Specifically, the participants drove a simulated\ncar through an intersection while listening to music. The intersection was not\nempty, as another simulated vehicle, controlled autonomously, was also crossing\nthe intersection in a different direction. Our results clearly indicate that\nsuch background information can be effectively incorporated in an agent's world\nrepresentation in order to better predict people's behavior. We subsequently\nanalyze how knowledge of music impacted both participant behavior and the\nresulting learned policy.\\setcounter{footnote}{2}\\footnote{An earlier version\nof part of the material in this paper appeared originally in the first author's\nPh.D. Dissertation~\\cite{liebman2020sequential} but it has not appeared in any\npear-reviewed conference or journal.}",
            "author": [
                "Elad Liebman",
                "Peter Stone"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14269v1",
                "http://arxiv.org/pdf/2308.14269v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14267v1",
            "title": "Unleash Model Potential: Bootstrapped Meta Self-supervised Learning",
            "updated": "2023-08-28T02:49:07Z",
            "published": "2023-08-28T02:49:07Z",
            "summary": "The long-term goal of machine learning is to learn general visual\nrepresentations from a small amount of data without supervision, mimicking\nthree advantages of human cognition: i) no need for labels, ii) robustness to\ndata scarcity, and iii) learning from experience. Self-supervised learning and\nmeta-learning are two promising techniques to achieve this goal, but they both\nonly partially capture the advantages and fail to address all the problems.\nSelf-supervised learning struggles to overcome the drawbacks of data scarcity,\nwhile ignoring prior knowledge that can facilitate learning and generalization.\nMeta-learning relies on supervised information and suffers from a bottleneck of\ninsufficient learning. To address these issues, we propose a novel Bootstrapped\nMeta Self-Supervised Learning (BMSSL) framework that aims to simulate the human\nlearning process. We first analyze the close relationship between meta-learning\nand self-supervised learning. Based on this insight, we reconstruct tasks to\nleverage the strengths of both paradigms, achieving advantages i and ii.\nMoreover, we employ a bi-level optimization framework that alternates between\nsolving specific tasks with a learned ability (first level) and improving this\nability (second level), attaining advantage iii. To fully harness its power, we\nintroduce a bootstrapped target based on meta-gradient to make the model its\nown teacher. We validate the effectiveness of our approach with comprehensive\ntheoretical and empirical study.",
            "author": [
                "Jingyao Wang",
                "Zeen Song",
                "Wenwen Qiang",
                "Changwen Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14267v1",
                "http://arxiv.org/pdf/2308.14267v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14266v1",
            "title": "SalesBot 2.0: A Human-Like Intent-Guided Chit-Chat Dataset",
            "updated": "2023-08-28T02:48:49Z",
            "published": "2023-08-28T02:48:49Z",
            "summary": "In recent research on dialogue systems and corpora, there has been a\nsignificant focus on two distinct categories: task-oriented (TOD) and\nopen-domain (chit-chat) dialogues. TOD systems aim to satisfy specific user\ngoals, such as finding a movie to watch, whereas open-domain systems primarily\nfocus on generating engaging conversations. A recent study by Chiu et al.\n(2022) introduced SalesBot, which provides simulators and a dataset with\none-turn transition from chit-chat to task-oriented dialogues. However, the\npreviously generated data solely relied on BlenderBot, which raised concerns\nabout its long-turn naturalness and consistency during a conversation. To\naddress this issue, this paper aims to build SalesBot 2.0, a revised version of\nthe published data, by leveraging the commonsense knowledge of large language\nmodels (LLMs) through proper prompting. The objective is to gradually bridge\nthe gap between chit-chat and TOD towards better naturalness and consistency.\nThe newly released large-scale dataset with detailed annotations exhibits\nsmoother transitions between topics and is more human-like in terms of\nnaturalness and consistency. It can serve as a valuable resource for both\nacademic research and commercial applications. Furthermore, our proposed\nframework can be applied to generate numerous dialogues with various target\nintents.",
            "author": [
                "Wen-Yu Chang",
                "Yun-Nung Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14266v1",
                "http://arxiv.org/pdf/2308.14266v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14254v1",
            "title": "Posterior distributions of Gibbs-type priors",
            "updated": "2023-08-28T02:13:46Z",
            "published": "2023-08-28T02:13:46Z",
            "summary": "Gibbs type priors have been shown to be natural generalizations of Dirichlet\nprocess (DP) priors used for intricate applications of Bayesian nonparametric\nmethods. This includes applications to mixture models and to species sampling\nmodels arising in populations genetics. Notably these latter applications, and\nalso applications where power law behavior such as that arising in natural\nlanguage models are exhibited, provide instances where the DP model is wholly\ninadequate. Gibbs type priors include the DP, the also popular Pitman-Yor\nprocess and closely related normalized generalized gamma process as special\ncases. However, there is in fact a richer infinite class of such priors, where,\ndespite knowledge about the exchangeable marginal structures produced by\nsampling $n$ observations, descriptions of the corresponding posterior\ndistribution, a crucial component in Bayesian analysis, remain unknown. This\npaper presents descriptions of the posterior distributions for the general\nclass, utilizing a novel proof that leverages the exclusive Gibbs properties of\nthese models. The results are applied to several specific cases for further\nillustration.",
            "author": [
                "Lancelot F. James"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14254v1",
                "http://arxiv.org/pdf/2308.14254v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "math.PR",
                "stat.TH",
                "60C05, 60G09, 60G57, 60E99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14247v1",
            "title": "Draco 2: An Extensible Platform to Model Visualization Design",
            "updated": "2023-08-28T01:27:12Z",
            "published": "2023-08-28T01:27:12Z",
            "summary": "Draco introduced a constraint-based framework to model visualization design\nin an extensible and testable form. It provides a way to abstract design\nguidelines from theoretical and empirical studies and applies the knowledge in\nautomated design tools. However, Draco is challenging to use because there is\nlimited tooling and documentation. In response, we present Draco 2, the\nsuccessor with (1) a more flexible visualization specification format, (2) a\ncomprehensive test suite and documentation, and (3) flexible and convenient\nAPIs. We designed Draco 2 to be more extensible and easier to integrate into\nvisualization systems. We demonstrate these advantages and believe that they\nmake Draco 2 a platform for future research.",
            "author": [
                "Junran Yang",
                "P\u00e9ter Ferenc Gyarmati",
                "Zehua Zeng",
                "Dominik Moritz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14247v1",
                "http://arxiv.org/pdf/2308.14247v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14244v1",
            "title": "HoloFusion: Towards Photo-realistic 3D Generative Modeling",
            "updated": "2023-08-28T01:19:33Z",
            "published": "2023-08-28T01:19:33Z",
            "summary": "Diffusion-based image generators can now produce high-quality and diverse\nsamples, but their success has yet to fully translate to 3D generation:\nexisting diffusion methods can either generate low-resolution but 3D consistent\noutputs, or detailed 2D views of 3D objects but with potential structural\ndefects and lacking view consistency or realism. We present HoloFusion, a\nmethod that combines the best of these approaches to produce high-fidelity,\nplausible, and diverse 3D samples while learning from a collection of\nmulti-view 2D images only. The method first generates coarse 3D samples using a\nvariant of the recently proposed HoloDiffusion generator. Then, it\nindependently renders and upsamples a large number of views of the coarse 3D\nmodel, super-resolves them to add detail, and distills those into a single,\nhigh-fidelity implicit 3D representation, which also ensures view consistency\nof the final renders. The super-resolution network is trained as an integral\npart of HoloFusion, end-to-end, and the final distillation uses a new sampling\nscheme to capture the space of super-resolved signals. We compare our method\nagainst existing baselines, including DreamFusion, Get3D, EG3D, and\nHoloDiffusion, and achieve, to the best of our knowledge, the most realistic\nresults on the challenging CO3Dv2 dataset.",
            "author": [
                "Animesh Karnewar",
                "Niloy J. Mitra",
                "Andrea Vedaldi",
                "David Novotny"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14244v1",
                "http://arxiv.org/pdf/2308.14244v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14241v1",
            "title": "Too Many Cooks: Exploring How Graphical Perception Studies Influence\n  Visualization Recommendations in Draco",
            "updated": "2023-08-28T00:58:36Z",
            "published": "2023-08-28T00:58:36Z",
            "summary": "Findings from graphical perception can guide visualization recommendation\nalgorithms in identifying effective visualization designs. However, existing\nalgorithms use knowledge from, at best, a few studies, limiting our\nunderstanding of how complementary (or contradictory) graphical perception\nresults influence generated recommendations. In this paper, we present a\npipeline of applying a large body of graphical perception results to develop\nnew visualization recommendation algorithms and conduct an exploratory study to\ninvestigate how results from graphical perception can alter the behavior of\ndownstream algorithms. Specifically, we model graphical perception results from\n30 papers in Draco -- a framework to model visualization knowledge -- to\ndevelop new recommendation algorithms. By analyzing Draco-generated algorithms,\nwe showcase the feasibility of our method to (1) identify gaps in existing\ngraphical perception literature informing recommendation algorithms, (2)\ncluster papers by their preferred design rules and constraints, and (3)\ninvestigate why certain studies can dominate Draco's recommendations, whereas\nothers may have little influence. Given our findings, we discuss the potential\nfor mutually reinforcing advancements in graphical perception and visualization\nrecommendation research.",
            "author": [
                "Zehua Zeng",
                "Junran Yang",
                "Dominik Moritz",
                "Jeffrey Heer",
                "Leilani Battle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14241v1",
                "http://arxiv.org/pdf/2308.14241v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14232v1",
            "title": "Research Report -- Persistent Autonomy and Robot Learning Lab",
            "updated": "2023-08-27T23:29:34Z",
            "published": "2023-08-27T23:29:34Z",
            "summary": "Robots capable of performing manipulation tasks in a broad range of missions\nin unstructured environments can develop numerous applications to impact and\nenhance human life. Existing work in robot learning has shown success in\napplying conventional machine learning algorithms to enable robots for\nreplicating rather simple manipulation tasks in manufacturing, service and\nhealthcare applications, among others. However, learning robust and versatile\nmodels for complex manipulation tasks that are inherently multi-faceted and\nnaturally intricate demands algorithmic advancements in robot learning. Our\nresearch supports the long-term goal of making robots more accessible and\nserviceable to the general public by expanding robot applications to real-world\nscenarios that require systems capable of performing complex tasks. To achieve\nthis goal, we focus on identifying and investigating knowledge gaps in robot\nlearning of complex manipulation tasks by leveraging upon human-robot\ninteraction and robot learning from human instructions. This document presents\nan overview of the recent research developments in the Persistent Autonomy and\nRobot Learning (PeARL) lab at the University of Massachusetts Lowell. Here, I\nbriefly discuss different research directions, and present a few proposed\napproaches in our most recent publications. For each proposed approach, I then\nmention potential future directions that can advance the field.",
            "author": [
                "S. Reza Ahmadzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14232v1",
                "http://arxiv.org/pdf/2308.14232v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14230v1",
            "title": "Global well-posedness for the one-phase Muskat problem in 3D",
            "updated": "2023-08-27T23:26:35Z",
            "published": "2023-08-27T23:26:35Z",
            "summary": "This paper is concerned with the long time dynamics of the free boundary of a\nDarcy fluid in three space dimensions, also known as the one-phase Muskat\nproblem. The dynamics of the free boundary is governed by a nonlocal fully\nnonlinear parabolic partial differential equation. It is proven that for any\nperiodic Lipschitz graph given as initial data, the problem has a unique\nglobal-in-time solution which satisfies the equation in the strong sense.\nMoreover, all H\\\"older norms of the solution decay exponentially in time. These\nresults have been previously established in two space dimensions. This paper\naddresses new challenges to extend the results to the more difficult three\ndimensional setting. The approach developed is critical in three space\ndimensions and crucially relies on Dahlberg-Kenig's $W^{1, 2+\\varepsilon}$\noptimal regularity for layer potentials together with delicate structures of\nthe Dirichlet-to-Neumann operator and layer potentials in Lipschitz domains of\n$\\mathbb{T}^2\\times \\mathbb{R}$.",
            "author": [
                "H. Dong",
                "F. Gancedo. H. Q. Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14230v1",
                "http://arxiv.org/pdf/2308.14230v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14217v1",
            "title": "Generations of Knowledge Graphs: The Crazy Ideas and the Business Impact",
            "updated": "2023-08-27T22:35:27Z",
            "published": "2023-08-27T22:35:27Z",
            "summary": "Knowledge Graphs (KGs) have been used to support a wide range of\napplications, from web search to personal assistant. In this paper, we describe\nthree generations of knowledge graphs: entity-based KGs, which have been\nsupporting general search and question answering (e.g., at Google and Bing);\ntext-rich KGs, which have been supporting search and recommendations for\nproducts, bio-informatics, etc. (e.g., at Amazon and Alibaba); and the emerging\nintegration of KGs and LLMs, which we call dual neural KGs. We describe the\ncharacteristics of each generation of KGs, the crazy ideas behind the scenes in\nconstructing such KGs, and the techniques developed over time to enable\nindustry impact. In addition, we use KGs as examples to demonstrate a recipe to\nevolve research ideas from innovations to production practice, and then to the\nnext level of innovations, to advance both science and business.",
            "author": [
                "Xin Luna Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14217v1",
                "http://arxiv.org/pdf/2308.14217v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14206v1",
            "title": "Using Knowledge Representation and Task Planning for Robot-agnostic\n  Skills on the Example of Contact-Rich Wiping Tasks",
            "updated": "2023-08-27T21:17:32Z",
            "published": "2023-08-27T21:17:32Z",
            "summary": "The transition to agile manufacturing, Industry 4.0, and high-mix-low-volume\ntasks require robot programming solutions that are flexible. However, most\ndeployed robot solutions are still statically programmed and use stiff position\ncontrol, which limit their usefulness. In this paper, we show how a single\nrobot skill that utilizes knowledge representation, task planning, and\nautomatic selection of skill implementations based on the input parameters can\nbe executed in different contexts. We demonstrate how the skill-based control\nplatform enables this with contact-rich wiping tasks on different robot\nsystems. To achieve that in this case study, our approach needs to address\ndifferent kinematics, gripper types, vendors, and fundamentally different\ncontrol interfaces. We conducted the experiments with a mobile platform that\nhas a Universal Robots UR5e 6 degree-of-freedom robot arm with position control\nand a 7 degree-of-freedom KUKA iiwa with torque control.",
            "author": [
                "Matthias Mayr",
                "Faseeh Ahmad",
                "Alexander Duerr",
                "Volker Krueger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14206v1",
                "http://arxiv.org/pdf/2308.14206v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14205v1",
            "title": "Schur-Positive sets",
            "updated": "2023-08-27T21:09:40Z",
            "published": "2023-08-27T21:09:40Z",
            "summary": "In this thesis we prove Schur-positivity of certain graph families. In\naddition, we exlpor existence of cyclic descent extensions on several families\nof Schur-positive sets.",
            "author": [
                "Yuval Khachatryan-Raziel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14205v1",
                "http://arxiv.org/pdf/2308.14205v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14199v1",
            "title": "Symbolic and Language Agnostic Large Language Models",
            "updated": "2023-08-27T20:24:33Z",
            "published": "2023-08-27T20:24:33Z",
            "summary": "We argue that the relative success of large language models (LLMs) is not a\nreflection on the symbolic vs. subsymbolic debate but a reflection on employing\nan appropriate strategy of bottom-up reverse engineering of language at scale.\nHowever, due to the subsymbolic nature of these models whatever knowledge these\nsystems acquire about language will always be buried in millions of\nmicrofeatures (weights) none of which is meaningful on its own. Moreover, and\ndue to their stochastic nature, these models will often fail in capturing\nvarious inferential aspects that are prevalent in natural language. What we\nsuggest here is employing the successful bottom-up strategy in a symbolic\nsetting, producing symbolic, language agnostic and ontologically grounded large\nlanguage models.",
            "author": [
                "Walid S. Saba"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14199v1",
                "http://arxiv.org/pdf/2308.14199v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14191v1",
            "title": "SketchDreamer: Interactive Text-Augmented Creative Sketch Ideation",
            "updated": "2023-08-27T19:44:44Z",
            "published": "2023-08-27T19:44:44Z",
            "summary": "Artificial Intelligence Generated Content (AIGC) has shown remarkable\nprogress in generating realistic images. However, in this paper, we take a step\n\"backward\" and address AIGC for the most rudimentary visual modality of human\nsketches. Our objective is on the creative nature of sketches, and that\ncreative sketching should take the form of an interactive process. We further\nenable text to drive the sketch ideation process, allowing creativity to be\nfreely defined, while simultaneously tackling the challenge of \"I can't\nsketch\". We present a method to generate controlled sketches using a\ntext-conditioned diffusion model trained on pixel representations of images.\nOur proposed approach, referred to as SketchDreamer, integrates a\ndifferentiable rasteriser of Bezier curves that optimises an initial input to\ndistil abstract semantic knowledge from a pretrained diffusion model. We\nutilise Score Distillation Sampling to learn a sketch that aligns with a given\ncaption, which importantly enable both text and sketch to interact with the\nideation process. Our objective is to empower non-professional users to create\nsketches and, through a series of optimisation processes, transform a narrative\ninto a storyboard by expanding the text prompt while making minor adjustments\nto the sketch input. Through this work, we hope to aspire the way we create\nvisual content, democratise the creative process, and inspire further research\nin enhancing human creativity in AIGC. The code is available at\n\\url{https://github.com/WinKawaks/SketchDreamer}.",
            "author": [
                "Zhiyu Qu",
                "Tao Xiang",
                "Yi-Zhe Song"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14191v1",
                "http://arxiv.org/pdf/2308.14191v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14181v1",
            "title": "Topological Augmentation for Class-Imbalanced Node Classification",
            "updated": "2023-08-27T19:01:29Z",
            "published": "2023-08-27T19:01:29Z",
            "summary": "Class imbalance is prevalent in real-world node classification tasks and\noften biases graph learning models toward majority classes. Most existing\nstudies root from a node-centric perspective and aim to address the class\nimbalance in training data by node/class-wise reweighting or resampling. In\nthis paper, we approach the source of the class-imbalance bias from an\nunder-explored topology-centric perspective. Our investigation reveals that\nbeyond the inherently skewed training class distribution, the graph topology\nalso plays an important role in the formation of predictive bias: we identify\ntwo fundamental challenges, namely ambivalent and distant message-passing, that\ncan exacerbate the bias by aggravating majority-class over-generalization and\nminority-class misclassification. In light of these findings, we devise a\nlightweight topological augmentation method ToBA to dynamically rectify the\nnodes influenced by ambivalent/distant message-passing during graph learning,\nso as to mitigate the class-imbalance bias. We highlight that ToBA is a\nmodel-agnostic, efficient, and versatile solution that can be seamlessly\ncombined with and further boost other imbalance-handling techniques. Systematic\nexperiments validate the superior performance of ToBA in both promoting\nimbalanced node classification and mitigating the prediction bias between\ndifferent classes.",
            "author": [
                "Zhining Liu",
                "Zhichen Zeng",
                "Ruizhong Qiu",
                "Hyunsik Yoo",
                "David Zhou",
                "Zhe Xu",
                "Yada Zhu",
                "Kommy Weldemariam",
                "Jingrui He",
                "Hanghang Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14181v1",
                "http://arxiv.org/pdf/2308.14181v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14179v1",
            "title": "Towards Vision-Language Mechanistic Interpretability: A Causal Tracing\n  Tool for BLIP",
            "updated": "2023-08-27T18:46:47Z",
            "published": "2023-08-27T18:46:47Z",
            "summary": "Mechanistic interpretability seeks to understand the neural mechanisms that\nenable specific behaviors in Large Language Models (LLMs) by leveraging\ncausality-based methods. While these approaches have identified neural circuits\nthat copy spans of text, capture factual knowledge, and more, they remain\nunusable for multimodal models since adapting these tools to the\nvision-language domain requires considerable architectural changes. In this\nwork, we adapt a unimodal causal tracing tool to BLIP to enable the study of\nthe neural mechanisms underlying image-conditioned text generation. We\ndemonstrate our approach on a visual question answering dataset, highlighting\nthe causal relevance of later layer representations for all tokens.\nFurthermore, we release our BLIP causal tracing tool as open source to enable\nfurther experimentation in vision-language mechanistic interpretability by the\ncommunity. Our code is available at\nhttps://github.com/vedantpalit/Towards-Vision-Language-Mechanistic-Interpretability.",
            "author": [
                "Vedant Palit",
                "Rohan Pandey",
                "Aryaman Arora",
                "Paul Pu Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14179v1",
                "http://arxiv.org/pdf/2308.14179v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14164v1",
            "title": "P3LI5: Practical and Confidential Lawful Interception on the 5G Core",
            "updated": "2023-08-27T17:57:30Z",
            "published": "2023-08-27T17:57:30Z",
            "summary": "Lawful Interception (LI) is a legal obligation of Communication Service\nProviders (CSPs) to provide interception capabilities to Law Enforcement\nAgencies (LEAs) in order to gain insightful data from network communications\nfor criminal proceedings, e.g., network identifiers for tracking suspects. With\nthe privacy-enhancements of network identifiers in the 5th generation of mobile\nnetworks (5G), LEAs need to interact with CSPs for network identifier\nresolution. This raises new privacy issues, as untrusted CSPs are able to infer\nsensitive information about ongoing investigations, e.g., the identities of\ntheir subscribers under suspicion. In this work, we propose P3LI5, a novel\nsystem that enables LEAs to privately query CSPs for network identifier\nresolution leveraging on an information retrieval protocol, SparseWPIR, that is\nbased on private information retrieval and its weakly private version. As such,\nP3LI5 can be adapted to various operational scenarios with different\nconfidentiality or latency requirements, by selectively allowing a bounded\ninformation leakage for improved performance. We implement P3LI5 on the 5G LI\ninfrastructure using well known open-source projects and demonstrate its\nscalability to large databases while retaining low latency. To the best of our\nknowledge, P3LI5 is the first proposal for addressing the privacy issues raised\nby the mandatory requirement for LI on the 5G core network.",
            "author": [
                "Francesco Intoci",
                "Julian Sturm",
                "Daniel Fraunholz",
                "Apostolos Pyrgelis",
                "Colin Barschel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14164v1",
                "http://arxiv.org/pdf/2308.14164v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14141v1",
            "title": "Giant Rainbow Trees in Sparse Random Graphs",
            "updated": "2023-08-27T15:42:17Z",
            "published": "2023-08-27T15:42:17Z",
            "summary": "For any small constant $\\epsilon>0$, the Erd\\H{o}s-R\\'enyi random graph\n$G(n,\\frac{1+\\epsilon}{n})$ with high probability has a unique largest\ncomponent which contains $(1\\pm O(\\epsilon))2\\epsilon n$ vertices. Let\n$G_c(n,p)$ be obtained by assigning each edge in $G(n,p)$ a color in $[c]$\nindependently and uniformly. Cooley, Do, Erde, and Missethan proved that for\nany fixed $\\alpha>0$, $G_{\\alpha n}(n,\\frac{1+\\epsilon}{n})$ with high\nprobability contains a rainbow tree (a tree that does not repeat colors) which\ncovers $(1\\pm O(\\epsilon))\\frac{\\alpha}{\\alpha+1}\\epsilon n$ vertices, and\nconjectured that there is one which covers $(1\\pm O(\\epsilon))2\\epsilon n$. In\nthis paper, we achieve the correct leading constant and prove their conjecture\ncorrect up to a logarithmic factor in the error term, as we show that with high\nprobability $G_{\\alpha n}(n,\\frac{1+\\epsilon}{n})$ contains a rainbow tree\nwhich covers $(1\\pm O(\\epsilon\\log(1/\\epsilon)))2\\epsilon n$ vertices.",
            "author": [
                "Tolson Bell",
                "Alan Frieze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14141v1",
                "http://arxiv.org/pdf/2308.14141v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35 (primary) 05D40 (secondary)",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14131v2",
            "title": "Improved Approximation Algorithms for Multidepot Capacitated Vehicle\n  Routing",
            "updated": "2023-09-13T03:35:28Z",
            "published": "2023-08-27T15:17:32Z",
            "summary": "The Multidepot Capacitated Vehicle Routing Problem (MCVRP) is a well-known\nvariant of the classic Capacitated Vehicle Routing Problem (CVRP), where we\nneed to route capacitated vehicles located in multiple depots to serve\ncustomers' demand such that each vehicle must return to the depot it starts,\nand the total traveling distance is minimized. There are three variants of\nMCVRP according to the property of the demand: unit-demand, splittable and\nunsplittable. We study approximation algorithms for $k$-MCVRP in metric graphs\nwhere $k$ is the capacity of each vehicle, and all three versions are APX-hard\nfor any constant $k\\geq 3$. Previously, Li and Simchi-Levi proposed a\n$(2\\alpha+1-\\alpha/k)$-approximation algorithm for splittable and unit-demand\n$k$-MCVRP and a $(2\\alpha+2-2\\alpha/k)$-approximation algorithm for\nunsplittable $k$-MCVRP, where $\\alpha=3/2-10^{-36}$ is the current best\napproximation ratio for metric TSP. Harks et al. further improved the ratio to\n4 for the unsplittable case. We give a $(4-1/1500)$-approximation algorithm for\nunit-demand and splittable $k$-MCVRP, and a $(4-1/50000)$-approximation\nalgorithm for unsplittable $k$-MCVRP. Furthermore, we give a\n$(3+\\ln2-\\max\\{\\Theta(1/\\sqrt{k}),1/9000\\})$-approximation algorithm for\nsplittable and unit-demand $k$-MCVRP, and a\n$(3+\\ln2-\\Theta(1/\\sqrt{k}))$-approximation algorithm for unsplittable\n$k$-MCVRP under the assumption that the capacity $k$ is a fixed constant. Our\nresults are based on recent progress in approximating CVRP.",
            "author": [
                "Jingyang Zhao",
                "Mingyu Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14131v2",
                "http://arxiv.org/pdf/2308.14131v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14129v2",
            "title": "SPEED: Streaming Partition and Parallel Acceleration for Temporal\n  Interaction Graph Embedding",
            "updated": "2023-09-11T05:30:49Z",
            "published": "2023-08-27T15:11:44Z",
            "summary": "Temporal Interaction Graphs (TIGs) are widely employed to model intricate\nreal-world systems such as financial systems and social networks. To capture\nthe dynamism and interdependencies of nodes, existing TIG embedding models need\nto process edges sequentially and chronologically. However, this requirement\nprevents it from being processed in parallel and struggle to accommodate\nburgeoning data volumes to GPU. Consequently, many large-scale temporal\ninteraction graphs are confined to CPU processing. Furthermore, a generalized\nGPU scaling and acceleration approach remains unavailable. To facilitate\nlarge-scale TIGs' implementation on GPUs for acceleration, we introduce a novel\ntraining approach namely Streaming Edge Partitioning and Parallel Acceleration\nfor Temporal Interaction Graph Embedding (SPEED). The SPEED is comprised of a\nStreaming Edge Partitioning Component (SEP) which addresses space overhead\nissue by assigning fewer nodes to each GPU, and a Parallel Acceleration\nComponent (PAC) which enables simultaneous training of different sub-graphs,\naddressing time overhead issue. Our method can achieve a good balance in\ncomputing resources, computing time, and downstream task performance. Empirical\nvalidation across 7 real-world datasets demonstrates the potential to expedite\ntraining speeds by a factor of up to 19.29x. Simultaneously, resource\nconsumption of a single-GPU can be diminished by up to 69%, thus enabling the\nmultiple GPU-based training and acceleration encompassing millions of nodes and\nbillions of edges. Furthermore, our approach also maintains its competitiveness\nin downstream tasks.",
            "author": [
                "Xi Chen",
                "Yongxiang Liao",
                "Yun Xiong",
                "Yao Zhang",
                "Siwei Zhang",
                "Jiawei Zhang",
                "Yiheng Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14129v2",
                "http://arxiv.org/pdf/2308.14129v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14123v1",
            "title": "On $Z$-monodromies in embedded graphs",
            "updated": "2023-08-27T14:40:11Z",
            "published": "2023-08-27T14:40:11Z",
            "summary": "We characterize all permutations which realize as the $z$-monodromies of\nfaces in connected simple finite graphs embedded in surfaces whose duals are\nalso simple.",
            "author": [
                "Adam Tyc"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14123v1",
                "http://arxiv.org/pdf/2308.14123v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14122v1",
            "title": "Preparing Reproducible Scientific Artifacts using Docker",
            "updated": "2023-08-27T14:36:48Z",
            "published": "2023-08-27T14:36:48Z",
            "summary": "The pursuit of scientific knowledge strongly depends on the ability to\nreproduce and validate research results. It is a well-known fact that the\nscientific community faces challenges related to transparency, reliability, and\nthe reproducibility of empirical published results. Consequently, the design\nand preparation of reproducible artifacts has a fundamental role in the\ndevelopment of science. Reproducible artifacts comprise comprehensive\ndocumentation, data, and code that enable replication and validation of\nresearch findings by others. In this work, we discuss a methodology to\nconstruct reproducible artifacts based on Docker. Our presentation centers\naround the preparation of an artifact to be submitted to scientific venues that\nencourage or require this process. This report's primary audience are\nscientists working with empirical computer science; however, we believe that\nthe presented methodology can be extended to other technology-oriented\nempirical disciplines.",
            "author": [
                "Michael Canesche",
                "Roland Leissa",
                "Fernando Magno Quint\u00e3o Pereira"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14122v1",
                "http://arxiv.org/pdf/2308.14122v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14120v3",
            "title": "Large Language Models Streamline Automated Machine Learning for Clinical\n  Studies",
            "updated": "2023-10-09T18:01:12Z",
            "published": "2023-08-27T14:28:38Z",
            "summary": "A knowledge gap persists between machine learning (ML) developers (e.g., data\nscientists) and practitioners (e.g., clinicians), hampering the full\nutilization of ML for clinical data analysis. We investigated the potential of\nthe ChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this\ngap and perform ML analyses efficiently. Real-world clinical datasets and study\ndetails from large trials across various medical specialties were presented to\nChatGPT ADA without specific guidance. ChatGPT ADA autonomously developed\nstate-of-the-art ML models based on the original study's training data to\npredict clinical outcomes such as cancer development, cancer progression,\ndisease complications, or biomarkers such as pathogenic gene sequences.\nFollowing the re-implementation and optimization of the published models, the\nhead-to-head comparison of the ChatGPT ADA-crafted ML models and their\nrespective manually crafted counterparts revealed no significant differences in\ntraditional performance metrics (P>0.474). Strikingly, the ChatGPT ADA-crafted\nML models often outperformed their counterparts. In conclusion, ChatGPT ADA\noffers a promising avenue to democratize ML in medicine by simplifying complex\ndata analyses, yet should enhance, not replace, specialized training and\nresources, to promote broader applications in medical research and practice.",
            "author": [
                "Soroosh Tayebi Arasteh",
                "Tianyu Han",
                "Mahshad Lotfinia",
                "Christiane Kuhl",
                "Jakob Nikolas Kather",
                "Daniel Truhn",
                "Sven Nebelung"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14120v3",
                "http://arxiv.org/pdf/2308.14120v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14118v1",
            "title": "Any link has a diagram with only triangles and quadrilaterals",
            "updated": "2023-08-27T14:21:23Z",
            "published": "2023-08-27T14:21:23Z",
            "summary": "A link diagram can be considered as a $4$-valent graph embedded in the\n$2$-sphere and divides the sphere into complementary regions. In this paper, we\nshow that any link has a diagram with only triangles and quadrilaterals. This\nextends previous results shown by the authors and C. Adams.",
            "author": [
                "Reiko Shinjo",
                "Kokoro Tanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14118v1",
                "http://arxiv.org/pdf/2308.14118v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.CO",
                "57K10, 57M15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14116v1",
            "title": "An Improved Kernel and Parameterized Algorithm for Almost Induced\n  Matching",
            "updated": "2023-08-27T14:16:18Z",
            "published": "2023-08-27T14:16:18Z",
            "summary": "An induced subgraph is called an induced matching if each vertex is a\ndegree-1 vertex in the subgraph. The \\textsc{Almost Induced Matching} problem\nasks whether we can delete at most $k$ vertices from the input graph such that\nthe remaining graph is an induced matching. This paper studies parameterized\nalgorithms for this problem by taking the size $k$ of the deletion set as the\nparameter. First, we prove a $6k$-vertex kernel for this problem, improving the\nprevious result of $7k$. Second, we give an $O^*(1.6957^k)$-time and\npolynomial-space algorithm, improving the previous running-time bound of\n$O^*(1.7485^k)$.",
            "author": [
                "Yuxi Liu",
                "Mingyu Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14116v1",
                "http://arxiv.org/pdf/2308.14116v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14105v2",
            "title": "Unified and Dynamic Graph for Temporal Character Grouping in Long Videos",
            "updated": "2023-08-29T12:43:53Z",
            "published": "2023-08-27T13:22:55Z",
            "summary": "Video temporal character grouping locates appearing moments of major\ncharacters within a video according to their identities. To this end, recent\nworks have evolved from unsupervised clustering to graph-based supervised\nclustering. However, graph methods are built upon the premise of fixed affinity\ngraphs, bringing many inexact connections. Besides, they extract multi-modal\nfeatures with kinds of models, which are unfriendly to deployment. In this\npaper, we present a unified and dynamic graph (UniDG) framework for temporal\ncharacter grouping. This is accomplished firstly by a unified representation\nnetwork that learns representations of multiple modalities within the same\nspace and still preserves the modality's uniqueness simultaneously. Secondly,\nwe present a dynamic graph clustering where the neighbors of different\nquantities are dynamically constructed for each node via a cyclic matching\nstrategy, leading to a more reliable affinity graph. Thirdly, a progressive\nassociation method is introduced to exploit spatial and temporal contexts among\ndifferent modalities, allowing multi-modal clustering results to be well fused.\nAs current datasets only provide pre-extracted features, we evaluate our UniDG\nmethod on a collected dataset named MTCG, which contains each character's\nappearing clips of face and body and speaking voice tracks. We also evaluate\nour key components on existing clustering and retrieval datasets to verify the\ngeneralization ability. Experimental results manifest that our method can\nachieve promising results and outperform several state-of-the-art approaches.",
            "author": [
                "Xiujun Shu",
                "Wei Wen",
                "Liangsheng Xu",
                "Mingbao Lin",
                "Ruizhi Qiao",
                "Taian Guo",
                "Hanjun Li",
                "Bei Gan",
                "Xiao Wang",
                "Xing Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14105v2",
                "http://arxiv.org/pdf/2308.14105v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14104v1",
            "title": "Towards Generalizable Neural Solvers for Vehicle Routing Problems via\n  Ensemble with Transferrable Local Policy",
            "updated": "2023-08-27T13:22:50Z",
            "published": "2023-08-27T13:22:50Z",
            "summary": "Machine learning has been adapted to help solve NP-hard combinatorial\noptimization problems. One prevalent way is learning to construct solutions by\ndeep neural networks, which has been receiving more and more attention due to\nthe high efficiency and less requirement for expert knowledge. However, many\nneural construction methods for Vehicle Routing Problems (VRPs) focus on\nsynthetic problem instances with limited scales and specified node\ndistributions, leading to poor performance on real-world problems which usually\ninvolve large scales together with complex and unknown node distributions. To\nmake neural VRP solvers more practical in real-world scenarios, we design an\nauxiliary policy that learns from the local transferable topological features,\nnamed local policy, and integrate it with a typical constructive policy (which\nlearns from the global information of VRP instances) to form an ensemble\npolicy. With joint training, the aggregated policies perform cooperatively and\ncomplementarily to boost generalization. The experimental results on two\nwell-known benchmarks, TSPLIB and CVRPLIB, of travelling salesman problem and\ncapacitated VRP show that the ensemble policy consistently achieves better\ngeneralization than state-of-the-art construction methods and even works well\non real-world problems with several thousand nodes.",
            "author": [
                "Chengrui Gao",
                "Haopu Shang",
                "Ke Xue",
                "Dong Li",
                "Chao Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14104v1",
                "http://arxiv.org/pdf/2308.14104v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14101v1",
            "title": "Superpixels algorithms through network community detection",
            "updated": "2023-08-27T13:13:28Z",
            "published": "2023-08-27T13:13:28Z",
            "summary": "Community detection is a powerful tool from complex networks analysis that\nfinds applications in various research areas. Several image segmentation\nmethods rely for instance on community detection algorithms as a black box in\norder to compute undersegmentations, i.e. a small number of regions that\nrepresent areas of interest of the image. However, to the best of our\nknowledge, the efficiency of such an approach w.r.t. superpixels, that aim at\nrepresenting the image at a smaller level while preserving as much as possible\noriginal information, has been neglected so far. The only related work seems to\nbe the one by Liu et. al. (IET Image Processing, 2022) that developed a\nsuperpixels algorithm using a so-called modularity maximization approach,\nleading to relevant results. We follow this line of research by studying the\nefficiency of superpixels computed by state-of-the-art community detection\nalgorithms on a 4-connected pixel graph, so-called pixel-grid. We first detect\ncommunities on such a graph and then apply a simple merging procedure that\nallows to obtain the desired number of superpixels. As we shall see, such\nmethods result in the computation of relevant superpixels as emphasized by both\nqualitative and quantitative experiments, according to different widely-used\nmetrics based on ground-truth comparison or on superpixels only. We observe\nthat the choice of the community detection algorithm has a great impact on the\nnumber of communities and hence on the merging procedure. Similarly, small\nvariations on the pixel-grid may provide different results from both\nqualitative and quantitative viewpoints. For the sake of completeness, we\ncompare our results with those of several state-of-the-art superpixels\nalgorithms as computed by Stutz et al. (Computer Vision and Image\nUnderstanding, 2018).",
            "author": [
                "Anthony Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14101v1",
                "http://arxiv.org/pdf/2308.14101v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.05942v1",
            "title": "Transactive Multi-Agent Systems over Flow Networks",
            "updated": "2023-08-27T12:54:55Z",
            "published": "2023-08-27T12:54:55Z",
            "summary": "This paper presented insights into the implementation of transactive\nmulti-agent systems over flow networks where local resources are decentralized.\nAgents have local resource demand and supply, and are interconnected through a\nflow network to support the sharing of local resources while respecting\nrestricted sharing/flow capacity. We first establish a competitive market with\na pricing mechanism that internalizes flow capacity constraints into agents'\nprivate decisions. We then demonstrate through duality theory that competitive\nequilibrium and social welfare equilibrium exist and agree under convexity\nassumptions, indicating the efficiency of the pricing mechanism. Additionally,\na new social acceptance sharing problem is defined to investigate homogeneous\npricing when the optimal sharing prices at all agents under competitive\nequilibrium are always equal for social acceptance. A conceptual computation\nmethod is proposed, prescribing a class of socially admissible utility\nfunctions to solve the social acceptance problem. A special case of\nlinear-quadratic multi-agent systems over undirected star graphs is provided as\na pedagogical example of how to explicitly prescribe socially admissible\nutility functions. Finally, extensive experiments are provided to validate the\nresults.",
            "author": [
                "Yijun Chen",
                "Zeinab Salehi",
                "Elizabeth L. Ratnam",
                "Ian R. Petersen",
                "Guodong Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.05942v1",
                "http://arxiv.org/pdf/2310.05942v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14084v1",
            "title": "Practical Edge Detection via Robust Collaborative Learning",
            "updated": "2023-08-27T12:12:27Z",
            "published": "2023-08-27T12:12:27Z",
            "summary": "Edge detection, as a core component in a wide range of visionoriented tasks,\nis to identify object boundaries and prominent edges in natural images. An edge\ndetector is desired to be both efficient and accurate for practical use. To\nachieve the goal, two key issues should be concerned: 1) How to liberate deep\nedge models from inefficient pre-trained backbones that are leveraged by most\nexisting deep learning methods, for saving the computational cost and cutting\nthe model size; and 2) How to mitigate the negative influence from noisy or\neven wrong labels in training data, which widely exist in edge detection due to\nthe subjectivity and ambiguity of annotators, for the robustness and accuracy.\nIn this paper, we attempt to simultaneously address the above problems via\ndeveloping a collaborative learning based model, termed PEdger. The principle\nbehind our PEdger is that, the information learned from different training\nmoments and heterogeneous (recurrent and non recurrent in this work)\narchitectures, can be assembled to explore robust knowledge against noisy\nannotations, even without the help of pre-training on extra data. Extensive\nablation studies together with quantitative and qualitative experimental\ncomparisons on the BSDS500 and NYUD datasets are conducted to verify the\neffectiveness of our design, and demonstrate its superiority over other\ncompetitors in terms of accuracy, speed, and model size. Codes can be found at\nhttps://github.co/ForawardStar/PEdger.",
            "author": [
                "Yuanbin Fu",
                "Xiaojie Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14084v1",
                "http://arxiv.org/pdf/2308.14084v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14061v1",
            "title": "Hierarchical Contrastive Learning for Pattern-Generalizable Image\n  Corruption Detection",
            "updated": "2023-08-27T10:03:48Z",
            "published": "2023-08-27T10:03:48Z",
            "summary": "Effective image restoration with large-size corruptions, such as blind image\ninpainting, entails precise detection of corruption region masks which remains\nextremely challenging due to diverse shapes and patterns of corruptions. In\nthis work, we present a novel method for automatic corruption detection, which\nallows for blind corruption restoration without known corruption masks.\nSpecifically, we develop a hierarchical contrastive learning framework to\ndetect corrupted regions by capturing the intrinsic semantic distinctions\nbetween corrupted and uncorrupted regions. In particular, our model detects the\ncorrupted mask in a coarse-to-fine manner by first predicting a coarse mask by\ncontrastive learning in low-resolution feature space and then refines the\nuncertain area of the mask by high-resolution contrastive learning. A\nspecialized hierarchical interaction mechanism is designed to facilitate the\nknowledge propagation of contrastive learning in different scales, boosting the\nmodeling performance substantially. The detected multi-scale corruption masks\nare then leveraged to guide the corruption restoration. Detecting corrupted\nregions by learning the contrastive distinctions rather than the semantic\npatterns of corruptions, our model has well generalization ability across\ndifferent corruption patterns. Extensive experiments demonstrate following\nmerits of our model: 1) the superior performance over other methods on both\ncorruption detection and various image restoration tasks including blind\ninpainting and watermark removal, and 2) strong generalization across different\ncorruption patterns such as graffiti, random noise or other image content.\nCodes and trained weights are available at https://github.com/xyfJASON/HCL .",
            "author": [
                "Xin Feng",
                "Yifeng Xu",
                "Guangming Lu",
                "Wenjie Pei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14061v1",
                "http://arxiv.org/pdf/2308.14061v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14016v1",
            "title": "MITRE ATT&CK: State of the Art and Way Forward",
            "updated": "2023-08-27T06:26:35Z",
            "published": "2023-08-27T06:26:35Z",
            "summary": "MITRE ATT&CK is a comprehensive framework of adversary tactics, techniques\nand procedures based on real-world observations. It has been used as a\nfoundation for threat modelling in different sectors, such as government,\nacademia and industry. To the best of our knowledge, no previous work has been\ndevoted to the comprehensive collection, study and investigation of the current\nstate of the art leveraging the MITRE ATT&CK framework. We select and inspect\nmore than fifty major research contributions, while conducting a detailed\nanalysis of their methodology and objectives in relation to the MITRE ATT&CK\nframework. We provide a categorization of the identified papers according to\ndifferent criteria such as use cases, application scenarios, adopted\nmethodologies and the use of additional data. Finally, we discuss open issues\nand future research directions involving not only the MITRE ATT&CK framework\nbut also the fields of risk analysis and cyber-threat intelligence at large.",
            "author": [
                "Bader Al-Sada",
                "Alireza Sadighian",
                "Gabriele Oligeri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14016v1",
                "http://arxiv.org/pdf/2308.14016v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14010v1",
            "title": "Shift-like graph with high odd girth and high chromatic number",
            "updated": "2023-08-27T05:56:38Z",
            "published": "2023-08-27T05:56:38Z",
            "summary": "It is known that shift graphs constructed by Erdos and Hajnal have some\ninteresting properties, such as being triangle-free and whose chromatic number\ncan be arbitrarily large. Given any graph $G$, we construct a completely new\ngraph $S(G)$, using the structure of the graph $G$. This can be seen as a\nabstraction of shift graphs in some sense. We discuss some interesting\nproperties of $S(G)$ that are inherited from the properties of the graph $G$.\nWe also study some structural properties of $S(G)$ that are independent from\nthe choice of $G$. As a consequence we give explicit constructions of graphs\nwith high odd girth, high chromatic number and local chromatic number bounded\nby $3$. We also prove that the $4$-hole-free induced subgraphs of the\ntriangle-free shift graphs $G_{n,2}$ have a chromatic number bounded by $4$,\nwhich improves a general bound from a recent theorem on the chromatic number of\n$H$-free induced subgraphs of high chromatic graphs, specifically in the case\nwhere $H$ is a $4$-hole.",
            "author": [
                "Arpan Sadhukhan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14010v1",
                "http://arxiv.org/pdf/2308.14010v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15, 05C75"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.14000v1",
            "title": "High-risk Factor Prediction in Lung Cancer Using Thin CT Scans: An\n  Attention-Enhanced Graph Convolutional Network Approach",
            "updated": "2023-08-27T04:24:04Z",
            "published": "2023-08-27T04:24:04Z",
            "summary": "Lung cancer, particularly in its advanced stages, remains a leading cause of\ndeath globally. Though early detection via low-dose computed tomography (CT) is\npromising, the identification of high-risk factors crucial for surgical mode\nselection remains a challenge. Addressing this, our study introduces an\nAttention-Enhanced Graph Convolutional Network (AE-GCN) model to classify\nwhether there are high-risk factors in stage I lung cancer based on the\npreoperative CT images. This will aid surgeons in determining the optimal\nsurgical method before the operation. Unlike previous studies that relied on 3D\npatch techniques to represent nodule spatial features, our method employs a GCN\nmodel to capture the spatial characteristics of pulmonary nodules.\nSpecifically, we regard each slice of the nodule as a graph vertex, and the\ninherent spatial relationships between slices form the edges. Then, to enhance\nthe expression of nodule features, we integrated both channel and spatial\nattention mechanisms with a pre-trained VGG model for adaptive feature\nextraction from pulmonary nodules. Lastly, the effectiveness of the proposed\nmethod is demonstrated using real-world data collected from the hospitals,\nthereby emphasizing its potential utility in the clinical practice.",
            "author": [
                "Xiaotong Fu",
                "Xiangyu Meng",
                "Jing Zhou",
                "Ying Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2308.14000v1",
                "http://arxiv.org/pdf/2308.14000v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13993v1",
            "title": "Comprehensive performance comparison among different types of features\n  in data-driven battery state of health estimation",
            "updated": "2023-08-27T03:13:09Z",
            "published": "2023-08-27T03:13:09Z",
            "summary": "Battery state of health (SOH), which informs the maximal available capacity\nof the battery, is a key indicator of battery aging failure. Accurately\nestimating battery SOH is a vital function of the battery management system\nthat remains to be addressed. In this study, a physics-informed Gaussian\nprocess regression (GPR) model is developed for battery SOH estimation, with\nthe performance being systematically compared with that of different types of\nfeatures and machine learning (ML) methods. The method performance is validated\nbased on 58826 cycling data units of 118 cells. Experimental results show that\nthe physics-driven ML generally estimates more accurate SOH than other\nnon-physical features under different scenarios. The physical features-based\nGPR predicts battery SOH with the errors being less than 1.1% based on 10 to 20\nmins' relaxation data. And the high robustness and generalization capability of\nthe methodology is also validated against different ratios of training and test\ndata under unseen conditions. Results also highlight the more effective\ncapability of knowledge transfer between different types of batteries with the\nphysical features and GPR. This study demonstrates the excellence of physical\nfeatures in indicating the state evolution of complex systems, and the improved\nindication performance of these features by combining a suitable ML method.",
            "author": [
                "Xinhong Feng",
                "Yongzhi Zhang",
                "Rui Xiong",
                "Chun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13993v1",
                "http://arxiv.org/pdf/2308.13993v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12906v1",
            "title": "Building explainable graph neural network by sparse learning for the\n  drug-protein binding prediction",
            "updated": "2023-08-27T02:20:30Z",
            "published": "2023-08-27T02:20:30Z",
            "summary": "Explainable Graph Neural Networks (GNNs) have been developed and applied to\ndrug-protein binding prediction to identify the key chemical structures in a\ndrug that have active interactions with the target proteins. However, the key\nstructures identified by the current explainable GNN models are typically\nchemically invalid. Furthermore, a threshold needs to be manually selected to\npinpoint the key structures from the rest. To overcome the limitations of the\ncurrent explainable GNN models, we propose our SLGNN, which stands for using\nSparse Learning to Graph Neural Networks. Our SLGNN relies on using a\nchemical-substructure-based graph (where nodes are chemical substructures) to\nrepresent a drug molecule. Furthermore, SLGNN incorporates generalized fussed\nlasso with message-passing algorithms to identify connected subgraphs that are\ncritical for the drug-protein binding prediction. Due to the use of the\nchemical-substructure-based graph, it is guaranteed that any subgraphs in a\ndrug identified by our SLGNN are chemically valid structures. These structures\ncan be further interpreted as the key chemical structures for the drug to bind\nto the target protein. We demonstrate the explanatory power of our SLGNN by\nfirst showing all the key structures identified by our SLGNN are chemically\nvalid. In addition, we illustrate that the key structures identified by our\nSLGNN have more predictive power than the key structures identified by the\ncompeting methods. At last, we use known drug-protein binding data to show the\nkey structures identified by our SLGNN contain most of the binding sites.",
            "author": [
                "Yang Wang",
                "Zanyu Shi",
                "Timothy Richardson",
                "Kun Huang",
                "Pathum Weerawarna",
                "Yijie Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12906v1",
                "http://arxiv.org/pdf/2309.12906v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13986v1",
            "title": "A Deep Learning Method for Computing Eigenvalues of the Fractional\n  Schr\u00f6dinger Operator",
            "updated": "2023-08-27T02:17:07Z",
            "published": "2023-08-27T02:17:07Z",
            "summary": "We present a novel deep learning method for computing eigenvalues of the\nfractional Schr\\\"odinger operator. Our approach combines a newly developed loss\nfunction with an innovative neural network architecture that incorporates prior\nknowledge of the problem. These improvements enable our method to handle both\nhigh-dimensional problems and problems posed on irregular bounded domains. We\nsuccessfully compute up to the first 30 eigenvalues for various fractional\nSchr\\\"odinger operators. As an application, we share a conjecture to the\nfractional order isospectral problem that has not yet been studied.",
            "author": [
                "Yixiao Guo",
                "Pingbing Ming"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13986v1",
                "http://arxiv.org/pdf/2308.13986v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13983v1",
            "title": "Interpolation of mountain weather forecasts by machine learning",
            "updated": "2023-08-27T01:32:23Z",
            "published": "2023-08-27T01:32:23Z",
            "summary": "Recent advancements in numerical simulation methods based on physical models\nhave enhanced the accuracy of weather forecasts. However, the precision\ndiminishes in complex terrains like mountainous regions due to the several\nkilometers square grid used in numerical simulations. While statistical machine\nlearning has also significantly advanced, its direct application is difficult\nto utilize physics knowledge. This paper proposes a method that employs machine\nlearning to ``interpolate'' future weather in mountainous regions using current\nobserved data and forecast data from surrounding plains. Generally, weather\nprediction relies on numerical simulations, so this approach can be considered\na hybrid method that indirectly merges numerical simulation and machine\nlearning. The use of binary cross-entropy in precipitation prediction is also\nexamined.",
            "author": [
                "Kazuma Iwase",
                "Tomoyuki Takenawa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13983v1",
                "http://arxiv.org/pdf/2308.13983v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13982v1",
            "title": "Universal Graph Continual Learning",
            "updated": "2023-08-27T01:19:19Z",
            "published": "2023-08-27T01:19:19Z",
            "summary": "We address catastrophic forgetting issues in graph learning as incoming data\ntransits from one to another graph distribution. Whereas prior studies\nprimarily tackle one setting of graph continual learning such as incremental\nnode classification, we focus on a universal approach wherein each data point\nin a task can be a node or a graph, and the task varies from node to graph\nclassification. We propose a novel method that enables graph neural networks to\nexcel in this universal setting. Our approach perseveres knowledge about past\ntasks through a rehearsal mechanism that maintains local and global structure\nconsistency across the graphs. We benchmark our method against various\ncontinual learning baselines in real-world graph datasets and achieve\nsignificant improvement in average performance and forgetting across tasks.",
            "author": [
                "Thanh Duc Hoang",
                "Do Viet Tung",
                "Duy-Hung Nguyen",
                "Bao-Sinh Nguyen",
                "Huy Hoang Nguyen",
                "Hung Le"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13982v1",
                "http://arxiv.org/pdf/2308.13982v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13978v2",
            "title": "A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss\n  Function for Combinatorial Optimization using Reinforcement Learning",
            "updated": "2023-09-28T13:08:22Z",
            "published": "2023-08-27T00:57:01Z",
            "summary": "Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to\nmodel various NP-hard combinatorial optimization problems in the form of binary\nvariables. The Hamiltonian function is often used to formulate QUBO problems\nwhere it is used as the objective function in the context of optimization.\nRecently, PI-GNN, a generic scalable framework, has been proposed to address\nthe Combinatorial Optimization (CO) problems over graphs based on a simple\nGraph Neural Network (GNN) architecture. Their novel contribution was a generic\nQUBO-formulated Hamiltonian-inspired loss function that was optimized using\nGNN. In this study, we address a crucial issue related to the aforementioned\nsetup especially observed in denser graphs. The reinforcement learning-based\nparadigm has also been widely used to address numerous CO problems. Here we\nalso formulate and empirically evaluate the compatibility of the\nQUBO-formulated Hamiltonian as the generic reward function in the Reinforcement\nLearning paradigm to directly integrate the actual node projection status\nduring training as the form of rewards. In our experiments, we observed up to\n44% improvement in the RL-based setup compared to the PI-GNN algorithm. Our\nimplementation can be found in\nhttps://github.com/rizveeredwan/learning-graph-structure.",
            "author": [
                "Redwan Ahmed Rizvee",
                "Md. Mosaddek Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13978v2",
                "http://arxiv.org/pdf/2308.13978v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13961v1",
            "title": "Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing\n  Idiomatic Translation with Language Models",
            "updated": "2023-08-26T21:38:31Z",
            "published": "2023-08-26T21:38:31Z",
            "summary": "To translate well, machine translation (MT) systems and general-purposed\nlanguage models (LMs) need a deep understanding of both source and target\nlanguages and cultures. Therefore, idioms, with their non-compositional nature,\npose particular challenges for Transformer-based systems, as literal\ntranslations often miss the intended meaning. Traditional methods, which\nreplace idioms using existing knowledge bases (KBs), often lack scale and\ncontext awareness. Addressing these challenges, our approach prioritizes\ncontext awareness and scalability, allowing for offline storage of idioms in a\nmanageable KB size. This ensures efficient serving with smaller models and\nprovides a more comprehensive understanding of idiomatic expressions. We\nintroduce a multilingual idiom KB (IdiomKB) developed using large LMs to\naddress this. This KB facilitates better translation by smaller models, such as\nBLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms'\nfigurative meanings. We present a novel, GPT-4-powered metric for human-aligned\nevaluation, demonstrating that IdiomKB considerably boosts model performance.\nHuman evaluations further validate our KB's quality.",
            "author": [
                "Shuang Li",
                "Jiangjie Chen",
                "Siyu Yuan",
                "Xinyi Wu",
                "Hao Yang",
                "Shimin Tao",
                "Yanghua Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13961v1",
                "http://arxiv.org/pdf/2308.13961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13958v1",
            "title": "Improving Knowledge Distillation for BERT Models: Loss Functions,\n  Mapping Methods, and Weight Tuning",
            "updated": "2023-08-26T20:59:21Z",
            "published": "2023-08-26T20:59:21Z",
            "summary": "The use of large transformer-based models such as BERT, GPT, and T5 has led\nto significant advancements in natural language processing. However, these\nmodels are computationally expensive, necessitating model compression\ntechniques that reduce their size and complexity while maintaining accuracy.\nThis project investigates and applies knowledge distillation for BERT model\ncompression, specifically focusing on the TinyBERT student model. We explore\nvarious techniques to improve knowledge distillation, including experimentation\nwith loss functions, transformer layer mapping methods, and tuning the weights\nof attention and representation loss and evaluate our proposed techniques on a\nselection of downstream tasks from the GLUE benchmark. The goal of this work is\nto improve the efficiency and effectiveness of knowledge distillation, enabling\nthe development of more efficient and accurate models for a range of natural\nlanguage processing tasks.",
            "author": [
                "Apoorv Dankar",
                "Adeem Jassani",
                "Kartikaeya Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13958v1",
                "http://arxiv.org/pdf/2308.13958v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13957v2",
            "title": "Differentiable Weight Masks for Domain Transfer",
            "updated": "2023-10-07T04:52:15Z",
            "published": "2023-08-26T20:45:52Z",
            "summary": "One of the major drawbacks of deep learning models for computer vision has\nbeen their inability to retain multiple sources of information in a modular\nfashion. For instance, given a network that has been trained on a source task,\nwe would like to re-train this network on a similar, yet different, target task\nwhile maintaining its performance on the source task. Simultaneously,\nresearchers have extensively studied modularization of network weights to\nlocalize and identify the set of weights culpable for eliciting the observed\nperformance on a given task. One set of works studies the modularization\ninduced in the weights of a neural network by learning and analysing weight\nmasks. In this work, we combine these fields to study three such weight masking\nmethods and analyse their ability to mitigate \"forgetting'' on the source task\nwhile also allowing for efficient finetuning on the target task. We find that\ndifferent masking techniques have trade-offs in retaining knowledge in the\nsource task without adversely affecting target task performance.",
            "author": [
                "Samar Khanna",
                "Skanda Vaidyanath",
                "Akash Velu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13957v2",
                "http://arxiv.org/pdf/2308.13957v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13927v1",
            "title": "Quantifying the Influence of User Behaviors on the Dissemination of Fake\n  News on Twitter with Multivariate Hawkes Processes",
            "updated": "2023-08-26T18:01:47Z",
            "published": "2023-08-26T18:01:47Z",
            "summary": "Fake news has emerged as a pervasive problem within Online Social Networks,\nleading to a surge of research interest in this area. Understanding the\ndissemination mechanisms of fake news is crucial in comprehending the\npropagation of disinformation/misinformation and its impact on users in Online\nSocial Networks. This knowledge can facilitate the development of interventions\nto curtail the spread of false information and inform affected users to remain\nvigilant against fraudulent/malicious content. In this paper, we specifically\ntarget the Twitter platform and propose a Multivariate Hawkes Point Processes\nmodel that incorporates essential factors such as user networks, response tweet\ntypes, and user stances as model parameters. Our objective is to investigate\nand quantify their influence on the dissemination process of fake news. We\nderive parameter estimation expressions using an Expectation Maximization\nalgorithm and validate them on a simulated dataset. Furthermore, we conduct a\ncase study using a real dataset of fake news collected from Twitter to explore\nthe impact of user stances and tweet types on dissemination patterns. This\nanalysis provides valuable insights into how users are influenced by or\ninfluence the dissemination process of disinformation/misinformation, and\ndemonstrates how our model can aid in intervening in this process.",
            "author": [
                "Yichen Jiang",
                "Michael D. Porter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13927v1",
                "http://arxiv.org/pdf/2308.13927v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13924v1",
            "title": "PaperToPlace: Transforming Instruction Documents into Spatialized and\n  Context-Aware Mixed Reality Experiences",
            "updated": "2023-08-26T17:51:12Z",
            "published": "2023-08-26T17:51:12Z",
            "summary": "While paper instructions are one of the mainstream medium for sharing\nknowledge, consuming such instructions and translating them into activities are\ninefficient due to the lack of connectivity with physical environment. We\npresent PaperToPlace, a novel workflow comprising an authoring pipeline, which\nallows the authors to rapidly transform and spatialize existing paper\ninstructions into MR experience, and a consumption pipeline, which\ncomputationally place each instruction step at an optimal location that is easy\nto read and do not occlude key interaction areas. Our evaluations of the\nauthoring pipeline with 12 participants demonstrated the usability of our\nworkflow and the effectiveness of using a machine learning based approach to\nhelp extracting the spatial locations associated with each steps. A second\nwithin-subject study with another 12 participants demonstrates the merits of\nour consumption pipeline by reducing efforts of context switching, delivering\nthe segmented instruction steps and offering the hands-free affordances.",
            "author": [
                "Chen Chen",
                "Cuong Nguyen",
                "Jane Hoffswell",
                "Jennifer Healey",
                "Trung Bui",
                "Nadir Weibel"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3586183.3606832",
                "http://arxiv.org/abs/2308.13924v1",
                "http://arxiv.org/pdf/2308.13924v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "H.4.m; H.5.2; I.7.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13921v1",
            "title": "Enhancement of database access performance by improving data consistency\n  in a non-relational database system (NoSQL)",
            "updated": "2023-08-26T17:37:46Z",
            "published": "2023-08-26T17:37:46Z",
            "summary": "This study aims to enhance data consistency in NoSQL databases, traditionally\ndesigned with BASE properties, as opposed to the strong consistency guaranteed\nby ACID principles in RDBMS. We introduce a comprehensive four-stage\nserver-side model engineered explicitly for MongoDB. This model covers\ntransaction management, bifurcation of read and write transactions, assessment\nof transaction readiness, and transaction execution via a specialized locking\nalgorithm. Utilizing the Yahoo Cloud Services Benchmark (YCSB), particularly\nfor update-heavy workloads (A, B, and F), our model exhibited significant\nimprovements. Specifically, the average throughput, read, and update latencies\nimproved to 2864.726 ms, 32806.275 ms, and 51845.629 ms, respectively, from the\nbaseline metrics of 2914.110 ms, 26510.930 ms, and 32457.662 ms. These results\ndemonstrate the efficacy of our proposed model in enhancing consistency not\nonly in document-based NoSQL databases like MongoDB but also in other NoSQL\ndatabase variants, including key-value, graph, and wide-column stores.",
            "author": [
                "Adam A. E. Alflahi",
                "Mohammed A. Y. Mohammed",
                "Abdallah Alsammani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13921v1",
                "http://arxiv.org/pdf/2308.13921v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13916v3",
            "title": "Exploring Large Language Models for Knowledge Graph Completion",
            "updated": "2023-09-10T17:42:37Z",
            "published": "2023-08-26T16:51:17Z",
            "summary": "Knowledge graphs play a vital role in numerous artificial intelligence tasks,\nyet they frequently face the issue of incompleteness. In this study, we explore\nutilizing Large Language Models (LLM) for knowledge graph completion. We\nconsider triples in knowledge graphs as text sequences and introduce an\ninnovative framework called Knowledge Graph LLM (KG-LLM) to model these\ntriples. Our technique employs entity and relation descriptions of a triple as\nprompts and utilizes the response for predictions. Experiments on various\nbenchmark knowledge graphs demonstrate that our method attains state-of-the-art\nperformance in tasks such as triple classification and relation prediction. We\nalso find that fine-tuning relatively smaller models (e.g., LLaMA-7B,\nChatGLM-6B) outperforms recent ChatGPT and GPT-4.",
            "author": [
                "Liang Yao",
                "Jiazhen Peng",
                "Chengsheng Mao",
                "Yuan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13916v3",
                "http://arxiv.org/pdf/2308.13916v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13913v1",
            "title": "Spectral Theory of Isogeny Graphs",
            "updated": "2023-08-26T16:30:32Z",
            "published": "2023-08-26T16:30:32Z",
            "summary": "We consider finite graphs whose vertexes are supersingular elliptic curves,\npossibly with level structure, and edges are isogenies. They can be applied to\nthe study of modular forms and to isogeny based cryptography. The main result\nof this paper says that these graphs have the Ramanujan property, which means\nthat the eigenvalues of their adjacency matrices are as small as possible. We\nalso study the asymptotic distribution of the eigenvalues of the adjacency\nmatrices, the number of connected components, the automorphisms of the graphs,\nand the connection between the graphs and modular forms.",
            "author": [
                "Giulio Codogni",
                "Guido Lido"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13913v1",
                "http://arxiv.org/pdf/2308.13913v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.AG",
                "14K02, 14H52, 11F52, 05C48, 14G50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13898v1",
            "title": "Memory-aware Scheduling for Complex Wired Networks with Iterative Graph\n  Optimization",
            "updated": "2023-08-26T14:52:02Z",
            "published": "2023-08-26T14:52:02Z",
            "summary": "Memory-aware network scheduling is becoming increasingly important for deep\nneural network (DNN) inference on resource-constrained devices. However, due to\nthe complex cell-level and network-level topologies, memory-aware scheduling\nbecomes very challenging. While previous algorithms all suffer from poor\nscalability, in this paper, we propose an efficient memory-aware scheduling\nframework based on iterative computation graph optimization. Our framework\nfeatures an iterative graph fusion algorithm that simplifies the computation\ngraph while preserving the scheduling optimality. We further propose an integer\nlinear programming formulation together with topology-aware variable pruning to\nschedule the simplified graph efficiently. We evaluate our method against\nprior-art algorithms on different networks and demonstrate that our method\noutperforms existing techniques in all the benchmarks, reducing the peak memory\nfootprint by 13.4%, and achieving better scalability for networks with complex\nnetwork-level topologies.",
            "author": [
                "Shuzhang Zhong",
                "Meng Li",
                "Yun Liang",
                "Runsheng Wang",
                "Ru Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13898v1",
                "http://arxiv.org/pdf/2308.13898v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13890v3",
            "title": "Spanning Adjacency Oracles in Sublinear Time",
            "updated": "2023-11-26T09:31:03Z",
            "published": "2023-08-26T14:21:21Z",
            "summary": "Suppose we are given an $n$-node, $m$-edge input graph $G$, and the goal is\nto compute a spanning subgraph $H$ on $O(n)$ edges. This can be achieved in\nlinear $O(m + n)$ time via breadth-first search. But can we hope for\n\\emph{sublinear} runtime in some range of parameters?\n  If the goal is to return $H$ as an adjacency list, there are simple lower\nbounds showing that $\\Omega(m + n)$ runtime is necessary. If the goal is to\nreturn $H$ as an adjacency matrix, then we need $\\Omega(n^2)$ time just to\nwrite down the entries of the output matrix. However, we show that neither of\nthese lower bounds still apply if instead the goal is to return $H$ as an\n\\emph{implicit} adjacency matrix, which we call an \\emph{adjacency oracle}. An\nadjacency oracle is a data structure that gives a user the illusion that an\nadjacency matrix has been computed: it accepts edge queries $(u, v)$, and it\nreturns in near-constant time a bit indicating whether $(u, v) \\in E(H)$.\n  Our main result is that one can construct an adjacency oracle for a spanning\nsubgraph on at most $(1+\\varepsilon)n$ edges, in $\\tilde{O}(n\n\\varepsilon^{-1})$ time, and that this construction time is near-optimal.\nAdditional results include constructions of adjacency oracles for\n$k$-connectivity certificates and spanners, which are similarly sublinear on\ndense-enough input graphs.\n  Our adjacency oracles are closely related to Local Computation Algorithms\n(LCAs) for graph sparsifiers; they can be viewed as LCAs with some computation\nmoved to a preprocessing step, in order to speed up queries. Our oracles imply\nthe first Local algorithm for computing sparse spanning subgraphs of general\ninput graphs in $\\tilde{O}(n)$ query time, which works by constructing our\nadjacency oracle, querying it once, and then throwing the rest of the oracle\naway. This addresses an open problem of Rubinfeld [CSR '17].",
            "author": [
                "Greg Bodwin",
                "Henry Fleischmann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13890v3",
                "http://arxiv.org/pdf/2308.13890v3"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13887v1",
            "title": "Quantum walks on blow-up graphs",
            "updated": "2023-08-26T14:07:25Z",
            "published": "2023-08-26T14:07:25Z",
            "summary": "A blow-up of $n$ copies of a graph $G$ is the graph $\\overset{n}\\uplus~G$\nobtained by replacing every vertex of $G$ by an independent set of size $n$,\nwhere the copies of vertices in $G$ are adjacent in the blow-up if and only if\nthe vertices adjacent in $G$. Our goal is to investigate the existence of\nquantum state transfer on a blow-up graph $\\overset{n}\\uplus~G$, where the\nadjacency matrix is taken to be the time-independent Hamiltonian of the quantum\nsystem represented by $\\overset{n}\\uplus~G$. In particular, we establish\nnecessary and sufficient conditions for vertices in a blow-up graph to exhibit\nstrong cospectrality and various types of high probability quantum transport,\nsuch as periodicity, perfect state transfer (PST) and pretty good state\ntransfer (PGST). It turns out, if $\\overset{n}\\uplus~G$ admits PST or PGST,\nthen one must have $n=2.$ Moreover, if $G$ has an invertible adjacency matrix,\nthen we show that every vertex in $\\overset{2}\\uplus~G$ pairs up with a unique\nvertex to exhibit strong cospectrality. We then apply our results to determine\ninfinite families of graphs whose blow-ups admit PST and PGST.",
            "author": [
                "Bikash Bhattacharjya",
                "Hermie Monterde",
                "Hiranmoy Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13887v1",
                "http://arxiv.org/pdf/2308.13887v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.CO",
                "05C50, 05C76, 15A16, 15A18, 81P45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13874v1",
            "title": "Sufficient conditions for $k$-factors and spanning trees of graphs",
            "updated": "2023-08-26T13:17:25Z",
            "published": "2023-08-26T13:17:25Z",
            "summary": "For any integer $k\\geq1,$ a graph $G$ has a $k$-factor if it contains a\n$k$-regular spanning subgraph. In this paper we prove a sufficient condition in\nterms of the number of $r$-cliques to guarantee the existence of a $k$-factor\nin a graph with minimum degree at least $\\delta$, which improves the sufficient\ncondition of O \\cite{O2021} based on the number of edges. For any integer\n$k\\geq2,$ a spanning $k$-tree of a connected graph $G$ is a spanning tree in\nwhich every vertex has degree at most $k$. Motivated by the technique of Li and\nNing \\cite{Li2016}, we present a tight spectral condition for an $m$-connected\ngraph to have a spanning $k$-tree, which extends the result of Fan, Goryainov,\nHuang and Lin \\cite{Fan2021} from $m=1$ to general $m$. Let $T$ be a spanning\ntree of a connected graph. The leaf degree of $T$ is the maximum number of\nleaves adjacent to $v$ in $T$ for any $v\\in V(T)$. We provide a tight spectral\ncondition for the existence of a spanning tree with leaf degree at most $k$ in\na connected graph with minimum degree $\\delta$, where $k\\geq1$ is an integer.",
            "author": [
                "Guoyan Ao",
                "Ruifang Liu",
                "Jinjiang Yuan",
                "C. T. Ng",
                "T. C. E. Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13874v1",
                "http://arxiv.org/pdf/2308.13874v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13871v1",
            "title": "Graph Edit Distance Learning via Different Attention",
            "updated": "2023-08-26T13:05:01Z",
            "published": "2023-08-26T13:05:01Z",
            "summary": "Recently, more and more research has focused on using Graph Neural Networks\n(GNN) to solve the Graph Similarity Computation problem (GSC), i.e., computing\nthe Graph Edit Distance (GED) between two graphs. These methods treat GSC as an\nend-to-end learnable task, and the core of their architecture is the feature\nfusion modules to interact with the features of two graphs. Existing methods\nconsider that graph-level embedding is difficult to capture the differences in\nlocal small structures between two graphs, and thus perform fine-grained\nfeature fusion on node-level embedding can improve the accuracy, but leads to\ngreater time and memory consumption in the training and inference phases.\nHowever, this paper proposes a novel graph-level fusion module Different\nAttention (DiffAtt), and demonstrates that graph-level fusion embeddings can\nsubstantially outperform these complex node-level fusion embeddings. We posit\nthat the relative difference structure of the two graphs plays an important\nrole in calculating their GED values. To this end, DiffAtt uses the difference\nbetween two graph-level embeddings as an attentional mechanism to capture the\ngraph structural difference of the two graphs. Based on DiffAtt, a new GSC\nmethod, named Graph Edit Distance Learning via Different Attention (REDRAFT),\nis proposed, and experimental results demonstrate that REDRAFT achieves\nstate-of-the-art performance in 23 out of 25 metrics in five benchmark\ndatasets. Especially on MSE, it respectively outperforms the second best by\n19.9%, 48.8%, 29.1%, 31.6%, and 2.2%. Moreover, we propose a quantitative test\nRemaining Subgraph Alignment Test (RESAT) to verify that among all graph-level\nfusion modules, the fusion embedding generated by DiffAtt can best capture the\nstructural differences between two graphs.",
            "author": [
                "Jiaxi Lv",
                "Liang Zhang",
                "Yi Huang",
                "Jiancheng Huang",
                "Shifeng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13871v1",
                "http://arxiv.org/pdf/2308.13871v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13868v3",
            "title": "A Graph-Theoretic Model for a Generic Three Jug Puzzle",
            "updated": "2023-09-30T08:14:06Z",
            "published": "2023-08-26T12:57:38Z",
            "summary": "In a classic three jug puzzle we have three jugs $A$, $B$, and $C$ with some\nfixed capacities. The jug $A$ is fully filled with wine to its capacity. The\ngoal of the puzzle is to divide the wine into two equal halves by pouring it\nfrom one jug to another without using any other measuring devices. However, we\nconsider a generic version of the three jug puzzle and present an independent\ngraph theoretic model to determine whether the puzzle has a solution at first\nplace. If it has a solution, then the same can be determined using this model.\nWe also present the sketch of an algorithm to determine the solution of the\npuzzle.",
            "author": [
                "Suresh Manjanath Hegde",
                "Shashanka Kulamarva"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13868v3",
                "http://arxiv.org/pdf/2308.13868v3"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "cs.DM",
                "math.CO",
                "05C20, 05C90"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13849v1",
            "title": "Effectively Heterogeneous Federated Learning: A Pairing and Split\n  Learning Based Approach",
            "updated": "2023-08-26T11:10:54Z",
            "published": "2023-08-26T11:10:54Z",
            "summary": "As a promising paradigm federated Learning (FL) is widely used in\nprivacy-preserving machine learning, which allows distributed devices to\ncollaboratively train a model while avoiding data transmission among clients.\nDespite its immense potential, the FL suffers from bottlenecks in training\nspeed due to client heterogeneity, leading to escalated training latency and\nstraggling server aggregation. To deal with this challenge, a novel split\nfederated learning (SFL) framework that pairs clients with different\ncomputational resources is proposed, where clients are paired based on\ncomputing resources and communication rates among clients, meanwhile the neural\nnetwork model is split into two parts at the logical level, and each client\nonly computes the part assigned to it by using the SL to achieve forward\ninference and backward training. Moreover, to effectively deal with the client\npairing problem, a heuristic greedy algorithm is proposed by reconstructing the\noptimization of training latency as a graph edge selection problem. Simulation\nresults show the proposed method can significantly improve the FL training\nspeed and achieve high performance both in independent identical distribution\n(IID) and Non-IID data distribution.",
            "author": [
                "Jinglong Shen",
                "Xiucheng Wang",
                "Nan Cheng",
                "Longfei Ma",
                "Conghao Zhou",
                "Yuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13849v1",
                "http://arxiv.org/pdf/2308.13849v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13836v1",
            "title": "SoK: Authenticated Prefix Relations -- A Unified Perspective On Relative\n  Time-Stamping and Append-Only Logs",
            "updated": "2023-08-26T10:04:37Z",
            "published": "2023-08-26T10:04:37Z",
            "summary": "Secure relative timestamping and secure append-only logs are two historically\nmostly independent lines of research, which we show to be sides of the same\ncoin -- the authentication of prefix relations. From this more general\nviewpoint, we derive several complexity criteria not yet considered in previous\nliterature. We define transitive prefix authentication graphs, a graph class\nthat captures all hash-based timestamping and log designs we know of. We survey\nexisting schemes by expressing them as transitive prefix authentication graphs,\nwhich yields more compact definitions and more complete evaluations than in the\nexisting literature.",
            "author": [
                "Aljoscha Meyer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13836v1",
                "http://arxiv.org/pdf/2308.13836v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13827v1",
            "title": "An exhaustive ADDIS principle for online FWER control",
            "updated": "2023-08-26T09:37:54Z",
            "published": "2023-08-26T09:37:54Z",
            "summary": "In this paper we consider online multiple testing with familywise error rate\n(FWER) control, where the probability of committing at least one type I error\nshall remain under control while testing a possibly infinite sequence of\nhypotheses over time. Currently, Adaptive-Discard (ADDIS) procedures seem to be\nthe most promising online procedures with FWER control in terms of power. Now,\nour main contribution is a uniform improvement of the ADDIS principle and thus\nof all ADDIS procedures. This means, the methods we propose reject as least as\nmuch hypotheses as ADDIS procedures and in some cases even more, while\nmaintaining FWER control. In addition, we show that our principle cannot be\nfurther uniformly improved. Finally, we apply the new principle to derive\nuniform improvements of the ADDIS-Spending and ADDIS-Graph.",
            "author": [
                "Lasse Fischer",
                "Marta Bofill Roig",
                "Werner Brannath"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13827v1",
                "http://arxiv.org/pdf/2308.13827v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13826v1",
            "title": "Evaluating Deep Learning Assisted Automated Aquaculture Net Pens\n  Inspection Using ROV",
            "updated": "2023-08-26T09:35:49Z",
            "published": "2023-08-26T09:35:49Z",
            "summary": "In marine aquaculture, inspecting sea cages is an essential activity for\nmanaging both the facilities' environmental impact and the quality of the fish\ndevelopment process. Fish escape from fish farms into the open sea due to net\ndamage, which can result in significant financial losses and compromise the\nnearby marine ecosystem. The traditional inspection system in use relies on\nvisual inspection by expert divers or ROVs, which is not only laborious,\ntime-consuming, and inaccurate but also largely dependent on the level of\nknowledge of the operator and has a poor degree of verifiability. This article\npresents a robotic-based automatic net defect detection system for aquaculture\nnet pens oriented to on-ROV processing and real-time detection. The proposed\nsystem takes a video stream from an onboard camera of the ROV, employs a deep\nlearning detector, and segments the defective part of the image from the\nbackground under different underwater conditions. The system was first tested\nusing a set of collected images for comparison with the state-of-the-art\napproaches and then using the ROV inspection sequences to evaluate its\neffectiveness in real-world scenarios. Results show that our approach presents\nhigh levels of accuracy even for adverse scenarios and is adequate for\nreal-time processing on embedded platforms.",
            "author": [
                "Waseem Akram",
                "Muhayyuddin Ahmed",
                "Lakmal Seneviratne",
                "Irfan Hussain"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13826v1",
                "http://arxiv.org/pdf/2308.13826v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13821v2",
            "title": "A Survey of Imbalanced Learning on Graphs: Problems, Techniques, and\n  Future Directions",
            "updated": "2023-08-29T09:31:11Z",
            "published": "2023-08-26T09:11:44Z",
            "summary": "Graphs represent interconnected structures prevalent in a myriad of\nreal-world scenarios. Effective graph analytics, such as graph learning\nmethods, enables users to gain profound insights from graph data, underpinning\nvarious tasks including node classification and link prediction. However, these\nmethods often suffer from data imbalance, a common issue in graph data where\ncertain segments possess abundant data while others are scarce, thereby leading\nto biased learning outcomes. This necessitates the emerging field of imbalanced\nlearning on graphs, which aims to correct these data distribution skews for\nmore accurate and representative learning outcomes. In this survey, we embark\non a comprehensive review of the literature on imbalanced learning on graphs.\nWe begin by providing a definitive understanding of the concept and related\nterminologies, establishing a strong foundational understanding for readers.\nFollowing this, we propose two comprehensive taxonomies: (1) the problem\ntaxonomy, which describes the forms of imbalance we consider, the associated\ntasks, and potential solutions; (2) the technique taxonomy, which details key\nstrategies for addressing these imbalances, and aids readers in their method\nselection process. Finally, we suggest prospective future directions for both\nproblems and techniques within the sphere of imbalanced learning on graphs,\nfostering further innovation in this critical area.",
            "author": [
                "Zemin Liu",
                "Yuan Li",
                "Nan Chen",
                "Qian Wang",
                "Bryan Hooi",
                "Bingsheng He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13821v2",
                "http://arxiv.org/pdf/2308.13821v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13819v1",
            "title": "Guaranteed Stable Quadratic Models and their applications in SINDy and\n  Operator Inference",
            "updated": "2023-08-26T09:00:31Z",
            "published": "2023-08-26T09:00:31Z",
            "summary": "Scientific machine learning for learning dynamical systems is a powerful tool\nthat combines data-driven modeling models, physics-based modeling, and\nempirical knowledge. It plays an essential role in an engineering design cycle\nand digital twinning. In this work, we primarily focus on an operator inference\nmethodology that builds dynamical models, preferably in low-dimension, with a\nprior hypothesis on the model structure, often determined by known physics or\ngiven by experts. Then, for inference, we aim to learn the operators of a model\nby setting up an appropriate optimization problem. One of the critical\nproperties of dynamical systems is{stability. However, such a property is not\nguaranteed by the inferred models. In this work, we propose inference\nformulations to learn quadratic models, which are stable by design. Precisely,\nwe discuss the parameterization of quadratic systems that are locally and\nglobally stable. Moreover, for quadratic systems with no stable point yet\nbounded (e.g., Chaotic Lorenz model), we discuss an attractive trapping region\nphilosophy and a parameterization of such systems. Using those\nparameterizations, we set up inference problems, which are then solved using a\ngradient-based optimization method. Furthermore, to avoid numerical derivatives\nand still learn continuous systems, we make use of an integration form of\ndifferential equations. We present several numerical examples, illustrating the\npreservation of stability and discussing its comparison with the existing\nstate-of-the-art approach to infer operators. By means of numerical examples,\nwe also demonstrate how proposed methods are employed to discover governing\nequations and energy-preserving models.",
            "author": [
                "Pawan Goyal",
                "Igor Pontes Duff",
                "Peter Benner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13819v1",
                "http://arxiv.org/pdf/2308.13819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.DS",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13812v1",
            "title": "Empowering Dynamics-aware Text-to-Video Diffusion with Large Language\n  Models",
            "updated": "2023-08-26T08:31:48Z",
            "published": "2023-08-26T08:31:48Z",
            "summary": "Text-to-video (T2V) synthesis has gained increasing attention in the\ncommunity, in which the recently emerged diffusion models (DMs) have\npromisingly shown stronger performance than the past approaches. While existing\nstate-of-the-art DMs are competent to achieve high-resolution video generation,\nthey may largely suffer from key limitations (e.g., action occurrence\ndisorders, crude video motions) with respect to the intricate temporal dynamics\nmodeling, one of the crux of video synthesis. In this work, we investigate\nstrengthening the awareness of video dynamics for DMs, for high-quality T2V\ngeneration. Inspired by human intuition, we design an innovative dynamic scene\nmanager (dubbed as Dysen) module, which includes (step-1) extracting from input\ntext the key actions with proper time-order arrangement, (step-2) transforming\nthe action schedules into the dynamic scene graph (DSG) representations, and\n(step-3) enriching the scenes in the DSG with sufficient and reasonable\ndetails. Taking advantage of the existing powerful LLMs (e.g., ChatGPT) via\nin-context learning, Dysen realizes (nearly) human-level temporal dynamics\nunderstanding. Finally, the resulting video DSG with rich action scene details\nis encoded as fine-grained spatio-temporal features, integrated into the\nbackbone T2V DM for video generating. Experiments on popular T2V datasets\nsuggest that our framework consistently outperforms prior arts with significant\nmargins, especially in the scenario with complex actions. Project page at\nhttps://haofei.vip/Dysen-VDM",
            "author": [
                "Hao Fei",
                "Shengqiong Wu",
                "Wei Ji",
                "Hanwang Zhang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13812v1",
                "http://arxiv.org/pdf/2308.13812v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13806v1",
            "title": "Mobile robots sampling algorithms for monitoring of insects populations\n  in agricultural fields",
            "updated": "2023-08-26T08:12:18Z",
            "published": "2023-08-26T08:12:18Z",
            "summary": "Plant diseases are major causes of production losses and may have a\nsignificant impact on the agricultural sector. Detecting pests as early as\npossible can help increase crop yields and production efficiency. Several\nrobotic monitoring systems have been developed allowing to collect data and\nprovide a greater understanding of environmental processes. An agricultural\nrobot can enable accurate timely detection of pests, by traversing the field\nautonomously and monitoring the entire cropped area within a field. However, in\nmany cases it is impossible to sample all plants due to resource limitations.\nIn this thesis, the development and evaluation of several sampling algorithms\nare presented to address the challenge of an agriculture-monitoring ground\nrobot designed to locate insects in an agricultural field, where complete\nsampling of all the plants is infeasible. Two situations were investigated in\nsimulation models that were specially developed as part of this thesis: where\nno a-priori information on the insects is available and where prior information\non the insects distributions within the field is known. For the first\nsituation, seven algorithms were tested, each utilizing an approach to sample\nthe field without prior knowledge of it. For the second situation, we present\nthe development and evaluation of a dynamic sampling algorithm which utilizes\nreal-time information to prioritize sampling at suspected points, locate hot\nspots and adapt sampling plans accordingly. The algorithm's performance was\ncompared to two existing algorithms using Tetranychidae insect data from\nprevious research. Analyses revealed that the dynamic algorithm outperformed\nthe others.",
            "author": [
                "Adi Yehoshua",
                "Yael Edan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13806v1",
                "http://arxiv.org/pdf/2308.13806v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13798v1",
            "title": "DM-VTON: Distilled Mobile Real-time Virtual Try-On",
            "updated": "2023-08-26T07:46:27Z",
            "published": "2023-08-26T07:46:27Z",
            "summary": "The fashion e-commerce industry has witnessed significant growth in recent\nyears, prompting exploring image-based virtual try-on techniques to incorporate\nAugmented Reality (AR) experiences into online shopping platforms. However,\nexisting research has primarily overlooked a crucial aspect - the runtime of\nthe underlying machine-learning model. While existing methods prioritize\nenhancing output quality, they often disregard the execution time, which\nrestricts their applications on a limited range of devices. To address this\ngap, we propose Distilled Mobile Real-time Virtual Try-On (DM-VTON), a novel\nvirtual try-on framework designed to achieve simplicity and efficiency. Our\napproach is based on a knowledge distillation scheme that leverages a strong\nTeacher network as supervision to guide a Student network without relying on\nhuman parsing. Notably, we introduce an efficient Mobile Generative Module\nwithin the Student network, significantly reducing the runtime while ensuring\nhigh-quality output. Additionally, we propose Virtual Try-on-guided Pose for\nData Synthesis to address the limited pose variation observed in training\nimages. Experimental results show that the proposed method can achieve 40\nframes per second on a single Nvidia Tesla T4 GPU and only take up 37 MB of\nmemory while producing almost the same output quality as other state-of-the-art\nmethods. DM-VTON stands poised to facilitate the advancement of real-time AR\napplications, in addition to the generation of lifelike attired human figures\ntailored for diverse specialized training tasks.\nhttps://sites.google.com/view/ltnghia/research/DMVTON",
            "author": [
                "Khoi-Nguyen Nguyen-Ngoc",
                "Thanh-Tung Phan-Nguyen",
                "Khanh-Duy Le",
                "Tam V. Nguyen",
                "Minh-Triet Tran",
                "Trung-Nghia Le"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13798v1",
                "http://arxiv.org/pdf/2308.13798v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13797v1",
            "title": "DeLELSTM: Decomposition-based Linear Explainable LSTM to Capture\n  Instantaneous and Long-term Effects in Time Series",
            "updated": "2023-08-26T07:45:41Z",
            "published": "2023-08-26T07:45:41Z",
            "summary": "Time series forecasting is prevalent in various real-world applications.\nDespite the promising results of deep learning models in time series\nforecasting, especially the Recurrent Neural Networks (RNNs), the explanations\nof time series models, which are critical in high-stakes applications, have\nreceived little attention. In this paper, we propose a Decomposition-based\nLinear Explainable LSTM (DeLELSTM) to improve the interpretability of LSTM.\nConventionally, the interpretability of RNNs only concentrates on the variable\nimportance and time importance. We additionally distinguish between the\ninstantaneous influence of new coming data and the long-term effects of\nhistorical data. Specifically, DeLELSTM consists of two components, i.e.,\nstandard LSTM and tensorized LSTM. The tensorized LSTM assigns each variable\nwith a unique hidden state making up a matrix $\\mathbf{h}_t$, and the standard\nLSTM models all the variables with a shared hidden state $\\mathbf{H}_t$. By\ndecomposing the $\\mathbf{H}_t$ into the linear combination of past information\n$\\mathbf{h}_{t-1}$ and the fresh information $\\mathbf{h}_{t}-\\mathbf{h}_{t-1}$,\nwe can get the instantaneous influence and the long-term effect of each\nvariable. In addition, the advantage of linear regression also makes the\nexplanation transparent and clear. We demonstrate the effectiveness and\ninterpretability of DeLELSTM on three empirical datasets. Extensive experiments\nshow that the proposed method achieves competitive performance against the\nbaseline methods and provides a reliable explanation relative to domain\nknowledge.",
            "author": [
                "Chaoqun Wang",
                "Yijun Li",
                "Xiangqian Sun",
                "Qi Wu",
                "Dongdong Wang",
                "Zhixiang Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13797v1",
                "http://arxiv.org/pdf/2308.13797v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13793v1",
            "title": "Cooperative Resource Trading for Network Slicing in Industrial IoT: A\n  Multi-Agent DRL Approach",
            "updated": "2023-08-26T07:35:40Z",
            "published": "2023-08-26T07:35:40Z",
            "summary": "The industrial Internet of Things (IIoT) and network slicing (NS) paradigms\nhave been envisioned as key enablers for flexible and intelligent manufacturing\nin the industry 4.0, where a myriad of interconnected machines, sensors, and\ndevices of diversified quality of service (QoS) requirements coexist. To\noptimize network resource usage, stakeholders in the IIoT network are\nencouraged to take pragmatic steps towards resource sharing. However, resource\nsharing is only attractive if the entities involved are able to settle on a\nfair exchange of resource for remuneration in a win-win situation. In this\npaper, we design an economic model that analyzes the multilateral strategic\ntrading interactions between sliced tenants in IIoT networks. We formulate the\nresource pricing and purchasing problem of the seller and buyer tenants as a\ncooperative Stackelberg game. Particularly, the cooperative game enforces\ncollaboration among the buyer tenants by coalition formation in order to\nstrengthen their position in resource price negotiations as opposed to acting\nindividually, while the Stackelberg game determines the optimal policy\noptimization of the seller tenants and buyer tenant coalitions. To achieve a\nStackelberg equilibrium (SE), a multi-agent deep reinforcement learning (MADRL)\nmethod is developed to make flexible pricing and purchasing decisions without\nprior knowledge of the environment. Simulation results and analysis prove that\nthe proposed method achieves convergence and is superior to other baselines, in\nterms of utility maximization.",
            "author": [
                "Gordon Owusu Boateng",
                "Guisong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13793v1",
                "http://arxiv.org/pdf/2308.13793v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13782v1",
            "title": "Planning with Logical Graph-based Language Model for Instruction\n  Generation",
            "updated": "2023-08-26T06:28:14Z",
            "published": "2023-08-26T06:28:14Z",
            "summary": "Despite the superior performance of large language models to generate natural\nlanguage texts, it is hard to generate texts with correct logic according to a\ngiven task, due to the difficulties for neural models to capture implied rules\nfrom free-form texts. In this paper, we propose a novel graph-based language\nmodel, Logical-GLM, to infuse logic into language models for more valid text\ngeneration and interpretability. Specifically, we first capture information\nfrom natural language instructions and construct logical bayes graphs that\ngenerally describe domains. Next, we generate logical skeletons to guide\nlanguage model training, infusing domain knowledge into language models.\nFinally, we alternately optimize the searching policy of graphs and language\nmodels until convergence. The experimental results show that Logical-GLM is\nboth effective and efficient compared with traditional language models, despite\nusing smaller-scale training data and fewer parameters. Our approach can\ngenerate instructional texts with more correct logic owing to the internalized\ndomain knowledge. Moreover, the usage of logical graphs reflects the inner\nmechanism of the language models, which improves the interpretability of\nblack-box models.",
            "author": [
                "Fan Zhang",
                "Kebing Jin",
                "Hankz Hankui Zhuo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13782v1",
                "http://arxiv.org/pdf/2308.13782v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13772v1",
            "title": "Boosting Residual Networks with Group Knowledge",
            "updated": "2023-08-26T05:39:57Z",
            "published": "2023-08-26T05:39:57Z",
            "summary": "Recent research understands the residual networks from a new perspective of\nthe implicit ensemble model. From this view, previous methods such as\nstochastic depth and stimulative training have further improved the performance\nof the residual network by sampling and training of its subnets. However, they\nboth use the same supervision for all subnets of different capacities and\nneglect the valuable knowledge generated by subnets during training. In this\nmanuscript, we mitigate the significant knowledge distillation gap caused by\nusing the same kind of supervision and advocate leveraging the subnets to\nprovide diverse knowledge. Based on this motivation, we propose a group\nknowledge based training framework for boosting the performance of residual\nnetworks. Specifically, we implicitly divide all subnets into hierarchical\ngroups by subnet-in-subnet sampling, aggregate the knowledge of different\nsubnets in each group during training, and exploit upper-level group knowledge\nto supervise lower-level subnet groups. Meanwhile, We also develop a subnet\nsampling strategy that naturally samples larger subnets, which are found to be\nmore helpful than smaller subnets in boosting performance for hierarchical\ngroups. Compared with typical subnet training and other methods, our method\nachieves the best efficiency and performance trade-offs on multiple datasets\nand network structures. The code will be released soon.",
            "author": [
                "Shengji Tang",
                "Peng Ye",
                "Baopu Li",
                "Weihao Lin",
                "Tao Chen",
                "Tong He",
                "Chong Yu",
                "Wanli Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13772v1",
                "http://arxiv.org/pdf/2308.13772v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13759v1",
            "title": "SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge\n  for Semi-Supervised Learning in Medical Image Segmentation",
            "updated": "2023-08-26T04:46:10Z",
            "published": "2023-08-26T04:46:10Z",
            "summary": "The Segment Anything Model (SAM) exhibits a capability to segment a wide\narray of objects in natural images, serving as a versatile perceptual tool for\nvarious downstream image segmentation tasks. In contrast, medical image\nsegmentation tasks often rely on domain-specific knowledge (DSK). In this\npaper, we propose a novel method that combines the segmentation foundation\nmodel (i.e., SAM) with domain-specific knowledge for reliable utilization of\nunlabeled images in building a medical image segmentation model. Our new method\nis iterative and consists of two main stages: (1) segmentation model training;\n(2) expanding the labeled set by using the trained segmentation model, an\nunlabeled set, SAM, and domain-specific knowledge. These two stages are\nrepeated until no more samples are added to the labeled set. A novel\noptimal-matching-based method is developed for combining the SAM-generated\nsegmentation proposals and pixel-level and image-level DSK for constructing\nannotations of unlabeled images in the iterative stage (2). In experiments, we\ndemonstrate the effectiveness of our proposed method for breast cancer\nsegmentation in ultrasound images, polyp segmentation in endoscopic images, and\nskin lesion segmentation in dermoscopic images. Our work initiates a new\ndirection of semi-supervised learning for medical image segmentation: the\nsegmentation foundation model can be harnessed as a valuable tool for\nlabel-efficient segmentation learning in medical image segmentation.",
            "author": [
                "Yizhe Zhang",
                "Tao Zhou",
                "Shuo Wang",
                "Ye Wu",
                "Pengfei Gu",
                "Danny Z. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13759v1",
                "http://arxiv.org/pdf/2308.13759v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13755v1",
            "title": "i-Align: an interpretable knowledge graph alignment model",
            "updated": "2023-08-26T03:48:52Z",
            "published": "2023-08-26T03:48:52Z",
            "summary": "Knowledge graphs (KGs) are becoming essential resources for many downstream\napplications. However, their incompleteness may limit their potential. Thus,\ncontinuous curation is needed to mitigate this problem. One of the strategies\nto address this problem is KG alignment, i.e., forming a more complete KG by\nmerging two or more KGs. This paper proposes i-Align, an interpretable KG\nalignment model. Unlike the existing KG alignment models, i-Align provides an\nexplanation for each alignment prediction while maintaining high alignment\nperformance. Experts can use the explanation to check the correctness of the\nalignment prediction. Thus, the high quality of a KG can be maintained during\nthe curation process (e.g., the merging process of two KGs). To this end, a\nnovel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component\nof i-Align for aggregating information from entities' neighbors (structures).\nTrans-GE uses Edge-gated Attention that combines the adjacency matrix and the\nself-attention matrix to learn a gating mechanism to control the information\naggregation from the neighboring entities. It also uses historical embeddings,\nallowing Trans-GE to be trained over mini-batches, or smaller sub-graphs, to\naddress the scalability issue when encoding a large KG. Another component of\ni-Align is a Transformer encoder for aggregating entities' attributes. This\nway, i-Align can generate explanations in the form of a set of the most\ninfluential attributes/neighbors based on attention weights. Extensive\nexperiments are conducted to show the power of i-Align. The experiments include\nseveral aspects, such as the model's effectiveness for aligning KGs, the\nquality of the generated explanations, and its practicality for aligning large\nKGs. The results show the effectiveness of i-Align in these aspects.",
            "author": [
                "Bayu Distiawan Trisedya",
                "Flora D Salim",
                "Jeffrey Chan",
                "Damiano Spina",
                "Falk Scholer",
                "Mark Sanderson"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s10618-023-00963-3",
                "http://arxiv.org/abs/2308.13755v1",
                "http://arxiv.org/pdf/2308.13755v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13748v1",
            "title": "This paper presents a new application of Borsuk-Ulam's theorem to\n  nonlinear programming",
            "updated": "2023-08-26T03:18:11Z",
            "published": "2023-08-26T03:18:11Z",
            "summary": "Borsuk-Ulam's theorem is a useful tool of algebraic topology. It states that\nfor any continuous mapping $f$ from the $n$-sphere to the $n$-dimensional\nEuclidean space, there exists a pair of antipodal points such that\n$f(x)=f(-x)$. As for its applications, ham-sandwich theorem, necklace theorem\nand coloring of Kneser graph by Lov\\'{a}sz are well-known. This paper attempts\nto apply Borsuk-Ulam's theorem to nonlinear programming.",
            "author": [
                "Hidefumi Kawasaki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13748v1",
                "http://arxiv.org/pdf/2308.13748v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "90C31, 55M20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13746v1",
            "title": "PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation",
            "updated": "2023-08-26T03:11:48Z",
            "published": "2023-08-26T03:11:48Z",
            "summary": "Interactive medical image segmentation refers to the accurate segmentation of\nthe target of interest through interaction (e.g., click) between the user and\nthe image. It has been widely studied in recent years as it is less dependent\non abundant annotated data and more flexible than fully automated segmentation.\nHowever, current studies have not fully explored user-provided prompt\ninformation (e.g., points), including the knowledge mined in one interaction,\nand the relationship between multiple interactions. Thus, in this paper, we\nintroduce a novel framework equipped with prompt enhancement, called PE-MED,\nfor interactive medical image segmentation. First, we introduce a Self-Loop\nstrategy to generate warm initial segmentation results based on the first\nprompt. It can prevent the highly unfavorable scenarios, such as encountering a\nblank mask as the initial input after the first interaction. Second, we propose\na novel Prompt Attention Learning Module (PALM) to mine useful prompt\ninformation in one interaction, enhancing the responsiveness of the network to\nuser clicks. Last, we build a Time Series Information Propagation (TSIP)\nmechanism to extract the temporal relationships between multiple interactions\nand increase the model stability. Comparative experiments with other\nstate-of-the-art (SOTA) medical image segmentation algorithms show that our\nmethod exhibits better segmentation accuracy and stability.",
            "author": [
                "Ao Chang",
                "Xing Tao",
                "Xin Yang",
                "Yuhao Huang",
                "Xinrui Zhou",
                "Jiajun Zeng",
                "Ruobing Huang",
                "Dong Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13746v1",
                "http://arxiv.org/pdf/2308.13746v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13742v1",
            "title": "DP-Coloring of Graphs from Random Covers",
            "updated": "2023-08-26T03:02:43Z",
            "published": "2023-08-26T03:02:43Z",
            "summary": "DP-coloring (also called correspondence coloring) of graphs is a\ngeneralization of list coloring that has been widely studied since its\nintroduction by Dvo\\v{r}\\'{a}k and Postle in $2015$. DP-coloring of a graph $G$\nis equivalent to an independent transversal of a DP-cover of $G$. Intuitively,\na $k$-fold DP-cover of a graph $G$ is an assignment of lists of size $k$ to the\nvertices of $G$ where the names of colors vary from edge to edge. In this\npaper, we introduce the notion of random DP-covers and study the behavior of\nDP-coloring from such random covers. We prove a series of results about the\nprobability that a graph is or is not DP-colorable from a random cover. These\nresults support the following threshold behavior on random $k$-fold DP-covers\nas $\\rho\\to\\infty$ where $\\rho$ is the maximum density of a graph: graphs are\nnon-DP-colorable with high probability when $k$ is sufficiently smaller than\n$\\rho/\\ln\\rho$, and graphs are DP-colorable with high probability when $k$ is\nsufficiently larger than $\\rho/\\ln\\rho$. Our results depend on $\\rho$ growing\nfast enough and imply a sharp threshold for dense enough graphs. For sparser\ngraphs, we analyze DP-colorability in terms of degeneracy. We also prove\nfractional DP-coloring analogs to these results.",
            "author": [
                "Anton Bernshteyn",
                "Daniel Dominik",
                "Hemanshu Kaul",
                "Jeffrey A. Mudrock"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13742v1",
                "http://arxiv.org/pdf/2308.13742v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "05C15 (Primary) 05C69, 05C80 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13741v1",
            "title": "A method of approximation of discrete Schr\u00f6dinger equation with the\n  normalized Laplacian by discrete-time quantum walk on graphs",
            "updated": "2023-08-26T02:57:47Z",
            "published": "2023-08-26T02:57:47Z",
            "summary": "We propose a class of continuous-time quantum walk models on graphs induced\nby a certain class of discrete-time quantum walk models with the parameter\n$\\epsilon\\in [0,1]$. Here the graph treated in this paper can be applied both\nfinite and infinite cases. The induced continuous-time quantum walk is an\nextended version of the (free) discrete-Schr\\\"odinger equation driven by the\nnormalized Laplacian: the element of the weighted Hermitian takes not only a\nscalar value but also a matrix value depending on the underlying discrete-time\nquantum walk. We show that each discrete-time quantum walk with an appropriate\nsetting of the parameter $\\epsilon$ in the long time limit identifies with its\ninduced continuous-time quantum walk and give the running time for the\ndiscrete-time to approximate the induced continuous-time quantum walk with a\nsmall error $\\delta$. We also investigate the detailed spectral information on\nthe induced continuous-time quantum walk.",
            "author": [
                "Kei Saito",
                "Etsuo Segawa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13741v1",
                "http://arxiv.org/pdf/2308.13741v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13735v1",
            "title": "MST-compression: Compressing and Accelerating Binary Neural Networks\n  with Minimum Spanning Tree",
            "updated": "2023-08-26T02:42:12Z",
            "published": "2023-08-26T02:42:12Z",
            "summary": "Binary neural networks (BNNs) have been widely adopted to reduce the\ncomputational cost and memory storage on edge-computing devices by using\none-bit representation for activations and weights. However, as neural networks\nbecome wider/deeper to improve accuracy and meet practical requirements, the\ncomputational burden remains a significant challenge even on the binary\nversion. To address these issues, this paper proposes a novel method called\nMinimum Spanning Tree (MST) compression that learns to compress and accelerate\nBNNs. The proposed architecture leverages an observation from previous works\nthat an output channel in a binary convolution can be computed using another\noutput channel and XNOR operations with weights that differ from the weights of\nthe reused channel. We first construct a fully connected graph with vertices\ncorresponding to output channels, where the distance between two vertices is\nthe number of different values between the weight sets used for these outputs.\nThen, the MST of the graph with the minimum depth is proposed to reorder output\ncalculations, aiming to reduce computational cost and latency. Moreover, we\npropose a new learning algorithm to reduce the total MST distance during\ntraining. Experimental results on benchmark models demonstrate that our method\nachieves significant compression ratios with negligible accuracy drops, making\nit a promising approach for resource-constrained edge-computing devices.",
            "author": [
                "Quang Hieu Vo",
                "Linh-Tam Tran",
                "Sung-Ho Bae",
                "Lok-Won Kim",
                "Choong Seon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13735v1",
                "http://arxiv.org/pdf/2308.13735v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13713v2",
            "title": "Causally Sound Priors for Binary Experiments",
            "updated": "2023-10-31T17:36:22Z",
            "published": "2023-08-25T23:58:38Z",
            "summary": "We introduce the BREASE framework for the Bayesian analysis of randomized\ncontrolled trials with a binary treatment and a binary outcome. Approaching the\nproblem from a causal inference perspective, we propose parameterizing the\nlikelihood in terms of the baseline risk, efficacy, and adverse side effects of\nthe treatment, along with a flexible, yet intuitive and tractable jointly\nindependent beta prior distribution on these parameters, which we show to be a\ngeneralization of the Dirichlet prior for the joint distribution of potential\noutcomes. Our approach has a number of desirable characteristics when compared\nto current mainstream alternatives: (i) it naturally induces prior dependence\nbetween expected outcomes in the treatment and control groups; (ii) as the\nbaseline risk, efficacy and risk of adverse side effects are quantities\ncommonly present in the clinicians' vocabulary, the hyperparameters of the\nprior are directly interpretable, thus facilitating the elicitation of prior\nknowledge and sensitivity analysis; and (iii) we provide analytical formulae\nfor the marginal likelihood, Bayes factor, and other posterior quantities, as\nwell as exact posterior sampling via simulation, in cases where traditional\nMCMC fails. Empirical examples demonstrate the utility of our methods for\nestimation, hypothesis testing, and sensitivity analysis of treatment effects.",
            "author": [
                "Nicholas J. Irons",
                "Carlos Cinelli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13713v2",
                "http://arxiv.org/pdf/2308.13713v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13700v3",
            "title": "Multipartite Entanglement in Quantum Networks using Subgraph\n  Complementations",
            "updated": "2023-11-21T02:13:31Z",
            "published": "2023-08-25T23:03:25Z",
            "summary": "Quantum networks are networks of quantum devices that can communicate and\nperform computations using quantum states. Entangled states are the building\nblocks of quantum computing and are essential for many tasks such as quantum\nteleportation, quantum key distribution, quantum sensing and quantum error\ncorrection. Graph states are a specific class of multipartite entangled states\nthat can be represented by graphs. We propose a novel approach for distributing\ngraph states across a noiseless quantum network. We show that the distribution\nof graph states can be characterized by a system of subgraph complementations,\nwhich we also relate to the minimum rank of the underlying graph and the degree\nof entanglement quantified by the Schmidt-rank of the quantum state. We analyze\nresource usage for our algorithm and show that it improves on the number of\nqubits, bits for classical communication and EPR pairs utilized, as compared to\nprior work. The number of local operations and resource consumption for our\napproach scales linearly in the number of vertices. This produce a quadratic\nimprovement in completion time for several classes of graph states represented\nby dense graphs, and suggests the potential for improved fidelity in the\npresence of noise. Common classes of graph states are classified along with the\noptimal time for their distribution using subgraph complementations. We also\nprovide a framework to similarly find the optimal sequence of subgraph\ncomplementation operations to distribute an arbitrary graph state, and\nestablish upper bounds on distribution time along with providing approximate\ngreedy algorithms.",
            "author": [
                "Aniruddha Sen",
                "Kenneth Goodenough",
                "Don Towsley"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13700v3",
                "http://arxiv.org/pdf/2308.13700v3"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13689v1",
            "title": "Cubulating Infinity in Hierarchically Hyperbolic Spaces",
            "updated": "2023-08-25T22:09:32Z",
            "published": "2023-08-25T22:09:32Z",
            "summary": "We prove that the hierarchical hull of any finite set of interior points,\nhierarchy rays, and boundary points in a hierarchically hyperbolic space (HHS)\nis quasi-median quasi-isometric to a CAT(0) cube complex of bounded dimension.\nOur construction extends and refines a theorem of Behrstock-Hagen-Sisto about\nmodeling hulls of interior points and our previous work with Zalloum on\nmodeling finite sets of rays via limits of these finite models. We further\nprove that the quasi-median quasi-isometry between the hull of a finite set of\nrays or boundary points and its cubical model extends to an isomorphism between\ntheir respective hierarchical and simplicial boundaries. In this sense, we\nprove that the hierarchical boundary of any proper HHS is locally modeled by\nthe simplicial boundaries of CAT(0) cube complexes. This is a purely geometric\nstatement, allowing one to important various topologies from the cubical\nsetting. Our proof of the cubical model theorem is new, even for the interior\npoints case. In particular, we provide a concrete description of the cubical\nmodel as a cubical subcomplex of a product of simplicial trees into which the\nhierarchical data is directly encoded. Moreover, the above boundary isomorphism\nis new for all non-cubical HHSes, including mapping class groups and\nTeichm\\\"uller spaces of finite-type surfaces. As an application of our\ntechniques, we show that in most HHSes, including all hierarchically hyperbolic\ngroups, the distance between any pair of points in the top-level hyperbolic\nspace is coarsely the length of a maximal 0-separated chain of hyperplanes\nseparating them in an appropriate cubical model. For mapping class groups, this\nsays that these cubical models cubically encode distance in the curve graph of\nthe surface.",
            "author": [
                "Matthew Gentry Durham"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13689v1",
                "http://arxiv.org/pdf/2308.13689v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.GT",
                "math.MG",
                "20F67, 20F65, 30F60, 57M60, 57M07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.16198v2",
            "title": "Learning Collaborative Information Dissemination with Graph-based\n  Multi-Agent Reinforcement Learning",
            "updated": "2023-10-12T15:57:52Z",
            "published": "2023-08-25T21:30:16Z",
            "summary": "In modern communication systems, efficient and reliable information\ndissemination is crucial for supporting critical operations across domains like\ndisaster response, autonomous vehicles, and sensor networks. This paper\nintroduces a Multi-Agent Reinforcement Learning (MARL) approach as a\nsignificant step forward in achieving more decentralized, efficient, and\ncollaborative solutions. We propose a Partially Observable Stochastic Game\n(POSG) formulation for information dissemination empowering each agent to\ndecide on message forwarding independently, based on their one-hop\nneighborhood. This constitutes a significant paradigm shift from traditional\nheuristics based on Multi-Point Relay (MPR) selection. Our approach harnesses\nGraph Convolutional Reinforcement Learning, employing Graph Attention Networks\n(GAT) with dynamic attention to capture essential network features. We propose\ntwo approaches, L-DGN and HL-DGN, which differ in the information that is\nexchanged among agents. We evaluate the performance of our decentralized\napproaches, by comparing them with a widely-used MPR heuristic, and we show\nthat our trained policies are able to efficiently cover the network while\nbypassing the MPR set selection process. Our approach is a first step toward\nsupporting the resilience of real-world broadcast communication infrastructures\nvia learned, collaborative information dissemination.",
            "author": [
                "Raffaele Galliera",
                "Kristen Brent Venable",
                "Matteo Bassani",
                "Niranjan Suri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.16198v2",
                "http://arxiv.org/pdf/2308.16198v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13676v1",
            "title": "Rethinking Language Models as Symbolic Knowledge Graphs",
            "updated": "2023-08-25T21:25:08Z",
            "published": "2023-08-25T21:25:08Z",
            "summary": "Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric\napplications such as search, question answering and recommendation. As\ncontemporary language models (LMs) trained on extensive textual data have\ngained prominence, researchers have extensively explored whether the parametric\nknowledge within these models can match up to that present in knowledge graphs.\nVarious methodologies have indicated that enhancing the size of the model or\nthe volume of training data enhances its capacity to retrieve symbolic\nknowledge, often with minimal or no human supervision. Despite these\nadvancements, there is a void in comprehensively evaluating whether LMs can\nencompass the intricate topological and semantic attributes of KGs, attributes\ncrucial for reasoning processes. In this work, we provide an exhaustive\nevaluation of language models of varying sizes and capabilities. We construct\nnine qualitative benchmarks that encompass a spectrum of attributes including\nsymmetry, asymmetry, hierarchy, bidirectionality, compositionality, paths,\nentity-centricity, bias and ambiguity. Additionally, we propose novel\nevaluation metrics tailored for each of these attributes. Our extensive\nevaluation of various LMs shows that while these models exhibit considerable\npotential in recalling factual information, their ability to capture intricate\ntopological and semantic traits of KGs remains significantly constrained. We\nnote that our proposed evaluation metrics are more reliable in evaluating these\nabilities than the existing metrics. Lastly, some of our benchmarks challenge\nthe common notion that larger LMs (e.g., GPT-4) universally outshine their\nsmaller counterparts (e.g., BERT).",
            "author": [
                "Vishwas Mruthyunjaya",
                "Pouya Pezeshkpour",
                "Estevam Hruschka",
                "Nikita Bhutani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13676v1",
                "http://arxiv.org/pdf/2308.13676v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13665v3",
            "title": "On the Parameterized Complexity of Bend-Minimum Orthogonal Planarity",
            "updated": "2023-09-06T08:08:38Z",
            "published": "2023-08-25T20:39:36Z",
            "summary": "Computing planar orthogonal drawings with the minimum number of bends is one\nof the most relevant topics in Graph Drawing. The problem is known to be\nNP-hard, even when we want to test the existence of a rectilinear planar\ndrawing, i.e., an orthogonal drawing without bends (Garg and Tamassia, 2001).\nFrom the parameterized complexity perspective, the problem is fixed-parameter\ntractable when parameterized by the sum of three parameters: the number of\nbends, the number of vertices of degree at most two, and the treewidth of the\ninput graph (Di Giacomo et al., 2022). We improve this last result by showing\nthat the problem remains fixed-parameter tractable when parameterized only by\nthe number of vertices of degree at most two plus the number of bends. As a\nconsequence, rectilinear planarity testing lies in \\FPT~parameterized by the\nnumber of vertices of degree at most two.",
            "author": [
                "Emilio Di Giacomo",
                "Walter Didimo",
                "Giuseppe Liotta",
                "Fabrizio Montecchiani",
                "Giacomo Ortali"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13665v3",
                "http://arxiv.org/pdf/2308.13665v3"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13662v1",
            "title": "Resource-Efficient Federated Learning for Heterogenous and\n  Resource-Constrained Environments",
            "updated": "2023-08-25T20:33:30Z",
            "published": "2023-08-25T20:33:30Z",
            "summary": "Federated Learning (FL) is a privacy-enforcing sub-domain of machine learning\nthat brings the model to the user's device for training, avoiding the need to\nshare personal data with a central server. While existing works address data\nheterogeneity, they overlook other challenges in FL, such as device\nheterogeneity and communication efficiency. In this paper, we propose RE-FL, a\nnovel approach that tackles computational and communication challenges in\nresource-constrained devices. Our variable pruning technique optimizes resource\nutilization by adapting pruning to each client's computational capabilities. We\nalso employ knowledge distillation to reduce bandwidth consumption and\ncommunication rounds. Experimental results on image classification tasks\ndemonstrate the effectiveness of our approach in resource-constrained\nenvironments, maintaining data privacy and performance while accommodating\nheterogeneous model architectures.",
            "author": [
                "Humaid Ahmed Desai",
                "Amr Hilal",
                "Hoda Eldardiry"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13662v1",
                "http://arxiv.org/pdf/2308.13662v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.04446v1",
            "title": "Fractional dynamics and recurrence analysis in cancer model",
            "updated": "2023-08-25T20:31:54Z",
            "published": "2023-08-25T20:31:54Z",
            "summary": "In this work, we analyze the effects of fractional derivatives in the chaotic\ndynamics of a cancer model. We begin by studying the dynamics of a standard\nmodel, {\\it i.e.}, with integer derivatives. We study the dynamical behavior by\nmeans of the bifurcation diagram, Lyapunov exponents, and recurrence\nquantification analysis (RQA), such as the recurrence rate (RR), the\ndeterminism (DET), and the recurrence time entropy (RTE). We find a high\ncorrelation coefficient between the Lyapunov exponents and RTE. Our simulations\nsuggest that the tumor growth parameter ($\\rho_1$) is associated with a chaotic\nregime. Our results suggest a high correlation between the largest Lyapunov\nexponents and RTE. After understanding the dynamics of the model in the\nstandard formulation, we extend our results by considering fractional\noperators. We fix the parameters in the chaotic regime and investigate the\neffects of the fractional order. We demonstrate how fractional dynamics can be\nproperly characterized using RQA measures, which offer the advantage of not\nrequiring knowledge of the fractional Jacobian matrix. We find that the chaotic\nmotion is suppressed as $\\alpha$ decreases, and the system becomes periodic for\n$\\alpha \\lessapprox 0.9966$. We observe limit cycles for $\\alpha \\in\n(0.9966,0.899)$ and fixed points for $\\alpha<0.899$. The fixed point is\ndetermined analytically for the considered parameters. Finally, we discover\nthat these dynamics are separated by an exponential relationship between\n$\\alpha$ and $\\rho_1$. Also, the transition depends on a supper transient which\nobeys the same relationship.",
            "author": [
                "Enrique C. Gabrick",
                "Matheus R. Sales",
                "Elaheh Sayari",
                "Jos\u00e9 Trobia",
                "Ervin K. Lenzi",
                "Fernando da S. Borges",
                "Jos\u00e9 D. Szezech Jr.",
                "Kelly C. Iarosz",
                "Ricardo L. Viana",
                "Iber\u00ea L. Caldas",
                "Antonio M. Batista"
            ],
            "link": [
                "http://arxiv.org/abs/2309.04446v1",
                "http://arxiv.org/pdf/2309.04446v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13658v1",
            "title": "Generating and Explaining Corner Cases Using Learnt Probabilistic Lane\n  Graphs",
            "updated": "2023-08-25T20:17:49Z",
            "published": "2023-08-25T20:17:49Z",
            "summary": "Validating the safety of Autonomous Vehicles (AVs) operating in open-ended,\ndynamic environments is challenging as vehicles will eventually encounter\nsafety-critical situations for which there is not representative training data.\nBy increasing the coverage of different road and traffic conditions and by\nincluding corner cases in simulation-based scenario testing, the safety of AVs\ncan be improved. However, the creation of corner case scenarios including\nmultiple agents is non-trivial. Our approach allows engineers to generate\nnovel, realistic corner cases based on historic traffic data and to explain why\nsituations were safety-critical. In this paper, we introduce Probabilistic Lane\nGraphs (PLGs) to describe a finite set of lane positions and directions in\nwhich vehicles might travel. The structure of PLGs is learnt directly from\nspatio-temporal traffic data. The graph model represents the actions of the\ndrivers in response to a given state in the form of a probabilistic policy. We\nuse reinforcement learning techniques to modify this policy and to generate\nrealistic and explainable corner case scenarios which can be used for assessing\nthe safety of AVs.",
            "author": [
                "Enrik Maci",
                "Rhys Howard",
                "Lars Kunze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13658v1",
                "http://arxiv.org/pdf/2308.13658v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO",
                "E.1; G.1.1; G.3; I.2.6; I.2.9; I.6.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13646v1",
            "title": "GRASP: A Rehearsal Policy for Efficient Online Continual Learning",
            "updated": "2023-08-25T19:34:21Z",
            "published": "2023-08-25T19:34:21Z",
            "summary": "Continual learning (CL) in deep neural networks (DNNs) involves incrementally\naccumulating knowledge in a DNN from a growing data stream. A major challenge\nin CL is that non-stationary data streams cause catastrophic forgetting of\npreviously learned abilities. Rehearsal is a popular and effective way to\nmitigate this problem, which is storing past observations in a buffer and\nmixing them with new observations during learning. This leads to a question:\nWhich stored samples should be selected for rehearsal? Choosing samples that\nare best for learning, rather than simply selecting them at random, could lead\nto significantly faster learning. For class incremental learning, prior work\nhas shown that a simple class balanced random selection policy outperforms more\nsophisticated methods. Here, we revisit this question by exploring a new sample\nselection policy called GRASP. GRASP selects the most prototypical (class\nrepresentative) samples first and then gradually selects less prototypical\n(harder) examples to update the DNN. GRASP has little additional compute or\nmemory overhead compared to uniform selection, enabling it to scale to large\ndatasets. We evaluate GRASP and other policies by conducting CL experiments on\nthe large-scale ImageNet-1K and Places-LT image classification datasets. GRASP\noutperforms all other rehearsal policies. Beyond vision, we also demonstrate\nthat GRASP is effective for CL on five text classification datasets.",
            "author": [
                "Md Yousuf Harun",
                "Jhair Gallardo",
                "Christopher Kanan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13646v1",
                "http://arxiv.org/pdf/2308.13646v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13642v1",
            "title": "The Potential of Quantum Techniques for Stock Price Prediction",
            "updated": "2023-08-25T19:26:41Z",
            "published": "2023-08-25T19:26:41Z",
            "summary": "We explored the potential applications of various Quantum Algorithms for\nstock price prediction by conducting a series of experimental simulations using\nboth Classical as well as Quantum Hardware. Firstly, we extracted various stock\nprice indicators, such as Moving Averages (MA), Average True Range (ATR), and\nAroon, to gain insights into market trends and stock price movements. Next, we\nemployed Quantum Annealing (QA) for feature selection and Principal Component\nAnalysis (PCA) for dimensionality reduction. Further, we transformed the stock\nprice prediction task essentially into a classification problem. We trained the\nQuantum Support Vector Machine (QSVM) to predict price movements (whether up or\ndown) contrasted their performance with classical models and analyzed their\naccuracy on a dataset formulated using Quantum Annealing and PCA individually.\nWe focused on the stock price prediction and binary classification of stock\nprices for four different companies, namely Apple, Visa, Johnson and Jonson,\nand Honeywell. We primarily used the real-time stock data of the raw stock\nprices of these companies. We compared various Quantum Computing techniques\nwith their classical counterparts in terms of accuracy and F-score of the\nprediction model. Through these experimental simulations, we shed light on the\npotential advantages and limitations of Quantum Algorithms in stock price\nprediction and contribute to the growing body of knowledge at the intersection\nof Quantum Computing and Finance.",
            "author": [
                "Naman S",
                "Gaurang B",
                "Neel S",
                "Aswath Babu H"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13642v1",
                "http://arxiv.org/pdf/2308.13642v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13639v2",
            "title": "Cubic graphs with colouring defect 3",
            "updated": "2023-10-02T05:59:46Z",
            "published": "2023-08-25T19:17:48Z",
            "summary": "The colouring defect of a cubic graph is the smallest number of edges left\nuncovered by any set of three perfect matchings. While $3$-edge-colourable\ngraphs have defect $0$, those that cannot be $3$-edge-coloured (that is,\nsnarks) are known to have defect at least $3$. In this paper we focus on the\nstructure and properties of snarks with defect $3$. For such snarks we develop\na theory of reductions similar to standard reductions of short cycles and small\ncuts in general snarks. We prove that every snark with defect $3$ can be\nreduced to a snark with defect $3$ which is either nontrivial (cyclically\n$4$-edge-connected and of girth at least $5$) or to one that arises from a\nnontrivial snark of defect greater than $3$ by inflating a vertex lying on a\nsuitable $5$-cycle to a triangle. The proofs rely on a detailed analysis of\nFano flows associated with triples of perfect matchings leaving exactly three\nuncovered edges. In the final part of the paper we discuss application of our\nresults to the conjectures of Berge and Fulkerson, which provide the main\nmotivation for our research.",
            "author": [
                "J\u00e1n Karab\u00e1\u0161",
                "Edita M\u00e1\u010dajov\u00e1",
                "Roman Nedela",
                "Martin \u0160koviera"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13639v2",
                "http://arxiv.org/pdf/2308.13639v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15 (Primary) 05C75 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13622v1",
            "title": "Detection of atmospheric species and dynamics in the bloated hot Jupiter\n  WASP-172~b with ESPRESSO",
            "updated": "2023-08-25T18:38:39Z",
            "published": "2023-08-25T18:38:39Z",
            "summary": "The population of strongly irradiated Jupiter-sized planets has no equivalent\nin the Solar System. It is characterised by strongly bloated atmospheres and\natmospheric large-scale heights. Recent space-based observations of SO2\nphotochemistry demonstrated the knowledge that can be gained from detailed\natmospheric studies of these unusual planets about Earth's uniqueness. Aims.\nHere we explore the atmosphere of WASP-172b a similar planet in temperature and\nbloating to the recently studied HD~149026~b. In this work, we characterise the\natmospheric composition and subsequently the atmospheric dynamics of this prime\ntarget. Methods. We observed a particular transit of WASP-172b in front of its\nhost star with ESO's ESPRESSO spectrograph and analysed the spectra obtained\nbefore during and after transit. Results. We detect the absorption of starlight\nby WASP-172b's atmosphere by sodium (5.6sigma), hydrogen (19.5sigma) and\nobtained a tentative detection of iron (4.1sigma). We detect strong - yet\nvarying - blue shifts, relative to the planetary rest frame, of all of these\nabsorption features. This allows for a preliminary study of the atmospheric\ndynamics of WASP-172b. Conclusions. With only one transit, we were able to\ndetect a wide variety of species, clearly tracking different atmospheric layers\nwith possible jets. WASP-172b is a prime follow-up target for a more in-depth\ncharacterisation both for ground and space-based observatories. If the\ndetection of Fe is confirmed, this may suggest that radius inflation is an\nimportant determinant for the detectability of Fe in hot Jupiters, as several\nnon-detections of Fe have been published for planets that are hotter but less\ninflated than WASP-172b.",
            "author": [
                "J. V. Seidel",
                "B. Prinoth",
                "E. Knudstrup",
                "H. J. Hoeijmakers",
                "J. J. Zanazzi",
                "S. Albrecht"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202347160",
                "http://arxiv.org/abs/2308.13622v1",
                "http://arxiv.org/pdf/2308.13622v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13611v1",
            "title": "LLPNet: Graph Autoencoder for Triggering Light Long-Lived Particles at\n  HL-LHC",
            "updated": "2023-08-25T18:12:10Z",
            "published": "2023-08-25T18:12:10Z",
            "summary": "In the search for exotic events involving displaced particles at HL-LHC, the\ntriggering at the level-1 (L1) system will pose a significant challenge. This\nis particularly relevant in scenarios where low mass long-lived particles\n(LLPs) are coupled to a Standard Model (SM)-like 125 GeV Higgs boson and they\ndecay into jets. The complexity arises from the low hadronic activity resulting\nfrom LLP decay, and the existing triggers' inability to efficiently select\ndisplaced events. This study introduces a novel machine learning approach to\naddress this challenge, utilizing a lightweight autoencoder architecture\ndesigned for low latency requirements at L1. Focusing on light LLPs with decay\nlengths ranging from 1 to 100 cm, this approach employs \"Edge convolution\" on\nL1 reconstructed tracks. The results show notable signal acceptance at the\npermissible background rate, primarily originating from minimum bias and QCD\ndi-jet events. For LLPs of mass 10, 30, and 50 GeV at decay length of 5 cm, the\nsignal efficiencies are 33%, 70%, and 80%, respectively. At a 50 cm decay\nlength, these efficiencies are 20%, 39%, and 45% for the same respective\nmasses.",
            "author": [
                "Biplob Bhattacherjee",
                "Partha Konar",
                "Vishal Singh Ngairangbam",
                "Prabhat Solanki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13611v1",
                "http://arxiv.org/pdf/2308.13611v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13607v2",
            "title": "Quantum-Informed Recursive Optimization Algorithms",
            "updated": "2023-09-18T11:19:14Z",
            "published": "2023-08-25T18:02:06Z",
            "summary": "We propose and implement a family of quantum-informed recursive optimization\n(QIRO) algorithms for combinatorial optimization problems. Our approach\nleverages quantum resources to obtain information that is used in\nproblem-specific classical reduction steps that recursively simplify the\nproblem. These reduction steps address the limitations of the quantum component\nand ensure solution feasibility in constrained optimization problems.\nAdditionally, we use backtracking techniques to further improve the performance\nof the algorithm without increasing the requirements on the quantum hardware.\nWe demonstrate the capabilities of our approach by informing QIRO with\ncorrelations from classical simulations of shallow (depth $p=1$) circuits of\nthe quantum approximate optimization algorithm (QAOA), solving instances of\nmaximum independent set and maximum satisfiability problems with hundreds of\nvariables. We also demonstrate how QIRO can be deployed on a neutral atom\nquantum processor available online on Amazon Braket to find large independent\nsets of graphs. In summary, our scheme achieves results comparable to classical\nheuristics, such as simulated annealing and greedy algorithms, even with\nrelatively weak quantum resources. Furthermore, enhancing the quality of these\nquantum resources improves the performance of the algorithms, highlighting the\npotential of QIRO. Notably, the modular nature of QIRO offers various avenues\nfor modifications, positioning our work as a blueprint for designing a broader\nclass of hybrid quantum-classical algorithms for combinatorial optimization.",
            "author": [
                "Jernej Rudi Fin\u017egar",
                "Aron Kerschbaumer",
                "Martin J. A. Schuetz",
                "Christian B. Mendl",
                "Helmut G. Katzgraber"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13607v2",
                "http://arxiv.org/pdf/2308.13607v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.CO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13515v3",
            "title": "Robust Core-Periphery Constrained Transformer for Domain Adaptation",
            "updated": "2023-09-17T05:31:02Z",
            "published": "2023-08-25T17:49:52Z",
            "summary": "Unsupervised domain adaptation (UDA) aims to learn transferable\nrepresentation across domains. Recently a few UDA works have successfully\napplied Transformer-based methods and achieved state-of-the-art (SOTA) results.\nHowever, it remains challenging when there exists a large domain gap between\nthe source and target domain. Inspired by humans' exceptional transferability\nabilities to adapt knowledge from familiar to uncharted domains, we try to\napply the universally existing organizational structure in the human functional\nbrain networks, i.e., the core-periphery principle to design the Transformer\nand improve its UDA performance. In this paper, we propose a novel\nbrain-inspired robust core-periphery constrained transformer (RCCT) for\nunsupervised domain adaptation, which brings a large margin of performance\nimprovement on various datasets. Specifically, in RCCT, the self-attention\noperation across image patches is rescheduled by an adaptively learned weighted\ngraph with the Core-Periphery structure (CP graph), where the information\ncommunication and exchange between images patches are manipulated and\ncontrolled by the connection strength, i.e., edge weight of the learned\nweighted CP graph. Besides, since the data in domain adaptation tasks can be\nnoisy, to improve the model robustness, we intentionally add perturbations to\nthe patches in the latent space to ensure generating robust learned weighted\ncore-periphery graphs. Extensive evaluations are conducted on several widely\ntested UDA benchmarks. Our proposed RCCT consistently performs best compared to\nexisting works, including 88.3\\% on Office-Home, 95.0\\% on Office-31, 90.7\\% on\nVisDA-2017, and 46.0\\% on DomainNet.",
            "author": [
                "Xiaowei Yu",
                "Lu Zhang",
                "Dajiang Zhu",
                "Tianming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13515v3",
                "http://arxiv.org/pdf/2308.13515v3"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13513v1",
            "title": "Unveiling the Role of Message Passing in Dual-Privacy Preservation on\n  GNNs",
            "updated": "2023-08-25T17:46:43Z",
            "published": "2023-08-25T17:46:43Z",
            "summary": "Graph Neural Networks (GNNs) are powerful tools for learning representations\non graphs, such as social networks. However, their vulnerability to privacy\ninference attacks restricts their practicality, especially in high-stake\ndomains. To address this issue, privacy-preserving GNNs have been proposed,\nfocusing on preserving node and/or link privacy. This work takes a step back\nand investigates how GNNs contribute to privacy leakage. Through theoretical\nanalysis and simulations, we identify message passing under structural bias as\nthe core component that allows GNNs to \\textit{propagate} and \\textit{amplify}\nprivacy leakage. Building upon these findings, we propose a principled\nprivacy-preserving GNN framework that effectively safeguards both node and link\nprivacy, referred to as dual-privacy preservation. The framework comprises\nthree major modules: a Sensitive Information Obfuscation Module that removes\nsensitive information from node embeddings, a Dynamic Structure Debiasing\nModule that dynamically corrects the structural bias, and an Adversarial\nLearning Module that optimizes the privacy-utility trade-off. Experimental\nresults on four benchmark datasets validate the effectiveness of the proposed\nmodel in protecting both node and link privacy while preserving high utility\nfor downstream tasks, such as node classification.",
            "author": [
                "Tianyi Zhao",
                "Hui Hu",
                "Lu Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13513v1",
                "http://arxiv.org/pdf/2308.13513v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13490v3",
            "title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor\n  Computational Graphs",
            "updated": "2023-12-05T22:36:34Z",
            "published": "2023-08-25T17:04:35Z",
            "summary": "Precise hardware performance models play a crucial role in code\noptimizations. They can assist compilers in making heuristic decisions or aid\nautotuners in identifying the optimal configuration for a given program. For\nexample, the autotuner for XLA, a machine learning compiler, discovered 10-20%\nspeedup on state-of-the-art models serving substantial production traffic at\nGoogle. Although there exist a few datasets for program performance prediction,\nthey target small sub-programs such as basic blocks or kernels. This paper\nintroduces TpuGraphs, a performance prediction dataset on full tensor programs,\nrepresented as computational graphs, running on Tensor Processing Units (TPUs).\nEach graph in the dataset represents the main computation of a machine learning\nworkload, e.g., a training epoch or an inference step. Each data sample\ncontains a computational graph, a compilation configuration, and the execution\ntime of the graph when compiled with the configuration. The graphs in the\ndataset are collected from open-source machine learning programs, featuring\npopular model architectures, e.g., ResNet, EfficientNet, Mask R-CNN, and\nTransformer. TpuGraphs provides 25x more graphs than the largest graph property\nprediction dataset (with comparable graph sizes), and 770x larger graphs on\naverage compared to existing performance prediction datasets on machine\nlearning programs. This graph-level prediction task on large graphs introduces\nnew challenges in learning, ranging from scalability, training efficiency, to\nmodel quality.",
            "author": [
                "Phitchaya Mangpo Phothilimthana",
                "Sami Abu-El-Haija",
                "Kaidi Cao",
                "Bahare Fatemi",
                "Mike Burrows",
                "Charith Mendis",
                "Bryan Perozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13490v3",
                "http://arxiv.org/pdf/2308.13490v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13489v1",
            "title": "Vector space Ramsey numbers and weakly Sidorenko affine configurations",
            "updated": "2023-08-25T17:03:12Z",
            "published": "2023-08-25T17:03:12Z",
            "summary": "For $B \\subseteq \\mathbb F_q^m$, the $n$-th affine extremal number of $B$ is\nthe maximum cardinality of a set $A \\subseteq \\mathbb F_q^n$ with no subset\nwhich is affinely isomorphic to $B$. Furstenberg and Katznelson proved that for\nany $B \\subseteq \\mathbb F_q^m$, the $n$-th affine extremal number of $B$ is\n$o(q^n)$ as $n \\to \\infty$. By counting affine homomorphisms between subsets of\n$\\mathbb F_q^n$, we derive new bounds and give new proofs of some previously\nknown bounds for certain affine extremal numbers. At the same time, we\nestablish corresponding supersaturation results. We connect these bounds to\ncertain Ramsey-type numbers in vector spaces over finite fields. For $s,t \\geq\n1$, let $R_q(s,t)$ denote the minimum $n$ such that in every red-blue coloring\nof the one-dimensional subspaces of $\\mathbb F_q^n$, there is either a red\n$s$-dimensional subspace or a blue $t$-dimensional subspace of $\\mathbb F_q^n$.\nThe existence of these numbers is a special case of a well-known theorem of\nGraham, Leeb, Rothschild. We improve the best known upper bounds on $R_2(2,t)$,\n$R_3(2,t)$, $R_2(t,t)$, and $R_3(t,t)$.",
            "author": [
                "Bryce Frederickson",
                "Liana Yepremyan"
            ],
            "link": [
                "http://dx.doi.org/10.5817/CZ.MUNI.EUROCOMB23-062",
                "http://arxiv.org/abs/2308.13489v1",
                "http://arxiv.org/pdf/2308.13489v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05D10 (Primary) 05B35 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13588v1",
            "title": "GeoExplainer: A Visual Analytics Framework for Spatial Modeling\n  Contextualization and Report Generation",
            "updated": "2023-08-25T16:55:33Z",
            "published": "2023-08-25T16:55:33Z",
            "summary": "Geographic regression models of various descriptions are often applied to\nidentify patterns and anomalies in the determinants of spatially distributed\nobservations. These types of analyses focus on answering why questions about\nunderlying spatial phenomena, e.g., why is crime higher in this locale, why do\nchildren in one school district outperform those in another, etc.? Answers to\nthese questions require explanations of the model structure, the choice of\nparameters, and contextualization of the findings with respect to their\ngeographic context. This is particularly true for local forms of regression\nmodels which are focused on the role of locational context in determining human\nbehavior. In this paper, we present GeoExplainer, a visual analytics framework\ndesigned to support analysts in creating explanative documentation that\nsummarizes and contextualizes their spatial analyses. As analysts create their\nspatial models, our framework flags potential issues with model parameter\nselections, utilizes template-based text generation to summarize model outputs,\nand links with external knowledge repositories to provide annotations that help\nto explain the model results. As analysts explore the model results, all\nvisualizations and annotations can be captured in an interactive report\ngeneration widget. We demonstrate our framework using a case study modeling the\ndeterminants of voting in the 2016 US Presidential Election.",
            "author": [
                "Fan Lei",
                "Yuxin Ma",
                "Stewart Fotheringham",
                "Elizabeth Mack",
                "Ziqi Li",
                "Mehak Sachdeva",
                "Sarah Bardin",
                "Ross Maciejewski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13588v1",
                "http://arxiv.org/pdf/2308.13588v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13485v1",
            "title": "On nonrepetitive colorings of paths and cycles",
            "updated": "2023-08-25T16:49:48Z",
            "published": "2023-08-25T16:49:48Z",
            "summary": "We say that a sequence $a_1 \\cdots a_{2t}$ of integers is repetitive if $a_i\n= a_{i+t}$ for every $i\\in\\{1,\\ldots,t\\}$. A walk in a graph $G$ is a sequence\n$v_1 \\cdots v_r$ of vertices of $G$ in which $v_iv_{i+1}\\in E(G)$ for every\n$i\\in\\{1,\\ldots,r-1\\}$. Given a $k$-coloring $c\\colon V(G)\\to\\{1,\\ldots,k\\}$ of\n$V(G)$, we say that $c$ is walk-nonrepetitive (resp. stroll-nonrepetitive) if\nfor every $t\\in\\mathbb{N}$ and every walk $v_1\\cdots v_{2t}$ the sequence\n$c(v_1) \\cdots c(v_{2t})$ is not repetitive unless $v_i = v_{i+t}$ for every\n$i\\in\\{1,\\ldots,t\\}$ (resp. unless $v_i = v_{i+t}$ for some\n$i\\in\\{1,\\ldots,t\\}$). The walk (resp. stroll) chromatic number $\\sigma(G)$\n(resp. $\\rho(G)$) of $G$ is the minimum $k$ for which $G$ has a\nwalk-nonrepetitive (resp. stroll-nonrepetitive) $k$-coloring. Let $C_n$ and\n$P_n$ denote, respectively, the cycle and the path with $n$ vertices. In this\npaper we present three results that answer questions posed by Bar\\'at and Wood\nin 2008: (i) $\\sigma(C_n) = 4$ whenever $n\\geq 4$ and $n \\notin\\{5,7\\}$; (ii)\n$\\rho(P_n) = 3$ if $3\\leq n\\leq 21$ and $\\rho(P_n) = 4$ otherwise; and (iii)\n$\\rho(C_n) = 4$, whenever $n \\notin\\{3,4,6,8\\}$, and $\\rho(C_n) = 3$ otherwise.\nIn particular, (ii) improves bounds on $n$ obtained by Tao in 2023.",
            "author": [
                "F\u00e1bio Botler",
                "Wanderson Lomenha",
                "Jo\u00e3o Pedro de Souza"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13485v1",
                "http://arxiv.org/pdf/2308.13485v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15, 05C38"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13469v2",
            "title": "RestNet: Boosting Cross-Domain Few-Shot Segmentation with Residual\n  Transformation Network",
            "updated": "2023-09-14T01:13:21Z",
            "published": "2023-08-25T16:13:22Z",
            "summary": "Cross-domain few-shot segmentation (CD-FSS) aims to achieve semantic\nsegmentation in previously unseen domains with a limited number of annotated\nsamples. Although existing CD-FSS models focus on cross-domain feature\ntransformation, relying exclusively on inter-domain knowledge transfer may lead\nto the loss of critical intra-domain information. To this end, we propose a\nnovel residual transformation network (RestNet) that facilitates knowledge\ntransfer while retaining the intra-domain support-query feature information.\nSpecifically, we propose a Semantic Enhanced Anchor Transform (SEAT) module\nthat maps features to a stable domain-agnostic space using advanced semantics.\nAdditionally, an Intra-domain Residual Enhancement (IRE) module is designed to\nmaintain the intra-domain representation of the original discriminant space in\nthe new space. We also propose a mask prediction strategy based on prototype\nfusion to help the model gradually learn how to segment. Our RestNet can\ntransfer cross-domain knowledge from both inter-domain and intra-domain without\nrequiring additional fine-tuning. Extensive experiments on ISIC, Chest X-ray,\nand FSS-1000 show that our RestNet achieves state-of-the-art performance. Our\ncode will be available soon.",
            "author": [
                "Xinyang Huang",
                "Chuang Zhu",
                "Wenkai Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13469v2",
                "http://arxiv.org/pdf/2308.13469v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13467v1",
            "title": "Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability\n  of Language Models",
            "updated": "2023-08-25T16:11:08Z",
            "published": "2023-08-25T16:11:08Z",
            "summary": "The Natural Language Processing(NLP) community has been using crowd sourcing\ntechniques to create benchmark datasets such as General Language Understanding\nand Evaluation(GLUE) for training modern Language Models such as BERT. GLUE\ntasks measure the reliability scores using inter annotator metrics i.e. Cohens\nKappa. However, the reliability aspect of LMs has often been overlooked. To\ncounter this problem, we explore a knowledge-guided LM ensembling approach that\nleverages reinforcement learning to integrate knowledge from ConceptNet and\nWikipedia as knowledge graph embeddings. This approach mimics human annotators\nresorting to external knowledge to compensate for information deficits in the\ndatasets. Across nine GLUE datasets, our research shows that ensembling\nstrengthens reliability and accuracy scores, outperforming state of the art.",
            "author": [
                "Nancy Tyagi",
                "Surjodeep Sarkar",
                "Manas Gaur"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13467v1",
                "http://arxiv.org/pdf/2308.13467v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13466v1",
            "title": "Staleness-Alleviated Distributed GNN Training via Online\n  Dynamic-Embedding Prediction",
            "updated": "2023-08-25T16:10:44Z",
            "published": "2023-08-25T16:10:44Z",
            "summary": "Despite the recent success of Graph Neural Networks (GNNs), it remains\nchallenging to train GNNs on large-scale graphs due to neighbor explosions. As\na remedy, distributed computing becomes a promising solution by leveraging\nabundant computing resources (e.g., GPU). However, the node dependency of graph\ndata increases the difficulty of achieving high concurrency in distributed GNN\ntraining, which suffers from the massive communication overhead. To address it,\nHistorical value approximation is deemed a promising class of distributed\ntraining techniques. It utilizes an offline memory to cache historical\ninformation (e.g., node embedding) as an affordable approximation of the exact\nvalue and achieves high concurrency. However, such benefits come at the cost of\ninvolving dated training information, leading to staleness, imprecision, and\nconvergence issues. To overcome these challenges, this paper proposes SAT\n(Staleness-Alleviated Training), a novel and scalable distributed GNN training\nframework that reduces the embedding staleness adaptively. The key idea of SAT\nis to model the GNN's embedding evolution as a temporal graph and build a model\nupon it to predict future embedding, which effectively alleviates the staleness\nof the cached historical embedding. We propose an online algorithm to train the\nembedding predictor and the distributed GNN alternatively and further provide a\nconvergence analysis. Empirically, we demonstrate that SAT can effectively\nreduce embedding staleness and thus achieve better performance and convergence\nspeed on multiple large-scale graph datasets.",
            "author": [
                "Guangji Bai",
                "Ziyang Yu",
                "Zheng Chai",
                "Yue Cheng",
                "Liang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13466v1",
                "http://arxiv.org/pdf/2308.13466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13460v1",
            "title": "Learning How to Price Charging in Electric Ride-Hailing Markets",
            "updated": "2023-08-25T16:09:23Z",
            "published": "2023-08-25T16:09:23Z",
            "summary": "With the electrification of ride-hailing fleets, there will be a need to\nincentivize where and when the ride-hailing vehicles should charge. In this\nwork, we assume that a central authority wants to control the distribution of\nthe vehicles and can do so by selecting charging prices. Since there will\nlikely be more than one ride-hailing company in the market, we model the\nproblem as a single-leader multiple-follower Stackelberg game. The followers,\ni.e., the companies, compete about the charging resources under given prices\nprovided by the leader. We present a learning algorithm based on the concept of\ncontextual bandits that allows the central authority to find an efficient\npricing strategy. We also show how the exploratory phase of the learning can be\nimproved if the leader has some partial knowledge about the companies'\nobjective functions. The efficiency of the proposed algorithm is demonstrated\nin a simulated case study for the city of Shenzhen, China.",
            "author": [
                "Marko Maljkovic",
                "Gustav Nilsson",
                "Nikolas Geroliminis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13460v1",
                "http://arxiv.org/pdf/2308.13460v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13458v1",
            "title": "ARTIST: ARTificial Intelligence for Simplified Text",
            "updated": "2023-08-25T16:06:06Z",
            "published": "2023-08-25T16:06:06Z",
            "summary": "Complex text is a major barrier for many citizens when accessing public\ninformation and knowledge. While often done manually, Text Simplification is a\nkey Natural Language Processing task that aims for reducing the linguistic\ncomplexity of a text while preserving the original meaning. Recent advances in\nGenerative Artificial Intelligence (AI) have enabled automatic text\nsimplification both on the lexical and syntactical levels. However, as\napplications often focus on English, little is understood about the\neffectiveness of Generative AI techniques on low-resource languages such as\nDutch. For this reason, we carry out empirical studies to understand the\nbenefits and limitations of applying generative technologies for text\nsimplification and provide the following outcomes: 1) the design and\nimplementation for a configurable text simplification pipeline that\norchestrates state-of-the-art generative text simplification models, domain and\nreader adaptation, and visualisation modules; 2) insights and lessons learned,\nshowing the strengths of automatic text simplification while exposing the\nchallenges in handling cultural and commonsense knowledge. These outcomes\nrepresent a first step in the exploration of Dutch text simplification and shed\nlight on future endeavours both for research and practice.",
            "author": [
                "Lorenzo Corti",
                "Jie Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13458v1",
                "http://arxiv.org/pdf/2308.13458v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13455v1",
            "title": "Simonovits's theorem in random graphs",
            "updated": "2023-08-25T16:02:56Z",
            "published": "2023-08-25T16:02:56Z",
            "summary": "Let $H$ be a graph with $\\chi(H) = r+1$. Simonovits's theorem states that, if\n$H$ is edge-critical, the unique largest $H$-free subgraph of $K_n$ is its\nlargest $r$-partite subgraph, provided that $n$ is sufficiently large. We show\nthat the same holds with $K_n$ replaced by the binomial random graph $G_{n,p}$\nwhenever $H$ is also strictly $2$-balanced and $p \\ge (\\theta_H+o(1))\nn^{-\\frac{1}{m_2(H)}} (\\log n)^{\\frac{1}{e_H-1}}$ for some explicit constant\n$\\theta_H$, which we believe to be optimal. This (partially) resolves a\nconjecture of DeMarco and Kahn.",
            "author": [
                "Ilay Hoshen",
                "Wojciech Samotij"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13455v1",
                "http://arxiv.org/pdf/2308.13455v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13451v2",
            "title": "Gotta match 'em all: Solution diversification in graph matching matched\n  filters",
            "updated": "2023-09-11T01:00:03Z",
            "published": "2023-08-25T15:53:30Z",
            "summary": "We present a novel approach for finding multiple noisily embedded template\ngraphs in a very large background graph. Our method builds upon the\ngraph-matching-matched-filter technique proposed in Sussman et al., with the\ndiscovery of multiple diverse matchings being achieved by iteratively\npenalizing a suitable node-pair similarity matrix in the matched filter\nalgorithm. In addition, we propose algorithmic speed-ups that greatly enhance\nthe scalability of our matched-filter approach. We present theoretical\njustification of our methodology in the setting of correlated Erdos-Renyi\ngraphs, showing its ability to sequentially discover multiple templates under\nmild model conditions. We additionally demonstrate our method's utility via\nextensive experiments both using simulated models and real-world dataset,\ninclude human brain connectomes and a large transactional knowledge base.",
            "author": [
                "Zhirui Li",
                "Ben Johnson",
                "Daniel L. Sussman",
                "Carey E. Priebe",
                "Vince Lyzinski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13451v2",
                "http://arxiv.org/pdf/2308.13451v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.CO",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13433v1",
            "title": "Representing Timed Automata and Timing Anomalies of Cyber-Physical\n  Production Systems in Knowledge Graphs",
            "updated": "2023-08-25T15:25:57Z",
            "published": "2023-08-25T15:25:57Z",
            "summary": "Model-Based Anomaly Detection has been a successful approach to identify\ndeviations from the expected behavior of Cyber-Physical Production Systems.\nSince manual creation of these models is a time-consuming process, it is\nadvantageous to learn them from data and represent them in a generic formalism\nlike timed automata. However, these models - and by extension, the detected\nanomalies - can be challenging to interpret due to a lack of additional\ninformation about the system. This paper aims to improve model-based anomaly\ndetection in CPPS by combining the learned timed automaton with a formal\nknowledge graph about the system. Both the model and the detected anomalies are\ndescribed in the knowledge graph in order to allow operators an easier\ninterpretation of the model and the detected anomalies. The authors\nadditionally propose an ontology of the necessary concepts. The approach was\nvalidated on a five-tank mixing CPPS and was able to formally define both\nautomata model as well as timing anomalies in automata execution.",
            "author": [
                "Tom Westermann",
                "Milapji Singh Gill",
                "Alexander Fay"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13433v1",
                "http://arxiv.org/pdf/2308.13433v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13428v1",
            "title": "On the arithmetic of the join rings over finite fields",
            "updated": "2023-08-25T15:13:29Z",
            "published": "2023-08-25T15:13:29Z",
            "summary": "Given a collection $\\{ G_i\\}_{i=1}^d$ of finite groups and a ring $R$, we\nhave previously introduced and studied certain foundational properties of the\njoin ring $\\mathcal{J}_{G_1, G_2, \\ldots, G_d}(R)$. This ring bridges two\nextreme worlds: matrix algebras $M_n(R)$ on one end and group algebras $RG$ on\nthe other. The construction of this ring was motivated by various problems in\ngraph theory, network theory, nonlinear dynamics, and neuroscience. In this\npaper, we continue our investigations of this ring, focussing more on its\narithmetic properties. We begin by constructing a generalized augmentation map\nthat gives a structural decomposition of this ring. This decomposition allows\nus to compute the zeta function of the join of group rings. We show that the\njoin of group rings is a natural home for studying the concept of simultaneous\nprimitive roots for a given set of primes. This concept is related to the order\nof the unit group of the join of group rings. Finally, we characterize the join\nof group rings over finite fields with the property that the order of every\nunit divides a fixed number. Remarkably, Mersenne and Fermat primes\nunexpectedly emerge within the context of this exploration.",
            "author": [
                "Sunil K. Chebolu",
                "Jonathan Merzel",
                "J\u00e1n Min\u00e1\u010d",
                "Tung T. Nguyen",
                "Federico Pasini",
                "Nguy\u00ean Duy T\u00e2n"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13428v1",
                "http://arxiv.org/pdf/2308.13428v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12343v1",
            "title": "Integrating Competency-Based Education in Interactive Learning Systems",
            "updated": "2023-08-25T15:11:53Z",
            "published": "2023-08-25T15:11:53Z",
            "summary": "Artemis is an interactive learning system that organizes courses, hosts\nlecture content and interactive exercises, conducts exams, and creates\nautomatic assessments with individual feedback. Research shows that students\nhave unique capabilities, previous experiences, and expectations. However, the\ncourse content on current learning systems, including Artemis, is not tailored\nto a student's competencies. The main goal of this paper is to describe how to\nmake Artemis capable of competency-based education and provide individual\ncourse content based on the unique characteristics of every student. We show\nhow instructors can define relations between competencies to create a\ncompetency relation graph, how Artemis measures and visualizes the student's\nprogress toward mastering a competency, and how the progress can generate a\npersonalized learning path for students that recommends relevant learning\nresources. Finally, we present the results of a user study regarding the\nusability of the newly designed competency visualization and give an outlook on\npossible improvements and future visions.",
            "author": [
                "Maximilian S\u00f6lch",
                "Moritz Aberle",
                "Stephan Krusche"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12343v1",
                "http://arxiv.org/pdf/2309.12343v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13418v1",
            "title": "Nougat: Neural Optical Understanding for Academic Documents",
            "updated": "2023-08-25T15:03:36Z",
            "published": "2023-08-25T15:03:36Z",
            "summary": "Scientific knowledge is predominantly stored in books and scientific\njournals, often in the form of PDFs. However, the PDF format leads to a loss of\nsemantic information, particularly for mathematical expressions. We propose\nNougat (Neural Optical Understanding for Academic Documents), a Visual\nTransformer model that performs an Optical Character Recognition (OCR) task for\nprocessing scientific documents into a markup language, and demonstrate the\neffectiveness of our model on a new dataset of scientific documents. The\nproposed approach offers a promising solution to enhance the accessibility of\nscientific knowledge in the digital age, by bridging the gap between\nhuman-readable documents and machine-readable text. We release the models and\ncode to accelerate future work on scientific text recognition.",
            "author": [
                "Lukas Blecher",
                "Guillem Cucurull",
                "Thomas Scialom",
                "Robert Stojnic"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13418v1",
                "http://arxiv.org/pdf/2308.13418v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.03027v1",
            "title": "Synergistic Fusion of Graph and Transformer Features for Enhanced\n  Molecular Property Prediction",
            "updated": "2023-08-25T14:47:46Z",
            "published": "2023-08-25T14:47:46Z",
            "summary": "Molecular property prediction is a critical task in computational drug\ndiscovery. While recent advances in Graph Neural Networks (GNNs) and\nTransformers have shown to be effective and promising, they face the following\nlimitations: Transformer self-attention does not explicitly consider the\nunderlying molecule structure while GNN feature representation alone is not\nsufficient to capture granular and hidden interactions and characteristics that\ndistinguish similar molecules. To address these limitations, we propose SYN-\nFUSION, a novel approach that synergistically combines pre-trained features\nfrom GNNs and Transformers. This approach provides a comprehensive molecular\nrepresentation, capturing both the global molecule structure and the individual\natom characteristics. Experimental results on MoleculeNet benchmarks\ndemonstrate superior performance, surpassing previous models in 5 out of 7\nclassification datasets and 4 out of 6 regression datasets. The performance of\nSYN-FUSION has been compared with other Graph-Transformer models that have been\njointly trained using a combination of transformer and graph features, and it\nis found that our approach is on par with those models in terms of performance.\nExtensive analysis of the learned fusion model across aspects such as loss,\nlatent space, and weight distribution further validates the effectiveness of\nSYN-FUSION. Finally, an ablation study unequivocally demonstrates that the\nsynergy achieved by SYN-FUSION surpasses the performance of its individual\nmodel components and their ensemble, offering a substantial improvement in\npredicting molecular properties.",
            "author": [
                "M V Sai Prakash",
                "Siddartha Reddy N",
                "Ganesh Parab",
                "Varun V",
                "Vishal Vaddina",
                "Saisubramaniam Gopalakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.03027v1",
                "http://arxiv.org/pdf/2310.03027v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13401v2",
            "title": "Min-$k$-planar Drawings of Graphs",
            "updated": "2023-09-04T13:38:27Z",
            "published": "2023-08-25T14:24:14Z",
            "summary": "The study of nonplanar drawings of graphs with restricted crossing\nconfigurations is a well-established topic in graph drawing, often referred to\nas beyond-planar graph drawing. One of the most studied types of drawings in\nthis area are the $k$-planar drawings $(k \\geq 1)$, where each edge cannot\ncross more than $k$ times. We generalize $k$-planar drawings, by introducing\nthe new family of min-$k$-planar drawings. In a min-$k$-planar drawing edges\ncan cross an arbitrary number of times, but for any two crossing edges, one of\nthe two must have no more than $k$ crossings. We prove a general upper bound on\nthe number of edges of min-$k$-planar drawings, a finer upper bound for $k=3$,\nand tight upper bounds for $k=1,2$. Also, we study the inclusion relations\nbetween min-$k$-planar graphs (i.e., graphs admitting min-$k$-planar drawings)\nand $k$-planar graphs.",
            "author": [
                "Carla Binucci",
                "Aaron B\u00fcngener",
                "Giuseppe Di Battista",
                "Walter Didimo",
                "Vida Dujmovi\u0107",
                "Seok-Hee Hong",
                "Michael Kaufmann",
                "Giuseppe Liotta",
                "Pat Morin",
                "Alessandra Tappini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13401v2",
                "http://arxiv.org/pdf/2308.13401v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13392v2",
            "title": "Self-Supervised Representation Learning with Cross-Context Learning\n  between Global and Hypercolumn Features",
            "updated": "2023-09-01T13:58:57Z",
            "published": "2023-08-25T14:08:07Z",
            "summary": "Whilst contrastive learning yields powerful representations by matching\ndifferent augmented views of the same instance, it lacks the ability to capture\nthe similarities between different instances. One popular way to address this\nlimitation is by learning global features (after the global pooling) to capture\ninter-instance relationships based on knowledge distillation, where the global\nfeatures of the teacher are used to guide the learning of the global features\nof the student. Inspired by cross-modality learning, we extend this existing\nframework that only learns from global features by encouraging the global\nfeatures and intermediate layer features to learn from each other. This leads\nto our novel self-supervised framework: cross-context learning between global\nand hypercolumn features (CGH), that enforces the consistency of instance\nrelations between low- and high-level semantics. Specifically, we stack the\nintermediate feature maps to construct a hypercolumn representation so that we\ncan measure instance relations using two contexts (hypercolumn and global\nfeature) separately, and then use the relations of one context to guide the\nlearning of the other. This cross-context learning allows the model to learn\nfrom the differences between the two contexts. The experimental results on\nlinear classification and downstream tasks show that our method outperforms the\nstate-of-the-art methods.",
            "author": [
                "Zheng Gao",
                "Chen Feng",
                "Ioannis Patras"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13392v2",
                "http://arxiv.org/pdf/2308.13392v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13380v1",
            "title": "In-context learning for model-free system identification",
            "updated": "2023-08-25T13:50:17Z",
            "published": "2023-08-25T13:50:17Z",
            "summary": "In traditional system identification, we estimate a model of an unknown\ndynamical system based on given input/output sequences and available physical\nknowledge. Yet, is it also possible to understand the intricacies of dynamical\nsystems not solely from their input/output patterns, but by observing the\nbehavior of other systems within the same class? This central question drives\nthe study presented in this paper.\n  In response to this query, we introduce a novel paradigm for system\nidentification, addressing two primary tasks: one-step-ahead prediction and\nmulti-step simulation. Unlike conventional methods, we do not directly estimate\na model for the specific system. Instead, we pretrain a meta model that\nrepresents a class of dynamical systems. This meta model is trained from a\npotentially infinite stream of synthetic data, generated by systems randomly\nextracted from a certain distribution. At its core, the meta model serves as an\nimplicit representation of the main characteristics of a class of dynamical\nsystems. When provided with a brief context from a new system - specifically, a\nshort input/output sequence - the meta model implicitly discerns its dynamics,\nenabling predictions of its behavior.\n  The proposed approach harnesses the power of Transformer architectures,\nrenowned for their in-context learning capabilities in Natural Language\nProcessing tasks. For one-step prediction, a GPT-like decoder-only architecture\nis utilized, whereas the simulation problem employs an encoder-decoder\nstructure.\n  Initial experimental results affirmatively answer our foundational question,\nopening doors to fresh research avenues in system identification.",
            "author": [
                "Marco Forgione",
                "Filippo Pura",
                "Dario Piga"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13380v1",
                "http://arxiv.org/pdf/2308.13380v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13373v1",
            "title": "Enhanced Mortality Prediction In Patients With Subarachnoid Haemorrhage\n  Using A Deep Learning Model Based On The Initial CT Scan",
            "updated": "2023-08-25T13:33:56Z",
            "published": "2023-08-25T13:33:56Z",
            "summary": "PURPOSE: Subarachnoid hemorrhage (SAH) entails high morbidity and mortality\nrates. Convolutional neural networks (CNN), a form of deep learning, are\ncapable of generating highly accurate predictions from imaging data. Our\nobjective was to predict mortality in SAH patients by processing the initial CT\nscan on a CNN based algorithm.\n  METHODS: Retrospective multicentric study of a consecutive cohort of patients\nwith SAH between 2011-2022. Demographic, clinical and radiological variables\nwere analyzed. Pre-processed baseline CT scan images were used as the input for\ntraining a CNN using AUCMEDI Framework. Our model's architecture leverages the\nDenseNet-121 structure, employing transfer learning principles. The output\nvariable was mortality in the first three months. Performance of the model was\nevaluated by statistical parameters conventionally used in studies involving\nartificial intelligence methods.\n  RESULTS: Images from 219 patients were processed, 175 for training and\nvalidation of the CNN and 44 for its evaluation. 52%(115/219) of patients were\nfemale, and the median age was 58(SD=13.06) years. 18.5%(39/219) were\nidiopathic SAH. Mortality rate was 28.5%(63/219). The model showed good\naccuracy at predicting mortality in SAH patients exclusively using the images\nof the initial CT scan (Accuracy=74%, F1=75% and AUC=82%). CONCLUSION: Modern\nimage processing techniques based on AI and CNN make possible to predict\nmortality in SAH patients with high accuracy using CT scan images as the only\ninput. These models might be optimized by including more data and patients\nresulting in better training, development and performance on tasks which are\nbeyond the skills of conventional clinical knowledge.",
            "author": [
                "Sergio Garcia-Garcia",
                "Santiago Cepeda",
                "Dominik Muller",
                "Alejandra Mosteiro",
                "Ramon Torne",
                "Silvia Agudo",
                "Natalia de la Torre",
                "Ignacio Arrese",
                "Rosario Sarabia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13373v1",
                "http://arxiv.org/pdf/2308.13373v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13369v3",
            "title": "Distribution-Aligned Diffusion for Human Mesh Recovery",
            "updated": "2023-10-25T03:32:42Z",
            "published": "2023-08-25T13:29:31Z",
            "summary": "Recovering a 3D human mesh from a single RGB image is a challenging task due\nto depth ambiguity and self-occlusion, resulting in a high degree of\nuncertainty. Meanwhile, diffusion models have recently seen much success in\ngenerating high-quality outputs by progressively denoising noisy inputs.\nInspired by their capability, we explore a diffusion-based approach for human\nmesh recovery, and propose a Human Mesh Diffusion (HMDiff) framework which\nframes mesh recovery as a reverse diffusion process. We also propose a\nDistribution Alignment Technique (DAT) that infuses prior distribution\ninformation into the mesh distribution diffusion process, and provides useful\nprior knowledge to facilitate the mesh recovery task. Our method achieves\nstate-of-the-art performance on three widely used datasets. Project page:\nhttps://gongjia0208.github.io/HMDiff/.",
            "author": [
                "Lin Geng Foo",
                "Jia Gong",
                "Hossein Rahmani",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13369v3",
                "http://arxiv.org/pdf/2308.13369v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13359v1",
            "title": "Topology of first integrals via Milnor fibrations II",
            "updated": "2023-08-25T13:10:26Z",
            "published": "2023-08-25T13:10:26Z",
            "summary": "This survey is the continuation of a series of works aimed at applying tools\nfrom Singularity Theory to Differential Equations. More precisely, we utilize\nthe powerfull Milnor's Fibration Theory to give geometric-topological\nclassifications of first integrals of differential systems. In the previous\npaper, systems of first-order quasilinear partial differential equations were\nexamined, focusing on the case of an isolated singularity. Now, we address both\ncases of isolated and \\textit{non-isolated singularities} for more general\ndynamical systems (namely, \\textit{foliations}) that admit at least one first\nintegral. For this, we utilize recently established connections between\nharmonic morphisms and Milnor fibrations to provide topological and geometric\ndescriptions of the foliations under consideration. In particular, we apply\nthese results to analyze the graph of solutions of some quasilinear systems.",
            "author": [
                "Fernando Reis",
                "Maico Ribeiro",
                "Euripedes da Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13359v1",
                "http://arxiv.org/pdf/2308.13359v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.AP",
                "math.DG",
                "math.GT",
                "14J17, 57R30, 14D06"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13346v1",
            "title": "GARHCX-NoVaS: A Model-free Approach to Incorporate Exogenous Variables",
            "updated": "2023-08-25T12:35:34Z",
            "published": "2023-08-25T12:35:34Z",
            "summary": "In this work, we further explore the forecasting ability of a recently\nproposed normalizing and variance-stabilizing (NoVaS) transformation after\nwrapping exogenous variables. In practice, especially in the area of financial\neconometrics, extra knowledge such as fundamentals- and sentiments-based\ninformation could be beneficial to improve the prediction accuracy of market\nvolatility if they are incorporated into the forecasting process. In a\nclassical approach, people usually apply GARCHX-type methods to include the\nexogenous variables. Being a Model-free prediction method, NoVaS has been shown\nto be more accurate and stable than classical GARCH-type methods. We are\ninterested in whether the novel NoVaS method can also sustain its superiority\nafter exogenous covariates are taken into account. We provide the NoVaS\ntransformation based on GARCHX model and then claim the corresponding\nprediction procedure with exogenous variables existing. Also, simulation\nstudies verify that the NoVaS method still outperforms traditional methods,\nespecially for long-term time aggregated predictions.",
            "author": [
                "Kejin Wu",
                "Sayar Karmakar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13346v1",
                "http://arxiv.org/pdf/2308.13346v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13342v1",
            "title": "The critical group of a combinatorial map",
            "updated": "2023-08-25T12:26:00Z",
            "published": "2023-08-25T12:26:00Z",
            "summary": "Motivated by the appearance of embeddings in the theory of chip firing and\nthe critical group of a graph, we introduce a version of the critical group (or\nsandpile group) for combinatorial maps, that is, for graphs embedded in\norientable surfaces. We provide several definitions of our critical group, by\napproaching it through analogues of the cycle-cocycle matrix, the Laplacian\nmatrix, and as the group of critical states of a chip firing game (or sandpile\nmodel) on the edges of a map.\n  Our group can be regarded as a perturbation of the classical critical group\nof its underlying graph by topological information, and it agrees with the\nclassical critical group in the plane case. Its cardinality is equal to the\nnumber of spanning quasi-trees in a connected map, just as the cardinality of\nthe classical critical group is equal to the number of spanning trees of a\nconnected graph.\n  Our approach exploits the properties of principally unimodular matrices and\nthe methods of delta-matroid theory.",
            "author": [
                "Criel Merino",
                "Iain Moffatt",
                "Steven Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13342v1",
                "http://arxiv.org/pdf/2308.13342v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13327v1",
            "title": "3D Face Alignment Through Fusion of Head Pose Information and Features",
            "updated": "2023-08-25T12:01:24Z",
            "published": "2023-08-25T12:01:24Z",
            "summary": "The ability of humans to infer head poses from face shapes, and vice versa,\nindicates a strong correlation between the two. Accordingly, recent studies on\nface alignment have employed head pose information to predict facial landmarks\nin computer vision tasks. In this study, we propose a novel method that employs\nhead pose information to improve face alignment performance by fusing said\ninformation with the feature maps of a face alignment network, rather than\nsimply using it to initialize facial landmarks. Furthermore, the proposed\nnetwork structure performs robust face alignment through a dual-dimensional\nnetwork using multidimensional features represented by 2D feature maps and a 3D\nheatmap. For effective dense face alignment, we also propose a prediction\nmethod for facial geometric landmarks through training based on knowledge\ndistillation using predicted keypoints. We experimentally assessed the\ncorrelation between the predicted facial landmarks and head pose information,\nas well as variations in the accuracy of facial landmarks with respect to the\nquality of head pose information. In addition, we demonstrated the\neffectiveness of the proposed method through a competitive performance\ncomparison with state-of-the-art methods on the AFLW2000-3D, AFLW, and BIWI\ndatasets.",
            "author": [
                "Jaehyun So",
                "Youngjoon Han"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13327v1",
                "http://arxiv.org/pdf/2308.13327v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13324v1",
            "title": "ConSlide: Asynchronous Hierarchical Interaction Transformer with\n  Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analysis",
            "updated": "2023-08-25T11:58:25Z",
            "published": "2023-08-25T11:58:25Z",
            "summary": "Whole slide image (WSI) analysis has become increasingly important in the\nmedical imaging community, enabling automated and objective diagnosis,\nprognosis, and therapeutic-response prediction. However, in clinical practice,\nthe ever-evolving environment hamper the utility of WSI analysis models. In\nthis paper, we propose the FIRST continual learning framework for WSI analysis,\nnamed ConSlide, to tackle the challenges of enormous image size, utilization of\nhierarchical structure, and catastrophic forgetting by progressive model\nupdating on multiple sequential datasets. Our framework contains three key\ncomponents. The Hierarchical Interaction Transformer (HIT) is proposed to model\nand utilize the hierarchical structural knowledge of WSI. The\nBreakup-Reorganize (BuRo) rehearsal method is developed for WSI data replay\nwith efficient region storing buffer and WSI reorganizing operation. The\nasynchronous updating mechanism is devised to encourage the network to learn\ngeneric and specific knowledge respectively during the replay stage, based on a\nnested cross-scale similarity learning (CSSL) module. We evaluated the proposed\nConSlide on four public WSI datasets from TCGA projects. It performs best over\nother state-of-the-art methods with a fair WSI-based continual learning setting\nand achieves a better trade-off of the overall performance and forgetting on\nprevious task",
            "author": [
                "Yanyan Huang",
                "Weiqin Zhao",
                "Shujun Wang",
                "Yu Fu",
                "Yuming Jiang",
                "Lequan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13324v1",
                "http://arxiv.org/pdf/2308.13324v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13323v1",
            "title": "SVQNet: Sparse Voxel-Adjacent Query Network for 4D Spatio-Temporal LiDAR\n  Semantic Segmentation",
            "updated": "2023-08-25T11:53:00Z",
            "published": "2023-08-25T11:53:00Z",
            "summary": "LiDAR-based semantic perception tasks are critical yet challenging for\nautonomous driving. Due to the motion of objects and static/dynamic occlusion,\ntemporal information plays an essential role in reinforcing perception by\nenhancing and completing single-frame knowledge. Previous approaches either\ndirectly stack historical frames to the current frame or build a 4D\nspatio-temporal neighborhood using KNN, which duplicates computation and\nhinders realtime performance. Based on our observation that stacking all the\nhistorical points would damage performance due to a large amount of redundant\nand misleading information, we propose the Sparse Voxel-Adjacent Query Network\n(SVQNet) for 4D LiDAR semantic segmentation. To take full advantage of the\nhistorical frames high-efficiently, we shunt the historical points into two\ngroups with reference to the current points. One is the Voxel-Adjacent\nNeighborhood carrying local enhancing knowledge. The other is the Historical\nContext completing the global knowledge. Then we propose new modules to select\nand extract the instructive features from the two groups. Our SVQNet achieves\nstate-of-the-art performance in LiDAR semantic segmentation of the\nSemanticKITTI benchmark and the nuScenes dataset.",
            "author": [
                "Xuechao Chen",
                "Shuangjie Xu",
                "Xiaoyi Zou",
                "Tongyi Cao",
                "Dit-Yan Yeung",
                "Lu Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13323v1",
                "http://arxiv.org/pdf/2308.13323v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13321v1",
            "title": "The Arrangement of Marks Impacts Afforded Messages: Ordering,\n  Partitioning, Spacing, and Coloring in Bar Charts",
            "updated": "2023-08-25T11:51:42Z",
            "published": "2023-08-25T11:51:42Z",
            "summary": "Data visualizations present a massive number of potential messages to an\nobserver. One might notice that one group's average is larger than another's,\nor that a difference in values is smaller than a difference between two others,\nor any of a combinatorial explosion of other possibilities. The message that a\nviewer tends to notice--the message that a visualization 'affords'--is strongly\naffected by how values are arranged in a chart, e.g., how the values are\ncolored or positioned. Although understanding the mapping between a chart's\narrangement and what viewers tend to notice is critical for creating guidelines\nand recommendation systems, current empirical work is insufficient to lay out\nclear rules. We present a set of empirical evaluations of how different\nmessages--including ranking, grouping, and part-to-whole relationships--are\nafforded by variations in ordering, partitioning, spacing, and coloring of\nvalues, within the ubiquitous case study of bar graphs. In doing so, we\nintroduce a quantitative method that is easily scalable, reviewable, and\nreplicable, laying groundwork for further investigation of the effects of\narrangement on message affordances across other visualizations and tasks.\nPre-registration and all supplemental materials are available at\nhttps://osf.io/np3q7 and https://osf.io/bvy95 .",
            "author": [
                "Racquel Fygenson",
                "Steven Franconeri",
                "Enrico Bertini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13321v1",
                "http://arxiv.org/pdf/2308.13321v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13320v1",
            "title": "Fine-tuning can cripple your foundation model; preserving features may\n  be the solution",
            "updated": "2023-08-25T11:49:51Z",
            "published": "2023-08-25T11:49:51Z",
            "summary": "Pre-trained foundation models, owing primarily to their enormous capacity and\nexposure to vast amount of training data scraped from the internet, enjoy the\nadvantage of storing knowledge about plenty of real-world concepts. Such models\nare typically fine-tuned on downstream datasets to produce remarkable\nstate-of-the-art performances. While various fine-tuning methods have been\ndevised and are shown to be highly effective, we observe that a fine-tuned\nmodel's ability to recognize concepts on tasks $\\textit{different}$ from the\ndownstream one is reduced significantly compared to its pre-trained\ncounterpart. This is clearly undesirable as a huge amount of time and money\nwent into learning those very concepts in the first place. We call this\nundesirable phenomenon \"concept forgetting\" and via experiments show that most\nend-to-end fine-tuning approaches suffer heavily from this side effect. To this\nend, we also propose a rather simple fix to this problem by designing a method\ncalled LDIFS (short for $\\ell_2$ distance in feature space) that simply\npreserves the features of the original foundation model during fine-tuning. We\nshow that LDIFS significantly reduces concept forgetting without having\nnoticeable impact on the downstream task performance.",
            "author": [
                "Jishnu Mukhoti",
                "Yarin Gal",
                "Philip H. S. Torr",
                "Puneet K. Dokania"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13320v1",
                "http://arxiv.org/pdf/2308.13320v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13315v2",
            "title": "Construction Grammar and Language Models",
            "updated": "2023-09-04T21:03:51Z",
            "published": "2023-08-25T11:37:56Z",
            "summary": "Recent progress in deep learning and natural language processing has given\nrise to powerful models that are primarily trained on a cloze-like task and\nshow some evidence of having access to substantial linguistic information,\nincluding some constructional knowledge. This groundbreaking discovery presents\nan exciting opportunity for a synergistic relationship between computational\nmethods and Construction Grammar research. In this chapter, we explore three\ndistinct approaches to the interplay between computational methods and\nConstruction Grammar: (i) computational methods for text analysis, (ii)\ncomputational Construction Grammar, and (iii) deep learning models, with a\nparticular focus on language models. We touch upon the first two approaches as\na contextual foundation for the use of computational methods before providing\nan accessible, yet comprehensive overview of deep learning models, which also\naddresses reservations construction grammarians may have. Additionally, we\ndelve into experiments that explore the emergence of constructionally relevant\ninformation within these models while also examining the aspects of\nConstruction Grammar that may pose challenges for these models. This chapter\naims to foster collaboration between researchers in the fields of natural\nlanguage processing and Construction Grammar. By doing so, we hope to pave the\nway for new insights and advancements in both these fields.",
            "author": [
                "Harish Tayyar Madabushi",
                "Laurence Romain",
                "Petar Milin",
                "Dagmar Divjak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13315v2",
                "http://arxiv.org/pdf/2308.13315v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13286v1",
            "title": "Unsupervised Domain Adaptation for Anatomical Landmark Detection",
            "updated": "2023-08-25T10:22:13Z",
            "published": "2023-08-25T10:22:13Z",
            "summary": "Recently, anatomical landmark detection has achieved great progresses on\nsingle-domain data, which usually assumes training and test sets are from the\nsame domain. However, such an assumption is not always true in practice, which\ncan cause significant performance drop due to domain shift. To tackle this\nproblem, we propose a novel framework for anatomical landmark detection under\nthe setting of unsupervised domain adaptation (UDA), which aims to transfer the\nknowledge from labeled source domain to unlabeled target domain. The framework\nleverages self-training and domain adversarial learning to address the domain\ngap during adaptation. Specifically, a self-training strategy is proposed to\nselect reliable landmark-level pseudo-labels of target domain data with dynamic\nthresholds, which makes the adaptation more effective. Furthermore, a domain\nadversarial learning module is designed to handle the unaligned data\ndistributions of two domains by learning domain-invariant features via\nadversarial training. Our experiments on cephalometric and lung landmark\ndetection show the effectiveness of the method, which reduces the domain gap by\na large margin and outperforms other UDA methods consistently. The code is\navailable at https://github.com/jhb86253817/UDA_Med_Landmark.",
            "author": [
                "Haibo Jin",
                "Haoxuan Che",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13286v1",
                "http://arxiv.org/pdf/2308.13286v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13276v2",
            "title": "Knowledge-Based Version Incompatibility Detection for Deep Learning",
            "updated": "2023-08-28T14:13:54Z",
            "published": "2023-08-25T09:53:26Z",
            "summary": "Version incompatibility issues are rampant when reusing or reproducing deep\nlearning models and applications. Existing techniques are limited to library\ndependency specifications declared in PyPI. Therefore, these techniques cannot\ndetect version issues due to undocumented version constraints or issues\ninvolving hardware drivers or OS. To address this challenge, we propose to\nleverage the abundant discussions of DL version issues from Stack Overflow to\nfacilitate version incompatibility detection. We reformulate the problem of\nknowledge extraction as a Question-Answering (QA) problem and use a pre-trained\nQA model to extract version compatibility knowledge from online discussions.\nThe extracted knowledge is further consolidated into a weighted knowledge graph\nto detect potential version incompatibilities when reusing a DL project. Our\nevaluation results show that (1) our approach can accurately extract version\nknowledge with 84% accuracy, and (2) our approach can accurately identify 65%\nof known version issues in 10 popular DL projects with a high precision (92%),\nwhile two state-of-the-art approaches can only detect 29% and 6% of these\nissues with 33% and 17% precision respectively.",
            "author": [
                "Zhongkai Zhao",
                "Bonan Kou",
                "Mohamed Yilmaz Ibrahim",
                "Muhao Chen",
                "Tianyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13276v2",
                "http://arxiv.org/pdf/2308.13276v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13265v1",
            "title": "Heterogeneous Federated Learning via Personalized Generative Networks",
            "updated": "2023-08-25T09:37:02Z",
            "published": "2023-08-25T09:37:02Z",
            "summary": "Federated Learning (FL) allows several clients to construct a common global\nmachine-learning model without having to share their data. FL, however, faces\nthe challenge of statistical heterogeneity between the client's data, which\ndegrades performance and slows down the convergence toward the global model. In\nthis paper, we provide theoretical proof that minimizing heterogeneity between\nclients facilitates the convergence of a global model for every single client.\nThis becomes particularly important under empirical concept shifts among\nclients, rather than merely considering imbalanced classes, which have been\nstudied until now. Therefore, we propose a method for knowledge transfer\nbetween clients where the server trains client-specific generators. Each\ngenerator generates samples for the corresponding client to remove the conflict\nwith other clients' models. Experiments conducted on synthetic and real data,\nalong with a theoretical study, support the effectiveness of our method in\nconstructing a well-generalizable global model by reducing the conflict between\nlocal models.",
            "author": [
                "Zahra Taghiyarrenani",
                "Abdallah Abdallah",
                "Slawomir Nowaczyk",
                "Sepideh Pashami"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13265v1",
                "http://arxiv.org/pdf/2308.13265v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13264v1",
            "title": "Capacity of infinite graphs over non-Archimedean ordered fields",
            "updated": "2023-08-25T09:35:15Z",
            "published": "2023-08-25T09:35:15Z",
            "summary": "In this article we study the notion of capacity of a vertex for infinite\ngraphs over non-Archimedean fields. In contrast to graphs over the real field\nmonotone limits do not need to exist. Thus, in our situation next to positive\nand null capacity there is a third case of divergent capacity. However, we show\nthat either of these cases is independent of the choice of the vertex and is\ntherefore a global property for connected graphs. The capacity is shown to\nconnect the minimization of the energy, solutions of the Dirichlet problem and\nexistence of a Green's function. We furthermore give sufficient criteria in\nform of a Nash-Williams test, study the relation to Hardy inequalities and\ndiscuss the existence of positive superharmonic functions. Finally, we\ninvestigate the analytic features of the transition operator in relation to the\ninverse of the Laplace operator.",
            "author": [
                "Florian Fischer",
                "Matthias Keller",
                "Anna Muranova",
                "Noema Nicolussi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13264v1",
                "http://arxiv.org/pdf/2308.13264v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math-ph",
                "math.MP",
                "math.SP",
                "31C20, 47S10, 05C50, 05C22, 12J15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13259v2",
            "title": "Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for\n  Knowledge-intensive Question Answering",
            "updated": "2023-10-28T12:19:29Z",
            "published": "2023-08-25T09:23:55Z",
            "summary": "Equipped with Chain-of-Thought (CoT), Large language models (LLMs) have shown\nimpressive reasoning ability in various downstream tasks. Even so, suffering\nfrom hallucinations and the inability to access external knowledge, LLMs often\ncome with incorrect or unfaithful intermediate reasoning steps, especially in\nthe context of answering knowledge-intensive tasks such as KBQA. To alleviate\nthis issue, we propose a framework called Knowledge-Driven Chain-of-Thought\n(KD-CoT) to verify and modify reasoning traces in CoT via interaction with\nexternal knowledge, and thus overcome the hallucinations and error propagation.\nConcretely, we formulate the CoT rationale process of LLMs into a structured\nmulti-round QA format. In each round, LLMs interact with a QA system that\nretrieves external knowledge and produce faithful reasoning traces based on\nretrieved precise answers. The structured CoT reasoning of LLMs is facilitated\nby our developed KBQA CoT collection, which serves as in-context learning\ndemonstrations and can also be utilized as feedback augmentation to train a\nrobust retriever. Extensive experiments on WebQSP and ComplexWebQuestion\ndatasets demonstrate the effectiveness of proposed KD-CoT in task-solving\nreasoning generation, which outperforms the vanilla CoT ICL with an absolute\nsuccess rate of 8.0% and 5.1%. Furthermore, our proposed feedback-augmented\nretriever outperforms the state-of-the-art baselines for retrieving knowledge,\nachieving significant improvement in Hit and recall performance. Our code and\ndata are released on https://github.com/AdelWang/KD-CoT/tree/main.",
            "author": [
                "Keheng Wang",
                "Feiyu Duan",
                "Sirui Wang",
                "Peiguang Li",
                "Yunsen Xian",
                "Chuantao Yin",
                "Wenge Rong",
                "Zhang Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13259v2",
                "http://arxiv.org/pdf/2308.13259v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13255v1",
            "title": "A lower bound on the multicolor size-Ramsey numbers of paths in\n  hypergraphs",
            "updated": "2023-08-25T09:01:24Z",
            "published": "2023-08-25T09:01:24Z",
            "summary": "The $r$-color size-Ramsey number of a $k$-uniform hypergraph~$H$, denoted by\n$\\hat{R}_r(H)$, is the minimum number of edges in a $k$-uniform hypergraph $G$\nsuch that for every $r$-coloring of the edges of $G$ there exists a\nmonochromatic copy of $H$. When $H$ is a graph path, it is known that\n$\\Omega(r^2n)=\\hat{R}_r(P_n)=O((r^2\\log r)n)$ with the best bounds essentially\ndue to Krivelevich. Letzter, Pokrovskiy, and Yepremyan~\\cite{LPY} recently\nproved that, for the $k$-uniform tight path $P_{n}^{(k)}$,\n$\\hat{R}_r(P_{n}^{(k)})=O_{r,k}(n)$.\n  We consider the problem of giving a lower bound on $\\hat{R}_r(P_{n}^{(k)})$\n(for fixed $k$ and growing $r$). We show that\n$\\hat{R}_r(P_n^{(k)})=\\Omega_k(r^kn)$. In the case $k=3$, we give a more\nprecise estimate which in particular improves the best known lower bound for\n$2$ colors due to Winter; i.e. we show $\\hat{R}(P^{(3)}_{n})\\geq\n\\frac{28}{9}n-30$. All of our results above generalize to $\\ell$-overlapping\n$k$-uniform paths $P_{n}^{(k, \\ell)}$. In general we have $\\hat{R}_r (\nP_{n}^{(k, \\ell)} ) = \\Omega_k( r^{\\left\\lfloor \\frac{k}{k-\\ell} \\right\\rfloor\n} n)$, and when $1\\leq \\ell\\leq \\frac{k}{2}$ we have $\\hat{R}_r(P_{n}^{(k,\n\\ell)})=\\Omega_k(r^{2}n)$.",
            "author": [
                "Deepak Bal",
                "Louis DeBiasio",
                "Allan Lo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13255v1",
                "http://arxiv.org/pdf/2308.13255v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13229v1",
            "title": "ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera\n  Multi-Object Tracking",
            "updated": "2023-08-25T08:02:04Z",
            "published": "2023-08-25T08:02:04Z",
            "summary": "Multi-Camera Multi-Object Tracking (MC-MOT) utilizes information from\nmultiple views to better handle problems with occlusion and crowded scenes.\nRecently, the use of graph-based approaches to solve tracking problems has\nbecome very popular. However, many current graph-based methods do not\neffectively utilize information regarding spatial and temporal consistency.\nInstead, they rely on single-camera trackers as input, which are prone to\nfragmentation and ID switch errors. In this paper, we propose a novel\nreconfigurable graph model that first associates all detected objects across\ncameras spatially before reconfiguring it into a temporal graph for Temporal\nAssociation. This two-stage association approach enables us to extract robust\nspatial and temporal-aware features and address the problem with fragmented\ntracklets. Furthermore, our model is designed for online tracking, making it\nsuitable for real-world applications. Experimental results show that the\nproposed graph model is able to extract more discriminating features for object\ntracking, and our model achieves state-of-the-art performance on several public\ndatasets.",
            "author": [
                "Cheng-Che Cheng",
                "Min-Xuan Qiu",
                "Chen-Kuo Chiang",
                "Shang-Hong Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13229v1",
                "http://arxiv.org/pdf/2308.13229v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13218v1",
            "title": "MultiCapCLIP: Auto-Encoding Prompts for Zero-Shot Multilingual Visual\n  Captioning",
            "updated": "2023-08-25T07:32:34Z",
            "published": "2023-08-25T07:32:34Z",
            "summary": "Supervised visual captioning models typically require a large scale of images\nor videos paired with descriptions in a specific language (i.e., the\nvision-caption pairs) for training. However, collecting and labeling\nlarge-scale datasets is time-consuming and expensive for many scenarios and\nlanguages. Therefore, sufficient labeled pairs are usually not available. To\ndeal with the label shortage problem, we present a simple yet effective\nzero-shot approach MultiCapCLIP that can generate visual captions for different\nscenarios and languages without any labeled vision-caption pairs of downstream\ndatasets. In the training stage, MultiCapCLIP only requires text data for\ninput. Then it conducts two main steps: 1) retrieving concept prompts that\npreserve the corresponding domain knowledge of new scenarios; 2) auto-encoding\nthe prompts to learn writing styles to output captions in a desired language.\nIn the testing stage, MultiCapCLIP instead takes visual data as input directly\nto retrieve the concept prompts to generate the final visual descriptions. The\nextensive experiments on image and video captioning across four benchmarks and\nfour languages (i.e., English, Chinese, German, and French) confirm the\neffectiveness of our approach. Compared with state-of-the-art zero-shot and\nweakly-supervised methods, our method achieves 4.8% and 21.5% absolute\nimprovements in terms of BLEU@4 and CIDEr metrics. Our code is available at\nhttps://github.com/yangbang18/MultiCapCLIP.",
            "author": [
                "Bang Yang",
                "Fenglin Liu",
                "Xian Wu",
                "Yaowei Wang",
                "Xu Sun",
                "Yuexian Zou"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.acl-long.664",
                "http://arxiv.org/abs/2308.13218v1",
                "http://arxiv.org/pdf/2308.13218v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13212v1",
            "title": "Physics-Inspired Neural Graph ODE for Long-term Dynamical Simulation",
            "updated": "2023-08-25T07:15:58Z",
            "published": "2023-08-25T07:15:58Z",
            "summary": "Simulating and modeling the long-term dynamics of multi-object physical\nsystems is an essential and challenging task. Current studies model the\nphysical systems utilizing Graph Neural Networks (GNNs) with equivariant\nproperties. Specifically, they model the dynamics as a sequence of discrete\nstates with a fixed time interval and learn a direct mapping for all the two\nadjacent states. However, this direct mapping overlooks the continuous nature\nbetween the two states. Namely, we have verified that there are countless\npossible trajectories between two discrete dynamic states in current GNN-based\ndirect mapping models. This issue greatly hinders the model generalization\nability, leading to poor performance of the long-term simulation. In this\npaper, to better model the latent trajectory through discrete supervision\nsignals, we propose a Physics-Inspired Neural Graph ODE (PINGO) algorithm. In\nPINGO, to ensure the uniqueness of the trajectory, we construct a\nPhysics-Inspired Neural ODE framework to update the latent trajectory.\nMeanwhile, to effectively capture intricate interactions among objects, we use\na GNN-based model to parameterize Neural ODE in a plug-and-play manner.\nFurthermore, we prove that the discrepancy between the learned trajectory of\nPIGNO and the true trajectory can be theoretically bounded. Extensive\nexperiments verify our theoretical findings and demonstrate that our model\nyields an order-of-magnitude improvement over the state-of-the-art baselines,\nespecially on long-term predictions and roll-out errors.",
            "author": [
                "Yang Liu",
                "Jiashun Cheng",
                "Haihong Zhao",
                "Tingyang Xu",
                "Peilin Zhao",
                "Fugee Tsung",
                "Jia Li",
                "Yu Rong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13212v1",
                "http://arxiv.org/pdf/2308.13212v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13207v1",
            "title": "LLM2KB: Constructing Knowledge Bases using instruction tuned context\n  aware Large Language Models",
            "updated": "2023-08-25T07:04:16Z",
            "published": "2023-08-25T07:04:16Z",
            "summary": "The advent of Large Language Models (LLM) has revolutionized the field of\nnatural language processing, enabling significant progress in various\napplications. One key area of interest is the construction of Knowledge Bases\n(KB) using these powerful models. Knowledge bases serve as repositories of\nstructured information, facilitating information retrieval and inference tasks.\nOur paper proposes LLM2KB, a system for constructing knowledge bases using\nlarge language models, with a focus on the Llama 2 architecture and the\nWikipedia dataset. We perform parameter efficient instruction tuning for\nLlama-2-13b-chat and StableBeluga-13B by training small injection models that\nhave only 0.05 % of the parameters of the base models using the Low Rank\nAdaptation (LoRA) technique. These injection models have been trained with\nprompts that are engineered to utilize Wikipedia page contexts of subject\nentities fetched using a Dense Passage Retrieval (DPR) algorithm, to answer\nrelevant object entities for a given subject entity and relation. Our best\nperforming model achieved an average F1 score of 0.6185 across 21 relations in\nthe LM-KBC challenge held at the ISWC 2023 conference.",
            "author": [
                "Anmol Nayak",
                "Hari Prasad Timmapathini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13207v1",
                "http://arxiv.org/pdf/2308.13207v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13198v1",
            "title": "Journey to the Center of the Knowledge Neurons: Discoveries of\n  Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons",
            "updated": "2023-08-25T06:26:05Z",
            "published": "2023-08-25T06:26:05Z",
            "summary": "Pre-trained language models (PLMs) contain vast amounts of factual knowledge,\nbut how the knowledge is stored in the parameters remains unclear. This paper\ndelves into the complex task of understanding how factual knowledge is stored\nin multilingual PLMs, and introduces the Architecture-adapted Multilingual\nIntegrated Gradients method, which successfully localizes knowledge neurons\nmore precisely compared to current methods, and is more universal across\nvarious architectures and languages. Moreover, we conduct an in-depth\nexploration of knowledge neurons, leading to the following two important\ndiscoveries: (1) The discovery of Language-Independent Knowledge Neurons, which\nstore factual knowledge in a form that transcends language. We design\ncross-lingual knowledge editing experiments, demonstrating that the PLMs can\naccomplish this task based on language-independent neurons; (2) The discovery\nof Degenerate Knowledge Neurons, a novel type of neuron showing that different\nknowledge neurons can store the same fact. Its property of functional overlap\nendows the PLMs with a robust mastery of factual knowledge. We design\nfact-checking experiments, proving that the degenerate knowledge neurons can\nhelp the PLMs to detect wrong facts. Experiments corroborate these findings,\nshedding light on the mechanisms of factual knowledge storage in multilingual\nPLMs, and contribute valuable insights to the field. The source code will be\nmade publicly available for further research.",
            "author": [
                "Yuheng Chen",
                "Pengfei Cao",
                "Yubo Chen",
                "Kang Liu",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13198v1",
                "http://arxiv.org/pdf/2308.13198v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13184v1",
            "title": "Performance Analysis of Finite Blocklength Transmissions Over Wiretap\n  Fading Channels: An Average Information Leakage Perspective",
            "updated": "2023-08-25T05:31:02Z",
            "published": "2023-08-25T05:31:02Z",
            "summary": "Physical-layer security (PLS) is a promising technique to complement\ncommunication security in beyond-5G wireless networks. However, PLS\ndevelopments in current research are often based on the ideal assumption of\ninfinite coding blocklengths or perfect knowledge of the wiretap link's channel\nstate information (CSI). In this work, we study the performance of finite\nblocklength (FBL) transmissions using a new secrecy metric - the average\ninformation leakage (AIL). We evaluate the exact and approximate AIL with\narbitrary signaling and fading channels, assuming that the eavesdropper's\ninstantaneous CSI is unknown. We then conduct case studies that use artificial\nnoise (AN) beamforming to thoroughly analyze the AIL in both Rayleigh and\nRician fading channels. The accuracy of the analytical expressions is verified\nthrough extensive simulations, and various insights regarding the impact of key\nsystem parameters on the AIL are obtained. Particularly, our results reveal\nthat allowing a small level of AIL can potentially lead to significant\nreliability improvements. To improve the system performance, we formulate and\nsolve an average secrecy throughput (AST) optimization problem via both\nnon-adaptive and adaptive design strategies. Our findings highlight the\nsignificance of blocklength design and AN power allocation, as well as the\nimpact of their trade-off on the AST.",
            "author": [
                "Milad Tatar Mamaghani",
                "Xiangyun Zhou",
                "Nan Yang",
                "A. Lee Swindlehurst",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13184v1",
                "http://arxiv.org/pdf/2308.13184v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13177v1",
            "title": "How to Evaluate the Generalization of Detection? A Benchmark for\n  Comprehensive Open-Vocabulary Detection",
            "updated": "2023-08-25T04:54:32Z",
            "published": "2023-08-25T04:54:32Z",
            "summary": "Object detection (OD) in computer vision has made significant progress in\nrecent years, transitioning from closed-set labels to open-vocabulary detection\n(OVD) based on large-scale vision-language pre-training (VLP). However, current\nevaluation methods and datasets are limited to testing generalization over\nobject types and referral expressions, which do not provide a systematic,\nfine-grained, and accurate benchmark of OVD models' abilities. In this paper,\nwe propose a new benchmark named OVDEval, which includes 9 sub-tasks and\nintroduces evaluations on commonsense knowledge, attribute understanding,\nposition understanding, object relation comprehension, and more. The dataset is\nmeticulously created to provide hard negatives that challenge models' true\nunderstanding of visual and linguistic input. Additionally, we identify a\nproblem with the popular Average Precision (AP) metric when benchmarking models\non these fine-grained label datasets and propose a new metric called\nNon-Maximum Suppression Average Precision (NMS-AP) to address this issue.\nExtensive experimental results show that existing top OVD models all fail on\nthe new tasks except for simple object types, demonstrating the value of the\nproposed dataset in pinpointing the weakness of current OVD models and guiding\nfuture research. Furthermore, the proposed NMS-AP metric is verified by\nexperiments to provide a much more truthful evaluation of OVD models, whereas\ntraditional AP metrics yield deceptive results. Data is available at\n\\url{https://github.com/om-ai-lab/OVDEval}",
            "author": [
                "Yiyang Yao",
                "Peng Liu",
                "Tiancheng Zhao",
                "Qianqian Zhang",
                "Jiajia Liao",
                "Chunxin Fang",
                "Kyusong Lee",
                "Qing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13177v1",
                "http://arxiv.org/pdf/2308.13177v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13176v1",
            "title": "Using Adamic-Adar Index Algorithm to Predict Volunteer Collaboration:\n  Less is More",
            "updated": "2023-08-25T04:52:54Z",
            "published": "2023-08-25T04:52:54Z",
            "summary": "Social networks exhibit a complex graph-like structure due to the uncertainty\nsurrounding potential collaborations among participants. Machine learning\nalgorithms possess generic outstanding performance in multiple real-world\nprediction tasks. However, whether machine learning algorithms outperform\nspecific algorithms designed for graph link prediction remains unknown to us.\nTo address this issue, the Adamic-Adar Index (AAI), Jaccard Coefficient (JC)\nand common neighbour centrality (CNC) as representatives of graph-specific\nalgorithms were applied to predict potential collaborations, utilizing data\nfrom volunteer activities during the Covid-19 pandemic in Shenzhen city, along\nwith the classical machine learning algorithms such as random forest, support\nvector machine, and gradient boosting as single predictors and components of\nensemble learning. This paper introduces that the AAI algorithm outperformed\nthe traditional JC and CNC, and other machine learning algorithms in analyzing\ngraph node attributes for this task.",
            "author": [
                "Chao Wu",
                "Peng Chen",
                "Baiqiao Yin",
                "Zijuan Lin",
                "Chen Jiang",
                "Di Yu",
                "Changhong Zou",
                "Chunwang Lui"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13176v1",
                "http://arxiv.org/pdf/2308.13176v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13172v1",
            "title": "Discovering Dichotomies for Problems in Database Theory",
            "updated": "2023-08-25T04:42:28Z",
            "published": "2023-08-25T04:42:28Z",
            "summary": "Dichotomy theorems, which characterize the conditions under which a problem\ncan be solved efficiently, have helped identify important tractability borders\nfor as probabilistic query evaluation, view maintenance, query containment\n(among many more problems). However, dichotomy theorems for many such problems\nremain elusive under key settings such as bag semantics or for queries with\nself-joins. This work aims to unearth dichotomies for fundamental problems in\nreverse data management and knowledge representation. We use a novel approach\nto discovering dichotomies: instead of creating dedicated algorithms for easy\n(PTIME) and hard cases (NP-complete), we devise unified algorithms that are\nguaranteed to terminate in PTIME for easy cases. Using this approach, we\ndiscovered new tractable cases for the problem of minimal factorization of\nprovenance formulas as well as dichotomies under bag semantics for the problems\nof resilience and causal responsibility",
            "author": [
                "Neha Makhija"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13172v1",
                "http://arxiv.org/pdf/2308.13172v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13170v1",
            "title": "Measuring Spurious Correlation in Classification: 'Clever Hans' in\n  Translationese",
            "updated": "2023-08-25T04:19:58Z",
            "published": "2023-08-25T04:19:58Z",
            "summary": "Recent work has shown evidence of 'Clever Hans' behavior in high-performance\nneural translationese classifiers, where BERT-based classifiers capitalize on\nspurious correlations, in particular topic information, between data and target\nclassification labels, rather than genuine translationese signals.\nTranslationese signals are subtle (especially for professional translation) and\ncompete with many other signals in the data such as genre, style, author, and,\nin particular, topic. This raises the general question of how much of the\nperformance of a classifier is really due to spurious correlations in the data\nversus the signals actually targeted for by the classifier, especially for\nsubtle target signals and in challenging (low resource) data settings. We focus\non topic-based spurious correlation and approach the question from two\ndirections: (i) where we have no knowledge about spurious topic information and\nits distribution in the data, (ii) where we have some indication about the\nnature of spurious topic correlations. For (i) we develop a measure from first\nprinciples capturing alignment of unsupervised topics with target\nclassification labels as an indication of spurious topic information in the\ndata. We show that our measure is the same as purity in clustering and propose\na 'topic floor' (as in a 'noise floor') for classification. For (ii) we\ninvestigate masking of known spurious topic carriers in classification. Both\n(i) and (ii) contribute to quantifying and (ii) to mitigating spurious\ncorrelations.",
            "author": [
                "Angana Borah",
                "Daria Pylypenko",
                "Cristina Espana-Bonet",
                "Josef van Genabith"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13170v1",
                "http://arxiv.org/pdf/2308.13170v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13165v1",
            "title": "Dual Compensation Residual Networks for Class Imbalanced Learning",
            "updated": "2023-08-25T04:06:30Z",
            "published": "2023-08-25T04:06:30Z",
            "summary": "Learning generalizable representation and classifier for class-imbalanced\ndata is challenging for data-driven deep models. Most studies attempt to\nre-balance the data distribution, which is prone to overfitting on tail classes\nand underfitting on head classes. In this work, we propose Dual Compensation\nResidual Networks to better fit both tail and head classes. Firstly, we propose\ndual Feature Compensation Module (FCM) and Logit Compensation Module (LCM) to\nalleviate the overfitting issue. The design of these two modules is based on\nthe observation: an important factor causing overfitting is that there is\nsevere feature drift between training and test data on tail classes. In\ndetails, the test features of a tail category tend to drift towards feature\ncloud of multiple similar head categories. So FCM estimates a multi-mode\nfeature drift direction for each tail category and compensate for it.\nFurthermore, LCM translates the deterministic feature drift vector estimated by\nFCM along intra-class variations, so as to cover a larger effective\ncompensation space, thereby better fitting the test features. Secondly, we\npropose a Residual Balanced Multi-Proxies Classifier (RBMC) to alleviate the\nunder-fitting issue. Motivated by the observation that re-balancing strategy\nhinders the classifier from learning sufficient head knowledge and eventually\ncauses underfitting, RBMC utilizes uniform learning with a residual path to\nfacilitate classifier learning. Comprehensive experiments on Long-tailed and\nClass-Incremental benchmarks validate the efficacy of our method.",
            "author": [
                "Ruibing Hou",
                "Hong Chang",
                "Bingpeng Ma",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13165v1",
                "http://arxiv.org/pdf/2308.13165v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13158v1",
            "title": "DAG-ACFL: Asynchronous Clustered Federated Learning based on DAG-DLT",
            "updated": "2023-08-25T03:35:29Z",
            "published": "2023-08-25T03:35:29Z",
            "summary": "Federated learning (FL) aims to collaboratively train a global model while\nensuring client data privacy. However, FL faces challenges from the non-IID\ndata distribution among clients. Clustered FL (CFL) has emerged as a promising\nsolution, but most existing CFL frameworks adopt synchronous frameworks lacking\nasynchrony. An asynchronous CFL framework called SDAGFL based on directed\nacyclic graph distributed ledger techniques (DAG-DLT) was proposed, but its\ncomplete decentralization leads to high communication and storage costs. We\npropose DAG-ACFL, an asynchronous clustered FL framework based on directed\nacyclic graph distributed ledger techniques (DAG-DLT). We first detail the\ncomponents of DAG-ACFL. A tip selection algorithm based on the cosine\nsimilarity of model parameters is then designed to aggregate models from\nclients with similar distributions. An adaptive tip selection algorithm\nleveraging change-point detection dynamically determines the number of selected\ntips. We evaluate the clustering and training performance of DAG-ACFL on\nmultiple datasets and analyze its communication and storage costs. Experiments\nshow the superiority of DAG-ACFL in asynchronous clustered FL. By combining\nDAG-DLT with clustered FL, DAG-ACFL realizes robust, decentralized and private\nmodel training with efficient performance.",
            "author": [
                "Xiaofeng Xue",
                "Haokun Mao",
                "Qiong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13158v1",
                "http://arxiv.org/pdf/2308.13158v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13153v1",
            "title": "Occupational Retirement and Pension Reform: The Roles of Physical and\n  Cognitive Health",
            "updated": "2023-08-25T03:13:44Z",
            "published": "2023-08-25T03:13:44Z",
            "summary": "Despite increasing cognitive demands of jobs, knowledge about the role of\nhealth in retirement has centered on its physical dimensions. This paper\nestimates a dynamic programming model of retirement that incorporates multiple\nhealth dimensions, allowing differential effects on labor supply across\noccupations. Results show that the effect of cognitive health surges\nexponentially after age 65, and it explains a notable share of employment\ndeclines in cognitively demanding occupations. Under pension reforms, physical\nconstraint mainly impedes manual workers from delaying retirement, whereas\ncognitive constraint dampens the response of clerical and professional workers.\nMultidimensional health thus unevenly exacerbate welfare losses across\noccupations.",
            "author": [
                "Jiayi Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13153v1",
                "http://arxiv.org/pdf/2308.13153v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13152v1",
            "title": "The time dimensional reduction method to determine the initial\n  conditions without the knowledge of damping coefficients",
            "updated": "2023-08-25T03:11:30Z",
            "published": "2023-08-25T03:11:30Z",
            "summary": "This paper aims to reconstruct the initial condition of a hyperbolic equation\nwith an unknown damping coefficient. Our approach involves approximating the\nhyperbolic equation's solution by its truncated Fourier expansion in the time\ndomain and using a polynomial-exponential basis. This truncation process\nfacilitates the elimination of the time variable, consequently, yielding a\nsystem of quasi-linear elliptic equations. To globally solve the system without\nneeding an accurate initial guess, we employ the Carleman contraction\nprinciple. We provide several numerical examples to illustrate the efficacy of\nour method. The method not only delivers precise solutions but also showcases\nremarkable computational efficiency.",
            "author": [
                "Thuy T. Le",
                "Linh V. Nguyen",
                "Loc H. Nguyen",
                "Hyunha Park"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13152v1",
                "http://arxiv.org/pdf/2308.13152v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13150v4",
            "title": "Enhancing Breast Cancer Classification Using Transfer ResNet with\n  Lightweight Attention Mechanism",
            "updated": "2023-10-21T02:02:07Z",
            "published": "2023-08-25T03:08:41Z",
            "summary": "Despite the remarkable results of deep learning in breast cancer image\nclassification, challenges such as data imbalance and interpretability still\nexist and require cross-domain knowledge and collaboration among medical\nexperts. In this study, we propose a dual-activated lightweight attention\nResNet50 module method-based breast cancer classification method that\neffectively addresses challenges such as data imbalance and interpretability.\nOur model fuses a pre-trained deep ResNet50 and a lightweight attention\nmechanism to accomplish classification by embedding an attention module in\nlayer 4 of ResNet50 and adding two fully connected layers. For the fully\nconnected network design, we employ both Leaky ReLU and ReLU activation\nfunctions. On medical histopathology datasets, our model outperforms\nconventional models, visual transformers, and large models in terms of\nprecision, accuracy, recall, F1 score, and GMean. In particular, the model\ndemonstrates significant robustness and broad applicability when dealing with\nthe unbalanced breast cancer dataset. Our model is tested on 40X, 100X, 200X,\nand 400X images and achieves accuracies of 98.5%, 98.7%, 97.9%, and 94.3%,\nrespectively. Through an in-depth analysis of loss and accuracy, as well as\nGrad-CAM analysis, we comprehensively assessed the model performance and gained\nperspective on its training process. In the later stages of training, the\nvalidated losses and accuracies change minimally, showing that the model avoids\noverfitting and exhibits good generalization ability. Overall, this study\nprovides an effective solution for breast cancer image classification with\npractical applica",
            "author": [
                "Suxing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13150v4",
                "http://arxiv.org/pdf/2308.13150v4"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13568v1",
            "title": "Region-Disentangled Diffusion Model for High-Fidelity PPG-to-ECG\n  Translation",
            "updated": "2023-08-25T02:44:51Z",
            "published": "2023-08-25T02:44:51Z",
            "summary": "The high prevalence of cardiovascular diseases (CVDs) calls for accessible\nand cost-effective continuous cardiac monitoring tools. Despite\nElectrocardiography (ECG) being the gold standard, continuous monitoring\nremains a challenge, leading to the exploration of Photoplethysmography (PPG),\na promising but more basic alternative available in consumer wearables. This\nnotion has recently spurred interest in translating PPG to ECG signals. In this\nwork, we introduce Region-Disentangled Diffusion Model (RDDM), a novel\ndiffusion model designed to capture the complex temporal dynamics of ECG.\nTraditional Diffusion models like Denoising Diffusion Probabilistic Models\n(DDPM) face challenges in capturing such nuances due to the indiscriminate\nnoise addition process across the entire signal. Our proposed RDDM overcomes\nsuch limitations by incorporating a novel forward process that selectively adds\nnoise to specific regions of interest (ROI) such as QRS complex in ECG signals,\nand a reverse process that disentangles the denoising of ROI and non-ROI\nregions. Quantitative experiments demonstrate that RDDM can generate\nhigh-fidelity ECG from PPG in as few as 10 diffusion steps, making it highly\neffective and computationally efficient. Additionally, to rigorously validate\nthe usefulness of the generated ECG signals, we introduce CardioBench, a\ncomprehensive evaluation benchmark for a variety of cardiac-related tasks\nincluding heart rate and blood pressure estimation, stress classification, and\nthe detection of atrial fibrillation and diabetes. Our thorough experiments\nshow that RDDM achieves state-of-the-art performance on CardioBench. To the\nbest of our knowledge, RDDM is the first diffusion model for cross-modal\nsignal-to-signal translation in the bio-signal domain.",
            "author": [
                "Debaditya Shome",
                "Pritam Sarkar",
                "Ali Etemad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13568v1",
                "http://arxiv.org/pdf/2308.13568v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13139v1",
            "title": "MatchXML: An Efficient Text-label Matching Framework for Extreme\n  Multi-label Text Classification",
            "updated": "2023-08-25T02:32:36Z",
            "published": "2023-08-25T02:32:36Z",
            "summary": "The eXtreme Multi-label text Classification(XMC) refers to training a\nclassifier that assigns a text sample with relevant labels from an extremely\nlarge-scale label set (e.g., millions of labels). We propose MatchXML, an\nefficient text-label matching framework for XMC. We observe that the label\nembeddings generated from the sparse Term Frequency-Inverse Document\nFrequency(TF-IDF) features have several limitations. We thus propose label2vec\nto effectively train the semantic dense label embeddings by the Skip-gram\nmodel. The dense label embeddings are then used to build a Hierarchical Label\nTree by clustering. In fine-tuning the pre-trained encoder Transformer, we\nformulate the multi-label text classification as a text-label matching problem\nin a bipartite graph. We then extract the dense text representations from the\nfine-tuned Transformer. Besides the fine-tuned dense text embeddings, we also\nextract the static dense sentence embeddings from a pre-trained Sentence\nTransformer. Finally, a linear ranker is trained by utilizing the sparse TF-IDF\nfeatures, the fine-tuned dense text representations and static dense sentence\nfeatures. Experimental results demonstrate that MatchXML achieves\nstate-of-the-art accuracy on five out of six datasets. As for the speed,\nMatchXML outperforms the competing methods on all the six datasets. Our source\ncode is publicly available at https://github.com/huiyegit/MatchXML.",
            "author": [
                "Hui Ye",
                "Rajshekhar Sunderraman",
                "Shihao Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13139v1",
                "http://arxiv.org/pdf/2308.13139v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13135v1",
            "title": "Nonparametric Additive Value Functions: Interpretable Reinforcement\n  Learning with an Application to Surgical Recovery",
            "updated": "2023-08-25T02:05:51Z",
            "published": "2023-08-25T02:05:51Z",
            "summary": "We propose a nonparametric additive model for estimating interpretable value\nfunctions in reinforcement learning. Learning effective adaptive clinical\ninterventions that rely on digital phenotyping features is a major for concern\nmedical practitioners. With respect to spine surgery, different post-operative\nrecovery recommendations concerning patient mobilization can lead to\nsignificant variation in patient recovery. While reinforcement learning has\nachieved widespread success in domains such as games, recent methods heavily\nrely on black-box methods, such neural networks. Unfortunately, these methods\nhinder the ability of examining the contribution each feature makes in\nproducing the final suggested decision. While such interpretations are easily\nprovided in classical algorithms such as Least Squares Policy Iteration, basic\nlinearity assumptions prevent learning higher-order flexible interactions\nbetween features. In this paper, we present a novel method that offers a\nflexible technique for estimating action-value functions without making\nexplicit parametric assumptions regarding their additive functional form. This\nnonparametric estimation strategy relies on incorporating local kernel\nregression and basis expansion to obtain a sparse, additive representation of\nthe action-value function. Under this approach, we are able to locally\napproximate the action-value function and retrieve the nonlinear, independent\ncontribution of select features as well as joint feature pairs. We validate the\nproposed approach with a simulation study, and, in an application to spine\ndisease, uncover recovery recommendations that are inline with related clinical\nknowledge.",
            "author": [
                "Patrick Emedom-Nnamdi",
                "Timothy R. Smith",
                "Jukka-Pekka Onnela",
                "Junwei Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13135v1",
                "http://arxiv.org/pdf/2308.13135v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13133v1",
            "title": "AccFlow: Backward Accumulation for Long-Range Optical Flow",
            "updated": "2023-08-25T01:51:26Z",
            "published": "2023-08-25T01:51:26Z",
            "summary": "Recent deep learning-based optical flow estimators have exhibited impressive\nperformance in generating local flows between consecutive frames. However, the\nestimation of long-range flows between distant frames, particularly under\ncomplex object deformation and large motion occlusion, remains a challenging\ntask. One promising solution is to accumulate local flows explicitly or\nimplicitly to obtain the desired long-range flow. Nevertheless, the\naccumulation errors and flow misalignment can hinder the effectiveness of this\napproach. This paper proposes a novel recurrent framework called AccFlow, which\nrecursively backward accumulates local flows using a deformable module called\nas AccPlus. In addition, an adaptive blending module is designed along with\nAccPlus to alleviate the occlusion effect by backward accumulation and rectify\nthe accumulation error. Notably, we demonstrate the superiority of backward\naccumulation over conventional forward accumulation, which to the best of our\nknowledge has not been explicitly established before. To train and evaluate the\nproposed AccFlow, we have constructed a large-scale high-quality dataset named\nCVO, which provides ground-truth optical flow labels between adjacent and\ndistant frames. Extensive experiments validate the effectiveness of AccFlow in\nhandling long-range optical flow estimation. Codes are available at\nhttps://github.com/mulns/AccFlow .",
            "author": [
                "Guangyang Wu",
                "Xiaohong Liu",
                "Kunming Luo",
                "Xi Liu",
                "Qingqing Zheng",
                "Shuaicheng Liu",
                "Xinyang Jiang",
                "Guangtao Zhai",
                "Wenyi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13133v1",
                "http://arxiv.org/pdf/2308.13133v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13565v1",
            "title": "DARWIN Series: Domain Specific Large Language Models for Natural Science",
            "updated": "2023-08-25T01:40:48Z",
            "published": "2023-08-25T01:40:48Z",
            "summary": "Emerging tools bring forth fresh approaches to work, and the field of natural\nscience is no different. In natural science, traditional manual, serial, and\nlabour-intensive work is being augmented by automated, parallel, and iterative\nprocesses driven by artificial intelligence-based experimental automation and\nmore. To add new capabilities in natural science, enabling the acceleration and\nenrichment of automation of the discovery process, we present DARWIN, a series\nof tailored LLMs for natural science, mainly in physics, chemistry, and\nmaterial science. This series relies on open-source LLM, incorporating\nstructured and unstructured scientific knowledge from public datasets and\nliterature. We fine-tuned the models using over 60,000 instruction data points,\nemphasizing factual correctness. During the fine-tuning, we introduce the\nScientific Instruction Generation (SIG) model, automating instruction\ngeneration from scientific texts. This eliminates the need for manual\nextraction or domain-specific knowledge graphs and efficiently injects\nscientific knowledge into the model. We also explore multi-task training\nstrategies, revealing interconnections between scientific tasks. DARWIN series\nnot only achieves state-of-the-art results on various scientific tasks but also\ndiminishes reliance on closed-source AI models. Our research showcases the\nability of LLM in the scientific domain, with the overarching goal of fostering\nprosperity within the broader AI for science community.",
            "author": [
                "Tong Xie",
                "Yuwei Wan",
                "Wei Huang",
                "Zhenyu Yin",
                "Yixuan Liu",
                "Shaozhou Wang",
                "Qingyuan Linghu",
                "Chunyu Kit",
                "Clara Grazian",
                "Wenjie Zhang",
                "Imran Razzak",
                "Bram Hoex"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13565v1",
                "http://arxiv.org/pdf/2308.13565v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13130v1",
            "title": "Packing a Degree Sequence Realization With A Graph",
            "updated": "2023-08-25T01:10:51Z",
            "published": "2023-08-25T01:10:51Z",
            "summary": "Two simple $n$-vertex graphs $G_{1}$ and $G_{2}$, with respective maximum\ndegrees $\\Delta_{1}$ and $\\Delta_{2}$, are said to pack if $G_{1}$ is\nisomorphic to a subgraph of the complement of $G_{2}$. The BEC conjecture by\nBollob\\'{a}s, Eldridge, and Catlin, states that if\n$(\\Delta_{1}+1)(\\Delta_{2}+1)\\leq n+1$, then $G_{1}$ and $G_{2}$ pack. The BEC\nconjecture is true when $\\Delta_{1}=2$ and has been confirmed for a few other\nclasses of graphs with various conditions on $\\Delta_{1}$, $\\Delta_{2}$, or\n$n$. We show that if \\[(\\Delta_{1}+1)(\\Delta_{2}+1)\\leq\nn+\\min\\{\\Delta_{1},\\Delta_{2}\\},\\] then there exists a simple graph with an\nidentical degree sequence as $G_{1}$ that packs with $G_{2}$. However, except\nfor a few cases, we show that this bound is not sharp. As a consequence of our\nwork, we confirm the BEC conjecture if $G_{1}$ is the vertex disjoint union of\na unigraph and a forest $F$ such that either $F$ has at least $\\Delta_{2}+1$\ncomponents or at most $2\\Delta_{2}-1$ edges.",
            "author": [
                "James M. Shook"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13130v1",
                "http://arxiv.org/pdf/2308.13130v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C75"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13122v1",
            "title": "Protective measurements of photon polarization using a temporal pointer",
            "updated": "2023-08-25T00:14:42Z",
            "published": "2023-08-25T00:14:42Z",
            "summary": "We experimentally demonstrate protective measurements by weakly coupling the\npolarization of a single-photon-level field to a measurement pointer that\ncorresponds to the arrival time of the photon. By using an optical loop, we\nimplement a variable, controlled number (1-9) of protection and measurement\nstages. We demonstrate the measurement of expectation values of photon\npolarization by measuring arrival times while simultaneously protecting the\npolarization state. No knowledge of the initial photon state is required or\navailable in our experiment, demonstrating that protective measurements provide\na genuine information gain that cannot simply be reduced to a priori\ninformation about the protection procedure.",
            "author": [
                "Meng-Wei Chen",
                "Owen Young",
                "Maximilian Schlosshauer",
                "M. Beck"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevA.108.022420",
                "http://arxiv.org/abs/2308.13122v1",
                "http://arxiv.org/pdf/2308.13122v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13116v1",
            "title": "Sentence Embedding Models for Ancient Greek Using Multilingual Knowledge\n  Distillation",
            "updated": "2023-08-24T23:38:44Z",
            "published": "2023-08-24T23:38:44Z",
            "summary": "Contextual language models have been trained on Classical languages,\nincluding Ancient Greek and Latin, for tasks such as lemmatization,\nmorphological tagging, part of speech tagging, authorship attribution, and\ndetection of scribal errors. However, high-quality sentence embedding models\nfor these historical languages are significantly more difficult to achieve due\nto the lack of training data. In this work, we use a multilingual knowledge\ndistillation approach to train BERT models to produce sentence embeddings for\nAncient Greek text. The state-of-the-art sentence embedding approaches for\nhigh-resource languages use massive datasets, but our distillation approach\nallows our Ancient Greek models to inherit the properties of these models while\nusing a relatively small amount of translated sentence data. We build a\nparallel sentence dataset using a sentence-embedding alignment method to align\nAncient Greek documents with English translations, and use this dataset to\ntrain our models. We evaluate our models on translation search, semantic\nsimilarity, and semantic retrieval tasks and investigate translation bias. We\nmake our training and evaluation datasets freely available at\nhttps://github.com/kevinkrahn/ancient-greek-datasets .",
            "author": [
                "Kevin Krahn",
                "Derrick Tate",
                "Andrew C. Lamicela"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13116v1",
                "http://arxiv.org/pdf/2308.13116v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13110v1",
            "title": "Path-Regularity and Martingale Properties of Set-Valued Stochastic\n  Integrals",
            "updated": "2023-08-24T23:02:18Z",
            "published": "2023-08-24T23:02:18Z",
            "summary": "In this paper we study the path-regularity and martingale properties of the\nset-valued stochastic integrals defined in our previous work Ararat et al.\n(2023). Such integrals have some fundamental differences from the well-known\nAumann-It\\^{o} stochastic integrals, and are much better suitable for\nrepresenting set-valued martingales, whence potentially useful in the study of\nset-valued backward stochastic differential equations. However, similar to the\nAumann-It\\^{o} integral, the new integral is only a set-valued submartingale in\ngeneral, and there is very limited knowledge about the path regularity of the\nrelated indefinite integral, much less the sufficient conditions under which\nthe integral is a true martingale. In this paper, we first establish the\nexistence of right- and left-continuous modifications of set-valued\nsubmartingales in continuous time, and apply the results to set-valued\nstochastic integrals. Moreover, we show that a set-valued stochastic integral\nyields a martingale if and only if the set of terminal values of the stochastic\nintegrals associated to the integrand is closed and decomposable. Finally, as a\nparticular example, we study the set-valued martingale in the form of the\nconditional expectation of a set-valued random variable. We show that when the\nrandom variable is a convex random polytope, the conditional expectation of a\nvertex stays as a vertex of the set-valued conditional expectation if and only\nif the random polytope has a deterministic normal fan.",
            "author": [
                "\u00c7a\u011f\u0131n Ararat",
                "Jin Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13110v1",
                "http://arxiv.org/pdf/2308.13110v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60H05, 60G44, 28B20, 47H04"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13087v1",
            "title": "Applications of tree decompositions and accessibility to treeability of\n  Borel graphs",
            "updated": "2023-08-24T21:12:31Z",
            "published": "2023-08-24T21:12:31Z",
            "summary": "A framework to handle tree decompositions of the components of a Borel graph\nin a Borel fashion is introduced, along the lines of Tserunyan's Stallings\nTheorem for equivalence relations arXiv:1805.09506. This setting leads to a\nnotion of accessibility for Borel graphs, together with a treeability\ncriterion. This criterion is applied to show that, in particular, Borel\nequivalence relations associated to Borel graphs with accessible planar\nconnected components are measure treeable, generalising results of Conley,\nGaboriau, Marks, and Tucker-Drob arXiv:2104.07431 and Timar arXiv:1910.01307.\nIt is also proven that uniformly locally finite Borel graphs with components of\nfinite tree-width yield Borel treeable equivalence relations. Our results imply\nthat p.m.p countable Borel equivalence relations with measured property (T) do\nnot admit locally finite graphings with planar components a.s.",
            "author": [
                "H\u00e9ctor Jard\u00f3n-S\u00e1nchez"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13087v1",
                "http://arxiv.org/pdf/2308.13087v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "math.DS",
                "37A20 (Primary) 03E15, 05C10, 05C83 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13073v1",
            "title": "SurGNN: Explainable visual scene understanding and assessment of\n  surgical skill using graph neural networks",
            "updated": "2023-08-24T20:32:57Z",
            "published": "2023-08-24T20:32:57Z",
            "summary": "This paper explores how graph neural networks (GNNs) can be used to enhance\nvisual scene understanding and surgical skill assessment. By using GNNs to\nanalyze the complex visual data of surgical procedures represented as graph\nstructures, relevant features can be extracted and surgical skill can be\npredicted. Additionally, GNNs provide interpretable results, revealing the\nspecific actions, instruments, or anatomical structures that contribute to the\npredicted skill metrics. This can be highly beneficial for surgical educators\nand trainees, as it provides valuable insights into the factors that contribute\nto successful surgical performance and outcomes. SurGNN proposes two concurrent\napproaches -- one supervised and the other self-supervised. The paper also\nbriefly discusses other automated surgical skill evaluation techniques and\nhighlights the limitations of hand-crafted features in capturing the\nintricacies of surgical expertise. We use the proposed methods to achieve\nstate-of-the-art results on EndoVis19, and custom datasets. The working\nimplementation of the code can be found at https://github.com/<redacted>.",
            "author": [
                "Shuja Khalid",
                "Frank Rudzicz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13073v1",
                "http://arxiv.org/pdf/2308.13073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13067v1",
            "title": "Causal Parrots: Large Language Models May Talk Causality But Are Not\n  Causal",
            "updated": "2023-08-24T20:23:13Z",
            "published": "2023-08-24T20:23:13Z",
            "summary": "Some argue scale is all what is needed to achieve AI, covering even causal\nmodels. We make it clear that large language models (LLMs) cannot be causal and\ngive reason onto why sometimes we might feel otherwise. To this end, we define\nand exemplify a new subgroup of Structural Causal Model (SCM) that we call meta\nSCM which encode causal facts about other SCM within their variables. We\nconjecture that in the cases where LLM succeed in doing causal inference,\nunderlying was a respective meta SCM that exposed correlations between causal\nfacts in natural language on whose data the LLM was ultimately trained. If our\nhypothesis holds true, then this would imply that LLMs are like parrots in that\nthey simply recite the causal knowledge embedded in the data. Our empirical\nanalysis provides favoring evidence that current LLMs are even weak `causal\nparrots.'",
            "author": [
                "Matej Ze\u010devi\u0107",
                "Moritz Willig",
                "Devendra Singh Dhami",
                "Kristian Kersting"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13067v1",
                "http://arxiv.org/pdf/2308.13067v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13054v2",
            "title": "Are there graphs whose shortest path structure requires large edge\n  weights?",
            "updated": "2023-11-30T02:33:57Z",
            "published": "2023-08-24T19:41:54Z",
            "summary": "The aspect ratio of a (positively) weighted graph $G$ is the ratio of its\nmaximum edge weight to its minimum edge weight. Aspect ratio commonly arises as\na complexity measure in graph algorithms, especially related to the computation\nof shortest paths. Popular paradigms are to interpolate between the settings of\nweighted and unweighted input graphs by incurring a dependence on aspect ratio,\nor by simply restricting attention to input graphs of low aspect ratio.\n  This paper studies the effects of these paradigms, investigating whether\ngraphs of low aspect ratio have more structured shortest paths than graphs in\ngeneral. In particular, we raise the question of whether one can generally take\na graph of large aspect ratio and reweight its edges, to obtain a graph with\nbounded aspect ratio while preserving the structure of its shortest paths. Our\nfindings are:\n  - Every weighted DAG on $n$ nodes has a shortest-paths preserving graph of\naspect ratio $O(n)$. A simple lower bound shows that this is tight.\n  - The previous result does not extend to general directed or undirected\ngraphs; in fact, the answer turns out to be exponential in these settings. In\nparticular, we construct directed and undirected $n$-node graphs for which any\nshortest-paths preserving graph has aspect ratio $2^{\\Omega(n)}$.\n  We also consider the approximate version of this problem, where the goal is\nfor shortest paths in $H$ to correspond to approximate shortest paths in $G$.\nWe show that our exponential lower bounds extend even to this setting. We also\nshow that in a closely related model, where approximate shortest paths in $H$\nmust also correspond to approximate shortest paths in $G$, even DAGs require\nexponential aspect ratio.",
            "author": [
                "Aaron Bernstein",
                "Greg Bodwin",
                "Nicole Wein"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13054v2",
                "http://arxiv.org/pdf/2308.13054v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13038v1",
            "title": "The role of PHF5A in cancer: A review and update",
            "updated": "2023-08-24T19:05:37Z",
            "published": "2023-08-24T19:05:37Z",
            "summary": "PHF5A is a member of the zinc-finger proteins. To advance knowledge on their\nrole in carcinogenesis, data from experimental studies, animal models and\nclinical studies in different tumorigenesis have been reviewed. Furthermore,\nPHF5A as an oncogenic function, is frequently expressed in tumor cells and a\npotential prognostic marker for different cancers. PHF5A is implicated in the\nregulation of cancer cell proliferation, invasion, migration and metastasis.\nKnockdown of PHF5A prevented the invasion and metastasis of tumor cells. Here,\nthe role of PHF5A in different cancers and their possible mechanism in relation\nto recent literature is reviewed and discussed. However, there is an open\npromising perspective to their therapeutic management for different cancer\ntypes.",
            "author": [
                "Patrick Diaba-Nuhoho"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.biopha.2023.115857",
                "http://arxiv.org/abs/2308.13038v1",
                "http://arxiv.org/pdf/2308.13038v1"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO",
                "q-bio.CB",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13035v1",
            "title": "The intersection of video capsule endoscopy and artificial intelligence:\n  addressing unique challenges using machine learning",
            "updated": "2023-08-24T19:00:26Z",
            "published": "2023-08-24T19:00:26Z",
            "summary": "Introduction: Technical burdens and time-intensive review processes limit the\npractical utility of video capsule endoscopy (VCE). Artificial intelligence\n(AI) is poised to address these limitations, but the intersection of AI and VCE\nreveals challenges that must first be overcome. We identified five challenges\nto address. Challenge #1: VCE data are stochastic and contains significant\nartifact. Challenge #2: VCE interpretation is cost-intensive. Challenge #3: VCE\ndata are inherently imbalanced. Challenge #4: Existing VCE AIMLT are\ncomputationally cumbersome. Challenge #5: Clinicians are hesitant to accept\nAIMLT that cannot explain their process.\n  Methods: An anatomic landmark detection model was used to test the\napplication of convolutional neural networks (CNNs) to the task of classifying\nVCE data. We also created a tool that assists in expert annotation of VCE data.\nWe then created more elaborate models using different approaches including a\nmulti-frame approach, a CNN based on graph representation, and a few-shot\napproach based on meta-learning.\n  Results: When used on full-length VCE footage, CNNs accurately identified\nanatomic landmarks (99.1%), with gradient weighted-class activation mapping\nshowing the parts of each frame that the CNN used to make its decision. The\ngraph CNN with weakly supervised learning (accuracy 89.9%, sensitivity of\n91.1%), the few-shot model (accuracy 90.8%, precision 91.4%, sensitivity\n90.9%), and the multi-frame model (accuracy 97.5%, precision 91.5%, sensitivity\n94.8%) performed well. Discussion: Each of these five challenges is addressed,\nin part, by one of our AI-based models. Our goal of producing high performance\nusing lightweight models that aim to improve clinician confidence was achieved.",
            "author": [
                "Shan Guleria",
                "Benjamin Schwartz",
                "Yash Sharma",
                "Philip Fernandes",
                "James Jablonski",
                "Sodiq Adewole",
                "Sanjana Srivastava",
                "Fisher Rhoads",
                "Michael Porter",
                "Michelle Yeghyayan",
                "Dylan Hyatt",
                "Andrew Copland",
                "Lubaina Ehsan",
                "Donald Brown",
                "Sana Syed"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13035v1",
                "http://arxiv.org/pdf/2308.13035v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13010v2",
            "title": "Tree-like graphings, wallings, and median graphings of equivalence\n  relations",
            "updated": "2023-09-26T15:52:26Z",
            "published": "2023-08-24T18:23:51Z",
            "summary": "We prove several results showing that every locally finite Borel graph whose\nlarge-scale geometry is \"tree-like\" induces a treeable equivalence relation. In\nparticular, our hypotheses hold if each component of the original graph either\nhas bounded tree-width or is quasi-isometric to a tree, answering a question of\nTucker-Drob. In the latter case, we moreover show that there exists a Borel\nquasi-isometry to a Borel forest, under the additional assumption of\n(componentwise) bounded degree. We also extend these results on quasi-treeings\nto Borel proper metric spaces. In fact, our most general result shows\ntreeability of countable Borel equivalence relations equipped with an abstract\nwallspace structure on each class obeying some local finiteness conditions,\nwhich we call a proper walling. The proof is based on the Stone duality between\nproper wallings and median graphs, i.e., CAT(0) cube complexes. Finally, we\nstrengthen the conclusion of treeability in these results to hyperfiniteness in\nthe case where the original graph has one (selected) end per component,\ngeneralizing the same result for trees due to Dougherty--Jackson--Kechris.",
            "author": [
                "Ruiyuan Chen",
                "Antoine Poulin",
                "Ran Tao",
                "Anush Tserunyan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13010v2",
                "http://arxiv.org/pdf/2308.13010v2"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "math.CO",
                "math.DS",
                "math.GR",
                "03E15, 20F65, 20E08, 37A20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12956v1",
            "title": "DLIP: Distilling Language-Image Pre-training",
            "updated": "2023-08-24T17:50:21Z",
            "published": "2023-08-24T17:50:21Z",
            "summary": "Vision-Language Pre-training (VLP) shows remarkable progress with the\nassistance of extremely heavy parameters, which challenges deployment in real\napplications. Knowledge distillation is well recognized as the essential\nprocedure in model compression. However, existing knowledge distillation\ntechniques lack an in-depth investigation and analysis of VLP, and practical\nguidelines for VLP-oriented distillation are still not yet explored. In this\npaper, we present DLIP, a simple yet efficient Distilling Language-Image\nPre-training framework, through which we investigate how to distill a light VLP\nmodel. Specifically, we dissect the model distillation from multiple\ndimensions, such as the architecture characteristics of different modules and\nthe information transfer of different modalities. We conduct comprehensive\nexperiments and provide insights on distilling a light but performant VLP\nmodel. Experimental results reveal that DLIP can achieve a state-of-the-art\naccuracy/efficiency trade-off across diverse cross-modal tasks, e.g.,\nimage-text retrieval, image captioning and visual question answering. For\nexample, DLIP compresses BLIP by 1.9x, from 213M to 108M parameters, while\nachieving comparable or better performance. Furthermore, DLIP succeeds in\nretaining more than 95% of the performance with 22.4% parameters and 24.8%\nFLOPs compared to the teacher model and accelerates inference speed by 2.7x.",
            "author": [
                "Huafeng Kuang",
                "Jie Wu",
                "Xiawu Zheng",
                "Ming Li",
                "Xuefeng Xiao",
                "Rui Wang",
                "Min Zheng",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12956v1",
                "http://arxiv.org/pdf/2308.12956v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12919v1",
            "title": "Towards Realistic Unsupervised Fine-tuning with CLIP",
            "updated": "2023-08-24T16:47:17Z",
            "published": "2023-08-24T16:47:17Z",
            "summary": "The emergence of vision-language models (VLMs), such as CLIP, has spurred a\nsignificant research effort towards their application for downstream supervised\nlearning tasks. Although some previous studies have explored the unsupervised\nfine-tuning of CLIP, they often rely on prior knowledge in the form of class\nnames associated with ground truth labels. In this paper, we delve into a\nrealistic unsupervised fine-tuning scenario by assuming that the unlabeled data\nmight contain out-of-distribution samples from unknown classes. Furthermore, we\nemphasize the importance of simultaneously enhancing out-of-distribution\ndetection capabilities alongside the recognition of instances associated with\npredefined class labels.\n  To tackle this problem, we present a simple, efficient, and effective\nfine-tuning approach called Universal Entropy Optimization (UEO). UEO leverages\nsample-level confidence to approximately minimize the conditional entropy of\nconfident instances and maximize the marginal entropy of less confident\ninstances. Apart from optimizing the textual prompts, UEO also incorporates\noptimization of channel-wise affine transformations within the visual branch of\nCLIP. Through extensive experiments conducted across 15 domains and 4 different\ntypes of prior knowledge, we demonstrate that UEO surpasses baseline methods in\nterms of both generalization and out-of-distribution detection.",
            "author": [
                "Jian Liang",
                "Lijun Sheng",
                "Zhengbo Wang",
                "Ran He",
                "Tieniu Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12919v1",
                "http://arxiv.org/pdf/2308.12919v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12910v1",
            "title": "SCoRD: Subject-Conditional Relation Detection with Text-Augmented Data",
            "updated": "2023-08-24T16:35:35Z",
            "published": "2023-08-24T16:35:35Z",
            "summary": "We propose Subject-Conditional Relation Detection SCoRD, where conditioned on\nan input subject, the goal is to predict all its relations to other objects in\na scene along with their locations. Based on the Open Images dataset, we\npropose a challenging OIv6-SCoRD benchmark such that the training and testing\nsplits have a distribution shift in terms of the occurrence statistics of\n$\\langle$subject, relation, object$\\rangle$ triplets. To solve this problem, we\npropose an auto-regressive model that given a subject, it predicts its\nrelations, objects, and object locations by casting this output as a sequence\nof tokens. First, we show that previous scene-graph prediction methods fail to\nproduce as exhaustive an enumeration of relation-object pairs when conditioned\non a subject on this benchmark. Particularly, we obtain a recall@3 of 83.8% for\nour relation-object predictions compared to the 49.75% obtained by a recent\nscene graph detector. Then, we show improved generalization on both\nrelation-object and object-box predictions by leveraging during training\nrelation-object pairs obtained automatically from textual captions and for\nwhich no object-box annotations are available. Particularly, for\n$\\langle$subject, relation, object$\\rangle$ triplets for which no object\nlocations are available during training, we are able to obtain a recall@3 of\n42.59% for relation-object pairs and 32.27% for their box locations.",
            "author": [
                "Ziyan Yang",
                "Kushal Kafle",
                "Zhe Lin",
                "Scott Cohen",
                "Zhihong Ding",
                "Vicente Ordonez"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12910v1",
                "http://arxiv.org/pdf/2308.12910v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12898v2",
            "title": "Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language\n  Pretraining?",
            "updated": "2023-08-25T12:22:53Z",
            "published": "2023-08-24T16:17:40Z",
            "summary": "The multimedia community has shown a significant interest in perceiving and\nrepresenting the physical world with multimodal pretrained neural network\nmodels, and among them, the visual-language pertaining (VLP) is, currently, the\nmost captivating topic. However, there have been few endeavors dedicated to the\nexploration of 1) whether essential linguistic knowledge (e.g., semantics and\nsyntax) can be extracted during VLP, and 2) how such linguistic knowledge\nimpact or enhance the multimodal alignment. In response, here we aim to\nelucidate the impact of comprehensive linguistic knowledge, including semantic\nexpression and syntactic structure, on multimodal alignment. Specifically, we\ndesign and release the SNARE, the first large-scale multimodal alignment\nprobing benchmark, to detect the vital linguistic components, e.g., lexical,\nsemantic, and syntax knowledge, containing four tasks: Semantic structure,\nNegation logic, Attribute ownership, and Relationship composition. Based on our\nproposed probing benchmarks, our holistic analyses of five advanced VLP models\nillustrate that the VLP model: i) shows insensitivity towards complex syntax\nstructures and relies on content words for sentence comprehension; ii)\ndemonstrates limited comprehension of combinations between sentences and\nnegations; iii) faces challenges in determining the presence of actions or\nspatial relationships within visual information and struggles with verifying\nthe correctness of triple combinations. We make our benchmark and code\navailable at \\url{https://github.com/WangFei-2019/SNARE/}.",
            "author": [
                "Fei Wang",
                "Liang Ding",
                "Jun Rao",
                "Ye Liu",
                "Li Shen",
                "Changxing Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12898v2",
                "http://arxiv.org/pdf/2308.12898v2"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13558v1",
            "title": "Federated Learning for Computer Vision",
            "updated": "2023-08-24T16:05:14Z",
            "published": "2023-08-24T16:05:14Z",
            "summary": "Computer Vision (CV) is playing a significant role in transforming society by\nutilizing machine learning (ML) tools for a wide range of tasks. However, the\nneed for large-scale datasets to train ML models creates challenges for\ncentralized ML algorithms. The massive computation loads required for\nprocessing and the potential privacy risks associated with storing and\nprocessing data on central cloud servers put these algorithms under severe\nstrain. To address these issues, federated learning (FL) has emerged as a\npromising solution, allowing privacy preservation by training models locally\nand exchanging them to improve overall performance. Additionally, the\ncomputational load is distributed across multiple clients, reducing the burden\non central servers. This paper presents, to the best of the authors' knowledge,\nthe first review discussing recent advancements of FL in CV applications,\ncomparing them to conventional centralized training paradigms. It provides an\noverview of current FL applications in various CV tasks, emphasizing the\nadvantages of FL and the challenges of implementing it in CV. To facilitate\nthis, the paper proposes a taxonomy of FL techniques in CV, outlining their\napplications and security threats. It also discusses privacy concerns related\nto implementing blockchain in FL schemes for CV tasks and summarizes existing\nprivacy preservation methods. Moving on, the paper identifies open research\nchallenges and potential future research directions to further exploit the\npotential of FL and blockchain in CV applications.",
            "author": [
                "Yassine Himeur",
                "Iraklis Varlamis",
                "Hamza Kheddar",
                "Abbes Amira",
                "Shadi Atalla",
                "Yashbir Singh",
                "Faycal Bensaali",
                "Wathiq Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13558v1",
                "http://arxiv.org/pdf/2308.13558v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12853v1",
            "title": "On self-duality and unigraphicity for $3$-polytopes",
            "updated": "2023-08-24T15:19:10Z",
            "published": "2023-08-24T15:19:10Z",
            "summary": "Recent literature posed the problem of characterising the graph degree\nsequences with exactly one $3$-polytopal (i.e. planar, $3$-connected)\nrealisation. This seems to be a difficult problem in full generality. In this\npaper, we characterise the sequences with exactly one self-dual $3$-polytopal\nrealisation.\n  An algorithm in the literature constructs a self-dual $3$-polytope for any\nadmissible degree sequence. To do so, it performs operations on the radial\ngraph, so that the corresponding $3$-polytope and its dual are modified in\nexactly the same way. To settle our question and construct the relevant graphs,\nwe apply this algorithm, we introduce some modifications of it, and we also\ndevise new ones. The speed of these algorithms is linear in the graph order.",
            "author": [
                "Riccardo W. Maffucci"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12853v1",
                "http://arxiv.org/pdf/2308.12853v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C85, 05C07, 05C76, 05C62, 05C10, 52B05, 52B10, 52C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12842v1",
            "title": "Text Similarity from Image Contents using Statistical and Semantic\n  Analysis Techniques",
            "updated": "2023-08-24T15:06:04Z",
            "published": "2023-08-24T15:06:04Z",
            "summary": "Plagiarism detection is one of the most researched areas among the Natural\nLanguage Processing(NLP) community. A good plagiarism detection covers all the\nNLP methods including semantics, named entities, paraphrases etc. and produces\ndetailed plagiarism reports. Detection of Cross Lingual Plagiarism requires\ndeep knowledge of various advanced methods and algorithms to perform effective\ntext similarity checking. Nowadays the plagiarists are also advancing\nthemselves from hiding the identity from being catch in such offense. The\nplagiarists are bypassed from being detected with techniques like paraphrasing,\nsynonym replacement, mismatching citations, translating one language to\nanother. Image Content Plagiarism Detection (ICPD) has gained importance,\nutilizing advanced image content processing to identify instances of plagiarism\nto ensure the integrity of image content. The issue of plagiarism extends\nbeyond textual content, as images such as figures, graphs, and tables also have\nthe potential to be plagiarized. However, image content plagiarism detection\nremains an unaddressed challenge. Therefore, there is a critical need to\ndevelop methods and systems for detecting plagiarism in image content. In this\npaper, the system has been implemented to detect plagiarism form contents of\nImages such as Figures, Graphs, Tables etc. Along with statistical algorithms\nsuch as Jaccard and Cosine, introducing semantic algorithms such as LSA, BERT,\nWordNet outperformed in detecting efficient and accurate plagiarism.",
            "author": [
                "Sagar Kulkarni",
                "Sharvari Govilkar",
                "Dhiraj Amin"
            ],
            "link": [
                "http://dx.doi.org/10.5121/csit.2023.131405",
                "http://arxiv.org/abs/2308.12842v1",
                "http://arxiv.org/pdf/2308.12842v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.05938v1",
            "title": "Component attention network for multimodal dance improvisation\n  recognition",
            "updated": "2023-08-24T15:04:30Z",
            "published": "2023-08-24T15:04:30Z",
            "summary": "Dance improvisation is an active research topic in the arts. Motion analysis\nof improvised dance can be challenging due to its unique dynamics. Data-driven\ndance motion analysis, including recognition and generation, is often limited\nto skeletal data. However, data of other modalities, such as audio, can be\nrecorded and benefit downstream tasks. This paper explores the application and\nperformance of multimodal fusion methods for human motion recognition in the\ncontext of dance improvisation. We propose an attention-based model, component\nattention network (CANet), for multimodal fusion on three levels: 1) feature\nfusion with CANet, 2) model fusion with CANet and graph convolutional network\n(GCN), and 3) late fusion with a voting strategy. We conduct thorough\nexperiments to analyze the impact of each modality in different fusion methods\nand distinguish critical temporal or component features. We show that our\nproposed model outperforms the two baseline methods, demonstrating its\npotential for analyzing improvisation in dance.",
            "author": [
                "Jia Fu",
                "Jiarui Tan",
                "Wenjie Yin",
                "Sepideh Pashami",
                "M\u00e5rten Bj\u00f6rkman"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3577190.3614114",
                "http://arxiv.org/abs/2310.05938v1",
                "http://arxiv.org/pdf/2310.05938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.SD",
                "eess.AS",
                "I.2; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13557v1",
            "title": "Magnetic fluctuations in Pb$_9$Cu(PO$_4$)$_6$O",
            "updated": "2023-08-24T14:42:12Z",
            "published": "2023-08-24T14:42:12Z",
            "summary": "The hope that copper doped lead apatite Pb$_9$Cu(PO$_4$)$_6$O is a\nroom-temperature superconductor has largely been dashed by global research\nefforts. Nevertheless, according to the current state of knowledge, the\nmaterial has interesting magnetic properties, and research groups around the\nworld have prepared high quality samples. We use a fluctuation exchange\napproximation (FLEX) approach to study the magnetic tendencies in\nPb$_9$Cu(PO$_4$)$_6$O. We find ferromagnetic fluctuations very close to the\nfilling of the stoichiometric compound which can be understood from Fermi\nsurface nesting at the M point. This is similar to the one-band triangular\nlattice Hamiltonian at three-quarter filling. Interestingly, the special kz\ndependence of the Pb$_9$Cu(PO$_4$)$_6$O band structure makes it very sensitive\nto doping. Only slight charge doping switches between antiferromagnetic and\nferromagnetic fluctuations. If the material could become superconducting, it\nmight be easily switchable between singlet and triplet superconductivity.",
            "author": [
                "Makoto Shimizu",
                "Junya Otsuki",
                "Harald O. Jeschke"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13557v1",
                "http://arxiv.org/pdf/2308.13557v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12828v1",
            "title": "Short Run Transit Route Planning Decision Support System Using a Deep\n  Learning-Based Weighted Graph",
            "updated": "2023-08-24T14:37:55Z",
            "published": "2023-08-24T14:37:55Z",
            "summary": "Public transport routing plays a crucial role in transit network design,\nensuring a satisfactory level of service for passengers. However, current\nrouting solutions rely on traditional operational research heuristics, which\ncan be time-consuming to implement and lack the ability to provide quick\nsolutions. Here, we propose a novel deep learning-based methodology for a\ndecision support system that enables public transport (PT) planners to identify\nshort-term route improvements rapidly. By seamlessly adjusting specific\nsections of routes between two stops during specific times of the day, our\nmethod effectively reduces times and enhances PT services. Leveraging diverse\ndata sources such as GTFS and smart card data, we extract features and model\nthe transportation network as a directed graph. Using self-supervision, we\ntrain a deep learning model for predicting lateness values for road segments.\n  These lateness values are then utilized as edge weights in the transportation\ngraph, enabling efficient path searching. Through evaluating the method on Tel\nAviv, we are able to reduce times on more than 9\\% of the routes. The improved\nroutes included both intraurban and suburban routes showcasing a fact\nhighlighting the model's versatility. The findings emphasize the potential of\nour data-driven decision support system to enhance public transport and city\nlogistics, promoting greater efficiency and reliability in PT services.",
            "author": [
                "Nadav Shalit",
                "Michael Fire",
                "Dima Kagan",
                "Eran Ben-Elia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12828v1",
                "http://arxiv.org/pdf/2308.12828v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12825v1",
            "title": "Requirements Quality Assurance in Industry: Why, What and How?",
            "updated": "2023-08-24T14:31:52Z",
            "published": "2023-08-24T14:31:52Z",
            "summary": "Context and Motivation: Natural language is the most common form to specify\nrequirements in industry. The quality of the specification depends on the\ncapability of the writer to formulate requirements aimed at different\nstakeholders: they are an expression of the customer's needs that are used by\nanalysts, designers and testers. Given this central role of requirements as a\nmean to communicate intention, assuring their quality is essential to reduce\nmisunderstandings that lead to potential waste. Problem: Quality assurance of\nrequirement specifications is largely a manual effort that requires expertise\nand domain knowledge. However, this demanding cognitive process is also\ncongested by trivial quality issues that should not occur in the first place.\nPrincipal ideas: We propose a taxonomy of requirements quality assurance\ncomplexity that characterizes cognitive load of verifying a quality aspect from\nthe human perspective, and automation complexity and accuracy from the machine\nperspective. Contribution: Once this taxonomy is realized and validated, it can\nserve as the basis for a decision framework of automated requirements quality\nassurance support.",
            "author": [
                "Michael Unterkalmsteiner",
                "Tony Gorschek"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-319-54045-0_6",
                "http://arxiv.org/abs/2308.12825v1",
                "http://arxiv.org/pdf/2308.12825v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12808v1",
            "title": "Decreasing the mean subtree order by adding $k$ edges",
            "updated": "2023-08-24T14:10:32Z",
            "published": "2023-08-24T14:10:32Z",
            "summary": "The mean subtree order of a given graph $G$, denoted $\\mu(G)$, is the average\nnumber of vertices in a subtree of $G$. Let $G$ be a connected graph. Chin,\nGordon, MacPhee, and Vincent [J. Graph Theory, 89(4): 413-438, 2018]\nconjectured that if $H$ is a proper spanning supergraph of $G$, then $\\mu(H) >\n\\mu(G)$. Cameron and Mol [J. Graph Theory, 96(3): 403-413, 2021] disproved this\nconjecture by showing that there are infinitely many pairs of graphs $H$ and\n$G$ with $H\\supset G$, $V(H)=V(G)$ and $|E(H)|= |E(G)|+1$ such that $\\mu(H) <\n\\mu(G)$. They also conjectured that for every positive integer $k$, there\nexists a pair of graphs $G$ and $H$ with $H\\supset G$, $V(H)=V(G)$ and $|E(H)|\n= |E(G)| +k$ such that $\\mu(H) < \\mu(G)$. Furthermore, they proposed that\n$\\mu(K_m+nK_1) < \\mu(K_{m, n})$ provided $n\\gg m$. In this note, we confirm\nthese two conjectures.",
            "author": [
                "Stijn Cambie",
                "Guantao Chen",
                "Yanli Hao",
                "Nizamettin Tokar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12808v1",
                "http://arxiv.org/pdf/2308.12808v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C05, 05C35, 05C40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12787v1",
            "title": "On a question of Matt Baker regarding the dollar game",
            "updated": "2023-08-24T13:41:17Z",
            "published": "2023-08-24T13:41:17Z",
            "summary": "In an introductory paper on dollar game played on a graph, Matt Baker wrote\nthe following: ``The total number of borrowing moves required to win the game\nwhen playing the 'borrowing binge strategy' is independent of which borrowing\nmoves you do in which order! Note, however, that it is usually possible to win\nin fewer moves by employing lending moves in combination with borrowing moves.\nThe optimal strategy when one uses both kinds of moves is not yet understood.''\n  In this article, we give a lower bound on the minimum number $ M_{\\text{min}}\n$ of such moves of an optimal algorithm in terms of the number of moves $ M_0 $\nof the borrowing binge strategy. Concretely, we have: $ M_{\\text{min}} \\geq\n\\frac{M_0}{n-1} $ where $ n $ is the number of vertices of the graph. This\nbound is tight.",
            "author": [
                "Marine Cases-Thomas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12787v1",
                "http://arxiv.org/pdf/2308.12787v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C57"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12777v1",
            "title": "Towards Communication-Efficient Model Updating for On-Device\n  Session-Based Recommendation",
            "updated": "2023-08-24T13:27:58Z",
            "published": "2023-08-24T13:27:58Z",
            "summary": "On-device recommender systems recently have garnered increasing attention due\nto their advantages of providing prompt response and securing privacy. To stay\ncurrent with evolving user interests, cloud-based recommender systems are\nperiodically updated with new interaction data. However, on-device models\nstruggle to retrain themselves because of limited onboard computing resources.\nAs a solution, we consider the scenario where the model retraining occurs on\nthe server side and then the updated parameters are transferred to edge devices\nvia network communication. While this eliminates the need for local retraining,\nit incurs a regular transfer of parameters that significantly taxes network\nbandwidth. To mitigate this issue, we develop an efficient approach based on\ncompositional codes to compress the model update. This approach ensures the\non-device model is updated flexibly with minimal additional parameters whilst\nutilizing previous knowledge. The extensive experiments conducted on multiple\nsession-based recommendation models with distinctive architectures demonstrate\nthat the on-device model can achieve comparable accuracy to the retrained\nserver-side counterpart through transferring an update 60x smaller in size. The\ncodes are available at \\url{https://github.com/xiaxin1998/ODUpdate}.",
            "author": [
                "Xin Xia",
                "Junliang Yu",
                "Guandong Xu",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12777v1",
                "http://arxiv.org/pdf/2308.12777v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12775v2",
            "title": "A Distributed Linear Quadratic Discrete-Time Game Approach to Formation\n  Control with Collision Avoidance",
            "updated": "2023-09-05T08:51:17Z",
            "published": "2023-08-24T13:27:07Z",
            "summary": "Formation control problems can be expressed as linear quadratic discrete-time\ngames (LQDTG) for which Nash equilibrium solutions are sought. However, solving\nsuch problems requires solving coupled Riccati equations, which cannot be done\nin a distributed manner. A recent study showed that a distributed\nimplementation is possible for a consensus problem when fictitious agents are\nassociated with edges in the network graph rather than nodes. This paper\nproposes an extension of this approach to formation control with collision\navoidance, where collision is precluded by including appropriate penalty terms\non the edges. To address the problem, a state-dependent Riccati equation needs\nto be solved since the collision avoidance term in the cost function leads to a\nstate-dependent weight matrix. This solution provides relative control inputs\nassociated with the edges of the network graph. These relative inputs then need\nto be mapped to the physical control inputs applied at the nodes; this can be\ndone in a distributed manner by iterating over a gradient descent search\nbetween neighbors in each sampling interval. Unlike inter-sample iteration\nfrequently used in distributed MPC, only a matrix-vector multiplication is\nneeded for each iteration step here, instead of an optimization problem to be\nsolved. This approach can be implemented in a receding horizon manner, this is\ndemonstrated through a numerical example.",
            "author": [
                "Prima Aditya",
                "Herbert Werner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12775v2",
                "http://arxiv.org/pdf/2308.12775v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12774v1",
            "title": "LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition",
            "updated": "2023-08-24T13:26:18Z",
            "published": "2023-08-24T13:26:18Z",
            "summary": "The diversity in length constitutes a significant characteristic of text. Due\nto the long-tail distribution of text lengths, most existing methods for scene\ntext recognition (STR) only work well on short or seen-length text, lacking the\ncapability of recognizing longer text or performing length extrapolation. This\nis a crucial issue, since the lengths of the text to be recognized are usually\nnot given in advance in real-world applications, but it has not been adequately\ninvestigated in previous works. Therefore, we propose in this paper a method\ncalled Length-Insensitive Scene TExt Recognizer (LISTER), which remedies the\nlimitation regarding the robustness to various text lengths. Specifically, a\nNeighbor Decoder is proposed to obtain accurate character attention maps with\nthe assistance of a novel neighbor matrix regardless of the text lengths.\nBesides, a Feature Enhancement Module is devised to model the long-range\ndependency with low computation cost, which is able to perform iterations with\nthe neighbor decoder to enhance the feature map progressively. To the best of\nour knowledge, we are the first to achieve effective length-insensitive scene\ntext recognition. Extensive experiments demonstrate that the proposed LISTER\nalgorithm exhibits obvious superiority on long text recognition and the ability\nfor length extrapolation, while comparing favourably with the previous\nstate-of-the-art methods on standard benchmarks for STR (mainly short text).",
            "author": [
                "Changxu Cheng",
                "Peng Wang",
                "Cheng Da",
                "Qi Zheng",
                "Cong Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12774v1",
                "http://arxiv.org/pdf/2308.12774v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12773v1",
            "title": "Pre-training Code Representation with Semantic Flow Graph for Effective\n  Bug Localization",
            "updated": "2023-08-24T13:25:17Z",
            "published": "2023-08-24T13:25:17Z",
            "summary": "Enlightened by the big success of pre-training in natural language\nprocessing, pre-trained models for programming languages have been widely used\nto promote code intelligence in recent years. In particular, BERT has been used\nfor bug localization tasks and impressive results have been obtained. However,\nthese BERT-based bug localization techniques suffer from two issues. First, the\npre-trained BERT model on source code does not adequately capture the deep\nsemantics of program code. Second, the overall bug localization models neglect\nthe necessity of large-scale negative samples in contrastive learning for\nrepresentations of changesets and ignore the lexical similarity between bug\nreports and changesets during similarity estimation. We address these two\nissues by 1) proposing a novel directed, multiple-label code graph\nrepresentation named Semantic Flow Graph (SFG), which compactly and adequately\ncaptures code semantics, 2) designing and training SemanticCodeBERT based on\nSFG, and 3) designing a novel Hierarchical Momentum Contrastive Bug\nLocalization technique (HMCBL). Evaluation results show that our method\nachieves state-of-the-art performance in bug localization.",
            "author": [
                "Yali Du",
                "Zhongxing Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12773v1",
                "http://arxiv.org/pdf/2308.12773v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12762v1",
            "title": "Reinforcement Learning Informed Evolutionary Search for Autonomous\n  Systems Testing",
            "updated": "2023-08-24T13:11:07Z",
            "published": "2023-08-24T13:11:07Z",
            "summary": "Evolutionary search-based techniques are commonly used for testing autonomous\nrobotic systems. However, these approaches often rely on computationally\nexpensive simulator-based models for test scenario evaluation. To improve the\ncomputational efficiency of the search-based testing, we propose augmenting the\nevolutionary search (ES) with a reinforcement learning (RL) agent trained using\nsurrogate rewards derived from domain knowledge. In our approach, known as\nRIGAA (Reinforcement learning Informed Genetic Algorithm for Autonomous systems\ntesting), we first train an RL agent to learn useful constraints of the problem\nand then use it to produce a certain part of the initial population of the\nsearch algorithm. By incorporating an RL agent into the search process, we aim\nto guide the algorithm towards promising regions of the search space from the\nstart, enabling more efficient exploration of the solution space. We evaluate\nRIGAA on two case studies: maze generation for an autonomous ant robot and road\ntopology generation for an autonomous vehicle lane keeping assist system. In\nboth case studies, RIGAA converges faster to fitter solutions and produces a\nbetter test suite (in terms of average test scenario fitness and diversity).\nRIGAA also outperforms the state-of-the-art tools for vehicle lane keeping\nassist system testing, such as AmbieGen and Frenetic.",
            "author": [
                "Dmytro Humeniuk",
                "Foutse Khomh",
                "Giuliano Antoniol"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12762v1",
                "http://arxiv.org/pdf/2308.12762v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12755v1",
            "title": "Acquiring Qualitative Explainable Graphs for Automated Driving Scene\n  Interpretation",
            "updated": "2023-08-24T13:01:46Z",
            "published": "2023-08-24T13:01:46Z",
            "summary": "The future of automated driving (AD) is rooted in the development of robust,\nfair and explainable artificial intelligence methods. Upon request, automated\nvehicles must be able to explain their decisions to the driver and the car\npassengers, to the pedestrians and other vulnerable road users and potentially\nto external auditors in case of accidents. However, nowadays, most explainable\nmethods still rely on quantitative analysis of the AD scene representations\ncaptured by multiple sensors. This paper proposes a novel representation of AD\nscenes, called Qualitative eXplainable Graph (QXG), dedicated to qualitative\nspatiotemporal reasoning of long-term scenes. The construction of this graph\nexploits the recent Qualitative Constraint Acquisition paradigm. Our\nexperimental results on NuScenes, an open real-world multi-modal dataset, show\nthat the qualitative eXplainable graph of an AD scene composed of 40 frames can\nbe computed in real-time and light in space storage which makes it a\npotentially interesting tool for improved and more trustworthy perception and\ncontrol processes in AD.",
            "author": [
                "Nassim Belmecheri",
                "Arnaud Gotlieb",
                "Nadjib Lazaar",
                "Helge Spieker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12755v1",
                "http://arxiv.org/pdf/2308.12755v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12750v1",
            "title": "Theoretical designing of multiband Nickelate and Palladate\n  superconductors with $d^{8+\u03b4}$ configuration",
            "updated": "2023-08-24T12:54:27Z",
            "published": "2023-08-24T12:54:27Z",
            "summary": "In a previous study, we proposed a possibility of high $T_c$\nsuperconductivity in mixed-anion nickelates with $d^{8+\\delta}$ electron\nconfiguration. The theory was based on the fact that the two-orbital Hubbard\nmodel, when all the intra- and interorbital interactions have the same\nmagnitude, is equivalent to the bilayer Hubbard model, which has been suggested\nto exhibit high $T_c$ superconductivity. The energy level offset $\\Delta E$ in\nthe two-orbital model is transformed to twice the interlayer hopping in the\nbilayer model, and hence appropriately large $\\Delta E$ is favorable for\nsuperconductivity in the former. Extending this idea to multiorbital systems,\nwe previously suggested materials with large energy level offset between\n$d_{x^2-y^2}$ and other $d$ orbitals, such as Ca$_2$NiO$_2$Cl$_2$, to be good\ncandidates for high $T_c$ superconductivity, but such materials have not been\nsynthesized to our knowledge. In the present study, we first focus on\nSr$_2$NiO$_2$Cl$_2$, which has been synthesized in the past but has small\n$\\Delta E$, and study the effect of applying pressure, which enhances $\\Delta\nE$. We also study a 4d analogue of Sr$_2$NiO$_2$Cl$_2$, namely,\nSr$_2$PdO$_2$X$_2$ ($X=$ Cl, F, H) , in which $\\Delta E$ turns out to be large.\nThe analysis using fluctuation exchange approximation suggests possibility of\nsuperconductivity in these systems with large $\\Delta E$. We also study the\neffect of electron doping of these material, which is expected to enhance\nsuperconductivity, within the virtual crystal approximation.",
            "author": [
                "Naoya Kitamine",
                "Masayuki Ochi",
                "Kazuhiko Kuroki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12750v1",
                "http://arxiv.org/pdf/2308.12750v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12739v2",
            "title": "Practical limitations on robustness and scalability of quantum Internet",
            "updated": "2023-11-06T11:17:21Z",
            "published": "2023-08-24T12:32:48Z",
            "summary": "As quantum theory allows for information processing and computing tasks that\notherwise are not possible with classical systems, there is a need and use of\nquantum Internet beyond existing network systems. At the same time, the\nrealization of a desirably functional quantum Internet is hindered by\nfundamental and practical challenges such as high loss during transmission of\nquantum systems, decoherence due to interaction with the environment, fragility\nof quantum states, etc. We study the implications of these constraints by\nanalyzing the limitations on the scaling and robustness of quantum Internet.\nConsidering quantum networks, we present practical bottlenecks for secure\ncommunication, delegated computing, and resource distribution among end nodes.\nMotivated by the power of abstraction in graph theory (in association with\nquantum information theory), we consider graph-theoretic quantifiers to assess\nnetwork robustness and provide critical values of communication lines for\nviable communication over quantum Internet.\n  In particular, we begin by discussing limitations on usefulness of isotropic\nstates as device-independent quantum key repeaters which otherwise could be\nuseful for device-independent quantum key distribution. We consider some\nquantum networks of practical interest, ranging from satellite-based networks\nconnecting far-off spatial locations to currently available quantum processor\narchitectures within computers, and analyze their robustness to perform quantum\ninformation processing tasks. Some of these tasks form primitives for delegated\nquantum computing, e.g., entanglement distribution and quantum teleportation.\nFor some examples of quantum networks, we present algorithms to perform\ndifferent quantum network tasks of interest such as constructing the network\nstructure, finding the shortest path between a pair of end nodes, and\noptimizing the flow of resources at a node.",
            "author": [
                "Abhishek Sadhu",
                "Meghana Ayyala Somayajula",
                "Karol Horodecki",
                "Siddhartha Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12739v2",
                "http://arxiv.org/pdf/2308.12739v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.IT",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12738v1",
            "title": "Learning Heavily-Degraded Prior for Underwater Object Detection",
            "updated": "2023-08-24T12:32:46Z",
            "published": "2023-08-24T12:32:46Z",
            "summary": "Underwater object detection suffers from low detection performance because\nthe distance and wavelength dependent imaging process yield evident image\nquality degradations such as haze-like effects, low visibility, and color\ndistortions. Therefore, we commit to resolving the issue of underwater object\ndetection with compounded environmental degradations. Typical approaches\nattempt to develop sophisticated deep architecture to generate high-quality\nimages or features. However, these methods are only work for limited ranges\nbecause imaging factors are either unstable, too sensitive, or compounded.\nUnlike these approaches catering for high-quality images or features, this\npaper seeks transferable prior knowledge from detector-friendly images. The\nprior guides detectors removing degradations that interfere with detection. It\nis based on statistical observations that, the heavily degraded regions of\ndetector-friendly (DFUI) and underwater images have evident feature\ndistribution gaps while the lightly degraded regions of them overlap each\nother. Therefore, we propose a residual feature transference module (RFTM) to\nlearn a mapping between deep representations of the heavily degraded patches of\nDFUI- and underwater- images, and make the mapping as a heavily degraded prior\n(HDP) for underwater detection. Since the statistical properties are\nindependent to image content, HDP can be learned without the supervision of\nsemantic labels and plugged into popular CNNbased feature extraction networks\nto improve their performance on underwater object detection. Without bells and\nwhistles, evaluations on URPC2020 and UODD show that our methods outperform\nCNN-based detectors by a large margin. Our method with higher speeds and less\nparameters still performs better than transformer-based detectors. Our code and\nDFUI dataset can be found in\nhttps://github.com/xiaoDetection/Learning-Heavily-Degraed-Prior.",
            "author": [
                "Chenping Fu",
                "Xin Fan",
                "Jiewen Xiao",
                "Wanqi Yuan",
                "Risheng Liu",
                "Zhongxuan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12738v1",
                "http://arxiv.org/pdf/2308.12738v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12737v1",
            "title": "Asymmetric Co-Training with Explainable Cell Graph Ensembling for\n  Histopathological Image Classification",
            "updated": "2023-08-24T12:27:03Z",
            "published": "2023-08-24T12:27:03Z",
            "summary": "Convolutional neural networks excel in histopathological image\nclassification, yet their pixel-level focus hampers explainability. Conversely,\nemerging graph convolutional networks spotlight cell-level features and medical\nimplications. However, limited by their shallowness and suboptimal use of\nhigh-dimensional pixel data, GCNs underperform in multi-class histopathological\nimage classification. To make full use of pixel-level and cell-level features\ndynamically, we propose an asymmetric co-training framework combining a deep\ngraph convolutional network and a convolutional neural network for multi-class\nhistopathological image classification. To improve the explainability of the\nentire framework by embedding morphological and topological distribution of\ncells, we build a 14-layer deep graph convolutional network to handle cell\ngraph data. For the further utilization and dynamic interactions between\npixel-level and cell-level information, we also design a co-training strategy\nto integrate the two asymmetric branches. Notably, we collect a private\nclinically acquired dataset termed LUAD7C, including seven subtypes of lung\nadenocarcinoma, which is rare and more challenging. We evaluated our approach\non the private LUAD7C and public colorectal cancer datasets, showcasing its\nsuperior performance, explainability, and generalizability in multi-class\nhistopathological image classification.",
            "author": [
                "Ziqi Yang",
                "Zhongyu Li",
                "Chen Liu",
                "Xiangde Luo",
                "Xingguang Wang",
                "Dou Xu",
                "Chaoqun Li",
                "Xiaoying Qin",
                "Meng Yang",
                "Long Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12737v1",
                "http://arxiv.org/pdf/2308.12737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12735v1",
            "title": "Reconciling Inconsistent Molecular Structures from Biochemical Databases",
            "updated": "2023-08-24T12:26:20Z",
            "published": "2023-08-24T12:26:20Z",
            "summary": "Information on the structure of molecules, retrieved via biochemical\ndatabases, plays a pivotal role in various disciplines, such as metabolomics,\nsystems biology, and drug discovery. However, no such database can be complete,\nand the chemical structure for a given compound is not necessarily consistent\nbetween databases. This paper presents StructRecon, a novel tool for resolving\nunique and correct molecular structures from database identifiers. StructRecon\ntraverses the cross-links between database entries in different databases to\nconstruct what we call an identifier graph, which offers a more complete view\nof the total information available on a particular compound across all the\ndatabases. In order to reconcile discrepancies between databases, we first\npresent an extensible model for chemical structure which supports multiple\nindependent levels of detail, allowing standardisation of the structure to be\napplied iteratively. In some cases, our standardisation approach results in\nmultiple structures for a given compound, in which case a random walk-based\nalgorithm is used to select the most likely structure among incompatible\nalternates. We applied StructRecon to the EColiCore2 model, resolving a unique\nchemical structure for 85.11 % of identifiers. StructRecon is open-source and\nmodular, which enables the potential support for more databases in the future.",
            "author": [
                "Casper Asbj\u00f8rn Eriksen",
                "Jakob Lykke Andersen",
                "Rolf Fagerberg",
                "Daniel Merkle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12735v1",
                "http://arxiv.org/pdf/2308.12735v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.DB",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12722v1",
            "title": "Accelerated Neural Network Training through Dimensionality Reduction for\n  High-Throughput Screening of Topological Materials",
            "updated": "2023-08-24T11:51:20Z",
            "published": "2023-08-24T11:51:20Z",
            "summary": "Machine Learning facilitates building a large variety of models, starting\nfrom elementary linear regression models to very complex neural networks.\nNeural networks are currently limited by the size of data provided and the huge\ncomputational cost of training a model. This is especially problematic when\ndealing with a large set of features without much prior knowledge of how good\nor bad each individual feature is. We try tackling the problem using\ndimensionality reduction algorithms to construct more meaningful features. We\nalso compare the accuracy and training times of raw data and data transformed\nafter dimensionality reduction to deduce a sufficient number of dimensions\nwithout sacrificing accuracy. The indicated estimation is done using a lighter\ndecision tree-based algorithm, AdaBoost, as it trains faster than neural\nnetworks. We have chosen the data from an online database of topological\nmaterials, Materiae. Our final goal is to construct a model to predict the\ntopological properties of new materials from elementary properties.",
            "author": [
                "Ruman Moulik",
                "Ankita Phutela",
                "Sajjan Sheoran",
                "Saswata Bhattacharya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12722v1",
                "http://arxiv.org/pdf/2308.12722v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12712v1",
            "title": "Ground-to-Aerial Person Search: Benchmark Dataset and Approach",
            "updated": "2023-08-24T11:11:26Z",
            "published": "2023-08-24T11:11:26Z",
            "summary": "In this work, we construct a large-scale dataset for Ground-to-Aerial Person\nSearch, named G2APS, which contains 31,770 images of 260,559 annotated bounding\nboxes for 2,644 identities appearing in both of the UAVs and ground\nsurveillance cameras. To our knowledge, this is the first dataset for\ncross-platform intelligent surveillance applications, where the UAVs could work\nas a powerful complement for the ground surveillance cameras. To more\nrealistically simulate the actual cross-platform Ground-to-Aerial surveillance\nscenarios, the surveillance cameras are fixed about 2 meters above the ground,\nwhile the UAVs capture videos of persons at different location, with a variety\nof view-angles, flight attitudes and flight modes. Therefore, the dataset has\nthe following unique characteristics: 1) drastic view-angle changes between\nquery and gallery person images from cross-platform cameras; 2) diverse\nresolutions, poses and views of the person images under 9 rich real-world\nscenarios. On basis of the G2APS benchmark dataset, we demonstrate detailed\nanalysis about current two-step and end-to-end person search methods, and\nfurther propose a simple yet effective knowledge distillation scheme on the\nhead of the ReID network, which achieves state-of-the-art performances on both\nof the G2APS and the previous two public person search datasets, i.e., PRW and\nCUHK-SYSU. The dataset and source code available on\n\\url{https://github.com/yqc123456/HKD_for_person_search}.",
            "author": [
                "Shizhou Zhang",
                "Qingchun Yang",
                "De Cheng",
                "Yinghui Xing",
                "Guoqiang Liang",
                "Peng Wang",
                "Yanning Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612105",
                "http://arxiv.org/abs/2308.12712v1",
                "http://arxiv.org/pdf/2308.12712v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.5.4; I.4.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12706v3",
            "title": "Some orientation theorems for restricted DP-colorings of graphs",
            "updated": "2023-10-04T16:58:06Z",
            "published": "2023-08-24T10:57:31Z",
            "summary": "We define $Z$-signable correspondence assignments on multigraphs, which\ngeneralize good correspondence assignments as introduced by Kaul and Mudrock.\nWe introduce an auxiliary digraph that allows us to prove an Alon-Tarsi style\ntheorem for DP-colorings from $Z$-signable correspondence assignments on\nmultigraphs, and apply this theorem to obtain three DP-coloring analogs of the\nAlon-Tarsi theorem for arbitrary correspondence assignments as corollaries. We\nillustrate the use of these corollaries for DP-colorings on a restricted class\nof correspondence assignments on toroidal grids.",
            "author": [
                "Ian Gossett"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12706v3",
                "http://arxiv.org/pdf/2308.12706v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12696v1",
            "title": "Disentanglement Learning via Topology",
            "updated": "2023-08-24T10:29:25Z",
            "published": "2023-08-24T10:29:25Z",
            "summary": "We propose TopDis (Topological Disentanglement), a method for learning\ndisentangled representations via adding multi-scale topological loss term.\nDisentanglement is a crucial property of data representations substantial for\nthe explainability and robustness of deep learning models and a step towards\nhigh-level cognition. The state-of-the-art method based on VAE minimizes the\ntotal correlation of the joint distribution of latent variables. We take a\ndifferent perspective on disentanglement by analyzing topological properties of\ndata manifolds. In particular, we optimize the topological similarity for data\nmanifolds traversals. To the best of our knowledge, our paper is the first one\nto propose a differentiable topological loss for disentanglement. Our\nexperiments have shown that the proposed topological loss improves\ndisentanglement scores such as MIG, FactorVAE score, SAP score and DCI\ndisentanglement score with respect to state-of-the-art results. Our method\nworks in an unsupervised manner, permitting to apply it for problems without\nlabeled factors of variation. Additionally, we show how to use the proposed\ntopological loss to find disentangled directions in a trained GAN.",
            "author": [
                "Nikita Balabin",
                "Daria Voronkova",
                "Ilya Trofimov",
                "Evgeny Burnaev",
                "Serguei Barannikov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12696v1",
                "http://arxiv.org/pdf/2308.12696v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12682v1",
            "title": "SayCanPay: Heuristic Planning with Large Language Models using Learnable\n  Domain Knowledge",
            "updated": "2023-08-24T09:47:28Z",
            "published": "2023-08-24T09:47:28Z",
            "summary": "Large Language Models (LLMs) have demonstrated impressive planning abilities\ndue to their vast \"world knowledge\". Yet, obtaining plans that are both\nfeasible (grounded in affordances) and cost-effective (in plan length), remains\na challenge, despite recent progress. This contrasts with heuristic planning\nmethods that employ domain knowledge (formalized in action models such as PDDL)\nand heuristic search to generate feasible, optimal plans. Inspired by this, we\npropose to combine the power of LLMs and heuristic planning by leveraging the\nworld knowledge of LLMs and the principles of heuristic search. Our approach,\nSayCanPay, employs LLMs to generate actions (Say) guided by learnable domain\nknowledge, that evaluates actions' feasibility (Can) and long-term\nreward/payoff (Pay), and heuristic search to select the best sequence of\nactions. Our contributions are (1) a novel framing of the LLM planning problem\nin the context of heuristic planning, (2) integrating grounding and\ncost-effective elements into the generated plans, and (3) using heuristic\nsearch over actions. Our extensive evaluations show that our model surpasses\nother LLM planning approaches.",
            "author": [
                "Rishi Hazra",
                "Pedro Zuidberg Dos Martires",
                "Luc De Raedt"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12682v1",
                "http://arxiv.org/pdf/2308.12682v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12680v1",
            "title": "Master-slave Deep Architecture for Top-K Multi-armed Bandits with\n  Non-linear Bandit Feedback and Diversity Constraints",
            "updated": "2023-08-24T09:39:04Z",
            "published": "2023-08-24T09:39:04Z",
            "summary": "We propose a novel master-slave architecture to solve the top-$K$\ncombinatorial multi-armed bandits problem with non-linear bandit feedback and\ndiversity constraints, which, to the best of our knowledge, is the first\ncombinatorial bandits setting considering diversity constraints under bandit\nfeedback. Specifically, to efficiently explore the combinatorial and\nconstrained action space, we introduce six slave models with distinguished\nmerits to generate diversified samples well balancing rewards and constraints\nas well as efficiency. Moreover, we propose teacher learning based optimization\nand the policy co-training technique to boost the performance of the multiple\nslave models. The master model then collects the elite samples provided by the\nslave models and selects the best sample estimated by a neural contextual\nUCB-based network to make a decision with a trade-off between exploration and\nexploitation. Thanks to the elaborate design of slave models, the co-training\nmechanism among slave models, and the novel interactions between the master and\nslave models, our approach significantly surpasses existing state-of-the-art\nalgorithms in both synthetic and real datasets for recommendation tasks. The\ncode is available at:\n\\url{https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits}.",
            "author": [
                "Hanchi Huang",
                "Li Shen",
                "Deheng Ye",
                "Wei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12680v1",
                "http://arxiv.org/pdf/2308.12680v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12679v1",
            "title": "A Continual Learning Approach for Cross-Domain White Blood Cell\n  Classification",
            "updated": "2023-08-24T09:38:54Z",
            "published": "2023-08-24T09:38:54Z",
            "summary": "Accurate classification of white blood cells in peripheral blood is essential\nfor diagnosing hematological diseases. Due to constantly evolving clinical\nsettings, data sources, and disease classifications, it is necessary to update\nmachine learning classification models regularly for practical real-world use.\nSuch models significantly benefit from sequentially learning from incoming data\nstreams without forgetting previously acquired knowledge. However, models can\nsuffer from catastrophic forgetting, causing a drop in performance on previous\ntasks when fine-tuned on new data. Here, we propose a rehearsal-based continual\nlearning approach for class incremental and domain incremental scenarios in\nwhite blood cell classification. To choose representative samples from previous\ntasks, we employ exemplar set selection based on the model's predictions. This\ninvolves selecting the most confident samples and the most challenging samples\nidentified through uncertainty estimation of the model. We thoroughly evaluated\nour proposed approach on three white blood cell classification datasets that\ndiffer in color, resolution, and class composition, including scenarios where\nnew domains or new classes are introduced to the model with every task. We also\ntest a long class incremental experiment with both new domains and new classes.\nOur results demonstrate that our approach outperforms established baselines in\ncontinual learning, including existing iCaRL and EWC methods for classifying\nwhite blood cells in cross-domain environments.",
            "author": [
                "Ario Sadafi",
                "Raheleh Salehi",
                "Armin Gruber",
                "Sayedali Shetab Boushehri",
                "Pascal Giehr",
                "Nassir Navab",
                "Carsten Marr"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12679v1",
                "http://arxiv.org/pdf/2308.12679v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12673v2",
            "title": "Masked Feature Modelling: Feature Masking for the Unsupervised\n  Pre-training of a Graph Attention Network Block for Bottom-up Video Event\n  Recognition",
            "updated": "2023-08-25T08:03:28Z",
            "published": "2023-08-24T09:31:02Z",
            "summary": "In this paper, we introduce Masked Feature Modelling (MFM), a novel approach\nfor the unsupervised pre-training of a Graph Attention Network (GAT) block. MFM\nutilizes a pretrained Visual Tokenizer to reconstruct masked features of\nobjects within a video, leveraging the MiniKinetics dataset. We then\nincorporate the pre-trained GAT block into a state-of-the-art bottom-up\nsupervised video-event recognition architecture, ViGAT, to improve the model's\nstarting point and overall accuracy. Experimental evaluations on the YLI-MED\ndataset demonstrate the effectiveness of MFM in improving event recognition\nperformance.",
            "author": [
                "Dimitrios Daskalakis",
                "Nikolaos Gkalelis",
                "Vasileios Mezaris"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12673v2",
                "http://arxiv.org/pdf/2308.12673v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12665v1",
            "title": "Note on intrinsic metrics on graphs",
            "updated": "2023-08-24T09:15:19Z",
            "published": "2023-08-24T09:15:19Z",
            "summary": "We study the set of intrinsic metrics on a given graph. This is a convex\ncompact set and it carries a natural order. We investigate existence of largest\nelements with respect to this order. We show that the only locally finite\ngraphs which admit a largest intrinsic metric are certain finite star graphs.\nIn particular all infinite locally finite graphs do not admit a largest\nintrinsic metric. Moreover, we give a characterization for the existence of\nintrinsic metrics with finite balls for weakly spherically symmetric graphs.",
            "author": [
                "Daniel Lenz",
                "Marcel Schmidt",
                "Felix Seifert"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12665v1",
                "http://arxiv.org/pdf/2308.12665v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "math.MG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12659v1",
            "title": "kTrans: Knowledge-Aware Transformer for Binary Code Embedding",
            "updated": "2023-08-24T09:07:11Z",
            "published": "2023-08-24T09:07:11Z",
            "summary": "Binary Code Embedding (BCE) has important applications in various reverse\nengineering tasks such as binary code similarity detection, type recovery,\ncontrol-flow recovery and data-flow analysis. Recent studies have shown that\nthe Transformer model can comprehend the semantics of binary code to support\ndownstream tasks. However, existing models overlooked the prior knowledge of\nassembly language. In this paper, we propose a novel Transformer-based\napproach, namely kTrans, to generate knowledge-aware binary code embedding. By\nfeeding explicit knowledge as additional inputs to the Transformer, and fusing\nimplicit knowledge with a novel pre-training task, kTrans provides a new\nperspective to incorporating domain knowledge into a Transformer framework. We\ninspect the generated embeddings with outlier detection and visualization, and\nalso apply kTrans to 3 downstream tasks: Binary Code Similarity Detection\n(BCSD), Function Type Recovery (FTR) and Indirect Call Recognition (ICR).\nEvaluation results show that kTrans can generate high-quality binary code\nembeddings, and outperforms state-of-the-art (SOTA) approaches on downstream\ntasks by 5.2%, 6.8%, and 12.6% respectively. kTrans is publicly available at:\nhttps://github.com/Learner0x5a/kTrans-release",
            "author": [
                "Wenyu Zhu",
                "Hao Wang",
                "Yuchen Zhou",
                "Jiaming Wang",
                "Zihan Sha",
                "Zeyu Gao",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12659v1",
                "http://arxiv.org/pdf/2308.12659v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12655v1",
            "title": "Epidemic spread, parameter sensitivity and vaccination strategies on a\n  random graph with overlapping communities",
            "updated": "2023-08-24T08:54:11Z",
            "published": "2023-08-24T08:54:11Z",
            "summary": "Our main goal is to examine the role of communities in epidemic spread in a\nrandom graph model. More precisely, we consider a random graph model which\nconsists of overlapping complete graphs, representing households, workplaces,\nschool classes, and which also has a simple geometric structure. We study the\nmodel's sensitivity to infection parameters and other tunable parameters of the\nmodel, which might be helpful in finding efficient social distancing\nstrategies. We also quantitatively compare different vaccination strategies to\nsee which order is the best to defend the most vulnerable groups or the\npopulation in general, and how important it is to gather and use information on\nthe position of infected individuals in the network.",
            "author": [
                "\u00c1gnes Backhausz",
                "Gy\u00f6rgy J. Sz\u00e9kely"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12655v1",
                "http://arxiv.org/pdf/2308.12655v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "q-bio.PE",
                "92D30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12654v1",
            "title": "An interlacing property of the signless Laplacian of threshold graphs",
            "updated": "2023-08-24T08:52:00Z",
            "published": "2023-08-24T08:52:00Z",
            "summary": "We show that for threshold graphs, the eigenvalues of the signless Laplacian\nmatrix interlace with the degrees of the vertices. As an application, we show\nthat the signless Brouwer conjecture holds for threshold graphs, i.e., for\nthreshold graphs the sum of the k largest eigenvalues is bounded by the number\nof edges plus k + 1 choose 2.",
            "author": [
                "Christoph Helmberg",
                "Guilherme Porto",
                "Guilherme Torres",
                "Vilmar Trevisan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12654v1",
                "http://arxiv.org/pdf/2308.12654v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 15A18"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12653v1",
            "title": "Shortest Odd Paths in Undirected Graphs with Conservative Weight\n  Functions",
            "updated": "2023-08-24T08:51:51Z",
            "published": "2023-08-24T08:51:51Z",
            "summary": "We consider the Shortest Odd Path problem, where given an undirected graph\n$G$, a weight function on its edges, and two vertices $s$ and $t$ in $G$, the\naim is to find an $(s,t)$-path with odd length and, among all such paths, of\nminimum weight. For the case when the weight function is conservative, i.e.,\nwhen every cycle has non-negative total weight, the complexity of the Shortest\nOdd Path problem had been open for 20 years, and was recently shown to be\nNP-hard. We give a polynomial-time algorithm for the special case when the\nweight function is conservative and the set $E^-$ of negative-weight edges\nforms a single tree. Our algorithm exploits the strong connection between\nShortest Odd Path and the problem of finding two internally vertex-disjoint\npaths between two terminals in an undirected edge-weighted graph. It also\nrelies on solving an intermediary problem variant called Shortest\nParity-Constrained Odd Path where for certain edges we have parity constraints\non their position along the path. Also, we exhibit two FPT algorithms for\nsolving Shortest Odd Path in graphs with conservative weight functions. The\nfirst FPT algorithm is parameterized by $|E^-|$, the number of negative edges,\nor more generally, by the maximum size of a matching in the subgraph of $G$\nspanned by $E^-$. Our second FPT algorithm is parameterized by the treewidth of\n$G$.",
            "author": [
                "Alp\u00e1r J\u00fcttner",
                "Csaba Kir\u00e1ly",
                "Lydia Mirabel Mendoza-Cadena",
                "Gyula Pap",
                "Ildik\u00f3 Schlotter",
                "Yutaro Yamaguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12653v1",
                "http://arxiv.org/pdf/2308.12653v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12651v2",
            "title": "Sink Location Problems in Dynamic Flow Grid Networks",
            "updated": "2023-08-29T16:59:10Z",
            "published": "2023-08-24T08:47:15Z",
            "summary": "A dynamic flow network consists of a directed graph, where nodes called\nsources represent locations of evacuees, and nodes called sinks represent\nlocations of evacuation facilities. Each source and each sink are given supply\nrepresenting the number of evacuees and demand representing the maximum number\nof acceptable evacuees, respectively. Each edge is given capacity and transit\ntime. Here, the capacity of an edge bounds the rate at which evacuees can enter\nthe edge per unit time, and the transit time represents the time which evacuees\ntake to travel across the edge. The evacuation completion time is the minimum\ntime at which each evacuees can arrive at one of the evacuation facilities.\nGiven a dynamic flow network without sinks, once sinks are located on some\nnodes or edges, the evacuation completion time for this sink location is\ndetermined. We then consider the problem of locating sinks to minimize the\nevacuation completion time, called the sink location problem. The problems have\nbeen given polynomial-time algorithms only for limited networks such as paths,\ncycles, and trees, but no polynomial-time algorithms are known for more complex\nnetwork classes. In this paper, we prove that the 1-sink location problem can\nbe solved in polynomial-time when an input network is a grid with uniform edge\ncapacity and transit time.",
            "author": [
                "Yuya Higashikawa",
                "Ayano Nishii",
                "Junichi Teruyama",
                "Yuki Tokuni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12651v2",
                "http://arxiv.org/pdf/2308.12651v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12647v1",
            "title": "Multitasking Evolutionary Algorithm Based on Adaptive Seed Transfer for\n  Combinatorial Problem",
            "updated": "2023-08-24T08:43:32Z",
            "published": "2023-08-24T08:43:32Z",
            "summary": "Evolutionary computing (EC) is widely used in dealing with combinatorial\noptimization problems (COP). Traditional EC methods can only solve a single\ntask in a single run, while real-life scenarios often need to solve multiple\nCOPs simultaneously. In recent years, evolutionary multitasking optimization\n(EMTO) has become an emerging topic in the EC community. And many methods have\nbeen designed to deal with multiple COPs concurrently through exchanging\nknowledge. However, many-task optimization, cross-domain knowledge transfer,\nand negative transfer are still significant challenges in this field. A new\nevolutionary multitasking algorithm based on adaptive seed transfer (MTEA-AST)\nis developed for multitasking COPs in this work. First, a dimension unification\nstrategy is proposed to unify the dimensions of different tasks. And then, an\nadaptive task selection strategy is designed to capture the similarity between\nthe target task and other online optimization tasks. The calculated similarity\nis exploited to select suitable source tasks for the target one and determine\nthe transfer strength. Next, a task transfer strategy is established to select\nseeds from source tasks and correct unsuitable knowledge in seeds to suppress\nnegative transfer. Finally, the experimental results indicate that MTEA-AST can\nadaptively transfer knowledge in both same-domain and cross-domain many-task\nenvironments. And the proposed method shows competitive performance compared to\nother state-of-the-art EMTOs in experiments consisting of four COPs.",
            "author": [
                "Haoyuan Lv",
                "Ruochen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12647v1",
                "http://arxiv.org/pdf/2308.12647v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12628v2",
            "title": "TimeLighting: Guidance-enhanced Exploration of 2D Projections of\n  Temporal Graphs",
            "updated": "2023-08-31T14:37:57Z",
            "published": "2023-08-24T08:12:04Z",
            "summary": "In temporal (or event-based) networks, time is a continuous axis, with\nreal-valued time coordinates for each node and edge. Computing a layout for\nsuch graphs means embedding the node trajectories and edge surfaces over time\nin a 2D + t space, known as the space-time cube. Currently, these space-time\ncube layouts are visualized through animation or by slicing the cube at regular\nintervals. However, both techniques present problems ranging from sub-par\nperformance on some tasks to loss of precision. In this paper, we present\nTimeLighting, a novel visual analytics approach to visualize and explore\ntemporal graphs embedded in the space-time cube. Our interactive approach\nhighlights the node trajectories and their mobility over time, visualizes node\n\"aging\", and provides guidance to support users during exploration. We evaluate\nour approach through two case studies, showing the system's efficacy in\nidentifying temporal patterns and the role of the guidance features in the\nexploration process.",
            "author": [
                "Velitchko Filipov",
                "Davide Ceneda",
                "Daniel Archambault",
                "Alessio Arleo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12628v2",
                "http://arxiv.org/pdf/2308.12628v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12627v1",
            "title": "Introducing a New Alert Data Set for Multi-Step Attack Analysis",
            "updated": "2023-08-24T08:06:52Z",
            "published": "2023-08-24T08:06:52Z",
            "summary": "Intrusion detection systems (IDS) reinforce cyber defense by autonomously\nmonitoring various data sources for traces of attacks. However, IDSs are also\ninfamous for frequently raising false positives and alerts that are difficult\nto interpret without context. This results in high workloads on security\noperators who need to manually verify all reported alerts, often leading to\nfatigue and incorrect decisions. To generate more meaningful alerts and\nalleviate these issues, the research domain focused on multi-step attack\nanalysis proposes approaches for filtering, clustering, and correlating IDS\nalerts, as well as generation of attack graphs. Unfortunately, existing data\nsets are outdated, unreliable, narrowly focused, or only suitable for IDS\nevaluation. Since hardly any suitable benchmark data sets are publicly\navailable, researchers often resort to private data sets that prevent\nreproducibility of evaluations. We therefore generate a new alert data set that\nwe publish alongside this paper. The data set contains alerts from three\ndistinct IDSs monitoring eight executions of a multi-step attack as well as\nsimulations of normal user behavior. To illustrate the potential of our data\nset, we experiment with alert prioritization as well as two open-source tools\nfor meta-alert generation and attack graph extraction.",
            "author": [
                "Max Landauer",
                "Florian Skopik",
                "Markus Wurzenberger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12627v1",
                "http://arxiv.org/pdf/2308.12627v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12621v2",
            "title": "Hydrogen jet diffusion modeling by using physics-informed graph neural\n  network and sparsely-distributed sensor data",
            "updated": "2023-09-05T09:43:51Z",
            "published": "2023-08-24T07:50:51Z",
            "summary": "Efficient modeling of jet diffusion during accidental release is critical for\noperation and maintenance management of hydrogen facilities. Deep learning has\nproven effective for concentration prediction in gas jet diffusion scenarios.\nNonetheless, its reliance on extensive simulations as training data and its\npotential disregard for physical laws limit its applicability to unseen\naccidental scenarios. Recently, physics-informed neural networks (PINNs) have\nemerged to reconstruct spatial information by using data from\nsparsely-distributed sensors which are easily collected in real-world\napplications. However, prevailing approaches use the fully-connected neural\nnetwork as the backbone without considering the spatial dependency of sensor\ndata, which reduces the accuracy of concentration prediction. This study\nintroduces the physics-informed graph deep learning approach (Physic_GNN) for\nefficient and accurate hydrogen jet diffusion prediction by using\nsparsely-distributed sensor data. Graph neural network (GNN) is used to model\nthe spatial dependency of such sensor data by using graph nodes at which\ngoverning equations describing the physical law of hydrogen jet diffusion are\nimmediately solved. The computed residuals are then applied to constrain the\ntraining process. Public experimental data of hydrogen jet is used to compare\nthe accuracy and efficiency between our proposed approach Physic_GNN and\nstate-of-the-art PINN. The results demonstrate our Physic_GNN exhibits higher\naccuracy and physical consistency of centerline concentration prediction given\nsparse concentration compared to PINN and more efficient compared to OpenFOAM.\nThe proposed approach enables accurate and robust real-time spatial consequence\nreconstruction and underlying physical mechanisms analysis by using sparse\nsensor data.",
            "author": [
                "Xinqi Zhang",
                "Jihao Shi",
                "Junjie Li",
                "Xinyan Huang",
                "Fu Xiao",
                "Qiliang Wang",
                "Asif Sohail Usmani",
                "Guoming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12621v2",
                "http://arxiv.org/pdf/2308.12621v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12614v1",
            "title": "Obstruction characterization of co-TT graphs",
            "updated": "2023-08-24T07:26:05Z",
            "published": "2023-08-24T07:26:05Z",
            "summary": "Threshold tolerance graphs and their complement graphs ( known as co-TT\ngraphs) were introduced by Monma, Reed and Trotter[24]. Introducing the concept\nof negative interval Hell et al.[19] defined signed-interval bigraphs/digraphs\nand have shown that they are equivalent to several seemingly different classes\nof bigraphs/digraphs. They have also shown that co-TT graphs are equivalent to\nsymmetric signed-interval digraphs. In this paper we characterize\nsigned-interval bigraphs and signed-interval graphs respectively in terms of\ntheir biadjacency matrices and adjacency matrices. Finally, based on the\ngeometric representation of signed-interval graphs we have setteled the open\nproblem of forbidden induced subgraph characterization of co-TT graphs posed by\nMonma, Reed and Trotter in the same paper.",
            "author": [
                "Ashok Kumar Das",
                "Indrajit Paul"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12614v1",
                "http://arxiv.org/pdf/2308.12614v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12609v1",
            "title": "Cross-Video Contextual Knowledge Exploration and Exploitation for\n  Ambiguity Reduction in Weakly Supervised Temporal Action Localization",
            "updated": "2023-08-24T07:19:59Z",
            "published": "2023-08-24T07:19:59Z",
            "summary": "Weakly supervised temporal action localization (WSTAL) aims to localize\nactions in untrimmed videos using video-level labels. Despite recent advances,\nexisting approaches mainly follow a localization-by-classification pipeline,\ngenerally processing each segment individually, thereby exploiting only limited\ncontextual information. As a result, the model will lack a comprehensive\nunderstanding (e.g. appearance and temporal structure) of various action\npatterns, leading to ambiguity in classification learning and temporal\nlocalization. Our work addresses this from a novel perspective, by exploring\nand exploiting the cross-video contextual knowledge within the dataset to\nrecover the dataset-level semantic structure of action instances via weak\nlabels only, thereby indirectly improving the holistic understanding of\nfine-grained action patterns and alleviating the aforementioned ambiguities.\nSpecifically, an end-to-end framework is proposed, including a Robust\nMemory-Guided Contrastive Learning (RMGCL) module and a Global Knowledge\nSummarization and Aggregation (GKSA) module. First, the RMGCL module explores\nthe contrast and consistency of cross-video action features, assisting in\nlearning more structured and compact embedding space, thus reducing ambiguity\nin classification learning. Further, the GKSA module is used to efficiently\nsummarize and propagate the cross-video representative action knowledge in a\nlearnable manner to promote holistic action patterns understanding, which in\nturn allows the generation of high-confidence pseudo-labels for self-learning,\nthus alleviating ambiguity in temporal localization. Extensive experiments on\nTHUMOS14, ActivityNet1.3, and FineAction demonstrate that our method\noutperforms the state-of-the-art methods, and can be easily plugged into other\nWSTAL methods.",
            "author": [
                "Songchun Zhang",
                "Chunhui Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12609v1",
                "http://arxiv.org/pdf/2308.12609v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12604v1",
            "title": "PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation",
            "updated": "2023-08-24T07:10:31Z",
            "published": "2023-08-24T07:10:31Z",
            "summary": "Automatic medical report generation (MRG) is of great research value as it\nhas the potential to relieve radiologists from the heavy burden of report\nwriting. Despite recent advancements, accurate MRG remains challenging due to\nthe need for precise clinical understanding and the identification of clinical\nfindings. Moreover, the imbalanced distribution of diseases makes the challenge\neven more pronounced, as rare diseases are underrepresented in training data,\nmaking their diagnostic performance unreliable. To address these challenges, we\npropose diagnosis-driven prompts for medical report generation (PromptMRG), a\nnovel framework that aims to improve the diagnostic accuracy of MRG with the\nguidance of diagnosis-aware prompts. Specifically, PromptMRG is based on\nencoder-decoder architecture with an extra disease classification branch. When\ngenerating reports, the diagnostic results from the classification branch are\nconverted into token prompts to explicitly guide the generation process. To\nfurther improve the diagnostic accuracy, we design cross-modal feature\nenhancement, which retrieves similar reports from the database to assist the\ndiagnosis of a query image by leveraging the knowledge from a pre-trained CLIP.\nMoreover, the disease imbalanced issue is addressed by applying an adaptive\nlogit-adjusted loss to the classification branch based on the individual\nlearning status of each disease, which overcomes the barrier of text decoder's\ninability to manipulate disease distributions. Experiments on two MRG\nbenchmarks show the effectiveness of the proposed method, where it obtains\nstate-of-the-art clinical efficacy performance on both datasets.",
            "author": [
                "Haibo Jin",
                "Haoxuan Che",
                "Yi Lin",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12604v1",
                "http://arxiv.org/pdf/2308.12604v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12595v1",
            "title": "Logic-induced Diagnostic Reasoning for Semi-supervised Semantic\n  Segmentation",
            "updated": "2023-08-24T06:50:07Z",
            "published": "2023-08-24T06:50:07Z",
            "summary": "Recent advances in semi-supervised semantic segmentation have been heavily\nreliant on pseudo labeling to compensate for limited labeled data, disregarding\nthe valuable relational knowledge among semantic concepts. To bridge this gap,\nwe devise LogicDiag, a brand new neural-logic semi-supervised learning\nframework. Our key insight is that conflicts within pseudo labels, identified\nthrough symbolic knowledge, can serve as strong yet commonly ignored learning\nsignals. LogicDiag resolves such conflicts via reasoning with logic-induced\ndiagnoses, enabling the recovery of (potentially) erroneous pseudo labels,\nultimately alleviating the notorious error accumulation problem. We showcase\nthe practical application of LogicDiag in the data-hungry segmentation\nscenario, where we formalize the structured abstraction of semantic concepts as\na set of logic rules. Extensive experiments on three standard semi-supervised\nsemantic segmentation benchmarks demonstrate the effectiveness and generality\nof LogicDiag. Moreover, LogicDiag highlights the promising opportunities\narising from the systematic integration of symbolic reasoning into the\nprevalent statistical, neural learning approaches.",
            "author": [
                "Chen Liang",
                "Wenguan Wang",
                "Jiaxu Miao",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12595v1",
                "http://arxiv.org/pdf/2308.12595v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12581v1",
            "title": "A Huber Loss Minimization Approach to Byzantine Robust Federated\n  Learning",
            "updated": "2023-08-24T05:49:58Z",
            "published": "2023-08-24T05:49:58Z",
            "summary": "Federated learning systems are susceptible to adversarial attacks. To combat\nthis, we introduce a novel aggregator based on Huber loss minimization, and\nprovide a comprehensive theoretical analysis. Under independent and identically\ndistributed (i.i.d) assumption, our approach has several advantages compared to\nexisting methods. Firstly, it has optimal dependence on $\\epsilon$, which\nstands for the ratio of attacked clients. Secondly, our approach does not need\nprecise knowledge of $\\epsilon$. Thirdly, it allows different clients to have\nunequal data sizes. We then broaden our analysis to include non-i.i.d data,\nsuch that clients have slightly different distributions.",
            "author": [
                "Puning Zhao",
                "Fei Yu",
                "Zhiguo Wan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12581v1",
                "http://arxiv.org/pdf/2308.12581v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12554v2",
            "title": "Deep Reinforcement Learning-driven Cross-Community Energy Interaction\n  Optimal Scheduling",
            "updated": "2023-09-02T13:22:39Z",
            "published": "2023-08-24T04:42:18Z",
            "summary": "In order to coordinate energy interactions among various communities and\nenergy conversions among multi-energy subsystems within the multi-community\nintegrated energy system under uncertain conditions, and achieve overall\noptimization and scheduling of the comprehensive energy system, this paper\nproposes a comprehensive scheduling model that utilizes a multi-agent deep\nreinforcement learning algorithm to learn load characteristics of different\ncommunities and make decisions based on this knowledge. In this model, the\nscheduling problem of the integrated energy system is transformed into a Markov\ndecision process and solved using a data-driven deep reinforcement learning\nalgorithm, which avoids the need for modeling complex energy coupling\nrelationships between multi-communities and multi-energy subsystems. The\nsimulation results show that the proposed method effectively captures the load\ncharacteristics of different communities and utilizes their complementary\nfeatures to coordinate reasonable energy interactions among them. This leads to\na reduction in wind curtailment rate from 16.3% to 0% and lowers the overall\noperating cost by 5445.6 Yuan, demonstrating significant economic and\nenvironmental benefits.",
            "author": [
                "Yang Li",
                "Wenjie Ma",
                "Fanjin Bu",
                "Zhen Yang",
                "Bin Wang",
                "Meng Han"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12554v2",
                "http://arxiv.org/pdf/2308.12554v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12528v1",
            "title": "Urns with Multiple Drawings and Graph-based Interaction",
            "updated": "2023-08-24T03:35:18Z",
            "published": "2023-08-24T03:35:18Z",
            "summary": "Consider a finite undirected graph and place an urn with balls of two colours\nat each vertex. At every discrete time-step, for each urn, a fixed number of\nballs are drawn from that same urn with probability $p$, and from a randomly\nchosen neighbour of that urn with probability $1-p$. Based on what is drawn,\nthe urns then reinforce themselves or their neighbours. For every ball of a\ngiven colour in the sample, in case of P\\'olya-type reinforcement, a constant\nmultiple of balls of that colour is added while in case of Friedman-type\nreinforcement, balls of the other colour are reinforced. These different\nchoices for reinforcement give rise to multiple models. In this paper, we study\nthe convergence of the fraction of balls of either colour across urns for all\nof these models. We show that in most cases the urns synchronize, that is, the\nfraction of balls of either colour in each urn converges to the same limit\nalmost surely. A different kind of asymptotic behaviour is observed on\nbipartite graphs. We also prove similar results for the case of finite directed\ngraphs.",
            "author": [
                "Yogesh D.",
                "Neeraja Sahasrabudhe"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12528v1",
                "http://arxiv.org/pdf/2308.12528v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12520v1",
            "title": "SC-PSRO: A Unified Strategy Learning Method for Normal-form Games",
            "updated": "2023-08-24T03:14:45Z",
            "published": "2023-08-24T03:14:45Z",
            "summary": "Solving Nash equilibrium is the key challenge in normal-form games with large\nstrategy spaces, wherein open-ended learning framework provides an efficient\napproach. Previous studies invariably employ diversity as a conduit to foster\nthe advancement of strategies. Nevertheless, diversity-based algorithms can\nonly work in zero-sum games with cyclic dimensions, which lead to limitations\nin their applicability. Here, we propose an innovative unified open-ended\nlearning framework SC-PSRO, i.e., Self-Confirming Policy Space Response Oracle,\nas a general framework for both zero-sum and general-sum games. In particular,\nwe introduce the advantage function as an improved evaluation metric for\nstrategies, allowing for a unified learning objective for agents in normal-form\ngames. Concretely, SC-PSRO comprises three quintessential components: 1) A\nDiversity Module, aiming to avoid strategies to be constrained by the cyclic\nstructure. 2) A LookAhead Module, devised for the promotion of strategy in the\ntransitive dimension. This module is theoretically guaranteed to learn\nstrategies in the direction of the Nash equilibrium. 3) A Confirming-based\nPopulation Clipping Module, contrived for tackling the equilibrium selection\nproblem in general-sum games. This module can be applied to learn equilibria\nwith optimal rewards, which to our knowledge is the first improvement for\ngeneral-sum games. Our experiments indicate that SC-PSRO accomplishes a\nconsiderable decrease in exploitability in zero-sum games and an escalation in\nrewards in general-sum games, markedly surpassing antecedent methodologies.\nCode will be released upon acceptance.",
            "author": [
                "Yudong Hu",
                "Haoran Li",
                "Congying Han",
                "Tiande Guo",
                "Mingqiang Li",
                "Bonan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12520v1",
                "http://arxiv.org/pdf/2308.12520v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12519v1",
            "title": "Large Language Model as Autonomous Decision Maker",
            "updated": "2023-08-24T03:11:45Z",
            "published": "2023-08-24T03:11:45Z",
            "summary": "While large language models (LLMs) exhibit impressive language understanding\nand in-context learning abilities, their decision-making ability still heavily\nrelies on the guidance of task-specific expert knowledge when solving\nreal-world tasks. To unleash the potential of LLMs as autonomous decision\nmakers, this paper presents an approach JuDec to endow LLMs with the\nself-judgment ability, enabling LLMs to achieve autonomous judgment and\nexploration for decision making. Specifically, in JuDec, Elo-based\nSelf-Judgment Mechanism is designed to assign Elo scores to decision steps to\njudge their values and utilities via pairwise comparisons between two solutions\nand then guide the decision-searching process toward the optimal solution\naccordingly. Experimental results on the ToolBench dataset demonstrate JuDec's\nsuperiority over baselines, achieving over 10% improvement in Pass Rate on\ndiverse tasks. It offers higher-quality solutions and reduces costs (ChatGPT\nAPI calls), highlighting its effectiveness and efficiency.",
            "author": [
                "Yining Ye",
                "Xin Cong",
                "Yujia Qin",
                "Yankai Lin",
                "Zhiyuan Liu",
                "Maosong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12519v1",
                "http://arxiv.org/pdf/2308.12519v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12516v1",
            "title": "Controlled transport in chiral quantum walks on graphs",
            "updated": "2023-08-24T03:02:30Z",
            "published": "2023-08-24T03:02:30Z",
            "summary": "We investigate novel transport properties of chiral continuous-time quantum\nwalks (CTQWs) on graphs. By employing a gauge transformation, we demonstrate\nthat CTQWs on chiral chains are equivalent to those on non-chiral chains, but\nwith additional momenta from initial wave packets. This explains the novel\ntransport phenomenon numerically studied in [New J. Phys. 23, 083005(2021)].\nBuilding on this, we delve deeper into the analysis of chiral CTQWs on the\nY-junction graph, introducing phases to account for the chirality. The phase\nplays a key role in controlling both asymmetric transport and directed complete\ntransport among the chains in the Y-junction graph. We systematically analyze\nthese features through a comprehensive examination of the chiral\ncontinuous-time quantum walk (CTQW) on a Y-junction graph. Our analysis shows\nthat the CTQW on Y-junction graph can be modeled as a combination of three wave\nfunctions, each of which evolves independently on three effective open chains.\nBy constructing a lattice scattering theory, we calculate the phase shift of a\nwave packet after it interacts with the potential-shifted boundary. Our results\ndemonstrate that the interplay of these phase shifts leads to the observed\nenhancement and suppression of quantum transport. The explicit condition for\ndirected complete transport or 100% efficiency is analytically derived. Our\ntheory has applications in building quantum versions of binary tree search\nalgorithms.",
            "author": [
                "Yi-Cong Yu",
                "Xiaoming Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12516v1",
                "http://arxiv.org/pdf/2308.12516v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12512v1",
            "title": "I3DOD: Towards Incremental 3D Object Detection via Prompting",
            "updated": "2023-08-24T02:54:38Z",
            "published": "2023-08-24T02:54:38Z",
            "summary": "3D object detection has achieved significant performance in many fields,\ne.g., robotics system, autonomous driving, and augmented reality. However, most\nexisting methods could cause catastrophic forgetting of old classes when\nperforming on the class-incremental scenarios. Meanwhile, the current\nclass-incremental 3D object detection methods neglect the relationships between\nthe object localization information and category semantic information and\nassume all the knowledge of old model is reliable. To address the above\nchallenge, we present a novel Incremental 3D Object Detection framework with\nthe guidance of prompting, i.e., I3DOD. Specifically, we propose a task-shared\nprompts mechanism to learn the matching relationships between the object\nlocalization information and category semantic information. After training on\nthe current task, these prompts will be stored in our prompt pool, and perform\nthe relationship of old classes in the next task. Moreover, we design a\nreliable distillation strategy to transfer knowledge from two aspects: a\nreliable dynamic distillation is developed to filter out the negative knowledge\nand transfer the reliable 3D knowledge to new detection model; the relation\nfeature is proposed to capture the responses relation in feature space and\nprotect plasticity of the model when learning novel 3D classes. To the end, we\nconduct comprehensive experiments on two benchmark datasets and our method\noutperforms the state-of-the-art object detection methods by 0.6% - 2.7% in\nterms of mAP@0.25.",
            "author": [
                "Wenqi Liang",
                "Gan Sun",
                "Chenxi Liu",
                "Jiahua Dong",
                "Kangru Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12512v1",
                "http://arxiv.org/pdf/2308.12512v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12510v1",
            "title": "Masked Autoencoders are Efficient Class Incremental Learners",
            "updated": "2023-08-24T02:49:30Z",
            "published": "2023-08-24T02:49:30Z",
            "summary": "Class Incremental Learning (CIL) aims to sequentially learn new classes while\navoiding catastrophic forgetting of previous knowledge. We propose to use\nMasked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally\ndesigned to learn useful representations through reconstructive unsupervised\nlearning, and they can be easily integrated with a supervised loss for\nclassification. Moreover, MAEs can reliably reconstruct original input images\nfrom randomly selected patches, which we use to store exemplars from past tasks\nmore efficiently for CIL. We also propose a bilateral MAE framework to learn\nfrom image-level and embedding-level fusion, which produces better-quality\nreconstructed images and more stable representations. Our experiments confirm\nthat our approach performs better than the state-of-the-art on CIFAR-100,\nImageNet-Subset, and ImageNet-Full. The code is available at\nhttps://github.com/scok30/MAE-CIL .",
            "author": [
                "Jiang-Tian Zhai",
                "Xialei Liu",
                "Andrew D. Bagdanov",
                "Ke Li",
                "Ming-Ming Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12510v1",
                "http://arxiv.org/pdf/2308.12510v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12509v1",
            "title": "Parameter-Efficient Transfer Learning for Remote Sensing Image-Text\n  Retrieval",
            "updated": "2023-08-24T02:43:53Z",
            "published": "2023-08-24T02:43:53Z",
            "summary": "Vision-and-language pre-training (VLP) models have experienced a surge in\npopularity recently. By fine-tuning them on specific datasets, significant\nperformance improvements have been observed in various tasks. However, full\nfine-tuning of VLP models not only consumes a significant amount of\ncomputational resources but also has a significant environmental impact.\nMoreover, as remote sensing (RS) data is constantly being updated, full\nfine-tuning may not be practical for real-world applications. To address this\nissue, in this work, we investigate the parameter-efficient transfer learning\n(PETL) method to effectively and efficiently transfer visual-language knowledge\nfrom the natural domain to the RS domain on the image-text retrieval task. To\nthis end, we make the following contributions. 1) We construct a novel and\nsophisticated PETL framework for the RS image-text retrieval (RSITR) task,\nwhich includes the pretrained CLIP model, a multimodal remote sensing adapter,\nand a hybrid multi-modal contrastive (HMMC) learning objective; 2) To deal with\nthe problem of high intra-modal similarity in RS data, we design a simple yet\neffective HMMC loss; 3) We provide comprehensive empirical studies for\nPETL-based RS image-text retrieval. Our results demonstrate that the proposed\nmethod is promising and of great potential for practical applications. 4) We\nbenchmark extensive state-of-the-art PETL methods on the RSITR task. Our\nproposed model only contains 0.16M training parameters, which can achieve a\nparameter reduction of 98.9% compared to full fine-tuning, resulting in\nsubstantial savings in training costs. Our retrieval performance exceeds\ntraditional methods by 7-13% and achieves comparable or better performance than\nfull fine-tuning. This work can provide new ideas and useful insights for RS\nvision-language tasks.",
            "author": [
                "Yuan Yuan",
                "Yang Zhan",
                "Zhitong Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12509v1",
                "http://arxiv.org/pdf/2308.12509v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.00013v1",
            "title": "Model Inversion Attack via Dynamic Memory Learning",
            "updated": "2023-08-24T02:32:59Z",
            "published": "2023-08-24T02:32:59Z",
            "summary": "Model Inversion (MI) attacks aim to recover the private training data from\nthe target model, which has raised security concerns about the deployment of\nDNNs in practice. Recent advances in generative adversarial models have\nrendered them particularly effective in MI attacks, primarily due to their\nability to generate high-fidelity and perceptually realistic images that\nclosely resemble the target data. In this work, we propose a novel Dynamic\nMemory Model Inversion Attack (DMMIA) to leverage historically learned\nknowledge, which interacts with samples (during the training) to induce diverse\ngenerations. DMMIA constructs two types of prototypes to inject the information\nabout historically learned knowledge: Intra-class Multicentric Representation\n(IMR) representing target-related concepts by multiple learnable prototypes,\nand Inter-class Discriminative Representation (IDR) characterizing the\nmemorized samples as learned prototypes to capture more privacy-related\ninformation. As a result, our DMMIA has a more informative representation,\nwhich brings more diverse and discriminative generated results. Experiments on\nmultiple benchmarks show that DMMIA performs better than state-of-the-art MI\nattack methods.",
            "author": [
                "Gege Qi",
                "YueFeng Chen",
                "Xiaofeng Mao",
                "Binyuan Hui",
                "Xiaodan Li",
                "Rong Zhang",
                "Hui Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2309.00013v1",
                "http://arxiv.org/pdf/2309.00013v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12506v2",
            "title": "General Covariance-Based Conditions for Central Limit Theorems with\n  Dependent Triangular Arrays",
            "updated": "2023-08-26T21:20:28Z",
            "published": "2023-08-24T02:15:04Z",
            "summary": "We present a general central limit theorem with simple, easy-to-check\ncovariance-based sufficient conditions for triangular arrays of random vectors\nwhen all variables could be interdependent. The result is constructed from\nStein's method, but the conditions are distinct from related work. We show that\nthese covariance conditions nest standard assumptions studied in the literature\nsuch as $M$-dependence, mixing random fields, non-mixing autoregressive\nprocesses, and dependency graphs, which themselves need not imply each other.\nThis permits researchers to work with high-level but intuitive conditions based\non overall correlation instead of more complicated and restrictive conditions\nsuch as strong mixing in random fields that may not have any obvious\nmicro-foundation. As examples of the implications, we show how the theorem\nimplies asymptotic normality in estimating: treatment effects with spillovers\nin more settings than previously admitted, covariance matrices, processes with\nglobal dependencies such as epidemic spread and information diffusion, and\nspatial process with Mat\\'{e}rn dependencies.",
            "author": [
                "Arun G. Chandrasekhar",
                "Matthew O. Jackson",
                "Tyler H. McCormick",
                "Vydhourie Thiyageswaran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12506v2",
                "http://arxiv.org/pdf/2308.12506v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12501v1",
            "title": "DD-GCN: Directed Diffusion Graph Convolutional Network for\n  Skeleton-based Human Action Recognition",
            "updated": "2023-08-24T01:53:59Z",
            "published": "2023-08-24T01:53:59Z",
            "summary": "Graph Convolutional Networks (GCNs) have been widely used in skeleton-based\nhuman action recognition. In GCN-based methods, the spatio-temporal graph is\nfundamental for capturing motion patterns. However, existing approaches ignore\nthe physical dependency and synchronized spatio-temporal correlations between\njoints, which limits the representation capability of GCNs. To solve these\nproblems, we construct the directed diffusion graph for action modeling and\nintroduce the activity partition strategy to optimize the weight sharing\nmechanism of graph convolution kernels. In addition, we present the\nspatio-temporal synchronization encoder to embed synchronized spatio-temporal\nsemantics. Finally, we propose Directed Diffusion Graph Convolutional Network\n(DD-GCN) for action recognition, and the experiments on three public datasets:\nNTU-RGB+D, NTU-RGB+D 120, and NW-UCLA, demonstrate the state-of-the-art\nperformance of our method.",
            "author": [
                "Chang Li",
                "Qian Huang",
                "Yingchi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12501v1",
                "http://arxiv.org/pdf/2308.12501v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12495v1",
            "title": "Source-Free Collaborative Domain Adaptation via Multi-Perspective\n  Feature Enrichment for Functional MRI Analysis",
            "updated": "2023-08-24T01:30:18Z",
            "published": "2023-08-24T01:30:18Z",
            "summary": "Resting-state functional MRI (rs-fMRI) is increasingly employed in multi-site\nresearch to aid neurological disorder analysis. Existing studies usually suffer\nfrom significant cross-site/domain data heterogeneity caused by site effects\nsuch as differences in scanners/protocols. Many methods have been proposed to\nreduce fMRI heterogeneity between source and target domains, heavily relying on\nthe availability of source data. But acquiring source data is challenging due\nto privacy concerns and/or data storage burdens in multi-site studies. To this\nend, we design a source-free collaborative domain adaptation (SCDA) framework\nfor fMRI analysis, where only a pretrained source model and unlabeled target\ndata are accessible. Specifically, a multi-perspective feature enrichment\nmethod (MFE) is developed for target fMRI analysis, consisting of multiple\ncollaborative branches to dynamically capture fMRI features of unlabeled target\ndata from multiple views. Each branch has a data-feeding module, a\nspatiotemporal feature encoder, and a class predictor. A mutual-consistency\nconstraint is designed to encourage pair-wise consistency of latent features of\nthe same input generated from these branches for robust representation\nlearning. To facilitate efficient cross-domain knowledge transfer without\nsource data, we initialize MFE using parameters of a pretrained source model.\nWe also introduce an unsupervised pretraining strategy using 3,806 unlabeled\nfMRIs from three large-scale auxiliary databases, aiming to obtain a general\nfeature encoder. Experimental results on three public datasets and one private\ndataset demonstrate the efficacy of our method in cross-scanner and cross-study\nprediction tasks. The model pretrained on large-scale rs-fMRI data has been\nreleased to the public.",
            "author": [
                "Yuqi Fang",
                "Jinjian Wu",
                "Qianqian Wang",
                "Shijun Qiu",
                "Andrea Bozoki",
                "Huaicheng Yan",
                "Mingxia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12495v1",
                "http://arxiv.org/pdf/2308.12495v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12488v1",
            "title": "GPTEval: A Survey on Assessments of ChatGPT and GPT-4",
            "updated": "2023-08-24T01:17:16Z",
            "published": "2023-08-24T01:17:16Z",
            "summary": "The emergence of ChatGPT has generated much speculation in the press about\nits potential to disrupt social and economic systems. Its astonishing language\nability has aroused strong curiosity among scholars about its performance in\ndifferent domains. There have been many studies evaluating the ability of\nChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive\nreview summarizing the collective assessment findings is lacking. The objective\nof this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4,\nfocusing on its language and reasoning abilities, scientific knowledge, and\nethical considerations. Furthermore, an examination of the existing evaluation\nmethods is conducted, offering several recommendations for future research in\nevaluating large language models.",
            "author": [
                "Rui Mao",
                "Guanyi Chen",
                "Xulang Zhang",
                "Frank Guerin",
                "Erik Cambria"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12488v1",
                "http://arxiv.org/pdf/2308.12488v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12486v2",
            "title": "A Brain-Inspired Sequence Learning Model based on a Logic",
            "updated": "2023-11-06T16:26:09Z",
            "published": "2023-08-24T01:01:41Z",
            "summary": "Sequence learning is an essential aspect of intelligence. In Artificial\nIntelligence, sequence prediction task is usually used to test a sequence\nlearning model. In this paper, a model of sequence learning, which is\ninterpretable through Non-Axiomatic Logic, is designed and tested. The learning\nmechanism is composed of three steps, hypothesizing, revising, and recycling,\nwhich enable the model to work under the Assumption of Insufficient Knowledge\nand Resources. Synthetic datasets for sequence prediction task are generated to\ntest the capacity of the model. The results show that the model works well\nwithin different levels of difficulty. In addition, since the model adopts\nconcept-centered representation, it theoretically does not suffer from\ncatastrophic forgetting, and the practical results also support this property.\nThis paper shows the potential of learning sequences in a logical way.",
            "author": [
                "Bowen Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12486v2",
                "http://arxiv.org/pdf/2308.12486v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12483v2",
            "title": "Linear-Sized Spectral Sparsifiers and the Kadison-Singer Problem",
            "updated": "2023-11-09T19:12:13Z",
            "published": "2023-08-24T00:49:59Z",
            "summary": "The Kadison-Singer Conjecture, as proved by Marcus, Spielman, and Srivastava\n(MSS) [Ann. Math. 182, 327-350 (2015)], has been informally thought of as a\nstrengthening of Batson, Spielman, and Srivastava's theorem that every\nundirected graph has a linear-sized spectral sparsifier [SICOMP 41, 1704-1721\n(2012)]. We formalize this intuition by using a corollary of the MSS result to\nderive the existence of spectral sparsifiers with a number of edges linear in\ntheir number of vertices for all undirected, weighted graphs. The proof\nconsists of two steps. First, following a suggestion of Srivastava [Asia Pac.\nMath. Newsl. 3, 15-20 (2013)], we show the result in the special case of graphs\nwith bounded leverage scores by repeatedly applying the MSS corollary to\npartition the graph, while maintaining an appropriate bound on the leverage\nscores of each subgraph. Then, we extend to the general case by constructing a\nrecursive algorithm that repeatedly (i) divides edges with high leverage scores\ninto multiple parallel edges and (ii) uses the bounded leverage score case to\nsparsify the resulting graph.",
            "author": [
                "Phevos Paschalidis",
                "Ashley Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12483v2",
                "http://arxiv.org/pdf/2308.12483v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12481v1",
            "title": "Fall Detection using Knowledge Distillation Based Long short-term memory\n  for Offline Embedded and Low Power Devices",
            "updated": "2023-08-24T00:49:07Z",
            "published": "2023-08-24T00:49:07Z",
            "summary": "This paper presents a cost-effective, low-power approach to unintentional\nfall detection using knowledge distillation-based LSTM (Long Short-Term Memory)\nmodels to significantly improve accuracy. With a primary focus on analyzing\ntime-series data collected from various sensors, the solution offers real-time\ndetection capabilities, ensuring prompt and reliable identification of falls.\nThe authors investigate fall detection models that are based on different\nsensors, comparing their accuracy rates and performance. Furthermore, they\nemploy the technique of knowledge distillation to enhance the models'\nprecision, resulting in refined accurate configurations that consume lower\npower. As a result, this proposed solution presents a compelling avenue for the\ndevelopment of energy-efficient fall detection systems for future advancements\nin this critical domain.",
            "author": [
                "Hannah Zhou",
                "Allison Chen",
                "Celine Buer",
                "Emily Chen",
                "Kayleen Tang",
                "Lauryn Gong",
                "Zhiqi Liu",
                "Jianbin Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12481v1",
                "http://arxiv.org/pdf/2308.12481v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12477v1",
            "title": "American Stories: A Large-Scale Structured Text Dataset of Historical\n  U.S. Newspapers",
            "updated": "2023-08-24T00:24:42Z",
            "published": "2023-08-24T00:24:42Z",
            "summary": "Existing full text datasets of U.S. public domain newspapers do not recognize\nthe often complex layouts of newspaper scans, and as a result the digitized\ncontent scrambles texts from articles, headlines, captions, advertisements, and\nother layout regions. OCR quality can also be low. This study develops a novel,\ndeep learning pipeline for extracting full article texts from newspaper images\nand applies it to the nearly 20 million scans in Library of Congress's public\ndomain Chronicling America collection. The pipeline includes layout detection,\nlegibility classification, custom OCR, and association of article texts\nspanning multiple bounding boxes. To achieve high scalability, it is built with\nefficient architectures designed for mobile phones. The resulting American\nStories dataset provides high quality data that could be used for pre-training\na large language model to achieve better understanding of historical English\nand historical world knowledge. The dataset could also be added to the external\ndatabase of a retrieval-augmented language model to make historical information\n- ranging from interpretations of political events to minutiae about the lives\nof people's ancestors - more widely accessible. Furthermore, structured article\ntexts facilitate using transformer-based methods for popular social science\napplications like topic classification, detection of reproduced content, and\nnews story clustering. Finally, American Stories provides a massive silver\nquality dataset for innovating multimodal layout analysis models and other\nmultimodal applications.",
            "author": [
                "Melissa Dell",
                "Jacob Carlson",
                "Tom Bryan",
                "Emily Silcock",
                "Abhishek Arora",
                "Zejiang Shen",
                "Luca D'Amico-Wong",
                "Quan Le",
                "Pablo Querubin",
                "Leander Heldring"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12477v1",
                "http://arxiv.org/pdf/2308.12477v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12462v3",
            "title": "Overcoming Generic Knowledge Loss with Selective Parameter Update",
            "updated": "2023-12-06T13:46:05Z",
            "published": "2023-08-23T22:55:45Z",
            "summary": "Foundation models encompass an extensive knowledge base and offer remarkable\ntransferability. However, this knowledge becomes outdated or insufficient over\ntime. The challenge lies in continuously updating foundation models to\naccommodate novel information while retaining their original capabilities.\nLeveraging the fact that foundation models have initial knowledge on various\ntasks and domains, we propose a novel approach that, instead of updating all\nparameters equally, localizes the updates to a sparse set of parameters\nrelevant to the task being learned. We strike a balance between efficiency and\nnew task performance, while maintaining the transferability and\ngeneralizability of foundation models. We extensively evaluate our method on\nfoundational vision-language models with a diverse spectrum of continual\nlearning tasks. Our method achieves improvements on the accuracy of the newly\nlearned tasks up to 7% while preserving the pretraining knowledge with a\nnegligible decrease of 0.9% on a representative control set accuracy.",
            "author": [
                "Wenxuan Zhang",
                "Paul Janson",
                "Rahaf Aljundi",
                "Mohamed Elhoseiny"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12462v3",
                "http://arxiv.org/pdf/2308.12462v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12433v1",
            "title": "A Spatiotemporal Correspondence Approach to Unsupervised LiDAR\n  Segmentation with Traffic Applications",
            "updated": "2023-08-23T21:32:46Z",
            "published": "2023-08-23T21:32:46Z",
            "summary": "We address the problem of unsupervised semantic segmentation of outdoor LiDAR\npoint clouds in diverse traffic scenarios. The key idea is to leverage the\nspatiotemporal nature of a dynamic point cloud sequence and introduce\ndrastically stronger augmentation by establishing spatiotemporal\ncorrespondences across multiple frames. We dovetail clustering and pseudo-label\nlearning in this work. Essentially, we alternate between clustering points into\nsemantic groups and optimizing models using point-wise pseudo-spatiotemporal\nlabels with a simple learning objective. Therefore, our method can learn\ndiscriminative features in an unsupervised learning fashion. We show promising\nsegmentation performance on Semantic-KITTI, SemanticPOSS, and FLORIDA benchmark\ndatasets covering scenarios in autonomous vehicle and intersection\ninfrastructure, which is competitive when compared against many existing fully\nsupervised learning methods. This general framework can lead to a unified\nrepresentation learning approach for LiDAR point clouds incorporating domain\nknowledge.",
            "author": [
                "Xiao Li",
                "Pan He",
                "Aotian Wu",
                "Sanjay Ranka",
                "Anand Rangarajan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12433v1",
                "http://arxiv.org/pdf/2308.12433v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12428v1",
            "title": "Uniform finite presentation for groups of polynomial growth",
            "updated": "2023-08-23T21:19:15Z",
            "published": "2023-08-23T21:19:15Z",
            "summary": "We prove a quantitative refinement of the statement that groups of polynomial\ngrowth are finitely presented. Let $G$ be a group with finite generating set\n$S$ and let $\\operatorname{Gr}(r)$ be the volume of the ball of radius $r$ in\nthe associated Cayley graph. For each $k \\geq 0$, let $R_k$ be the set of words\nof length at most $2^k$ in the free group $F_S$ that are equal to the identity\nin $G$, and let $\\langle \\langle R_k \\rangle\\rangle$ be the normal subgroup of\n$F_S$ generated by $R_k$, so that the quotient map $F_S/\\langle\\langle\nR_k\\rangle\\rangle \\to G$ induces a covering map of the associated Cayley graphs\nthat has injectivity radius at least $2^{k-1}-1$. Given a non-negative integer\n$k$, we say that $(G,S)$ has a new relation on scale k if $\\langle\\langle\nR_{k+1} \\rangle\\rangle \\neq \\langle\\langle R_{k} \\rangle\\rangle$. We prove that\nfor each $K<\\infty$ there exist constants $n_0$ and $C$ depending only on $K$\nand $|S|$ such that if $\\operatorname{Gr}(3n)\\leq K \\operatorname{Gr}(n)$ for\nsome $n\\geq n_0$, then there exist at most $C$ scales $k\\geq \\log_2 (n)$ on\nwhich $G$ has a new relation. We apply this result in a forthcoming paper as\npart of our proof of Schramm's locality conjecture in percolation theory.",
            "author": [
                "Philip Easo",
                "Tom Hutchcroft"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12428v1",
                "http://arxiv.org/pdf/2308.12428v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.02164v2",
            "title": "A Survey of Graph Unlearning",
            "updated": "2023-10-07T19:50:17Z",
            "published": "2023-08-23T20:50:52Z",
            "summary": "Graph unlearning emerges as a crucial advancement in the pursuit of\nresponsible AI, providing the means to remove sensitive data traces from\ntrained models, thereby upholding the right to be forgotten. It is evident that\ngraph machine learning exhibits sensitivity to data privacy and adversarial\nattacks, necessitating the application of graph unlearning techniques to\naddress these concerns effectively. In this comprehensive survey paper, we\npresent the first systematic review of graph unlearning approaches,\nencompassing a diverse array of methodologies and offering a detailed taxonomy\nand up-to-date literature overview to facilitate the understanding of\nresearchers new to this field. Additionally, we establish the vital connections\nbetween graph unlearning and differential privacy, augmenting our understanding\nof the relevance of privacy-preserving techniques in this context. To ensure\nclarity, we provide lucid explanations of the fundamental concepts and\nevaluation measures used in graph unlearning, catering to a broader audience\nwith varying levels of expertise. Delving into potential applications, we\nexplore the versatility of graph unlearning across various domains, including\nbut not limited to social networks, adversarial settings, and\nresource-constrained environments like the Internet of Things (IoT),\nillustrating its potential impact in safeguarding data privacy and enhancing AI\nsystems' robustness. Finally, we shed light on promising research directions,\nencouraging further progress and innovation within the domain of graph\nunlearning. By laying a solid foundation and fostering continued progress, this\nsurvey seeks to inspire researchers to further advance the field of graph\nunlearning, thereby instilling confidence in the ethical growth of AI systems\nand reinforcing the responsible application of machine learning techniques in\nvarious domains.",
            "author": [
                "Anwar Said",
                "Tyler Derr",
                "Mudassir Shabbir",
                "Waseem Abbas",
                "Xenofon Koutsoukos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.02164v2",
                "http://arxiv.org/pdf/2310.02164v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12420v1",
            "title": "Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature",
            "updated": "2023-08-23T20:42:32Z",
            "published": "2023-08-23T20:42:32Z",
            "summary": "Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating\ncomprehensive insights into their diverse components. However, a systematic\nliterature review that emphasizes the Environmental, Sustainability, and\nGovernance (ESG) components of DLT remains lacking. To bridge this gap, we\nselected 107 seed papers to build a citation network of 63,083 references and\nrefined it to a corpus of 24,539 publications for analysis. Then, we labeled\nthe named entities in 46 papers according to twelve top-level categories\nderived from an established technology taxonomy and enhanced the taxonomy by\npinpointing DLT's ESG elements. Leveraging transformer-based language models,\nwe fine-tuned a pre-trained language model for a Named Entity Recognition (NER)\ntask using our labeled dataset. We used our fine-tuned language model to\ndistill the corpus to 505 key papers, facilitating a literature review via\nnamed entities and temporal graph analysis on DLT evolution in the context of\nESG. Our contributions are a methodology to conduct a machine learning-driven\nsystematic literature review in the DLT field, placing a special emphasis on\nESG aspects. Furthermore, we present a first-of-its-kind NER dataset, composed\nof 54,808 named entities, designed for DLT and ESG-related explorations.",
            "author": [
                "Walter Hernandez",
                "Kamil Tylinski",
                "Alastair Moore",
                "Niall Roche",
                "Nikhil Vadgama",
                "Horst Treiblmaier",
                "Jiangbo Shangguan",
                "Paolo Tasca",
                "Jiahua Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12420v1",
                "http://arxiv.org/pdf/2308.12420v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12981v1",
            "title": "An approach based on Open Research Knowledge Graph for Knowledge\n  Acquisition from scientific papers",
            "updated": "2023-08-23T20:05:42Z",
            "published": "2023-08-23T20:05:42Z",
            "summary": "A scientific paper can be divided into two major constructs which are\nMetadata and Full-body text. Metadata provides a brief overview of the paper\nwhile the Full-body text contains key-insights that can be valuable to fellow\nresearchers. To retrieve metadata and key-insights from scientific papers,\nknowledge acquisition is a central activity. It consists of gathering,\nanalyzing and organizing knowledge embedded in scientific papers in such a way\nthat it can be used and reused whenever needed. Given the wealth of scientific\nliterature, manual knowledge acquisition is a cumbersome task. Thus,\ncomputer-assisted and (semi-)automatic strategies are generally adopted. Our\npurpose in this research was two fold: curate Open Research Knowledge Graph\n(ORKG) with papers related to ontology learning and define an approach using\nORKG as a computer-assisted tool to organize key-insights extracted from\nresearch papers. This approach was used to document the \"epidemiological\nsurveillance systems design and implementation\" research problem and to prepare\nthe related work of this paper. It is currently used to document \"food\ninformation engineering\", \"Tabular data to Knowledge Graph Matching\" and\n\"Question Answering\" research problems and \"Neuro-symbolic AI\" domain.",
            "author": [
                "Azanzi Jiomekong",
                "Sanju Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12981v1",
                "http://arxiv.org/pdf/2308.12981v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12399v1",
            "title": "Symmetric Nonnegative Trifactorization of Pattern Matrices",
            "updated": "2023-08-23T19:37:43Z",
            "published": "2023-08-23T19:37:43Z",
            "summary": "A factorization of an $n \\times n$ nonnegative symmetric matrix $A$ of the\nform $BCB^T$, where $C$ is a $k \\times k$ symmetric matrix, and both $B$ and\n$C$ are required to be nonnegative, is called the Symmetric Nonnegative Matrix\nTrifactorization (SN-Trifactorization). The SNT-rank of $A$ is the minimal $k$\nfor which such factorization exists. The SNT-rank of a simple graph $G$ that\nallows loops is defined to be the minimal possible SNT-rank of all symmetric\nnonnegative matrices whose zero-nonzero pattern is prescribed by a given graph.\n  We define set-join covers of graphs, and show that finding the SNT-rank of\n$G$ is equivalent to finding the minimal order of a set-join cover of $G$.\nUsing this insight we develop basic properties of the SNT-rank for graphs and\ncompute it for trees and cycles without loops. We show the equivalence between\nthe SNT-rank for complete graphs and the Katona problem, and discuss uniqueness\nof patterns of matrices in the factorization.",
            "author": [
                "Damjana Kokol Bukov\u0161ek",
                "Helena \u0160migoc"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12399v1",
                "http://arxiv.org/pdf/2308.12399v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.16716v1",
            "title": "Towards Safe Autonomy in Hybrid Traffic: Detecting Unpredictable\n  Abnormal Behaviors of Human Drivers via Information Sharing",
            "updated": "2023-08-23T18:24:28Z",
            "published": "2023-08-23T18:24:28Z",
            "summary": "Hybrid traffic which involves both autonomous and human-driven vehicles would\nbe the norm of the autonomous vehicles practice for a while. On the one hand,\nunlike autonomous vehicles, human-driven vehicles could exhibit sudden abnormal\nbehaviors such as unpredictably switching to dangerous driving modes, putting\nits neighboring vehicles under risks; such undesired mode switching could arise\nfrom numbers of human driver factors, including fatigue, drunkenness,\ndistraction, aggressiveness, etc. On the other hand, modern vehicle-to-vehicle\ncommunication technologies enable the autonomous vehicles to efficiently and\nreliably share the scarce run-time information with each other. In this paper,\nwe propose, to the best of our knowledge, the first efficient algorithm that\ncan (1) significantly improve trajectory prediction by effectively fusing the\nrun-time information shared by surrounding autonomous vehicles, and can (2)\naccurately and quickly detect abnormal human driving mode switches or abnormal\ndriving behavior with formal assurance without hurting human drivers privacy.\nTo validate our proposed algorithm, we first evaluate our proposed trajectory\npredictor on NGSIM and Argoverse datasets and show that our proposed predictor\noutperforms the baseline methods. Then through extensive experiments on SUMO\nsimulator, we show that our proposed algorithm has great detection performance\nin both highway and urban traffic. The best performance achieves detection rate\nof 97.3%, average detection delay of 1.2s, and 0 false alarm.",
            "author": [
                "Jiangwei Wang",
                "Lili Su",
                "Songyang Han",
                "Dongjin Song",
                "Fei Miao"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16716v1",
                "http://arxiv.org/pdf/2309.16716v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12371v1",
            "title": "Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and\n  Feature Augmentation",
            "updated": "2023-08-23T18:22:03Z",
            "published": "2023-08-23T18:22:03Z",
            "summary": "Open-set face recognition refers to a scenario in which biometric systems\nhave incomplete knowledge of all existing subjects. Therefore, they are\nexpected to prevent face samples of unregistered subjects from being identified\nas previously enrolled identities. This watchlist context adds an arduous\nrequirement that calls for the dismissal of irrelevant faces by focusing mainly\non subjects of interest. As a response, this work introduces a novel method\nthat associates an ensemble of compact neural networks with a margin-based cost\nfunction that explores additional samples. Supplementary negative samples can\nbe obtained from external databases or synthetically built at the\nrepresentation level in training time with a new mix-up feature augmentation\napproach. Deep neural networks pre-trained on large face datasets serve as the\npreliminary feature extraction module. We carry out experiments on well-known\nLFW and IJB-C datasets where results show that the approach is able to boost\nclosed and open-set identification rates.",
            "author": [
                "Rafael Henrique Vareto",
                "Manuel G\u00fcnther",
                "William Robson Schwartz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12371v1",
                "http://arxiv.org/pdf/2308.12371v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12366v1",
            "title": "Continual Zero-Shot Learning through Semantically Guided Generative\n  Random Walks",
            "updated": "2023-08-23T18:10:12Z",
            "published": "2023-08-23T18:10:12Z",
            "summary": "Learning novel concepts, remembering previous knowledge, and adapting it to\nfuture tasks occur simultaneously throughout a human's lifetime. To model such\ncomprehensive abilities, continual zero-shot learning (CZSL) has recently been\nintroduced. However, most existing methods overused unseen semantic information\nthat may not be continually accessible in realistic settings. In this paper, we\naddress the challenge of continual zero-shot learning where unseen information\nis not provided during training, by leveraging generative modeling. The heart\nof the generative-based methods is to learn quality representations from seen\nclasses to improve the generative understanding of the unseen visual space.\nMotivated by this, we introduce generalization-bound tools and provide the\nfirst theoretical explanation for the benefits of generative modeling to CZSL\ntasks. Guided by the theoretical analysis, we then propose our learning\nalgorithm that employs a novel semantically guided Generative Random Walk (GRW)\nloss. The GRW loss augments the training by continually encouraging the model\nto generate realistic and characterized samples to represent the unseen space.\nOur algorithm achieves state-of-the-art performance on AWA1, AWA2, CUB, and SUN\ndatasets, surpassing existing CZSL methods by 3-7\\%. The code has been made\navailable here \\url{https://github.com/wx-zhang/IGCZSL}",
            "author": [
                "Wenxuan Zhang",
                "Paul Janson",
                "Kai Yi",
                "Ivan Skorokhodov",
                "Mohamed Elhoseiny"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12366v1",
                "http://arxiv.org/pdf/2308.12366v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12285v2",
            "title": "Kapranov degrees",
            "updated": "2023-09-08T15:09:12Z",
            "published": "2023-08-23T17:58:21Z",
            "summary": "The moduli space of stable rational curves with marked points has two\ndistinguished families of maps: the forgetful maps, given by forgetting some of\nthe markings, and the Kapranov maps, given by complete linear series of\n$\\psi$-classes. The collection of all these maps embeds the moduli space into a\nproduct of projective spaces. We call the multidegrees of this embedding\n``Kapranov degrees,'' which include as special cases the work of Witten,\nSilversmith, Gallet--Grasegger--Schicho, Castravet--Tevelev, Postnikov,\nCavalieri--Gillespie--Monin, and Gillespie--Griffins--Levinson. We establish,\nin terms of a combinatorial matching condition, upper bounds for Kapranov\ndegrees and a characterization of their positivity. The positivity\ncharacterization answers a question of Silversmith and gives a new proof of\nLaman's theorem characterizing generically rigid graphs in the plane. We\nachieve this by proving a recursive formula for Kapranov degrees and by using\ntools from the theory of error correcting codes.",
            "author": [
                "Joshua Brakensiek",
                "Christopher Eur",
                "Matt Larson",
                "Shiyue Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12285v2",
                "http://arxiv.org/pdf/2308.12285v2"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12283v1",
            "title": "Constraining Circumgalactic Turbulence with QSO Absorption-line\n  Measurements",
            "updated": "2023-08-23T17:57:51Z",
            "published": "2023-08-23T17:57:51Z",
            "summary": "Our knowledge of the circumgalactic medium (CGM) is mostly based on quasar\nabsorption-line measurements. These have uncovered a multiphase medium that is\nlikely highly turbulent, but constraints of this turbulence are limited to\nmeasurements of the non-thermal width of absorption-line components\n($b_{turb}$) and the line-of-sight velocity dispersion between components\n($\\sigma_{LOS}$). Here we analyze a suite of CGM simulations to determine how\nwell these indirect measures are related to the underlying CGM. Our simulations\ntrack the non-equilibrium evolution of all commonly observed ions, and consist\nof two main types: small-scale simulations of regions of homogeneous CGM\nturbulence and global simulations of inhomogeneous turbulence throughout a\ngalactic halo. From each simulation, we generate mock spectra of Si II, Si IV,\nC IV, and O VI, which allow us to directly compare $b_{turb}$ and\n$\\sigma_{LOS}$ to the true line-of-sight turbulence ($\\sigma_{1D}$). In the\nsmall-scale simulations, $b_{turb}$ is only weakly correlated with\n$\\sigma_{1D}$, likely because it measures random motions within individual warm\nCGM clouds, which do not sample the overall random motions. Meanwhile,\n$\\sigma_{LOS}$ and $\\sigma_{1D}$ are strongly correlated, with\n$\\sigma_{1D}\\approx\\sigma_{LOS}+10$ km s$^{-1}$ in the densest regions we\nsimulated, though, the strength of this correlation depended weakly on the gas\nphase being probed. Our large-scale simulations also indicate that $b_{turb}$\nand $\\sigma_{1D}$ are largely uncorrelated, and that\n$\\sigma_{1D}\\approx\\sigma_{LOS}+10$ kms$^{-1}$ on average, although it varies\nalong individual sightlines. Moreover, the $\\sigma_\\mathrm{LOS}$ distributions\nfrom our global simulations are similar to recent observations, suggesting that\nthis quantity may provide useful constraints on circumgalactic turbulence\nregardless of the axis probed.",
            "author": [
                "Brad Koplitz",
                "Edward Buie II",
                "Evan Scannapieco"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12283v1",
                "http://arxiv.org/pdf/2308.12283v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12273v3",
            "title": "Assouad-Nagata dimension of minor-closed metrics",
            "updated": "2023-09-21T22:15:55Z",
            "published": "2023-08-23T17:42:31Z",
            "summary": "Assouad-Nagata dimension addresses both large and small scale behaviors of\nmetric spaces and is a refinement of Gromov's asymptotic dimension. A metric\nspace $M$ is a minor-closed metric if there exists an (edge-)weighted graph $G$\nsatisfying a fixed minor-closed property such that the underlying space of $M$\nis the vertex-set of $G$, and the metric of $M$ is the distance function in\n$G$. Minor-closed metrics naturally arise when removing redundant edges of the\nunderlying graphs by using edge-deletion and edge-contraction. In this paper,\nwe determine the Assouad-Nagata dimension of every minor-closed metric. It is a\ncommon generalization of known results about the asymptotic dimension of\n$H$-minor free unweighted graphs and about the Assouad-Nagata dimension of\ncomplete Riemannian surfaces with finite Euler genus and their corollaries.",
            "author": [
                "Chun-Hung Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12273v3",
                "http://arxiv.org/pdf/2308.12273v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "math.GR",
                "math.GT",
                "math.MG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12272v1",
            "title": "Simple is Better and Large is Not Enough: Towards Ensembling of\n  Foundational Language Models",
            "updated": "2023-08-23T17:40:35Z",
            "published": "2023-08-23T17:40:35Z",
            "summary": "Foundational Language Models (FLMs) have advanced natural language processing\n(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,\nT5) to enable contextualized language representation, classification, and\ngeneration. While developing larger FLMs has been of significant advantage, it\nis also a liability concerning hallucination and predictive uncertainty.\nFundamentally, larger FLMs are built on the same foundations as smaller FLMs\n(e.g., BERT); hence, one must recognize the potential of smaller FLMs which can\nbe realized through an ensemble. In the current research, we perform a reality\ncheck on FLMs and their ensemble on benchmark and real-world datasets. We\nhypothesize that the ensembling of FLMs can influence the individualistic\nattention of FLMs and unravel the strength of coordination and cooperation of\ndifferent FLMs. We utilize BERT and define three other ensemble techniques:\n{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a\nknowledge-guided reinforcement learning approach. We discovered that the\nsuggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by\na factor of many times using datasets that show the usefulness of NLP in\nsensitive fields, such as mental health.",
            "author": [
                "Nancy Tyagi",
                "Aidin Shiri",
                "Surjodeep Sarkar",
                "Abhishek Kumar Umrawal",
                "Manas Gaur"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12272v1",
                "http://arxiv.org/pdf/2308.12272v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12259v3",
            "title": "Data-driven Identification of Parametric Governing Equations of\n  Dynamical Systems Using the Signed Cumulative Distribution Transform",
            "updated": "2023-11-14T19:59:04Z",
            "published": "2023-08-23T17:25:27Z",
            "summary": "This paper presents a novel data-driven approach to identify partial\ndifferential equation (PDE) parameters of a dynamical system. Specifically, we\nadopt a mathematical \"transport\" model for the solution of the dynamical system\nat specific spatial locations that allows us to accurately estimate the model\nparameters, including those associated with structural damage. This is\naccomplished by means of a newly-developed mathematical transform, the signed\ncumulative distribution transform (SCDT), which is shown to convert the general\nnonlinear parameter estimation problem into a simple linear regression. This\napproach has the additional practical advantage of requiring no a priori\nknowledge of the source of the excitation (or, alternatively, the initial\nconditions). By using training data, we devise a coarse regression procedure to\nrecover different PDE parameters from the PDE solution measured at a single\nlocation. Numerical experiments show that the proposed regression procedure is\ncapable of detecting and estimating PDE parameters with superior accuracy\ncompared to a number of recently developed machine learning methods.\nFurthermore, a damage identification experiment conducted on a publicly\navailable dataset provides strong evidence of the proposed method's\neffectiveness in structural health monitoring (SHM) applications. The Python\nimplementation of the proposed system identification technique is integrated as\na part of the software package PyTransKit\n(https://github.com/rohdelab/PyTransKit).",
            "author": [
                "Abu Hasnat Mohammad Rubaiyat",
                "Duy H. Thai",
                "Jonathan M. Nichols",
                "Meredith N. Hutchinson",
                "Samuel P. Wallen",
                "Christina J. Naify",
                "Nathan Geib",
                "Michael R. Haberman",
                "Gustavo K. Rohde"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12259v3",
                "http://arxiv.org/pdf/2308.12259v3"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12234v1",
            "title": "MolGrapher: Graph-based Visual Recognition of Chemical Structures",
            "updated": "2023-08-23T16:16:11Z",
            "published": "2023-08-23T16:16:11Z",
            "summary": "The automatic analysis of chemical literature has immense potential to\naccelerate the discovery of new materials and drugs. Much of the critical\ninformation in patent documents and scientific articles is contained in\nfigures, depicting the molecule structures. However, automatically parsing the\nexact chemical structure is a formidable challenge, due to the amount of\ndetailed information, the diversity of drawing styles, and the need for\ntraining data. In this work, we introduce MolGrapher to recognize chemical\nstructures visually. First, a deep keypoint detector detects the atoms. Second,\nwe treat all candidate atoms and bonds as nodes and put them in a graph. This\nconstruct allows a natural graph representation of the molecule. Last, we\nclassify atom and bond nodes in the graph with a Graph Neural Network. To\naddress the lack of real training data, we propose a synthetic data generation\npipeline producing diverse and realistic results. In addition, we introduce a\nlarge-scale benchmark of annotated real molecule images, USPTO-30K, to spur\nresearch on this critical topic. Extensive experiments on five datasets show\nthat our approach significantly outperforms classical and learning-based\nmethods in most settings. Code, models, and datasets are available.",
            "author": [
                "Lucas Morin",
                "Martin Danelljan",
                "Maria Isabel Agea",
                "Ahmed Nassar",
                "Valery Weber",
                "Ingmar Meijer",
                "Peter Staar",
                "Fisher Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12234v1",
                "http://arxiv.org/pdf/2308.12234v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12221v1",
            "title": "Critical Learning Periods Emerge Even in Deep Linear Networks",
            "updated": "2023-08-23T16:01:50Z",
            "published": "2023-08-23T16:01:50Z",
            "summary": "Critical learning periods are periods early in development where temporary\nsensory deficits can have a permanent effect on behavior and learned\nrepresentations. Despite the radical differences between biological and\nartificial networks, critical learning periods have been empirically observed\nin both systems. This suggests that critical periods may be fundamental to\nlearning and not an accident of biology. Yet, why exactly critical periods\nemerge in deep networks is still an open question, and in particular it is\nunclear whether the critical periods observed in both systems depend on\nparticular architectural or optimization details. To isolate the key underlying\nfactors, we focus on deep linear network models, and show that, surprisingly,\nsuch networks also display much of the behavior seen in biology and artificial\nnetworks, while being amenable to analytical treatment. We show that critical\nperiods depend on the depth of the model and structure of the data\ndistribution. We also show analytically and in simulations that the learning of\nfeatures is tied to competition between sources. Finally, we extend our\nanalysis to multi-task learning to show that pre-training on certain tasks can\ndamage the transfer performance on new tasks, and show how this depends on the\nrelationship between tasks and the duration of the pre-training stage. To the\nbest of our knowledge, our work provides the first analytically tractable model\nthat sheds light into why critical learning periods emerge in biological and\nartificial networks.",
            "author": [
                "Michael Kleinman",
                "Alessandro Achille",
                "Stefano Soatto"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12221v1",
                "http://arxiv.org/pdf/2308.12221v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.NC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12219v2",
            "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and\n  Instruction-Finetuning",
            "updated": "2023-08-25T16:32:31Z",
            "published": "2023-08-23T16:01:12Z",
            "summary": "The recent surge of generative AI has been fueled by the generative power of\ndiffusion probabilistic models and the scalable capabilities of large language\nmodels. Despite their potential, it remains elusive whether diffusion language\nmodels can solve general language tasks comparable to their autoregressive\ncounterparts. This paper demonstrates that scaling diffusion models w.r.t.\ndata, sizes, and tasks can effectively make them strong language learners. We\nbuild competent diffusion language models at scale by first acquiring knowledge\nfrom massive data via masked language modeling pretraining thanks to their\nintrinsic connections. We then reprogram pretrained masked language models into\ndiffusion language models via diffusive adaptation, wherein task-specific\nfinetuning and instruction finetuning are explored to unlock their versatility\nin solving general language tasks. Experiments show that scaling diffusion\nlanguage models consistently improves performance across downstream language\ntasks. We further discover that instruction finetuning can elicit zero-shot and\nfew-shot in-context learning abilities that help tackle many unseen tasks by\nfollowing natural language instructions, and show promise in advanced and\nchallenging abilities such as reasoning.",
            "author": [
                "Jiasheng Ye",
                "Zaixiang Zheng",
                "Yu Bao",
                "Lihua Qian",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12219v2",
                "http://arxiv.org/pdf/2308.12219v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12210v1",
            "title": "ULDP-FL: Federated Learning with Across Silo User-Level Differential\n  Privacy",
            "updated": "2023-08-23T15:50:51Z",
            "published": "2023-08-23T15:50:51Z",
            "summary": "Differentially Private Federated Learning (DP-FL) has garnered attention as a\ncollaborative machine learning approach that ensures formal privacy. Most DP-FL\napproaches ensure DP at the record-level within each silo for cross-silo FL.\nHowever, a single user's data may extend across multiple silos, and the desired\nuser-level DP guarantee for such a setting remains unknown. In this study, we\npresent ULDP-FL, a novel FL framework designed to guarantee user-level DP in\ncross-silo FL where a single user's data may belong to multiple silos. Our\nproposed algorithm directly ensures user-level DP through per-user weighted\nclipping, departing from group-privacy approaches. We provide a theoretical\nanalysis of the algorithm's privacy and utility. Additionally, we enhance the\nalgorithm's utility and showcase its private implementation using cryptographic\nbuilding blocks. Empirical experiments on real-world datasets show substantial\nimprovements in our methods in privacy-utility trade-offs under user-level DP\ncompared to baseline methods. To the best of our knowledge, our work is the\nfirst FL framework that effectively provides user-level DP in the general\ncross-silo FL setting.",
            "author": [
                "Fumiyuki Kato",
                "Li Xiong",
                "Shun Takagi",
                "Yang Cao",
                "Masatoshi Yoshikawa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12210v1",
                "http://arxiv.org/pdf/2308.12210v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12325v1",
            "title": "Predicting Drug Solubility Using Different Machine Learning Methods --\n  Linear Regression Model with Extracted Chemical Features vs Graph\n  Convolutional Neural Network",
            "updated": "2023-08-23T15:35:20Z",
            "published": "2023-08-23T15:35:20Z",
            "summary": "Predicting the solubility of given molecules is an important task in the\npharmaceutical industry, and consequently this is a well-studied topic. In this\nresearch, we revisited this problem with the advantage of modern computing\nresources. We applied two machine learning models, a linear regression model\nand a graph convolutional neural network model, on multiple experimental\ndatasets. Both methods can make reasonable predictions while the GCNN model had\nthe best performance. However, the current GCNN model is a black box, while\nfeature importance analysis from the linear regression model offers more\ninsights into the underlying chemical influences. Using the linear regression\nmodel, we show how each functional group affects the overall solubility.\nUltimately, knowing how chemical structure influences chemical properties is\ncrucial when designing new drugs. Future work should aim to combine the high\nperformance of GCNNs with the interpretability of linear regression, unlocking\nnew advances in next generation high throughput screening.",
            "author": [
                "John Ho",
                "Zhao-Heng Yin",
                "Colin Zhang",
                "Henry Overhauser",
                "Kyle Swanson",
                "Yang Ha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12325v1",
                "http://arxiv.org/pdf/2308.12325v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12193v1",
            "title": "Self-Supervised Knowledge-Driven Deep Learning for 3D Magnetic Inversion",
            "updated": "2023-08-23T15:31:38Z",
            "published": "2023-08-23T15:31:38Z",
            "summary": "The magnetic inversion method is one of the non-destructive geophysical\nmethods, which aims to estimate the subsurface susceptibility distribution from\nsurface magnetic anomaly data. Recently, supervised deep learning methods have\nbeen widely utilized in lots of geophysical fields including magnetic\ninversion. However, these methods rely heavily on synthetic training data,\nwhose performance is limited since the synthetic data is not independently and\nidentically distributed with the field data. Thus, we proposed to realize\nmagnetic inversion by self-supervised deep learning. The proposed\nself-supervised knowledge-driven 3D magnetic inversion method (SSKMI) learns on\nthe target field data by a closed loop of the inversion and forward models.\nGiven that the parameters of the forward model are preset, SSKMI can optimize\nthe inversion model by minimizing the mean absolute error between observed and\nre-estimated surface magnetic anomalies. Besides, there is a knowledge-driven\nmodule in the proposed inversion model, which makes the deep learning method\nmore explicable. Meanwhile, comparative experiments demonstrate that the\nknowledge-driven module can accelerate the training of the proposed method and\nachieve better results. Since magnetic inversion is an ill-pose task, SSKMI\nproposed to constrain the inversion model by a guideline in the auxiliary loop.\nThe experimental results demonstrate that the proposed method is a reliable\nmagnetic inversion method with outstanding performance.",
            "author": [
                "Yinshuo Li",
                "Zhuo Jia",
                "Wenkai Lu",
                "Cao Song"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12193v1",
                "http://arxiv.org/pdf/2308.12193v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12191v1",
            "title": "Sign Language Translation with Iterative Prototype",
            "updated": "2023-08-23T15:27:50Z",
            "published": "2023-08-23T15:27:50Z",
            "summary": "This paper presents IP-SLT, a simple yet effective framework for sign\nlanguage translation (SLT). Our IP-SLT adopts a recurrent structure and\nenhances the semantic representation (prototype) of the input sign language\nvideo via an iterative refinement manner. Our idea mimics the behavior of human\nreading, where a sentence can be digested repeatedly, till reaching accurate\nunderstanding. Technically, IP-SLT consists of feature extraction, prototype\ninitialization, and iterative prototype refinement. The initialization module\ngenerates the initial prototype based on the visual feature extracted by the\nfeature extraction module. Then, the iterative refinement module leverages the\ncross-attention mechanism to polish the previous prototype by aggregating it\nwith the original video feature. Through repeated refinement, the prototype\nfinally converges to a more stable and accurate state, leading to a fluent and\nappropriate translation. In addition, to leverage the sequential dependence of\nprototypes, we further propose an iterative distillation loss to compress the\nknowledge of the final iteration into previous ones. As the autoregressive\ndecoding process is executed only once in inference, our IP-SLT is ready to\nimprove various SLT systems with acceptable overhead. Extensive experiments are\nconducted on public benchmarks to demonstrate the effectiveness of the IP-SLT.",
            "author": [
                "Huijie Yao",
                "Wengang Zhou",
                "Hao Feng",
                "Hezhen Hu",
                "Hao Zhou",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12191v1",
                "http://arxiv.org/pdf/2308.12191v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12190v1",
            "title": "The Hereditary Closure of the Unigraphs",
            "updated": "2023-08-23T15:26:51Z",
            "published": "2023-08-23T15:26:51Z",
            "summary": "A graph with degree sequence $\\pi$ is a \\emph{unigraph} if it is isomorphic\nto every graph that has degree sequence $\\pi$. The class of unigraphs is not\nhereditary and in this paper we study the related hereditary class HCU, the\nhereditary closure of unigraphs, consisting of all graphs induced in a\nunigraph. We characterize the class HCU in multiple ways making use of the\ntools of a decomposition due to Tyshkevich and a partial order on degree\nsequences due to Rao. We also provide a new characterization of the class that\nconsists of unigraphs for which all induced subgraphs are also unigraphs.",
            "author": [
                "Michael D. Barrus",
                "Ann N. Trenk",
                "Rebecca Whitman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12190v1",
                "http://arxiv.org/pdf/2308.12190v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C07, 05C75"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12185v1",
            "title": "Profinite Subgroup Accessibility and Recognition of Amalgamated Factors",
            "updated": "2023-08-23T15:16:22Z",
            "published": "2023-08-23T15:16:22Z",
            "summary": "We investigate accessible subgroups of a profinite group $G$, i.e. subgroups\n$H$ appearing as vertex groups in a graph of profinite groups decomposition of\n$G$ with finite edge groups. We prove that any accessible subgroup $H \\leq G$\narises as the kernel of a continuous derivation of $G$ in a free module over\nits completed group algebra. This allows us to deduce splittings of an abstract\ngroup from splittings of its profinite completion. We prove that any finitely\ngenerated subgroup $\\Delta$ of a finitely generated virtually free group\n$\\Gamma$ whose closure is a factor in a profinite amalgamated product\n$\\widehat{\\Gamma} = \\overline{\\Delta} \\amalg_K L$ along a finite $K$ must be a\nfactor in an amalgamated product $\\Gamma = \\Delta \\ast_\\chi \\Lambda$ along some\n$\\chi \\cong K$. This extends previous results of Parzanchevski--Puder, Wilton\nand Garrido--Jaikin-Zapirain on free factors.",
            "author": [
                "Julian Wykowski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12185v1",
                "http://arxiv.org/pdf/2308.12185v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "20E18 20E08"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12177v1",
            "title": "On the Existence of EFX (and Pareto-Optimal) Allocations for Binary\n  Chores",
            "updated": "2023-08-23T14:56:53Z",
            "published": "2023-08-23T14:56:53Z",
            "summary": "We study the problem of allocating a group of indivisible chores among agents\nwhile each chore has a binary marginal. We focus on the fairness criteria of\nenvy-freeness up to any item (EFX) and investigate the existence of EFX\nallocations. We show that when agents have additive binary cost functions,\nthere exist EFX and Pareto-optimal (PO) allocations that can be computed in\npolynomial time. To the best of our knowledge, this is the first setting of a\ngeneral number of agents that admits EFX and PO allocations, before which EFX\nand PO allocations have only been shown to exist for three bivalued agents. We\nfurther consider more general cost functions: cancelable and general monotone\n(both with binary marginal). We show that EFX allocations exist and can be\ncomputed for binary cancelable chores, but EFX is incompatible with PO. For\ngeneral binary marginal functions, we propose an algorithm that computes\n(partial) envy-free (EF) allocations with at most $n-1$ unallocated items.",
            "author": [
                "Biaoshuai Tao",
                "Xiaowei Wu",
                "Ziqi Yu",
                "Shengwei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12177v1",
                "http://arxiv.org/pdf/2308.12177v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12165v1",
            "title": "Assignment Based Metrics for Attributed Graphs",
            "updated": "2023-08-23T14:31:30Z",
            "published": "2023-08-23T14:31:30Z",
            "summary": "We introduce the Graph TT (GTT) and Graph OSPA (GOSPA) metrics based on\noptimal assignment, which allow us to compare not only the edge structures but\nalso general vertex and edge attributes of graphs of possibly different sizes.\nWe argue that this provides an intuitive and universal way to measure the\ndistance between finite simple attributed graphs. Our paper discusses useful\nequivalences and inequalities as well as the relation of the new metrics to\nvarious existing quantifications of distance between graphs. By deriving a\nrepresentation of a graph as a pair of point processes, we are able to\nformulate and study a new type of (finite) random graph convergence and\ndemonstrate its applicability using general point processes of vertices with\nindependent random edges. Computational aspects of the new metrics are studied\nin the form of an exact and two heuristic algorithms that are derived from\nprevious algorithms for similar tasks. As an application, we perform a\nstatistical test based on the GOSPA metric for functional differences in\nolfactory neurons of Drosophila flies.",
            "author": [
                "Dominic Schuhmacher",
                "Leoni Carla Wirth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12165v1",
                "http://arxiv.org/pdf/2308.12165v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CO",
                "Primary 05C99, Secondary 60B99, 05C80, 60B10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12159v1",
            "title": "On bicyclic graphs with maximal Graovac-Ghorbani index",
            "updated": "2023-08-23T14:20:29Z",
            "published": "2023-08-23T14:20:29Z",
            "summary": "Graovac-Ghorbani index is a new version of the atom-bond connectivity index.\nD. Pacheco et al. [D. Pacheco, L. de Lima, C. S. Oliveira, On the\nGraovac-Ghorbani Index for Bicyclic Graph with No Pendent Vertices, MATCH\nCommun. Math. Comput. Chem. 86 (2021) 429-448] conjectured a sharp lower and\nupper bounds to the Graovac-Ghorbani index for all bicyclic graphs. Motivated\nby their nice work, in this paper we determine the maximal Graovac-Ghorbani\nindex of bicyclic graphs and characterize the corresponding extremal graphs,\nwhich solves one of their Conjectures.",
            "author": [
                "Rui Song",
                "Saihua Liu",
                "Jianping Ou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12159v1",
                "http://arxiv.org/pdf/2308.12159v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12149v1",
            "title": "First passage percolation on Erd\u0151s-R\u00e9nyi graphs with general\n  weights",
            "updated": "2023-08-23T14:07:19Z",
            "published": "2023-08-23T14:07:19Z",
            "summary": "We consider first passage percolation on the Erd\\H{o}s-R\\'{e}nyi graph with\n$n$ vertices in which each pair of distinct vertices is connected independently\nby an edge with probability $\\lambda/n$ for some $\\lambda>1$. The edges of the\ngraph are given non-negative i.i.d. weights with a non-degenerate distribution\nsuch that the probability of zero is not too large. We consider the paths with\nsmall total weight between two distinct typical vertices and analyse the joint\nbehaviour of the numbers of edges on such paths, the so-called hopcounts, and\nthe total weights of these paths. For $n\\to\\infty$, we show that, after a\nsuitable transformation, the pairs of hopcounts and total weights of these\npaths converge in distribution to a Cox process, i.e., a Poisson process with a\nrandom intensity measure. The random intensity measure is controlled by two\nindependent random variables, whose distribution is the solution of a\ndistributional fixed point equation and is related to branching processes. For\nnon-arithmetic and arithmetic edge weight distributions we observe different\nbehaviour. In particular, we derive the limiting distribution for the minimal\ntotal weight and the corresponding hopcount(s). Our results generalise earlier\nwork of Bhamidi, van der Hofstad and Hooghiemstra, who assume edge weights are\nexponentially distributed. The main tool we employ is the method of moments.",
            "author": [
                "Fraser Daly",
                "Matthias Schulte",
                "Seva Shneer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12149v1",
                "http://arxiv.org/pdf/2308.12149v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60F05, 05C80 (Primary) 60C05, 60G55 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12112v1",
            "title": "Generalized Continual Category Discovery",
            "updated": "2023-08-23T13:02:52Z",
            "published": "2023-08-23T13:02:52Z",
            "summary": "Most of Continual Learning (CL) methods push the limit of supervised learning\nsettings, where an agent is expected to learn new labeled tasks and not forget\nprevious knowledge. However, these settings are not well aligned with real-life\nscenarios, where a learning agent has access to a vast amount of unlabeled data\nencompassing both novel (entirely unlabeled) classes and examples from known\nclasses. Drawing inspiration from Generalized Category Discovery (GCD), we\nintroduce a novel framework that relaxes this assumption. Precisely, in any\ntask, we allow for the existence of novel and known classes, and one must use\ncontinual version of unsupervised learning methods to discover them. We call\nthis setting Generalized Continual Category Discovery (GCCD). It unifies CL and\nGCD, bridging the gap between synthetic benchmarks and real-life scenarios.\nWith a series of experiments, we present that existing methods fail to\naccumulate knowledge from subsequent tasks in which unlabeled samples of novel\nclasses are present. In light of these limitations, we propose a method that\nincorporates both supervised and unsupervised signals and mitigates the\nforgetting through the use of centroid adaptation. Our method surpasses strong\nCL methods adopted for GCD techniques and presents a superior representation\nlearning performance.",
            "author": [
                "Daniel Marczak",
                "Grzegorz Rype\u015b\u0107",
                "Sebastian Cygert",
                "Tomasz Trzci\u0144ski",
                "Bart\u0142omiej Twardowski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12112v1",
                "http://arxiv.org/pdf/2308.12112v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.07096v2",
            "title": "The legibility of the imaged human brain",
            "updated": "2023-11-09T13:50:54Z",
            "published": "2023-08-23T12:37:13Z",
            "summary": "Our knowledge of the organisation of the human brain at the population-level\nis yet to translate into power to predict functional differences at the\nindividual-level, limiting clinical applications, and casting doubt on the\ngeneralisability of inferred mechanisms. It remains unknown whether the\ndifficulty arises from the absence of individuating biological patterns within\nthe brain, or from limited power to access them with the models and compute at\nour disposal. Here we comprehensively investigate the resolvability of such\npatterns with data and compute at unprecedented scale. Across 23810 unique\nparticipants from UK Biobank, we systematically evaluate the predictability of\n25 individual biological characteristics, from all available combinations of\nstructural and functional neuroimaging data. Over 4526 GPU*hours of\ncomputation, we train, optimize, and evaluate out-of-sample 700 individual\npredictive models, including multilayer perceptrons of demographic,\npsychological, serological, chronic morbidity, and functional connectivity\ncharacteristics, and both uni- and multi-modal 3D convolutional neural network\nmodels of macro- and micro-structural brain imaging. We find a marked\ndiscrepancy between the high predictability of sex (balanced accuracy 99.7%),\nage (mean absolute error 2.048 years, R2 0.859), and weight (mean absolute\nerror 2.609Kg, R2 0.625), for which we set new state-of-the-art performance,\nand the surprisingly low predictability of other characteristics. Neither\nstructural nor functional imaging predicted individual psychology better than\nthe coincidence of common chronic morbidity (p<0.05). Serology predicted common\nmorbidity (p<0.05) and was best predicted by it (p<0.001), followed by\nstructural neuroimaging (p<0.05). Our findings suggest either more informative\nimaging or more powerful models will be needed to decipher individual level\ncharacteristics from the brain.",
            "author": [
                "James K Ruffle",
                "Robert J Gray",
                "Samia Mohinta",
                "Guilherme Pombo",
                "Chaitanya Kaul",
                "Harpreet Hyare",
                "Geraint Rees",
                "Parashkev Nachev"
            ],
            "link": [
                "http://arxiv.org/abs/2309.07096v2",
                "http://arxiv.org/pdf/2309.07096v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12322v1",
            "title": "Fine-grained Spatio-Temporal Distribution Prediction of Mobile Content\n  Delivery in 5G Ultra-Dense Networks",
            "updated": "2023-08-23T12:34:30Z",
            "published": "2023-08-23T12:34:30Z",
            "summary": "The 5G networks have extensively promoted the growth of mobile users and\nnovel applications, and with the skyrocketing user requests for a large amount\nof popular content, the consequent content delivery services (CDSs) have been\nbringing a heavy load to mobile service providers. As a key mission in\nintelligent networks management, understanding and predicting the distribution\nof CDSs benefits many tasks of modern network services such as resource\nprovisioning and proactive content caching for content delivery networks.\nHowever, the revolutions in novel ubiquitous network architectures led by\nultra-dense networks (UDNs) make the task extremely challenging. Specifically,\nconventional methods face the challenges of insufficient spatio precision,\nlacking generalizability, and complex multi-feature dependencies of user\nrequests, making their effectiveness unreliable in CDSs prediction under 5G\nUDNs. In this paper, we propose to adopt a series of encoding and sampling\nmethods to model CDSs of known and unknown areas at a tailored fine-grained\nlevel. Moreover, we design a spatio-temporal-social multi-feature extraction\nframework for CDSs hotspots prediction, in which a novel edge-enhanced graph\nconvolution block is proposed to encode dynamic CDSs networks based on the\nsocial relationships and the spatio features. Besides, we introduce the\nLong-Short Term Memory (LSTM) to further capture the temporal dependency.\nExtensive performance evaluations with real-world measurement data collected in\ntwo mobile content applications demonstrate the effectiveness of our proposed\nsolution, which can improve the prediction area under the curve (AUC) by 40.5%\ncompared to the state-of-the-art proposals at a spatio granularity of 76m, with\nup to 80% of the unknown areas.",
            "author": [
                "Shaoyuan Huang",
                "Heng Zhang",
                "Xiaofei Wang",
                "Min Chen",
                "Jianxin Li",
                "Victor C. M. Leung"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12322v1",
                "http://arxiv.org/pdf/2308.12322v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12095v2",
            "title": "On Using Information Retrieval to Recommend Machine Learning Good\n  Practices for Software Engineers",
            "updated": "2023-08-25T08:05:52Z",
            "published": "2023-08-23T12:28:18Z",
            "summary": "Machine learning (ML) is nowadays widely used for different purposes and in\nseveral disciplines. From self-driving cars to automated medical diagnosis,\nmachine learning models extensively support users' daily activities, and\nsoftware engineering tasks are no exception. Not embracing good ML practices\nmay lead to pitfalls that hinder the performance of an ML system and\npotentially lead to unexpected results. Despite the existence of documentation\nand literature about ML best practices, many non-ML experts turn towards gray\nliterature like blogs and Q&A systems when looking for help and guidance when\nimplementing ML systems. To better aid users in distilling relevant knowledge\nfrom such sources, we propose a recommender system that recommends ML practices\nbased on the user's context. As a first step in creating a recommender system\nfor machine learning practices, we implemented Idaka. A tool that provides two\ndifferent approaches for retrieving/generating ML best practices: i) an\ninformation retrieval (IR) engine and ii) a large language model. The IR-engine\nuses BM25 as the algorithm for retrieving the practices, and a large language\nmodel, in our case Alpaca. The platform has been designed to allow comparative\nstudies of best practices retrieval tools. Idaka is publicly available at\nGitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM.",
            "author": [
                "Laura Cabra-Acela",
                "Anamaria Mojica-Hanke",
                "Mario Linares-V\u00e1squez",
                "Steffen Herbold"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12095v2",
                "http://arxiv.org/pdf/2308.12095v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12093v1",
            "title": "Cached Operator Reordering: A Unified View for Fast GNN Training",
            "updated": "2023-08-23T12:27:55Z",
            "published": "2023-08-23T12:27:55Z",
            "summary": "Graph Neural Networks (GNNs) are a powerful tool for handling structured\ngraph data and addressing tasks such as node classification, graph\nclassification, and clustering. However, the sparse nature of GNN computation\nposes new challenges for performance optimization compared to traditional deep\nneural networks. We address these challenges by providing a unified view of GNN\ncomputation, I/O, and memory. By analyzing the computational graphs of the\nGraph Convolutional Network (GCN) and Graph Attention (GAT) layers -- two\nwidely used GNN layers -- we propose alternative computation strategies. We\npresent adaptive operator reordering with caching, which achieves a speedup of\nup to 2.43x for GCN compared to the current state-of-the-art. Furthermore, an\nexploration of different caching schemes for GAT yields a speedup of up to\n1.94x. The proposed optimizations save memory, are easily implemented across\nvarious hardware platforms, and have the potential to alleviate performance\nbottlenecks in training large-scale GNN models.",
            "author": [
                "Julia Bazinska",
                "Andrei Ivanov",
                "Tal Ben-Nun",
                "Nikoli Dryden",
                "Maciej Besta",
                "Siyuan Shen",
                "Torsten Hoefler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12093v1",
                "http://arxiv.org/pdf/2308.12093v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12083v1",
            "title": "Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in\n  Recommender Systems",
            "updated": "2023-08-23T12:05:48Z",
            "published": "2023-08-23T12:05:48Z",
            "summary": "In recommendation literature, explainability and fairness are becoming two\nprominent perspectives to consider. However, prior works have mostly addressed\nthem separately, for instance by explaining to consumers why a certain item was\nrecommended or mitigating disparate impacts in recommendation utility. None of\nthem has leveraged explainability techniques to inform unfairness mitigation.\nIn this paper, we propose an approach that relies on counterfactual\nexplanations to augment the set of user-item interactions, such that using them\nwhile inferring recommendations leads to fairer outcomes. Modeling user-item\ninteractions as a bipartite graph, our approach augments the latter by\nidentifying new user-item edges that not only can explain the original\nunfairness by design, but can also mitigate it. Experiments on two public data\nsets show that our approach effectively leads to a better trade-off between\nfairness and recommendation utility compared with state-of-the-art mitigation\nprocedures. We further analyze the characteristics of added edges to highlight\nkey unfairness patterns. Source code available at\nhttps://github.com/jackmedda/RS-BGExplainer/tree/cikm2023.",
            "author": [
                "Ludovico Boratto",
                "Francesco Fabbri",
                "Gianni Fenu",
                "Mirko Marras",
                "Giacomo Medda"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12083v1",
                "http://arxiv.org/pdf/2308.12083v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12074v1",
            "title": "Video Analysis of Behavioral Patterns During Prolonged Work in VR",
            "updated": "2023-08-23T11:44:43Z",
            "published": "2023-08-23T11:44:43Z",
            "summary": "VR has recently been promoted as a tool for knowledge workers and studies\nhave shown that it has the potential to improve knowledge work. However,\nstudies on its prolonged use have been scarce. A prior study compared working\nin VR for one week to working in a physical environment, focusing on\nperformance measures and subjective feedback. However, a nuanced understanding\nand comparison of participants' behavior in VR and the physical environment is\nstill missing. To this end, we analyzed video material made available from this\npreviously conducted experiment, carried out over a working week, and present\nour findings on comparing the behavior of participants while working in VR and\nin a physical environment.",
            "author": [
                "Verena Biener",
                "Forouzan Farzinnejad",
                "Rinaldo Schuster",
                "Seyedmasih Tabaei",
                "Leon Lindlein",
                "Jinghui Hu",
                "Negar Nouri",
                "John J. Dudley",
                "Per Ola Kristensson",
                "J\u00f6rg M\u00fcller",
                "Jens Grubert"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12074v1",
                "http://arxiv.org/pdf/2308.12074v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "I.3.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12319v3",
            "title": "RemovalNet: DNN Fingerprint Removal Attacks",
            "updated": "2023-11-22T05:52:25Z",
            "published": "2023-08-23T11:31:38Z",
            "summary": "With the performance of deep neural networks (DNNs) remarkably improving,\nDNNs have been widely used in many areas. Consequently, the DNN model has\nbecome a valuable asset, and its intellectual property is safeguarded by\nownership verification techniques (e.g., DNN fingerprinting). However, the\nfeasibility of the DNN fingerprint removal attack and its potential influence\nremains an open problem. In this paper, we perform the first comprehensive\ninvestigation of DNN fingerprint removal attacks. Generally, the knowledge\ncontained in a DNN model can be categorized into general semantic and\nfingerprint-specific knowledge. To this end, we propose a min-max bilevel\noptimization-based DNN fingerprint removal attack named RemovalNet, to evade\nmodel ownership verification. The lower-level optimization is designed to\nremove fingerprint-specific knowledge. While in the upper-level optimization,\nwe distill the victim model's general semantic knowledge to maintain the\nsurrogate model's performance. We conduct extensive experiments to evaluate the\nfidelity, effectiveness, and efficiency of the RemovalNet against four advanced\ndefense methods on six metrics. The empirical results demonstrate that (1) the\nRemovalNet is effective. After our DNN fingerprint removal attack, the model\ndistance between the target and surrogate models is x100 times higher than that\nof the baseline attacks, (2) the RemovalNet is efficient. It uses only 0.2%\n(400 samples) of the substitute dataset and 1,000 iterations to conduct our\nattack. Besides, compared with advanced model stealing attacks, the RemovalNet\nsaves nearly 85% of computational resources at most, (3) the RemovalNet\nachieves high fidelity that the created surrogate model maintains high accuracy\nafter the DNN fingerprint removal process. Our code is available at:\nhttps://github.com/grasses/RemovalNet.",
            "author": [
                "Hongwei Yao",
                "Zheng Li",
                "Kunzhe Huang",
                "Jian Lou",
                "Zhan Qin",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12319v3",
                "http://arxiv.org/pdf/2308.12319v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12061v1",
            "title": "HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using\n  Harvest Piles and Remote Sensing",
            "updated": "2023-08-23T11:03:28Z",
            "published": "2023-08-23T11:03:28Z",
            "summary": "Small farms contribute to a large share of the productive land in developing\ncountries. In regions such as sub-Saharan Africa, where 80% of farms are small\n(under 2 ha in size), the task of mapping smallholder cropland is an important\npart of tracking sustainability measures such as crop productivity. However,\nthe visually diverse and nuanced appearance of small farms has limited the\neffectiveness of traditional approaches to cropland mapping. Here we introduce\na new approach based on the detection of harvest piles characteristic of many\nsmallholder systems throughout the world. We present HarvestNet, a dataset for\nmapping the presence of farms in the Ethiopian regions of Tigray and Amhara\nduring 2020-2023, collected using expert knowledge and satellite images,\ntotaling 7k hand-labeled images and 2k ground collected labels. We also\nbenchmark a set of baselines including SOTA models in remote sensing with our\nbest models having around 80% classification performance on hand labelled data\nand 90%, 98% accuracy on ground truth data for Tigray, Amhara respectively. We\nalso perform a visual comparison with a widely used pre-existing coverage map\nand show that our model detects an extra 56,621 hectares of cropland in Tigray.\nWe conclude that remote sensing of harvest piles can contribute to more timely\nand accurate cropland assessments in food insecure region.",
            "author": [
                "Jonathan Xu",
                "Amna Elmustafa",
                "Liya Weldegebriel",
                "Emnet Negash",
                "Richard Lee",
                "Chenlin Meng",
                "Stefano Ermon",
                "David Lobell"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12061v1",
                "http://arxiv.org/pdf/2308.12061v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12060v1",
            "title": "FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base\n  Question Answering",
            "updated": "2023-08-23T11:00:36Z",
            "published": "2023-08-23T11:00:36Z",
            "summary": "Knowledge base question answering (KBQA) is a critical yet challenging task\ndue to the vast number of entities within knowledge bases and the diversity of\nnatural language questions posed by users. Unfortunately, the performance of\nmost KBQA models tends to decline significantly in real-world scenarios where\nhigh-quality annotated data is insufficient. To mitigate the burden associated\nwith manual annotation, we introduce FlexKBQA by utilizing Large Language\nModels (LLMs) as program translators for addressing the challenges inherent in\nthe few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms\nto sample diverse programs, such as SPARQL queries, from the knowledge base,\nwhich are subsequently converted into natural language questions via LLMs. This\nsynthetic dataset facilitates training a specialized lightweight model for the\nKB. Additionally, to reduce the barriers of distribution shift between\nsynthetic data and real user questions, FlexKBQA introduces an executionguided\nself-training method to iterative leverage unlabeled user questions.\nFurthermore, we explore harnessing the inherent reasoning capability of LLMs to\nenhance the entire framework. Consequently, FlexKBQA delivers substantial\nflexibility, encompassing data annotation, deployment, and being domain\nagnostic. Through extensive experiments on GrailQA, WebQSP, and KQA Pro, we\nobserve that under the few-shot even the more challenging zero-shot scenarios,\nFlexKBQA achieves impressive results with a few annotations, surpassing all\nprevious baselines and even approaching the performance of supervised models,\nachieving a remarkable 93% performance relative to the fully-supervised models.\nWe posit that FlexKBQA represents a significant advancement towards exploring\nbetter integration of large and lightweight models. The code is open-sourced.",
            "author": [
                "Zhenyu Li",
                "Sunqi Fan",
                "Yu Gu",
                "Xiuxing Li",
                "Zhichao Duan",
                "Bowen Dong",
                "Ning Liu",
                "Jianyong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12060v1",
                "http://arxiv.org/pdf/2308.12060v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12058v1",
            "title": "DR-Tune: Improving Fine-tuning of Pretrained Visual Models by\n  Distribution Regularization with Semantic Calibration",
            "updated": "2023-08-23T10:59:20Z",
            "published": "2023-08-23T10:59:20Z",
            "summary": "The visual models pretrained on large-scale benchmarks encode general\nknowledge and prove effective in building more powerful representations for\ndownstream tasks. Most existing approaches follow the fine-tuning paradigm,\neither by initializing or regularizing the downstream model based on the\npretrained one. The former fails to retain the knowledge in the successive\nfine-tuning phase, thereby prone to be over-fitting, and the latter imposes\nstrong constraints to the weights or feature maps of the downstream model\nwithout considering semantic drift, often incurring insufficient optimization.\nTo deal with these issues, we propose a novel fine-tuning framework, namely\ndistribution regularization with semantic calibration (DR-Tune). It employs\ndistribution regularization by enforcing the downstream task head to decrease\nits classification error on the pretrained feature distribution, which prevents\nit from over-fitting while enabling sufficient training of downstream encoders.\nFurthermore, to alleviate the interference by semantic drift, we develop the\nsemantic calibration (SC) module to align the global shape and class centers of\nthe pretrained and downstream feature distributions. Extensive experiments on\nwidely used image classification datasets show that DR-Tune consistently\nimproves the performance when combing with various backbones under different\npretraining strategies. Code is available at:\nhttps://github.com/weeknan/DR-Tune.",
            "author": [
                "Nan Zhou",
                "Jiaxin Chen",
                "Di Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12058v1",
                "http://arxiv.org/pdf/2308.12058v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12053v1",
            "title": "Layer-wise Feedback Propagation",
            "updated": "2023-08-23T10:48:28Z",
            "published": "2023-08-23T10:48:28Z",
            "summary": "In this paper, we present Layer-wise Feedback Propagation (LFP), a novel\ntraining approach for neural-network-like predictors that utilizes\nexplainability, specifically Layer-wise Relevance Propagation(LRP), to assign\nrewards to individual connections based on their respective contributions to\nsolving a given task. This differs from traditional gradient descent, which\nupdates parameters towards anestimated loss minimum. LFP distributes a reward\nsignal throughout the model without the need for gradient computations. It then\nstrengthens structures that receive positive feedback while reducingthe\ninfluence of structures that receive negative feedback. We establish the\nconvergence of LFP theoretically and empirically, and demonstrate its\neffectiveness in achieving comparable performance to gradient descent on\nvarious models and datasets. Notably, LFP overcomes certain limitations\nassociated with gradient-based methods, such as reliance on meaningful\nderivatives. We further investigate how the different LRP-rules can be extended\nto LFP, what their effects are on training, as well as potential applications,\nsuch as training models with no meaningful derivatives, e.g., step-function\nactivated Spiking Neural Networks (SNNs), or for transfer learning, to\nefficiently utilize existing knowledge.",
            "author": [
                "Leander Weber",
                "Jim Berend",
                "Alexander Binder",
                "Thomas Wiegand",
                "Wojciech Samek",
                "Sebastian Lapuschkin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12053v1",
                "http://arxiv.org/pdf/2308.12053v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "68T05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12048v1",
            "title": "Head-Tail Cooperative Learning Network for Unbiased Scene Graph\n  Generation",
            "updated": "2023-08-23T10:29:25Z",
            "published": "2023-08-23T10:29:25Z",
            "summary": "Scene Graph Generation (SGG) as a critical task in image understanding,\nfacing the challenge of head-biased prediction caused by the long-tail\ndistribution of predicates. However, current unbiased SGG methods can easily\nprioritize improving the prediction of tail predicates while ignoring the\nsubstantial sacrifice in the prediction of head predicates, leading to a shift\nfrom head bias to tail bias. To address this issue, we propose a model-agnostic\nHead-Tail Collaborative Learning (HTCL) network that includes head-prefer and\ntail-prefer feature representation branches that collaborate to achieve\naccurate recognition of both head and tail predicates. We also propose a\nself-supervised learning approach to enhance the prediction ability of the\ntail-prefer feature representation branch by constraining tail-prefer predicate\nfeatures. Specifically, self-supervised learning converges head predicate\nfeatures to their class centers while dispersing tail predicate features as\nmuch as possible through contrast learning and head center loss. We demonstrate\nthe effectiveness of our HTCL by applying it to various SGG models on VG150,\nOpen Images V6 and GQA200 datasets. The results show that our method achieves\nhigher mean Recall with a minimal sacrifice in Recall and achieves a new\nstate-of-the-art overall performance. Our code is available at\nhttps://github.com/wanglei0618/HTCL.",
            "author": [
                "Lei Wang",
                "Zejian Yuan",
                "Yao Lu",
                "Badong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12048v1",
                "http://arxiv.org/pdf/2308.12048v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12044v3",
            "title": "A multiobjective continuation method to compute the regularization path\n  of deep neural networks",
            "updated": "2023-09-19T13:57:06Z",
            "published": "2023-08-23T10:08:52Z",
            "summary": "Sparsity is a highly desired feature in deep neural networks (DNNs) since it\nensures numerical efficiency, improves the interpretability of models (due to\nthe smaller number of relevant features), and robustness. In machine learning\napproaches based on linear models, it is well known that there exists a\nconnecting path between the sparsest solution in terms of the $\\ell^1$ norm\n(i.e., zero weights) and the non-regularized solution, which is called the\nregularization path. Very recently, there was a first attempt to extend the\nconcept of regularization paths to DNNs by means of treating the empirical loss\nand sparsity ($\\ell^1$ norm) as two conflicting criteria and solving the\nresulting multiobjective optimization problem. However, due to the\nnon-smoothness of the $\\ell^1$ norm and the high number of parameters, this\napproach is not very efficient from a computational perspective. To overcome\nthis limitation, we present an algorithm that allows for the approximation of\nthe entire Pareto front for the above-mentioned objectives in a very efficient\nmanner. We present numerical examples using both deterministic and stochastic\ngradients. We furthermore demonstrate that knowledge of the regularization path\nallows for a well-generalizing network parametrization.",
            "author": [
                "Augustina C. Amakor",
                "Konstantin Sonntag",
                "Sebastian Peitz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12044v3",
                "http://arxiv.org/pdf/2308.12044v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12028v1",
            "title": "LKPNR: LLM and KG for Personalized News Recommendation Framework",
            "updated": "2023-08-23T09:39:18Z",
            "published": "2023-08-23T09:39:18Z",
            "summary": "Accurately recommending candidate news articles to users is a basic challenge\nfaced by personalized news recommendation systems. Traditional methods are\nusually difficult to grasp the complex semantic information in news texts,\nresulting in unsatisfactory recommendation results. Besides, these traditional\nmethods are more friendly to active users with rich historical behaviors.\nHowever, they can not effectively solve the \"long tail problem\" of inactive\nusers. To address these issues, this research presents a novel general\nframework that combines Large Language Models (LLM) and Knowledge Graphs (KG)\ninto semantic representations of traditional methods. In order to improve\nsemantic understanding in complex news texts, we use LLMs' powerful text\nunderstanding ability to generate news representations containing rich semantic\ninformation. In addition, our method combines the information about news\nentities and mines high-order structural information through multiple hops in\nKG, thus alleviating the challenge of long tail distribution. Experimental\nresults demonstrate that compared with various traditional models, the\nframework significantly improves the recommendation effect. The successful\nintegration of LLM and KG in our framework has established a feasible path for\nachieving more accurate personalized recommendations in the news field. Our\ncode is available at https://github.com/Xuan-ZW/LKPNR.",
            "author": [
                "Chen hao",
                "Xie Runfeng",
                "Cui Xiangyang",
                "Yan Zhou",
                "Wang Xin",
                "Xuan Zhanwei",
                "Zhang Kai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12028v1",
                "http://arxiv.org/pdf/2308.12028v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12025v1",
            "title": "Knowledge-injected Prompt Learning for Chinese Biomedical Entity\n  Normalization",
            "updated": "2023-08-23T09:32:40Z",
            "published": "2023-08-23T09:32:40Z",
            "summary": "The Biomedical Entity Normalization (BEN) task aims to align raw,\nunstructured medical entities to standard entities, thus promoting data\ncoherence and facilitating better downstream medical applications. Recently,\nprompt learning methods have shown promising results in this task. However,\nexisting research falls short in tackling the more complex Chinese BEN task,\nespecially in the few-shot scenario with limited medical data, and the vast\npotential of the external medical knowledge base has yet to be fully harnessed.\nTo address these challenges, we propose a novel Knowledge-injected Prompt\nLearning (PL-Knowledge) method. Specifically, our approach consists of five\nstages: candidate entity matching, knowledge extraction, knowledge encoding,\nknowledge injection, and prediction output. By effectively encoding the\nknowledge items contained in medical entities and incorporating them into our\ntailor-made knowledge-injected templates, the additional knowledge enhances the\nmodel's ability to capture latent relationships between medical entities, thus\nachieving a better match with the standard entities. We extensively evaluate\nour model on a benchmark dataset in both few-shot and full-scale scenarios. Our\nmethod outperforms existing baselines, with an average accuracy boost of\n12.96\\% in few-shot and 0.94\\% in full-data cases, showcasing its excellence in\nthe BEN task.",
            "author": [
                "Songhua Yang",
                "Chenghao Zhang",
                "Hongfei Xu",
                "Yuxiang Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12025v1",
                "http://arxiv.org/pdf/2308.12025v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12316v1",
            "title": "Graph Neural Stochastic Differential Equations",
            "updated": "2023-08-23T09:20:38Z",
            "published": "2023-08-23T09:20:38Z",
            "summary": "We present a novel model Graph Neural Stochastic Differential Equations\n(Graph Neural SDEs). This technique enhances the Graph Neural Ordinary\nDifferential Equations (Graph Neural ODEs) by embedding randomness into data\nrepresentation using Brownian motion. This inclusion allows for the assessment\nof prediction uncertainty, a crucial aspect frequently missed in current\nmodels. In our framework, we spotlight the \\textit{Latent Graph Neural SDE}\nvariant, demonstrating its effectiveness. Through empirical studies, we find\nthat Latent Graph Neural SDEs surpass conventional models like Graph\nConvolutional Networks and Graph Neural ODEs, especially in confidence\nprediction, making them superior in handling out-of-distribution detection\nacross both static and spatio-temporal contexts.",
            "author": [
                "Richard Bergna",
                "Felix Opolka",
                "Pietro Li\u00f2",
                "Jose Miguel Hernandez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12316v1",
                "http://arxiv.org/pdf/2308.12316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12001v1",
            "title": "Local Distortion Aware Efficient Transformer Adaptation for Image\n  Quality Assessment",
            "updated": "2023-08-23T08:41:21Z",
            "published": "2023-08-23T08:41:21Z",
            "summary": "Image Quality Assessment (IQA) constitutes a fundamental task within the\nfield of computer vision, yet it remains an unresolved challenge, owing to the\nintricate distortion conditions, diverse image contents, and limited\navailability of data. Recently, the community has witnessed the emergence of\nnumerous large-scale pretrained foundation models, which greatly benefit from\ndramatically increased data and parameter capacities. However, it remains an\nopen problem whether the scaling law in high-level tasks is also applicable to\nIQA task which is closely related to low-level clues. In this paper, we\ndemonstrate that with proper injection of local distortion features, a larger\npretrained and fixed foundation model performs better in IQA tasks.\nSpecifically, for the lack of local distortion structure and inductive bias of\nvision transformer (ViT), alongside the large-scale pretrained ViT, we use\nanother pretrained convolution neural network (CNN), which is well known for\ncapturing the local structure, to extract multi-scale image features. Further,\nwe propose a local distortion extractor to obtain local distortion features\nfrom the pretrained CNN and a local distortion injector to inject the local\ndistortion features into ViT. By only training the extractor and injector, our\nmethod can benefit from the rich knowledge in the powerful foundation models\nand achieve state-of-the-art performance on popular IQA datasets, indicating\nthat IQA is not only a low-level problem but also benefits from stronger\nhigh-level features drawn from large-scale pretrained models.",
            "author": [
                "Kangmin Xu",
                "Liang Liao",
                "Jing Xiao",
                "Chaofeng Chen",
                "Haoning Wu",
                "Qiong Yan",
                "Weisi Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12001v1",
                "http://arxiv.org/pdf/2308.12001v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11995v1",
            "title": "Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations",
            "updated": "2023-08-23T08:33:14Z",
            "published": "2023-08-23T08:33:14Z",
            "summary": "Building socialbots that can have deep, engaging open-domain conversations\nwith humans is one of the grand challenges of artificial intelligence (AI). To\nthis end, bots need to be able to leverage world knowledge spanning several\ndomains effectively when conversing with humans who have their own world\nknowledge. Existing knowledge-grounded conversation datasets are primarily\nstylized with explicit roles for conversation partners. These datasets also do\nnot explore depth or breadth of topical coverage with transitions in\nconversations. We introduce Topical-Chat, a knowledge-grounded human-human\nconversation dataset where the underlying knowledge spans 8 broad topics and\nconversation partners don't have explicitly defined roles, to help further\nresearch in open-domain conversational AI. We also train several\nstate-of-the-art encoder-decoder conversational models on Topical-Chat and\nperform automated and human evaluation for benchmarking.",
            "author": [
                "Karthik Gopalakrishnan",
                "Behnam Hedayatnia",
                "Qinlang Chen",
                "Anna Gottardi",
                "Sanjeev Kwatra",
                "Anu Venkatesh",
                "Raefer Gabriel",
                "Dilek Hakkani-Tur"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11995v1",
                "http://arxiv.org/pdf/2308.11995v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11994v1",
            "title": "Progressive Feature Mining and External Knowledge-Assisted\n  Text-Pedestrian Image Retrieval",
            "updated": "2023-08-23T08:29:10Z",
            "published": "2023-08-23T08:29:10Z",
            "summary": "Text-Pedestrian Image Retrieval aims to use the text describing pedestrian\nappearance to retrieve the corresponding pedestrian image. This task involves\nnot only modality discrepancy, but also the challenge of the textual diversity\nof pedestrians with the same identity. At present, although existing research\nprogress has been made in text-pedestrian image retrieval, these methods do not\ncomprehensively consider the above-mentioned problems. Considering these, this\npaper proposes a progressive feature mining and external knowledge-assisted\nfeature purification method. Specifically, we use a progressive mining mode to\nenable the model to mine discriminative features from neglected information,\nthereby avoiding the loss of discriminative information and improving the\nexpression ability of features. In addition, to further reduce the negative\nimpact of modal discrepancy and text diversity on cross-modal matching, we\npropose to use other sample knowledge of the same modality, i.e., external\nknowledge to enhance identity-consistent features and weaken\nidentity-inconsistent features. This process purifies features and alleviates\nthe interference caused by textual diversity and negative sample correlation\nfeatures of the same modal. Extensive experiments on three challenging datasets\ndemonstrate the effectiveness and superiority of the proposed method, and the\nretrieval performance even surpasses that of the large-scale model-based method\non large-scale datasets.",
            "author": [
                "Huafeng Li",
                "Shedan Yang",
                "Yafei Zhang",
                "Dapeng Tao",
                "Zhengtao Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11994v1",
                "http://arxiv.org/pdf/2308.11994v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11991v1",
            "title": "Relational Concept Based Models",
            "updated": "2023-08-23T08:25:33Z",
            "published": "2023-08-23T08:25:33Z",
            "summary": "The design of interpretable deep learning models working in relational\ndomains poses an open challenge: interpretable deep learning methods, such as\nConcept-Based Models (CBMs), are not designed to solve relational problems,\nwhile relational models are not as interpretable as CBMs. To address this\nproblem, we propose Relational Concept-Based Models, a family of relational\ndeep learning methods providing interpretable task predictions. Our\nexperiments, ranging from image classification to link prediction in knowledge\ngraphs, show that relational CBMs (i) match generalization performance of\nexisting relational black-boxes (as opposed to non-relational CBMs), (ii)\nsupport the generation of quantified concept-based explanations, (iii)\neffectively respond to test-time interventions, and (iv) withstand demanding\nsettings including out-of-distribution scenarios, limited training data\nregimes, and scarce concept supervisions.",
            "author": [
                "Pietro Barbiero",
                "Francesco Giannini",
                "Gabriele Ciravegna",
                "Michelangelo Diligenti",
                "Giuseppe Marra"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11991v1",
                "http://arxiv.org/pdf/2308.11991v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12979v2",
            "title": "BMS Symmetries of Gravitational Scattering",
            "updated": "2023-09-02T10:13:57Z",
            "published": "2023-08-23T08:19:58Z",
            "summary": "After motivating the relevance of the Bondi-Metzner-Sachs (BMS) group over\nthe last decades, we review how concepts such as Penrose diagrams and the\ncovariant phase space formalism can be used to understand the asymptotic\nstructure of asymptotically flat spacetimes (AFS). We then explicitly construct\nthe asymptotic symmetry group of AFS in $3+1$ dimensions, the BMS group. Next,\nwe apply this knowledge to the usual far-field scattering problem in general\nrelativity, which leads to the unravelling of the intrinsic features of gravity\nin the infrared. In particular, we work out the connections between asymptotic\nsymmetries, soft theorems in quantum field theories and gravitational memory\neffects. We restrict to the study of this infrared triangle through the lens of\nsupertranslations here, but the analogous features that can be found in the\ncase of superrotations or for other gauge theories are also motivated at the\nend of our discussion. We conclude with an overview of the implications of the\ninfrared triangle of gravity for the formulation of an approach to quantum\ngravity through holography, as well as a brief discussion of its potential in\ntackling the black hole information paradox.",
            "author": [
                "Xavier Kervyn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12979v2",
                "http://arxiv.org/pdf/2308.12979v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11980v1",
            "title": "Joint Prediction of Audio Event and Annoyance Rating in an Urban\n  Soundscape by Hierarchical Graph Representation Learning",
            "updated": "2023-08-23T08:05:10Z",
            "published": "2023-08-23T08:05:10Z",
            "summary": "Sound events in daily life carry rich information about the objective world.\nThe composition of these sounds affects the mood of people in a soundscape.\nMost previous approaches only focus on classifying and detecting audio events\nand scenes, but may ignore their perceptual quality that may impact humans'\nlistening mood for the environment, e.g. annoyance. To this end, this paper\nproposes a novel hierarchical graph representation learning (HGRL) approach\nwhich links objective audio events (AE) with subjective annoyance ratings (AR)\nof the soundscape perceived by humans. The hierarchical graph consists of\nfine-grained event (fAE) embeddings with single-class event semantics,\ncoarse-grained event (cAE) embeddings with multi-class event semantics, and AR\nembeddings. Experiments show the proposed HGRL successfully integrates AE with\nAR for AEC and ARP tasks, while coordinating the relations between cAE and fAE\nand further aligning the two different grains of AE information with the AR.",
            "author": [
                "Yuanbo Hou",
                "Siyang Song",
                "Cheng Luo",
                "Andrew Mitchell",
                "Qiaoqiao Ren",
                "Weicheng Xie",
                "Jian Kang",
                "Wenwu Wang",
                "Dick Botteldooren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11980v1",
                "http://arxiv.org/pdf/2308.11980v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11978v2",
            "title": "Will More Expressive Graph Neural Networks do Better on Generative\n  Tasks?",
            "updated": "2023-11-26T17:41:49Z",
            "published": "2023-08-23T07:57:45Z",
            "summary": "Graph generation poses a significant challenge as it involves predicting a\ncomplete graph with multiple nodes and edges based on simply a given label.\nThis task also carries fundamental importance to numerous real-world\napplications, including de-novo drug and molecular design. In recent years,\nseveral successful methods have emerged in the field of graph generation.\nHowever, these approaches suffer from two significant shortcomings: (1) the\nunderlying Graph Neural Network (GNN) architectures used in these methods are\noften underexplored; and (2) these methods are often evaluated on only a\nlimited number of metrics. To fill this gap, we investigate the expressiveness\nof GNNs under the context of the molecular graph generation task, by replacing\nthe underlying GNNs of graph generative models with more expressive GNNs.\nSpecifically, we analyse the performance of six GNNs on six different molecular\ngenerative objectives on the ZINC-250k dataset in two different generative\nframeworks: autoregressive generation models, such as GCPN and GraphAF, and\none-shot generation models, such as GraphEBM. Through our extensive\nexperiments, we demonstrate that advanced GNNs can indeed improve the\nperformance of GCPN, GraphAF, and GraphEBM on molecular generation tasks, but\nGNN expressiveness is not a necessary condition for a good GNN-based generative\nmodel. Moreover, we show that GCPN and GraphAF with advanced GNNs can achieve\nstate-of-the-art results across 17 other non-GNN-based graph generative\napproaches, such as variational autoencoders and Bayesian optimisation models,\non the proposed molecular generative objectives (DRD2, Median1, Median2), which\nare important metrics for de-novo molecular design.",
            "author": [
                "Xiandong Zou",
                "Xiangyu Zhao",
                "Pietro Li\u00f2",
                "Yiren Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11978v2",
                "http://arxiv.org/pdf/2308.11978v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11977v1",
            "title": "ESTA: An Efficient Spatial-Temporal Range Aggregation Query Processing\n  Algorithm for UAV Networks",
            "updated": "2023-08-23T07:54:17Z",
            "published": "2023-08-23T07:54:17Z",
            "summary": "Unmanned Aerial Vehicle (UAV) networks have been widely used in both military\nand civilian scenarios. When users are interested in the statistical\ninformation of the historical sensory data in a certain region during a certain\ntime period, they will send an aggregation query request with a\nspatial-temporal constraint to target UAVs which store the qualified data.\nThen, the target UAVs will return the query results to users. Meanwhile, the\nquery results can be aggregated within the network during transmission to save\nenergy and bandwidth resources, which are typically scarce in UAV networks.\nHowever, due to the unique characteristics of UAV networks, it is difficult to\nperform efficient in-network aggregation of query results without the sacrifice\nof the user query delay. To the best of our knowledge, there is no research on\nspatial-temporal range aggregation query in UAV networks. In this paper, we\npropose an Efficient Spatial-Temporal range Aggregation query processing (ESTA)\nalgorithm for UAV networks. First, a topology change graph is constructed based\non the pre-planned trajectory information. Meanwhile, an efficient shortest\npath algorithm is proposed to obtain the user query delay. Then, on the basis\nof ensuring the user query delay, ESTA transforms the aggregation processing of\nquery results into recursively solving the set cover problem, thereby\nconstructing a spatial-temporal aggregation tree (STAT), based on which an\nefficient in-network aggregation routing path for query results can be found.\nThrough extensive simulation, we demonstrate that ESTA can save more than 50%\nof the energy consumption compared with the baseline algorithm.",
            "author": [
                "Wenbin Zhai",
                "Xin Li",
                "Liang Liu",
                "Youwei Ding",
                "Wanying Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11977v1",
                "http://arxiv.org/pdf/2308.11977v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11970v1",
            "title": "Compressing CFI Graphs and Lower Bounds for the Weisfeiler-Leman\n  Refinements",
            "updated": "2023-08-23T07:32:28Z",
            "published": "2023-08-23T07:32:28Z",
            "summary": "The $k$-dimensional Weisfeiler-Leman ($k$-WL) algorithm is a simple\ncombinatorial algorithm that was originally designed as a graph isomorphism\nheuristic. It naturally finds applications in Babai's quasipolynomial time\nisomorphism algorithm, practical isomorphism solvers, and algebraic graph\ntheory. However, it also has surprising connections to other areas such as\nlogic, proof complexity, combinatorial optimization, and machine learning.\n  The algorithm iteratively computes a coloring of the $k$-tuples of vertices\nof a graph. Since F\\\"urer's linear lower bound [ICALP 2001], it has been an\nopen question whether there is a super-linear lower bound for the iteration\nnumber for $k$-WL on graphs. We answer this question affirmatively,\nestablishing an $\\Omega(n^{k/2})$-lower bound for all $k$.",
            "author": [
                "Martin Grohe",
                "Moritz Lichter",
                "Daniel Neuen",
                "Pascal Schweitzer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11970v1",
                "http://arxiv.org/pdf/2308.11970v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.DS",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13041v1",
            "title": "Advancing stable set problem solutions through quantum annealers",
            "updated": "2023-08-23T07:18:52Z",
            "published": "2023-08-23T07:18:52Z",
            "summary": "We assess the performance of D-wave quantum solvers for solving the stable\nset problem in a graph, one of the most studied NP-hard problems. We perform\ncomputations on some instances from the literature with up to 125 vertices and\ncompare the quality of the obtained solutions with known optimum solutions. It\nturns out that the hybrid solver gives very good results, while the Quantum\nProcessing Unit solver shows rather modest performance overall.",
            "author": [
                "Janez Povh",
                "Dunja Pucher"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13041v1",
                "http://arxiv.org/pdf/2308.13041v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "quant-ph",
                "90C27, 81P68"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11959v2",
            "title": "Scalable \u03b4-Level Coherent State Synchronization of Multi-Agent\n  Systems in the Presence of Bounded Disturbances",
            "updated": "2023-08-24T06:51:47Z",
            "published": "2023-08-23T06:58:03Z",
            "summary": "In this paper, we study scalable {\\delta}-Level coherent state\nsynchronization for multi-agent systems (MAS) where the agents are subject to\nbounded disturbances/noises. We propose a scale-free framework designed solely\nbased on the knowledge of agent models and agnostic to the communication graphs\nand size of the network. We define the level of coherency for each agent as the\nnorm of the weighted sum of the disagreement dynamics with its neighbors. The\nobjective is to restrict the level of coherency of the network to {\\delta}\nwithout a-priori information about the disturbances.",
            "author": [
                "Donya Nojavanzadeh",
                "Zhenwei Liu",
                "Ali Saberi",
                "Anton A. Stoorvogel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11959v2",
                "http://arxiv.org/pdf/2308.11959v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11957v2",
            "title": "CED: Consistent ensemble distillation for audio tagging",
            "updated": "2023-09-08T02:31:24Z",
            "published": "2023-08-23T06:57:00Z",
            "summary": "Augmentation and knowledge distillation (KD) are well-established techniques\nemployed in audio classification tasks, aimed at enhancing performance and\nreducing model sizes on the widely recognized Audioset (AS) benchmark. Although\nboth techniques are effective individually, their combined use, called\nconsistent teaching, hasn't been explored before. This paper proposes CED, a\nsimple training framework that distils student models from large teacher\nensembles with consistent teaching. To achieve this, CED efficiently stores\nlogits as well as the augmentation methods on disk, making it scalable to\nlarge-scale datasets. Central to CED's efficacy is its label-free nature,\nmeaning that only the stored logits are used for the optimization of a student\nmodel only requiring 0.3\\% additional disk space for AS. The study trains\nvarious transformer-based models, including a 10M parameter model achieving a\n49.0 mean average precision (mAP) on AS. Pretrained models and code are\navailable at https://github.com/RicherMans/CED.",
            "author": [
                "Heinrich Dinkel",
                "Yongqing Wang",
                "Zhiyong Yan",
                "Junbo Zhang",
                "Yujun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11957v2",
                "http://arxiv.org/pdf/2308.11957v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11951v3",
            "title": "Pose Modulated Avatars from Video",
            "updated": "2023-09-29T15:03:09Z",
            "published": "2023-08-23T06:49:07Z",
            "summary": "It is now possible to reconstruct dynamic human motion and shape from a\nsparse set of cameras using Neural Radiance Fields (NeRF) driven by an\nunderlying skeleton. However, a challenge remains to model the deformation of\ncloth and skin in relation to skeleton pose. Unlike existing avatar models that\nare learned implicitly or rely on a proxy surface, our approach is motivated by\nthe observation that different poses necessitate unique frequency assignments.\nNeglecting this distinction yields noisy artifacts in smooth areas or blurs\nfine-grained texture and shape details in sharp regions. We develop a\ntwo-branch neural network that is adaptive and explicit in the frequency\ndomain. The first branch is a graph neural network that models correlations\namong body parts locally, taking skeleton pose as input. The second branch\ncombines these correlation features to a set of global frequencies and then\nmodulates the feature encoding. Our experiments demonstrate that our network\noutperforms state-of-the-art methods in terms of preserving details and\ngeneralization capabilities.",
            "author": [
                "Chunjin Song",
                "Bastian Wandt",
                "Helge Rhodin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11951v3",
                "http://arxiv.org/pdf/2308.11951v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11950v1",
            "title": "Cliquewidth and dimension",
            "updated": "2023-08-23T06:47:28Z",
            "published": "2023-08-23T06:47:28Z",
            "summary": "We prove that every poset with bounded cliquewidth and with sufficiently\nlarge dimension contains the standard example of dimension $k$ as a subposet.\nThis applies in particular to posets whose cover graphs have bounded treewidth,\nas the cliquewidth of a poset is bounded in terms of the treewidth of the cover\ngraph. For the latter posets, we prove a stronger statement: every such poset\nwith sufficiently large dimension contains the Kelly example of dimension $k$\nas a subposet. Using this result, we obtain a full characterization of the\nminor-closed graph classes $\\mathcal{C}$ such that posets with cover graphs in\n$\\mathcal{C}$ have bounded dimension: they are exactly the classes excluding\nthe cover graph of some Kelly example. Finally, we consider a variant of poset\ndimension called Boolean dimension, and we prove that posets with bounded\ncliquewidth have bounded Boolean dimension.\n  The proofs rely on Colcombet's deterministic version of Simon's factorization\ntheorem, which is a fundamental tool in formal language and automata theory,\nand which we believe deserves a wider recognition in structural and algorithmic\ngraph theory.",
            "author": [
                "Gwena\u00ebl Joret",
                "Piotr Micek",
                "Micha\u0142 Pilipczuk",
                "Bartosz Walczak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11950v1",
                "http://arxiv.org/pdf/2308.11950v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11943v1",
            "title": "RamseyRL: A Framework for Intelligent Ramsey Number Counterexample\n  Searching",
            "updated": "2023-08-23T06:32:14Z",
            "published": "2023-08-23T06:32:14Z",
            "summary": "The Ramsey number is the minimum number of nodes, $n = R(s, t)$, such that\nall undirected simple graphs of order $n$, contain a clique of order $s$, or an\nindependent set of order $t$. This paper explores the application of a best\nfirst search algorithm and reinforcement learning (RL) techniques to find\ncounterexamples to specific Ramsey numbers. We incrementally improve over prior\nsearch methods such as random search by introducing a graph vectorization and\ndeep neural network (DNN)-based heuristic, which gauge the likelihood of a\ngraph being a counterexample. The paper also proposes algorithmic optimizations\nto confine a polynomial search runtime. This paper does not aim to present new\ncounterexamples but rather introduces and evaluates a framework supporting\nRamsey counterexample exploration using other heuristics. Code and methods are\nmade available through a PyPI package and GitHub repository.",
            "author": [
                "Steve Vott",
                "Adam M. Lehavi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11943v1",
                "http://arxiv.org/pdf/2308.11943v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.8; G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11937v1",
            "title": "Learning Bottleneck Transformer for Event Image-Voxel Feature Fusion\n  based Classification",
            "updated": "2023-08-23T06:07:56Z",
            "published": "2023-08-23T06:07:56Z",
            "summary": "Recognizing target objects using an event-based camera draws more and more\nattention in recent years. Existing works usually represent the event streams\ninto point-cloud, voxel, image, etc, and learn the feature representations\nusing various deep neural networks. Their final results may be limited by the\nfollowing factors: monotonous modal expressions and the design of the network\nstructure. To address the aforementioned challenges, this paper proposes a\nnovel dual-stream framework for event representation, extraction, and fusion.\nThis framework simultaneously models two common representations: event images\nand event voxels. By utilizing Transformer and Structured Graph Neural Network\n(GNN) architectures, spatial information and three-dimensional stereo\ninformation can be learned separately. Additionally, a bottleneck Transformer\nis introduced to facilitate the fusion of the dual-stream information.\nExtensive experiments demonstrate that our proposed framework achieves\nstate-of-the-art performance on two widely used event-based classification\ndatasets. The source code of this work is available at:\n\\url{https://github.com/Event-AHU/EFV_event_classification}",
            "author": [
                "Chengguo Yuan",
                "Yu Jin",
                "Zongzhen Wu",
                "Fanting Wei",
                "Yangzirui Wang",
                "Lan Chen",
                "Xiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11937v1",
                "http://arxiv.org/pdf/2308.11937v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11927v1",
            "title": "Recovering a Molecule's 3D Dynamics from Liquid-phase Electron\n  Microscopy Movies",
            "updated": "2023-08-23T05:26:27Z",
            "published": "2023-08-23T05:26:27Z",
            "summary": "The dynamics of biomolecules are crucial for our understanding of their\nfunctioning in living systems. However, current 3D imaging techniques, such as\ncryogenic electron microscopy (cryo-EM), require freezing the sample, which\nlimits the observation of their conformational changes in real time. The\ninnovative liquid-phase electron microscopy (liquid-phase EM) technique allows\nmolecules to be placed in the native liquid environment, providing a unique\nopportunity to observe their dynamics. In this paper, we propose TEMPOR, a\nTemporal Electron MicroscoPy Object Reconstruction algorithm for liquid-phase\nEM that leverages an implicit neural representation (INR) and a dynamical\nvariational auto-encoder (DVAE) to recover time series of molecular structures.\nWe demonstrate its advantages in recovering different motion dynamics from two\nsimulated datasets, 7bcq and Cas9. To our knowledge, our work is the first\nattempt to directly recover 3D structures of a temporally-varying particle from\nliquid-phase EM movies. It provides a promising new approach for studying\nmolecules' 3D dynamics in structural biology.",
            "author": [
                "Enze Ye",
                "Yuhang Wang",
                "Hong Zhang",
                "Yiqin Gao",
                "Huan Wang",
                "He Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11927v1",
                "http://arxiv.org/pdf/2308.11927v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11914v2",
            "title": "Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge\n  Reasoning via Promoting Causal Consistency in LLMs",
            "updated": "2023-09-04T10:15:51Z",
            "published": "2023-08-23T04:59:21Z",
            "summary": "Despite advancements in LLMs, knowledge-based reasoning remains a\nlongstanding issue due to the fragility of knowledge recall and inference.\nExisting methods primarily encourage LLMs to autonomously plan and solve\nproblems or to extensively sample reasoning chains without addressing the\nconceptual and inferential fallacies. Attempting to alleviate inferential\nfallacies and drawing inspiration from multi-agent collaboration, we present a\nframework to increase faithfulness and causality for knowledge-based reasoning.\nSpecifically, we propose to employ multiple intelligent agents (i.e., reasoners\nand an evaluator) to work collaboratively in a reasoning-and-consensus paradigm\nfor elevated reasoning faithfulness. The reasoners focus on providing solutions\nwith human-like causality to solve open-domain problems. On the other hand, the\n\\textit{evaluator} agent scrutinizes if a solution is deducible from a\nnon-causal perspective and if it still holds when challenged by a\ncounterfactual candidate. According to the extensive and comprehensive\nevaluations on a variety of knowledge reasoning tasks (e.g., science question\nanswering and commonsense reasoning), our framework outperforms all compared\nstate-of-the-art approaches by large margins.",
            "author": [
                "Ziyi Tang",
                "Ruilin Wang",
                "Weixing Chen",
                "Keze Wang",
                "Yang Liu",
                "Tianshui Chen",
                "Liang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11914v2",
                "http://arxiv.org/pdf/2308.11914v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12923v1",
            "title": "Diagnosing Infeasible Optimization Problems Using Large Language Models",
            "updated": "2023-08-23T04:34:05Z",
            "published": "2023-08-23T04:34:05Z",
            "summary": "Decision-making problems can be represented as mathematical optimization\nmodels, finding wide applications in fields such as economics, engineering and\nmanufacturing, transportation, and health care. Optimization models are\nmathematical abstractions of the problem of making the best decision while\nsatisfying a set of requirements or constraints. One of the primary barriers to\ndeploying these models in practice is the challenge of helping practitioners\nunderstand and interpret such models, particularly when they are infeasible,\nmeaning no decision satisfies all the constraints. Existing methods for\ndiagnosing infeasible optimization models often rely on expert systems,\nnecessitating significant background knowledge in optimization. In this paper,\nwe introduce OptiChat, a first-of-its-kind natural language-based system\nequipped with a chatbot GUI for engaging in interactive conversations about\ninfeasible optimization models. OptiChat can provide natural language\ndescriptions of the optimization model itself, identify potential sources of\ninfeasibility, and offer suggestions to make the model feasible. The\nimplementation of OptiChat is built on GPT-4, which interfaces with an\noptimization solver to identify the minimal subset of constraints that render\nthe entire optimization problem infeasible, also known as the Irreducible\nInfeasible Subset (IIS). We utilize few-shot learning, expert chain-of-thought,\nkey-retrieve, and sentiment prompts to enhance OptiChat's reliability. Our\nexperiments demonstrate that OptiChat assists both expert and non-expert users\nin improving their understanding of the optimization models, enabling them to\nquickly identify the sources of infeasibility.",
            "author": [
                "Hao Chen",
                "Gonzalo E. Constante-Flores",
                "Can Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12923v1",
                "http://arxiv.org/pdf/2308.12923v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CL",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11909v6",
            "title": "Edge-aware Hard Clustering Graph Pooling for Brain Imaging",
            "updated": "2023-12-03T04:52:56Z",
            "published": "2023-08-23T04:29:40Z",
            "summary": "Graph Convolutional Networks (GCNs) can capture non-Euclidean spatial\ndependence between different brain regions. The graph pooling operator, a\ncrucial element of GCNs, enhances the representation learning capability and\nfacilitates the acquisition of abnormal brain maps. However, most existing\nresearch designs graph pooling operators solely from the perspective of nodes\nwhile disregarding the original edge features. This confines graph pooling\napplication scenarios and diminishes its ability to capture critical\nsubstructures. In this paper, we propose a novel edge-aware hard clustering\ngraph pool (EHCPool), which is tailored to dominant edge features and redefines\nthe clustering process. EHCPool initially introduced the 'Edge-to-Node' score\ncriterion which utilized edge information to evaluate the significance of\nnodes. An innovative Iteration n-top strategy was then developed, guided by\nedge scores, to adaptively learn sparse hard clustering assignments for graphs.\nAdditionally, a N-E Aggregation strategy is designed to aggregate node and edge\nfeatures in each independent subgraph. Extensive experiments on the multi-site\npublic datasets demonstrate the superiority and robustness of the proposed\nmodel. More notably, EHCPool has the potential to probe different types of\ndysfunctional brain networks from a data-driven perspective. Method code:\nhttps://github.com/swfen/EHCPool",
            "author": [
                "Cheng Zhu",
                "Jiayi Zhu",
                "Lijuan Zhang",
                "Xi Wu",
                "Shuqi Yang",
                "Ping Liang",
                "Honghan Chen",
                "Ying Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11909v6",
                "http://arxiv.org/pdf/2308.11909v6"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11907v2",
            "title": "Cohen-Macaulay oriented graphs with large girth",
            "updated": "2023-08-25T02:10:53Z",
            "published": "2023-08-23T04:20:43Z",
            "summary": "We classify the Cohen-Macaulay weighted oriented graphs whose underlying\ngraphs have girth at least $5$.",
            "author": [
                "Le Xuan Dung",
                "Tran Nam Trung"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11907v2",
                "http://arxiv.org/pdf/2308.11907v2"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11901v1",
            "title": "Camera-Driven Representation Learning for Unsupervised Domain Adaptive\n  Person Re-identification",
            "updated": "2023-08-23T04:01:56Z",
            "published": "2023-08-23T04:01:56Z",
            "summary": "We present a novel unsupervised domain adaption method for person\nre-identification (reID) that generalizes a model trained on a labeled source\ndomain to an unlabeled target domain. We introduce a camera-driven curriculum\nlearning (CaCL) framework that leverages camera labels of person images to\ntransfer knowledge from source to target domains progressively. To this end, we\ndivide target domain dataset into multiple subsets based on the camera labels,\nand initially train our model with a single subset (i.e., images captured by a\nsingle camera). We then gradually exploit more subsets for training, according\nto a curriculum sequence obtained with a camera-driven scheduling rule. The\nscheduler considers maximum mean discrepancies (MMD) between each subset and\nthe source domain dataset, such that the subset closer to the source domain is\nexploited earlier within the curriculum. For each curriculum sequence, we\ngenerate pseudo labels of person images in a target domain to train a reID\nmodel in a supervised way. We have observed that the pseudo labels are highly\nbiased toward cameras, suggesting that person images obtained from the same\ncamera are likely to have the same pseudo labels, even for different IDs. To\naddress the camera bias problem, we also introduce a camera-diversity (CD) loss\nencouraging person images of the same pseudo label, but captured across various\ncameras, to involve more for discriminative feature learning, providing person\nrepresentations robust to inter-camera variations. Experimental results on\nstandard benchmarks, including real-to-real and synthetic-to-real scenarios,\ndemonstrate the effectiveness of our framework.",
            "author": [
                "Geon Lee",
                "Sanghoon Lee",
                "Dohyung Kim",
                "Younghoon Shin",
                "Yongsang Yoon",
                "Bumsub Ham"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11901v1",
                "http://arxiv.org/pdf/2308.11901v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11884v1",
            "title": "Integrating the Wikidata Taxonomy into YAGO",
            "updated": "2023-08-23T03:03:14Z",
            "published": "2023-08-23T03:03:14Z",
            "summary": "Wikidata is one of the largest public general-purpose Knowledge Bases (KBs).\nYet, due to its collaborative nature, its schema and taxonomy have become\nconvoluted. For the YAGO 4 KB, we combined Wikidata with the ontology from\nSchema.org, which reduced and cleaned up the taxonomy and constraints and made\nit possible to run automated reasoners on the data. However, it also cut away\nlarge parts of the Wikidata taxonomy. In this paper, we present our effort to\nmerge the entire Wikidata taxonomy into the YAGO KB as much as possible. We pay\nparticular attention to logical constraints and a careful distinction of\nclasses and instances. Our work creates YAGO 4.5, which adds a rich layer of\ninformative classes to YAGO, while at the same time keeping the KB logically\nconsistent.",
            "author": [
                "Fabian Suchanek",
                "Mehwish Alam",
                "Thomas Bonald",
                "Pierre-Henri Paris",
                "Jules Soria"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11884v1",
                "http://arxiv.org/pdf/2308.11884v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11874v1",
            "title": "Semi-Supervised Learning via Weight-aware Distillation under Class\n  Distribution Mismatch",
            "updated": "2023-08-23T02:37:34Z",
            "published": "2023-08-23T02:37:34Z",
            "summary": "Semi-Supervised Learning (SSL) under class distribution mismatch aims to\ntackle a challenging problem wherein unlabeled data contain lots of unknown\ncategories unseen in the labeled ones. In such mismatch scenarios, traditional\nSSL suffers severe performance damage due to the harmful invasion of the\ninstances with unknown categories into the target classifier. In this study, by\nstrict mathematical reasoning, we reveal that the SSL error under class\ndistribution mismatch is composed of pseudo-labeling error and invasion error,\nboth of which jointly bound the SSL population risk. To alleviate the SSL\nerror, we propose a robust SSL framework called Weight-Aware Distillation (WAD)\nthat, by weights, selectively transfers knowledge beneficial to the target task\nfrom unsupervised contrastive representation to the target classifier.\nSpecifically, WAD captures adaptive weights and high-quality pseudo labels to\ntarget instances by exploring point mutual information (PMI) in representation\nspace to maximize the role of unlabeled data and filter unknown categories.\nTheoretically, we prove that WAD has a tight upper bound of population risk\nunder class distribution mismatch. Experimentally, extensive results\ndemonstrate that WAD outperforms five state-of-the-art SSL approaches and one\nstandard baseline on two benchmark datasets, CIFAR10 and CIFAR100, and an\nartificial cross-dataset. The code is available at\nhttps://github.com/RUC-DWBI-ML/research/tree/main/WAD-master.",
            "author": [
                "Pan Du",
                "Suyun Zhao",
                "Zisen Sheng",
                "Cuiping Li",
                "Hong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11874v1",
                "http://arxiv.org/pdf/2308.11874v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11867v1",
            "title": "Atomic scale understanding of initial Cu-Ni oxidation from\n  machine-learning accelerated first-principles simulations and in situ TEM\n  experiments",
            "updated": "2023-08-23T02:02:56Z",
            "published": "2023-08-23T02:02:56Z",
            "summary": "The development of accurate methods for determining how alloy surfaces\nspontaneously restructure under reactive and corrosive environments is a key,\nlong-standing, grand challenge in materials science. Current oxidation models,\nsuch as Cabrera-Mott, are based on macroscopic empirical knowledge that lacks\nfundamental insight at the atomic level. Using machine learning-accelerated\ndensity functional theory with in situ environmental transmission electron\nmicroscopy (ETEM), we examine the interplay between surface reconstructions and\npreferential segregation tendencies of CuNi(100) surfaces under oxidation\nconditions. Our modeling approach based on molecular dynamics and grand\ncanonical Monte Carlo simulations shows that oxygen-induced Ni segregation in\nCuNi alloy favors Cu(100)-O c(2x2) reconstruction and destabilizes the\nCu(100)-O missing row reconstruction. The underpinnings of these stabilization\ntendencies are rationalized based on the similar atomic coordination and bond\nlengths in NiO rock salt and Cu(100)-O c(2x2) structures. In situ ETEM\nexperiments show Ni segregation followed by NiO nucleation and growth in\nregions without MRR, with secondary nucleation and growth of Cu2O in MRR\nregions. This further corroborates the simulated surface oxidation and\nsegregation modelling outcomes. Our findings are general and are expected to\nextend to other alloy systems.",
            "author": [
                "Pandu Wisesa",
                "Meng Li",
                "Matthew T. Curnan",
                "Jeong Woo Han",
                "Judith C. Yang",
                "Wissam A. Saidi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11867v1",
                "http://arxiv.org/pdf/2308.11867v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11863v1",
            "title": "KinSPEAK: Improving speech recognition for Kinyarwanda via\n  semi-supervised learning methods",
            "updated": "2023-08-23T01:44:28Z",
            "published": "2023-08-23T01:44:28Z",
            "summary": "Despite recent availability of large transcribed Kinyarwanda speech data,\nachieving robust speech recognition for Kinyarwanda is still challenging. In\nthis work, we show that using self-supervised pre-training, following a simple\ncurriculum schedule during fine-tuning and using semi-supervised learning to\nleverage large unlabelled speech data significantly improve speech recognition\nperformance for Kinyarwanda. Our approach focuses on using public domain data\nonly. A new studio-quality speech dataset is collected from a public website,\nthen used to train a clean baseline model. The clean baseline model is then\nused to rank examples from a more diverse and noisy public dataset, defining a\nsimple curriculum training schedule. Finally, we apply semi-supervised learning\nto label and learn from large unlabelled data in four successive generations.\nOur final model achieves 3.2% word error rate (WER) on the new dataset and\n15.9% WER on Mozilla Common Voice benchmark, which is state-of-the-art to the\nbest of our knowledge. Our experiments also indicate that using syllabic rather\nthan character-based tokenization results in better speech recognition\nperformance for Kinyarwanda.",
            "author": [
                "Antoine Nzeyimana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11863v1",
                "http://arxiv.org/pdf/2308.11863v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11827v1",
            "title": "Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study\n  of the Driver's License Knowledge Test",
            "updated": "2023-08-22T23:18:53Z",
            "published": "2023-08-22T23:18:53Z",
            "summary": "Large language models such as Open AI's Generative Pre-trained Transformer\n(GPT) models are proficient at answering questions, but their knowledge is\nconfined to the information present in their training data. This limitation\nrenders them ineffective when confronted with questions about recent\ndevelopments or non-public documents. Our research proposes a method that\nenables GPT models to answer questions by employing context from an information\nsource not previously included in their training data. The methodology includes\npreprocessing of contextual information, the embedding of contexts and queries,\nconstructing prompt through the integration of context embeddings, and\ngenerating answers using GPT models. We applied this method in a controlled\ntest scenario using the California Driver's Handbook as the information source.\nThe GPT-3 model achieved a 96% passing score on a set of 50 sample driving\nknowledge test questions. In contrast, without context, the model's passing\nscore fell to 82%. However, the model still fails to answer some questions\ncorrectly even with providing library of context, highlighting room for\nimprovement. The research also examined the impact of prompt length and context\nformat, on the model's performance. Overall, the study provides insights into\nthe limitations and potential improvements for GPT models in question-answering\ntasks.",
            "author": [
                "Saba Rahimi",
                "Tucker Balch",
                "Manuela Veloso"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11827v1",
                "http://arxiv.org/pdf/2308.11827v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11825v1",
            "title": "Accel-GCN: High-Performance GPU Accelerator Design for Graph Convolution\n  Networks",
            "updated": "2023-08-22T23:12:17Z",
            "published": "2023-08-22T23:12:17Z",
            "summary": "Graph Convolutional Networks (GCNs) are pivotal in extracting latent\ninformation from graph data across various domains, yet their acceleration on\nmainstream GPUs is challenged by workload imbalance and memory access\nirregularity. To address these challenges, we present Accel-GCN, a GPU\naccelerator architecture for GCNs. The design of Accel-GCN encompasses: (i) a\nlightweight degree sorting stage to group nodes with similar degree; (ii) a\nblock-level partition strategy that dynamically adjusts warp workload sizes,\nenhancing shared memory locality and workload balance, and reducing metadata\noverhead compared to designs like GNNAdvisor; (iii) a combined warp strategy\nthat improves memory coalescing and computational parallelism in the column\ndimension of dense matrices.\n  Utilizing these principles, we formulated a kernel for sparse matrix\nmultiplication (SpMM) in GCNs that employs block-level partitioning and\ncombined warp strategy. This approach augments performance and multi-level\nmemory efficiency and optimizes memory bandwidth by exploiting memory\ncoalescing and alignment. Evaluation of Accel-GCN across 18 benchmark graphs\nreveals that it outperforms cuSPARSE, GNNAdvisor, and graph-BLAST by factors of\n1.17 times, 1.86 times, and 2.94 times respectively. The results underscore\nAccel-GCN as an effective solution for enhancing GCN computational efficiency.",
            "author": [
                "Xi Xie",
                "Hongwu Peng",
                "Amit Hasan",
                "Shaoyi Huang",
                "Jiahui Zhao",
                "Haowen Fang",
                "Wei Zhang",
                "Tong Geng",
                "Omer Khan",
                "Caiwen Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11825v1",
                "http://arxiv.org/pdf/2308.11825v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG",
                "I.2; B.6; C.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13550v1",
            "title": "AI and the Future of Work in Statistical Quality Control: Insights from\n  a First Attempt to Augmenting ChatGPT with an SQC Knowledge Base (ChatSQC)",
            "updated": "2023-08-22T22:37:10Z",
            "published": "2023-08-22T22:37:10Z",
            "summary": "We introduce ChatSQC, an innovative chatbot system that combines the power of\nOpenAI's Large Language Models (LLM) with a specific knowledge base in\nStatistical Quality Control (SQC). Our research focuses on enhancing LLMs using\nspecific SQC references, shedding light on how data preprocessing parameters\nand LLM selection impact the quality of generated responses. By illustrating\nthis process, we hope to motivate wider community engagement to refine LLM\ndesign and output appraisal techniques. We also highlight potential research\nopportunities within the SQC domain that can be facilitated by leveraging\nChatSQC, thereby broadening the application spectrum of SQC. A primary goal of\nour work is to equip practitioners with a tool capable of generating precise\nSQC-related responses, thereby democratizing access to advanced SQC knowledge.\nTo continuously improve ChatSQC, we ask the SQC community to provide feedback,\nhighlight potential issues, request additional features, and/or contribute via\npull requests through our public GitHub repository. Additionally, the team will\ncontinue to explore adding supplementary reference material that would further\nimprove the contextual understanding of the chatbot. Overall, ChatSQC serves as\na testament to the transformative potential of AI within SQC, and we hope it\nwill spur further advancements in the integration of AI in this field.",
            "author": [
                "Fadel M. Megahed",
                "Ying-Ju Chen",
                "Inez Zwetsloot",
                "Sven Knoth",
                "Douglas C. Montgomery",
                "L. Allison Jones-Farmer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13550v1",
                "http://arxiv.org/pdf/2308.13550v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11808v1",
            "title": "Apportionable matrices and gracefully labelled graphs",
            "updated": "2023-08-22T22:20:28Z",
            "published": "2023-08-22T22:20:28Z",
            "summary": "To apportion a complex matrix means to apply a similarity so that all entries\nof the resulting matrix have the same magnitude. We initiate the study of\napportionment, both by unitary matrix similarity and general matrix similarity.\nThere are connections between apportionment and classical graph decomposition\nproblems, including graceful labelings of graphs, Hadamard matrices, and\nequiangluar lines, and potential applications to instantaneous uniform mixing\nin quantum walks. The connection between apportionment and graceful labelings\nallows the construction of apportionable matrices from trees and a\ngeneralization of the well-known Eigenvalue Interlacing Inequalities. It is\nshown that every rank one matrix can be apportioned by a unitary similarity,\nbut there are $2\\times 2$ matrices that cannot be apportioned. A necessary\ncondition for a matrix to be apportioned by unitary matrix is established. This\ncondition is used to construct a set of matrices with nonzero Lebesgue measure\nthat are not apportionable by a unitary matrix.",
            "author": [
                "Antwan Clark",
                "Bryan A. Curtis",
                "Edinah K. Gnang",
                "Leslie Hogben"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11808v1",
                "http://arxiv.org/pdf/2308.11808v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C78, 15A04, 15A18"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11804v2",
            "title": "Adversarial Illusions in Multi-Modal Embeddings",
            "updated": "2023-10-06T10:58:23Z",
            "published": "2023-08-22T21:57:22Z",
            "summary": "Multi-modal embeddings encode images, sounds, texts, videos, etc. into a\nsingle embedding space, aligning representations across modalities (e.g.,\nassociate an image of a dog with a barking sound). We show that multi-modal\nembeddings can be vulnerable to an attack we call \"adversarial illusions.\"\nGiven an image or a sound, an adversary can perturb it so as to make its\nembedding close to an arbitrary, adversary-chosen input in another modality.\nThis enables the adversary to align any image and any sound with any text.\n  Adversarial illusions exploit proximity in the embedding space and are thus\nagnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how\nadversarially aligned inputs, generated without knowledge of specific\ndownstream tasks, mislead image generation, text generation, and zero-shot\nclassification.",
            "author": [
                "Eugene Bagdasaryan",
                "Rishi Jha",
                "Tingwei Zhang",
                "Vitaly Shmatikov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11804v2",
                "http://arxiv.org/pdf/2308.11804v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11792v2",
            "title": "Karasu: A Collaborative Approach to Efficient Cluster Configuration for\n  Big Data Analytics",
            "updated": "2023-11-23T14:56:37Z",
            "published": "2023-08-22T21:14:57Z",
            "summary": "Selecting the right resources for big data analytics jobs is hard because of\nthe wide variety of configuration options like machine type and cluster size.\nAs poor choices can have a significant impact on resource efficiency, cost, and\nenergy usage, automated approaches are gaining popularity. Most existing\nmethods rely on profiling recurring workloads to find near-optimal solutions\nover time. Due to the cold-start problem, this often leads to lengthy and\ncostly profiling phases. However, big data analytics jobs across users can\nshare many common properties: they often operate on similar infrastructure,\nusing similar algorithms implemented in similar frameworks. The potential in\nsharing aggregated profiling runs to collaboratively address the cold start\nproblem is largely unexplored.\n  We present Karasu, an approach to more efficient resource configuration\nprofiling that promotes data sharing among users working with similar\ninfrastructures, frameworks, algorithms, or datasets. Karasu trains lightweight\nperformance models using aggregated runtime information of collaborators and\ncombines them into an ensemble method to exploit inherent knowledge of the\nconfiguration search space. Moreover, Karasu allows the optimization of\nmultiple objectives simultaneously. Our evaluation is based on performance data\nfrom diverse workload executions in a public cloud environment. We show that\nKarasu is able to significantly boost existing methods in terms of performance,\nsearch time, and cost, even when few comparable profiling runs are available\nthat share only partial common characteristics with the target job.",
            "author": [
                "Dominik Scheinert",
                "Philipp Wiesner",
                "Thorsten Wittkopp",
                "Lauritz Thamsen",
                "Jonathan Will",
                "Odej Kao"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IPCCC59175.2023.10253884",
                "http://arxiv.org/abs/2308.11792v2",
                "http://arxiv.org/pdf/2308.11792v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11787v2",
            "title": "HypBO: Expert-Guided Chemist-in-the-Loop Bayesian Search for New\n  Materials",
            "updated": "2023-08-24T13:24:45Z",
            "published": "2023-08-22T20:59:21Z",
            "summary": "Robotics and automation offer massive accelerations for solving intractable,\nmultivariate scientific problems such as materials discovery, but the available\nsearch spaces can be dauntingly large. Bayesian optimization (BO) has emerged\nas a popular sample-efficient optimization engine, thriving in tasks where no\nanalytic form of the target function/property is known. Here we exploit expert\nhuman knowledge in the form of hypotheses to direct Bayesian searches more\nquickly to promising regions of chemical space. Previous methods have used\nunderlying distributions derived from existing experimental measurements, which\nis unfeasible for new, unexplored scientific tasks. Also, such distributions\ncannot capture intricate hypotheses. Our proposed method, which we call HypBO,\nuses expert human hypotheses to generate an improved seed of samples.\nUnpromising seeds are automatically discounted, while promising seeds are used\nto augment the surrogate model data, thus achieving better-informed sampling.\nThis process continues in a global versus local search fashion, organized in a\nbilevel optimization framework. We validate the performance of our method on a\nrange of synthetic functions and demonstrate its practical utility on a real\nchemical design task where the use of expert hypotheses accelerates the search\nperformance significantly.",
            "author": [
                "Abdoulatif Cisse",
                "Xenophon Evangelopoulos",
                "Sam Carruthers",
                "Vladimir V. Gusev",
                "Andrew I. Cooper"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11787v2",
                "http://arxiv.org/pdf/2308.11787v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11785v2",
            "title": "Towards Safe Automated Refactoring of Imperative Deep Learning Programs\n  to Graph Execution",
            "updated": "2023-10-10T18:12:18Z",
            "published": "2023-08-22T20:50:19Z",
            "summary": "Efficiency is essential to support responsiveness w.r.t. ever-growing\ndatasets, especially for Deep Learning (DL) systems. DL frameworks have\ntraditionally embraced deferred execution-style DL code -- supporting symbolic,\ngraph-based Deep Neural Network (DNN) computation. While scalable, such\ndevelopment tends to produce code that is error-prone, non-intuitive, and\ndifficult to debug. Consequently, more natural, less error-prone imperative DL\nframeworks encouraging eager execution have emerged at the expense of run-time\nperformance. Though hybrid approaches aim for the \"best of both worlds,\" using\nthem effectively requires subtle considerations to make code amenable to safe,\naccurate, and efficient graph execution -- avoiding performance bottlenecks and\nsemantically inequivalent results. We present our ongoing work on an automated\nrefactoring approach that assists developers in specifying whether and how\ntheir otherwise eagerly-executed imperative DL code could be reliably and\nefficiently executed as graphs at run-time in a semantics-preserving fashion.\nThe approach, based on a novel tensor analysis specifically for imperative DL\ncode, consists of refactoring preconditions for automatically determining when\nit is safe and potentially advantageous to migrate imperative DL code to graph\nexecution and modifying decorator parameters or eagerly executing code already\nrunning as graphs. The approach is being implemented as a PyDev Eclipse IDE\nplug-in and uses the WALA Ariadne analysis framework. We discuss our ongoing\nwork towards optimizing imperative DL code to its full potential.",
            "author": [
                "Raffi Khatchadourian",
                "Tatiana Castro V\u00e9lez",
                "Mehdi Bagherzadeh",
                "Nan Jia",
                "Anita Raja"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11785v2",
                "http://arxiv.org/pdf/2308.11785v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11780v1",
            "title": "Few-shot Anomaly Detection in Text with Deviation Learning",
            "updated": "2023-08-22T20:40:21Z",
            "published": "2023-08-22T20:40:21Z",
            "summary": "Most current methods for detecting anomalies in text concentrate on\nconstructing models solely relying on unlabeled data. These models operate on\nthe presumption that no labeled anomalous examples are available, which\nprevents them from utilizing prior knowledge of anomalies that are typically\npresent in small numbers in many real-world applications. Furthermore, these\nmodels prioritize learning feature embeddings rather than optimizing anomaly\nscores directly, which could lead to suboptimal anomaly scoring and inefficient\nuse of data during the learning process. In this paper, we introduce FATE, a\ndeep few-shot learning-based framework that leverages limited anomaly examples\nand learns anomaly scores explicitly in an end-to-end method using deviation\nlearning. In this approach, the anomaly scores of normal examples are adjusted\nto closely resemble reference scores obtained from a prior distribution.\nConversely, anomaly samples are forced to have anomalous scores that\nconsiderably deviate from the reference score in the upper tail of the prior.\nAdditionally, our model is optimized to learn the distinct behavior of\nanomalies by utilizing a multi-head self-attention layer and multiple instance\nlearning approaches. Comprehensive experiments on several benchmark datasets\ndemonstrate that our proposed approach attains a new level of state-of-the-art\nperformance.",
            "author": [
                "Anindya Sundar Das",
                "Aravind Ajay",
                "Sriparna Saha",
                "Monowar Bhuyan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11780v1",
                "http://arxiv.org/pdf/2308.11780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11764v4",
            "title": "Halo: Estimation and Reduction of Hallucinations in Open-Source Weak\n  Large Language Models",
            "updated": "2023-09-13T18:01:36Z",
            "published": "2023-08-22T20:12:49Z",
            "summary": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP). Although convenient for research and practical applications, open-source\nLLMs with fewer parameters often suffer from severe hallucinations compared to\ntheir larger counterparts. This paper focuses on measuring and reducing\nhallucinations in BLOOM 7B, a representative of such weaker open-source LLMs\nthat are publicly available for research and commercial applications. We\nintroduce HaloCheck, a lightweight BlackBox knowledge-free framework designed\nto quantify the severity of hallucinations in LLMs. Additionally, we explore\ntechniques like knowledge injection and teacher-student approaches to alleviate\nhallucinations in low-parameter LLMs. Our experiments effectively demonstrate\nthe reduction of hallucinations in challenging domains for these LLMs.",
            "author": [
                "Mohamed Elaraby",
                "Mengyin Lu",
                "Jacob Dunn",
                "Xueying Zhang",
                "Yu Wang",
                "Shizhu Liu",
                "Pingchuan Tian",
                "Yuping Wang",
                "Yuxuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11764v4",
                "http://arxiv.org/pdf/2308.11764v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11760v2",
            "title": "The Jacobian of a Sixth-Root-of-Unity Matroid",
            "updated": "2023-09-05T00:40:04Z",
            "published": "2023-08-22T20:07:06Z",
            "summary": "The Jacobian group (also called the sandpile group, Picard group, or critical\ngroup) of a graph or, more generally, of a regular matroid has been well\nstudied. Sixth-root-of-unity matroids, also called complex unimodular matroids,\nare generalizations of regular matroids. This paper provides a definition, and\nestablishes some basic properties, of the Jacobian group of a\nsixth-root-of-unity matroid.",
            "author": [
                "Matthew Baker",
                "Changxin Ding",
                "Xu Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11760v2",
                "http://arxiv.org/pdf/2308.11760v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11754v1",
            "title": "Multi-Instance Adversarial Attack on GNN-Based Malicious Domain\n  Detection",
            "updated": "2023-08-22T19:51:16Z",
            "published": "2023-08-22T19:51:16Z",
            "summary": "Malicious domain detection (MDD) is an open security challenge that aims to\ndetect if an Internet domain is associated with cyber-attacks. Among many\napproaches to this problem, graph neural networks (GNNs) are deemed highly\neffective. GNN-based MDD uses DNS logs to represent Internet domains as nodes\nin a maliciousness graph (DMG) and trains a GNN to infer their maliciousness by\nleveraging identified malicious domains. Since this method relies on accessible\nDNS logs to construct DMGs, it exposes a vulnerability for adversaries to\nmanipulate their domain nodes' features and connections within DMGs. Existing\nresearch mainly concentrates on threat models that manipulate individual\nattacker nodes. However, adversaries commonly generate multiple domains to\nachieve their goals economically and avoid detection. Their objective is to\nevade discovery across as many domains as feasible. In this work, we call the\nattack that manipulates several nodes in the DMG concurrently a multi-instance\nevasion attack. We present theoretical and empirical evidence that the existing\nsingle-instance evasion techniques for are inadequate to launch multi-instance\nevasion attacks against GNN-based MDDs. Therefore, we introduce MintA, an\ninference-time multi-instance adversarial attack on GNN-based MDDs. MintA\nenhances node and neighborhood evasiveness through optimized perturbations and\noperates successfully with only black-box access to the target model,\neliminating the need for knowledge about the model's specifics or non-adversary\nnodes. We formulate an optimization challenge for MintA, achieving an\napproximate solution. Evaluating MintA on a leading GNN-based MDD technique\nwith real-world data showcases an attack success rate exceeding 80%. These\nfindings act as a warning for security experts, underscoring GNN-based MDDs'\nsusceptibility to practical attacks that can undermine their effectiveness and\nbenefits.",
            "author": [
                "Mahmoud Nazzal",
                "Issa Khalil",
                "Abdallah Khreishah",
                "NhatHai Phan",
                "Yao Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11754v1",
                "http://arxiv.org/pdf/2308.11754v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11744v1",
            "title": "Efficient Controllable Multi-Task Architectures",
            "updated": "2023-08-22T19:09:56Z",
            "published": "2023-08-22T19:09:56Z",
            "summary": "We aim to train a multi-task model such that users can adjust the desired\ncompute budget and relative importance of task performances after deployment,\nwithout retraining. This enables optimizing performance for dynamically varying\nuser needs, without heavy computational overhead to train and save models for\nvarious scenarios. To this end, we propose a multi-task model consisting of a\nshared encoder and task-specific decoders where both encoder and decoder\nchannel widths are slimmable. Our key idea is to control the task importance by\nvarying the capacities of task-specific decoders, while controlling the total\ncomputational cost by jointly adjusting the encoder capacity. This improves\noverall accuracy by allowing a stronger encoder for a given budget, increases\ncontrol over computational cost, and delivers high-quality slimmed\nsub-architectures based on user's constraints. Our training strategy involves a\nnovel 'Configuration-Invariant Knowledge Distillation' loss that enforces\nbackbone representations to be invariant under different runtime width\nconfigurations to enhance accuracy. Further, we present a simple but effective\nsearch algorithm that translates user constraints to runtime width\nconfigurations of both the shared encoder and task decoders, for sampling the\nsub-architectures. The key rule for the search algorithm is to provide a larger\ncomputational budget to the higher preferred task decoder, while searching a\nshared encoder configuration that enhances the overall MTL performance. Various\nexperiments on three multi-task benchmarks (PASCALContext, NYUDv2, and\nCIFAR100-MTL) with diverse backbone architectures demonstrate the advantage of\nour approach. For example, our method shows a higher controllability by ~33.5%\nin the NYUD-v2 dataset over prior methods, while incurring much less compute\ncost.",
            "author": [
                "Abhishek Aich",
                "Samuel Schulter",
                "Amit K. Roy-Chowdhury",
                "Manmohan Chandraker",
                "Yumin Suh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11744v1",
                "http://arxiv.org/pdf/2308.11744v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11738v1",
            "title": "Lifted Inference beyond First-Order Logic",
            "updated": "2023-08-22T18:58:21Z",
            "published": "2023-08-22T18:58:21Z",
            "summary": "Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic\ninference in statistical relational learning models. As WFOMC is known to be\nintractable in general ($\\#$P-complete), logical fragments that admit\npolynomial time WFOMC are of significant interest. Such fragments are called\ndomain liftable. Recent works have shown that the two-variable fragment of\nfirst order logic extended with counting quantifiers ($\\mathrm{C^2}$) is\ndomain-liftable. However, many properties of real-world data, like acyclicity\nin citation networks and connectivity in social networks, cannot be modeled in\n$\\mathrm{C^2}$, or first order logic in general. In this work, we expand the\ndomain liftability of $\\mathrm{C^2}$ with multiple such properties. We show\nthat any $\\mathrm{C^2}$ sentence remains domain liftable when one of its\nrelations is restricted to represent a directed acyclic graph, a connected\ngraph, a tree (resp. a directed tree) or a forest (resp. a directed forest).\nAll our results rely on a novel and general methodology of \"counting by\nsplitting\". Besides their application to probabilistic inference, our results\nprovide a general framework for counting combinatorial structures. We expand a\nvast array of previous results in discrete mathematics literature on directed\nacyclic graphs, phylogenetic networks, etc.",
            "author": [
                "Sagar Malhotra",
                "Davide Bizzaro",
                "Luciano Serafini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11738v1",
                "http://arxiv.org/pdf/2308.11738v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11734v1",
            "title": "Dynamic Compact Data Structure for Temporal Reachability with Unsorted\n  Contact Insertions",
            "updated": "2023-08-22T18:46:38Z",
            "published": "2023-08-22T18:46:38Z",
            "summary": "Temporal graphs represent interactions between entities over time. Deciding\nwhether entities can reach each other through temporal paths is useful for\nvarious applications such as in communication networks and epidemiology.\nPrevious works have studied the scenario in which addition of new interactions\ncan happen at any point in time. A known strategy maintains, incrementally, a\nTimed Transitive Closure by using a dynamic data structure composed of $O(n^2)$\nbinary search trees containing non-nested time intervals. However, space usage\nfor storing these trees grows rapidly as more interactions are inserted. In\nthis paper, we present a compact data structures that represent each tree as\ntwo dynamic bit-vectors. In our experiments, we observed that our data\nstructure improves space usage while having similar time performance for\nincremental updates when comparing with the previous strategy in temporally\ndense temporal graphs.",
            "author": [
                "Luiz Fernando Afra Brito",
                "Marcelo Keese Albertini",
                "Bruno Augusto Nassif Traven\u00e7olo",
                "Gonzalo Navarro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11734v1",
                "http://arxiv.org/pdf/2308.11734v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11730v1",
            "title": "Knowledge Graph Prompting for Multi-Document Question Answering",
            "updated": "2023-08-22T18:41:31Z",
            "published": "2023-08-22T18:41:31Z",
            "summary": "The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has\nachieved remarkable success in open-domain question answering (OD-QA). However,\nfew works explore this paradigm in the scenario of multi-document question\nanswering (MD-QA), a task demanding a thorough understanding of the logical\nassociations among the contents and structures of different documents. To fill\nthis crucial gap, we propose a Knowledge Graph Prompting (KGP) method to\nformulate the right context in prompting LLMs for MD-QA, which consists of a\ngraph construction module and a graph traversal module. For graph construction,\nwe create a knowledge graph (KG) over multiple documents with nodes symbolizing\npassages or document structures (e.g., pages/tables), and edges denoting the\nsemantic/lexical similarity between passages or intra-document structural\nrelations. For graph traversal, we design an LM-guided graph traverser that\nnavigates across nodes and gathers supporting passages assisting LLMs in MD-QA.\nThe constructed graph serves as the global ruler that regulates the\ntransitional space among passages and reduces retrieval latency. Concurrently,\nthe LM-guided traverser acts as a local navigator that gathers pertinent\ncontext to progressively approach the question and guarantee retrieval quality.\nExtensive experiments underscore the efficacy of KGP for MD-QA, signifying the\npotential of leveraging graphs in enhancing the prompt design for LLMs. Our\ncode is at https://github.com/YuWVandy/KG-LLM-MDQA.",
            "author": [
                "Yu Wang",
                "Nedim Lipka",
                "Ryan A. Rossi",
                "Alexa Siu",
                "Ruiyi Zhang",
                "Tyler Derr"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11730v1",
                "http://arxiv.org/pdf/2308.11730v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11701v1",
            "title": "Equivariant localization for AdS/CFT",
            "updated": "2023-08-22T18:00:00Z",
            "published": "2023-08-22T18:00:00Z",
            "summary": "We explain how equivariant localization may be applied to AdS/CFT to compute\nvarious BPS observables in gravity, such as central charges and conformal\ndimensions of chiral primary operators, without solving the supergravity\nequations. The key ingredient is that supersymmetric AdS solutions with an\nR-symmetry are equipped with a set of equivariantly closed forms. These may in\nturn be used to impose flux quantization and compute observables for\nsupergravity solutions, using only topological information and the\nBerline--Vergne--Atiyah--Bott fixed point formula. We illustrate the formalism\nby considering $AdS_5\\times M_6$ and $AdS_3\\times M_8$ solutions of $D=11$\nsupergravity. As well as recovering results for many classes of well-known\nsupergravity solutions, without using any knowledge of their explicit form, we\nalso compute central charges for which explicit supergravity solutions have not\nbeen constructed.",
            "author": [
                "Pietro Benetti Genolini",
                "Jerome P. Gauntlett",
                "James Sparks"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11701v1",
                "http://arxiv.org/pdf/2308.11701v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11613v2",
            "title": "Ascending Subgraph Decomposition",
            "updated": "2023-09-05T12:50:42Z",
            "published": "2023-08-22T17:58:11Z",
            "summary": "A typical theme for many well-known decomposition problems is to show that\nsome obvious necessary conditions for decomposing a graph $G$ into copies $H_1,\n\\ldots, H_m$ are also sufficient. One such problem was posed in 1987, by Alavi,\nBoals, Chartrand, Erd\\H{o}s, and Oellerman. They conjectured that the edges of\nevery graph with $\\binom{m+1}2$ edges can be decomposed into subgraphs $H_1,\n\\dots, H_m$ such that each $H_i$ has $i$ edges and is isomorphic to a subgraph\nof $H_{i+1}$. In this paper we prove this conjecture for sufficiently large\n$m$.",
            "author": [
                "Kyriakos Katsamaktsis",
                "Shoham Letzter",
                "Alexey Pokrovskiy",
                "Benny Sudakov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11613v2",
                "http://arxiv.org/pdf/2308.11613v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C70",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11598v1",
            "title": "The grapheme-valued Wright-Fisher diffusion with mutation",
            "updated": "2023-08-22T17:46:50Z",
            "published": "2023-08-22T17:46:50Z",
            "summary": "In [Athreya, den Hollander, R\\\"ollin; 2021, arXiv:1908.06241] models from\npopulation genetics were used to define stochastic dynamics in the space of\ngraphons arising as continuum limits of dense graphs. In the present paper we\nexhibit an example of a simple neutral population genetics model for which this\ndynamics is a Markovian diffusion that can be characterised as the solution of\na martingale problem. In particular, we consider a Markov chain in the space of\nfinite graphs that resembles a Moran model with resampling and mutation. We\nencode the finite graphs as graphemes, which can be represented as a triple\nconsisting of a vertex set, an adjacency matrix and a sampling measure. We\nequip the space of graphons with convergence of sample subgraph densities and\nshow that the grapheme-valued Markov chain converges to a grapheme-valued\ndiffusion as the number of vertices goes to infinity. We show that the\ngrapheme-valued diffusion has a stationary distribution that is linked to the\nPoisson-Dirichlet distribution. In a companion paper [Greven, den Hollander,\nKlimovsky, Winter; 2023], we build up a general theory for obtaining\ngrapheme-valued diffusions via genealogies of models in population genetics.",
            "author": [
                "Andreas Greven",
                "Frank den Hollander",
                "Anton Klimovsky",
                "Anita Winter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11598v1",
                "http://arxiv.org/pdf/2308.11598v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "05C80, 60J68, 60J70, 92D25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11587v1",
            "title": "Graph-like Scheduling Problems and Property B",
            "updated": "2023-08-22T17:35:13Z",
            "published": "2023-08-22T17:35:13Z",
            "summary": "Breuer and Klivans defined a diverse class of scheduling problems in terms of\nBoolean formulas with atomic clauses that are inequalities. We consider what we\ncall graph-like scheduling problems. These are Boolean formulas that are\nconjunctions of disjunctions of atomic clauses $(x_i \\neq x_j)$. These problems\ngeneralize proper coloring in graphs and hypergraphs. We focus on the existence\nof a solution with all $x_i$ taking the value of $0$ or $1$ (i.e. problems\nanalogous to the bipartite case). When a graph-like scheduling problem has such\na solution, we say it has property B just as is done for $2$-colorable\nhypergraphs. We define the notion of a $\\lambda$-uniform graph-like scheduling\nproblem for any integer partition $\\lambda$. Some bounds are attained for the\nsize of the smallest $\\lambda$-uniform graph-like scheduling problems without\nproperty B. We make use of both random and constructive methods to obtain\nbounds. Just as in the case of hypergraphs finding tight bounds remains an open\nproblem.",
            "author": [
                "John Machacek"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11587v1",
                "http://arxiv.org/pdf/2308.11587v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "Primary 05D40, Secondary 5C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11573v1",
            "title": "G3Reg: Pyramid Graph-based Global Registration using Gaussian Ellipsoid\n  Model",
            "updated": "2023-08-22T17:23:00Z",
            "published": "2023-08-22T17:23:00Z",
            "summary": "This study introduces a novel framework, G3Reg, for fast and robust global\nregistration of LiDAR point clouds. In contrast to conventional complex\nkeypoints and descriptors, we extract fundamental geometric primitives\nincluding planes, clusters, and lines (PCL) from the raw point cloud to obtain\nlow-level semantic segments. Each segment is formulated as a unified Gaussian\nEllipsoid Model (GEM) by employing a probability ellipsoid to ensure the ground\ntruth centers are encompassed with a certain degree of probability. Utilizing\nthese GEMs, we then present a distrust-and-verify scheme based on a Pyramid\nCompatibility Graph for Global Registration (PAGOR). Specifically, we establish\nan upper bound, which can be traversed based on the confidence level for\ncompatibility testing to construct the pyramid graph. Gradually, we solve\nmultiple maximum cliques (MAC) for each level of the graph, generating numerous\ntransformation candidates. In the verification phase, we adopt a precise and\nefficient metric for point cloud alignment quality, founded on geometric\nprimitives, to identify the optimal candidate. The performance of the algorithm\nis extensively validated on three publicly available datasets and a\nself-collected multi-session dataset, without changing any parameter settings\nin the experimental evaluation. The results exhibit superior robustness and\nreal-time performance of the G3Reg framework compared to state-of-the-art\nmethods. Furthermore, we demonstrate the potential for integrating individual\nGEM and PAGOR components into other algorithmic frameworks to enhance their\nefficacy. To advance further research and promote community understanding, we\nhave publicly shared the source code.",
            "author": [
                "Zhijian Qiao",
                "Zehuan Yu",
                "Binqian Jiang",
                "Huan Yin",
                "Shaojie Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11573v1",
                "http://arxiv.org/pdf/2308.11573v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11572v1",
            "title": "Neumaier Cayley graphs",
            "updated": "2023-08-22T17:22:23Z",
            "published": "2023-08-22T17:22:23Z",
            "summary": "A Neumaier graph is a non-complete edge-regular graph with the property that\nit has a regular clique. In this paper, we study Neumaier Cayley graphs. We\ngive a necessary and sufficient condition under which a Neumaier Cayley graph\nis a strongly regular Neumaier Cayley graph. We also characterize Neumaier\nCayley graphs with small valency at most $10$.",
            "author": [
                "Mojtaba Jazaeri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11572v1",
                "http://arxiv.org/pdf/2308.11572v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11570v1",
            "title": "Central limit theorem for crossings in randomly embedded graphs",
            "updated": "2023-08-22T17:21:43Z",
            "published": "2023-08-22T17:21:43Z",
            "summary": "We consider the number of crossings in a random embedding of a graph, $G$,\nwith vertices in convex position. We give explicit formulas for the mean and\nvariance of the number of crossings as a function of various subgraph counts of\n$G$. Using Stein's method and size-bias coupling, we prove an upper bound on\nthe Kolmogorov distance between the distribution of the number of crossings and\na standard normal random variable. As an application, we establish central\nlimit theorems, along with convergence rates, for the number of crossings in\nrandom matchings, path graphs, cycle graphs, and the disjoint union of\ntriangles.",
            "author": [
                "Santiago Arenas-Velilla",
                "Octavio Arizmendi",
                "J. E. Paguyo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11570v1",
                "http://arxiv.org/pdf/2308.11570v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CO",
                "60C05, 60F05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11561v4",
            "title": "Target-Grounded Graph-Aware Transformer for Aerial Vision-and-Dialog\n  Navigation",
            "updated": "2023-09-04T09:33:35Z",
            "published": "2023-08-22T16:45:35Z",
            "summary": "This report details the methods of the winning entry of the AVDN Challenge in\nICCV CLVL 2023. The competition addresses the Aerial Navigation from Dialog\nHistory (ANDH) task, which requires a drone agent to associate dialog history\nwith aerial observations to reach the destination. For better cross-modal\ngrounding abilities of the drone agent, we propose a Target-Grounded\nGraph-Aware Transformer (TG-GAT) framework. Concretely, TG-GAT first leverages\na graph-aware transformer to capture spatiotemporal dependency, which benefits\nnavigation state tracking and robust action planning. In addition,an auxiliary\nvisual grounding task is devised to boost the agent's awareness of referred\nlandmarks. Moreover, a hybrid augmentation strategy based on large language\nmodels is utilized to mitigate data scarcity limitations. Our TG-GAT framework\nwon the AVDN Challenge, with 2.2% and 3.0% absolute improvements over the\nbaseline on SPL and SR metrics, respectively. The code is available at\nhttps://github.com/yifeisu/TG-GAT.",
            "author": [
                "Yifei Su",
                "Dong An",
                "Yuan Xu",
                "Kehan Chen",
                "Yan Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11561v4",
                "http://arxiv.org/pdf/2308.11561v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11560v4",
            "title": "Calculation of lepton magnetic moments in quantum electrodynamics: a\n  justification of the flexible divergence elimination method",
            "updated": "2023-12-07T16:55:07Z",
            "published": "2023-08-22T16:43:38Z",
            "summary": "The flexible method of reduction to finite integrals, briefly described in\nearlier publications of the author, is described in detail. The method is\nsuitable for the calculation of all quantum electrodynamical contributions to\nthe magnetic moments of leptons. It includes mass-dependent contributions. The\nmethod removes all divergences (UV, IR and mixed) point-by-point in Feynman\nparametric space without any usage of limit-like regularizations. It yields a\nfinite integral for each individual Feynman graph. The subtraction procedure is\nbased on the use of linear operators applied to the Feynman amplitudes of\nUV-divergent subgraphs; a placement of all terms in the same Feynman parametric\nspace is implied. The final result is simply the sum of the individual graph\ncontributions; no residual renormalization is required. The method also allows\nus to split the total contribution into the contributions of small\ngauge-invariant classes. The procedure offers a great freedom in the choice of\nthe linear operators. This freedom can be used for improving the computation\nspeed and for a reliability check. The mechanism of divergence elimination is\nexplained, as well as the equivalence of the method and the on-shell\nrenormalization. For illustrative purposes, all 4-loop contributions to the\nanomalous magnetic moments of the electron and muon are given for each small\ngauge-invariant class, as well as their comparison with previously known\nresults. This also includes the contributions that depend on the ratios of the\ntau-lepton mass to the electron and muon mass.",
            "author": [
                "Sergey Volkov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11560v4",
                "http://arxiv.org/pdf/2308.11560v4"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11543v1",
            "title": "Representational differences in how students compare measurements",
            "updated": "2023-08-22T16:20:59Z",
            "published": "2023-08-22T16:20:59Z",
            "summary": "Measurement uncertainty plays a critical role in the process of experimental\nphysics. It is useful to be able to assess student proficiency around the topic\nto iteratively improve instruction and student learning. For the topic of\nmeasurement uncertainty, we developed an assessment tool called the Survey of\nPhysics Reasoning on Uncertainty Concepts in Experiments (SPRUCE), which aims\nto assess students' knowledge, and use of, a variety of concepts related to\nmeasurement uncertainty. This assessment includes two isomorphic questions\nfocused on comparing two measurements with uncertainty. One is presented\nnumerically and the other pictorially. Despite the questions probing identical\nconcepts, students answer them in different ways, indicating that they rely on\ndistinct modes of representation to make sense of measurement uncertainty and\ncomparisons. Specifically, students score much higher on the pictorially\nrepresented item, which suggests possible instructional changes to leverage\nstudents' use of representations while working with concepts of measurement\nuncertainty.",
            "author": [
                "Gayle Geschwind",
                "Michael Vignal",
                "H. J. Lewandowski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11543v1",
                "http://arxiv.org/pdf/2308.11543v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.03208v1",
            "title": "A Circuit Domain Generalization Framework for Efficient Logic Synthesis\n  in Chip Design",
            "updated": "2023-08-22T16:18:48Z",
            "published": "2023-08-22T16:18:48Z",
            "summary": "Logic Synthesis (LS) plays a vital role in chip design -- a cornerstone of\nthe semiconductor industry. A key task in LS is to transform circuits --\nmodeled by directed acyclic graphs (DAGs) -- into simplified circuits with\nequivalent functionalities. To tackle this task, many LS operators apply\ntransformations to subgraphs -- rooted at each node on an input DAG --\nsequentially. However, we found that a large number of transformations are\nineffective, which makes applying these operators highly time-consuming. In\nparticular, we notice that the runtime of the Resub and Mfs2 operators often\ndominates the overall runtime of LS optimization processes. To address this\nchallenge, we propose a novel data-driven LS operator paradigm, namely PruneX,\nto reduce ineffective transformations. The major challenge of developing PruneX\nis to learn models that well generalize to unseen circuits, i.e., the\nout-of-distribution (OOD) generalization problem. Thus, the major technical\ncontribution of PruneX is the novel circuit domain generalization framework,\nwhich learns domain-invariant representations based on the\ntransformation-invariant domain-knowledge. To the best of our knowledge, PruneX\nis the first approach to tackle the OOD problem in LS operators. We integrate\nPruneX with the aforementioned Resub and Mfs2 operators. Experiments\ndemonstrate that PruneX significantly improves their efficiency while keeping\ncomparable optimization performance on industrial and very large-scale\ncircuits, achieving up to $3.1\\times$ faster runtime.",
            "author": [
                "Zhihai Wang",
                "Lei Chen",
                "Jie Wang",
                "Xing Li",
                "Yinqi Bai",
                "Xijun Li",
                "Mingxuan Yuan",
                "Jianye Hao",
                "Yongdong Zhang",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2309.03208v1",
                "http://arxiv.org/pdf/2309.03208v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11540v1",
            "title": "Central limit theorem for linear eigenvalue statistics of the adjacency\n  matrices of random simplicial complexes",
            "updated": "2023-08-22T16:12:34Z",
            "published": "2023-08-22T16:12:34Z",
            "summary": "We study the adjacency matrix of the Linial-Meshulam complex model, which is\na higher-dimensional generalization of the Erd\\H{o}s-R\\'enyi graph model.\nRecently, Knowles and Rosenthal proved that the empirical spectral distribution\nof the adjacency matrix is asymptotically given by Wigner's semicircle law in a\ndiluted regime. In this article, we prove a central limit theorem for the\nlinear eigenvalue statistics for test functions of polynomial growth that is of\nclass $C^{2}$ on a closed interval. The proof is based on higher-dimensional\ncombinatorial enumerations and concentration properties of random symmetric\nmatrices. Furthermore, when the test function is a polynomial function, we\nobtain the explicit formula for the variance of the limiting Gaussian\ndistribution.",
            "author": [
                "Shu Kanazawa",
                "Khanh Duy Trinh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11540v1",
                "http://arxiv.org/pdf/2308.11540v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60C05, 60B20, 05E45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11538v1",
            "title": "Algebraic Geometry of Quantum Graphical Models",
            "updated": "2023-08-22T16:07:07Z",
            "published": "2023-08-22T16:07:07Z",
            "summary": "Algebro-geometric methods have proven to be very successful in the study of\ngraphical models in statistics. In this paper we introduce the foundations to\ncarry out a similar study of their quantum counterparts. These quantum\ngraphical models are families of quantum states satisfying certain locality or\ncorrelation conditions encoded by a graph. We lay out several ways to associate\nan algebraic variety to a quantum graphical model. The classical graphical\nmodels can be recovered from most of these varieties by restricting to quantum\nstates represented by diagonal matrices. We study fundamental properties of\nthese varieties and provide algorithms to compute their defining equations.\nMoreover, we study quantum information projections to quantum exponential\nfamilies defined by graphs and prove a quantum analogue of Birch's Theorem.",
            "author": [
                "Eliana Duarte",
                "Dmitrii Pavlov",
                "Maximilian Wiesmann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11538v1",
                "http://arxiv.org/pdf/2308.11538v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "quant-ph",
                "14Q99, 81P45, 62R01"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11537v1",
            "title": "BELB: a Biomedical Entity Linking Benchmark",
            "updated": "2023-08-22T16:05:18Z",
            "published": "2023-08-22T16:05:18Z",
            "summary": "Biomedical entity linking (BEL) is the task of grounding entity mentions to a\nknowledge base. It plays a vital role in information extraction pipelines for\nthe life sciences literature. We review recent work in the field and find that,\nas the task is absent from existing benchmarks for biomedical text mining,\ndifferent studies adopt different experimental setups making comparisons based\non published numbers problematic. Furthermore, neural systems are tested\nprimarily on instances linked to the broad coverage knowledge base UMLS,\nleaving their performance to more specialized ones, e.g. genes or variants,\nunderstudied. We therefore developed BELB, a Biomedical Entity Linking\nBenchmark, providing access in a unified format to 11 corpora linked to 7\nknowledge bases and spanning six entity types: gene, disease, chemical,\nspecies, cell line and variant. BELB greatly reduces preprocessing overhead in\ntesting BEL systems on multiple corpora offering a standardized testbed for\nreproducible experiments. Using BELB we perform an extensive evaluation of six\nrule-based entity-specific systems and three recent neural approaches\nleveraging pre-trained language models. Our results reveal a mixed picture\nshowing that neural approaches fail to perform consistently across entity\ntypes, highlighting the need of further studies towards entity-agnostic models.",
            "author": [
                "Samuele Garda",
                "Leon Weber-Genzel",
                "Robert Martin",
                "Ulf Leser"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11537v1",
                "http://arxiv.org/pdf/2308.11537v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11517v1",
            "title": "Zero Forcing on 2-connected Outerplanar Graphs",
            "updated": "2023-08-22T15:45:55Z",
            "published": "2023-08-22T15:45:55Z",
            "summary": "We determine upper and lower bounds on the zero forcing number of 2-connected\nouterplanar graphs in terms of the structure of the weak dual. We show that the\nupper bound is always at most half the number of vertices of the graph. This\nwork generalizes work of Hern\\'andez, Ranilla and Ranilla-Cortina who proved a\nsimilar result for maximal outerplanar graphs.",
            "author": [
                "Nolan Ison",
                "Mark Kempton",
                "Franklin Kenter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11517v1",
                "http://arxiv.org/pdf/2308.11517v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C57, 05C10, 05C50, 05C40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11507v2",
            "title": "Unsupervised Prototype Adapter for Vision-Language Models",
            "updated": "2023-08-25T00:07:50Z",
            "published": "2023-08-22T15:28:49Z",
            "summary": "Recently, large-scale pre-trained vision-language models (e.g. CLIP and\nALIGN) have demonstrated remarkable effectiveness in acquiring transferable\nvisual representations. To leverage the valuable knowledge encoded within these\nmodels for downstream tasks, several fine-tuning approaches, including prompt\ntuning methods and adapter-based methods, have been developed to adapt\nvision-language models effectively with supervision. However, these methods\nrely on the availability of annotated samples, which can be labor-intensive and\ntime-consuming to acquire, thus limiting scalability. To address this issue, in\nthis work, we design an unsupervised fine-tuning approach for vision-language\nmodels called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for\nthe unannotated target datasets, we leverage the text-image aligning capability\nof CLIP to automatically select the most confident samples for each class.\nUtilizing these selected samples, we generate class prototypes, which serve as\nthe initialization for the learnable prototype model. After fine-tuning, the\nprototype model prediction is combined with the original CLIP's prediction by a\nresidual connection to perform downstream recognition tasks. Our extensive\nexperimental results on image recognition and domain generalization show that\nthe proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter,\nand also the state-of-the-art UPL method by large margins.",
            "author": [
                "Yi Zhang",
                "Ce Zhang",
                "Xueting Hu",
                "Zhihai He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11507v2",
                "http://arxiv.org/pdf/2308.11507v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11492v1",
            "title": "A LiDAR-Inertial SLAM Tightly-Coupled with Dropout-Tolerant GNSS Fusion\n  for Autonomous Mine Service Vehicles",
            "updated": "2023-08-22T15:14:40Z",
            "published": "2023-08-22T15:14:40Z",
            "summary": "Multi-modal sensor integration has become a crucial prerequisite for the\nreal-world navigation systems. Recent studies have reported successful\ndeployment of such system in many fields. However, it is still challenging for\nnavigation tasks in mine scenes due to satellite signal dropouts, degraded\nperception, and observation degeneracy. To solve this problem, we propose a\nLiDAR-inertial odometry method in this paper, utilizing both Kalman filter and\ngraph optimization. The front-end consists of multiple parallel running\nLiDAR-inertial odometries, where the laser points, IMU, and wheel odometer\ninformation are tightly fused in an error-state Kalman filter. Instead of the\ncommonly used feature points, we employ surface elements for registration. The\nback-end construct a pose graph and jointly optimize the pose estimation\nresults from inertial, LiDAR odometry, and global navigation satellite system\n(GNSS). Since the vehicle has a long operation time inside the tunnel, the\nlargely accumulated drift may be not fully by the GNSS measurements. We hereby\nleverage a loop closure based re-initialization process to achieve full\nalignment. In addition, the system robustness is improved through handling data\nloss, stream consistency, and estimation error. The experimental results show\nthat our system has a good tolerance to the long-period degeneracy with the\ncooperation different LiDARs and surfel registration, achieving meter-level\naccuracy even for tens of minutes running during GNSS dropouts.",
            "author": [
                "Yusheng Wang",
                "Yidong Lou",
                "Weiwei Song",
                "Bing Zhan",
                "Feihuang Xia",
                "Qigeng Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11492v1",
                "http://arxiv.org/pdf/2308.11492v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11489v2",
            "title": "Learning from Semantic Alignment between Unpaired Multiviews for\n  Egocentric Video Recognition",
            "updated": "2023-08-23T16:16:44Z",
            "published": "2023-08-22T15:10:42Z",
            "summary": "We are concerned with a challenging scenario in unpaired multiview video\nlearning. In this case, the model aims to learn comprehensive multiview\nrepresentations while the cross-view semantic information exhibits variations.\nWe propose Semantics-based Unpaired Multiview Learning (SUM-L) to tackle this\nunpaired multiview learning problem. The key idea is to build cross-view\npseudo-pairs and do view-invariant alignment by leveraging the semantic\ninformation of videos. To facilitate the data efficiency of multiview learning,\nwe further perform video-text alignment for first-person and third-person\nvideos, to fully leverage the semantic knowledge to improve video\nrepresentations. Extensive experiments on multiple benchmark datasets verify\nthe effectiveness of our framework. Our method also outperforms multiple\nexisting view-alignment methods, under the more challenging scenario than\ntypical paired or unpaired multimodal or multiview learning. Our code is\navailable at https://github.com/wqtwjt1996/SUM-L.",
            "author": [
                "Qitong Wang",
                "Long Zhao",
                "Liangzhe Yuan",
                "Ting Liu",
                "Xi Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11489v2",
                "http://arxiv.org/pdf/2308.11489v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11487v3",
            "title": "Free Lunch for Gait Recognition: A Novel Relation Descriptor",
            "updated": "2023-12-05T03:37:33Z",
            "published": "2023-08-22T15:06:14Z",
            "summary": "Gait recognition is to seek correct matches for query individuals by their\nunique walking patterns. However, current methods focus solely on extracting\nindividual-specific features, overlooking ``interpersonal\" relationships. In\nthis paper, we propose a novel $\\textbf{Relation Descriptor}$ that captures not\nonly individual features but also relations between test gaits and pre-selected\ngait anchors. Specifically, we reinterpret classifier weights as gait anchors\nand compute similarity scores between test features and these anchors, which\nre-expresses individual gait features into a similarity relation distribution.\nIn essence, the relation descriptor offers a holistic perspective that\nleverages the collective knowledge stored within the classifier's weights,\nemphasizing meaningful patterns and enhancing robustness. Despite its\npotential, relation descriptor poses dimensionality challenges since its\ndimension depends on the training set's identity count. To address this, we\npropose Farthest gait-Anchor Selection to identify the most discriminative gait\nanchors and an Orthogonal Regularization Loss to increase diversity within gait\nanchors. Compared to individual-specific features extracted from the backbone,\nour relation descriptor can boost the performance nearly without any extra\ncosts. We evaluate the effectiveness of our method on the popular GREW, Gait3D,\nOU-MVLP, CASIA-B, and CCPG, showing that our method consistently outperforms\nthe baselines and achieves state-of-the-art performance.",
            "author": [
                "Jilong Wang",
                "Saihui Hou",
                "Yan Huang",
                "Chunshui Cao",
                "Xu Liu",
                "Yongzhen Huang",
                "Tianzhu Zhang",
                "Liang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11487v3",
                "http://arxiv.org/pdf/2308.11487v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11681v2",
            "title": "VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video\n  Anomaly Detection",
            "updated": "2023-08-25T06:55:14Z",
            "published": "2023-08-22T14:58:36Z",
            "summary": "The recent contrastive language-image pre-training (CLIP) model has shown\ngreat success in a wide range of image-level tasks, revealing remarkable\nability for learning powerful visual representations with rich semantics. An\nopen and worthwhile problem is efficiently adapting such a strong model to the\nvideo domain and designing a robust video anomaly detector. In this work, we\npropose VadCLIP, a new paradigm for weakly supervised video anomaly detection\n(WSVAD) by leveraging the frozen CLIP model directly without any pre-training\nand fine-tuning process. Unlike current works that directly feed extracted\nfeatures into the weakly supervised classifier for frame-level binary\nclassification, VadCLIP makes full use of fine-grained associations between\nvision and language on the strength of CLIP and involves dual branch. One\nbranch simply utilizes visual features for coarse-grained binary\nclassification, while the other fully leverages the fine-grained language-image\nalignment. With the benefit of dual branch, VadCLIP achieves both\ncoarse-grained and fine-grained video anomaly detection by transferring\npre-trained knowledge from CLIP to WSVAD task. We conduct extensive experiments\non two commonly-used benchmarks, demonstrating that VadCLIP achieves the best\nperformance on both coarse-grained and fine-grained WSVAD, surpassing the\nstate-of-the-art methods by a large margin. Specifically, VadCLIP achieves\n84.51% AP and 88.02% AUC on XD-Violence and UCF-Crime, respectively. Code and\nfeatures will be released to facilitate future VAD research.",
            "author": [
                "Peng Wu",
                "Xuerong Zhou",
                "Guansong Pang",
                "Lingru Zhou",
                "Qingsen Yan",
                "Peng Wang",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11681v2",
                "http://arxiv.org/pdf/2308.11681v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11479v1",
            "title": "Charged-particle jet spectra in event-shape engineered Pb--Pb collisions\n  at $\\sqrt{s_{\\rm NN}}$ = 5.02 TeV with ALICE",
            "updated": "2023-08-22T14:47:10Z",
            "published": "2023-08-22T14:47:10Z",
            "summary": "The path-length dependence of jet quenching can help to constrain different\njet quenching mechanisms in heavy-ion collisions. However, measuring an\nexplicit value for this dependence has proven challenging. Traditional\napproaches, which consider anisotropic jet suppression arising from geometric\nasymmetries, have successfully measured a non-zero azimuthal dependence of jet\nmodification with respect to the event-plane angle of the collision. While such\nsignals improve our qualitative understanding of this topic, extraction of an\nexplicit dependence from these results is limited by fluctuations in the\ninitial state and jet--medium interactions. A new approach to characterize the\ngeometry of the collision is to use event-shape engineering, a technique that\nclassifies events within a centrality class according to their elliptical\nanisotropies. By doing so, we gain an improved knowledge of the initial-state\nmedium, consequently enabling better constraints on the average path length\ntraversed by the jet. In these proceedings, new results of jet spectra from\nevent-shape-engineered collisions at ALICE will be presented.",
            "author": [
                "Caitlin Beattie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11479v1",
                "http://arxiv.org/pdf/2308.11479v1"
            ],
            "primary_category": "nucl-ex",
            "category": [
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11473v1",
            "title": "IT3D: Improved Text-to-3D Generation with Explicit View Synthesis",
            "updated": "2023-08-22T14:39:17Z",
            "published": "2023-08-22T14:39:17Z",
            "summary": "Recent strides in Text-to-3D techniques have been propelled by distilling\nknowledge from powerful large text-to-image diffusion models (LDMs).\nNonetheless, existing Text-to-3D approaches often grapple with challenges such\nas over-saturation, inadequate detailing, and unrealistic outputs. This study\npresents a novel strategy that leverages explicitly synthesized multi-view\nimages to address these issues. Our approach involves the utilization of\nimage-to-image pipelines, empowered by LDMs, to generate posed high-quality\nimages based on the renderings of coarse 3D models. Although the generated\nimages mostly alleviate the aforementioned issues, challenges such as view\ninconsistency and significant content variance persist due to the inherent\ngenerative nature of large diffusion models, posing extensive difficulties in\nleveraging these images effectively. To overcome this hurdle, we advocate\nintegrating a discriminator alongside a novel Diffusion-GAN dual training\nstrategy to guide the training of 3D models. For the incorporated\ndiscriminator, the synthesized multi-view images are considered real data,\nwhile the renderings of the optimized 3D models function as fake data. We\nconduct a comprehensive set of experiments that demonstrate the effectiveness\nof our method over baseline approaches.",
            "author": [
                "Yiwen Chen",
                "Chi Zhang",
                "Xiaofeng Yang",
                "Zhongang Cai",
                "Gang Yu",
                "Lei Yang",
                "Guosheng Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11473v1",
                "http://arxiv.org/pdf/2308.11473v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11463v1",
            "title": "Bridging Cognitive Maps: a Hierarchical Active Inference Model of\n  Spatial Alternation Tasks and the Hippocampal-Prefrontal Circuit",
            "updated": "2023-08-22T14:21:33Z",
            "published": "2023-08-22T14:21:33Z",
            "summary": "Cognitive problem-solving benefits from cognitive maps aiding navigation and\nplanning. Previous studies revealed that cognitive maps for physical space\nnavigation involve hippocampal (HC) allocentric codes, while cognitive maps for\nabstract task space engage medial prefrontal cortex (mPFC) task-specific codes.\nSolving challenging cognitive tasks requires integrating these two types of\nmaps. This is exemplified by spatial alternation tasks in multi-corridor\nsettings, where animals like rodents are rewarded upon executing an alternation\npattern in maze corridors. Existing studies demonstrated the HC - mPFC\ncircuit's engagement in spatial alternation tasks and that its disruption\nimpairs task performance. Yet, a comprehensive theory explaining how this\ncircuit integrates task-related and spatial information is lacking. We advance\na novel hierarchical active inference model clarifying how the HC - mPFC\ncircuit enables the resolution of spatial alternation tasks, by merging\nphysical and task-space cognitive maps. Through a series of simulations, we\ndemonstrate that the model's dual layers acquire effective cognitive maps for\nnavigation within physical (HC map) and task (mPFC map) spaces, using a\nbiologically-inspired approach: a clone-structured cognitive graph. The model\nsolves spatial alternation tasks through reciprocal interactions between the\ntwo layers. Importantly, disrupting inter-layer communication impairs difficult\ndecisions, consistent with empirical findings. The same model showcases the\nability to switch between multiple alternation rules. However, inhibiting\nmessage transmission between the two layers results in perseverative behavior,\nconsistent with empirical findings. In summary, our model provides a\nmechanistic account of how the HC - mPFC circuit supports spatial alternation\ntasks and how its disruption impairs task performance.",
            "author": [
                "Toon Van de Maele",
                "Bart Dhoedt",
                "Tim Verbelen",
                "Giovanni Pezzulo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11463v1",
                "http://arxiv.org/pdf/2308.11463v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11444v2",
            "title": "Adaptive Graduated Non-Convexity for Pose Graph Optimization",
            "updated": "2023-09-23T15:15:14Z",
            "published": "2023-08-22T13:51:10Z",
            "summary": "We present a novel approach to robust pose graph optimization based on\nGraduated Non-Convexity (GNC). Unlike traditional GNC-based methods, the\nproposed approach employs an adaptive shape function using B-spline to optimize\nthe shape of the robust kernel. This aims to reduce GNC iterations, boosting\ncomputational speed without compromising accuracy. When integrated with the\nopen-source riSAM algorithm, the method demonstrates enhanced efficiency across\ndiverse datasets. Accompanying open-source code aims to encourage further\nresearch in this area. https://github.com/SNU-DLLAB/AGNC-PGO",
            "author": [
                "Seungwon Choi",
                "Wonseok Kang",
                "Jiseong Chung",
                "Jaehyun Kim",
                "Tae-wan Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11444v2",
                "http://arxiv.org/pdf/2308.11444v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11440v1",
            "title": "PoseGraphNet++: Enriching 3D Human Pose with Orientation Estimation",
            "updated": "2023-08-22T13:42:15Z",
            "published": "2023-08-22T13:42:15Z",
            "summary": "Existing kinematic skeleton-based 3D human pose estimation methods only\npredict joint positions. Although this is sufficient to compute the yaw and\npitch of the bone rotations, the roll around the axis of the bones remains\nunresolved by these methods. In this paper, we propose a novel 2D-to-3D lifting\nGraph Convolution Network named PoseGraphNet++ to predict the complete human\npose including the joint positions and the bone orientations. We employ node\nand edge convolutions to utilize the joint and bone features. Our model is\nevaluated on multiple benchmark datasets, and its performance is either on par\nwith or better than the state-of-the-art in terms of both position and rotation\nmetrics. Through extensive ablation studies, we show that PoseGraphNet++\nbenefits from exploiting the mutual relationship between the joints and the\nbones.",
            "author": [
                "Soubarna Banik",
                "Edvard Avagyan",
                "Alejandro Mendoza Gracia",
                "Alois Knoll"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11440v1",
                "http://arxiv.org/pdf/2308.11440v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11434v2",
            "title": "On the subgroup regular set in Cayley graphs",
            "updated": "2023-08-24T20:50:46Z",
            "published": "2023-08-22T13:35:33Z",
            "summary": "A subset $C$ of the vertex set of a graph $\\Gamma$ is said to be\n$(a,b)$-regular if $C$ induces an $a$-regular subgraph and every vertex outside\n$C$ is adjacent to exactly $b$ vertices in $C$. In particular, if $C$ is an\n$(a,b)$-regular set of some Cayley graph on a finite group $G$, then $C$ is\ncalled an $(a,b)$-regular set of $G$ and a $(0,1)$-regular set is called a\nperfect code of $G$. In [Wang, Xia and Zhou, Regular sets in Cayley graphs, J.\nAlgebr. Comb., 2022] it is proved that if $H$ is a normal subgroup of $G$, then\n$H$ is a perfect code of $G$ if and only if it is an $(a,b)$-regular set of\n$G$, for each $0\\leq a\\leq|H|-1$ and $0\\leq b\\leq|H|$ with $\\gcd(2,|H|-1)\\mid\na$. In this paper, we generalize this result and show that a subgroup $H$ of\n$G$ is a perfect code of $G$ if and only if it is an $(a,b)$-regular set of\n$G$, for each $0\\leq a\\leq|H|-1$ and $0\\leq b\\leq|H|$ such that $\\gcd(2,|H|-1)$\ndivides $a$.",
            "author": [
                "Asamin Khaefi",
                "Zeinab Akhlaghi",
                "Behrooz Khosravi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11434v2",
                "http://arxiv.org/pdf/2308.11434v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11432v2",
            "title": "A Survey on Large Language Model based Autonomous Agents",
            "updated": "2023-09-07T04:42:48Z",
            "published": "2023-08-22T13:30:37Z",
            "summary": "Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.",
            "author": [
                "Lei Wang",
                "Chen Ma",
                "Xueyang Feng",
                "Zeyu Zhang",
                "Hao Yang",
                "Jingsen Zhang",
                "Zhiyuan Chen",
                "Jiakai Tang",
                "Xu Chen",
                "Yankai Lin",
                "Wayne Xin Zhao",
                "Zhewei Wei",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11432v2",
                "http://arxiv.org/pdf/2308.11432v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11422v1",
            "title": "Recommending Analogical APIs via Knowledge Graph Embedding",
            "updated": "2023-08-22T13:12:13Z",
            "published": "2023-08-22T13:12:13Z",
            "summary": "Library migration, which re-implements the same software behavior by using a\ndifferent library instead of using the current one, has been widely observed in\nsoftware evolution. One essential part of library migration is to find an\nanalogical API that could provide the same functionality as current ones.\nHowever, given the large number of libraries/APIs, manually finding an\nanalogical API could be very time-consuming and error-prone. Researchers have\ndeveloped multiple automated analogical API recommendation techniques.\nDocumentation-based methods have particularly attracted significant interest.\nDespite their potential, these methods have limitations, such as a lack of\ncomprehensive semantic understanding in documentation and scalability\nchallenges. In this work, we propose KGE4AR, a novel documentation-based\napproach that leverages knowledge graph (KG) embedding to recommend analogical\nAPIs during library migration. Specifically, KGE4AR proposes a novel unified\nAPI KG to comprehensively and structurally represent three types of knowledge\nin documentation, which can better capture the high-level semantics. Moreover,\nKGE4AR then proposes to embed the unified API KG into vectors, enabling more\neffective and scalable similarity calculation. We build KGE4AR' s unified API\nKG for 35,773 Java libraries and assess it in two API recommendation scenarios:\nwith and without target libraries. Our results show that KGE4AR substantially\noutperforms state-of-the-art documentation-based techniques in both evaluation\nscenarios in terms of all metrics (e.g., 47.1%-143.0% and 11.7%-80.6% MRR\nimprovements in each scenario). Additionally, we explore KGE4AR' s scalability,\nconfirming its effective scaling with the growing number of libraries.",
            "author": [
                "Mingwei Liu",
                "Yanjun Yang",
                "Yiling Lou",
                "Xin Peng",
                "Zhong Zhou",
                "Xueying Du",
                "Tianyong Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11422v1",
                "http://arxiv.org/pdf/2308.11422v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11416v1",
            "title": "Consistency-Checking Problems: A Gateway to Parameterized Sample\n  Complexity",
            "updated": "2023-08-22T13:02:09Z",
            "published": "2023-08-22T13:02:09Z",
            "summary": "Recently, Brand, Ganian and Simonov introduced a parameterized refinement of\nthe classical PAC-learning sample complexity framework. A crucial outcome of\ntheir investigation is that for a very wide range of learning problems, there\nis a direct and provable correspondence between fixed-parameter\nPAC-learnability (in the sample complexity setting) and the fixed-parameter\ntractability of a corresponding \"consistency checking\" search problem (in the\nsetting of computational complexity). The latter can be seen as generalizations\nof classical search problems where instead of receiving a single instance, one\nreceives multiple yes- and no-examples and is tasked with finding a solution\nwhich is consistent with the provided examples.\n  Apart from a few initial results, consistency checking problems are almost\nentirely unexplored from a parameterized complexity perspective. In this\narticle, we provide an overview of these problems and their connection to\nparameterized sample complexity, with the primary aim of facilitating further\nresearch in this direction. Afterwards, we establish the fixed-parameter\n(in)-tractability for some of the arguably most natural consistency checking\nproblems on graphs, and show that their complexity-theoretic behavior is\nsurprisingly very different from that of classical decision problems. Our new\nresults cover consistency checking variants of problems as diverse as (k-)Path,\nMatching, 2-Coloring, Independent Set and Dominating Set, among others.",
            "author": [
                "Robert Ganian",
                "Liana Khazaliya",
                "Kirill Simonov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11416v1",
                "http://arxiv.org/pdf/2308.11416v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "68Q27"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11411v1",
            "title": "Extracting Relational Triples Based on Graph Recursive Neural Network\n  via Dynamic Feedback Forest Algorithm",
            "updated": "2023-08-22T13:00:13Z",
            "published": "2023-08-22T13:00:13Z",
            "summary": "Extracting relational triples (subject, predicate, object) from text enables\nthe transformation of unstructured text data into structured knowledge. The\nnamed entity recognition (NER) and the relation extraction (RE) are two\nfoundational subtasks in this knowledge generation pipeline. The integration of\nsubtasks poses a considerable challenge due to their disparate nature. This\npaper presents a novel approach that converts the triple extraction task into a\ngraph labeling problem, capitalizing on the structural information of\ndependency parsing and graph recursive neural networks (GRNNs). To integrate\nsubtasks, this paper proposes a dynamic feedback forest algorithm that connects\nthe representations of subtasks by inference operations during model training.\nExperimental results demonstrate the effectiveness of the proposed method.",
            "author": [
                "Hongyin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11411v1",
                "http://arxiv.org/pdf/2308.11411v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11401v2",
            "title": "Parameterized Complexity of Simultaneous Planarity",
            "updated": "2023-09-01T12:11:08Z",
            "published": "2023-08-22T12:42:56Z",
            "summary": "Given $k$ input graphs $G_1, \\dots ,G_k$, where each pair $G_i$, $G_j$ with\n$i \\neq j$ shares the same graph $G$, the problem Simultaneous Embedding With\nFixed Edges (SEFE) asks whether there exists a planar drawing for each input\ngraph such that all drawings coincide on $G$. While SEFE is still open for the\ncase of two input graphs, the problem is NP-complete for $k \\geq 3$ [Schaefer,\nJGAA 13]. In this work, we explore the parameterized complexity of SEFE. We\nshow that SEFE is FPT with respect to $k$ plus the vertex cover number or the\nfeedback edge set number of the the union graph $G^\\cup = G_1 \\cup \\dots \\cup\nG_k$. Regarding the shared graph $G$, we show that SEFE is NP-complete, even if\n$G$ is a tree with maximum degree 4. Together with a known NP-hardness\nreduction [Angelini et al., TCS 15], this allows us to conclude that several\nparameters of $G$, including the maximum degree, the maximum number of degree-1\nneighbors, the vertex cover number, and the number of cutvertices are\nintractable. We also settle the tractability of all pairs of these parameters.\nWe give FPT algorithms for the vertex cover number plus either of the first two\nparameters and for the number of cutvertices plus the maximum degree, whereas\nwe prove all remaining combinations to be intractable.",
            "author": [
                "Simon D. Fink",
                "Matthias Pfretzschner",
                "Ignaz Rutter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11401v2",
                "http://arxiv.org/pdf/2308.11401v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11369v1",
            "title": "Enhancing Interpretable Object Abstraction via Clustering-based Slot\n  Initialization",
            "updated": "2023-08-22T11:48:43Z",
            "published": "2023-08-22T11:48:43Z",
            "summary": "Object-centric representations using slots have shown the advances towards\nefficient, flexible and interpretable abstraction from low-level perceptual\nfeatures in a compositional scene. Current approaches randomize the initial\nstate of slots followed by an iterative refinement. As we show in this paper,\nthe random slot initialization significantly affects the accuracy of the final\nslot prediction. Moreover, current approaches require a predetermined number of\nslots from prior knowledge of the data, which limits the applicability in the\nreal world. In our work, we initialize the slot representations with clustering\nalgorithms conditioned on the perceptual input features. This requires an\nadditional layer in the architecture to initialize the slots given the\nidentified clusters. We design permutation invariant and permutation\nequivariant versions of this layer to enable the exchangeable slot\nrepresentations after clustering. Additionally, we employ mean-shift clustering\nto automatically identify the number of slots for a given scene. We evaluate\nour method on object discovery and novel view synthesis tasks with various\ndatasets. The results show that our method outperforms prior works\nconsistently, especially for complex scenes.",
            "author": [
                "Ning Gao",
                "Bernard Hohmann",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11369v1",
                "http://arxiv.org/pdf/2308.11369v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11366v1",
            "title": "A class of graphs of zero Tur\u00e1n density in a hypercube",
            "updated": "2023-08-22T11:43:59Z",
            "published": "2023-08-22T11:43:59Z",
            "summary": "A graph is cubical if it is a subgraph of a hypercube. For a cubical graph\n$H$ and a hypercube $Q_n$, $ex(Q_n, H)$ is the largest number of edges in an\n$H$-free subgraph of $Q_n$. If $ex(Q_n, H)$ is at least a positive proportion\nof the number of edges in $Q_n$, $H$ is said to have a positive Tur\\'an density\nin a hypercube or simply a positive Tur\\'an density; otherwise it has a zero\nTur\\'an density. Determining $ex(Q_n, H)$ and even identifying whether $H$ has\na positive or a zero Tur\\'an density remains a widely open question for general\n$H$. By relating extremal numbers in a hypercube and certain corresponding\nhypergraphs, Conlon found a large class of cubical graphs, ones having\nso-called partite representation, that have a zero Tur\\'an density. He raised a\nquestion whether this gives a characterisation, i.e., whether a cubical graph\nhas zero Tur\\'an density if and only if it has partite representation. Here, we\nshow that, as suspected by Conlon, this is not the case. We give an example of\na class of cubical graphs which have no partite representation, but on the\nother hand, have a zero Tur\\'an density. In addition, we show that any graph\nwhose every block has partite representation has a zero Tur\\'an density in a\nhypercube.",
            "author": [
                "Maria Axenovich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11366v1",
                "http://arxiv.org/pdf/2308.11366v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11672v1",
            "title": "Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian\n  Models",
            "updated": "2023-08-22T10:43:05Z",
            "published": "2023-08-22T10:43:05Z",
            "summary": "A central characteristic of Bayesian statistics is the ability to\nconsistently incorporate prior knowledge into various modeling processes. In\nthis paper, we focus on translating domain expert knowledge into corresponding\nprior distributions over model parameters, a process known as prior\nelicitation. Expert knowledge can manifest itself in diverse formats, including\ninformation about raw data, summary statistics, or model parameters. A major\nchallenge for existing elicitation methods is how to effectively utilize all of\nthese different formats in order to formulate prior distributions that align\nwith the expert's expectations, regardless of the model structure. To address\nthese challenges, we develop a simulation-based elicitation method that can\nlearn the hyperparameters of potentially any parametric prior distribution from\na wide spectrum of expert knowledge using stochastic gradient descent. We\nvalidate the effectiveness and robustness of our elicitation method in four\nrepresentative case studies covering linear models, generalized linear models,\nand hierarchical models. Our results support the claim that our method is\nlargely independent of the underlying model structure and adaptable to various\nelicitation techniques, including quantile-based, moment-based, and\nhistogram-based methods.",
            "author": [
                "Florence Bockting",
                "Stefan T. Radev",
                "Paul-Christian B\u00fcrkner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11672v1",
                "http://arxiv.org/pdf/2308.11672v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11335v1",
            "title": "Graph Neural Network-Enhanced Expectation Propagation Algorithm for MIMO\n  Turbo Receivers",
            "updated": "2023-08-22T10:24:42Z",
            "published": "2023-08-22T10:24:42Z",
            "summary": "Deep neural networks (NNs) are considered a powerful tool for balancing the\nperformance and complexity of multiple-input multiple-output (MIMO) receivers\ndue to their accurate feature extraction, high parallelism, and excellent\ninference ability. Graph NNs (GNNs) have recently demonstrated outstanding\ncapability in learning enhanced message passing rules and have shown success in\novercoming the drawback of inaccurate Gaussian approximation of expectation\npropagation (EP)-based MIMO detectors. However, the application of the\nGNN-enhanced EP detector to MIMO turbo receivers is underexplored and\nnon-trivial due to the requirement of extrinsic information for iterative\nprocessing. This paper proposes a GNN-enhanced EP algorithm for MIMO turbo\nreceivers, which realizes the turbo principle of generating extrinsic\ninformation from the MIMO detector through a specially designed training\nprocedure. Additionally, an edge pruning strategy is designed to eliminate\nredundant connections in the original fully connected model of the GNN\nutilizing the correlation information inherently from the EP algorithm. Edge\npruning reduces the computational cost dramatically and enables the network to\nfocus more attention on the weights that are vital for performance. Simulation\nresults and complexity analysis indicate that the proposed MIMO turbo receiver\noutperforms the EP turbo approaches by over 1 dB at the bit error rate of\n$10^{-5}$, exhibits performance equivalent to state-of-the-art receivers with\n2.5 times shorter running time, and adapts to various scenarios.",
            "author": [
                "Xingyu Zhou",
                "Jing Zhang",
                "Chao-Kai Wen",
                "Shi Jin",
                "Shuangfeng Han"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11335v1",
                "http://arxiv.org/pdf/2308.11335v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11333v1",
            "title": "Protect Federated Learning Against Backdoor Attacks via Data-Free\n  Trigger Generation",
            "updated": "2023-08-22T10:16:12Z",
            "published": "2023-08-22T10:16:12Z",
            "summary": "As a distributed machine learning paradigm, Federated Learning (FL) enables\nlarge-scale clients to collaboratively train a model without sharing their raw\ndata. However, due to the lack of data auditing for untrusted clients, FL is\nvulnerable to poisoning attacks, especially backdoor attacks. By using poisoned\ndata for local training or directly changing the model parameters, attackers\ncan easily inject backdoors into the model, which can trigger the model to make\nmisclassification of targeted patterns in images. To address these issues, we\npropose a novel data-free trigger-generation-based defense approach based on\nthe two characteristics of backdoor attacks: i) triggers are learned faster\nthan normal knowledge, and ii) trigger patterns have a greater effect on image\nclassification than normal class patterns. Our approach generates the images\nwith newly learned knowledge by identifying the differences between the old and\nnew global models, and filters trigger images by evaluating the effect of these\ngenerated images. By using these trigger images, our approach eliminates\npoisoned models to ensure the updated global model is benign. Comprehensive\nexperiments demonstrate that our approach can defend against almost all the\nexisting types of backdoor attacks and outperform all the seven\nstate-of-the-art defense methods with both IID and non-IID scenarios.\nEspecially, our approach can successfully defend against the backdoor attack\neven when 80\\% of the clients are malicious.",
            "author": [
                "Yanxin Yang",
                "Ming Hu",
                "Yue Cao",
                "Jun Xia",
                "Yihao Huang",
                "Yang Liu",
                "Mingsong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11333v1",
                "http://arxiv.org/pdf/2308.11333v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11331v1",
            "title": "GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive\n  Language-Image Pre-training",
            "updated": "2023-08-22T10:07:49Z",
            "published": "2023-08-22T10:07:49Z",
            "summary": "Cross-modal pre-training has shown impressive performance on a wide range of\ndownstream tasks, benefiting from massive image-text pairs collected from the\nInternet. In practice, online data are growing constantly, highlighting the\nimportance of the ability of pre-trained model to learn from data that is\ncontinuously growing. Existing works on cross-modal pre-training mainly focus\non training a network with fixed architecture. However, it is impractical to\nlimit the model capacity when considering the continuously growing nature of\npre-training data in real-world applications. On the other hand, it is\nimportant to utilize the knowledge in the current model to obtain efficient\ntraining and better performance. To address the above issues, in this paper, we\npropose GrowCLIP, a data-driven automatic model growing algorithm for\ncontrastive language-image pre-training with continuous image-text pairs as\ninput. Specially, we adopt a dynamic growth space and seek out the optimal\narchitecture at each growth step to adapt to online learning scenarios. And the\nshared encoder is proposed in our growth space to enhance the degree of\ncross-modal fusion. Besides, we explore the effect of growth in different\ndimensions, which could provide future references for the design of cross-modal\nmodel architecture. Finally, we employ parameter inheriting with momentum (PIM)\nto maintain the previous knowledge and address the issue of the local minimum\ndilemma. Compared with the existing methods, GrowCLIP improves 2.3% average\ntop-1 accuracy on zero-shot image classification of 9 downstream tasks. As for\nzero-shot image retrieval, GrowCLIP can improve 1.2% for top-1 image-to-text\nrecall on Flickr30K dataset.",
            "author": [
                "Xinchi Deng",
                "Han Shi",
                "Runhui Huang",
                "Changlin Li",
                "Hang Xu",
                "Jianhua Han",
                "James Kwok",
                "Shen Zhao",
                "Wei Zhang",
                "Xiaodan Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11331v1",
                "http://arxiv.org/pdf/2308.11331v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11669v1",
            "title": "Class Label-aware Graph Anomaly Detection",
            "updated": "2023-08-22T09:46:12Z",
            "published": "2023-08-22T09:46:12Z",
            "summary": "Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a\nnode is anomalous or not. One common observation we made from previous\nunsupervised methods is that they not only assume the absence of such anomaly\nlabels, but also the absence of class labels (the class a node belongs to used\nin a general node classification task). In this work, we study the utility of\nclass labels for unsupervised GAD; in particular, how they enhance the\ndetection of structural anomalies. To this end, we propose a Class Label-aware\nGraph Anomaly Detection framework (CLAD) that utilizes a limited amount of\nlabeled nodes to enhance the performance of unsupervised GAD. Extensive\nexperiments on ten datasets demonstrate the superior performance of CLAD in\ncomparison to existing unsupervised GAD methods, even in the absence of\nground-truth class label information. The source code for CLAD is available at\n\\url{https://github.com/jhkim611/CLAD}.",
            "author": [
                "Junghoon Kim",
                "Yeonjun In",
                "Kanghoon Yoon",
                "Junmo Lee",
                "Chanyoung Park"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615249",
                "http://arxiv.org/abs/2308.11669v1",
                "http://arxiv.org/pdf/2308.11669v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11302v1",
            "title": "From Mundane to Meaningful: AI's Influence on Work Dynamics -- evidence\n  from ChatGPT and Stack Overflow",
            "updated": "2023-08-22T09:30:02Z",
            "published": "2023-08-22T09:30:02Z",
            "summary": "This paper illustrates how generative AI could give opportunities for big\nproductivity gains but also opens up questions about the impact of these new\npowerful technologies on the way we work and share knowledge. More\nspecifically, we explore how ChatGPT changed a fundamental aspect of coding:\nproblem-solving. To do so, we exploit the effect of the sudden release of\nChatGPT on the 30th of November 2022 on the usage of the largest online\ncommunity for coders: Stack Overflow. Using quasi-experimental methods\n(Difference-in-Difference), we find a significant drop in the number of\nquestions. In addition, the questions are better documented after the release\nof ChatGPT. Finally, we find evidence that the remaining questions are more\ncomplex. These findings suggest not only productivity gains but also a\nfundamental change in the way we work where routine inquiries are solved by AI\nallowing humans to focus on more complex tasks.",
            "author": [
                "Quentin Gallea"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11302v1",
                "http://arxiv.org/pdf/2308.11302v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "cs.AI",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11301v1",
            "title": "Intersection subgroup graph with forbidden subgraphs",
            "updated": "2023-08-22T09:29:21Z",
            "published": "2023-08-22T09:29:21Z",
            "summary": "Let $G$ be a group. The intersection subgroup graph of $G$ (introduced by\nAnderson et al. \\cite{anderson}) is the simple graph $\\Gamma_{S}(G)$ whose\nvertices are those non-trivial subgroups say $H$ of $G$ with $H\\cap K=\\{e\\}$\nfor some non-trivial subgroup $K$ of $G$; two distinct vertices $H$ and $K$ are\nadjacent if and only if $H\\cap K=\\{e\\}$, where $e$ is the identity element of\n$G$. In this communication, we explore the groups whose intersection subgroup\ngraph belongs to several significant graph classes including cluster graphs,\nperfect graphs, cographs, chordal graphs, bipartite graphs, triangle-free and\nclaw-fee graphs. We categorize each nilpotent group $G$ so that $\\Gamma_S(G)$\nbelongs to the above classes. We entirely classify the simple group of Lie type\nwhose intersection subgroup graph is a cograph. Moreover, we deduce that\n$\\Gamma_{S}(G)$ is neither a cograph nor a chordal graph if $G$ is a\ntorsion-free nilpotent group.",
            "author": [
                "Santanu Mandal",
                "Pallabi Manna"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11301v1",
                "http://arxiv.org/pdf/2308.11301v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11294v1",
            "title": "Network Momentum across Asset Classes",
            "updated": "2023-08-22T09:15:43Z",
            "published": "2023-08-22T09:15:43Z",
            "summary": "We investigate the concept of network momentum, a novel trading signal\nderived from momentum spillover across assets. Initially observed within the\nconfines of pairwise economic and fundamental ties, such as the stock-bond\nconnection of the same company and stocks linked through supply-demand chains,\nmomentum spillover implies a propagation of momentum risk premium from one\nasset to another. The similarity of momentum risk premium, exemplified by\nco-movement patterns, has been spotted across multiple asset classes including\ncommodities, equities, bonds and currencies. However, studying the network\neffect of momentum spillover across these classes has been challenging due to a\nlack of readily available common characteristics or economic ties beyond the\ncompany level. In this paper, we explore the interconnections of momentum\nfeatures across a diverse range of 64 continuous future contracts spanning\nthese four classes. We utilise a linear and interpretable graph learning model\nwith minimal assumptions to reveal the intricacies of the momentum spillover\nnetwork. By leveraging the learned networks, we construct a network momentum\nstrategy that exhibits a Sharpe ratio of 1.5 and an annual return of 22%, after\nvolatility scaling, from 2000 to 2022. This paper pioneers the examination of\nmomentum spillover across multiple asset classes using only pricing data,\npresents a multi-asset investment strategy based on network momentum, and\nunderscores the effectiveness of this strategy through robust empirical\nanalysis.",
            "author": [
                "Xingyue Pu",
                "Stephen Roberts",
                "Xiaowen Dong",
                "Stefan Zohren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11294v1",
                "http://arxiv.org/pdf/2308.11294v1"
            ],
            "primary_category": "q-fin.PM",
            "category": [
                "q-fin.PM",
                "cs.LG",
                "eess.SP",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13546v2",
            "title": "Functional Graph Contrastive Learning of Hyperscanning EEG Reveals\n  Emotional Contagion Evoked by Stereotype-Based Stressors",
            "updated": "2023-09-25T04:11:04Z",
            "published": "2023-08-22T09:04:14Z",
            "summary": "This study delves into the intricacies of emotional contagion and its impact\non performance within dyadic interactions. Specifically, it focuses on the\ncontext of stereotype-based stress (SBS) during collaborative problem-solving\ntasks among female pairs. Through an exploration of emotional contagion, this\nstudy seeks to unveil its underlying mechanisms and effects. Leveraging\nEEG-based hyperscanning technology, we introduced an innovative approach known\nas the functional Graph Contrastive Learning (fGCL), which extracts\nsubject-invariant representations of neural activity patterns from feedback\ntrials. These representations are further subjected to analysis using the\nDynamic Graph Classification (DGC) model, aimed at dissecting the process of\nemotional contagion along three independent temporal stages. The results\nunderscore the substantial role of emotional contagion in shaping the\ntrajectories of participants' performance during collaborative tasks in the\npresence of SBS conditions. Overall, our research contributes invaluable\ninsights into the neural underpinnings of emotional contagion, thereby\nenriching our comprehension of the complexities underlying social interactions\nand emotional dynamics.",
            "author": [
                "Jingyun Huang",
                "Rachel C. Amey",
                "Mengting Liu",
                "Chad E. Forbes"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13546v2",
                "http://arxiv.org/pdf/2308.13546v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11261v1",
            "title": "HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations",
            "updated": "2023-08-22T08:07:12Z",
            "published": "2023-08-22T08:07:12Z",
            "summary": "Generating both plausible and accurate full body avatar motion is the key to\nthe quality of immersive experiences in mixed reality scenarios. Head-Mounted\nDevices (HMDs) typically only provide a few input signals, such as head and\nhands 6-DoF. Recently, different approaches achieved impressive performance in\ngenerating full body motion given only head and hands signal. However, to the\nbest of our knowledge, all existing approaches rely on full hand visibility.\nWhile this is the case when, e.g., using motion controllers, a considerable\nproportion of mixed reality experiences do not involve motion controllers and\ninstead rely on egocentric hand tracking. This introduces the challenge of\npartial hand visibility owing to the restricted field of view of the HMD. In\nthis paper, we propose the first unified approach, HMD-NeMo, that addresses\nplausible and accurate full body motion generation even when the hands may be\nonly partially visible. HMD-NeMo is a lightweight neural network that predicts\nthe full body motion in an online and real-time fashion. At the heart of\nHMD-NeMo is the spatio-temporal encoder with novel temporally adaptable mask\ntokens that encourage plausible motion in the absence of hand observations. We\nperform extensive analysis of the impact of different components in HMD-NeMo\nand introduce a new state-of-the-art on AMASS dataset through our evaluation.",
            "author": [
                "Sadegh Aliakbarian",
                "Fatemeh Saleh",
                "David Collier",
                "Pashmina Cameron",
                "Darren Cosker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11261v1",
                "http://arxiv.org/pdf/2308.11261v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.05933v1",
            "title": "Mise en \u0153uvre d'une ing\u00e9nierie didactique de d\u00e9veloppement dans\n  le cadre d'un travail collaboratif chercheur/enseignant lors de la\n  conceptualisation des objets de l'Analyse au d\u00e9but du cursus dans le\n  sup\u00e9rieur",
            "updated": "2023-08-22T08:04:12Z",
            "published": "2023-08-22T08:04:12Z",
            "summary": "At the start of the higher education curriculum, the conceptualization of\nlocal approximation objects of a function requires the articulation of\nknowledge and skills from Functional Analysis and Topology. In the study of\nfunctions, a number of studies have established the existence of difficulties\nencountered by students, mainly as a result of the change of didactic contract\nduring the transition from secondary to higher education. The construction of a\nteaching-learning project, as part of a collaborative effort with the class\nteacher, a priori helps students to overcome the main difficulties inherent in\nconceptualizing the local approximation objects of a function in the first year\nof preparatory classes. In the case of the design and implementation of\ndidactic development engineering, analysis of the reasoning produced by\nstudents confronted with a situation with an adidactic dimension will enable us\na priori to study the nature and origin of these difficulties. Our methodology\nfor analyzing student work is based on a model of reasoning analysis within the\nframework of the theory of didactic situations mathematics. This model has\nplayed an essential role in the development of didactic engineering, in the\nidentification of students' conceptions, forms and functions of reasoning. It\nalso enabled us to identify epistemological, didactic and cultural obstacles to\nlearning the concept of local approximation of a function. These obstacles\nresult either from the paradigm shift that takes place during the transition\nfrom secondary to higher education, or from working within the paradigm of\nInfinitesimal Analysis during the appropriation of this mathematical concept.",
            "author": [
                "Fatma Belhaj Amor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.05933v1",
                "http://arxiv.org/pdf/2310.05933v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11257v2",
            "title": "HopPG: Self-Iterative Program Generation for Multi-Hop Question\n  Answering over Heterogeneous Knowledge",
            "updated": "2023-09-10T17:05:36Z",
            "published": "2023-08-22T08:00:50Z",
            "summary": "The semantic parsing-based method is an important research branch for\nknowledge-based question answering. It usually generates executable programs\nlean upon the question and then conduct them to reason answers over a knowledge\nbase. Benefit from this inherent mechanism, it has advantages in the\nperformance and the interpretability. However, traditional semantic parsing\nmethods usually generate a complete program before executing it, which\nstruggles with multi-hop question answering over heterogeneous knowledge. On\none hand, generating a complete multi-hop program relies on multiple\nheterogeneous supporting facts, and it is difficult for generators to\nunderstand these facts simultaneously. On the other hand, this way ignores the\nsemantic information of the intermediate answers at each hop, which is\nbeneficial for subsequent generation. To alleviate these challenges, we propose\na self-iterative framework for multi-hop program generation (HopPG) over\nheterogeneous knowledge, which leverages the previous execution results to\nretrieve supporting facts and generate subsequent programs hop by hop. We\nevaluate our model on MMQA-T^2, and the experimental results show that HopPG\noutperforms existing semantic-parsing-based baselines, especially on the\nmulti-hop questions.",
            "author": [
                "Yingyao Wang",
                "Yongwei Zhou",
                "Chaoqun Duan",
                "Junwei Bao",
                "Tiejun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11257v2",
                "http://arxiv.org/pdf/2308.11257v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11242v1",
            "title": "Faster Optimization in S-Graphs Exploiting Hierarchy",
            "updated": "2023-08-22T07:35:15Z",
            "published": "2023-08-22T07:35:15Z",
            "summary": "3D scene graphs hierarchically represent the environment appropriately\norganizing different environmental entities in various layers. Our previous\nwork on situational graphs extends the concept of 3D scene graph to SLAM by\ntightly coupling the robot poses with the scene graph entities, achieving\nstate-of-the-art results. Though, one of the limitations of S-Graphs is\nscalability in really large environments due to the increased graph size over\ntime, increasing the computational complexity.\n  To overcome this limitation in this work we present an initial research of an\nimproved version of S-Graphs exploiting the hierarchy to reduce the graph size\nby marginalizing redundant robot poses and their connections to the\nobservations of the same structural entities. Firstly, we propose the\ngeneration and optimization of room-local graphs encompassing all graph\nentities within a room-like structure. These room-local graphs are used to\ncompress the S-Graphs marginalizing the redundant robot keyframes within the\ngiven room. We then perform windowed local optimization of the compressed graph\nat regular time-distance intervals. A global optimization of the compressed\ngraph is performed every time a loop closure is detected. We show similar\naccuracy compared to the baseline while showing a 39.81% reduction in the\ncomputation time with respect to the baseline.",
            "author": [
                "Hriday Bavle",
                "Jose Luis Sanchez-Lopez",
                "Javier Civera",
                "Holger Voos"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11242v1",
                "http://arxiv.org/pdf/2308.11242v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11240v1",
            "title": "Minwise-Independent Permutations with Insertion and Deletion of Features",
            "updated": "2023-08-22T07:27:45Z",
            "published": "2023-08-22T07:27:45Z",
            "summary": "In their seminal work, Broder \\textit{et. al.}~\\citep{BroderCFM98} introduces\nthe $\\mathrm{minHash}$ algorithm that computes a low-dimensional sketch of\nhigh-dimensional binary data that closely approximates pairwise Jaccard\nsimilarity. Since its invention, $\\mathrm{minHash}$ has been commonly used by\npractitioners in various big data applications. Further, the data is dynamic in\nmany real-life scenarios, and their feature sets evolve over time. We consider\nthe case when features are dynamically inserted and deleted in the dataset. We\nnote that a naive solution to this problem is to repeatedly recompute\n$\\mathrm{minHash}$ with respect to the updated dimension. However, this is an\nexpensive task as it requires generating fresh random permutations. To the best\nof our knowledge, no systematic study of $\\mathrm{minHash}$ is recorded in the\ncontext of dynamic insertion and deletion of features. In this work, we\ninitiate this study and suggest algorithms that make the $\\mathrm{minHash}$\nsketches adaptable to the dynamic insertion and deletion of features. We show a\nrigorous theoretical analysis of our algorithms and complement it with\nextensive experiments on several real-world datasets. Empirically we observe a\nsignificant speed-up in the running time while simultaneously offering\ncomparable performance with respect to running $\\mathrm{minHash}$ from scratch.\nOur proposal is efficient, accurate, and easy to implement in practice.",
            "author": [
                "Rameshwar Pratap",
                "Raghav Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11240v1",
                "http://arxiv.org/pdf/2308.11240v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11239v3",
            "title": "LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and\n  Bootstrapped Self-training",
            "updated": "2023-12-02T18:06:55Z",
            "published": "2023-08-22T07:27:09Z",
            "summary": "Learning object segmentation in image and video datasets without human\nsupervision is a challenging problem. Humans easily identify moving salient\nobjects in videos using the gestalt principle of common fate, which suggests\nthat what moves together belongs together. Building upon this idea, we propose\na self-supervised object discovery approach that leverages motion and\nappearance information to produce high-quality object segmentation masks.\nSpecifically, we redesign the traditional graph cut on images to include motion\ninformation in a linear combination with appearance information to produce edge\nweights. Remarkably, this step produces object segmentation masks comparable to\nthe current state-of-the-art on multiple benchmarks. To further improve\nperformance, we bootstrap a segmentation network trained on these preliminary\nmasks as pseudo-ground truths to learn from its own outputs via self-training.\nWe demonstrate the effectiveness of our approach, named LOCATE, on multiple\nstandard video object segmentation, image saliency detection, and object\nsegmentation benchmarks, achieving results on par with and, in many cases\nsurpassing state-of-the-art methods. We also demonstrate the transferability of\nour approach to novel domains through a qualitative study on in-the-wild\nimages. Additionally, we present extensive ablation analysis to support our\ndesign choices and highlight the contribution of each component of our proposed\nmethod.",
            "author": [
                "Silky Singh",
                "Shripad Deshmukh",
                "Mausoom Sarkar",
                "Balaji Krishnamurthy"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11239v3",
                "http://arxiv.org/pdf/2308.11239v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11224v2",
            "title": "Evaluating Large Language Models on Graphs: Performance Insights and\n  Comparative Analysis",
            "updated": "2023-09-09T03:14:10Z",
            "published": "2023-08-22T06:32:07Z",
            "summary": "Large Language Models (LLMs) have garnered considerable interest within both\nacademic and industrial. Yet, the application of LLMs to graph data remains\nunder-explored. In this study, we evaluate the capabilities of four LLMs in\naddressing several analytical problems with graph data. We employ four distinct\nevaluation metrics: Comprehension, Correctness, Fidelity, and Rectification.\nOur results show that: 1) LLMs effectively comprehend graph data in natural\nlanguage and reason with graph topology. 2) GPT models can generate logical and\ncoherent results, outperforming alternatives in correctness. 3) All examined\nLLMs face challenges in structural reasoning, with techniques like zero-shot\nchain-of-thought and few-shot prompting showing diminished efficacy. 4) GPT\nmodels often produce erroneous answers in multi-answer tasks, raising concerns\nin fidelity. 5) GPT models exhibit elevated confidence in their outputs,\npotentially hindering their rectification capacities. Notably, GPT-4 has\ndemonstrated the capacity to rectify responses from GPT-3.5-turbo and its own\nprevious iterations. The code is available at:\nhttps://github.com/Ayame1006/LLMtoGraph.",
            "author": [
                "Chang Liu",
                "Bo Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11224v2",
                "http://arxiv.org/pdf/2308.11224v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11222v1",
            "title": "Approximate Core Allocations for Edge Cover Games",
            "updated": "2023-08-22T06:27:33Z",
            "published": "2023-08-22T06:27:33Z",
            "summary": "We study the approximate core for edge cover games, which are cooperative\ngames stemming from edge cover problems. In these games, each player controls a\nvertex on a network $G = (V, E; w)$, and the cost of a coalition $S\\subseteq V$\nis equivalent to the minimum weight of edge covers in the subgraph induced by\n$S$. We prove that the 3/4-core of edge cover games is always non-empty and can\nbe computed in polynomial time by using linear program duality approach. This\nratio is the best possible, as it represents the integrality gap of the natural\nLP for edge cover problems. Moreover, our analysis reveals that the ratio of\napproximate core corresponds with the length of the shortest odd cycle of\nunderlying graphs.",
            "author": [
                "Tianhang Lu",
                "Han Xian",
                "Qizhi Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11222v1",
                "http://arxiv.org/pdf/2308.11222v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11217v3",
            "title": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
            "updated": "2023-08-24T06:24:13Z",
            "published": "2023-08-22T06:05:11Z",
            "summary": "Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.",
            "author": [
                "Zengxiang Li",
                "Zhaoxiang Hou",
                "Hui Liu",
                "Ying Wang",
                "Tongzhi Li",
                "Longfei Xie",
                "Chao Shi",
                "Chengyi Yang",
                "Weishan Zhang",
                "Zelei Liu",
                "Liang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11217v3",
                "http://arxiv.org/pdf/2308.11217v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11205v1",
            "title": "Learned Lock-free Search Data Structures",
            "updated": "2023-08-22T05:42:08Z",
            "published": "2023-08-22T05:42:08Z",
            "summary": "Non-blocking search data structures offer scalability with a progress\nguarantee on high-performance multi-core architectures. In the recent past,\n\"learned queries\" have gained remarkable attention. It refers to predicting the\nrank of a key computed by machine learning models trained to infer the\ncumulative distribution function of an ordered dataset. A line of works\nexhibits the superiority of learned queries over classical query algorithms.\nYet, to our knowledge, no existing non-blocking search data structure employs\nthem. In this paper, we introduce \\textbf{Kanva}, a framework for learned\nnon-blocking search. Kanva has an intuitive yet non-trivial design: traverse\ndown a shallow hierarchy of lightweight linear models to reach the\n\"non-blocking bins,\" which are dynamic ordered search structures. The proposed\napproach significantly outperforms the current state-of-the-art -- non-blocking\ninterpolation search trees and elimination (a,b) trees -- in many workload and\ndata distributions. Kanva is provably linearizable.",
            "author": [
                "Gaurav Bhardwaj",
                "Bapi Chatterjee",
                "Abhinav Sharma",
                "Sathya Peri",
                "Siddharth Nayak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11205v1",
                "http://arxiv.org/pdf/2308.11205v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11667v1",
            "title": "Enhancements of Electron-Atom Collisions due to Pauli Repulsion in\n  Neutron-Star Magnetic Fields",
            "updated": "2023-08-22T05:24:41Z",
            "published": "2023-08-22T05:24:41Z",
            "summary": "Neutron star surfaces and atmospheres are unique environments that sustain\nthe largest-known magnetic fields in the universe. Our knowledge of neutron\nstar material properties, including the composition and equation of state,\nremains highly unconstrained. Electron-atom collisions are integral to\ntheoretical thermal conduction and spectral emission models that describe\nneutron star surfaces. The theory of scattering in magnetic fields was\ndeveloped in the 1970s, but focused only on bare nuclei scattering. In this\nwork, we present a quantum treatment of atom-electron collisions in magnetic\nfields; of significant importance is the inclusion of Pauli repulsion arising\nfrom two interacting electrons. We find strange behaviors not seen in\ncollisions without a magnetic field. In high magnetic fields, Pauli repulsion\ncan lead to orders of magnitude enhancements of collision cross sections.\nAdditionally, the elastic collision cross sections that involve the ground\nstate become comparable to those involving excited states, and states with\nlarge orbits have the largest contribution to the collisions. We anticipate\nsignificant changes to transport properties and spectral line broadening in\nneutron star surfaces and atmospheres, which will aid in spectral diagnostics\nof these extreme environments.",
            "author": [
                "Thomas Gomez",
                "Mark Zammit",
                "Igor Bray",
                "Christopher Fontes",
                "Jackson White"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11667v1",
                "http://arxiv.org/pdf/2308.11667v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.SR",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11198v1",
            "title": "Novel-view Synthesis and Pose Estimation for Hand-Object Interaction\n  from Sparse Views",
            "updated": "2023-08-22T05:17:41Z",
            "published": "2023-08-22T05:17:41Z",
            "summary": "Hand-object interaction understanding and the barely addressed novel view\nsynthesis are highly desired in the immersive communication, whereas it is\nchallenging due to the high deformation of hand and heavy occlusions between\nhand and object. In this paper, we propose a neural rendering and pose\nestimation system for hand-object interaction from sparse views, which can also\nenable 3D hand-object interaction editing. We share the inspiration from recent\nscene understanding work that shows a scene specific model built beforehand can\nsignificantly improve and unblock vision tasks especially when inputs are\nsparse, and extend it to the dynamic hand-object interaction scenario and\npropose to solve the problem in two stages. We first learn the shape and\nappearance prior knowledge of hands and objects separately with the neural\nrepresentation at the offline stage. During the online stage, we design a\nrendering-based joint model fitting framework to understand the dynamic\nhand-object interaction with the pre-built hand and object models as well as\ninteraction priors, which thereby overcomes penetration and separation issues\nbetween hand and object and also enables novel view synthesis. In order to get\nstable contact during the hand-object interaction process in a sequence, we\npropose a stable contact loss to make the contact region to be consistent.\nExperiments demonstrate that our method outperforms the state-of-the-art\nmethods. Code and dataset are available in project webpage\nhttps://iscas3dv.github.io/HO-NeRF.",
            "author": [
                "Wentian Qu",
                "Zhaopeng Cui",
                "Yinda Zhang",
                "Chenyu Meng",
                "Cuixia Ma",
                "Xiaoming Deng",
                "Hongan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11198v1",
                "http://arxiv.org/pdf/2308.11198v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11192v1",
            "title": "Automatic Task Parallelization of Dataflow Graphs in ML/DL models",
            "updated": "2023-08-22T04:54:30Z",
            "published": "2023-08-22T04:54:30Z",
            "summary": "Several methods exist today to accelerate Machine Learning(ML) or\nDeep-Learning(DL) model performance for training and inference. However, modern\ntechniques that rely on various graph and operator parallelism methodologies\nrely on search space optimizations which are costly in terms of power and\nhardware usage. Especially in the case of inference, when the batch size is 1\nand execution is on CPUs or for power-constrained edge devices, current\ntechniques can become costly, complicated or inapplicable. To ameliorate this,\nwe present a Critical-Path-based Linear Clustering approach to exploit inherent\nparallel paths in ML dataflow graphs. Our task parallelization approach further\noptimizes the structure of graphs via cloning and prunes them via constant\npropagation and dead-code elimination. Contrary to other work, we generate\nreadable and executable parallel Pytorch+Python code from input ML models in\nONNX format via a new tool that we have built called {\\bf Ramiel}. This allows\nus to benefit from other downstream acceleration techniques like intra-op\nparallelism and potentially pipeline parallelism. Our preliminary results on\nseveral ML graphs demonstrate up to 1.9$\\times$ speedup over serial execution\nand outperform some of the current mechanisms in both compile and runtimes.\nLastly, our methods are lightweight and fast enough so that they can be used\neffectively for power and resource-constrained devices, while still enabling\ndownstream optimizations.",
            "author": [
                "Srinjoy Das",
                "Lawrence Rauchwerger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11192v1",
                "http://arxiv.org/pdf/2308.11192v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11186v1",
            "title": "Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models",
            "updated": "2023-08-22T04:24:45Z",
            "published": "2023-08-22T04:24:45Z",
            "summary": "Pre-trained vision-language models, e.g., CLIP, working with manually\ndesigned prompts have demonstrated great capacity of transfer learning.\nRecently, learnable prompts achieve state-of-the-art performance, which however\nare prone to overfit to seen classes, failing to generalize to unseen classes.\nIn this paper, we propose a Knowledge-Aware Prompt Tuning (KAPT) framework for\nvision-language models. Our approach takes inspiration from human intelligence\nin which external knowledge is usually incorporated into recognizing novel\ncategories of objects. Specifically, we design two complementary types of\nknowledge-aware prompts for the text encoder to leverage the distinctive\ncharacteristics of category-related external knowledge. The discrete prompt\nextracts the key information from descriptions of an object category, and the\nlearned continuous prompt captures overall contexts. We further design an\nadaptation head for the visual encoder to aggregate salient attentive visual\ncues, which establishes discriminative and task-aware visual representations.\nWe conduct extensive experiments on 11 widely-used benchmark datasets and the\nresults verify the effectiveness in few-shot image classification, especially\nin generalizing to unseen categories. Compared with the state-of-the-art CoCoOp\nmethod, KAPT exhibits favorable performance and achieves an absolute gain of\n3.22% on new classes and 2.57% in terms of harmonic mean.",
            "author": [
                "Baoshuo Kan",
                "Teng Wang",
                "Wenpeng Lu",
                "Xiantong Zhen",
                "Weili Guan",
                "Feng Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11186v1",
                "http://arxiv.org/pdf/2308.11186v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11184v1",
            "title": "ReFit: Recurrent Fitting Network for 3D Human Recovery",
            "updated": "2023-08-22T04:20:18Z",
            "published": "2023-08-22T04:20:18Z",
            "summary": "We present Recurrent Fitting (ReFit), a neural network architecture for\nsingle-image, parametric 3D human reconstruction. ReFit learns a\nfeedback-update loop that mirrors the strategy of solving an inverse problem\nthrough optimization. At each iterative step, it reprojects keypoints from the\nhuman model to feature maps to query feedback, and uses a recurrent-based\nupdater to adjust the model to fit the image better. Because ReFit encodes\nstrong knowledge of the inverse problem, it is faster to train than previous\nregression models. At the same time, ReFit improves state-of-the-art\nperformance on standard benchmarks. Moreover, ReFit applies to other\noptimization settings, such as multi-view fitting and single-view shape\nfitting. Project website: https://yufu-wang.github.io/refit_humans/",
            "author": [
                "Yufu Wang",
                "Kostas Daniilidis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11184v1",
                "http://arxiv.org/pdf/2308.11184v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11176v1",
            "title": "Is this network proper forest-based?",
            "updated": "2023-08-22T04:07:56Z",
            "published": "2023-08-22T04:07:56Z",
            "summary": "In evolutionary biology, networks are becoming increasingly used to represent\nevolutionary histories for species that have undergone non-treelike or\nreticulate evolution. Such networks are essentially directed acyclic graphs\nwith a leaf set that corresponds to a collection of species, and in which\nnon-leaf vertices with indegree 1 correspond to speciation events and vertices\nwith indegree greater than 1 correspond to reticulate events such as gene\ntransfer. Recently forest-based networks have been introduced, which are\nessentially (multi-rooted) networks that can be formed by adding some arcs to a\ncollection of phylogenetic trees (or phylogenetic forest), where each arc is\nadded in such a way that its ends always lie in two different trees in the\nforest. In this paper, we consider the complexity of deciding whether or not a\ngiven network is proper forest-based, that is, whether it can be formed by\nadding arcs to some underlying phylogenetic forest which contains the same\nnumber of trees as there are roots in the network. More specifically, we show\nthat it can be decided in polynomial time whether or not a binary, tree-child\nnetwork with $m \\ge 2$ roots is proper forest-based in case $m=2$, but that\nthis problem is NP-complete for $m\\ge 3$. We also give a fixed parameter\ntractable (FPT) algorithm for deciding whether or not a network in which every\nvertex has indegree at most 2 is proper forest-based. A key element in proving\nour results is a new characterization for when a network with $m$ roots is\nproper forest-based which is given in terms of the existence of certain\n$m$-colorings of the vertices of the network.",
            "author": [
                "Katharina T. Huber",
                "Leo van Iersel",
                "Vincent Moulton",
                "Guillaume Scholz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11176v1",
                "http://arxiv.org/pdf/2308.11176v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11168v1",
            "title": "Discretized Normal Approximation of Sums of Locally Dependent Random\n  Variables via Stein's Method",
            "updated": "2023-08-22T03:54:32Z",
            "published": "2023-08-22T03:54:32Z",
            "summary": "Let $\\{X_{i}, i\\in J\\}$ be a family of locally dependent non-negative\ninteger-valued random variables with finite expectation and variance. We\nconsider the sum $W=\\sum_{i\\in J}X_i$ and establish general error upper bounds\nfor the total variation distance $d_{TV}(W, Y^{d})$, where $Y^{d}$ is the\ndiscretized normal distribution. The major ingredient of the proof is to\napproximate $W$ by a three-parametric intermediate random variable $M$ based on\nStein's method. As applications, we study in detail four well-known examples,\nwhich are counting vertices of all edges point inward, birthday problem,\ncounting monochromatic edges in uniformly colored graphs, and triangles in the\nErd\\H{o}s-R\\'{e}nyi random graph. Through delicate analysis and computations we\nobtain sharper upper error bounds than existing results.",
            "author": [
                "Zhonggen Su",
                "Xiaolin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11168v1",
                "http://arxiv.org/pdf/2308.11168v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11161v1",
            "title": "Adversarial Attacks on Code Models with Discriminative Graph Patterns",
            "updated": "2023-08-22T03:40:34Z",
            "published": "2023-08-22T03:40:34Z",
            "summary": "Pre-trained language models of code are now widely used in various software\nengineering tasks such as code generation, code completion, vulnerability\ndetection, etc. This, in turn, poses security and reliability risks to these\nmodels. One of the important threats is \\textit{adversarial attacks}, which can\nlead to erroneous predictions and largely affect model performance on\ndownstream tasks. Current adversarial attacks on code models usually adopt\nfixed sets of program transformations, such as variable renaming and dead code\ninsertion, leading to limited attack effectiveness. To address the\naforementioned challenges, we propose a novel adversarial attack framework,\nGraphCodeAttack, to better evaluate the robustness of code models. Given a\ntarget code model, GraphCodeAttack automatically mines important code patterns,\nwhich can influence the model's decisions, to perturb the structure of input\ncode to the model. To do so, GraphCodeAttack uses a set of input source codes\nto probe the model's outputs and identifies the \\textit{discriminative} ASTs\npatterns that can influence the model decisions. GraphCodeAttack then selects\nappropriate AST patterns, concretizes the selected patterns as attacks, and\ninserts them as dead code into the model's input program. To effectively\nsynthesize attacks from AST patterns, GraphCodeAttack uses a separate\npre-trained code model to fill in the ASTs with concrete code snippets. We\nevaluate the robustness of two popular code models (e.g., CodeBERT and\nGraphCodeBERT) against our proposed approach on three tasks: Authorship\nAttribution, Vulnerability Prediction, and Clone Detection. The experimental\nresults suggest that our proposed approach significantly outperforms\nstate-of-the-art approaches in attacking code models such as CARROT and ALERT.",
            "author": [
                "Thanh-Dat Nguyen",
                "Yang Zhou",
                "Xuan Bach D. Le",
                "Patanamon",
                "Thongtanunam",
                "David Lo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11161v1",
                "http://arxiv.org/pdf/2308.11161v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11160v4",
            "title": "Searching High Temperature Superconductors with the assistance of Graph\n  Neural Networks",
            "updated": "2023-11-11T07:31:38Z",
            "published": "2023-08-22T03:34:18Z",
            "summary": "Predicting high temperature superconductors has long been a great challenge.\nA major difficulty is how to predict the transition temperature Tc of\nsuperconductors. Recently, progress in material informatics has led to a number\nof machine learning models predicting Tc, which greatly improves the efficiency\nof prediction. Unfortunately, prevailing models have not shown adequate\nphysical rationality and generalization ability to find new high temperature\nsuperconductors, yet. In this work, in order to give a trustable prediction on\nthe unexplored materials, we built a bond-sensitive graph neural network\n(BSGNN), which is optimized to process the information of chemical bond and\nelectron interaction in the crystal lattice, to predict the Tc maximum of each\ntype of superconducting materials. On the basis of the domain knowledge\nconsidered in the data preparation and algorithm design, our model revealed a\nrelevance between the Tc-Tc maximum and chemical bonds. The results indicate\nthat shorter bond length is favored by high Tc, which is in accordance with\nprevious human experience. Moreover, it also shows that some specific chemical\nelements are favored by high Tc, which is beyond what human experts already\nknew. It gives a convenient guidance for searching high temperature\nsuperconductors in materials database, by ruling out the materials that could\nnever have high Tc.",
            "author": [
                "Liang Gu",
                "Yang Liu",
                "Pin Chen",
                "Haiyou Huang",
                "Ning Chen",
                "Yang Li",
                "Yutong Lu",
                "Yanjing Su"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11160v4",
                "http://arxiv.org/pdf/2308.11160v4"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11153v1",
            "title": "Information Complexity of Mixed-integer Convex Optimization",
            "updated": "2023-08-22T03:14:11Z",
            "published": "2023-08-22T03:14:11Z",
            "summary": "We investigate the information complexity of mixed-integer convex\noptimization under different types of oracles. We establish new lower bounds\nfor the standard first-order oracle, improving upon the previous best known\nlower bound. This leaves only a lower order linear term (in the dimension) as\nthe gap between the lower and upper bounds. This is derived as a corollary of a\nmore fundamental ``transfer\" result that shows how lower bounds on information\ncomplexity of continuous convex optimization under different oracles can be\ntransferred to the mixed-integer setting in a black-box manner.\n  Further, we (to the best of our knowledge) initiate the study of, and obtain\nthe first set of results on, information complexity under oracles that only\nreveal \\emph{partial} first-order information, e.g., where one can only make a\nbinary query over the function value or subgradient at a given point. We give\nalgorithms for (mixed-integer) convex optimization that work under these less\ninformative oracles. We also give lower bounds showing that, for some of these\noracles, every algorithm requires more iterations to achieve a target error\ncompared to when complete first-order information is available. That is, these\noracles are provably less informative than full first-order oracles for the\npurpose of optimization.",
            "author": [
                "Amitabh Basu",
                "Hongyi Jiang",
                "Phillip Kerger",
                "Marco Molinaro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11153v1",
                "http://arxiv.org/pdf/2308.11153v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11148v2",
            "title": "LLaMA-Reviewer: Advancing Code Review Automation with Large Language\n  Models through Parameter-Efficient Fine-Tuning",
            "updated": "2023-09-05T02:28:49Z",
            "published": "2023-08-22T03:10:40Z",
            "summary": "The automation of code review activities, a long-standing pursuit in software\nengineering, has been primarily addressed by numerous domain-specific\npre-trained models. Despite their success, these models frequently demand\nextensive resources for pre-training from scratch. In contrast, Large Language\nModels (LLMs) provide an intriguing alternative, given their remarkable\ncapabilities when supplemented with domain-specific knowledge. However, their\npotential for automating code review tasks remains largely unexplored.\n  In response to this research gap, we present LLaMA-Reviewer, an innovative\nframework that leverages the capabilities of LLaMA, a popular LLM, in the realm\nof code review. Mindful of resource constraints, this framework employs\nparameter-efficient fine-tuning (PEFT) methods, delivering high performance\nwhile using less than 1% of trainable parameters.\n  An extensive evaluation of LLaMA-Reviewer is conducted on two diverse,\npublicly available datasets. Notably, even with the smallest LLaMA base model\nconsisting of 6.7B parameters and a limited number of tuning epochs,\nLLaMA-Reviewer equals the performance of existing code-review-focused models.\n  The ablation experiments provide insights into the influence of various\nfine-tuning process components, including input representation, instruction\ntuning, and different PEFT methods. To foster continuous progress in this\nfield, the code and all PEFT-weight plugins have been made open-source.",
            "author": [
                "Junyi Lu",
                "Lei Yu",
                "Xiaojia Li",
                "Li Yang",
                "Chun Zuo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11148v2",
                "http://arxiv.org/pdf/2308.11148v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11146v1",
            "title": "Finding Small Complete Subgraphs Efficiently",
            "updated": "2023-08-22T03:03:16Z",
            "published": "2023-08-22T03:03:16Z",
            "summary": "(I) We revisit the algorithmic problem of finding all triangles in a graph\n$G=(V,E)$ with $n$ vertices and $m$ edges. According to a result of Chiba and\nNishizeki (1985), this task can be achieved by a combinatorial algorithm\nrunning in $O(m \\alpha) = O(m^{3/2})$ time, where $\\alpha= \\alpha(G)$ is the\ngraph arboricity. We provide a new very simple combinatorial algorithm for\nfinding all triangles in a graph and show that is amenable to the same running\ntime analysis. We derive these worst-case bounds from first principles and with\nvery simple proofs that do not rely on classic results due to Nash-Williams\nfrom the 1960s.\n  (II) We extend our arguments to the problem of finding all small complete\nsubgraphs of a given fixed size. We show that the dependency on $m$ and\n$\\alpha$ in the running time $O(\\alpha^{\\ell-2} \\cdot m)$ of the algorithm of\nChiba and Nishizeki for listing all copies of $K_\\ell$, where $\\ell \\geq 3$, is\nasymptotically tight.\n  (III) We give improved arboricity-sensitive running times for counting and/or\ndetection of copies of $K_\\ell$, for small $\\ell \\geq 4$. A key ingredient in\nour algorithms is, once again, the algorithm of Chiba and Nishizeki. Our new\nalgorithms are faster than all previous algorithms in certain high-range\narboricity intervals for every $\\ell \\geq 7$.",
            "author": [
                "Adrian Dumitrescu",
                "Andrzej Lingas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11146v1",
                "http://arxiv.org/pdf/2308.11146v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11142v1",
            "title": "Graph Encoding and Neural Network Approaches for Volleyball Analytics:\n  From Game Outcome to Individual Play Predictions",
            "updated": "2023-08-22T02:51:42Z",
            "published": "2023-08-22T02:51:42Z",
            "summary": "This research aims to improve the accuracy of complex volleyball predictions\nand provide more meaningful insights to coaches and players. We introduce a\nspecialized graph encoding technique to add additional contact-by-contact\nvolleyball context to an already available volleyball dataset without any\nadditional data gathering. We demonstrate the potential benefits of using graph\nneural networks (GNNs) on this enriched dataset for three different volleyball\nprediction tasks: rally outcome prediction, set location prediction, and hit\ntype prediction. We compare the performance of our graph-based models to\nbaseline models and analyze the results to better understand the underlying\nrelationships in a volleyball rally. Our results show that the use of GNNs with\nour graph encoding yields a much more advanced analysis of the data, which\nnoticeably improves prediction results overall. We also show that these\nbaseline tasks can be significantly improved with simple adjustments, such as\nremoving blocked hits. Lastly, we demonstrate the importance of choosing a\nmodel architecture that will better extract the important information for a\ncertain task. Overall, our study showcases the potential strengths and\nweaknesses of using graph encodings in sports data analytics and hopefully will\ninspire future improvements in machine learning strategies across sports and\napplications by using graphbased encodings.",
            "author": [
                "Rhys Tracy",
                "Haotian Xia",
                "Alex Rasla",
                "Yuan-Fang Wang",
                "Ambuj Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11142v1",
                "http://arxiv.org/pdf/2308.11142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11663v1",
            "title": "A new class of disconnected antimagic graphs",
            "updated": "2023-08-22T02:41:30Z",
            "published": "2023-08-22T02:41:30Z",
            "summary": "A graph $G$ is antimagic if there exists a bijection $f$ from $E(G)$ to\n$\\left\\{1,2, \\dots,|E(G)|\\right\\}$ such that the vertex sums for all vertices\nof $G$ are distinct, where the vertex sum is defined as the sum of the labels\nof all incident edges.\n  Hartsfield and Ringel conjectured that every connected graph other than $K_2$\nadmits an antimagic labeling. It is still a challenging problem to address\nantimagicness in the case of disconnected graphs. In this paper, we study\nantimagicness for the disconnected graph that is constructed as the direct\nproduct of a star and a path.",
            "author": [
                "Vinothkumar Latchoumanane",
                "Murugan Varadhan",
                "Andrea Semani\u010dov\u00e1-Fe\u0148ov\u010d\u00edkov\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11663v1",
                "http://arxiv.org/pdf/2308.11663v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11131v2",
            "title": "ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential\n  Behavior Comprehension in Recommendation",
            "updated": "2023-10-13T16:13:52Z",
            "published": "2023-08-22T02:25:04Z",
            "summary": "With large language models (LLMs) achieving remarkable breakthroughs in\nnatural language processing (NLP) domains, LLM-enhanced recommender systems\nhave received much attention and have been actively explored currently. In this\npaper, we focus on adapting and empowering a pure large language model for\nzero-shot and few-shot recommendation tasks. First and foremost, we identify\nand formulate the lifelong sequential behavior incomprehension problem for LLMs\nin recommendation domains, i.e., LLMs fail to extract useful information from a\ntextual context of long user behavior sequence, even if the length of context\nis far from reaching the context limitation of LLMs. To address such an issue\nand improve the recommendation performance of LLMs, we propose a novel\nframework, namely Retrieval-enhanced Large Language models (ReLLa) for\nrecommendation tasks in both zero-shot and few-shot settings. For zero-shot\nrecommendation, we perform semantic user behavior retrieval (SUBR) to improve\nthe data quality of testing samples, which greatly reduces the difficulty for\nLLMs to extract the essential knowledge from user behavior sequences. As for\nfew-shot recommendation, we further design retrieval-enhanced instruction\ntuning (ReiT) by adopting SUBR as a data augmentation technique for training\nsamples. Specifically, we develop a mixed training dataset consisting of both\nthe original data samples and their retrieval-enhanced counterparts. We conduct\nextensive experiments on three real-world public datasets to demonstrate the\nsuperiority of ReLLa compared with existing baseline models, as well as its\ncapability for lifelong sequential behavior comprehension. To be highlighted,\nwith only less than 10% training samples, few-shot ReLLa can outperform\ntraditional CTR models that are trained on the entire training set (e.g.,\nDCNv2, DIN, SIM).",
            "author": [
                "Jianghao Lin",
                "Rong Shan",
                "Chenxu Zhu",
                "Kounianhua Du",
                "Bo Chen",
                "Shigang Quan",
                "Ruiming Tang",
                "Yong Yu",
                "Weinan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11131v2",
                "http://arxiv.org/pdf/2308.11131v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11129v1",
            "title": "Transformers for Capturing Multi-level Graph Structure using\n  Hierarchical Distances",
            "updated": "2023-08-22T02:22:34Z",
            "published": "2023-08-22T02:22:34Z",
            "summary": "Graph transformers need strong inductive biases to derive meaningful\nattention scores. Yet, current proposals rarely address methods capturing\nlonger ranges, hierarchical structures, or community structures, as they appear\nin various graphs such as molecules, social networks, and citation networks. In\nthis paper, we propose a hierarchy-distance structural encoding (HDSE), which\nmodels a hierarchical distance between the nodes in a graph focusing on its\nmulti-level, hierarchical nature. In particular, this yields a framework which\ncan be flexibly integrated with existing graph transformers, allowing for\nsimultaneous application with other positional representations. Through\nextensive experiments on 12 real-world datasets, we demonstrate that our HDSE\nmethod successfully enhances various types of baseline transformers, achieving\nstate-of-the-art empirical performances on 10 benchmark datasets.",
            "author": [
                "Yuankai Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11129v1",
                "http://arxiv.org/pdf/2308.11129v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11127v3",
            "title": "How Expressive are Graph Neural Networks in Recommendation?",
            "updated": "2023-09-15T21:49:23Z",
            "published": "2023-08-22T02:17:34Z",
            "summary": "Graph Neural Networks (GNNs) have demonstrated superior performance on\nvarious graph learning tasks, including recommendation, where they leverage\nuser-item collaborative filtering signals in graphs. However, theoretical\nformulations of their capability are scarce, despite their empirical\neffectiveness in state-of-the-art recommender models. Recently, research has\nexplored the expressiveness of GNNs in general, demonstrating that message\npassing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that\nGNNs combined with random node initialization are universal. Nevertheless, the\nconcept of \"expressiveness\" for GNNs remains vaguely defined. Most existing\nworks adopt the graph isomorphism test as the metric of expressiveness, but\nthis graph-level task may not effectively assess a model's ability in\nrecommendation, where the objective is to distinguish nodes of different\ncloseness. In this paper, we provide a comprehensive theoretical analysis of\nthe expressiveness of GNNs in recommendation, considering three levels of\nexpressiveness metrics: graph isomorphism (graph-level), node automorphism\n(node-level), and topological closeness (link-level). We propose the\ntopological closeness metric to evaluate GNNs' ability to capture the\nstructural distance between nodes, which aligns closely with the objective of\nrecommendation. To validate the effectiveness of this new metric in evaluating\nrecommendation performance, we introduce a learning-less GNN algorithm that is\noptimal on the new metric and can be optimal on the node-level metric with\nsuitable modification. We conduct extensive experiments comparing the proposed\nalgorithm against various types of state-of-the-art GNN models to explore the\nexplainability of the new metric in the recommendation task. For\nreproducibility, implementation codes are available at\nhttps://github.com/HKUDS/GTE.",
            "author": [
                "Xuheng Cai",
                "Lianghao Xia",
                "Xubin Ren",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11127v3",
                "http://arxiv.org/pdf/2308.11127v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11100v2",
            "title": "Using Early Exits for Fast Inference in Automatic Modulation\n  Classification",
            "updated": "2023-11-09T18:10:17Z",
            "published": "2023-08-22T00:51:44Z",
            "summary": "Automatic modulation classification (AMC) plays a critical role in wireless\ncommunications by autonomously classifying signals transmitted over the radio\nspectrum. Deep learning (DL) techniques are increasingly being used for AMC due\nto their ability to extract complex wireless signal features. However, DL\nmodels are computationally intensive and incur high inference latencies. This\npaper proposes the application of early exiting (EE) techniques for DL models\nused for AMC to accelerate inference. We present and analyze four early exiting\narchitectures and a customized multi-branch training algorithm for this\nproblem. Through extensive experimentation, we show that signals with moderate\nto high signal-to-noise ratios (SNRs) are easier to classify, do not require\ndeep architectures, and can therefore leverage the proposed EE architectures.\nOur experimental results demonstrate that EE techniques can significantly\nreduce the inference speed of deep neural networks without sacrificing\nclassification accuracy. We also thoroughly study the trade-off between\nclassification accuracy and inference time when using these architectures. To\nthe best of our knowledge, this work represents the first attempt to apply\nearly exiting methods to AMC, providing a foundation for future research in\nthis area.",
            "author": [
                "Elsayed Mohammed",
                "Omar Mashaal",
                "Hatem Abou-Zeid"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11100v2",
                "http://arxiv.org/pdf/2308.11100v2"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11082v1",
            "title": "PrAIoritize: Learning to Prioritize Smart Contract Bugs and\n  Vulnerabilities",
            "updated": "2023-08-21T23:30:39Z",
            "published": "2023-08-21T23:30:39Z",
            "summary": "Smart contract vulnerabilities and bugs have become a key concern for\nsoftware engineers, as they can lead to significant financial losses,\nreputational damage, and legal issues. Therefore, prioritizing bug fixing for\nsmart contracts is critical to maintaining trust. Due to the lack of tracking\ntools, prioritizing smart contract-reported bugs is done manually, which is a\ntedious task, limits bug triaging, and needs specialized knowledge. Towards\nthis end, we propose PrAIoritize; an automated approach for predicting smart\ncontract bug priorities that assist software engineers in prioritizing highly\nurgent bug reports. PrAIoritize consists of two main phases: 1) automatic\nlabeling, which involves the automatic construction of a smart contract keyword\nlexicon and the automatic assignment of priority levels to unlabeled bug\nreports; 2) model construction, which involves feature engineering and designs\nlayers of feed-forward neural networks (FFNNs) and bidirectional long\nshort-term memory (BiLSTM) with multi-class classification to better capture\nthe features of the textual descriptions of bugs and predict their priority\nlevels. The model then is trained using smart contract bug reports collected\nfrom two data sources: open-source software (OSS) projects available on GitHub\nand NVD vulnerability database. Our evaluation demonstrates significant\nimprovement over state-of-the-art baselines and commonly used pre-trained\nmodels (e.g. BERT) for similar classification tasks, with 5.75%-35.29% increase\nin F-measure, precision, and recall.",
            "author": [
                "Majd Soud",
                "Grischa Liebel",
                "Mohammad Hamdaqa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11082v1",
                "http://arxiv.org/pdf/2308.11082v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11078v1",
            "title": "Matrix Completion over Finite Fields: Bounds and Belief Propagation\n  Algorithms",
            "updated": "2023-08-21T23:09:09Z",
            "published": "2023-08-21T23:09:09Z",
            "summary": "We consider the low rank matrix completion problem over finite fields. This\nproblem has been extensively studied in the domain of real/complex numbers,\nhowever, to the best of authors' knowledge, there exists merely one efficient\nalgorithm to tackle the problem in the binary field, due to Saunderson et al.\n[1]. In this paper, we improve upon the theoretical guarantees for the\nalgorithm provided in [1]. Furthermore, we formulate a new graphical model for\nthe matrix completion problem over the finite field of size $q$, $\\Bbb{F}_q$,\nand present a message passing (MP) based approach to solve this problem. The\nproposed algorithm is the first one for the considered matrix completion\nproblem over finite fields of arbitrary size. Our proposed method has a\nsignificantly lower computational complexity, reducing it from $O(n^{2r+3})$ in\n[1] down to $O(n^2)$ (where, the underlying matrix has dimension $n \\times n$\nand $r$ denotes its rank), while also improving the performance.",
            "author": [
                "Mahdi Soleymani",
                "Qiang Liu",
                "Hessam Mahdavifar",
                "Laura Balzano"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11078v1",
                "http://arxiv.org/pdf/2308.11078v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11068v2",
            "title": "Topological Graph Signal Compression",
            "updated": "2023-12-05T13:42:53Z",
            "published": "2023-08-21T22:26:21Z",
            "summary": "Recently emerged Topological Deep Learning (TDL) methods aim to extend\ncurrent Graph Neural Networks (GNN) by naturally processing higher-order\ninteractions, going beyond the pairwise relations and local neighborhoods\ndefined by graph representations. In this paper we propose a novel TDL-based\nmethod for compressing signals over graphs, consisting in two main steps:\nfirst, disjoint sets of higher-order structures are inferred based on the\noriginal signal --by clustering $N$ datapoints into $K\\ll N$ collections; then,\na topological-inspired message passing gets a compressed representation of the\nsignal within those multi-element sets. Our results show that our framework\nimproves both standard GNN and feed-forward architectures in compressing\ntemporal link-based signals from two real-word Internet Service Provider\nNetworks' datasets --from $30\\%$ up to $90\\%$ better reconstruction errors\nacross all evaluation scenarios--, suggesting that it better captures and\nexploits spatial and temporal correlations over the whole graph-based network\nstructure.",
            "author": [
                "Guillermo Bern\u00e1rdez",
                "Lev Telyatnikov",
                "Eduard Alarc\u00f3n",
                "Albert Cabellos-Aparicio",
                "Pere Barlet-Ros",
                "Pietro Li\u00f2"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11068v2",
                "http://arxiv.org/pdf/2308.11068v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11061v1",
            "title": "Spin models and distance-regular graphs of $q$-Racah type",
            "updated": "2023-08-21T22:11:08Z",
            "published": "2023-08-21T22:11:08Z",
            "summary": "Let $\\Gamma$ denote a distance-regular graph, with vertex set $X$ and\ndiameter $D\\geq 3$. We assume that $\\Gamma$ is formally self-dual and $q$-Racah\ntype. We also assume that for each $x \\in X$ the subconstituent algebra\n$T=T(x)$ contains a certain central element $Z=Z(x)$. We use $Z$ to construct a\nspin model $\\sf W$ afforded by $\\Gamma$. We investigate the combinatorial\nimplications of $Z$. We reverse the logical direction and recover $Z$ from $\\sf\nW$. We finish with some open problems.",
            "author": [
                "Kazumasa Nomura",
                "Paul Terwilliger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11061v1",
                "http://arxiv.org/pdf/2308.11061v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.QA",
                "05E30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12305v1",
            "title": "FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal\n  Heterogeneous Federated Learning",
            "updated": "2023-08-21T21:57:01Z",
            "published": "2023-08-21T21:57:01Z",
            "summary": "Recently, foundation models have exhibited remarkable advancements in\nmulti-modal learning. These models, equipped with millions (or billions) of\nparameters, typically require a substantial amount of data for finetuning.\nHowever, collecting and centralizing training data from diverse sectors becomes\nchallenging due to distinct privacy regulations. Federated Learning (FL)\nemerges as a promising solution, enabling multiple clients to collaboratively\ntrain neural networks without centralizing their local data. To alleviate\nclient computation burdens and communication overheads, previous works have\nadapted Parameter-efficient Finetuning (PEFT) methods for FL. Hereby, only a\nsmall fraction of the model parameters are optimized and communicated during\nfederated communications. Nevertheless, most previous works have focused on a\nsingle modality and neglected one common phenomenon, i.e., the presence of data\nheterogeneity across the clients. Therefore, in this work, we propose a\nfinetuning framework tailored to heterogeneous multi-modal FL, called Federated\nDual-Aadapter Teacher (FedDAT). Specifically, our approach leverages a\nDual-Adapter Teacher (DAT) to address data heterogeneity by regularizing the\nclient local updates and applying Mutual Knowledge Distillation (MKD) for an\nefficient knowledge transfer. FedDAT is the first approach that enables an\nefficient distributed finetuning of foundation models for a variety of\nheterogeneous Vision-Language tasks. To demonstrate its effectiveness, we\nconduct extensive experiments on four multi-modality FL benchmarks with\ndifferent types of data heterogeneity, where FedDAT substantially outperforms\nthe existing centralized PEFT methods adapted for FL.",
            "author": [
                "Haokun Chen",
                "Yao Zhang",
                "Denis Krompass",
                "Jindong Gu",
                "Volker Tresp"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12305v1",
                "http://arxiv.org/pdf/2308.12305v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11056v1",
            "title": "Closeness and Residual Closeness of Harary Graphs",
            "updated": "2023-08-21T21:52:08Z",
            "published": "2023-08-21T21:52:08Z",
            "summary": "Analysis of a network in terms of vulnerability is one of the most\nsignificant problems. Graph theory serves as a valuable tool for solving\ncomplex network problems, and there exist numerous graph-theoretic parameters\nto analyze the system's stability. Among these parameters, the closeness\nparameter stands out as one of the most commonly used vulnerability metric. Its\ndefinition has evolved over time to enhance ease of formulation and\napplicability to disconnected structures. Furthermore, based on the closeness\nparameter, residual closeness, which is a newer and more sensitive parameter\ncompared to other existing parameters, has been introduced as a new graph\nvulnerability index by Dangalchev. In this study, the outcomes of the closeness\nand residual closeness parameters in Harary Graphs have been examined. Harary\nGraphs are well-known constructs that are distinguished by having $n$ vertices\nthat are $k$-connected with the least possible number of edges.",
            "author": [
                "Hande Tuncel Golpek",
                "Aysun Aytac"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11056v1",
                "http://arxiv.org/pdf/2308.11056v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "05C12, 05C76, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11043v1",
            "title": "Spurious Correlations and Where to Find Them",
            "updated": "2023-08-21T21:06:36Z",
            "published": "2023-08-21T21:06:36Z",
            "summary": "Spurious correlations occur when a model learns unreliable features from the\ndata and are a well-known drawback of data-driven learning. Although there are\nseveral algorithms proposed to mitigate it, we are yet to jointly derive the\nindicators of spurious correlations. As a result, the solutions built upon\nstandalone hypotheses fail to beat simple ERM baselines. We collect some of the\ncommonly studied hypotheses behind the occurrence of spurious correlations and\ninvestigate their influence on standard ERM baselines using synthetic datasets\ngenerated from causal graphs. Subsequently, we observe patterns connecting\nthese hypotheses and model design choices.",
            "author": [
                "Gautam Sreekumar",
                "Vishnu Naresh Boddeti"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11043v1",
                "http://arxiv.org/pdf/2308.11043v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11015v1",
            "title": "Spectral Graphormer: Spectral Graph-based Transformer for Egocentric\n  Two-Hand Reconstruction using Multi-View Color Images",
            "updated": "2023-08-21T20:07:02Z",
            "published": "2023-08-21T20:07:02Z",
            "summary": "We propose a novel transformer-based framework that reconstructs two high\nfidelity hands from multi-view RGB images. Unlike existing hand pose estimation\nmethods, where one typically trains a deep network to regress hand model\nparameters from single RGB image, we consider a more challenging problem\nsetting where we directly regress the absolute root poses of two-hands with\nextended forearm at high resolution from egocentric view. As existing datasets\nare either infeasible for egocentric viewpoints or lack background variations,\nwe create a large-scale synthetic dataset with diverse scenarios and collect a\nreal dataset from multi-calibrated camera setup to verify our proposed\nmulti-view image feature fusion strategy. To make the reconstruction physically\nplausible, we propose two strategies: (i) a coarse-to-fine spectral graph\nconvolution decoder to smoothen the meshes during upsampling and (ii) an\noptimisation-based refinement stage at inference to prevent self-penetrations.\nThrough extensive quantitative and qualitative evaluations, we show that our\nframework is able to produce realistic two-hand reconstructions and demonstrate\nthe generalisation of synthetic-trained models to real data, as well as\nreal-time AR/VR applications.",
            "author": [
                "Tze Ho Elden Tse",
                "Franziska Mueller",
                "Zhengyang Shen",
                "Danhang Tang",
                "Thabo Beeler",
                "Mingsong Dou",
                "Yinda Zhang",
                "Sasa Petrovic",
                "Hyung Jin Chang",
                "Jonathan Taylor",
                "Bardia Doosti"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11015v1",
                "http://arxiv.org/pdf/2308.11015v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11010v1",
            "title": "Valence-Bond Solid phases in the spin-$1/2$ Kekul{\u00e9}-Heisenberg model",
            "updated": "2023-08-21T19:50:56Z",
            "published": "2023-08-21T19:50:56Z",
            "summary": "We map out the ground state phase diagram of the isotropic Kekul{\\'e}-Kitaev\nmodel on the honeycomb lattice in the presence of the Heisenberg exchange\ncouplings. Our study relies on large-scale tensor network simulations based on\ngraph-based projected entangled pair state (gPEPS) approach in the\nthermodynamic limit. We find that on top of the quantum spin liquid (QSL) and\nconventional magnetically ordered phases which are typical of the\nKitaev-Heisenberg model, the Kekul{\\'e}-Heisenberg phase diagram, hosts two\nplaquette valance bond solid (VBS) phases with vanishing magnetic order. While\nthe VBS phases preserve the symmetries of the original Hamiltonian, they differ\nmarkedly from the Kitaev spin liquid by having decorated plaquette ordering\nwhich is distinguished by a plaquette order parameter.",
            "author": [
                "Fatemeh Mirmojarabian",
                "Saeed S. Jahromi",
                "Jahanfar Abouie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11010v1",
                "http://arxiv.org/pdf/2308.11010v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11003v1",
            "title": "Autonomous Detection of Methane Emissions in Multispectral Satellite\n  Data Using Deep Learning",
            "updated": "2023-08-21T19:36:50Z",
            "published": "2023-08-21T19:36:50Z",
            "summary": "Methane is one of the most potent greenhouse gases, and its short atmospheric\nhalf-life makes it a prime target to rapidly curb global warming. However,\ncurrent methane emission monitoring techniques primarily rely on approximate\nemission factors or self-reporting, which have been shown to often dramatically\nunderestimate emissions. Although initially designed to monitor surface\nproperties, satellite multispectral data has recently emerged as a powerful\nmethod to analyze atmospheric content. However, the spectral resolution of\nmultispectral instruments is poor, and methane measurements are typically very\nnoisy. Methane data products are also sensitive to absorption by the surface\nand other atmospheric gases (water vapor in particular) and therefore provide\nnoisy maps of potential methane plumes, that typically require extensive human\nanalysis. Here, we show that the image recognition capabilities of deep\nlearning methods can be leveraged to automatize the detection of methane leaks\nin Sentinel-2 satellite multispectral data, with dramatically reduced false\npositive rates compared with state-of-the-art multispectral methane data\nproducts, and without the need for a priori knowledge of potential leak sites.\nOur proposed approach paves the way for the automated, high-definition and\nhigh-frequency monitoring of point-source methane emissions across the world.",
            "author": [
                "Bertrand Rouet-Leduc",
                "Thomas Kerdreux",
                "Alexandre Tuel",
                "Claudia Hulbert"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11003v1",
                "http://arxiv.org/pdf/2308.11003v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10978v2",
            "title": "Triangle-degree and triangle-distinct graphs",
            "updated": "2023-08-30T13:54:39Z",
            "published": "2023-08-21T18:54:17Z",
            "summary": "Let $G$ be a simple graph and $v$ be a vertex of $G$. The triangle-degree of\n$v$ in $G$ is the number of triangles that contain $v$. While every graph has\nat least two vertices with the same degree, there are graphs in which every\nvertex has a distinct triangle-degree. In this paper, we construct an infinite\nfamily of graphs with this property. We also study the vertex degrees and size\nof graphs with this property.",
            "author": [
                "Zhanar Berikkyzy",
                "Beth Bjorkman",
                "Heather Smith Blake",
                "Sogol Jahanbekam",
                "Lauren Keough",
                "Kevin Moss",
                "Danny Rorabaugh",
                "Songling Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10978v2",
                "http://arxiv.org/pdf/2308.10978v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10974v3",
            "title": "\"Guinea Pig Trials\" Utilizing GPT: A Novel Smart Agent-Based Modeling\n  Approach for Studying Firm Competition and Collusion",
            "updated": "2023-11-20T18:30:20Z",
            "published": "2023-08-21T18:42:17Z",
            "summary": "Firm competition and collusion involve complex dynamics, particularly when\nconsidering communication among firms. Such issues can be modeled as problems\nof complex systems, traditionally approached through experiments involving\nhuman subjects or agent-based modeling methods. We propose an innovative\nframework called Smart Agent-Based Modeling (SABM), wherein smart agents,\nsupported by GPT-4 technologies, represent firms, and interact with one\nanother. We conducted a controlled experiment to study firm price competition\nand collusion behaviors under various conditions. SABM is more cost-effective\nand flexible compared to conducting experiments with human subjects. Smart\nagents possess an extensive knowledge base for decision-making and exhibit\nhuman-like strategic abilities, surpassing traditional ABM agents. Furthermore,\nsmart agents can simulate human conversation and be personalized, making them\nideal for studying complex situations involving communication. Our results\ndemonstrate that, in the absence of communication, smart agents consistently\nreach tacit collusion, leading to prices converging at levels higher than the\nBertrand equilibrium price but lower than monopoly or cartel prices. When\ncommunication is allowed, smart agents achieve a higher-level collusion with\nprices close to cartel prices. Collusion forms more quickly with communication,\nwhile price convergence is smoother without it. These results indicate that\ncommunication enhances trust between firms, encouraging frequent small price\ndeviations to explore opportunities for a higher-level win-win situation and\nreducing the likelihood of triggering a price war. We also assigned different\npersonas to firms to analyze behavioral differences and tested variant models\nunder diverse market structures. The findings showcase the effectiveness and\nrobustness of SABM and provide intriguing insights into competition and\ncollusion.",
            "author": [
                "Xu Han",
                "Zengqing Wu",
                "Chuan Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10974v3",
                "http://arxiv.org/pdf/2308.10974v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CE",
                "cs.MA",
                "econ.GN",
                "q-fin.EC",
                "I.2.1; I.2.7; I.6.5; J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10881v1",
            "title": "A note on Ambarzumian's theorem for quantum graphs",
            "updated": "2023-08-21T17:28:09Z",
            "published": "2023-08-21T17:28:09Z",
            "summary": "Based on the main result presented in a recent paper, we derive\nAmbarzumian-type theorems for Schr\\\"odinger operators defined on quantum\ngraphs. We recover existing results such as the classical theorem by\nAmbarzumian and establish some seemingly new statements, too.",
            "author": [
                "Patrizio Bifulco",
                "Joachim Kerner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10881v1",
                "http://arxiv.org/pdf/2308.10881v1"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math-ph",
                "math.MP",
                "34L05, 81Q35, 34L15, 34L20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10874v2",
            "title": "Analyzing Transformer Dynamics as Movement through Embedding Space",
            "updated": "2023-11-14T05:06:01Z",
            "published": "2023-08-21T17:21:23Z",
            "summary": "Transformer based language models exhibit intelligent behaviors such as\nunderstanding natural language, recognizing patterns, acquiring knowledge,\nreasoning, planning, reflecting and using tools. This paper explores how their\nunderlying mechanics give rise to intelligent behaviors. Towards that end, we\npropose framing Transformer dynamics as movement through embedding space.\nExamining Transformers through this perspective reveals key insights,\nestablishing a Theory of Transformers: 1) Intelligent behaviours map to paths\nin Embedding Space which, the Transformer random-walks through during\ninferencing. 2) LM training learns a probability distribution over all possible\npaths. `Intelligence' is learnt by assigning higher probabilities to paths\nrepresenting intelligent behaviors. No learning can take place in-context;\ncontext only narrows the subset of paths sampled during decoding. 5) The\nTransformer is a self-mapping composition function, folding a context sequence\ninto a context-vector such that it's proximity to a token-vector reflects its\nco-occurrence and conditioned probability. Thus, the physical arrangement of\nvectors in Embedding Space determines path probabilities. 6) Context vectors\nare composed by aggregating features of the sequence's tokens via a process we\ncall the encoding walk. Attention contributes a - potentially redundant -\nassociation-bias to this process. 7) This process is comprised of two principal\noperation types: filtering (data independent) and aggregation (data dependent).\nThis generalization unifies Transformers with other sequence models. Building\nupon this foundation, we formalize a popular semantic interpretation of\nembeddings into a ``concept-space theory'' and find some evidence of it's\nvalidity.",
            "author": [
                "Sumeet S. Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10874v2",
                "http://arxiv.org/pdf/2308.10874v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10873v1",
            "title": "SpikingBERT: Distilling BERT to Train Spiking Language Models Using\n  Implicit Differentiation",
            "updated": "2023-08-21T17:20:05Z",
            "published": "2023-08-21T17:20:05Z",
            "summary": "Large language Models (LLMs), though growing exceedingly powerful, comprises\nof orders of magnitude less neurons and synapses than the human brain. However,\nit requires significantly more power/energy to operate. In this work, we\npropose a novel bio-inspired spiking language model (LM) which aims to reduce\nthe computational cost of conventional LMs by drawing motivation from the\nsynaptic information flow in the brain. In this paper, we demonstrate a\nframework that leverages the average spiking rate of neurons at equilibrium to\ntrain a neuromorphic spiking LM using implicit differentiation technique,\nthereby overcoming the non-differentiability problem of spiking neural network\n(SNN) based algorithms without using any type of surrogate gradient. The\nsteady-state convergence of the spiking neurons also allows us to design a\nspiking attention mechanism, which is critical in developing a scalable spiking\nLM. Moreover, the convergence of average spiking rate of neurons at equilibrium\nis utilized to develop a novel ANN-SNN knowledge distillation based technique\nwherein we use a pre-trained BERT model as \"teacher\" to train our \"student\"\nspiking architecture. While the primary architecture proposed in this paper is\nmotivated by BERT, the technique can be potentially extended to different kinds\nof LLMs. Our work is the first one to demonstrate the performance of an\noperational spiking LM architecture on multiple different tasks in the GLUE\nbenchmark.",
            "author": [
                "Malyaban Bal",
                "Abhronil Sengupta"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10873v1",
                "http://arxiv.org/pdf/2308.10873v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10872v1",
            "title": "A study of $4-$cycle systems",
            "updated": "2023-08-21T17:18:34Z",
            "published": "2023-08-21T17:18:34Z",
            "summary": "A $4-$cycle system is a partition of the edges of the complete graph $K_n$\ninto $4-$cycles. Let ${ C}$ be a collection of cycles of length 4 whose edges\npartition the edges of $K_n$. A set of 4-cycles $T_1 \\subset C$ is called a\n4-cycle trade if there exists a set $T_2$ of edge-disjoint 4-cycles on the same\nvertices, such that $({C} \\setminus T_1)\\cup T_2$ also is a collection of\ncycles of length 4 whose edges partition the edges of $K_n$.\n  We study $4-$cycle trades of volume two (double-diamonds) and three and show\nthat the set of all 4-CS(9) is connected with respect of trading with trades of\nvolume 2 (double-diamond) and 3.\n  In addition, we present a full rank matrix whose null-space is containing\ntrade-vectors.",
            "author": [
                "B. Bagheri Gh.",
                "M. Khosravi",
                "E. S. Mahmoodian",
                "S. Rashidi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10872v1",
                "http://arxiv.org/pdf/2308.10872v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05B30, 05B05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10864v1",
            "title": "Clustering of Dynamical Systems",
            "updated": "2023-08-21T17:08:37Z",
            "published": "2023-08-21T17:08:37Z",
            "summary": "In this work, we address the problem of community detection in a graph whose\nconnectivity is given by probabilities (denoted by numbers between zero and\none) rather than an adjacency matrix (only 0 or 1). The graphs themselves come\nfrom partitions of a dynamical system's state space where the probabilities\ndenote likely transition pathways for dynamics. We propose a modification of\nthe Leicht-Newman algorithm \\cite{Leicht2008} which is able to automatically\ndetect communities of strongly intra-connected points in state space, from\nwhich information about the residence time of the system and its principal\nperiodicities can be extracted. Furthermore, a novel algorithm to construct the\ntransition rate matrix of a dynamical system which encodes the time dependency\nof its Perron-Frobenius operator, is developed. Crucially, it overcomes the\nissue of time-scale separation stemming from the matrix construction based on\n{\\it{infinitesimal}} generators and the exploration of {\\it{long-term}}\nfeatures of the underlying dynamical system. This method is then tested on a\nrange of dynamical systems and datasets.",
            "author": [
                "Ludovico Theo Giorgini",
                "Andre N. Souza",
                "Peter J. Schmid"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10864v1",
                "http://arxiv.org/pdf/2308.10864v1"
            ],
            "primary_category": "nlin.CD",
            "category": [
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12152v1",
            "title": "Geo-Sketcher: Rapid 3D Geological Modeling using Geological and\n  Topographic Map Sketches",
            "updated": "2023-08-21T17:01:36Z",
            "published": "2023-08-21T17:01:36Z",
            "summary": "The construction of 3D geological models is an essential task in oil/gas\nexploration, development and production. However, it is a cumbersome,\ntime-consuming and error-prone task mainly because of the model's geometric and\ntopological complexity. The models construction is usually separated into\ninterpretation and 3D modeling, performed by different highly specialized\nindividuals, which leads to inconsistencies and intensifies the challenges. In\naddition, the creation of models following geological rules is paramount for\nproperly depicting static and dynamic properties of oil/gas reservoirs. In this\nwork, we propose a sketch-based approach to expedite the creation of valid 3D\ngeological models by mimicking how domain experts interpret geological\nstructures, allowing creating models directly from interpretation sketches. Our\nsketch-based modeler (Geo-Sketcher) is based on sketches of standard 2D\ntopographic and geological maps, comprised of lines, symbols and annotations.\nWe developed a graph-based representation to enable (1) the automatic\ncomputation of the relative ages of rock series and layers, and (2) the\nembedding of specific geological rules directly in the sketching. We introduce\nthe use of Hermite-Birkhoff Radial Basis Functions to interpolate the\ngeological map constraints, and demonstrate the capabilities of our approach\nwith a variety of results with different levels of complexity.",
            "author": [
                "Ronan Amorim",
                "Emilio Vital Brazil",
                "Faramarz Samavati",
                "Mario Costa Sousa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12152v1",
                "http://arxiv.org/pdf/2308.12152v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10853v1",
            "title": "Generalized point configurations in ${\\mathbb F}_q^d$",
            "updated": "2023-08-21T16:49:00Z",
            "published": "2023-08-21T16:49:00Z",
            "summary": "In this paper, we generalize \\cite{IosevichParshall}, \\cite{LongPaths} and\n\\cite{cycles} by allowing the \\emph{distance} between two points in a finite\nfield vector space to be defined by a general non-degenerate bilinear form or\nquadratic form. We prove the same bounds on the sizes of large subsets of\n$\\F_q^d$ for them to contain distance graphs with a given maximal vertex\ndegree, under the more general notion of distance. We also prove the same\nresults for embedding paths, trees and cycles in the general setting.",
            "author": [
                "Paige Bright",
                "Xinyu Fang",
                "Barrett Heritage",
                "Alex Iosevich",
                "Tingsong Jiang",
                "Hans Parshall",
                "Maxwell Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10853v1",
                "http://arxiv.org/pdf/2308.10853v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.CA",
                "52C10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10851v1",
            "title": "Learning in Dynamic Systems and Its Application to Adaptive PID Control",
            "updated": "2023-08-21T16:48:11Z",
            "published": "2023-08-21T16:48:11Z",
            "summary": "Deep learning using neural networks has revolutionized machine learning and\nput artificial intelligence into everyday life. In order to introduce\nself-learning to dynamic systems other than neural networks, we extend the\nBrandt-Lin learning algorithm of neural networks to a large class of dynamic\nsystems. This extension is possible because the Brandt-Lin algorithm does not\nrequire a dedicated step to back-propagate the errors in neural networks. To\nthis end, we first generalize signal-flow graphs so that they can be used to\nmodel nonlinear systems as well as linear systems. We then derive the extended\nBrandt-Lin algorithm that can be used to adapt the weights of branches in\ngeneralized signal-flow graphs. We show the applications of the new algorithm\nby applying it to adaptive PID control. In particular, we derive a new\nadaptation law for PID controllers. We verify the effectiveness of the method\nusing simulations for linear and nonlinear plants, stable as well as unstable\nplants.",
            "author": [
                "Omar Makke",
                "Feng Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10851v1",
                "http://arxiv.org/pdf/2308.10851v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10838v1",
            "title": "An impossibility result for Markov Chain Monte Carlo sampling from\n  micro-canonical bipartite graph ensembles",
            "updated": "2023-08-21T16:40:27Z",
            "published": "2023-08-21T16:40:27Z",
            "summary": "Markov Chain Monte Carlo (MCMC) algorithms are commonly used to sample from\ngraph ensembles. Two graphs are neighbors in the state space if one can be\nobtained from the other with only a few modifications, e.g., edge rewirings.\nFor many common ensembles, e.g., those preserving the degree sequences of\nbipartite graphs, rewiring operations involving two edges are sufficient to\ncreate a fully-connected state space, and they can be performed efficiently. We\nshow that, for ensembles of bipartite graphs with fixed degree sequences and\nnumber of butterflies (k2,2 bi-cliques), there is no universal constant c such\nthat a rewiring of at most c edges at every step is sufficient for any such\nensemble to be fully connected. Our proof relies on an explicit construction of\na family of pairs of graphs with the same degree sequences and number of\nbutterflies, with each pair indexed by a natural c, and such that any sequence\nof rewiring operations transforming one graph into the other must include at\nleast one rewiring operation involving at least c edges. Whether rewiring these\nmany edges is sufficient to guarantee the full connectivity of the state space\nof any such ensemble remains an open question. Our result implies the\nimpossibility of developing efficient, graph-agnostic, MCMC algorithms for\nthese ensembles, as the necessity to rewire an impractically large number of\nedges may hinder taking a step on the state space.",
            "author": [
                "Giulia Preti",
                "Gianmarco De Francisci Morales",
                "Matteo Riondato"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10838v1",
                "http://arxiv.org/pdf/2308.10838v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10837v1",
            "title": "Leveraging Large Language Models for Pre-trained Recommender Systems",
            "updated": "2023-08-21T16:39:11Z",
            "published": "2023-08-21T16:39:11Z",
            "summary": "Recent advancements in recommendation systems have shifted towards more\ncomprehensive and personalized recommendations by utilizing large language\nmodels (LLM). However, effectively integrating LLM's commonsense knowledge and\nreasoning abilities into recommendation systems remains a challenging problem.\nIn this paper, we propose RecSysLLM, a novel pre-trained recommendation model\nbased on LLMs. RecSysLLM retains LLM reasoning and knowledge while integrating\nrecommendation domain knowledge through unique designs of data, training, and\ninference. This allows RecSysLLM to leverage LLMs' capabilities for\nrecommendation tasks in an efficient, unified framework. We demonstrate the\neffectiveness of RecSysLLM on benchmarks and real-world scenarios. RecSysLLM\nprovides a promising approach to developing unified recommendation systems by\nfully exploiting the power of pre-trained language models.",
            "author": [
                "Zhixuan Chu",
                "Hongyan Hao",
                "Xin Ouyang",
                "Simeng Wang",
                "Yan Wang",
                "Yue Shen",
                "Jinjie Gu",
                "Qing Cui",
                "Longfei Li",
                "Siqiao Xue",
                "James Y Zhang",
                "Sheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10837v1",
                "http://arxiv.org/pdf/2308.10837v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10835v1",
            "title": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
            "updated": "2023-08-21T16:35:19Z",
            "published": "2023-08-21T16:35:19Z",
            "summary": "Recommendation systems aim to provide users with relevant suggestions, but\noften lack interpretability and fail to capture higher-level semantic\nrelationships between user behaviors and profiles. In this paper, we propose a\nnovel approach that leverages large language models (LLMs) to construct\npersonalized reasoning graphs. These graphs link a user's profile and\nbehavioral sequences through causal and logical inferences, representing the\nuser's interests in an interpretable way. Our approach, LLM reasoning graphs\n(LLMRG), has four components: chained graph reasoning, divergent extension,\nself-verification and scoring, and knowledge base self-improvement. The\nresulting reasoning graph is encoded using graph neural networks, which serves\nas additional input to improve conventional recommender systems, without\nrequiring extra user or item information. Our approach demonstrates how LLMs\ncan enable more logical and interpretable recommender systems through\npersonalized reasoning graphs. LLMRG allows recommendations to benefit from\nboth engineered recommendation systems and LLM-derived reasoning graphs. We\ndemonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios\nin enhancing base recommendation models.",
            "author": [
                "Yan Wang",
                "Zhixuan Chu",
                "Xin Ouyang",
                "Simeng Wang",
                "Hongyan Hao",
                "Yue Shen",
                "Jinjie Gu",
                "Siqiao Xue",
                "James Y Zhang",
                "Qing Cui",
                "Longfei Li",
                "Jun Zhou",
                "Sheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10835v1",
                "http://arxiv.org/pdf/2308.10835v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10833v1",
            "title": "Ramsey numbers of hypergraphs of a given size",
            "updated": "2023-08-21T16:31:09Z",
            "published": "2023-08-21T16:31:09Z",
            "summary": "The $q$-color Ramsey number of a $k$-uniform hypergraph $H$ is the minimum\ninteger $N$ such that any $q$-coloring of the complete $k$-uniform hypergraph\non $N$ vertices contains a monochromatic copy of $H$. The study of these\nnumbers is one of the central topics in Combinatorics. In 1973, Erd\\H{o}s and\nGraham asked to maximize the Ramsey number of a graph as a function of the\nnumber of its edges. Motivated by this problem, we study the analogous question\nfor hypergaphs. For fixed $k \\ge 3$ and $q \\ge 2$ we prove that the largest\npossible $q$-color Ramsey number of a $k$-uniform hypergraph with $m$ edges is\nat most $\\mathrm{tw}_k(O(\\sqrt{m})),$ where $\\mathrm{tw}$ denotes the tower\nfunction. We also present a construction showing that this bound is tight for\n$q \\ge 4$. This resolves a problem by Conlon, Fox and Sudakov. They previously\nproved the upper bound for $k \\geq 4$ and the lower bound for $k=3$. Although\nin the graph case the tightness follows simply by considering a clique of\nappropriate size, for higher uniformities the construction is rather involved\nand is obtained by using paths in expander graphs.",
            "author": [
                "Domagoj Brada\u010d",
                "Jacob Fox",
                "Benny Sudakov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10833v1",
                "http://arxiv.org/pdf/2308.10833v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10811v2",
            "title": "Tree Drawings with Columns",
            "updated": "2023-09-04T16:42:39Z",
            "published": "2023-08-21T15:59:36Z",
            "summary": "Our goal is to visualize an additional data dimension of a tree with\nmultifaceted data through superimposition on vertical strips, which we call\ncolumns. Specifically, we extend upward drawings of unordered rooted trees\nwhere vertices have assigned heights by mapping each vertex to a column. Under\nan orthogonal drawing style and with every subtree within a column drawn\nplanar, we consider different natural variants concerning the arrangement of\nsubtrees within a column. We show that minimizing the number of crossings in\nsuch a drawing can be achieved in fixed-parameter tractable (FPT) time in the\nmaximum vertex degree $\\Delta$ for the most restrictive variant, while becoming\nNP-hard (even to approximate) already for a slightly relaxed variant. However,\nwe provide an FPT algorithm in the number of crossings plus $\\Delta$, and an\nFPT-approximation algorithm in $\\Delta$ via a reduction to feedback arc set.",
            "author": [
                "Jonathan Klawitter",
                "Johannes Zink"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10811v2",
                "http://arxiv.org/pdf/2308.10811v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10809v1",
            "title": "Improving Continuous Sign Language Recognition with Cross-Lingual Signs",
            "updated": "2023-08-21T15:58:47Z",
            "published": "2023-08-21T15:58:47Z",
            "summary": "This work dedicates to continuous sign language recognition (CSLR), which is\na weakly supervised task dealing with the recognition of continuous signs from\nvideos, without any prior knowledge about the temporal boundaries between\nconsecutive signs. Data scarcity heavily impedes the progress of CSLR. Existing\napproaches typically train CSLR models on a monolingual corpus, which is orders\nof magnitude smaller than that of speech recognition. In this work, we explore\nthe feasibility of utilizing multilingual sign language corpora to facilitate\nmonolingual CSLR. Our work is built upon the observation of cross-lingual\nsigns, which originate from different sign languages but have similar visual\nsignals (e.g., hand shape and motion). The underlying idea of our approach is\nto identify the cross-lingual signs in one sign language and properly leverage\nthem as auxiliary training data to improve the recognition capability of\nanother. To achieve the goal, we first build two sign language dictionaries\ncontaining isolated signs that appear in two datasets. Then we identify the\nsign-to-sign mappings between two sign languages via a well-optimized isolated\nsign language recognition model. At last, we train a CSLR model on the\ncombination of the target data with original labels and the auxiliary data with\nmapped labels. Experimentally, our approach achieves state-of-the-art\nperformance on two widely-used CSLR datasets: Phoenix-2014 and Phoenix-2014T.",
            "author": [
                "Fangyun Wei",
                "Yutong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10809v1",
                "http://arxiv.org/pdf/2308.10809v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10810v1",
            "title": "Evaluating Pauli errors on cluster states by weighted distances",
            "updated": "2023-08-21T15:58:47Z",
            "published": "2023-08-21T15:58:47Z",
            "summary": "We address the problem of evaluating the difference between quantum states\nbefore and after being affected by errors encoded in unitary transformations.\nStandard distance functions, e.g., the Bures length, are not fully adequate for\nsuch a task. Weighted distances are instead appropriate information measures to\nquantify distinguishability of multipartite states. Here, we employ the\npreviously introduced weighted Bures length and the newly defined weighted\nHilbert-Schmidt distance to quantify how much single-qubit Pauli errors alter\ncluster states. We find that different errors of the same dimension change\ncluster states in a different way, i.e., their detectability is in general\ndifferent. Indeed, they transform an ideal cluster state into a state whose\nweighted distance from the input depends on the specific chosen Pauli rotation,\nas well as the position of the affected qubit in the graph related to the\nstate. As these features are undetected by using standard distances, the study\nproves the usefulness of weighted distances to monitor key but elusive\nproperties of many-body quantum systems.",
            "author": [
                "Choong Pak Shen",
                "Davide Girolami"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10810v1",
                "http://arxiv.org/pdf/2308.10810v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10808v1",
            "title": "Graph Neural Bandits",
            "updated": "2023-08-21T15:57:57Z",
            "published": "2023-08-21T15:57:57Z",
            "summary": "Contextual bandits algorithms aim to choose the optimal arm with the highest\nreward out of a set of candidates based on the contextual information. Various\nbandit algorithms have been applied to real-world applications due to their\nability of tackling the exploitation-exploration dilemma. Motivated by online\nrecommendation scenarios, in this paper, we propose a framework named Graph\nNeural Bandits (GNB) to leverage the collaborative nature among users empowered\nby graph neural networks (GNNs). Instead of estimating rigid user clusters as\nin existing works, we model the \"fine-grained\" collaborative effects through\nestimated user graphs in terms of exploitation and exploration respectively.\nThen, to refine the recommendation strategy, we utilize separate GNN-based\nmodels on estimated user graphs for exploitation and adaptive exploration.\nTheoretical analysis and experimental results on multiple real data sets in\ncomparison with state-of-the-art baselines are provided to demonstrate the\neffectiveness of our proposed framework.",
            "author": [
                "Yunzhe Qi",
                "Yikun Ban",
                "Jingrui He"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3580305.3599371",
                "http://arxiv.org/abs/2308.10808v1",
                "http://arxiv.org/pdf/2308.10808v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10807v2",
            "title": "DynED: Dynamic Ensemble Diversification in Data Stream Classification",
            "updated": "2023-09-06T14:27:17Z",
            "published": "2023-08-21T15:56:05Z",
            "summary": "Ensemble methods are commonly used in classification due to their remarkable\nperformance. Achieving high accuracy in a data stream environment is a\nchallenging task considering disruptive changes in the data distribution, also\nknown as concept drift. A greater diversity of ensemble components is known to\nenhance prediction accuracy in such settings. Despite the diversity of\ncomponents within an ensemble, not all contribute as expected to its overall\nperformance. This necessitates a method for selecting components that exhibit\nhigh performance and diversity. We present a novel ensemble construction and\nmaintenance approach based on MMR (Maximal Marginal Relevance) that dynamically\ncombines the diversity and prediction accuracy of components during the process\nof structuring an ensemble. The experimental results on both four real and 11\nsynthetic datasets demonstrate that the proposed approach (DynED) provides a\nhigher average mean accuracy compared to the five state-of-the-art baselines.",
            "author": [
                "Soheil Abadifard",
                "Sepehr Bakhshi",
                "Sanaz Gheibuni",
                "Fazli Can"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615266",
                "http://arxiv.org/abs/2308.10807v2",
                "http://arxiv.org/pdf/2308.10807v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10779v1",
            "title": "Spear and Shield: Adversarial Attacks and Defense Methods for\n  Model-Based Link Prediction on Continuous-Time Dynamic Graphs",
            "updated": "2023-08-21T15:09:51Z",
            "published": "2023-08-21T15:09:51Z",
            "summary": "Real-world graphs are dynamic, constantly evolving with new interactions,\nsuch as financial transactions in financial networks. Temporal Graph Neural\nNetworks (TGNNs) have been developed to effectively capture the evolving\npatterns in dynamic graphs. While these models have demonstrated their\nsuperiority, being widely adopted in various important fields, their\nvulnerabilities against adversarial attacks remain largely unexplored. In this\npaper, we propose T-SPEAR, a simple and effective adversarial attack method for\nlink prediction on continuous-time dynamic graphs, focusing on investigating\nthe vulnerabilities of TGNNs. Specifically, before the training procedure of a\nvictim model, which is a TGNN for link prediction, we inject edge perturbations\nto the data that are unnoticeable in terms of the four constraints we propose,\nand yet effective enough to cause malfunction of the victim model. Moreover, we\npropose a robust training approach T-SHIELD to mitigate the impact of\nadversarial attacks. By using edge filtering and enforcing temporal smoothness\nto node embeddings, we enhance the robustness of the victim model. Our\nexperimental study shows that T-SPEAR significantly degrades the victim model's\nperformance on link prediction tasks, and even more, our attacks are\ntransferable to other TGNNs, which differ from the victim model assumed by the\nattacker. Moreover, we demonstrate that T-SHIELD effectively filters out\nadversarial edges and exhibits robustness against adversarial attacks,\nsurpassing the link prediction performance of the naive TGNN by up to 11.2%\nunder T-SPEAR.",
            "author": [
                "Dongjin Lee",
                "Juho Lee",
                "Kijung Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10779v1",
                "http://arxiv.org/pdf/2308.10779v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10778v2",
            "title": "A Topology-aware Analysis of Graph Collaborative Filtering",
            "updated": "2023-11-26T11:32:59Z",
            "published": "2023-08-21T15:09:19Z",
            "summary": "The successful integration of graph neural networks into recommender systems\n(RSs) has led to a novel paradigm in collaborative filtering (CF), graph\ncollaborative filtering (graph CF). By representing user-item data as an\nundirected, bipartite graph, graph CF utilizes short- and long-range\nconnections to extract collaborative signals that yield more accurate user\npreferences than traditional CF methods. Although the recent literature\nhighlights the efficacy of various algorithmic strategies in graph CF, the\nimpact of datasets and their topological features on recommendation performance\nis yet to be studied. To fill this gap, we propose a topology-aware analysis of\ngraph CF. In this study, we (i) take some widely-adopted recommendation\ndatasets and use them to generate a large set of synthetic sub-datasets through\ntwo state-of-the-art graph sampling methods, (ii) measure eleven of their\nclassical and topological characteristics, and (iii) estimate the accuracy\ncalculated on the generated sub-datasets considering four popular and recent\ngraph-based RSs (i.e., LightGCN, DGCF, UltraGCN, and SVD-GCN). Finally, the\ninvestigation presents an explanatory framework that reveals the linear\nrelationships between characteristics and accuracy measures. The results,\nstatistically validated under different graph sampling settings, confirm the\nexistence of solid dependencies between topological characteristics and\naccuracy in the graph-based recommendation, offering a new perspective on how\nto interpret graph CF.",
            "author": [
                "Daniele Malitesta",
                "Claudio Pomo",
                "Vito Walter Anelli",
                "Alberto Carlo Maria Mancino",
                "Eugenio Di Sciascio",
                "Tommaso Di Noia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10778v2",
                "http://arxiv.org/pdf/2308.10778v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10776v1",
            "title": "A Modular and Adaptive System for Business Email Compromise Detection",
            "updated": "2023-08-21T15:06:02Z",
            "published": "2023-08-21T15:06:02Z",
            "summary": "The growing sophistication of Business Email Compromise (BEC) and spear\nphishing attacks poses significant challenges to organizations worldwide. The\ntechniques featured in traditional spam and phishing detection are insufficient\ndue to the tailored nature of modern BEC attacks as they often blend in with\nthe regular benign traffic. Recent advances in machine learning, particularly\nin Natural Language Understanding (NLU), offer a promising avenue for combating\nsuch attacks but in a practical system, due to limitations such as data\navailability, operational costs, verdict explainability requirements or a need\nto robustly evolve the system, it is essential to combine multiple approaches\ntogether. We present CAPE, a comprehensive and efficient system for BEC\ndetection that has been proven in a production environment for a period of over\ntwo years. Rather than being a single model, CAPE is a system that combines\nindependent ML models and algorithms detecting BEC-related behaviors across\nvarious email modalities such as text, images, metadata and the email's\ncommunication context. This decomposition makes CAPE's verdicts naturally\nexplainable. In the paper, we describe the design principles and constraints\nbehind its architecture, as well as the challenges of model design, evaluation\nand adapting the system continuously through a Bayesian approach that combines\nlimited data with domain knowledge. Furthermore, we elaborate on several\nspecific behavioral detectors, such as those based on Transformer neural\narchitectures.",
            "author": [
                "Jan Brabec",
                "Filip \u0160rajer",
                "Radek Starosta",
                "Tom\u00e1\u0161 Sixta",
                "Marc Dupont",
                "Milo\u0161 Lenoch",
                "Ji\u0159\u00ed Men\u0161\u00edk",
                "Florian Becker",
                "Jakub Boros",
                "Tom\u00e1\u0161 Pop",
                "Pavel Nov\u00e1k"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10776v1",
                "http://arxiv.org/pdf/2308.10776v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10756v1",
            "title": "Computing Optimal Leaf Roots of Chordal Cographs in Linear Time",
            "updated": "2023-08-21T14:41:07Z",
            "published": "2023-08-21T14:41:07Z",
            "summary": "A graph G is a k-leaf power, for an integer k >= 2, if there is a tree T with\nleaf set V(G) such that, for all vertices x, y in V(G), the edge xy exists in G\nif and only if the distance between x and y in T is at most k. Such a tree T is\ncalled a k-leaf root of G. The computational problem of constructing a k-leaf\nroot for a given graph G and an integer k, if any, is motivated by the\nchallenge from computational biology to reconstruct phylogenetic trees. For\nfixed k, Lafond [SODA 2022] recently solved this problem in polynomial time.\n  In this paper, we propose to study optimal leaf roots of graphs G, that is,\nthe k-leaf roots of G with minimum k value. Thus, all k'-leaf roots of G\nsatisfy k <= k'. In terms of computational biology, seeking optimal leaf roots\nis more justified as they yield more probable phylogenetic trees. Lafond's\nresult does not imply polynomial-time computability of optimal leaf roots,\nbecause, even for optimal k-leaf roots, k may (exponentially) depend on the\nsize of G. This paper presents a linear-time construction of optimal leaf roots\nfor chordal cographs (also known as trivially perfect graphs). Additionally, it\nhighlights the importance of the parity of the parameter k and provides a\ndeeper insight into the differences between optimal k-leaf roots of even versus\nodd k.\n  Keywords: k-leaf power, k-leaf root, optimal k-leaf root, trivially perfect\nleaf power, chordal cograph",
            "author": [
                "Van Bang Le",
                "Christian Rosenke"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10756v1",
                "http://arxiv.org/pdf/2308.10756v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C85",
                "F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10752v1",
            "title": "Comprehensive Molecular Representation from Equivariant Transformer",
            "updated": "2023-08-21T14:39:29Z",
            "published": "2023-08-21T14:39:29Z",
            "summary": "We implement an equivariant transformer that embeds molecular net charge and\nspin state without additional neural network parameters. The model trained on a\nsinglet/triplet non-correlated \\ce{CH2} dataset can identify different spin\nstates and shows state-of-the-art extrapolation capability. We found that\nSoftmax activation function utilised in the self-attention mechanism of graph\nnetworks outperformed ReLU-like functions in prediction accuracy. Additionally,\nincreasing the attention temperature from $\\tau = \\sqrt{d}$ to $\\sqrt{2d}$\nfurther improved the extrapolation capability. We also purposed a weight\ninitialisation method that sensibly accelerated the training process.",
            "author": [
                "Nianze Tao",
                "Hiromi Morimoto",
                "Stefano Leoni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10752v1",
                "http://arxiv.org/pdf/2308.10752v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.mtrl-sci",
                "physics.atm-clus",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10923v1",
            "title": "Eigenvalue Interlacing of Bipartite Graphs and Construction of Expander\n  Code using Vertex-split of a Bipartite Graph",
            "updated": "2023-08-21T14:10:58Z",
            "published": "2023-08-21T14:10:58Z",
            "summary": "The second largest eigenvalue of a graph is an important algebraic parameter\nwhich is related with the expansion, connectivity and randomness properties of\na graph. Expanders are highly connected sparse graphs. In coding theory,\nExpander codes are Error Correcting codes made up of bipartite expander graphs.\nIn this paper, first we prove the interlacing of the eigenvalues of the\nadjacency matrix of the bipartite graph with the eigenvalues of the bipartite\nquotient matrices of the corresponding graph matrices. Then we obtain bounds\nfor the second largest and second smallest eigenvalues. Since the graph is\nbipartite, the results for Laplacian will also hold for Signless Laplacian\nmatrix. We then introduce a new method called vertex-split of a bipartite graph\nto construct asymptotically good expander codes with expansion factor\n$\\frac{D}{2}<\\alpha < D$ and $\\epsilon<\\frac{1}{2}$ and prove a condition for\nthe vertex-split of a bipartite graph to be $k-$connected with respect to\n$\\lambda_{2}.$ Further, we prove that the vertex-split of $G$ is a bipartite\nexpander. Finally, we construct an asymptotically good expander code whose\nfactor graph is a graph obtained by the vertex-split of a bipartite graph.",
            "author": [
                "Machasri Manickam",
                "Kalyani Desikan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10923v1",
                "http://arxiv.org/pdf/2308.10923v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C40, 05C48, 05C50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10737v1",
            "title": "UGSL: A Unified Framework for Benchmarking Graph Structure Learning",
            "updated": "2023-08-21T14:05:21Z",
            "published": "2023-08-21T14:05:21Z",
            "summary": "Graph neural networks (GNNs) demonstrate outstanding performance in a broad\nrange of applications. While the majority of GNN applications assume that a\ngraph structure is given, some recent methods substantially expanded the\napplicability of GNNs by showing that they may be effective even when no graph\nstructure is explicitly provided. The GNN parameters and a graph structure are\njointly learned. Previous studies adopt different experimentation setups,\nmaking it difficult to compare their merits. In this paper, we propose a\nbenchmarking strategy for graph structure learning using a unified framework.\nOur framework, called Unified Graph Structure Learning (UGSL), reformulates\nexisting models into a single model. We implement a wide range of existing\nmodels in our framework and conduct extensive analyses of the effectiveness of\ndifferent components in the framework. Our results provide a clear and concise\nunderstanding of the different methods in this area as well as their strengths\nand weaknesses. The benchmark code is available at\nhttps://github.com/google-research/google-research/tree/master/ugsl.",
            "author": [
                "Bahare Fatemi",
                "Sami Abu-El-Haija",
                "Anton Tsitsulin",
                "Mehran Kazemi",
                "Dustin Zelle",
                "Neslihan Bulut",
                "Jonathan Halcrow",
                "Bryan Perozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10737v1",
                "http://arxiv.org/pdf/2308.10737v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10735v1",
            "title": "Different Types of Isomorphisms of Drawings of Complete Multipartite\n  Graphs",
            "updated": "2023-08-21T14:01:07Z",
            "published": "2023-08-21T14:01:07Z",
            "summary": "Simple drawings are drawings of graphs in which any two edges intersect at\nmost once (either at a common endpoint or a proper crossing), and no edge\nintersects itself. We analyze several characteristics of simple drawings of\ncomplete multipartite graphs: which pairs of edges cross, in which order they\ncross, and the cyclic order around vertices and crossings, respectively. We\nconsider all possible combinations of how two drawings can share some\ncharacteristics and determine which other characteristics they imply and which\nthey do not imply. Our main results are that for simple drawings of complete\nmultipartite graphs, the orders in which edges cross determine all other\nconsidered characteristics. Further, if all partition classes have at least\nthree vertices, then the pairs of edges that cross determine the rotation\nsystem and the rotation around the crossings determine the extended rotation\nsystem. We also show that most other implications -- including the ones that\nhold for complete graphs -- do not hold for complete multipartite graphs. Using\nthis analysis, we establish which types of isomorphisms are meaningful for\nsimple drawings of complete multipartite graphs.",
            "author": [
                "Oswin Aichholzer",
                "Birgit Vogtenhuber",
                "Alexandra Weinberger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10735v1",
                "http://arxiv.org/pdf/2308.10735v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10725v1",
            "title": "Some applications of linear algebraic methods in combinatorics",
            "updated": "2023-08-21T13:47:50Z",
            "published": "2023-08-21T13:47:50Z",
            "summary": "In this note, we intend to produce all latin squares from one of them using\nsuitable move which is defined by small trades and do the similar work on\n4-cycle systems. These problems, reformulate as finding basis for the kernel of\nspecial matrices, representef to some graphs.",
            "author": [
                "Maryam Khosravi",
                "Ebadollah S. Mahmoodian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10725v1",
                "http://arxiv.org/pdf/2308.10725v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05B30, 15A03"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10719v1",
            "title": "Ground or Excited State: a State-Specific Variational Quantum\n  Eigensolver for Them All",
            "updated": "2023-08-21T13:39:58Z",
            "published": "2023-08-21T13:39:58Z",
            "summary": "Variational Quantum Eigensolver (VQE) provides a lucrative platform to\ndetermine molecular energetics in near-term quantum devices. While the VQE is\ntraditionally tailored to determine the ground state wavefunction with the\nunderlying Rayleigh-Ritz principle, the access to specific symmetry-adapted\nexcited states remains elusive. This often requires high depth circuit or\nadditional ancilla qubits along with prior knowledge of the ground state\nwavefunction. We propose a unified VQE framework that treats the ground and\nexcited states in the same footings. With the knowledge of the irreducible\nrepresentations of the spinorbitals, we construct a multi-determinantal\nreference that is adapted to a given spatial symmetry where additionally, the\ndeterminants are entangled through appropriate Clebsch-Gordan coefficients to\nensure the desired spin-multiplicity. We introduce the notion of totally\nsymmetric, spin-scalar unitary which maintains the purity of the reference at\neach step of the optimization. The state-selectivity safeguards the method\nagainst any variational collapse while leading to any targeted low-lying\neigenroot of arbitrary symmetry. The direct access to the excited states\nshields our approach from the cumulative error that plagues excited state\ncalculations in a quantum computer and with few parameter count, it is expected\nto be realized in near-term quantum devices.",
            "author": [
                "Dibyendu Mondal",
                "Rahul Maitra"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10719v1",
                "http://arxiv.org/pdf/2308.10719v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10700v1",
            "title": "Global assessment of university research comprehensiveness",
            "updated": "2023-08-21T13:09:59Z",
            "published": "2023-08-21T13:09:59Z",
            "summary": "The demand for global university league tables has been high over the past\ntwo decades. However, significant criticism of their methodologies is\naccumulating without being addressed. I revisit global university league tables\nby normalizing each field as to create a uniform distribution of value. Then,\nthe overall performance of an institution is interpreted as the probability of\nhaving a high score in any given academic field. I focus on the similarity of\ninstitutions across ten criteria related to academic performance in eighty\nsubjects of all fields of knowledge. The latter does not induce a zero-sum\ngame, removing one of the most prominent negative features of established\nleague tables. The present assessment shows that the main difference between\nhundreds of leading global research universities is whether their coverage of\nall areas of human knowledge is comprehensive or specialized, as their mean\nperformance per subject is nearly indistinguishable. I compare the results with\nthe main league tables and found excellent agreement, suggesting that\nregardless of their methodologies, research-intensive institutions perform well\nin rankings if they are comprehensive. This comprehensiveness is ultimately\ndependent on institutional age, privileged funding allocation and regional\nacademic culture. Consequently, when the size of an institution is taken out of\nthe picture, I found no correlation between comprehensiveness and quality, and\nno difference can be found in the mean quality of institutions regionally or\nglobally. Furthermore, I find the reputation and prestige of several famous\ninstitutions to far exceed their performance within the present methodology,\nwhile numerous institutions with less reputation and visibility perform better\nthan expected.",
            "author": [
                "Saulo Mendes"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10700v1",
                "http://arxiv.org/pdf/2308.10700v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10698v1",
            "title": "High-Order Numerical Integration on Domains Bounded by Intersecting\n  Level Sets",
            "updated": "2023-08-21T13:07:03Z",
            "published": "2023-08-21T13:07:03Z",
            "summary": "We present a high-order method that provides numerical integration on\nvolumes, surfaces, and lines defined implicitly by two smooth intersecting\nlevel sets. To approximate the integrals, the method maps quadrature rules\ndefined on hypercubes to the curved domains of the integrals. This enables the\nnumerical integration of a wide range of integrands since integration on\nhypercubes is a well known problem. The mappings are constructed by treating\nthe isocontours of the level sets as graphs of height functions. Numerical\nexperiments with smooth integrands indicate a high-order of convergence for\ntransformed Gauss quadrature rules on domains defined by polynomial, rational,\nand trigonometric level sets. We show that the approach we have used can be\ncombined readily with adaptive quadrature methods. Moreover, we apply the\napproach to numerically integrate on difficult geometries without requiring a\nlow-order fallback method.",
            "author": [
                "Lauritz Beck",
                "Florian Kummer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10698v1",
                "http://arxiv.org/pdf/2308.10698v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10920v1",
            "title": "Addressing Knowledge Leakage Risk caused by the use of mobile devices in\n  Australian Organizations",
            "updated": "2023-08-21T13:03:26Z",
            "published": "2023-08-21T13:03:26Z",
            "summary": "Information and knowledge leakage has become a significant security risk to\nAustralian organizations. Each security incident in Australian business cost an\naverage US$\\$$2.8 million. Furthermore, Australian organisations spend the\nsecond most worldwide (US$\\$$1.2 million each on average) on investigating and\nassessing information breaches. The leakage of sensitive organizational\ninformation occurs through different avenues, such as social media, cloud\ncomputing and mobile devices. In this study, we (1) analyze the knowledge\nleakage risk (KLR) caused by the use of mobile devices in knowledge-intensive\nAustralian organizations, (2) present a conceptual research model to explain\nthe determinants that influence KLR through the use of mobile devices grounded\nin the literature, (3) conduct interviews with security and knowledge managers\nto understand what strategies they use to mitigate KLR caused by the use of\nmobile devices and (4) use content analysis and the conceptual model to frame\nthe preliminary findings from the interviews. Keywords: Knowledge leakage,\nmobile devices, mobile contexts, knowledge leakage risk",
            "author": [
                "Carlos Andres Agudelo Serna",
                "Rachelle Bosua",
                "Sean B. Maynard",
                "Atif Ahmad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10920v1",
                "http://arxiv.org/pdf/2308.10920v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10689v1",
            "title": "Towards a knowledge leakage Mitigation framework for mobile Devices in\n  knowledge-intensive Organizations",
            "updated": "2023-08-21T12:54:46Z",
            "published": "2023-08-21T12:54:46Z",
            "summary": "The use of mobile devices in knowledge-intensive organizations while\neffective and cost-efficient also pose a challenging management problem. Often\nemployees whether deliberately or inadvertently are the cause of knowledge\nleakage in organizations and the use of mobile devices further exacerbates it.\nThis problem is the result of overly focusing on technical controls while\nneglecting human factors. Knowledge leakage is a multidimensional problem, and\nin this paper, we highlight the different dimensions that constitute it. In\nthis study, our contributions are threefold. First, we study knowledge leakage\nrisk (KLR) within the context of mobile devices in knowledge-intensive\norganizations in Australia. Second, we present a conceptual framework to\nexplain and categorize the mitigation strategies to combat KLR through the use\nof mobile devices grounded in the literature. And third, we apply the framework\nto the findings from interviews with security and knowledge managers. Keywords:\nKnowledge Leakage, Knowledge Risk, Knowledge intensive, Mobile device.",
            "author": [
                "Carlos Andres Agudelo Serna",
                "Rachelle Bosua",
                "Atif Ahmad",
                "Sean B. Maynard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10689v1",
                "http://arxiv.org/pdf/2308.10689v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10685v2",
            "title": "Contrastive Graph Prompt-tuning for Cross-domain Recommendation",
            "updated": "2023-11-03T10:01:43Z",
            "published": "2023-08-21T12:38:53Z",
            "summary": "Recommender systems are frequently challenged by the data sparsity problem.\nOne approach to mitigate this issue is through cross-domain recommendation\ntechniques. In a cross-domain context, sharing knowledge between domains can\nenhance the effectiveness in the target domain. Recent cross-domain methods\nhave employed a pre-training approach, but we argue that these methods often\nresult in suboptimal fine-tuning, especially with large neural models. Modern\nlanguage models utilize prompts for efficient model tuning. Such prompts act as\na tunable latent vector, allowing for the freezing of the main model\nparameters. In our research, we introduce the Personalised Graph Prompt-based\nRecommendation (PGPRec) framework. This leverages the advantages of\nprompt-tuning. Within this framework, we formulate personalized graph prompts\nitem-wise, rooted in items that a user has previously engaged with.\nSpecifically, we employ Contrastive Learning (CL) to produce pre-trained\nembeddings that offer greater generalizability in the pre-training phase,\nensuring robust training during the tuning phase. Our evaluation of PGPRec in\ncross-domain scenarios involves comprehensive testing with the top-k\nrecommendation tasks and a cold-start analysis. Our empirical findings, based\non four Amazon Review datasets, reveal that the PGPRec framework can decrease\nthe tuned parameters by as much as 74%, maintaining competitive performance.\nRemarkably, there's an 11.41% enhancement in performance against the leading\nbaseline in cold-start situations.",
            "author": [
                "Zixuan Yi",
                "Iadh Ounis",
                "Craig Macdonald"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10685v2",
                "http://arxiv.org/pdf/2308.10685v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10675v1",
            "title": "An Improved Best-of-both-worlds Algorithm for Bandits with Delayed\n  Feedback",
            "updated": "2023-08-21T12:17:40Z",
            "published": "2023-08-21T12:17:40Z",
            "summary": "We propose a new best-of-both-worlds algorithm for bandits with variably\ndelayed feedback. The algorithm improves on prior work by Masoudian et al.\n[2022] by eliminating the need in prior knowledge of the maximal delay\n$d_{\\mathrm{max}}$ and providing tighter regret bounds in both regimes. The\nalgorithm and its regret bounds are based on counts of outstanding observations\n(a quantity that is observed at action time) rather than delays or the maximal\ndelay (quantities that are only observed when feedback arrives). One major\ncontribution is a novel control of distribution drift, which is based on biased\nloss estimators and skipping of observations with excessively large delays.\nAnother major contribution is demonstrating that the complexity of\nbest-of-both-worlds bandits with delayed feedback is characterized by the\ncumulative count of outstanding observations after skipping of observations\nwith excessively large delays, rather than the delays or the maximal delay.",
            "author": [
                "Saeed Masoudian",
                "Julian Zimmert",
                "Yevgeny Seldin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10675v1",
                "http://arxiv.org/pdf/2308.10675v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10666v2",
            "title": "Degenerate crossing number and signed reversal distance",
            "updated": "2023-08-22T10:19:50Z",
            "published": "2023-08-21T12:03:20Z",
            "summary": "The degenerate crossing number of a graph is the minimum number of transverse\ncrossings among all its drawings, where edges are represented as simple arcs\nand multiple edges passing through the same point are counted as a single\ncrossing. Interpreting each crossing as a cross-cap induces an embedding into a\nnon-orientable surface. In 2007, Mohar showed that the degenerate crossing\nnumber of a graph is at most its non-orientable genus and he conjectured that\nthese quantities are equal for every graph. He also made the stronger\nconjecture that this also holds for any loopless pseudotriangulation with a\nfixed embedding scheme.\n  In this paper, we prove a structure theorem that almost completely classifies\nthe loopless 2-vertex embedding schemes for which the degenerate crossing\nnumber equals the non-orientable genus. In particular, we provide a\ncounterexample to Mohar's stronger conjecture, but show that in the vast\nmajority of the 2-vertex cases, the conjecture does hold.\n  The reversal distance between two signed permutations is the minimum number\nof reversals that transform one permutation to the other one. If we represent\nthe trajectory of each element of a signed permutation under successive\nreversals by a simple arc, we obtain a drawing of a 2-vertex embedding scheme\nwith degenerate crossings. Our main result is proved by leveraging this\nconnection and a classical result in genome rearrangement (the\nHannenhali-Pevzner algorithm) and can also be understood as an extension of\nthis algorithm when the reversals do not necessarily happen in a monotone\norder.",
            "author": [
                "Niloufar Fuladi",
                "Alfredo Hubard",
                "Arnaud de Mesmay"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10666v2",
                "http://arxiv.org/pdf/2308.10666v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10661v1",
            "title": "On the super edge-magicness of graphs with a specific degree sequence",
            "updated": "2023-08-21T11:55:28Z",
            "published": "2023-08-21T11:55:28Z",
            "summary": "A graph $G$ is said to be super edge-magic if there exists a bijective\nfunction $f:V\\left(G\\right) \\cup E\\left(G\\right)\\rightarrow \\left\\{1, 2, \\ldots\n, \\left\\vert V\\left( G\\right) \\right\\vert +\\left\\vert E\\left( G\\right)\n\\right\\vert \\right\\}$ such that $f\\left(V \\left(G\\right)\\right) =\\left\\{1, 2,\n\\ldots , \\left\\vert V\\left( G\\right) \\right\\vert \\right\\}$ and $f\\left(u\\right)\n+ f\\left(v\\right) + f\\left(uv\\right)$ is a constant for each $uv\\in E\\left(\nG\\right) $. In this paper, we study the super edge-magicness of graphs of order\n$n$ with degree sequence $s:4, 2, 2, \\ldots, 2$. We also investigate the super\nedge-magic properties of certain families of graphs. This leads us to propose\nsome open problems.",
            "author": [
                "Rikio Ichishima",
                "Francesc A. Muntaner-Batle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10661v1",
                "http://arxiv.org/pdf/2308.10661v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10657v1",
            "title": "Parameterized Complexity of Fair Bisection: FPT-Approximation meets\n  Unbreakability",
            "updated": "2023-08-21T11:49:56Z",
            "published": "2023-08-21T11:49:56Z",
            "summary": "In the Minimum Bisection problem, input is a graph $G$ and the goal is to\npartition the vertex set into two parts $A$ and $B$, such that $||A|-|B|| \\le\n1$ and the number $k$ of edges between $A$ and $B$ is minimized. This problem\ncan be viewed as a clustering problem where edges represent similarity, and the\ntask is to partition the vertices into two equally sized clusters, while\nminimizing the number of pairs of similar objects that end up in different\nclusters. In this paper, we initiate the study of a fair version of Minimum\nBisection. In this problem, the vertices of the graph are colored using one of\n$c \\ge 1$ colors. The goal is to find a bisection $(A, B)$ with at most $k$\nedges between the parts, such that for each color $i\\in [c]$, $A$ has exactly\n$r_i$ vertices of color $i$.\n  We first show that Fair Bisection is $W$[1]-hard parameterized by $c$ even\nwhen $k = 0$. On the other hand, our main technical contribution shows that is\nthat this hardness result is simply a consequence of the very strict\nrequirement that each color class $i$ has {\\em exactly} $r_i$ vertices in $A$.\nIn particular, we give an $f(k,c,\\epsilon)n^{O(1)}$ time algorithm that finds a\nbalanced partition $(A, B)$ with at most $k$ edges between them, such that for\neach color $i\\in [c]$, there are at most $(1\\pm \\epsilon)r_i$ vertices of color\n$i$ in $A$. Our approximation algorithm is best viewed as a proof of concept\nthat the technique introduced by [Lampis, ICALP '18] for obtaining\nFPT-approximation algorithms for problems of bounded tree-width or clique-width\ncan be efficiently exploited even on graphs of unbounded width. The key insight\nis that the technique of Lampis is applicable on tree decompositions with\nunbreakable bags (as introduced in [Cygan et al., SIAM Journal on Computing\n'14]). Along the way, we also derive a combinatorial result regarding tree\ndecompositions of graphs.",
            "author": [
                "Tanmay Inamdar",
                "Daniel Lokshtanov",
                "Saket Saurabh",
                "Vaishali Surianarayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10657v1",
                "http://arxiv.org/pdf/2308.10657v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12337v1",
            "title": "ActiveAI: Introducing AI Literacy for Middle School Learners with\n  Goal-based Scenario Learning",
            "updated": "2023-08-21T11:43:43Z",
            "published": "2023-08-21T11:43:43Z",
            "summary": "The ActiveAI project addresses key challenges in AI education for grades 7-9\nstudents by providing an engaging AI literacy learning experience based on the\nAI4K12 knowledge framework. Utilizing learning science mechanisms such as\ngoal-based scenarios, immediate feedback, project-based learning, and\nintelligent agents, the app incorporates a variety of learner inputs like\nsliders, steppers, and collectors to enhance understanding. In these courses,\nstudents work on real-world scenarios like analyzing sentiment in social media\ncomments. This helps them learn to effectively engage with AI systems and\ndevelop their ability to evaluate AI-generated output. The Learning Engineering\nProcess (LEP) guided the project's creation and data instrumentation, focusing\non design and impact. The project is currently in the implementation stage,\nleveraging the intelligent tutor design principles for app development. The\nextended abstract presents the foundational design and development, with\nfurther evaluation and research to be conducted in the future.",
            "author": [
                "Ying Jui Tseng",
                "Gautam Yadav"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12337v1",
                "http://arxiv.org/pdf/2309.12337v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10633v2",
            "title": "RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented\n  Large Language Models",
            "updated": "2023-10-16T09:41:13Z",
            "published": "2023-08-21T11:08:16Z",
            "summary": "Retrieval-augmented large language models (R-LLMs) combine pre-trained large\nlanguage models (LLMs) with information retrieval systems to improve the\naccuracy of factual question-answering. However, current libraries for building\nR-LLMs provide high-level abstractions without sufficient transparency for\nevaluating and optimizing prompts within specific inference processes such as\nretrieval and generation. To address this gap, we present RaLLe, an open-source\nframework designed to facilitate the development, evaluation, and optimization\nof R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily\ndevelop and evaluate R-LLMs, improving hand-crafted prompts, assessing\nindividual inference processes, and objectively measuring overall system\nperformance quantitatively. By leveraging these features, developers can\nenhance the performance and accuracy of their R-LLMs in knowledge-intensive\ngeneration tasks. We open-source our code at https://github.com/yhoshi3/RaLLe.",
            "author": [
                "Yasuto Hoshi",
                "Daisuke Miyashita",
                "Youyang Ng",
                "Kento Tatsuno",
                "Yasuhiro Morioka",
                "Osamu Torii",
                "Jun Deguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10633v2",
                "http://arxiv.org/pdf/2308.10633v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10617v1",
            "title": "Optical Properties of Metal-poor T Dwarf Candidates",
            "updated": "2023-08-21T10:31:30Z",
            "published": "2023-08-21T10:31:30Z",
            "summary": "Context. Metal-poor brown dwarfs are poorly understood because they are\nextremely faint and rare. Only a few candidates have been identified as T-type\nsubdwarfs in infrared surveys and their optical properties remain\nunconstrained.\n  Aims. We aim to improve the knowledge of the optical properties of T subdwarf\ncandidates to break the degeneracy between metallicity and temperature and to\ninvestigate their atmospheric properties.\n  Methods. Deep $z$-band images of 10 known T subdwarf candidates were\ncollected with the 10.4-m Gran Telescopio Canarias. Low-resolution optical\nspectra for two of them were obtained with the same telescope. Photometric\nmeasurements of the $z$-band flux were performed for all the targets and they\nwere combined with infrared photometry in $J, H, K, W1$ and $W2$-bands from the\nliterature to obtain the colours. The spectra were compared with\nsolar-metallicity T dwarf templates and with laboratory spectra.\n  Results. We found that the targets segregate into three distinct groups in\nthe $W1 - W2$ vs. $z - W1$ colour-colour diagram. Group I objects are mixed\nwith solar-metallicity T dwarfs. Group III objects have $W1 - W2$ colours\nsimilar to T dwarfs but very red $z - W1$ colours. Group II objects lie between\nGroup I and III. The two targets for which we obtained spectra are located in\nGroup I and their spectroscopic properties resemble normal T dwarfs but with\nwater features that are deeper and have a shape akin to pure water.\n  Conclusions. We conclude that the $W1 - W2$ vs. $z - W1$ colour-colour\ndiagram is excellent to break the metallicity-temperature degeneracy for\nobjects cooler than L-type. A revision of the spectral classification of T\nsubdwarf might be needed in the future, according to the photometric and\nspectroscopic properties of WISE1810 and WISE0414 in Group III discussed in\nthis work.",
            "author": [
                "Jerry Jun-Yan Zhang",
                "Nicolas Lodieu",
                "Eduardo Mart\u00edn"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202346923",
                "http://arxiv.org/abs/2308.10617v1",
                "http://arxiv.org/pdf/2308.10617v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10611v1",
            "title": "Superconducting Quantum Circuits in the light of Dirac's Constraint\n  Analysis Framework",
            "updated": "2023-08-21T10:22:36Z",
            "published": "2023-08-21T10:22:36Z",
            "summary": "In this work we introduce a new framework - Dirac's Hamiltonian formalism of\nconstraint systems - to study different types of Superconducting Quantum\nCircuits (SQC) in a {\\it{unified}} and unambiguous way. The Lagrangian of a SQC\nreveals the constraints, that are classified in a Hamiltonian framework, such\nthat redundant variables can be removed to isolate the canonical degrees of\nfreedom for subsequent quantization of the Dirac Brackets via a generalized\nCorrespondence Principle. This purely algebraic approach makes the application\nof concepts such as graph theory, null vector, loop charge,\\ etc that are in\nvogue, (each for a specific type of circuit), completely redundant.",
            "author": [
                "Akshat Pandey",
                "Subir Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10611v1",
                "http://arxiv.org/pdf/2308.10611v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10609v1",
            "title": "ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal",
            "updated": "2023-08-21T10:18:26Z",
            "published": "2023-08-21T10:18:26Z",
            "summary": "In this paper, we introduce ST-RAP, a novel Spatio-Temporal framework for\nReal estate APpraisal. ST-RAP employs a hierarchical architecture with a\nheterogeneous graph neural network to encapsulate temporal dynamics and spatial\nrelationships simultaneously. Through comprehensive experiments on a\nlarge-scale real estate dataset, ST-RAP outperforms previous methods,\ndemonstrating the significant benefits of integrating spatial and temporal\naspects in real estate appraisal. Our code and dataset are available at\nhttps://github.com/dojeon-ai/STRAP.",
            "author": [
                "Hojoon Lee",
                "Hawon Jeong",
                "Byungkun Lee",
                "Kyungyup Lee",
                "Jaegul Choo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10609v1",
                "http://arxiv.org/pdf/2308.10609v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10606v1",
            "title": "Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian\n  Networks",
            "updated": "2023-08-21T10:06:15Z",
            "published": "2023-08-21T10:06:15Z",
            "summary": "Interacting systems of events may exhibit cascading behavior where events\ntend to be temporally clustered. While the cascades themselves may be obvious\nfrom the data, it is important to understand which states of the system trigger\nthem. For this purpose, we propose a modeling framework based on\ncontinuous-time Bayesian networks (CTBNs) to analyze cascading behavior in\ncomplex systems. This framework allows us to describe how events propagate\nthrough the system and to identify likely sentry states, that is, system states\nthat may lead to imminent cascading behavior. Moreover, CTBNs have a simple\ngraphical representation and provide interpretable outputs, both of which are\nimportant when communicating with domain experts. We also develop new methods\nfor knowledge extraction from CTBNs and we apply the proposed methodology to a\ndata set of alarms in a large industrial system.",
            "author": [
                "Alessandro Bregoli",
                "Karin Rathsman",
                "Marco Scutari",
                "Fabio Stella",
                "S\u00f8ren Wengel Mogensen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10606v1",
                "http://arxiv.org/pdf/2308.10606v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10600v2",
            "title": "Fixed-Parameter Algorithms for Computing RAC Drawings of Graphs",
            "updated": "2023-08-23T07:44:30Z",
            "published": "2023-08-21T09:56:56Z",
            "summary": "In a right-angle crossing (RAC) drawing of a graph, each edge is represented\nas a polyline and edge crossings must occur at an angle of exactly $90^\\circ$,\nwhere the number of bends on such polylines is typically restricted in some\nway. While structural and topological properties of RAC drawings have been the\nfocus of extensive research, little was known about the boundaries of\ntractability for computing such drawings. In this paper, we initiate the study\nof RAC drawings from the viewpoint of parameterized complexity. In particular,\nwe establish that computing a RAC drawing of an input graph $G$ with at most\n$b$ bends (or determining that none exists) is fixed-parameter tractable\nparameterized by either the feedback edge number of $G$, or $b$ plus the vertex\ncover number of $G$.",
            "author": [
                "Cornelius Brand",
                "Robert Ganian",
                "Sebastian R\u00f6der",
                "Florian Schager"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10600v2",
                "http://arxiv.org/pdf/2308.10600v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10576v2",
            "title": "Incorprating Prompt tuning for Commit classification with prior\n  Knowledge",
            "updated": "2023-10-26T08:23:08Z",
            "published": "2023-08-21T09:17:43Z",
            "summary": "Commit Classification(CC) is an important task in software maintenance since\nit helps software developers classify code changes into different types\naccording to their nature and purpose. This allows them to better understand\nhow their development efforts are progressing, identify areas where they need\nimprovement. However, existing methods are all discriminative models, usually\nwith complex architectures that require additional output layers to produce\nclass label probabilities. Moreover, they require a large amount of labeled\ndata for fine-tuning, and it is difficult to learn effective classification\nboundaries in the case of limited labeled data. To solve above problems, we\npropose a generative framework that Incorporating prompt-tuning for commit\nclassification with prior knowledge (IPCK)\nhttps://github.com/AppleMax1992/IPCK, which simplifies the model structure and\nlearns features across different tasks. It can still reach the SOTA performance\nwith only limited samples. Firstly, we proposed a generative framework based on\nT5. This encoder-decoder construction method unifies different CC task into a\ntext2text problem, which simplifies the structure of the model by not requiring\nan extra output layer. Second, instead of fine-tuning, we design an\nprompt-tuning solution which can be adopted in few-shot scenarios with only\nlimit samples. Furthermore, we incorporate prior knowledge via an external\nknowledge graph to map the probabilities of words into the final labels in the\nspeech machine step to improve performance in few-shot scenarios. Extensive\nexperiments on two open available datasets show that our framework can solve\nthe CC problem simply but effectively in few-shot and zeroshot scenarios, while\nimproving the adaptability of the model without requiring a large amount of\ntraining samples for fine-tuning.",
            "author": [
                "Jiajun Tong",
                "Xiaobin Rui"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10576v2",
                "http://arxiv.org/pdf/2308.10576v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10574v1",
            "title": "CHORD: Category-level Hand-held Object Reconstruction via Shape\n  Deformation",
            "updated": "2023-08-21T09:14:18Z",
            "published": "2023-08-21T09:14:18Z",
            "summary": "In daily life, humans utilize hands to manipulate objects. Modeling the shape\nof objects that are manipulated by the hand is essential for AI to comprehend\ndaily tasks and to learn manipulation skills. However, previous approaches have\nencountered difficulties in reconstructing the precise shapes of hand-held\nobjects, primarily owing to a deficiency in prior shape knowledge and\ninadequate data for training. As illustrated, given a particular type of tool,\nsuch as a mug, despite its infinite variations in shape and appearance, humans\nhave a limited number of 'effective' modes and poses for its manipulation. This\ncan be attributed to the fact that humans have mastered the shape prior of the\n'mug' category, and can quickly establish the corresponding relations between\ndifferent mug instances and the prior, such as where the rim and handle are\nlocated. In light of this, we propose a new method, CHORD, for Category-level\nHand-held Object Reconstruction via shape Deformation. CHORD deforms a\ncategorical shape prior for reconstructing the intra-class objects. To ensure\naccurate reconstruction, we empower CHORD with three types of awareness:\nappearance, shape, and interacting pose. In addition, we have constructed a new\ndataset, COMIC, of category-level hand-object interaction. COMIC contains a\nrich array of object instances, materials, hand interactions, and viewing\ndirections. Extensive evaluation shows that CHORD outperforms state-of-the-art\napproaches in both quantitative and qualitative measures. Code, model, and\ndatasets are available at https://kailinli.github.io/CHORD.",
            "author": [
                "Kailin Li",
                "Lixin Yang",
                "Haoyu Zhen",
                "Zenan Lin",
                "Xinyu Zhan",
                "Licheng Zhong",
                "Jian Xu",
                "Kejian Wu",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10574v1",
                "http://arxiv.org/pdf/2308.10574v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10569v1",
            "title": "RT-MonoDepth: Real-time Monocular Depth Estimation on Embedded Systems",
            "updated": "2023-08-21T08:59:59Z",
            "published": "2023-08-21T08:59:59Z",
            "summary": "Depth sensing is a crucial function of unmanned aerial vehicles and\nautonomous vehicles. Due to the small size and simple structure of monocular\ncameras, there has been a growing interest in depth estimation from a single\nRGB image. However, state-of-the-art monocular CNN-based depth estimation\nmethods using fairly complex deep neural networks are too slow for real-time\ninference on embedded platforms. This paper addresses the problem of real-time\ndepth estimation on embedded systems. We propose two efficient and lightweight\nencoder-decoder network architectures, RT-MonoDepth and RT-MonoDepth-S, to\nreduce computational complexity and latency. Our methodologies demonstrate that\nit is possible to achieve similar accuracy as prior state-of-the-art works on\ndepth estimation at a faster inference speed. Our proposed networks,\nRT-MonoDepth and RT-MonoDepth-S, runs at 18.4\\&30.5 FPS on NVIDIA Jetson Nano\nand 253.0\\&364.1 FPS on NVIDIA Jetson AGX Orin on a single RGB image of\nresolution 640$\\times$192, and achieve relative state-of-the-art accuracy on\nthe KITTI dataset. To the best of the authors' knowledge, this paper achieves\nthe best accuracy and fastest inference speed compared with existing fast\nmonocular depth estimation methods.",
            "author": [
                "Cheng Feng",
                "Zhen Chen",
                "Congxuan Zhang",
                "Weiming Hu",
                "Bing Li",
                "Feng Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10569v1",
                "http://arxiv.org/pdf/2308.10569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.12302v1",
            "title": "A Method for Investigating Thermodynamics of Inaccessible Objects by\n  Determining the Co-Amoeba of their Partition Functions",
            "updated": "2023-08-21T08:12:55Z",
            "published": "2023-08-21T08:12:55Z",
            "summary": "Given an Ising-type system, the zeros of its complexified partition function,\nknown as Lee--Yang zeros, form an algebraic variety that sheds light on the\nthermodynamics of that system. But in practice, we often confront with the\ninaccessibility of a system for direct experimentation and then a strategic\napproach is taken to investigate a probe that is interacting with the target\nsystem. Considering such an inaccessible system, reading the probe alone, we\npresent a method to determine the co-amoeba, the images of the argument map of\nan algebraic variety corresponding to the Lee--Yang zeros of its partition\nfunction. In our method, starting from thermal equilibrium of target and probe,\nthe target can be effectively initiated at any chosen value of its internal\nparameters by doing operations only on the probe. Thus, sampling the co-amoeba\ncorresponding to a wide of range of physical parameters is possible which\nallows one to perceive the full algebraic variety and thereby determining the\nthermodynamics of the system. No prior knowledge about the internal parameters,\nneither any control over the target system under investigation is required for\nthis protocol. Finally, we experimentally demonstrate this protocol via the\nnuclear magnetic resonance architecture using a system of three mutually\ninteracting spin-1/2 nuclei.",
            "author": [
                "Arijit Chatterjee",
                "T S Mahesh",
                "Mounir Nisse",
                "Yen-Kheng Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12302v1",
                "http://arxiv.org/pdf/2308.12302v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "math-ph",
                "math.AG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10555v3",
            "title": "Semantic Programming for Device-Edge-Cloud Continuum",
            "updated": "2023-09-17T20:07:40Z",
            "published": "2023-08-21T08:12:28Z",
            "summary": "This position paper presents ThothSP, a Semantic Programming framework with\nthe aim of lowering the coding effort in building smart applications on the\nDevice-Edge-Cloud continuum by leveraging semantic knowledge. It introduces a\nnovel neural-symbolic stream fusion mechanism, which enables the specification\nof data fusion pipelines via declarative rules, with degrees of learnable\nprobabilistic weights. Moreover, it includes an adaptive federator that allows\nthe Thoth>runtime to be distributed across multiple compute nodes in a network,\nand to coordinate their resources to collaboratively process tasks by\ndelegating partial workloads to their peers. To demonstrate ThothSP's\ncapability, we report a case study on a distributed camera network to show\nThothSP's behaviour against a traditional edge-cloud setup.",
            "author": [
                "Anh Le-Tuan",
                "David Bowden",
                "Danh Le-Phuoc"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10555v3",
                "http://arxiv.org/pdf/2308.10555v3"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10547v1",
            "title": "Decentralized Riemannian Conjugate Gradient Method on the Stiefel\n  Manifold",
            "updated": "2023-08-21T08:02:16Z",
            "published": "2023-08-21T08:02:16Z",
            "summary": "The conjugate gradient method is a crucial first-order optimization method\nthat generally converges faster than the steepest descent method, and its\ncomputational cost is much lower than the second-order methods. However, while\nvarious types of conjugate gradient methods have been studied in Euclidean\nspaces and on Riemannian manifolds, there has little study for those in\ndistributed scenarios. This paper proposes a decentralized Riemannian conjugate\ngradient descent (DRCGD) method that aims at minimizing a global function over\nthe Stiefel manifold. The optimization problem is distributed among a network\nof agents, where each agent is associated with a local function, and\ncommunication between agents occurs over an undirected connected graph. Since\nthe Stiefel manifold is a non-convex set, a global function is represented as a\nfinite sum of possibly non-convex (but smooth) local functions. The proposed\nmethod is free from expensive Riemannian geometric operations such as\nretractions, exponential maps, and vector transports, thereby reducing the\ncomputational complexity required by each agent. To the best of our knowledge,\nDRCGD is the first decentralized Riemannian conjugate gradient algorithm to\nachieve global convergence over the Stiefel manifold.",
            "author": [
                "Jun Chen",
                "Haishan Ye",
                "Mengmeng Wang",
                "Tianxin Huang",
                "Guang Dai",
                "Ivor W. Tsang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10547v1",
                "http://arxiv.org/pdf/2308.10547v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10546v1",
            "title": "Ramsey numbers of color critical graphs versus large generalized fans",
            "updated": "2023-08-21T08:01:32Z",
            "published": "2023-08-21T08:01:32Z",
            "summary": "Given two graphs $G$ and $H$, the {Ramsey number} $R(G,H)$ is the smallest\npositive integer $N$ such that every 2-coloring of the edges of $K_{N}$\ncontains either a red $G$ or a blue $H$. Let $K_{N-1}\\sqcup K_{1,k}$ be the\ngraph obtained from $K_{N-1}$ by adding a new vertex $v$ connecting $k$\nvertices of $K_{N-1}$. Hook and Isaak (2011) defined the {\\em star-critical\nRamsey number} $r_{*}(G,H)$ as the smallest integer $k$ such that every\n2-coloring of the edges of $K_{N-1}\\sqcup K_{1,k}$ contains either a red $G$ or\na blue $H$, where $N=R(G, H)$. For sufficiently large $n$, Li and\nRousseau~(1996) proved that $R(K_{k+1},K_{1}+nK_{t})=knt +1$, Hao, Lin~(2018)\nshowed that $r_{*}(K_{k+1},K_{1}+nK_{t})=(k-1)tn+t$;\n  Li and Liu~(2016) proved that $R(C_{2k+1}, K_{1}+nK_{t})=2nt+1$, and Li, Li,\nand Wang~(2020) showed that $r_{*}(C_{2m+1},K_{1}+nK_{t})=nt+t$. A graph $G$\nwith $\\chi(G)=k+1$ is called edge-critical if $G$ contains an edge $e$ such\nthat $\\chi(G-e)=k$. In this paper, we extend the above results by showing that\nfor an edge-critical graph $G$ with $\\chi(G)=k+1$, when $k\\geq 2$, $t\\geq 2$\nand $n$ is sufficiently large, $R(G, K_{1}+nK_{t})=knt+1$ and\n$r_{*}(G,K_{1}+nK_{t})=(k-1)nt+t$.",
            "author": [
                "Taiping Jiang",
                "Xinmin Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10546v1",
                "http://arxiv.org/pdf/2308.10546v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10541v2",
            "title": "Monotone Symplectic Six-Manifolds that admit a Hamiltonian GKM Action\n  are diffeomorphic to Smooth Fano Threefolds",
            "updated": "2023-09-20T06:37:10Z",
            "published": "2023-08-21T07:47:20Z",
            "summary": "Let $(M,\\omega)$ be a compact symplectic manifold with a Hamiltonian GKM\naction of a compact torus. We formulate a positive condition on the space; this\ncondition is satisfied if the underlying symplectic manifold is monotone. The\nmain result of this article is that the underlying manifold of a positive\nHamiltonian GKM space of dimension six is diffeomorphic to a smooth Fano\nthreefold. We prove the main result in two steps. In the first step, we deduce\nfrom results of Goertsches, Konstantis, and Zoller that if the complexity of\nthe action is zero or one then the equivariant and the ordinary cohomology with\ninteger coefficients are determined by the GKM graph. This result, in\ncombination with a classification result by Jupp, Wall and Zubr for certain\nsix-manifolds, implies that the diffeomorphism type of a compact symplectic\nsix-manifold with a Hamiltonian GKM action is determined by the associated GKM\ngraph. In the second step, based on results by Godinho and Sabatini, we compute\nthe complete list of the GKM graphs of positive Hamiltonian GKM spaces of\ndimension six. We deduce that any such GKM graph is isomorphic to a GKM graph\nof a smooth Fano threefold.",
            "author": [
                "Isabelle Charton",
                "Liat Kessler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10541v2",
                "http://arxiv.org/pdf/2308.10541v2"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "53D05, 57M60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10537v1",
            "title": "KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks",
            "updated": "2023-08-21T07:43:10Z",
            "published": "2023-08-21T07:43:10Z",
            "summary": "In recent years, countless research papers have addressed the topics of\nknowledge graph creation, extension, or completion in order to create knowledge\ngraphs that are larger, more correct, or more diverse. This research is\ntypically motivated by the argumentation that using such enhanced knowledge\ngraphs to solve downstream tasks will improve performance. Nonetheless, this is\nhardly ever evaluated. Instead, the predominant evaluation metrics - aiming at\ncorrectness and completeness - are undoubtedly valuable but fail to capture the\ncomplete picture, i.e., how useful the created or enhanced knowledge graph\nactually is. Further, the accessibility of such a knowledge graph is rarely\nconsidered (e.g., whether it contains expressive labels, descriptions, and\nsufficient context information to link textual mentions to the entities of the\nknowledge graph). To better judge how well knowledge graphs perform on actual\ntasks, we present KGrEaT - a framework to estimate the quality of knowledge\ngraphs via actual downstream tasks like classification, clustering, or\nrecommendation. Instead of comparing different methods of processing knowledge\ngraphs with respect to a single task, the purpose of KGrEaT is to compare\nvarious knowledge graphs as such by evaluating them on a fixed task setup. The\nframework takes a knowledge graph as input, automatically maps it to the\ndatasets to be evaluated on, and computes performance metrics for the defined\ntasks. It is built in a modular way to be easily extendable with additional\ntasks and datasets.",
            "author": [
                "Nicolas Heist",
                "Sven Hertling",
                "Heiko Paulheim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10537v1",
                "http://arxiv.org/pdf/2308.10537v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10526v1",
            "title": "UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with\n  Action Understanding and Feedback in Natural Language",
            "updated": "2023-08-21T07:26:05Z",
            "published": "2023-08-21T07:26:05Z",
            "summary": "We introduce UbiPhysio, a milestone framework that delivers fine-grained\naction description and feedback in natural language to support people's daily\nfunctioning, fitness, and rehabilitation activities. This expert-like\ncapability assists users in properly executing actions and maintaining\nengagement in remote fitness and rehabilitation programs. Specifically, the\nproposed UbiPhysio framework comprises a fine-grained action descriptor and a\nknowledge retrieval-enhanced feedback module. The action descriptor translates\naction data, represented by a set of biomechanical movement features we\ndesigned based on clinical priors, into textual descriptions of action types\nand potential movement patterns. Building on physiotherapeutic domain\nknowledge, the feedback module provides clear and engaging expert feedback. We\nevaluated UbiPhysio's performance through extensive experiments with data from\n104 diverse participants, collected in a home-like setting during 25 types of\neveryday activities and exercises. We assessed the quality of the language\noutput under different tuning strategies using standard benchmarks. We\nconducted a user study to gather insights from clinical experts and potential\nusers on our framework. Our initial tests show promise for deploying UbiPhysio\nin real-life settings without specialized devices.",
            "author": [
                "Chongyang Wang",
                "Yuan Feng",
                "Lingxiao Zhong",
                "Siyi Zhu",
                "Chi Zhang",
                "Siqi Zheng",
                "Chen Liang",
                "Yuntao Wang",
                "Chengqi He",
                "Chun Yu",
                "Yuanchun Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10526v1",
                "http://arxiv.org/pdf/2308.10526v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10524v1",
            "title": "Dataset Quantization",
            "updated": "2023-08-21T07:24:29Z",
            "published": "2023-08-21T07:24:29Z",
            "summary": "State-of-the-art deep neural networks are trained with large amounts\n(millions or even billions) of data. The expensive computation and memory costs\nmake it difficult to train them on limited hardware resources, especially for\nrecent popular large language models (LLM) and computer vision models (CV).\nRecent popular dataset distillation methods are thus developed, aiming to\nreduce the number of training samples via synthesizing small-scale datasets via\ngradient matching. However, as the gradient calculation is coupled with the\nspecific network architecture, the synthesized dataset is biased and performs\npoorly when used for training unseen architectures. To address these\nlimitations, we present dataset quantization (DQ), a new framework to compress\nlarge-scale datasets into small subsets which can be used for training any\nneural network architectures. Extensive experiments demonstrate that DQ is able\nto generate condensed small datasets for training unseen network architectures\nwith state-of-the-art compression ratios for lossless model training. To the\nbest of our knowledge, DQ is the first method that can successfully distill\nlarge-scale datasets such as ImageNet-1k with a state-of-the-art compression\nratio. Notably, with 60% data from ImageNet and 20% data from Alpaca's\ninstruction tuning data, the models can be trained with negligible or no\nperformance drop for both vision tasks (including classification, semantic\nsegmentation, and object detection) as well as language tasks (including\ninstruction tuning tasks such as BBH and DROP).",
            "author": [
                "Daquan Zhou",
                "Kai Wang",
                "Jianyang Gu",
                "Xiangyu Peng",
                "Dongze Lian",
                "Yifan Zhang",
                "Yang You",
                "Jiashi Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10524v1",
                "http://arxiv.org/pdf/2308.10524v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10521v1",
            "title": "PHE-SICH-CT-IDS: A Benchmark CT Image Dataset for Evaluation Semantic\n  Segmentation, Object Detection and Radiomic Feature Extraction of\n  Perihematomal Edema in Spontaneous Intracerebral Hemorrhage",
            "updated": "2023-08-21T07:18:51Z",
            "published": "2023-08-21T07:18:51Z",
            "summary": "Intracerebral hemorrhage is one of the diseases with the highest mortality\nand poorest prognosis worldwide. Spontaneous intracerebral hemorrhage (SICH)\ntypically presents acutely, prompt and expedited radiological examination is\ncrucial for diagnosis, localization, and quantification of the hemorrhage.\nEarly detection and accurate segmentation of perihematomal edema (PHE) play a\ncritical role in guiding appropriate clinical intervention and enhancing\npatient prognosis. However, the progress and assessment of computer-aided\ndiagnostic methods for PHE segmentation and detection face challenges due to\nthe scarcity of publicly accessible brain CT image datasets. This study\nestablishes a publicly available CT dataset named PHE-SICH-CT-IDS for\nperihematomal edema in spontaneous intracerebral hemorrhage. The dataset\ncomprises 120 brain CT scans and 7,022 CT images, along with corresponding\nmedical information of the patients. To demonstrate its effectiveness,\nclassical algorithms for semantic segmentation, object detection, and radiomic\nfeature extraction are evaluated. The experimental results confirm the\nsuitability of PHE-SICH-CT-IDS for assessing the performance of segmentation,\ndetection and radiomic feature extraction methods. To the best of our\nknowledge, this is the first publicly available dataset for PHE in SICH,\ncomprising various data formats suitable for applications across diverse\nmedical scenarios. We believe that PHE-SICH-CT-IDS will allure researchers to\nexplore novel algorithms, providing valuable support for clinicians and\npatients in the clinical setting. PHE-SICH-CT-IDS is freely published for\nnon-commercial purpose at:\nhttps://figshare.com/articles/dataset/PHE-SICH-CT-IDS/23957937.",
            "author": [
                "Deguo Ma",
                "Chen Li",
                "Lin Qiao",
                "Tianming Du",
                "Dechao Tang",
                "Zhiyu Ma",
                "Marcin Grzegorzek Hongzan",
                "Hongzan Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10521v1",
                "http://arxiv.org/pdf/2308.10521v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10493v1",
            "title": "Semantic Graph Representation Learning for Handwritten Mathematical\n  Expression Recognition",
            "updated": "2023-08-21T06:23:41Z",
            "published": "2023-08-21T06:23:41Z",
            "summary": "Handwritten mathematical expression recognition (HMER) has attracted\nextensive attention recently. However, current methods cannot explicitly study\nthe interactions between different symbols, which may fail when faced similar\nsymbols. To alleviate this issue, we propose a simple but efficient method to\nenhance semantic interaction learning (SIL). Specifically, we firstly construct\na semantic graph based on the statistical symbol co-occurrence probabilities.\nThen we design a semantic aware module (SAM), which projects the visual and\nclassification feature into semantic space. The cosine distance between\ndifferent projected vectors indicates the correlation between symbols. And\njointly optimizing HMER and SIL can explicitly enhances the model's\nunderstanding of symbol relationships. In addition, SAM can be easily plugged\ninto existing attention-based models for HMER and consistently bring\nimprovement. Extensive experiments on public benchmark datasets demonstrate\nthat our proposed module can effectively enhance the recognition performance.\nOur method achieves better recognition performance than prior arts on both\nCROHME and HME100K datasets.",
            "author": [
                "Zhuang Liu",
                "Ye Yuan",
                "Zhilong Ji",
                "Jingfeng Bai",
                "Xiang Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10493v1",
                "http://arxiv.org/pdf/2308.10493v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10487v1",
            "title": "Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees",
            "updated": "2023-08-21T06:04:53Z",
            "published": "2023-08-21T06:04:53Z",
            "summary": "Neuro-symbolic hybrid systems are promising for integrating machine learning\nand symbolic reasoning, where perception models are facilitated with\ninformation inferred from a symbolic knowledge base through logical reasoning.\nDespite empirical evidence showing the ability of hybrid systems to learn\naccurate perception models, the theoretical understanding of learnability is\nstill lacking. Hence, it remains unclear why a hybrid system succeeds for a\nspecific task and when it may fail given a different knowledge base. In this\npaper, we introduce a novel way of characterising supervision signals from a\nknowledge base, and establish a criterion for determining the knowledge's\nefficacy in facilitating successful learning. This, for the first time, allows\nus to address the two questions above by inspecting the knowledge base under\ninvestigation. Our analysis suggests that many knowledge bases satisfy the\ncriterion, thus enabling effective learning, while some fail to satisfy it,\nindicating potential failures. Comprehensive experiments confirm the utility of\nour criterion on benchmark tasks.",
            "author": [
                "Lue Tao",
                "Yu-Xuan Huang",
                "Wang-Zhou Dai",
                "Yuan Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10487v1",
                "http://arxiv.org/pdf/2308.10487v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10918v1",
            "title": "Deep Semi-supervised Anomaly Detection with Metapath-based Context\n  Knowledge",
            "updated": "2023-08-21T05:41:05Z",
            "published": "2023-08-21T05:41:05Z",
            "summary": "Graph anomaly detection has attracted considerable attention in recent years.\nThis paper introduces a novel approach that leverages metapath-based\nsemi-supervised learning, addressing the limitations of previous methods. We\npresent a new framework, Metapath-based Semi-supervised Anomaly Detection\n(MSAD), incorporating GCN layers in both the encoder and decoder to efficiently\npropagate context information between abnormal and normal nodes. The design of\nmetapath-based context information and a specifically crafted anomaly community\nenhance the process of learning differences in structures and attributes, both\nglobally and locally. Through a comprehensive set of experiments conducted on\nseven real-world networks, this paper demonstrates the superiority of the MSAD\nmethod compared to state-of-the-art techniques. The promising results of this\nstudy pave the way for future investigations, focusing on the optimization and\nanalysis of metapath patterns to further enhance the effectiveness of anomaly\ndetection on attributed networks.",
            "author": [
                "Hwan Kim",
                "Junghoon Kim",
                "Byung Suk Lee",
                "Sungsu Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10918v1",
                "http://arxiv.org/pdf/2308.10918v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10467v1",
            "title": "Single-User Injection for Invisible Shilling Attack against Recommender\n  Systems",
            "updated": "2023-08-21T05:08:20Z",
            "published": "2023-08-21T05:08:20Z",
            "summary": "Recommendation systems (RS) are crucial for alleviating the information\noverload problem. Due to its pivotal role in guiding users to make decisions,\nunscrupulous parties are lured to launch attacks against RS to affect the\ndecisions of normal users and gain illegal profits. Among various types of\nattacks, shilling attack is one of the most subsistent and profitable attacks.\nIn shilling attack, an adversarial party injects a number of well-designed fake\nuser profiles into the system to mislead RS so that the attack goal can be\nachieved. Although existing shilling attack methods have achieved promising\nresults, they all adopt the attack paradigm of multi-user injection, where some\nfake user profiles are required. This paper provides the first study of\nshilling attack in an extremely limited scenario: only one fake user profile is\ninjected into the victim RS to launch shilling attacks (i.e., single-user\ninjection). We propose a novel single-user injection method SUI-Attack for\ninvisible shilling attack. SUI-Attack is a graph based attack method that\nmodels shilling attack as a node generation task over the user-item bipartite\ngraph of the victim RS, and it constructs the fake user profile by generating\nuser features and edges that link the fake user to items. Extensive experiments\ndemonstrate that SUI-Attack can achieve promising attack results in single-user\ninjection. In addition to its attack power, SUI-Attack increases the\nstealthiness of shilling attack and reduces the risk of being detected. We\nprovide our implementation at: https://github.com/KDEGroup/SUI-Attack.",
            "author": [
                "Chengzhi Huang",
                "Hui Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10467v1",
                "http://arxiv.org/pdf/2308.10467v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10463v1",
            "title": "On the index of depth stability of symbolic powers of cover ideals of\n  graphs",
            "updated": "2023-08-21T04:35:26Z",
            "published": "2023-08-21T04:35:26Z",
            "summary": "Let $G$ be a graph with $n$ vertices and let $S=\\mathbb{K}[x_1,\\dots,x_n]$ be\nthe polynomial ring in $n$ variables over a field $\\mathbb{K}$. Assume that\n$I(G)$ and $J(G)$ denote the edge ideal and the cover ideal of $G$,\nrespectively. We provide a combinatorial upper bound for the index of depth\nstability of symbolic powers of $J(G)$. As a consequence, we compute the depth\nof symbolic powers of cover ideals of fully clique-whiskered graphs. Meanwhile,\nwe determine a class of graphs $G$ with the property that the\nCastelnuovo--Mumford regularity of $S/I(G)$ is equal to the induced matching\nnumber of $G$.",
            "author": [
                "Seyed Amin Seyed Fakhari",
                "Siamak Yassemi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10463v1",
                "http://arxiv.org/pdf/2308.10463v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10453v1",
            "title": "DOMINO++: Domain-aware Loss Regularization for Deep Learning\n  Generalizability",
            "updated": "2023-08-21T03:58:04Z",
            "published": "2023-08-21T03:58:04Z",
            "summary": "Out-of-distribution (OOD) generalization poses a serious challenge for modern\ndeep learning (DL). OOD data consists of test data that is significantly\ndifferent from the model's training data. DL models that perform well on\nin-domain test data could struggle on OOD data. Overcoming this discrepancy is\nessential to the reliable deployment of DL. Proper model calibration decreases\nthe number of spurious connections that are made between model features and\nclass outputs. Hence, calibrated DL can improve OOD generalization by only\nlearning features that are truly indicative of the respective classes. Previous\nwork proposed domain-aware model calibration (DOMINO) to improve DL\ncalibration, but it lacks designs for model generalizability to OOD data. In\nthis work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss\nregularization focused on OOD generalizability. DOMINO++ integrates\nexpert-guided and data-guided knowledge in its regularization. Unlike DOMINO\nwhich imposed a fixed scaling and regularization rate, DOMINO++ designs a\ndynamic scaling factor and an adaptive regularization rate. Comprehensive\nevaluations compare DOMINO++ with DOMINO and the baseline model for head tissue\nsegmentation from magnetic resonance images (MRIs) on OOD data. The OOD data\nconsists of synthetic noisy and rotated datasets, as well as real data using a\ndifferent MRI scanner from a separate site. DOMINO++'s superior performance\ndemonstrates its potential to improve the trustworthy deployment of DL on real\nclinical data.",
            "author": [
                "Skylar E. Stolte",
                "Kyle Volle",
                "Aprinda Indahlastari",
                "Alejandro Albizu",
                "Adam J. Woods",
                "Kevin Brink",
                "Matthew Hale",
                "Ruogu Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10453v1",
                "http://arxiv.org/pdf/2308.10453v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10445v1",
            "title": "When Prompt-based Incremental Learning Does Not Meet Strong Pretraining",
            "updated": "2023-08-21T03:33:21Z",
            "published": "2023-08-21T03:33:21Z",
            "summary": "Incremental learning aims to overcome catastrophic forgetting when learning\ndeep networks from sequential tasks. With impressive learning efficiency and\nperformance, prompt-based methods adopt a fixed backbone to sequential tasks by\nlearning task-specific prompts. However, existing prompt-based methods heavily\nrely on strong pretraining (typically trained on ImageNet-21k), and we find\nthat their models could be trapped if the potential gap between the pretraining\ntask and unknown future tasks is large. In this work, we develop a learnable\nAdaptive Prompt Generator (APG). The key is to unify the prompt retrieval and\nprompt learning processes into a learnable prompt generator. Hence, the whole\nprompting process can be optimized to reduce the negative effects of the gap\nbetween tasks effectively. To make our APG avoid learning ineffective\nknowledge, we maintain a knowledge pool to regularize APG with the feature\ndistribution of each class. Extensive experiments show that our method\nsignificantly outperforms advanced methods in exemplar-free incremental\nlearning without (strong) pretraining. Besides, under strong retraining, our\nmethod also has comparable performance to existing prompt-based models, showing\nthat our method can still benefit from pretraining. Codes can be found at\nhttps://github.com/TOM-tym/APG",
            "author": [
                "Yu-Ming Tang",
                "Yi-Xing Peng",
                "Wei-Shi Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10445v1",
                "http://arxiv.org/pdf/2308.10445v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10442v1",
            "title": "DySuse: Susceptibility Estimation in Dynamic Social Networks",
            "updated": "2023-08-21T03:28:34Z",
            "published": "2023-08-21T03:28:34Z",
            "summary": "Influence estimation aims to predict the total influence spread in social\nnetworks and has received surged attention in recent years. Most current\nstudies focus on estimating the total number of influenced users in a social\nnetwork, and neglect susceptibility estimation that aims to predict the\nprobability of each user being influenced from the individual perspective. As a\nmore fine-grained estimation task, susceptibility estimation is full of\nattractiveness and practical value. Based on the significance of susceptibility\nestimation and dynamic properties of social networks, we propose a task, called\nsusceptibility estimation in dynamic social networks, which is even more\nrealistic and valuable in real-world applications. Susceptibility estimation in\ndynamic networks has yet to be explored so far and is computationally\nintractable to naively adopt Monte Carlo simulation to obtain the results. To\nthis end, we propose a novel end-to-end framework DySuse based on dynamic graph\nembedding technology. Specifically, we leverage a structural feature module to\nindependently capture the structural information of influence diffusion on each\nsingle graph snapshot. Besides, {we propose the progressive mechanism according\nto the property of influence diffusion,} to couple the structural and temporal\ninformation during diffusion tightly. Moreover, a self-attention block {is\ndesigned to} further capture temporal dependency by flexibly weighting\nhistorical timestamps. Experimental results show that our framework is superior\nto the existing dynamic graph embedding models and has satisfactory prediction\nperformance in multiple influence diffusion models.",
            "author": [
                "Yingdan Shi",
                "Jingya Zhou",
                "Congcong Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.eswa.2023.121042",
                "http://arxiv.org/abs/2308.10442v1",
                "http://arxiv.org/pdf/2308.10442v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10436v3",
            "title": "Approximately Equivariant Graph Networks",
            "updated": "2023-11-17T16:29:49Z",
            "published": "2023-08-21T03:13:38Z",
            "summary": "Graph neural networks (GNNs) are commonly described as being permutation\nequivariant with respect to node relabeling in the graph. This symmetry of GNNs\nis often compared to the translation equivariance of Euclidean convolution\nneural networks (CNNs). However, these two symmetries are fundamentally\ndifferent: The translation equivariance of CNNs corresponds to symmetries of\nthe fixed domain acting on the image signals (sometimes known as active\nsymmetries), whereas in GNNs any permutation acts on both the graph signals and\nthe graph domain (sometimes described as passive symmetries). In this work, we\nfocus on the active symmetries of GNNs, by considering a learning setting where\nsignals are supported on a fixed graph. In this case, the natural symmetries of\nGNNs are the automorphisms of the graph. Since real-world graphs tend to be\nasymmetric, we relax the notion of symmetries by formalizing approximate\nsymmetries via graph coarsening. We present a bias-variance formula that\nquantifies the tradeoff between the loss in expressivity and the gain in the\nregularity of the learned estimator, depending on the chosen symmetry group. To\nillustrate our approach, we conduct extensive experiments on image inpainting,\ntraffic flow prediction, and human pose estimation with different choices of\nsymmetries. We show theoretically and empirically that the best generalization\nperformance can be achieved by choosing a suitably larger group than the graph\nautomorphism, but smaller than the permutation group.",
            "author": [
                "Ningyuan Huang",
                "Ron Levie",
                "Soledad Villar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10436v3",
                "http://arxiv.org/pdf/2308.10436v3"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10408v1",
            "title": "Turning a CLIP Model into a Scene Text Spotter",
            "updated": "2023-08-21T01:25:48Z",
            "published": "2023-08-21T01:25:48Z",
            "summary": "We exploit the potential of the large-scale Contrastive Language-Image\nPretraining (CLIP) model to enhance scene text detection and spotting tasks,\ntransforming it into a robust backbone, FastTCM-CR50. This backbone utilizes\nvisual prompt learning and cross-attention in CLIP to extract image and\ntext-based prior knowledge. Using predefined and learnable prompts,\nFastTCM-CR50 introduces an instance-language matching process to enhance the\nsynergy between image and text embeddings, thereby refining text regions. Our\nBimodal Similarity Matching (BSM) module facilitates dynamic language prompt\ngeneration, enabling offline computations and improving performance.\nFastTCM-CR50 offers several advantages: 1) It can enhance existing text\ndetectors and spotters, improving performance by an average of 1.7% and 1.5%,\nrespectively. 2) It outperforms the previous TCM-CR50 backbone, yielding an\naverage improvement of 0.2% and 0.56% in text detection and spotting tasks,\nalong with a 48.5% increase in inference speed. 3) It showcases robust few-shot\ntraining capabilities. Utilizing only 10% of the supervised data, FastTCM-CR50\nimproves performance by an average of 26.5% and 5.5% for text detection and\nspotting tasks, respectively. 4) It consistently enhances performance on\nout-of-distribution text detection and spotting datasets, particularly the\nNightTime-ArT subset from ICDAR2019-ArT and the DOTA dataset for oriented\nobject detection. The code is available at https://github.com/wenwenyu/TCM.",
            "author": [
                "Wenwen Yu",
                "Yuliang Liu",
                "Xingkui Zhu",
                "Haoyu Cao",
                "Xing Sun",
                "Xiang Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10408v1",
                "http://arxiv.org/pdf/2308.10408v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10916v1",
            "title": "Diffusion Model as Representation Learner",
            "updated": "2023-08-21T00:38:39Z",
            "published": "2023-08-21T00:38:39Z",
            "summary": "Diffusion Probabilistic Models (DPMs) have recently demonstrated impressive\nresults on various generative tasks.Despite its promises, the learned\nrepresentations of pre-trained DPMs, however, have not been fully understood.\nIn this paper, we conduct an in-depth investigation of the representation power\nof DPMs, and propose a novel knowledge transfer method that leverages the\nknowledge acquired by generative DPMs for recognition tasks. Our study begins\nby examining the feature space of DPMs, revealing that DPMs are inherently\ndenoising autoencoders that balance the representation learning with\nregularizing model capacity. To this end, we introduce a novel knowledge\ntransfer paradigm named RepFusion. Our paradigm extracts representations at\ndifferent time steps from off-the-shelf DPMs and dynamically employs them as\nsupervision for student networks, in which the optimal time is determined\nthrough reinforcement learning. We evaluate our approach on several image\nclassification, semantic segmentation, and landmark detection benchmarks, and\ndemonstrate that it outperforms state-of-the-art methods. Our results uncover\nthe potential of DPMs as a powerful tool for representation learning and\nprovide insights into the usefulness of generative models beyond sample\ngeneration. The code is available at\n\\url{https://github.com/Adamdad/Repfusion}.",
            "author": [
                "Xingyi Yang",
                "Xinchao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10916v1",
                "http://arxiv.org/pdf/2308.10916v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10383v2",
            "title": "A Variational Qubit-Efficient MaxCut Heuristic Algorithm",
            "updated": "2023-11-23T18:49:54Z",
            "published": "2023-08-20T23:06:18Z",
            "summary": "MaxCut is a key NP-Hard combinatorial optimization graph problem with\nextensive theoretical and industrial applications, including the Ising model\nand chip design. While quantum computing offers new solutions for such\ncombinatorial challenges which are potentially better than classical schemes,\nwith the Quantum Approximate Optimization Algorithm (QAOA) being a\nstate-of-the-art example, its performance is currently hindered by hardware\nnoise and limited qubit number. Here, we present a new variational\nQubit-Efficient MaxCut (QEMC) algorithm that requires a logarithmic number of\nqubits with respect to the graph size, an exponential reduction compared to\nQAOA. We demonstrate cutting-edge performance for graph instances consisting of\nup to 32 nodes (5 qubits) on real superconducting hardware, and for graphs with\nup to 2048 nodes (11 qubits) using noiseless simulations, outperforming the\nestablished classical algorithm of Goemans and Williamson (GW). The QEMC\nalgorithm's innovative encoding scheme empowers it with great noise-resiliency\non the one hand, but also enables its efficient classical simulation on the\nother, thus obscuring a distinct quantum advantage. Nevertheless, even in the\nabsence of quantum advantage, the QEMC algorithm serves as a potential\nquantum-inspired algorithm, provides a challenging benchmark for QAOA, and\npresents a novel encoding paradigm with potential applications extending to\nother quantum and classical algorithms.",
            "author": [
                "Yovav Tene-Cohen",
                "Tomer Kelman",
                "Ohad Lev",
                "Adi Makmal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10383v2",
                "http://arxiv.org/pdf/2308.10383v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08407v1",
            "title": "Hom-associative algebras, Admissibility and Relative averaging operators",
            "updated": "2023-08-20T22:51:11Z",
            "published": "2023-08-20T22:51:11Z",
            "summary": "We introduce the notion of relative averaging operators on Hom-associative\nalgebras with a representation. Relative averaging operators are twisted\ngeneralizations of relative averaging operators on associative algebras. We\ngive two characterizations of relative averaging operators of Hom-associative\nalgebras via graphs and Nijenhuis operators. A (homomorphic) relative averaging\noperator of Hom-associative algebras with respect to a given representation\ngives rise to Hom-associative (tri)dialgebras. By admissibility, a Hom-Jordan\n(tri)dialgebra and a Hom-(tri)Leibniz algebra can be obtained from\nHom-associative (tri)dialgebra.",
            "author": [
                "Safa Braiek",
                "Taoufik Chtioui",
                "Sami Mabrouk",
                "Mohamed Elhamdadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08407v1",
                "http://arxiv.org/pdf/2311.08407v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA",
                "math.RT",
                "17B61, 17B60, 17C10, 17A32"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10377v2",
            "title": "Proper Minor-Closed Classes of Graphs have Assouad-Nagata Dimension 2",
            "updated": "2023-08-25T07:59:40Z",
            "published": "2023-08-20T22:15:40Z",
            "summary": "Asymptotic dimension and Assouad-Nagata dimension are measures of the\nlarge-scale shape of a class of graphs. Bonamy et al. [J. Eur. Math. Society]\nshowed that any proper minor-closed class has asymptotic dimension 2, dropping\nto 1 only if the treewidth is bounded. We improve this result by showing it\nalso holds for the stricter Assouad-Nagata dimension. We also characterise when\nsubdivision-closed classes of graphs have bounded Assouad-Nagata dimension.",
            "author": [
                "Marc Distel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10377v2",
                "http://arxiv.org/pdf/2308.10377v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.MG",
                "05C83 (Primary) 05C12, 51F99 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10375v2",
            "title": "Model Selection over Partially Ordered Sets",
            "updated": "2023-08-23T17:04:49Z",
            "published": "2023-08-20T22:08:44Z",
            "summary": "In problems such as variable selection and graph estimation, models are\ncharacterized by Boolean logical structure such as presence or absence of a\nvariable or an edge. Consequently, false positive and false negative errors can\nbe specified as the number of variables or edges that are incorrectly\nincluded/excluded in an estimated model. However, there are several other\nproblems such as ranking, clustering, and causal inference in which the\nassociated model classes do not admit transparent notions of false positive and\nfalse negative errors due to the lack of an underlying Boolean logical\nstructure. In this paper, we present a generic approach to endow a collection\nof models with partial order structure, which leads to a hierarchical\norganization of model classes as well as natural analogs of false positive and\nfalse negative errors. We describe model selection procedures that provide\nfalse positive error control in our general setting and we illustrate their\nutility with numerical experiments.",
            "author": [
                "Armeen Taeb",
                "Peter B\u00fchlmann",
                "Venkat Chandrasekaran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10375v2",
                "http://arxiv.org/pdf/2308.10375v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10364v4",
            "title": "SE(3) Equivariant Augmented Coupling Flows",
            "updated": "2023-11-28T14:20:28Z",
            "published": "2023-08-20T20:49:15Z",
            "summary": "Coupling normalizing flows allow for fast sampling and density evaluation,\nmaking them the tool of choice for probabilistic modeling of physical systems.\nHowever, the standard coupling architecture precludes endowing flows that\noperate on the Cartesian coordinates of atoms with the SE(3) and permutation\ninvariances of physical systems. This work proposes a coupling flow that\npreserves SE(3) and permutation equivariance by performing coordinate splits\nalong additional augmented dimensions. At each layer, the flow maps atoms'\npositions into learned SE(3) invariant bases, where we apply standard flow\ntransformations, such as monotonic rational-quadratic splines, before returning\nto the original basis. Crucially, our flow preserves fast sampling and density\nevaluation, and may be used to produce unbiased estimates of expectations with\nrespect to the target distribution via importance sampling. When trained on the\nDW4, LJ13, and QM9-positional datasets, our flow is competitive with\nequivariant continuous normalizing flows, while allowing sampling more than an\norder of magnitude faster. Moreover, to the best of our knowledge, we are the\nfirst to learn the full Boltzmann distribution of alanine dipeptide by only\nmodeling the Cartesian positions of its atoms. Lastly, we demonstrate that our\nflow can be trained to approximately sample from the Boltzmann distribution of\nthe DW4 and LJ13 particle systems using only their energy functions.",
            "author": [
                "Laurence I. Midgley",
                "Vincent Stimper",
                "Javier Antor\u00e1n",
                "Emile Mathieu",
                "Bernhard Sch\u00f6lkopf",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10364v4",
                "http://arxiv.org/pdf/2308.10364v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10330v1",
            "title": "Towards Real-World Visual Tracking with Temporal Contexts",
            "updated": "2023-08-20T17:59:40Z",
            "published": "2023-08-20T17:59:40Z",
            "summary": "Visual tracking has made significant improvements in the past few decades.\nMost existing state-of-the-art trackers 1) merely aim for performance in ideal\nconditions while overlooking the real-world conditions; 2) adopt the\ntracking-by-detection paradigm, neglecting rich temporal contexts; 3) only\nintegrate the temporal information into the template, where temporal contexts\namong consecutive frames are far from being fully utilized. To handle those\nproblems, we propose a two-level framework (TCTrack) that can exploit temporal\ncontexts efficiently. Based on it, we propose a stronger version for real-world\nvisual tracking, i.e., TCTrack++. It boils down to two levels: features and\nsimilarity maps. Specifically, for feature extraction, we propose an\nattention-based temporally adaptive convolution to enhance the spatial features\nusing temporal information, which is achieved by dynamically calibrating the\nconvolution weights. For similarity map refinement, we introduce an adaptive\ntemporal transformer to encode the temporal knowledge efficiently and decode it\nfor the accurate refinement of the similarity map. To further improve the\nperformance, we additionally introduce a curriculum learning strategy. Also, we\nadopt online evaluation to measure performance in real-world conditions.\nExhaustive experiments on 8 wellknown benchmarks demonstrate the superiority of\nTCTrack++. Real-world tests directly verify that TCTrack++ can be readily used\nin real-world applications.",
            "author": [
                "Ziang Cao",
                "Ziyuan Huang",
                "Liang Pan",
                "Shiwei Zhang",
                "Ziwei Liu",
                "Changhong Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10330v1",
                "http://arxiv.org/pdf/2308.10330v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10320v1",
            "title": "Hyper Association Graph Matching with Uncertainty Quantification for\n  Coronary Artery Semantic Labeling",
            "updated": "2023-08-20T16:59:17Z",
            "published": "2023-08-20T16:59:17Z",
            "summary": "Coronary artery disease (CAD) is one of the primary causes leading to death\nworldwide. Accurate extraction of individual arterial branches on invasive\ncoronary angiograms (ICA) is important for stenosis detection and CAD\ndiagnosis. However, deep learning-based models face challenges in generating\nsemantic segmentation for coronary arteries due to the morphological similarity\namong different types of coronary arteries. To address this challenge, we\npropose an innovative approach using the hyper association graph-matching\nneural network with uncertainty quantification (HAGMN-UQ) for coronary artery\nsemantic labeling on ICAs. The graph-matching procedure maps the arterial\nbranches between two individual graphs, so that the unlabeled arterial segments\nare classified by the labeled segments, and the coronary artery semantic\nlabeling is achieved. By incorporating the anatomical structural loss and\nuncertainty, our model achieved an accuracy of 0.9345 for coronary artery\nsemantic labeling with a fast inference speed, leading to an effective and\nefficient prediction in real-time clinical decision-making scenarios.",
            "author": [
                "Chen Zhao",
                "Michele Esposito",
                "Zhihui Xu",
                "Weihua Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10320v1",
                "http://arxiv.org/pdf/2308.10320v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10315v2",
            "title": "Improving Adversarial Robustness of Masked Autoencoders via Test-time\n  Frequency-domain Prompting",
            "updated": "2023-08-22T07:20:59Z",
            "published": "2023-08-20T16:27:17Z",
            "summary": "In this paper, we investigate the adversarial robustness of vision\ntransformers that are equipped with BERT pretraining (e.g., BEiT, MAE). A\nsurprising observation is that MAE has significantly worse adversarial\nrobustness than other BERT pretraining methods. This observation drives us to\nrethink the basic differences between these BERT pretraining methods and how\nthese differences affect the robustness against adversarial perturbations. Our\nempirical analysis reveals that the adversarial robustness of BERT pretraining\nis highly related to the reconstruction target, i.e., predicting the raw pixels\nof masked image patches will degrade more adversarial robustness of the model\nthan predicting the semantic context, since it guides the model to concentrate\nmore on medium-/high-frequency components of images. Based on our analysis, we\nprovide a simple yet effective way to boost the adversarial robustness of MAE.\nThe basic idea is using the dataset-extracted domain knowledge to occupy the\nmedium-/high-frequency of images, thus narrowing the optimization space of\nadversarial perturbations. Specifically, we group the distribution of\npretraining data and optimize a set of cluster-specific visual prompts on\nfrequency domain. These prompts are incorporated with input images through\nprototype-based prompt selection during test period. Extensive evaluation shows\nthat our method clearly boost MAE's adversarial robustness while maintaining\nits clean performance on ImageNet-1k classification. Our code is available at:\nhttps://github.com/shikiw/RobustMAE.",
            "author": [
                "Qidong Huang",
                "Xiaoyi Dong",
                "Dongdong Chen",
                "Yinpeng Chen",
                "Lu Yuan",
                "Gang Hua",
                "Weiming Zhang",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10315v2",
                "http://arxiv.org/pdf/2308.10315v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10309v1",
            "title": "Digital Real Estate in the Metaverse: An Empirical Analysis of Retail\n  Investor Motivations",
            "updated": "2023-08-20T16:08:06Z",
            "published": "2023-08-20T16:08:06Z",
            "summary": "This paper investigates retail investor motivations for digital real estate\nownership in the crypto-metaverse. Utilizing a detailed financial behavior\nsurvey of metaverse landowners' intrinsic and extrinsic motivations, we apply\nprincipal components analysis to uncover four distinct motivational groups: (1)\nAesthetics and Identity, (2) Social and Community, (3) Speculation and\nInvestment, and (4) Innovation and Technology. Our findings reveal that age,\neducation, investment knowledge, risk-taking, and impulsivity significantly\ninfluence investor group membership. This research provides valuable insights\nto investors and developers, underscoring the potential of a platform to\nattract retail investors with speculative intentions, engagement longevity, and\npassive or active trading characteristics, contingent on unique\ncrypto-metaverse attributes.",
            "author": [
                "Lennart Ante",
                "Friedrich-Philipp Wazinski",
                "Aman Saggu"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.frl.2023.104299",
                "http://arxiv.org/abs/2308.10309v1",
                "http://arxiv.org/pdf/2308.10309v1"
            ],
            "primary_category": "q-fin.GN",
            "category": [
                "q-fin.GN",
                "91G70, 91B08",
                "J.4; K.4.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10308v1",
            "title": "Representation Disparity-aware Distillation for 3D Object Detection",
            "updated": "2023-08-20T16:06:42Z",
            "published": "2023-08-20T16:06:42Z",
            "summary": "In this paper, we focus on developing knowledge distillation (KD) for compact\n3D detectors. We observe that off-the-shelf KD methods manifest their efficacy\nonly when the teacher model and student counterpart share similar intermediate\nfeature representations. This might explain why they are less effective in\nbuilding extreme-compact 3D detectors where significant representation\ndisparity arises due primarily to the intrinsic sparsity and irregularity in 3D\npoint clouds. This paper presents a novel representation disparity-aware\ndistillation (RDD) method to address the representation disparity issue and\nreduce performance gap between compact students and over-parameterized\nteachers. This is accomplished by building our RDD from an innovative\nperspective of information bottleneck (IB), which can effectively minimize the\ndisparity of proposal region pairs from student and teacher in features and\nlogits. Extensive experiments are performed to demonstrate the superiority of\nour RDD over existing KD methods. For example, our RDD increases mAP of\nCP-Voxel-S to 57.1% on nuScenes dataset, which even surpasses teacher\nperformance while taking up only 42% FLOPs.",
            "author": [
                "Yanjing Li",
                "Sheng Xu",
                "Mingbao Lin",
                "Jihao Yin",
                "Baochang Zhang",
                "Xianbin Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10308v1",
                "http://arxiv.org/pdf/2308.10308v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10306v1",
            "title": "Omnidirectional Information Gathering for Knowledge Transfer-based\n  Audio-Visual Navigation",
            "updated": "2023-08-20T16:03:54Z",
            "published": "2023-08-20T16:03:54Z",
            "summary": "Audio-visual navigation is an audio-targeted wayfinding task where a robot\nagent is entailed to travel a never-before-seen 3D environment towards the\nsounding source. In this article, we present ORAN, an omnidirectional\naudio-visual navigator based on cross-task navigation skill transfer. In\nparticular, ORAN sharpens its two basic abilities for a such challenging task,\nnamely wayfinding and audio-visual information gathering. First, ORAN is\ntrained with a confidence-aware cross-task policy distillation (CCPD) strategy.\nCCPD transfers the fundamental, point-to-point wayfinding skill that is well\ntrained on the large-scale PointGoal task to ORAN, so as to help ORAN to better\nmaster audio-visual navigation with far fewer training samples. To improve the\nefficiency of knowledge transfer and address the domain gap, CCPD is made to be\nadaptive to the decision confidence of the teacher policy. Second, ORAN is\nequipped with an omnidirectional information gathering (OIG) mechanism, i.e.,\ngleaning visual-acoustic observations from different directions before\ndecision-making. As a result, ORAN yields more robust navigation behaviour.\nTaking CCPD and OIG together, ORAN significantly outperforms previous\ncompetitors. After the model ensemble, we got 1st in Soundspaces Challenge\n2022, improving SPL and SR by 53% and 35% relatively.",
            "author": [
                "Jinyu Chen",
                "Wenguan Wang",
                "Si Liu",
                "Hongsheng Li",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10306v1",
                "http://arxiv.org/pdf/2308.10306v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10302v1",
            "title": "Preserving Specificity in Federated Graph Learning for fMRI-based\n  Neurological Disorder Identification",
            "updated": "2023-08-20T15:55:45Z",
            "published": "2023-08-20T15:55:45Z",
            "summary": "Resting-state functional magnetic resonance imaging (rs-fMRI) offers a\nnon-invasive approach to examining abnormal brain connectivity associated with\nbrain disorders. Graph neural network (GNN) gains popularity in fMRI\nrepresentation learning and brain disorder analysis with powerful graph\nrepresentation capabilities. Training a general GNN often necessitates a\nlarge-scale dataset from multiple imaging centers/sites, but centralizing\nmulti-site data generally faces inherent challenges related to data privacy,\nsecurity, and storage burden. Federated Learning (FL) enables collaborative\nmodel training without centralized multi-site fMRI data. Unfortunately,\nprevious FL approaches for fMRI analysis often ignore site-specificity,\nincluding demographic factors such as age, gender, and education level. To this\nend, we propose a specificity-aware federated graph learning (SFGL) framework\nfor rs-fMRI analysis and automated brain disorder identification, with a server\nand multiple clients/sites for federated model aggregation and prediction. At\neach client, our model consists of a shared and a personalized branch, where\nparameters of the shared branch are sent to the server while those of the\npersonalized branch remain local. This can facilitate knowledge sharing among\nsites and also helps preserve site specificity. In the shared branch, we employ\na spatio-temporal attention graph isomorphism network to learn dynamic fMRI\nrepresentations. In the personalized branch, we integrate vectorized\ndemographic information (i.e., age, gender, and education years) and functional\nconnectivity networks to preserve site-specific characteristics.\nRepresentations generated by the two branches are then fused for\nclassification. Experimental results on two fMRI datasets with a total of 1,218\nsubjects suggest that SFGL outperforms several state-of-the-art approaches.",
            "author": [
                "Junhao Zhang",
                "Qianqian Wang",
                "Xiaochuan Wang",
                "Lishan Qiao",
                "Mingxia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10302v1",
                "http://arxiv.org/pdf/2308.10302v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10292v1",
            "title": "An interpretable deep learning method for bearing fault diagnosis",
            "updated": "2023-08-20T15:22:08Z",
            "published": "2023-08-20T15:22:08Z",
            "summary": "Deep learning (DL) has gained popularity in recent years as an effective tool\nfor classifying the current health and predicting the future of industrial\nequipment. However, most DL models have black-box components with an underlying\nstructure that is too complex to be interpreted and explained to human users.\nThis presents significant challenges when deploying these models for\nsafety-critical maintenance tasks, where non-technical personnel often need to\nhave complete trust in the recommendations these models give. To address these\nchallenges, we utilize a convolutional neural network (CNN) with\nGradient-weighted Class Activation Mapping (Grad-CAM) activation map\nvisualizations to form an interpretable DL method for classifying bearing\nfaults. After the model training process, we apply Grad-CAM to identify a\ntraining sample's feature importance and to form a library of diagnosis\nknowledge (or health library) containing training samples with annotated\nfeature maps. During the model evaluation process, the proposed approach\nretrieves prediction basis samples from the health library according to the\nsimilarity of the feature importance. The proposed method can be easily applied\nto any CNN model without modifying the model architecture, and our experimental\nresults show that this method can select prediction basis samples that are\nintuitively and physically meaningful, improving the model's trustworthiness\nfor human users.",
            "author": [
                "Hao Lu",
                "Austin M. Bray",
                "Chao Hu",
                "Andrew T. Zimmerman",
                "Hongyi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10292v1",
                "http://arxiv.org/pdf/2308.10292v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10282v1",
            "title": "Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity\n  Analysis",
            "updated": "2023-08-20T14:31:55Z",
            "published": "2023-08-20T14:31:55Z",
            "summary": "Traffic prediction is one of the key elements to ensure the safety and\nconvenience of citizens. Existing traffic prediction models primarily focus on\ndeep learning architectures to capture spatial and temporal correlation. They\noften overlook the underlying nature of traffic. Specifically, the sensor\nnetworks in most traffic datasets do not accurately represent the actual road\nnetwork exploited by vehicles, failing to provide insights into the traffic\npatterns in urban activities. To overcome these limitations, we propose an\nimproved traffic prediction method based on graph convolution deep learning\nalgorithms. We leverage human activity frequency data from National Household\nTravel Survey to enhance the inference capability of a causal relationship\nbetween activity and traffic patterns. Despite making minimal modifications to\nthe conventional graph convolutional recurrent networks and graph convolutional\ntransformer architectures, our approach achieves state-of-the-art performance\nwithout introducing excessive computational overhead.",
            "author": [
                "Sumin Han",
                "Youngjun Park",
                "Minji Lee",
                "Jisun An",
                "Dongman Lee"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614867",
                "http://arxiv.org/abs/2308.10282v1",
                "http://arxiv.org/pdf/2308.10282v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10276v2",
            "title": "Minimalist Traffic Prediction: Linear Layer Is All You Need",
            "updated": "2023-08-23T10:10:49Z",
            "published": "2023-08-20T14:12:11Z",
            "summary": "Traffic prediction is essential for the progression of Intelligent\nTransportation Systems (ITS) and the vision of smart cities. While\nSpatial-Temporal Graph Neural Networks (STGNNs) have shown promise in this\ndomain by leveraging Graph Neural Networks (GNNs) integrated with either RNNs\nor Transformers, they present challenges such as computational complexity,\ngradient issues, and resource-intensiveness. This paper addresses these\nchallenges, advocating for three main solutions: a node-embedding approach,\ntime series decomposition, and periodicity learning. We introduce STLinear, a\nminimalist model architecture designed for optimized efficiency and\nperformance. Unlike traditional STGNNs, STlinear operates fully locally,\navoiding inter-node data exchanges, and relies exclusively on linear layers,\ndrastically cutting computational demands. Our empirical studies on real-world\ndatasets confirm STLinear's prowess, matching or exceeding the accuracy of\nleading STGNNs, but with significantly reduced complexity and computation\noverhead (more than 95% reduction in MACs per epoch compared to\nstate-of-the-art STGNN baseline published in 2023). In summary, STLinear\nemerges as a potent, efficient alternative to conventional STGNNs, with\nprofound implications for the future of ITS and smart city initiatives.",
            "author": [
                "Wenying Duan",
                "Hong Rao",
                "Wei Huang",
                "Xiaoxi He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10276v2",
                "http://arxiv.org/pdf/2308.10276v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10267v2",
            "title": "Percolation through Isoperimetry",
            "updated": "2023-09-07T15:44:42Z",
            "published": "2023-08-20T13:44:00Z",
            "summary": "We provide a sufficient condition on the isoperimetric properties of a\nregular graph $G$ of growing degree $d$, under which the random subgraph $G_p$\ntypically undergoes a phase transition around $p=\\frac{1}{d}$ which resembles\nthe emergence of a giant component in the binomial random graph model $G(n,p)$.\nWe further show that this condition is tight.\n  More precisely, let $d=\\omega(1)$, let $\\epsilon>0$ be a small enough\nconstant, and let $p \\cdot d=1+\\epsilon$. We show that if $C$ is sufficiently\nlarge and $G$ is a $d$-regular $n$-vertex graph where every subset $S\\subseteq\nV(G)$ of order at most $\\frac{n}{2}$ has edge-boundary of size at least $C|S|$,\nthen $G_p$ typically has a unique linear sized component, whose order is\nasymptotically $y(\\epsilon)n$, where $y(\\epsilon)$ is the survival probability\nof a Galton-Watson tree with offspring distribution Po$(1+\\epsilon)$. We\nfurther give examples to show that this result is tight both in terms of its\ndependence on $C$, and with respect to the order of the second-largest\ncomponent.\n  We also consider a more general setting, where we only control the expansion\nof sets up to size $k$. In this case, we show that if $G$ is such that every\nsubset $S\\subseteq V(G)$ of order at most $k$ has edge-boundary of size at\nleast $d|S|$ and $p$ is such that $p\\cdot d \\geq 1 + \\epsilon$, then $G_p$\ntypically contains a component of order $\\Omega(k)$.",
            "author": [
                "Sahar Diskin",
                "Joshua Erde",
                "Mihyun Kang",
                "Michael Krivelevich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10267v2",
                "http://arxiv.org/pdf/2308.10267v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "05C80, 60K35, 82B43"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10264v1",
            "title": "Quantum Codes on Graphs",
            "updated": "2023-08-20T13:22:58Z",
            "published": "2023-08-20T13:22:58Z",
            "summary": "We consider some questions related to codes constructed using various graphs,\nin particular focusing on graphs which are not lattices in two or three\ndimensions. We begin by considering Floquet codes which can be constructed\nusing ``emergent fermions\". Here, we are considering codes that in some sense\ngeneralize the honeycomb code[1] to more general, non-planar graphs. We then\nconsider a class of these codes that is related to (generalized) toric codes on\n$2$-complexes. For (generalized) toric codes on $2$-complexes, the following\nquestion arises: can the distance of these codes grow faster than square-root?\nWe answer the question negatively, and remark on recent systolic\ninequalities[2]. We then turn to the case that of planar codes with vacancies,\nor ``dead qubits\", and consider the statistical mechanics of decoding in this\nsetting. Although we do not prove a threshold, our results should be\nasymptotically correct for low error probability and high degree decoding\ngraphs (high degree taken before low error probability). In an appendix, we\ndiscuss a toy model of vacancies in planar quantum codes, giving a\nphenomenological discussion of how errors occur when ``super-stabilizers\" are\nnot measured, and in a separate appendix we discuss a relation between Floquet\ncodes and chain maps.",
            "author": [
                "M. B. Hastings"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10264v1",
                "http://arxiv.org/pdf/2308.10264v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10232v1",
            "title": "Gelation, hydrodynamic limits and uniqueness in cluster coagulation\n  processes",
            "updated": "2023-08-20T11:37:10Z",
            "published": "2023-08-20T11:37:10Z",
            "summary": "We consider the problem of gelation in the cluster coagulation model\nintroduced by Norris [$\\textit{Comm. Math. Phys.}$, 209(2):407-435 (2000)],\nwhere clusters take values in a measure space $E$, and merge to form a new\nparticle $z$ according to a transition kernel $K(x,y, \\mathrm{d} z)$. This\nmodel is general enough to incorporate various inhomogenieties in the evolution\nof clusters, for example, their shape, or their location in space. We derive\ngeneral, sufficient criteria for stochastic gelation in this model, and for\ntrajectories associated with this process to concentrate among solutions of a\ngeneralisation of the Flory equation; thus providing sufficient criteria for\nthe equation to have gelling solutions. As particular cases, we extend results\nrelated to the classical Marcus-Lushnikov coagulation process and Smoluchowski\ncoagulation equation, showing that reasonable `homogenous' coagulation\nprocesses with exponent $\\gamma>1$ yield gelation; and also, coagulation\nprocesses with kernel $\\alpha(m,n)~\\geq~(m \\wedge n) \\log{(m \\wedge n)}^{3\n+\\varepsilon}$ for $\\varepsilon>0$. In another special case, we prove a law of\nlarge numbers for the trajectory of the empirical measure of the stochastic\ncluster coagulation process, by means of a uniqueness result for the solution\nof the aforementioned generalised Flory equation. Finally, we use coupling\narguments with inhomogeneous random graphs to deduce sufficient criterion for\nstrong gelation (the emergence of a particle of size $O(N)$).",
            "author": [
                "Luisa Andreis",
                "Tejas Iyer",
                "Elena Magnanini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10232v1",
                "http://arxiv.org/pdf/2308.10232v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.AP",
                "math.MP",
                "60K35, 35Q70, 82C22, 05C90"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10228v1",
            "title": "Scene-Driven Exploration and GUI Modeling for Android Apps",
            "updated": "2023-08-20T10:54:25Z",
            "published": "2023-08-20T10:54:25Z",
            "summary": "Due to the competitive environment, mobile apps are usually produced under\npressure with lots of complicated functionality and UI pages. Therefore, it is\nchallenging for various roles to design, understand, test, and maintain these\napps. The extracted transition graphs for apps such as ATG, WTG, and STG have a\nlow transition coverage and coarse-grained granularity, which limits the\nexisting methods of graphical user interface (GUI) modeling by UI exploration.\nTo solve these problems, in this paper, we propose SceneDroid, a scene-driven\nexploration approach to extracting the GUI scenes dynamically by integrating a\nseries of novel techniques including smart exploration, state fuzzing, and\nindirect launching strategies. We present the GUI scenes as a scene transition\ngraph (SceneTG) to model the GUI of apps with high transition coverage and\nfine? grained granularity. Compared with the existing GUI modeling tools,\nSceneDroid has improved by 168.74% in the coverage of transition pairs and\n162.42% in scene extraction. Apart from the effectiveness evaluation of\nSceneDroid, we also illustrate the future potential of SceneDroid as a\nfundamental capability to support app development, reverse engineering, and GUI\nregression testing.",
            "author": [
                "Xiangyu Zhang",
                "Lingling Fan",
                "Sen Chen",
                "Yucheng Su",
                "Boyuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10228v1",
                "http://arxiv.org/pdf/2308.10228v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10220v1",
            "title": "Designing and Evaluating Presentation Strategies for Fact-Checked\n  Content",
            "updated": "2023-08-20T10:08:55Z",
            "published": "2023-08-20T10:08:55Z",
            "summary": "With the rapid growth of online misinformation, it is crucial to have\nreliable fact-checking methods. Recent research on finding check-worthy claims\nand automated fact-checking have made significant advancements. However,\nlimited guidance exists regarding the presentation of fact-checked content to\neffectively convey verified information to users. We address this research gap\nby exploring the critical design elements in fact-checking reports and\ninvestigating whether credibility and presentation-based design improvements\ncan enhance users' ability to interpret the report accurately. We co-developed\npotential content presentation strategies through a workshop involving\nfact-checking professionals, communication experts, and researchers. The\nworkshop examined the significance and utility of elements such as veracity\nindicators and explored the feasibility of incorporating interactive components\nfor enhanced information disclosure. Building on the workshop outcomes, we\nconducted an online experiment involving 76 crowd workers to assess the\nefficacy of different design strategies. The results indicate that proposed\nstrategies significantly improve users' ability to accurately interpret the\nverdict of fact-checking articles. Our findings underscore the critical role of\neffective presentation of fact reports in addressing the spread of\nmisinformation. By adopting appropriate design enhancements, the effectiveness\nof fact-checking reports can be maximized, enabling users to make informed\njudgments.",
            "author": [
                "Danula Hettiachchi",
                "Kaixin Ji",
                "Jenny Kennedy",
                "Anthony McCosker",
                "Flora Dylis Salim",
                "Mark Sanderson",
                "Falk Scholer",
                "Damiano Spina"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614841",
                "http://arxiv.org/abs/2308.10220v1",
                "http://arxiv.org/pdf/2308.10220v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10214v1",
            "title": "Computational complexity of counting coincidences",
            "updated": "2023-08-20T09:48:24Z",
            "published": "2023-08-20T09:48:24Z",
            "summary": "Can you decide if there is a coincidence in the numbers counting two\ndifferent combinatorial objects? For example, can you decide if two regions in\n$\\mathbb{R}^3$ have the same number of domino tilings? There are two versions\nof the problem, with $2\\times 1 \\times 1$ and $2\\times 2 \\times 1$ boxes. We\nprove that in both cases the coincidence problem is not in the polynomial\nhierarchy unless the polynomial hierarchy collapses to a finite level. While\nthe conclusions are the same, the proofs are notably different and generalize\nin different directions.\n  We proceed to explore the coincidence problem for counting independent sets\nand matchings in graphs, matroid bases, order ideals and linear extensions in\nposets, permutation patterns, and the Kronecker coefficients. We also make a\nnumber of conjectures for counting other combinatorial objects such as plane\ntriangulations, contingency tables, standard Young tableaux, reduced\nfactorizations and the Littlewood--Richardson coefficients.",
            "author": [
                "Swee Hong Chan",
                "Igor Pak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10214v1",
                "http://arxiv.org/pdf/2308.10214v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.CC",
                "cs.CG",
                "cs.DM",
                "05A20, 68R05 (Primary) 05A16, 05B45, 05C30, 05E10, 06A07, 52C20,\n  68Q15, 68Q17 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10205v1",
            "title": "GeT: Generative Target Structure Debiasing for Domain Adaptation",
            "updated": "2023-08-20T08:52:43Z",
            "published": "2023-08-20T08:52:43Z",
            "summary": "Domain adaptation (DA) aims to transfer knowledge from a fully labeled source\nto a scarcely labeled or totally unlabeled target under domain shift. Recently,\nsemi-supervised learning-based (SSL) techniques that leverage pseudo labeling\nhave been increasingly used in DA. Despite the competitive performance, these\npseudo labeling methods rely heavily on the source domain to generate pseudo\nlabels for the target domain and therefore still suffer considerably from\nsource data bias. Moreover, class distribution bias in the target domain is\nalso often ignored in the pseudo label generation and thus leading to further\ndeterioration of performance. In this paper, we propose GeT that learns a\nnon-bias target embedding distribution with high quality pseudo labels.\nSpecifically, we formulate an online target generative classifier to induce the\ntarget distribution into distinctive Gaussian components weighted by their\nclass priors to mitigate source data bias and enhance target class\ndiscriminability. We further propose a structure similarity regularization\nframework to alleviate target class distribution bias and further improve\ntarget class discriminability. Experimental results show that our proposed GeT\nis effective and achieves consistent improvements under various DA settings\nwith and without class distribution bias. Our code is available at:\nhttps://lulusindazc.github.io/getproject/.",
            "author": [
                "Can Zhang",
                "Gim Hee Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10205v1",
                "http://arxiv.org/pdf/2308.10205v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10201v1",
            "title": "Hiding Backdoors within Event Sequence Data via Poisoning Attacks",
            "updated": "2023-08-20T08:27:42Z",
            "published": "2023-08-20T08:27:42Z",
            "summary": "The financial industry relies on deep learning models for making important\ndecisions. This adoption brings new danger, as deep black-box models are known\nto be vulnerable to adversarial attacks. In computer vision, one can shape the\noutput during inference by performing an adversarial attack called poisoning\nvia introducing a backdoor into the model during training. For sequences of\nfinancial transactions of a customer, insertion of a backdoor is harder to\nperform, as models operate over a more complex discrete space of sequences, and\nsystematic checks for insecurities occur. We provide a method to introduce\nconcealed backdoors, creating vulnerabilities without altering their\nfunctionality for uncontaminated data. To achieve this, we replace a clean\nmodel with a poisoned one that is aware of the availability of a backdoor and\nutilize this knowledge. Our most difficult for uncovering attacks include\neither additional supervised detection step of poisoned data activated during\nthe test or well-hidden model weight modifications. The experimental study\nprovides insights into how these effects vary across different datasets,\narchitectures, and model components. Alternative methods and baselines, such as\ndistillation-type regularization, are also explored but found to be less\nefficient. Conducted on three open transaction datasets and architectures,\nincluding LSTM, CNN, and Transformer, our findings not only illuminate the\nvulnerabilities in contemporary models but also can drive the construction of\nmore robust systems.",
            "author": [
                "Elizaveta Kovtun",
                "Alina Ermilova",
                "Dmitry Berestnev",
                "Alexey Zaytsev"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10201v1",
                "http://arxiv.org/pdf/2308.10201v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10197v1",
            "title": "Generating Preferential Attachment Graphs via a P\u00f3lya Urn with\n  Expanding Colors",
            "updated": "2023-08-20T08:06:47Z",
            "published": "2023-08-20T08:06:47Z",
            "summary": "We introduce a novel preferential attachment model using the draw variables\nof a modified P\\'olya urn with an expanding number of colors, notably capable\nof modeling influential opinions (in terms of vertices of high degree) as the\ngraph evolves. Similar to the Barab\\'asi-Albert model, the generated graph\ngrows in size by one vertex at each time instance; in contrast however, each\nvertex of the graph is uniquely characterized by a color, which is represented\nby a ball color in the P\\'olya urn. More specifically at each time step, we\ndraw a ball from the urn and return it to the urn along with a number\n(potentially time-varying and non-integer) of reinforcing balls of the same\ncolor; we also add another ball of a new color to the urn. We then construct an\nedge between the new vertex (corresponding to the new color) and the existing\nvertex whose color ball is drawn. Using color-coded vertices in conjunction\nwith the time-varying reinforcing parameter allows for vertices added (born)\nlater in the process to potentially attain a high degree in a way that is not\ncaptured in the Barab\\'asi-Albert model. We study the degree count of the\nvertices by analyzing the draw vectors of the underlying stochastic process. In\nparticular, we establish the probability distribution of the random variable\ncounting the number of draws of a given color which determines the degree of\nthe vertex corresponding to that color in the graph. We further provide\nsimulation results presenting a comparison between our model and the\nBarab\\'asi-Albert network.",
            "author": [
                "Somya Singh",
                "Fady Alajaji",
                "Bahman Gharesifard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10197v1",
                "http://arxiv.org/pdf/2308.10197v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10185v1",
            "title": "ViT-Lens: Towards Omni-modal Representations",
            "updated": "2023-08-20T07:26:51Z",
            "published": "2023-08-20T07:26:51Z",
            "summary": "Though the success of CLIP-based training recipes in vision-language models,\ntheir scalability to more modalities (e.g., 3D, audio, etc.) is limited to\nlarge-scale data, which is expensive or even inapplicable for rare modalities.\nIn this paper, we present ViT-Lens that facilitates efficient omni-modal\nrepresentation learning by perceiving novel modalities with a pretrained ViT\nand aligning to a pre-defined space. Specifically, the modality-specific lens\nis tuned to project multimodal signals to the shared embedding space, which are\nthen processed by a strong ViT that carries pre-trained image knowledge. The\nencoded multimodal representations are optimized toward aligning with the\nmodal-independent space, pre-defined by off-the-shelf foundation models. A\nwell-trained lens with a ViT backbone has the potential to serve as one of\nthese foundation models, supervising the learning of subsequent modalities.\nViT-Lens provides a unified solution for representation learning of increasing\nmodalities with two appealing benefits: (i) Exploiting the pretrained ViT\nacross tasks and domains effectively with efficient data regime; (ii) Emergent\ndownstream capabilities of novel modalities are demonstrated due to the\nmodality alignment space. We evaluate ViT-Lens in the context of 3D as an\ninitial verification. In zero-shot 3D classification, ViT-Lens achieves\nsubstantial improvements over previous state-of-the-art, showing 52.0% accuracy\non Objaverse-LVIS, 87.4% on ModelNet40, and 60.6% on ScanObjectNN. Furthermore,\nwe enable zero-shot 3D question-answering by simply integrating the trained 3D\nlens into the InstructBLIP model without any adaptation. We will release the\nresults of ViT-Lens on more modalities in the near future.",
            "author": [
                "Weixian Lei",
                "Yixiao Ge",
                "Jianfeng Zhang",
                "Dylan Sun",
                "Kun Yi",
                "Ying Shan",
                "Mike Zheng Shou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10185v1",
                "http://arxiv.org/pdf/2308.10185v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10178v1",
            "title": "Eventually-Consistent Federated Scheduling for Data Center Workloads",
            "updated": "2023-08-20T06:56:33Z",
            "published": "2023-08-20T06:56:33Z",
            "summary": "Data center schedulers operate at unprecedented scales today to accommodate\nthe growing demand for computing and storage power. The challenge that\nschedulers face is meeting the requirements of scheduling speeds despite the\nscale. To do so, most scheduler architectures use parallelism. However, these\narchitectures consist of multiple parallel scheduling entities that can only\nutilize partial knowledge of the data center's state, as maintaining consistent\nglobal knowledge or state would involve considerable communication overhead.\nThe disadvantage of scheduling without global knowledge is sub-optimal\nplacements-tasks may be made to wait in queues even though there are resources\navailable in zones outside the scope of the scheduling entity's state. This\nleads to unnecessary queuing overheads and lower resource utilization of the\ndata center. In this paper, extend our previous work on Megha, a federated\ndecentralized data center scheduling architecture that uses eventual\nconsistency. The architecture utilizes both parallelism and an\neventually-consistent global state in each of its scheduling entities to make\nfast decisions in a scalable manner. In our work, we compare Megha with 3\nscheduling architectures: Sparrow, Eagle, and Pigeon, using simulation. We also\nevaluate Megha's prototype on a 123-node cluster and compare its performance\nwith Pigeon's prototype using cluster traces. The results of our experiments\nshow that Megha consistently reduces delays in job completion time when\ncompared to other architectures.",
            "author": [
                "Meghana Thiyyakat",
                "Subramaniam Kalambur",
                "Rishit Chaudhary",
                "Saurav G Nayak",
                "Adarsh Shetty",
                "Dinkar Sitaram"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10178v1",
                "http://arxiv.org/pdf/2308.10178v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10175v1",
            "title": "BAVS: Bootstrapping Audio-Visual Segmentation by Integrating Foundation\n  Knowledge",
            "updated": "2023-08-20T06:48:08Z",
            "published": "2023-08-20T06:48:08Z",
            "summary": "Given an audio-visual pair, audio-visual segmentation (AVS) aims to locate\nsounding sources by predicting pixel-wise maps. Previous methods assume that\neach sound component in an audio signal always has a visual counterpart in the\nimage. However, this assumption overlooks that off-screen sounds and background\nnoise often contaminate the audio recordings in real-world scenarios. They\nimpose significant challenges on building a consistent semantic mapping between\naudio and visual signals for AVS models and thus impede precise sound\nlocalization. In this work, we propose a two-stage bootstrapping audio-visual\nsegmentation framework by incorporating multi-modal foundation knowledge. In a\nnutshell, our BAVS is designed to eliminate the interference of background\nnoise or off-screen sounds in segmentation by establishing the audio-visual\ncorrespondences in an explicit manner. In the first stage, we employ a\nsegmentation model to localize potential sounding objects from visual data\nwithout being affected by contaminated audio signals. Meanwhile, we also\nutilize a foundation audio classification model to discern audio semantics.\nConsidering the audio tags provided by the audio foundation model are noisy,\nassociating object masks with audio tags is not trivial. Thus, in the second\nstage, we develop an audio-visual semantic integration strategy (AVIS) to\nlocalize the authentic-sounding objects. Here, we construct an audio-visual\ntree based on the hierarchical correspondence between sounds and object\ncategories. We then examine the label concurrency between the localized objects\nand classified audio tags by tracing the audio-visual tree. With AVIS, we can\neffectively segment real-sounding objects. Extensive experiments demonstrate\nthe superiority of our method on AVS datasets, particularly in scenarios\ninvolving background noise. Our project website is\nhttps://yenanliu.github.io/AVSS.github.io/.",
            "author": [
                "Chen Liu",
                "Peike Li",
                "Hu Zhang",
                "Lincheng Li",
                "Zi Huang",
                "Dadong Wang",
                "Xin Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10175v1",
                "http://arxiv.org/pdf/2308.10175v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10173v1",
            "title": "FoodGPT: A Large Language Model in Food Testing Domain with Incremental\n  Pre-training and Knowledge Graph Prompt",
            "updated": "2023-08-20T05:58:33Z",
            "published": "2023-08-20T05:58:33Z",
            "summary": "Currently, the construction of large language models in specific domains is\ndone by fine-tuning on a base model. Some models also incorporate knowledge\nbases without the need for pre-training. This is because the base model already\ncontains domain-specific knowledge during the pre-training process. We build a\nlarge language model for food testing. Unlike the above approach, a significant\namount of data in this domain exists in Scanning format for domain standard\ndocuments. In addition, there is a large amount of untrained structured\nknowledge. Therefore, we introduce an incremental pre-training step to inject\nthis knowledge into a large language model. In this paper, we propose a method\nfor handling structured knowledge and scanned documents in incremental\npre-training. To overcome the problem of machine hallucination, we constructe a\nknowledge graph to serve as an external knowledge base for supporting retrieval\nin the large language model. It is worth mentioning that this paper is a\ntechnical report of our pre-release version, and we will report our specific\nexperimental data in future versions.",
            "author": [
                "Zhixiao Qi",
                "Yijiong Yu",
                "Meiqi Tu",
                "Junyi Tan",
                "Yongfeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10173v1",
                "http://arxiv.org/pdf/2308.10173v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10172v1",
            "title": "VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language\n  Navigation",
            "updated": "2023-08-20T05:55:30Z",
            "published": "2023-08-20T05:55:30Z",
            "summary": "The performance of the Vision-and-Language Navigation~(VLN) tasks has\nwitnessed rapid progress recently thanks to the use of large pre-trained\nvision-and-language models. However, full fine-tuning the pre-trained model for\nevery downstream VLN task is becoming costly due to the considerable model\nsize. Recent research hotspot of Parameter-Efficient Transfer Learning (PETL)\nshows great potential in efficiently tuning large pre-trained models for the\ncommon CV and NLP tasks, which exploits the most of the representation\nknowledge implied in the pre-trained model while only tunes a minimal set of\nparameters. However, simply utilizing existing PETL methods for the more\nchallenging VLN tasks may bring non-trivial degeneration to the performance.\nTherefore, we present the first study to explore PETL methods for VLN tasks and\npropose a VLN-specific PETL method named VLN-PETL. Specifically, we design two\nPETL modules: Historical Interaction Booster (HIB) and Cross-modal Interaction\nBooster (CIB). Then we combine these two modules with several existing PETL\nmethods as the integrated VLN-PETL. Extensive experimental results on four\nmainstream VLN tasks (R2R, REVERIE, NDH, RxR) demonstrate the effectiveness of\nour proposed VLN-PETL, where VLN-PETL achieves comparable or even better\nperformance to full fine-tuning and outperforms other PETL methods with\npromising margins.",
            "author": [
                "Yanyuan Qiao",
                "Zheng Yu",
                "Qi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10172v1",
                "http://arxiv.org/pdf/2308.10172v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10168v1",
            "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A.\n  Will LLMs Replace Knowledge Graphs?",
            "updated": "2023-08-20T05:31:03Z",
            "published": "2023-08-20T05:31:03Z",
            "summary": "Since the recent prosperity of Large Language Models (LLMs), there have been\ninterleaved discussions regarding how to reduce hallucinations from LLM\nresponses, how to increase the factuality of LLMs, and whether Knowledge Graphs\n(KGs), which store the world knowledge in a symbolic form, will be replaced\nwith LLMs. In this paper, we try to answer these questions from a new angle:\nHow knowledgeable are LLMs?\n  To answer this question, we constructed Head-to-Tail, a benchmark that\nconsists of 18K question-answer (QA) pairs regarding head, torso, and tail\nfacts in terms of popularity. We designed an automated evaluation method and a\nset of metrics that closely approximate the knowledge an LLM confidently\ninternalizes. Through a comprehensive evaluation of 14 publicly available LLMs,\nwe show that existing LLMs are still far from being perfect in terms of their\ngrasp of factual knowledge, especially for facts of torso-to-tail entities.",
            "author": [
                "Kai Sun",
                "Yifan Ethan Xu",
                "Hanwen Zha",
                "Yue Liu",
                "Xin Luna Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10168v1",
                "http://arxiv.org/pdf/2308.10168v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10166v1",
            "title": "Cell Spatial Analysis in Crohn's Disease: Unveiling Local Cell\n  Arrangement Pattern with Graph-based Signatures",
            "updated": "2023-08-20T05:26:25Z",
            "published": "2023-08-20T05:26:25Z",
            "summary": "Crohn's disease (CD) is a chronic and relapsing inflammatory condition that\naffects segments of the gastrointestinal tract. CD activity is determined by\nhistological findings, particularly the density of neutrophils observed on\nHematoxylin and Eosin stains (H&E) imaging. However, understanding the broader\nmorphometry and local cell arrangement beyond cell counting and tissue\nmorphology remains challenging. To address this, we characterize six distinct\ncell types from H&E images and develop a novel approach for the local spatial\nsignature of each cell. Specifically, we create a 10-cell neighborhood matrix,\nrepresenting neighboring cell arrangements for each individual cell. Utilizing\nt-SNE for non-linear spatial projection in scatter-plot and Kernel Density\nEstimation contour-plot formats, our study examines patterns of differences in\nthe cellular environment associated with the odds ratio of spatial patterns\nbetween active CD and control groups. This analysis is based on data collected\nat the two research institutes. The findings reveal heterogeneous\nnearest-neighbor patterns, signifying distinct tendencies of cell clustering,\nwith a particular focus on the rectum region. These variations underscore the\nimpact of data heterogeneity on cell spatial arrangements in CD patients.\nMoreover, the spatial distribution disparities between the two research sites\nhighlight the significance of collaborative efforts among healthcare\norganizations. All research analysis pipeline tools are available at\nhttps://github.com/MASILab/cellNN.",
            "author": [
                "Shunxing Bao",
                "Sichen Zhu",
                "Vasantha L Kolachala",
                "Lucas W. Remedios",
                "Yeonjoo Hwang",
                "Yutong Sun",
                "Ruining Deng",
                "Can Cui",
                "Yike Li",
                "Jia Li",
                "Joseph T. Roland",
                "Qi Liu",
                "Ken S. Lau",
                "Subra Kugathasan",
                "Peng Qiu",
                "Keith T. Wilson",
                "Lori A. Coburn",
                "Bennett A. Landman",
                "Yuankai Huo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10166v1",
                "http://arxiv.org/pdf/2308.10166v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10162v1",
            "title": "Rethinking Client Drift in Federated Learning: A Logit Perspective",
            "updated": "2023-08-20T04:41:01Z",
            "published": "2023-08-20T04:41:01Z",
            "summary": "Federated Learning (FL) enables multiple clients to collaboratively learn in\na distributed way, allowing for privacy protection. However, the real-world\nnon-IID data will lead to client drift which degrades the performance of FL.\nInterestingly, we find that the difference in logits between the local and\nglobal models increases as the model is continuously updated, thus seriously\ndeteriorating FL performance. This is mainly due to catastrophic forgetting\ncaused by data heterogeneity between clients. To alleviate this problem, we\npropose a new algorithm, named FedCSD, a Class prototype Similarity\nDistillation in a federated framework to align the local and global models.\nFedCSD does not simply transfer global knowledge to local clients, as an\nundertrained global model cannot provide reliable knowledge, i.e., class\nsimilarity information, and its wrong soft labels will mislead the optimization\nof local models. Concretely, FedCSD introduces a class prototype similarity\ndistillation to align the local logits with the refined global logits that are\nweighted by the similarity between local logits and the global prototype. To\nenhance the quality of global logits, FedCSD adopts an adaptive mask to filter\nout the terrible soft labels of the global models, thereby preventing them to\nmislead local optimization. Extensive experiments demonstrate the superiority\nof our method over the state-of-the-art federated learning approaches in\nvarious heterogeneous settings. The source code will be released.",
            "author": [
                "Yunlu Yan",
                "Chun-Mei Feng",
                "Mang Ye",
                "Wangmeng Zuo",
                "Ping Li",
                "Rick Siow Mong Goh",
                "Lei Zhu",
                "C. L. Philip Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10162v1",
                "http://arxiv.org/pdf/2308.10162v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10160v1",
            "title": "Higher-Order Cheeger Inequality for Partitioning with Buffers",
            "updated": "2023-08-20T04:31:59Z",
            "published": "2023-08-20T04:31:59Z",
            "summary": "We prove a new generalization of the higher-order Cheeger inequality for\npartitioning with buffers. Consider a graph $G=(V,E)$. The buffered expansion\nof a set $S \\subseteq V$ with a buffer $B \\subseteq V \\setminus S$ is the edge\nexpansion of $S$ after removing all the edges from set $S$ to its buffer $B$.\nAn $\\varepsilon$-buffered $k$-partitioning is a partitioning of a graph into\ndisjoint components $P_i$ and buffers $B_i$, in which the size of buffer $B_i$\nfor $P_i$ is small relative to the size of $P_i$: $|B_i| \\le \\varepsilon\n|P_i|$. The buffered expansion of a buffered partition is the maximum of\nbuffered expansions of the $k$ sets $P_i$ with buffers $B_i$. Let\n$h^{k,\\varepsilon}_G$ be the buffered expansion of the optimal\n$\\varepsilon$-buffered $k$-partitioning, then for every $\\delta>0$,\n$$h_G^{k,\\varepsilon} \\le O_\\delta(1) \\cdot \\Big( \\frac{\\log k}{\n\\varepsilon}\\Big) \\cdot \\lambda_{\\lfloor (1+\\delta) k\\rfloor},$$ where\n$\\lambda_{\\lfloor (1+\\delta)k\\rfloor}$ is the $\\lfloor (1+\\delta)k\\rfloor$-th\nsmallest eigenvalue of the normalized Laplacian of $G$.\n  Our inequality is constructive and avoids the ``square-root loss'' that is\npresent in the standard Cheeger inequalities (even for $k=2$). We also provide\na complementary lower bound, and a novel generalization to the setting with\narbitrary vertex weights and edge costs. Moreover our result implies and\ngeneralizes the standard higher-order Cheeger inequalities and another recent\nCheeger-type inequality by Kwok, Lau, and Lee (2017) involving robust vertex\nexpansion.",
            "author": [
                "Konstantin Makarychev",
                "Yury Makarychev",
                "Liren Shan",
                "Aravindan Vijayaraghavan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10160v1",
                "http://arxiv.org/pdf/2308.10160v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10151v1",
            "title": "Box dimension of stable sub-slices of fractal graphs over Anosov\n  diffeomorphisms",
            "updated": "2023-08-20T03:47:02Z",
            "published": "2023-08-20T03:47:02Z",
            "summary": "We consider fractal graphs invariant by a skew product $F:\\mathbb{T}^k\\times\n\\mathbb{R}\\rightarrow \\mathbb{T}^k\\times \\mathbb{R}$ of the form $F(x,y)=(Ax,\n\\lambda y+p(x))$ where $0<\\lambda<1$, $p\\colon\\mathbb{T}^k\\to\\mathbb{R}$ is a\n$C^{k+1}$ function, and $A$ is an Anosov diffeomorphism of $\\mathbb{T}^k$\nadmitting $k$ distinct eigenvalues with respective eigenvectors forming a basis\nof $\\mathbb{R}^k$. We note that the stable sub-slices can give information of\nthe fractal structure of the graph that is not captured by the box dimension of\nthe graph. Using the results of Kaplan,Mallet-Paret, and York [6], we exhibit\nconditions on the skew product that ensure the box dimension of the graph is\nsmaller than the sum of the box dimensions of its stable/unstable sub-slices.\nWe prove that these conditions hold for generic functions $p\\in C^{k+1}$.",
            "author": [
                "Bernardo Carvalho",
                "Rafael da Costa Pereira"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10151v1",
                "http://arxiv.org/pdf/2308.10151v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "Primary:37D45, Secondary:37D05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10146v1",
            "title": "OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision",
            "updated": "2023-08-20T03:13:17Z",
            "published": "2023-08-20T03:13:17Z",
            "summary": "Hand Pose Estimation (HPE) is crucial to many applications, but conventional\ncameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as\ncameras cannot capture occluded objects. In this paper, we propose to exploit\nRadio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving\noccluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose\nestimation capability. OCHID-Fi employs wideband RF sensors widely available on\nsmart devices (e.g., iPhones) to probe 3D human hand pose and extract their\nskeletons behind obstacles. To overcome the challenge in labeling RF imaging\ngiven its human incomprehensible nature, OCHID-Fi employs a cross-modality and\ncross-domain training process. It uses a pre-trained CM-HPE network and a\nsynchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE\nnetwork under LoS conditions. It further transfers knowledge learned from\nlabeled LoS domain to unlabeled occluded domain via adversarial learning,\nenabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental\nresults demonstrate the superiority of OCHID-Fi: it achieves comparable\naccuracy to CM-HPE under normal conditions while maintaining such accuracy even\nin occluded scenarios, with empirical evidence for its generalizability to new\ndomains.",
            "author": [
                "Shujie Zhang",
                "Tianyue Zheng",
                "Zhe Chen",
                "Jingzhi Hu",
                "Abdelwahed Khamis",
                "Jiajun Liu",
                "Jun Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10146v1",
                "http://arxiv.org/pdf/2308.10146v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10144v1",
            "title": "ExpeL: LLM Agents Are Experiential Learners",
            "updated": "2023-08-20T03:03:34Z",
            "published": "2023-08-20T03:03:34Z",
            "summary": "The recent surge in research interest in applying large language models\n(LLMs) to decision-making tasks has flourished by leveraging the extensive\nworld knowledge embedded in LLMs. While there is a growing demand to tailor\nLLMs for custom decision-making tasks, finetuning them for specific tasks is\nresource-intensive and may diminish the model's generalization capabilities.\nMoreover, state-of-the-art language models like GPT-4 and Claude are primarily\naccessible through API calls, with their parametric weights remaining\nproprietary and unavailable to the public. This scenario emphasizes the growing\nneed for new methodologies that allow learning from agent experiences without\nrequiring parametric updates. To address these problems, we introduce the\nExperiential Learning (ExpeL) agent. Our agent autonomously gathers experiences\nand extracts knowledge using natural language from a collection of training\ntasks. At inference, the agent recalls its extracted insights and past\nexperiences to make informed decisions. Our empirical results highlight the\nrobust learning efficacy of the ExpeL agent, indicating a consistent\nenhancement in its performance as it accumulates experiences. We further\nexplore the emerging capabilities and transfer learning potential of the ExpeL\nagent through qualitative observations and additional experiments.",
            "author": [
                "Andrew Zhao",
                "Daniel Huang",
                "Quentin Xu",
                "Matthieu Lin",
                "Yong-Jin Liu",
                "Gao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10144v1",
                "http://arxiv.org/pdf/2308.10144v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10142v1",
            "title": "Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map\n  Prediction",
            "updated": "2023-08-20T03:00:27Z",
            "published": "2023-08-20T03:00:27Z",
            "summary": "Recently, deep learning (DL) has automated and accelerated the clinical\nradiation therapy (RT) planning significantly by predicting accurate dose maps.\nHowever, most DL-based dose map prediction methods are data-driven and not\napplicable for cervical cancer where only a small amount of data is available.\nTo address this problem, this paper proposes to transfer the rich knowledge\nlearned from another cancer, i.e., rectum cancer, which has the same scanning\narea and more clinically available data, to improve the dose map prediction\nperformance for cervical cancer through domain adaptation. In order to close\nthe congenital domain gap between the source (i.e., rectum cancer) and the\ntarget (i.e., cervical cancer) domains, we develop an effective\nTransformer-based polymerized feature module (PFM), which can generate an\noptimal polymerized feature distribution to smoothly align the two input\ndistributions. Experimental results on two in-house clinical datasets\ndemonstrate the superiority of the proposed method compared with\nstate-of-the-art methods.",
            "author": [
                "Jie Zeng",
                "Zeyu Han",
                "Xingchen Peng",
                "Jianghong Xiao",
                "Peng Wang",
                "Yan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10142v1",
                "http://arxiv.org/pdf/2308.10142v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10135v1",
            "title": "A Review on Objective-Driven Artificial Intelligence",
            "updated": "2023-08-20T02:07:42Z",
            "published": "2023-08-20T02:07:42Z",
            "summary": "While advancing rapidly, Artificial Intelligence still falls short of human\nintelligence in several key aspects due to inherent limitations in current AI\ntechnologies and our understanding of cognition. Humans have an innate ability\nto understand context, nuances, and subtle cues in communication, which allows\nus to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret\nsuch contextual information accurately. Humans possess a vast repository of\ncommon-sense knowledge that helps us make logical inferences and predictions\nabout the world. Machines lack this innate understanding and often struggle\nwith making sense of situations that humans find trivial. In this article, we\nreview the prospective Machine Intelligence candidates, a review from Prof.\nYann LeCun, and other work that can help close this gap between human and\nmachine intelligence. Specifically, we talk about what's lacking with the\ncurrent AI techniques such as supervised learning, reinforcement learning,\nself-supervised learning, etc. Then we show how Hierarchical planning-based\napproaches can help us close that gap and deep-dive into energy-based,\nlatent-variable methods and Joint embedding predictive architecture methods.",
            "author": [
                "Apoorv Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10135v1",
                "http://arxiv.org/pdf/2308.10135v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10128v2",
            "title": "Forward-Forward Mean Field Games in mathematical modeling with\n  application to opinion formation and voting models",
            "updated": "2023-09-11T22:34:59Z",
            "published": "2023-08-20T01:24:44Z",
            "summary": "While the general theory for the terminal-initial value problem in mean-field\ngames is widely used in many models of applied mathematics, the modeling\npotential of the corresponding forward-forward version is still\nunder-considered. In this work, we study the well-posedness of the problem in a\nquite general setting and explain how it is appropriate to model a system of\nplayers that have a complete knowledge of the past states of the system and are\nadapting to new information without any knowledge about the future. Then we\nshow how forward-forward mean field games can be effectively used in\nmathematical models for opinion formation and other social phenomena.",
            "author": [
                "Adriano Festa",
                "Simone Gottlich",
                "Michele Ricciardi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10128v2",
                "http://arxiv.org/pdf/2308.10128v2"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10122v1",
            "title": "HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision\n  Mitigation",
            "updated": "2023-08-19T22:28:17Z",
            "published": "2023-08-19T22:28:17Z",
            "summary": "Neural radiance fields (NeRF) have garnered significant attention, with\nrecent works such as Instant-NGP accelerating NeRF training and evaluation\nthrough a combination of hashgrid-based positional encoding and neural\nnetworks. However, effectively leveraging the spatial sparsity of 3D scenes\nremains a challenge. To cull away unnecessary regions of the feature grid,\nexisting solutions rely on prior knowledge of object shape or periodically\nestimate object shape during training by repeated model evaluations, which are\ncostly and wasteful.\n  To address this issue, we propose HollowNeRF, a novel compression solution\nfor hashgrid-based NeRF which automatically sparsifies the feature grid during\nthe training phase. Instead of directly compressing dense features, HollowNeRF\ntrains a coarse 3D saliency mask that guides efficient feature pruning, and\nemploys an alternating direction method of multipliers (ADMM) pruner to\nsparsify the 3D saliency mask during training. By exploiting the sparsity in\nthe 3D scene to redistribute hash collisions, HollowNeRF improves rendering\nquality while using a fraction of the parameters of comparable state-of-the-art\nsolutions, leading to a better cost-accuracy trade-off. Our method delivers\ncomparable rendering quality to Instant-NGP, while utilizing just 31% of the\nparameters. In addition, our solution can achieve a PSNR accuracy gain of up to\n1dB using only 56% of the parameters.",
            "author": [
                "Xiufeng Xie",
                "Riccardo Gherardi",
                "Zhihong Pan",
                "Stephen Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10122v1",
                "http://arxiv.org/pdf/2308.10122v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10109v1",
            "title": "Unbiased Library of k-regular, n-sized, Connected, Small Graphs",
            "updated": "2023-08-19T20:57:00Z",
            "published": "2023-08-19T20:57:00Z",
            "summary": "The past decade highlighted the usefulness of social network simulations that\nrun on k-regular, n-size, connected graphs. These can be seen as small-scale\nmodels of human social networks of large societies. By narrowing down onto\nk-regular graphs, the degree variation can be eliminated from the research\nquestion, which allows a focus on the isolated impact by other variables, for\ninstance, by the clustering coefficient or the size of the network. This paper\ndescribes the generation of a random graph library that uses a random walk\ngraph creation algorithm that starts from the \"chain of caves\", which is the\nstructure in which the clustering coefficient is at its maximum. This method\nfinds mid and high clustering coefficient graphs, while Wolfram`s RandomGraph\nwas useful for finding low ones. The merge of the two samples proved to be\nsomewhat biased. After eliminating a host of network measures, the paper\nfocused on mean graph distance as a further variable and created an unbiased\nsubsample for each size and clustering coefficient bin.",
            "author": [
                "Tamas David-Barrett"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10109v1",
                "http://arxiv.org/pdf/2308.10109v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10099v2",
            "title": "Geometric instability of graph neural networks on large graphs",
            "updated": "2023-11-28T10:35:06Z",
            "published": "2023-08-19T20:10:54Z",
            "summary": "We analyse the geometric instability of embeddings produced by graph neural\nnetworks (GNNs). Existing methods are only applicable for small graphs and lack\ncontext in the graph domain. We propose a simple, efficient and graph-native\nGraph Gram Index (GGI) to measure such instability which is invariant to\npermutation, orthogonal transformation, translation and order of evaluation.\nThis allows us to study the varying instability behaviour of GNN embeddings on\nlarge graphs for both node classification and link prediction.",
            "author": [
                "Emily Morris",
                "Haotian Shen",
                "Weiling Du",
                "Muhammad Hamza Sajjad",
                "Borun Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10099v2",
                "http://arxiv.org/pdf/2308.10099v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10093v1",
            "title": "Securing Pathways with Orthogonal Robots",
            "updated": "2023-08-19T19:05:13Z",
            "published": "2023-08-19T19:05:13Z",
            "summary": "The protection of pathways holds immense significance across various domains,\nincluding urban planning, transportation, surveillance, and security. This\narticle introduces a groundbreaking approach to safeguarding pathways by\nemploying orthogonal robots. The study specifically addresses the challenge of\nefficiently guarding orthogonal areas with the minimum number of orthogonal\nrobots. The primary focus is on orthogonal pathways, characterized by a\npath-like dual graph of vertical decomposition. It is demonstrated that\ndetermining the minimum number of orthogonal robots for pathways can be\nachieved in linear time. However, it is essential to note that the general\nproblem of finding the minimum number of robots for simple polygons with\ngeneral visibility, even in the orthogonal case, is known to be NP-hard.\nEmphasis is placed on the flexibility of placing robots anywhere within the\npolygon, whether on the boundary or in the interior.",
            "author": [
                "Hamid Hoorfar",
                "Faraneh Fathi",
                "Sara Moshtaghi Largani",
                "Alireza Bagheri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10093v1",
                "http://arxiv.org/pdf/2308.10093v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10087v2",
            "title": "GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism",
            "updated": "2023-09-24T17:04:05Z",
            "published": "2023-08-19T18:44:14Z",
            "summary": "Communication is a key bottleneck for distributed graph neural network (GNN)\ntraining. This paper proposes GNNPipe, a new approach that scales the\ndistributed full-graph deep GNN training. Being the first to use layer-level\nmodel parallelism for GNN training, GNNPipe partitions GNN layers among GPUs,\neach device performs the computation for a disjoint subset of consecutive GNN\nlayers on the whole graph. Compared to graph parallelism with each GPU handling\na graph partition, GNNPipe reduces the communication volume by a factor of the\nnumber of GNN layers. GNNPipe overcomes the unique challenges for pipelined\nlayer-level model parallelism on the whole graph by partitioning it into\ndependent chunks, allowing the use of historical vertex embeddings, and\napplying specific training techniques to ensure convergence. We also propose a\nhybrid approach by combining GNNPipe with graph parallelism to handle large\ngraphs, achieve better computer resource utilization and ensure model\nconvergence. We build a general GNN training system supporting all three\nparallelism setting. Extensive experiments show that our method reduces the\nper-epoch training time by up to 2.45x (on average 1.58x) and reduces the\ncommunication volume and overhead by up to 22.89x and 27.21x (on average 8.69x\nand 11.60x), respectively, while achieving a comparable level of model accuracy\nand convergence speed compared to graph parallelism.",
            "author": [
                "Jingji Chen",
                "Zhuoming Chen",
                "Xuehai Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10087v2",
                "http://arxiv.org/pdf/2308.10087v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10077v1",
            "title": "Contrastive Learning for Non-Local Graphs with Multi-Resolution\n  Structural Views",
            "updated": "2023-08-19T17:42:02Z",
            "published": "2023-08-19T17:42:02Z",
            "summary": "Learning node-level representations of heterophilic graphs is crucial for\nvarious applications, including fraudster detection and protein function\nprediction. In such graphs, nodes share structural similarity identified by the\nequivalence of their connectivity which is implicitly encoded in the form of\nhigher-order hierarchical information in the graphs. The contrastive methods\nare popular choices for learning the representation of nodes in a graph.\nHowever, existing contrastive methods struggle to capture higher-order graph\nstructures. To address this limitation, we propose a novel multiview\ncontrastive learning approach that integrates diffusion filters on graphs. By\nincorporating multiple graph views as augmentations, our method captures the\nstructural equivalence in heterophilic graphs, enabling the discovery of hidden\nrelationships and similarities not apparent in traditional node\nrepresentations. Our approach outperforms baselines on synthetic and real\nstructural datasets, surpassing the best baseline by $16.06\\%$ on Cornell,\n$3.27\\%$ on Texas, and $8.04\\%$ on Wisconsin. Additionally, it consistently\nachieves superior performance on proximal tasks, demonstrating its\neffectiveness in uncovering structural information and improving downstream\napplications.",
            "author": [
                "Asif Khan",
                "Amos Storkey"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10077v1",
                "http://arxiv.org/pdf/2308.10077v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11592v2",
            "title": "UniDoc: A Universal Large Multimodal Model for Simultaneous Text\n  Detection, Recognition, Spotting and Understanding",
            "updated": "2023-09-02T04:28:42Z",
            "published": "2023-08-19T17:32:34Z",
            "summary": "In the era of Large Language Models (LLMs), tremendous strides have been made\nin the field of multimodal understanding. However, existing advanced algorithms\nare limited to effectively utilizing the immense representation capabilities\nand rich world knowledge inherent to these large pre-trained models, and the\nbeneficial connections among tasks within the context of text-rich scenarios\nhave not been sufficiently explored. In this work, we introduce UniDoc, a novel\nmultimodal model equipped with text detection and recognition capabilities,\nwhich are deficient in existing approaches. Moreover, UniDoc capitalizes on the\nbeneficial interactions among tasks to enhance the performance of each\nindividual task. To implement UniDoc, we perform unified multimodal instruct\ntuning on the contributed large-scale instruction following datasets.\nQuantitative and qualitative experimental results show that UniDoc sets\nstate-of-the-art scores across multiple challenging benchmarks. To the best of\nour knowledge, this is the first large multimodal model capable of simultaneous\ntext detection, recognition, spotting, and understanding.",
            "author": [
                "Hao Feng",
                "Zijian Wang",
                "Jingqun Tang",
                "Jinghui Lu",
                "Wengang Zhou",
                "Houqiang Li",
                "Can Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11592v2",
                "http://arxiv.org/pdf/2308.11592v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11652v1",
            "title": "Accelerating Exact Combinatorial Optimization via RL-based\n  Initialization -- A Case Study in Scheduling",
            "updated": "2023-08-19T15:52:43Z",
            "published": "2023-08-19T15:52:43Z",
            "summary": "Scheduling on dataflow graphs (also known as computation graphs) is an\nNP-hard problem. The traditional exact methods are limited by runtime\ncomplexity, while reinforcement learning (RL) and heuristic-based approaches\nstruggle with determinism and solution quality. This research aims to develop\nan innovative approach that employs machine learning (ML) for addressing\ncombinatorial optimization problems, using scheduling as a case study. The goal\nis to provide guarantees in optimality and determinism while maintaining the\nruntime cost of heuristic methods. Specifically, we introduce a novel two-phase\nRL-to-ILP scheduling framework, which includes three steps: 1) RL solver acts\nas coarse-grain scheduler, 2) solution relaxation and 3) exact solving via ILP.\nOur framework demonstrates the same scheduling performance compared with using\nexact scheduling methods while achieving up to 128 $\\times$ speed improvements.\nThis was conducted on actual EdgeTPU platforms, utilizing ImageNet DNN\ncomputation graphs as input. Additionally, the framework offers improved\non-chip inference runtime and acceleration compared to the commercially\navailable EdgeTPU compiler.",
            "author": [
                "Jiaqi Yin",
                "Cunxi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11652v1",
                "http://arxiv.org/pdf/2308.11652v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10051v1",
            "title": "The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive\n  field",
            "updated": "2023-08-19T15:21:12Z",
            "published": "2023-08-19T15:21:12Z",
            "summary": "Despite Graph Neural Networks demonstrating considerable promise in graph\nrepresentation learning tasks, GNNs predominantly face significant issues with\nover-fitting and over-smoothing as they go deeper as models of computer vision\nrealm. In this work, we conduct a systematic study of deeper GNN research\ntrajectories. Our findings indicate that the current success of deep GNNs\nprimarily stems from (I) the adoption of innovations from CNNs, such as\nresidual/skip connections, or (II) the tailor-made aggregation algorithms like\nDropEdge. However, these algorithms often lack intrinsic interpretability and\nindiscriminately treat all nodes within a given layer in a similar manner,\nthereby failing to capture the nuanced differences among various nodes. To this\nend, we introduce the Snowflake Hypothesis -- a novel paradigm underpinning the\nconcept of ``one node, one receptive field''. The hypothesis draws inspiration\nfrom the unique and individualistic patterns of each snowflake, proposing a\ncorresponding uniqueness in the receptive fields of nodes in the GNNs.\n  We employ the simplest gradient and node-level cosine distance as guiding\nprinciples to regulate the aggregation depth for each node, and conduct\ncomprehensive experiments including: (1) different training schemes; (2)\nvarious shallow and deep GNN backbones, and (3) various numbers of layers (8,\n16, 32, 64) on multiple benchmarks (six graphs including dense graphs with\nmillions of nodes); (4) compare with different aggregation strategies. The\nobservational results demonstrate that our hypothesis can serve as a universal\noperator for a range of tasks, and it displays tremendous potential on deep\nGNNs. It can be applied to various GNN frameworks, enhancing its effectiveness\nwhen operating in-depth, and guiding the selection of the optimal network depth\nin an explainable and generalizable way.",
            "author": [
                "Kun Wang",
                "Guohao Li",
                "Shilong Wang",
                "Guibin Zhang",
                "Kai Wang",
                "Yang You",
                "Xiaojiang Peng",
                "Yuxuan Liang",
                "Yang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10051v1",
                "http://arxiv.org/pdf/2308.10051v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10047v2",
            "title": "Towards Probabilistic Causal Discovery, Inference & Explanations for\n  Autonomous Drones in Mine Surveying Tasks",
            "updated": "2023-10-01T14:42:17Z",
            "published": "2023-08-19T15:12:55Z",
            "summary": "Causal modelling offers great potential to provide autonomous agents the\nability to understand the data-generation process that governs their\ninteractions with the world. Such models capture formal knowledge as well as\nprobabilistic representations of noise and uncertainty typically encountered by\nautonomous robots in real-world environments. Thus, causality can aid\nautonomous agents in making decisions and explaining outcomes, but deploying\ncausality in such a manner introduces new challenges. Here we identify\nchallenges relating to causality in the context of a drone system operating in\na salt mine. Such environments are challenging for autonomous agents because of\nthe presence of confounders, non-stationarity, and a difficulty in building\ncomplete causal models ahead of time. To address these issues, we propose a\nprobabilistic causal framework consisting of: causally-informed POMDP planning,\nonline SCM adaptation, and post-hoc counterfactual explanations. Further, we\noutline planned experimentation to evaluate the framework integrated with a\ndrone system in simulated mine environments and on a real-world mine dataset.",
            "author": [
                "Ricardo Cannizzaro",
                "Rhys Howard",
                "Paulina Lewinska",
                "Lars Kunze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10047v2",
                "http://arxiv.org/pdf/2308.10047v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "I.2.9; I.2.6; G.3; I.6.3; I.2.8; J.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13474v1",
            "title": "OCTAL: Graph Representation Learning for LTL Model Checking",
            "updated": "2023-08-19T15:11:18Z",
            "published": "2023-08-19T15:11:18Z",
            "summary": "Model Checking is widely applied in verifying the correctness of complex and\nconcurrent systems against a specification. Pure symbolic approaches while\npopular, suffer from the state space explosion problem due to cross product\noperations required that make them prohibitively expensive for large-scale\nsystems and/or specifications. In this paper, we propose to use graph\nrepresentation learning (GRL) for solving linear temporal logic (LTL) model\nchecking, where the system and the specification are expressed by a B{\\\"u}chi\nautomaton and an LTL formula, respectively. A novel GRL-based framework \\model,\nis designed to learn the representation of the graph-structured system and\nspecification, which reduces the model checking problem to binary\nclassification. Empirical experiments on two model checking scenarios show that\n\\model achieves promising accuracy, with up to $11\\times$ overall speedup\nagainst canonical SOTA model checkers and $31\\times$ for satisfiability\nchecking alone.",
            "author": [
                "Prasita Mukherjee",
                "Haoteng Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13474v1",
                "http://arxiv.org/pdf/2308.13474v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10028v2",
            "title": "Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural\n  Networks",
            "updated": "2023-08-30T06:33:32Z",
            "published": "2023-08-19T14:25:59Z",
            "summary": "Voucher abuse detection is an important anomaly detection problem in\nE-commerce. While many GNN-based solutions have emerged, the supervised\nparadigm depends on a large quantity of labeled data. A popular alternative is\nto adopt self-supervised pre-training using label-free data, and further\nfine-tune on a downstream task with limited labels. Nevertheless, the\n\"pre-train, fine-tune\" paradigm is often plagued by the objective gap between\npre-training and downstream tasks. Hence, we propose VPGNN, a prompt-based\nfine-tuning framework on GNNs for voucher abuse detection. We design a novel\ngraph prompting function to reformulate the downstream task into a similar\ntemplate as the pretext task in pre-training, thereby narrowing the objective\ngap. Extensive experiments on both proprietary and public datasets demonstrate\nthe strength of VPGNN in both few-shot and semi-supervised scenarios. Moreover,\nan online deployment of VPGNN in a production environment shows a 23.4%\nimprovement over two existing deployed models.",
            "author": [
                "Zhihao Wen",
                "Yuan Fang",
                "Yihan Liu",
                "Yang Guo",
                "Shuji Hao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615505",
                "http://arxiv.org/abs/2308.10028v2",
                "http://arxiv.org/pdf/2308.10028v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10002v1",
            "title": "Existence of Solutions to a Class of Kazdan-Warner Equations on Finite\n  Graphs",
            "updated": "2023-08-19T12:43:24Z",
            "published": "2023-08-19T12:43:24Z",
            "summary": "Let $G=(V, E)$ be a connected finite graph, $h$ be a positive function on $V$\nand $\\lambda _{1}(V)$ be the first non-zero eigenvalue of $-\\Delta$. For any\ngiven finite measure $\\mu$ on $V$, define functionals \\begin{eqnarray*}\n  J_{ \\beta }(u)&=&\\frac{1}{2}\\int_{V}|\\nabla u|^{2}d \\mu -\\beta\n\\log\\int_{V}he^{u}d \\mu,\n  J_{ \\alpha ,\\beta }(u)&=&\\frac{1}{2}\\int_{V}\\left(|\\nabla u|^{2}- \\alpha\nu^{2}\\right) d \\mu -\\beta \\log\\int_{V}he^{u}d \\mu \\end{eqnarray*} on the\nfunctional space $$ {\\bf H}= \\left\\{ u\\in{\\bf W}^{1,2}(V) \\Bigg| \\int_{V}u\\!\\\nd\\mu =0 \\right\\}. $$\n  For any $\\beta \\in \\mathbb{R}$, we show that $J_{ \\beta }(u)$ has a minimizer\n$u\\in{\\bf H}$, and then, based on variational principle, the Kazdan-Warner\nequation $$ \\Delta u=-\\frac{\\beta he^{u}}{\\displaystyle{\\int_{V}he^{u}d \\mu\n}}+\\frac{\\beta }{\\text{Vol}(V)} $$ has a solution in ${\\bf H}$.\n  If $\\alpha < \\lambda _{1}(V)$, then for any $\\beta \\in \\mathbb{R} , J_{\n\\alpha ,\\beta }(u)$ has a minimizer in ${\\bf H}$, thus the Kazdan-Warner\nequation $$ \\Delta u+\\alpha\\!\\ u=-\\frac{\\beta\nhe^{u}}{\\displaystyle{\\int_{V}he^{u}d \\mu }}+\\frac{\\beta }{\\text{Vol}(V)} $$\nhas a solution in ${\\bf H}$. If $\\alpha > \\lambda _{1}(V)$, then for any $\\beta\n\\in \\mathbb{R}$, $\\displaystyle{\\inf_{u\\in{\\bf H}} J_{ \\alpha ,\\beta }(u) =-\n\\infty}$. When $\\alpha=\\lambda_{1}(V)$, the situation becomes complicated: if\n$\\beta=0$, the corresponding equation is $-\\Delta u=\\lambda_{1}(V)u$ which has\na solution in ${\\bf H}$ obviously; if $\\beta>0$, then $\\displaystyle{\\inf_{u\\in\n{\\bf H}} J_{\\alpha,\\beta }(u) =- \\infty}$; if $\\beta<0$, $J_{ \\alpha ,\\beta\n}(u)$ has a minimizer in some subspace of ${\\bf H}$.\n  Moreover, we consider the same problem where higher eigenvalues are involved.",
            "author": [
                "Yi Li",
                "Qianwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10002v1",
                "http://arxiv.org/pdf/2308.10002v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09996v1",
            "title": "The $\\mathrm{v}$-number and Castelnuovo-Mumford regularity of cover\n  ideals of graphs",
            "updated": "2023-08-19T12:15:35Z",
            "published": "2023-08-19T12:15:35Z",
            "summary": "The $\\mathrm{v}$-number of a graded ideal $I\\subseteq R$, denoted by\n$\\mathrm{v}(I)$, is the minimum degree of a polynomial $f$ for which $I:f$ is a\nprime ideal. Jaramillo and Villarreal (J Combin Theory Ser A 177:105310, 2021)\nstudied the $\\mathrm{v}$-number of edge ideals. In this paper, we study the\n$\\mathrm{v}$-number of the cover ideal $J(G)$ of a graph $G$. The main result\nshows that $\\mathrm{v}(J(G))\\leq \\mathrm{reg}(R/J(G))$ for any simple graph\n$G$, which is quite surprising because, for the case of edge ideals, this\ninequality does not hold. Our main result relates $\\mathrm{v}(J(G))$ with the\nCohen-Macaulay property of $R/I(G)$. We provide an infinite class of connected\ngraphs, which satisfy $\\mathrm{v}(J(G))=\\mathrm{reg}(R/J(G))$. Also, we show\nthat for every positive integer $k$, there exists a connected graph $G_k$ such\nthat $\\mathrm{reg}(R/J(G_k))-\\mathrm{v}(J(G_k))=k$. Also, we explicitly compute\nthe $\\mathrm{v}$-number of cover ideals of cycles.",
            "author": [
                "Kamalesh Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09996v1",
                "http://arxiv.org/pdf/2308.09996v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "Primary 13F20, 05E40, Secondary 13C70, 05C69"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09991v2",
            "title": "AltDiffusion: A Multilingual Text-to-Image Diffusion Model",
            "updated": "2023-08-23T05:19:03Z",
            "published": "2023-08-19T11:52:12Z",
            "summary": "Large Text-to-Image(T2I) diffusion models have shown a remarkable capability\nto produce photorealistic and diverse images based on text inputs. However,\nexisting works only support limited language input, e.g., English, Chinese, and\nJapanese, leaving users beyond these languages underserved and blocking the\nglobal expansion of T2I models. Therefore, this paper presents AltDiffusion, a\nnovel multilingual T2I diffusion model that supports eighteen different\nlanguages. Specifically, we first train a multilingual text encoder based on\nthe knowledge distillation. Then we plug it into a pretrained English-only\ndiffusion model and train the model with a two-stage schema to enhance the\nmultilingual capability, including concept alignment and quality improvement\nstage on a large-scale multilingual dataset. Furthermore, we introduce a new\nbenchmark, which includes Multilingual-General-18(MG-18) and\nMultilingual-Cultural-18(MC-18) datasets, to evaluate the capabilities of T2I\ndiffusion models for generating high-quality images and capturing\nculture-specific concepts in different languages. Experimental results on both\nMG-18 and MC-18 demonstrate that AltDiffusion outperforms current\nstate-of-the-art T2I models, e.g., Stable Diffusion in multilingual\nunderstanding, especially with respect to culture-specific concepts, while\nstill having comparable capability for generating high-quality images. All\nsource code and checkpoints could be found in\nhttps://github.com/superhero-7/AltDiffuson.",
            "author": [
                "Fulong Ye",
                "Guang Liu",
                "Xinya Wu",
                "Ledell Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09991v2",
                "http://arxiv.org/pdf/2308.09991v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09986v1",
            "title": "Extensive approach to absolute homogeneity",
            "updated": "2023-08-19T11:34:03Z",
            "published": "2023-08-19T11:34:03Z",
            "summary": "The main aim of the paper is to study in greater detail absolutely\nhomogeneous structures (that is, objects with the property that each partial\nisomorphism extends to a global automorphism), with special emphasis on metric\nspaces and (possibly infinite, full) graphs with edge-coloring. Besides, a\ngeneral categorical approach to this concept is presented. The main achievement\nof the paper is the discovery of one-to-one correspondence between absolutely\nhomogeneous objects and certain classes (that become sets when isomorphic\nobjects are identified) of \"finite\" objects that satisfy a few quite general\naxioms (such as amalgamation and heredity). It is also introduced and discussed\nin detail the concept of products for graphs with edge-coloring (that produces\nan absolutely homogeneous graph provided all factors are so). Among the most\nsignificant results of the paper, it is worth mentioning a full classification\n(up to isometry) of all absolutely homogeneous ultrametric spaces as well as of\nall absolutely homogeneous graphs with edge-coloring in which all triangles are\nisosceles or in which all triangles are (precisely) tricolored.",
            "author": [
                "Piotr Niemiec"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09986v1",
                "http://arxiv.org/pdf/2308.09986v1"
            ],
            "primary_category": "math.GN",
            "category": [
                "math.GN",
                "math.CT",
                "2010: Primary 22F30, Secondary 05C63, 05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11651v1",
            "title": "Distributionally Robust Cross Subject EEG Decoding",
            "updated": "2023-08-19T11:31:33Z",
            "published": "2023-08-19T11:31:33Z",
            "summary": "Recently, deep learning has shown to be effective for Electroencephalography\n(EEG) decoding tasks. Yet, its performance can be negatively influenced by two\nkey factors: 1) the high variance and different types of corruption that are\ninherent in the signal, 2) the EEG datasets are usually relatively small given\nthe acquisition cost, annotation cost and amount of effort needed. Data\naugmentation approaches for alleviation of this problem have been empirically\nstudied, with augmentation operations on spatial domain, time domain or\nfrequency domain handcrafted based on expertise of domain knowledge. In this\nwork, we propose a principled approach to perform dynamic evolution on the data\nfor improvement of decoding robustness. The approach is based on\ndistributionally robust optimization and achieves robustness by optimizing on a\nfamily of evolved data distributions instead of the single training data\ndistribution. We derived a general data evolution framework based on\nWasserstein gradient flow (WGF) and provides two different forms of evolution\nwithin the framework. Intuitively, the evolution process helps the EEG decoder\nto learn more robust and diverse features. It is worth mentioning that the\nproposed approach can be readily integrated with other data augmentation\napproaches for further improvements. We performed extensive experiments on the\nproposed approach and tested its performance on different types of corrupted\nEEG signals. The model significantly outperforms competitive baselines on\nchallenging decoding scenarios.",
            "author": [
                "Tiehang Duan",
                "Zhenyi Wang",
                "Gianfranco Doretto",
                "Fang Li",
                "Cui Tao",
                "Donald Adjeroh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11651v1",
                "http://arxiv.org/pdf/2308.11651v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09983v1",
            "title": "Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia\n  Visual Inspection",
            "updated": "2023-08-19T11:25:09Z",
            "published": "2023-08-19T11:25:09Z",
            "summary": "Early detection of dysplasia of the cervix is critical for cervical cancer\ntreatment. However, automatic cervical dysplasia diagnosis via visual\ninspection, which is more appropriate in low-resource settings, remains a\nchallenging problem. Though promising results have been obtained by recent deep\nlearning models, their performance is significantly hindered by the limited\nscale of the available cervix datasets. Distinct from previous methods that\nlearn from a single dataset, we propose to leverage cross-domain cervical\nimages that were collected in different but related clinical studies to improve\nthe model's performance on the targeted cervix dataset. To robustly learn the\ntransferable information across datasets, we propose a novel prototype-based\nknowledge filtering method to estimate the transferability of cross-domain\nsamples. We further optimize the shared feature space by aligning the\ncross-domain image representations simultaneously on domain level with early\nalignment and class level with supervised contrastive learning, which endows\nmodel training and knowledge transfer with stronger robustness. The empirical\nresults on three real-world benchmark cervical image datasets show that our\nproposed method outperforms the state-of-the-art cervical dysplasia visual\ninspection by an absolute improvement of 4.7% in top-1 accuracy, 7.0% in\nprecision, 1.4% in recall, 4.6% in F1 score, and 0.05 in ROC-AUC.",
            "author": [
                "Yichen Zhang",
                "Yifang Yin",
                "Ying Zhang",
                "Zhenguang Liu",
                "Zheng Wang",
                "Roger Zimmermann"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612000",
                "http://arxiv.org/abs/2308.09983v1",
                "http://arxiv.org/pdf/2308.09983v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09982v2",
            "title": "Super approximation for $\\text{SL}_2(\\mathbb Z/q\\mathbb Z)\\times\n  \\text{SL}_2(\\mathbb Z/q\\mathbb Z)$",
            "updated": "2023-09-11T14:06:00Z",
            "published": "2023-08-19T11:24:17Z",
            "summary": "Let $S\\subset \\text{SL}_2(\\mathbb Z)\\times \\text{SL}_2(\\mathbb Z)$ be finite\nsymmetric and assume $S$ generates a group $G$ which is Zariski-dense in\n$\\text{SL}_2\\times \\text{SL}_2$. We prove that the Cayley graphs $$\\{\\mathcal\nCay(G (\\text{mod }q), S (\\text{mod }q))\\}_{q\\in \\mathbb Z_+}$$ form a family of\nexpanders.",
            "author": [
                "Jincheng Tang",
                "Xin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09982v2",
                "http://arxiv.org/pdf/2308.09982v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO",
                "math.DS",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09980v1",
            "title": "Breast Lesion Diagnosis Using Static Images and Dynamic Video",
            "updated": "2023-08-19T11:09:58Z",
            "published": "2023-08-19T11:09:58Z",
            "summary": "Deep learning based Computer Aided Diagnosis (CAD) systems have been\ndeveloped to treat breast ultrasound. Most of them focus on a single ultrasound\nimaging modality, either using representative static images or the dynamic\nvideo of a real-time scan. In fact, these two image modalities are\ncomplementary for lesion diagnosis. Dynamic videos provide detailed\nthree-dimensional information about the lesion, while static images capture the\ntypical sections of the lesion. In this work, we propose a multi-modality\nbreast tumor diagnosis model to imitate the diagnosing process of radiologists,\nwhich learns the features of both static images and dynamic video and explores\nthe potential relationship between the two modalities. Considering that static\nimages are carefully selected by professional radiologists, we propose to\naggregate dynamic video features under the guidance of domain knowledge from\nstatic images before fusing multi-modality features. Our work is validated on a\nbreast ultrasound dataset composed of 897 sets of ultrasound images and videos.\nExperimental results show that our model boosts the performance of\nBenign/Malignant classification, achieving 90.0% in AUC and 81.7% in accuracy.",
            "author": [
                "Yunwen Huang",
                "Hongyu Hu",
                "Ying Zhu",
                "Yi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09980v1",
                "http://arxiv.org/pdf/2308.09980v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09976v1",
            "title": "Explicit Time Embedding Based Cascade Attention Network for Information\n  Popularity Prediction",
            "updated": "2023-08-19T10:43:11Z",
            "published": "2023-08-19T10:43:11Z",
            "summary": "Predicting information cascade popularity is a fundamental problem in social\nnetworks. Capturing temporal attributes and cascade role information (e.g.,\ncascade graphs and cascade sequences) is necessary for understanding the\ninformation cascade. Current methods rarely focus on unifying this information\nfor popularity predictions, which prevents them from effectively modeling the\nfull properties of cascades to achieve satisfactory prediction performances. In\nthis paper, we propose an explicit Time embedding based Cascade Attention\nNetwork (TCAN) as a novel popularity prediction architecture for large-scale\ninformation networks. TCAN integrates temporal attributes (i.e., periodicity,\nlinearity, and non-linear scaling) into node features via a general time\nembedding approach (TE), and then employs a cascade graph attention encoder\n(CGAT) and a cascade sequence attention encoder (CSAT) to fully learn the\nrepresentation of cascade graphs and cascade sequences. We use two real-world\ndatasets (i.e., Weibo and APS) with tens of thousands of cascade samples to\nvalidate our methods. Experimental results show that TCAN obtains mean\nlogarithm squared errors of 2.007 and 1.201 and running times of 1.76 hours and\n0.15 hours on both datasets, respectively. Furthermore, TCAN outperforms other\nrepresentative baselines by 10.4%, 3.8%, and 10.4% in terms of MSLE, MAE, and\nR-squared on average while maintaining good interpretability.",
            "author": [
                "Xigang Sun",
                "Jingya Zhou",
                "Ling Liu",
                "Wenqi Wei"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.ipm.2023.103278",
                "http://arxiv.org/abs/2308.09976v1",
                "http://arxiv.org/pdf/2308.09976v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09975v1",
            "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for\n  Large Language Models",
            "updated": "2023-08-19T10:38:00Z",
            "published": "2023-08-19T10:38:00Z",
            "summary": "Large language models (LLMs) have demonstrated exceptional performance in\nvarious natural language processing tasks, yet their efficacy in more\nchallenging and domain-specific tasks remains largely unexplored. This paper\npresents FinEval, a benchmark specifically designed for the financial domain\nknowledge in the LLMs. FinEval is a collection of high-quality multiple-choice\nquestions covering Finance, Economy, Accounting, and Certificate. It includes\n4,661 questions spanning 34 different academic subjects. To ensure a\ncomprehensive model performance evaluation, FinEval employs a range of prompt\ntypes, including zero-shot and few-shot prompts, as well as answer-only and\nchain-of-thought prompts. Evaluating state-of-the-art Chinese and English LLMs\non FinEval, the results show that only GPT-4 achieved an accuracy close to 70%\nin different prompt settings, indicating significant growth potential for LLMs\nin the financial domain knowledge. Our work offers a more comprehensive\nfinancial knowledge evaluation benchmark, utilizing data of mock exams and\ncovering a wide range of evaluated LLMs.",
            "author": [
                "Liwen Zhang",
                "Weige Cai",
                "Zhaowei Liu",
                "Zhi Yang",
                "Wei Dai",
                "Yujie Liao",
                "Qianru Qin",
                "Yifei Li",
                "Xingyu Liu",
                "Zhiqiang Liu",
                "Zhoufan Zhu",
                "Anbo Wu",
                "Xin Guo",
                "Yun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09975v1",
                "http://arxiv.org/pdf/2308.09975v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09971v1",
            "title": "Disposable Transfer Learning for Selective Source Task Unlearning",
            "updated": "2023-08-19T10:13:17Z",
            "published": "2023-08-19T10:13:17Z",
            "summary": "Transfer learning is widely used for training deep neural networks (DNN) for\nbuilding a powerful representation. Even after the pre-trained model is adapted\nfor the target task, the representation performance of the feature extractor is\nretained to some extent. As the performance of the pre-trained model can be\nconsidered the private property of the owner, it is natural to seek the\nexclusive right of the generalized performance of the pre-trained weight. To\naddress this issue, we suggest a new paradigm of transfer learning called\ndisposable transfer learning (DTL), which disposes of only the source task\nwithout degrading the performance of the target task. To achieve knowledge\ndisposal, we propose a novel loss named Gradient Collision loss (GC loss). GC\nloss selectively unlearns the source knowledge by leading the gradient vectors\nof mini-batches in different directions. Whether the model successfully\nunlearns the source task is measured by piggyback learning accuracy (PL\naccuracy). PL accuracy estimates the vulnerability of knowledge leakage by\nretraining the scrubbed model on a subset of source data or new downstream\ndata. We demonstrate that GC loss is an effective approach to the DTL problem\nby showing that the model trained with GC loss retains the performance on the\ntarget task with a significantly reduced PL accuracy.",
            "author": [
                "Seunghee Koh",
                "Hyounguk Shon",
                "Janghyeon Lee",
                "Hyeong Gwon Hong",
                "Junmo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09971v1",
                "http://arxiv.org/pdf/2308.09971v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09967v1",
            "title": "Stable value of depth of symbolic powers of edge ideals of graphs",
            "updated": "2023-08-19T09:50:41Z",
            "published": "2023-08-19T09:50:41Z",
            "summary": "Let $G$ be a simple graph on $n$ vertices. We introduce the notion of\nbipartite connectivity of $G$, denoted by $\\operatorname{bc}(G)$ and prove that\n  $$\\lim_{s \\to \\infty} \\operatorname{depth} (S/I(G)^{(s)}) \\le\n\\operatorname{bc}(G),$$\n  where $I(G)$ denotes the edge ideal of $G$ and $S = \\mathrm{k}[x_1, \\ldots,\nx_n]$ is a standard graded polynomial ring over a field $\\mathrm{k}$. We\nfurther compute the depth of symbolic powers of edge ideals of several classes\nof graphs, including odd cycles and whisker graphs of complete graphs to\nillustrate the cases where the above inequality becomes equality.",
            "author": [
                "Nguyen Cong Minh",
                "Tran Nam Trung",
                "Thanh Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09967v1",
                "http://arxiv.org/pdf/2308.09967v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "13D02, 13F55, 05E40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09954v1",
            "title": "Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs",
            "updated": "2023-08-19T09:17:19Z",
            "published": "2023-08-19T09:17:19Z",
            "summary": "Large language models (LLMs) possess a wealth of knowledge encoded in their\nparameters. However, this knowledge may become outdated or unsuitable over\ntime. As a result, there has been a growing interest in knowledge editing for\nLLMs and evaluating its effectiveness. Existing studies primarily focus on\nknowledge editing using factual triplets, which not only incur high costs for\ncollection but also struggle to express complex facts. Furthermore, these\nstudies are often limited in their evaluation perspectives. In this paper, we\npropose Eva-KELLM, a new benchmark for evaluating knowledge editing of LLMs.\nThis benchmark includes an evaluation framework and a corresponding dataset.\nUnder our framework, we first ask the LLM to perform knowledge editing using\nraw documents, which provides a more convenient and universal approach compared\nto using factual triplets. We then evaluate the updated LLM from multiple\nperspectives. In addition to assessing the effectiveness of knowledge editing\nand the retention of unrelated knowledge from conventional studies, we further\ntest the LLM's ability in two aspects: 1) Reasoning with the altered knowledge,\naiming for the LLM to genuinely learn the altered knowledge instead of simply\nmemorizing it. 2) Cross-lingual knowledge transfer, where the LLM updated with\nraw documents in one language should be capable of handling queries from\nanother language. To facilitate further research, we construct and release the\ncorresponding dataset. Using this benchmark, we investigate the effectiveness\nof several commonly-used knowledge editing methods. Experimental results\nindicate that the current methods for knowledge editing using raw documents are\nnot effective in yielding satisfactory results, particularly when it comes to\nreasoning with altered knowledge and cross-lingual knowledge transfer.",
            "author": [
                "Suhang Wu",
                "Minlong Peng",
                "Yue Chen",
                "Jinsong Su",
                "Mingming Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09954v1",
                "http://arxiv.org/pdf/2308.09954v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09953v1",
            "title": "UniAP: Towards Universal Animal Perception in Vision via Few-shot\n  Learning",
            "updated": "2023-08-19T09:13:46Z",
            "published": "2023-08-19T09:13:46Z",
            "summary": "Animal visual perception is an important technique for automatically\nmonitoring animal health, understanding animal behaviors, and assisting\nanimal-related research. However, it is challenging to design a deep\nlearning-based perception model that can freely adapt to different animals\nacross various perception tasks, due to the varying poses of a large diversity\nof animals, lacking data on rare species, and the semantic inconsistency of\ndifferent tasks. We introduce UniAP, a novel Universal Animal Perception model\nthat leverages few-shot learning to enable cross-species perception among\nvarious visual tasks. Our proposed model takes support images and labels as\nprompt guidance for a query image. Images and labels are processed through a\nTransformer-based encoder and a lightweight label encoder, respectively. Then a\nmatching module is designed for aggregating information between prompt guidance\nand the query image, followed by a multi-head label decoder to generate outputs\nfor various tasks. By capitalizing on the shared visual characteristics among\ndifferent animals and tasks, UniAP enables the transfer of knowledge from\nwell-studied species to those with limited labeled data or even unseen species.\nWe demonstrate the effectiveness of UniAP through comprehensive experiments in\npose estimation, segmentation, and classification tasks on diverse animal\nspecies, showcasing its ability to generalize and adapt to new classes with\nminimal labeled examples.",
            "author": [
                "Meiqi Sun",
                "Zhonghan Zhao",
                "Wenhao Chai",
                "Hanjun Luo",
                "Shidong Cao",
                "Yanting Zhang",
                "Jenq-Neng Hwang",
                "Gaoang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09953v1",
                "http://arxiv.org/pdf/2308.09953v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09950v1",
            "title": "Multicolor Ramsey numbers on stars versus pat",
            "updated": "2023-08-19T09:09:15Z",
            "published": "2023-08-19T09:09:15Z",
            "summary": "For given simple graphs $H_1,H_2,\\dots,H_c$, the multicolor Ramsey number\n$R(H_1,H_2,\\dots,H_c)$ is defined as the smallest positive integer $n$ such\nthat for an arbitrary edge-decomposition $\\{G_i\\}^c_{i=1}$ of the complete\ngraph $K_n$, at least one $G_i$ has a subgraph isomorphic to $H_i$. Let\n$m,n_1,n_2,\\dots,n_c$ be positive integers and $\\Sigma=\\sum_{i=1}^{c}(n_i-1)$.\nSome bounds and exact values of $R(K_{1,n_1},\\dots,K_{1,n_c},P_m)$ have been\nobtained in literature. Wang (Graphs Combin., 2020) conjectured that if\n$\\Sigma\\not\\equiv 0\\pmod{m-1}$ and $\\Sigma+1\\ge (m-3)^2$, then\n$R(K_{1,n_1},\\ldots, K_{1,n_c}, P_m)=\\Sigma+m-1.$ In this note, we give a new\nlower bound and some exact values of $R(K_{1,n_1},\\dots,K_{1,n_c},P_m)$ when\n$m\\leq\\Sigma$, $\\Sigma\\equiv k\\pmod{m-1}$, and $2\\leq k \\leq m-2$. These\nresults partially confirm Wang's conjecture.",
            "author": [
                "Xuejun Zhang",
                "Xinmin Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09950v1",
                "http://arxiv.org/pdf/2308.09950v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09943v1",
            "title": "printf: Preference Modeling Based on User Reviews with Item Images and\n  Textual Information via Graph Learning",
            "updated": "2023-08-19T08:29:15Z",
            "published": "2023-08-19T08:29:15Z",
            "summary": "Nowadays, modern recommender systems usually leverage textual and visual\ncontents as auxiliary information to predict user preference. For textual\ninformation, review texts are one of the most popular contents to model user\nbehaviors. Nevertheless, reviews usually lose their shine when it comes to\ntop-N recommender systems because those that solely utilize textual reviews as\nfeatures struggle to adequately capture the interaction relationships between\nusers and items. For visual one, it is usually modeled with naive convolutional\nnetworks and also hard to capture high-order relationships between users and\nitems. Moreover, previous works did not collaboratively use both texts and\nimages in a proper way. In this paper, we propose printf, preference modeling\nbased on user reviews with item images and textual information via graph\nlearning, to address the above challenges. Specifically, the dimension-based\nattention mechanism directs relations between user reviews and interacted\nitems, allowing each dimension to contribute different importance weights to\nderive user representations. Extensive experiments are conducted on three\npublicly available datasets. The experimental results demonstrate that our\nproposed printf consistently outperforms baseline methods with the relative\nimprovements for NDCG@5 of 26.80%, 48.65%, and 25.74% on Amazon-Grocery,\nAmazon-Tools, and Amazon-Electronics datasets, respectively. The in-depth\nanalysis also indicates the dimensions of review representations definitely\nhave different topics and aspects, assisting the validity of our model design.",
            "author": [
                "Hao-Lun Lin",
                "Jyun-Yu Jiang",
                "Ming-Hao Juan",
                "Pu-Jen Cheng"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615012",
                "http://arxiv.org/abs/2308.09943v1",
                "http://arxiv.org/pdf/2308.09943v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09940v1",
            "title": "Evaluating Transfer Learning for Simplifying GitHub READMEs",
            "updated": "2023-08-19T08:20:41Z",
            "published": "2023-08-19T08:20:41Z",
            "summary": "Software documentation captures detailed knowledge about a software product,\ne.g., code, technologies, and design. It plays an important role in the\ncoordination of development teams and in conveying ideas to various\nstakeholders. However, software documentation can be hard to comprehend if it\nis written with jargon and complicated sentence structure. In this study, we\nexplored the potential of text simplification techniques in the domain of\nsoftware engineering to automatically simplify GitHub README files. We\ncollected software-related pairs of GitHub README files consisting of 14,588\nentries, aligned difficult sentences with their simplified counterparts, and\ntrained a Transformer-based model to automatically simplify difficult versions.\nTo mitigate the sparse and noisy nature of the software-related simplification\ndataset, we applied general text simplification knowledge to this field. Since\nmany general-domain difficult-to-simple Wikipedia document pairs are already\npublicly available, we explored the potential of transfer learning by first\ntraining the model on the Wikipedia data and then fine-tuning it on the README\ndata. Using automated BLEU scores and human evaluation, we compared the\nperformance of different transfer learning schemes and the baseline models\nwithout transfer learning. The transfer learning model using the best\ncheckpoint trained on a general topic corpus achieved the best performance of\n34.68 BLEU score and statistically significantly higher human annotation scores\ncompared to the rest of the schemes and baselines. We conclude that using\ntransfer learning is a promising direction to circumvent the lack of data and\ndrift style problem in software README files simplification and achieved a\nbetter trade-off between simplification and preservation of meaning.",
            "author": [
                "Haoyu Gao",
                "Christoph Treude",
                "Mansooreh Zahedi"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3611643.3616291",
                "http://arxiv.org/abs/2308.09940v1",
                "http://arxiv.org/pdf/2308.09940v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10905v1",
            "title": "Analyzing Quantization in TVM",
            "updated": "2023-08-19T07:39:46Z",
            "published": "2023-08-19T07:39:46Z",
            "summary": "There has been many papers in academic literature on quantizing weight\ntensors in deep learning models to reduce inference latency and memory\nfootprint. TVM also has the ability to quantize weights and support low-bit\ncomputations. Although quantization is typically expected to improve inference\ntime, in TVM, the performance of 8-bit quantization does not meet the\nexpectations. Typically, when applying 8-bit quantization to a deep learning\nmodel, it is usually expected to achieve around 50% of the full-precision\ninference time. However, in this particular case, not only does the quantized\nversion fail to achieve the desired performance boost, but it actually performs\nworse, resulting in an inference time that is about 2 times as slow as the\nnon-quantized version. In this project, we thoroughly investigate the reasons\nbehind the underperformance and assess the compatibility and optimization\nopportunities of 8-bit quantization in TVM. We discuss the optimization of two\ndifferent types of tasks: computation-bound and memory-bound, and provide a\ndetailed comparison of various optimization techniques in TVM. Through the\nidentification of performance issues, we have successfully improved\nquantization by addressing a bug in graph building. Furthermore, we analyze\nmultiple optimization strategies to achieve the optimal quantization result.\nThe best experiment achieves 163.88% improvement compared with the TVM compiled\nbaseline in inference time for the compute-bound task and 194.98% for the\nmemory-bound task.",
            "author": [
                "Mingfei Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10905v1",
                "http://arxiv.org/pdf/2308.10905v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09922v2",
            "title": "MDCS: More Diverse Experts with Consistency Self-distillation for\n  Long-tailed Recognition",
            "updated": "2023-11-30T11:58:12Z",
            "published": "2023-08-19T06:21:22Z",
            "summary": "Recently, multi-expert methods have led to significant improvements in\nlong-tail recognition (LTR). We summarize two aspects that need further\nenhancement to contribute to LTR boosting: (1) More diverse experts; (2) Lower\nmodel variance. However, the previous methods didn't handle them well. To this\nend, we propose More Diverse experts with Consistency Self-distillation (MDCS)\nto bridge the gap left by earlier methods. Our MDCS approach consists of two\ncore components: Diversity Loss (DL) and Consistency Self-distillation (CS). In\ndetail, DL promotes diversity among experts by controlling their focus on\ndifferent categories. To reduce the model variance, we employ KL divergence to\ndistill the richer knowledge of weakly augmented instances for the experts'\nself-distillation. In particular, we design Confident Instance Sampling (CIS)\nto select the correctly classified instances for CS to avoid biased/noisy\nknowledge. In the analysis and ablation study, we demonstrate that our method\ncompared with previous work can effectively increase the diversity of experts,\nsignificantly reduce the variance of the model, and improve recognition\naccuracy. Moreover, the roles of our DL and CS are mutually reinforcing and\ncoupled: the diversity of experts benefits from the CS, and the CS cannot\nachieve remarkable results without the DL. Experiments show our MDCS\noutperforms the state-of-the-art by 1% $\\sim$ 2% on five popular long-tailed\nbenchmarks, including CIFAR10-LT, CIFAR100-LT, ImageNet-LT, Places-LT, and\niNaturalist 2018. The code is available at https://github.com/fistyee/MDCS.",
            "author": [
                "Qihao Zhao",
                "Chen Jiang",
                "Wei Hu",
                "Fan Zhang",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09922v2",
                "http://arxiv.org/pdf/2308.09922v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09920v1",
            "title": "Graph4J -- A computationally efficient Java library for graph algorithms",
            "updated": "2023-08-19T06:08:24Z",
            "published": "2023-08-19T06:08:24Z",
            "summary": "Graph algorithms play an important role in many computer science areas. In\norder to solve problems that can be modeled using graphs, it is necessary to\nuse a data structure that can represent those graphs in an efficient manner. On\ntop of this, an infrastructure should be build that will assist in implementing\ncommon algorithms or developing specialized ones. Here, a new Java library is\nintroduced, called Graph4J, that uses a different approach when compared to\nexisting, well-known Java libraries such as JGraphT, JUNG and Guava Graph.\nInstead of using object-oriented data structures for graph representation, a\nlower-level model based on arrays of primitive values is utilized, that\ndrastically reduces the required memory and the running times of the algorithm\nimplementations. The design of the library, the space complexity of the graph\nstructures and the time complexity of the most common graph operations are\npresented in detail, along with an experimental study that evaluates its\nperformance, when compared to the other libraries. Emphasis is given to\ninfrastructure related aspects, that is graph creation, inspection, alteration\nand traversal. The improvements obtained for other implemented algorithms are\nalso analyzed and it is shown that the proposed library significantly\noutperforms the existing ones.",
            "author": [
                "Cristian Fr\u0103sinaru",
                "Emanuel Florentin Olariu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09920v1",
                "http://arxiv.org/pdf/2308.09920v1"
            ],
            "primary_category": "cs.MS",
            "category": [
                "cs.MS",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09919v1",
            "title": "Monitoring a developing pandemic with available data",
            "updated": "2023-08-19T06:06:24Z",
            "published": "2023-08-19T06:06:24Z",
            "summary": "This paper addresses pandemic statistics from a management perspective. Both\ninput and output are easy to understand. Focus is on operations and cross\nborder communication. To be able to work with simple available data some new\nmissing data issues have to be solved from a mathematical statistical point of\nview. We illustrate our approach with data from France collected during the\nrecent Covid-19 pandemic. Our new benchmark method also introduces a potential\nnew division of labour while working with pandemic statistics allowing crucial\ninput to be fed to the model via prior knowledge from external experts.",
            "author": [
                "Mar\u00eda Luz G\u00e1miz",
                "Enno Mammen",
                "Mar\u00eda Dolores Mart\u00ednez-Miranda",
                "Jens Perch Nielsen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09919v1",
                "http://arxiv.org/pdf/2308.09919v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "62G05",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09908v1",
            "title": "LEGO: Learning and Graph-Optimized Modular Tracker for Online\n  Multi-Object Tracking with Point Clouds",
            "updated": "2023-08-19T05:15:02Z",
            "published": "2023-08-19T05:15:02Z",
            "summary": "Online multi-object tracking (MOT) plays a pivotal role in autonomous\nsystems. The state-of-the-art approaches usually employ a tracking-by-detection\nmethod, and data association plays a critical role. This paper proposes a\nlearning and graph-optimized (LEGO) modular tracker to improve data association\nperformance in the existing literature. The proposed LEGO tracker integrates\ngraph optimization and self-attention mechanisms, which efficiently formulate\nthe association score map, facilitating the accurate and efficient matching of\nobjects across time frames. To further enhance the state update process, the\nKalman filter is added to ensure consistent tracking by incorporating temporal\ncoherence in the object states. Our proposed method utilizing LiDAR alone has\nshown exceptional performance compared to other online tracking approaches,\nincluding LiDAR-based and LiDAR-camera fusion-based methods. LEGO ranked 1st at\nthe time of submitting results to KITTI object tracking evaluation ranking\nboard and remains 2nd at the time of submitting this paper, among all online\ntrackers in the KITTI MOT benchmark for cars1",
            "author": [
                "Zhenrong Zhang",
                "Jianan Liu",
                "Yuxuan Xia",
                "Tao Huang",
                "Qing-Long Han",
                "Hongbin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09908v1",
                "http://arxiv.org/pdf/2308.09908v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09907v1",
            "title": "Imputing Brain Measurements Across Data Sets via Graph Neural Networks",
            "updated": "2023-08-19T05:03:35Z",
            "published": "2023-08-19T05:03:35Z",
            "summary": "Publicly available data sets of structural MRIs might not contain specific\nmeasurements of brain Regions of Interests (ROIs) that are important for\ntraining machine learning models. For example, the curvature scores computed by\nFreesurfer are not released by the Adolescent Brain Cognitive Development\n(ABCD) Study. One can address this issue by simply reapplying Freesurfer to the\ndata set. However, this approach is generally computationally and labor\nintensive (e.g., requiring quality control). An alternative is to impute the\nmissing measurements via a deep learning approach. However, the\nstate-of-the-art is designed to estimate randomly missing values rather than\nentire measurements. We therefore propose to re-frame the imputation problem as\na prediction task on another (public) data set that contains the missing\nmeasurements and shares some ROI measurements with the data sets of interest. A\ndeep learning model is then trained to predict the missing measurements from\nthe shared ones and afterwards is applied to the other data sets. Our proposed\nalgorithm models the dependencies between ROI measurements via a graph neural\nnetwork (GNN) and accounts for demographic differences in brain measurements\n(e.g. sex) by feeding the graph encoding into a parallel architecture. The\narchitecture simultaneously optimizes a graph decoder to impute values and a\nclassifier in predicting demographic factors. We test the approach, called\nDemographic Aware Graph-based Imputation (DAGI), on imputing those missing\nFreesurfer measurements of ABCD (N=3760) by training the predictor on those\npublicly released by the National Consortium on Alcohol and Neurodevelopment in\nAdolescence (NCANDA, N=540)...",
            "author": [
                "Yixin Wang",
                "Wei Peng",
                "Susan F. Tapert",
                "Qingyu Zhao",
                "Kilian M. Pohl"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09907v1",
                "http://arxiv.org/pdf/2308.09907v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09906v1",
            "title": "On the physical layer security capabilities of reconfigurable\n  intelligent surface empowered wireless systems",
            "updated": "2023-08-19T04:55:00Z",
            "published": "2023-08-19T04:55:00Z",
            "summary": "In this paper, we investigate the physical layer security capabilities of\nreconfigurable intelligent surface (RIS) empowered wireless systems. In more\ndetail, we consider a general system model, in which the links between the\ntransmitter (TX) and the RIS as well as the links between the RIS and the\nlegitimate receiver are modeled as mixture Gamma (MG) random variables (RVs).\nMoreover, the link between the TX and eavesdropper is also modeled as a MG RV.\nBuilding upon this system model, we derive the probability of zero-secrecy\ncapacity as well as the probability of information leakage. Finally, we extract\nthe average secrecy rate for both cases of TX having full and partial channel\nstate information knowledge.",
            "author": [
                "Alexandros--Apostolos A. Boulogeorgos",
                "Angeliki Alexiou",
                "Angelos Michalas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09906v1",
                "http://arxiv.org/pdf/2308.09906v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09896v1",
            "title": "Contrastive Learning-based Imputation-Prediction Networks for\n  In-hospital Mortality Risk Modeling using EHRs",
            "updated": "2023-08-19T03:24:34Z",
            "published": "2023-08-19T03:24:34Z",
            "summary": "Predicting the risk of in-hospital mortality from electronic health records\n(EHRs) has received considerable attention. Such predictions will provide early\nwarning of a patient's health condition to healthcare professionals so that\ntimely interventions can be taken. This prediction task is challenging since\nEHR data are intrinsically irregular, with not only many missing values but\nalso varying time intervals between medical records. Existing approaches focus\non exploiting the variable correlations in patient medical records to impute\nmissing values and establishing time-decay mechanisms to deal with such\nirregularity. This paper presents a novel contrastive learning-based\nimputation-prediction network for predicting in-hospital mortality risks using\nEHR data. Our approach introduces graph analysis-based patient stratification\nmodeling in the imputation process to group similar patients. This allows\ninformation of similar patients only to be used, in addition to personal\ncontextual information, for missing value imputation. Moreover, our approach\ncan integrate contrastive learning into the proposed network architecture to\nenhance patient representation learning and predictive performance on the\nclassification task. Experiments on two real-world EHR datasets show that our\napproach outperforms the state-of-the-art approaches in both imputation and\nprediction tasks.",
            "author": [
                "Yuxi Liu",
                "Zhenhao Zhang",
                "Shaowen Qin",
                "Flora D. Salim",
                "Antonio Jimeno Yepes"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09896v1",
                "http://arxiv.org/pdf/2308.09896v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09895v2",
            "title": "Knowledge Transfer from High-Resource to Low-Resource Programming\n  Languages for Code LLMs",
            "updated": "2023-08-22T01:51:54Z",
            "published": "2023-08-19T03:19:01Z",
            "summary": "Over the past few years, Large Language Models of Code (Code LLMs) have\nstarted to have a significant impact on programming practice. Code LLMs are\nalso emerging as a building block for research in programming languages and\nsoftware engineering. However, the quality of code produced by a Code LLM\nvaries significantly by programming languages. Code LLMs produce impressive\nresults on programming languages that are well represented in their training\ndata (e.g., Java, Python, or JavaScript), but struggle with low-resource\nlanguages, like OCaml and Racket.\n  This paper presents an effective approach for boosting the performance of\nCode LLMs on low-resource languages using semi-synthetic data. Our approach\ngenerates high-quality datasets for low-resource languages, which can then be\nused to fine-tune any pretrained Code LLM. Our approach, called MultiPL-T,\ntranslates training data from high-resource languages into training data for\nlow-resource languages. We apply our approach to generate tens of thousands of\nnew, validated training items for Racket, OCaml, and Lua from Python. Moreover,\nwe use an open dataset (The Stack) and model (StarCoderBase), which allow us to\ndecontaminate benchmarks and train models on this data without violating the\nmodel license.\n  With MultiPL-T generated data, we present fine-tuned versions of\nStarCoderBase that achieve state-of-the-art performance for Racket, OCaml, and\nLua on benchmark problems. For Lua, our fine-tuned model achieves the same\nperformance as StarCoderBase as Python -- a very high-resource language -- on\nthe MultiPL-E benchmarks. For Racket and OCaml, we double their performance on\nMultiPL-E, bringing their performance close to higher-resource languages such\nas Ruby and C#.",
            "author": [
                "Federico Cassano",
                "John Gouwar",
                "Francesca Lucchetti",
                "Claire Schlesinger",
                "Carolyn Jane Anderson",
                "Michael Greenberg",
                "Abhinav Jangda",
                "Arjun Guha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09895v2",
                "http://arxiv.org/pdf/2308.09895v2"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09884v2",
            "title": "A Transformer-based Framework For Multi-variate Time Series: A Remaining\n  Useful Life Prediction Use Case",
            "updated": "2023-08-29T21:23:03Z",
            "published": "2023-08-19T02:30:35Z",
            "summary": "In recent times, Large Language Models (LLMs) have captured a global\nspotlight and revolutionized the field of Natural Language Processing. One of\nthe factors attributed to the effectiveness of LLMs is the model architecture\nused for training, transformers. Transformer models excel at capturing\ncontextual features in sequential data since time series data are sequential,\ntransformer models can be leveraged for more efficient time series data\nprediction. The field of prognostics is vital to system health management and\nproper maintenance planning. A reliable estimation of the remaining useful life\n(RUL) of machines holds the potential for substantial cost savings. This\nincludes avoiding abrupt machine failures, maximizing equipment usage, and\nserving as a decision support system (DSS). This work proposed an\nencoder-transformer architecture-based framework for multivariate time series\nprediction for a prognostics use case. We validated the effectiveness of the\nproposed framework on all four sets of the C-MAPPS benchmark dataset for the\nremaining useful life prediction task. To effectively transfer the knowledge\nand application of transformers from the natural language domain to time\nseries, three model-specific experiments were conducted. Also, to enable the\nmodel awareness of the initial stages of the machine life and its degradation\npath, a novel expanding window method was proposed for the first time in this\nwork, it was compared with the sliding window method, and it led to a large\nimprovement in the performance of the encoder transformer model. Finally, the\nperformance of the proposed encoder-transformer model was evaluated on the test\ndataset and compared with the results from 13 other state-of-the-art (SOTA)\nmodels in the literature and it outperformed them all with an average\nperformance increase of 137.65% over the next best model across all the\ndatasets.",
            "author": [
                "Oluwaseyi Ogunfowora",
                "Homayoun Najjaran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09884v2",
                "http://arxiv.org/pdf/2308.09884v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09876v2",
            "title": "Characterizing Usability Issue Discussions in Open Source Software\n  Projects",
            "updated": "2023-11-09T20:03:16Z",
            "published": "2023-08-19T01:47:08Z",
            "summary": "Usability is a crucial factor but one of the most neglected concerns in open\nsource software (OSS). While far from an ideal approach, a common practice that\nOSS communities adopt to collaboratively address usability is through\ndiscussions on issue tracking systems (ITSs). However, there is little\nknowledge about the extent to which OSS community members engage in usability\nissue discussions, the aspects of usability they frequently target, and the\ncharacteristics of their collaboration around usability issue discussions. This\nknowledge is important for providing practical recommendations and research\ndirections to better support OSS communities in addressing this important topic\nand improve OSS usability in general. To help achieve this goal, we performed\nan extensive empirical study on issues discussed in five popular OSS\napplications: three data science notebook projects (Jupyter Lab, Google Colab,\nand CoCalc) and two code editor projects (VSCode and Atom). Our results\nindicated that while usability issues are extensively discussed in the OSS\nprojects, their scope tended to be limited to efficiency and aesthetics.\nAdditionally, these issues are more frequently posted by experienced community\nmembers and display distinguishable characteristics, such as involving more\nvisual communication and more participants. Our results provide important\nimplications that can inform the OSS practitioners to better engage the\ncommunity in usability issue discussion and shed light on future research\nefforts toward collaboration techniques and tools for discussing niche topics\nin diverse communities, such as the usability issues in the OSS context.",
            "author": [
                "Arghavan Sanei",
                "Jinghui Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09876v2",
                "http://arxiv.org/pdf/2308.09876v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09849v1",
            "title": "A finitely convergent circumcenter method for the Convex Feasibility\n  Problem",
            "updated": "2023-08-18T22:51:27Z",
            "published": "2023-08-18T22:51:27Z",
            "summary": "In this paper, we present a variant of the circumcenter method for the Convex\nFeasibility Problem (CFP), ensuring finite convergence under a Slater\nassumption. The method replaces exact projections onto the convex sets with\nprojections onto separating halfspaces, perturbed by positive exogenous\nparameters that decrease to zero along the iterations. If the perturbation\nparameters decrease slowly enough, such as the terms of a diverging series,\nfinite convergence is achieved. To the best of our knowledge, this is the first\ncircumcenter method for CFP that guarantees finite convergence.",
            "author": [
                "Roger Behling",
                "Yunier Bello-Cruz",
                "Alfredo Iusem",
                "Di Liu",
                "Luiz-Rafael Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09849v1",
                "http://arxiv.org/pdf/2308.09849v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "49M27, 65K05, 65B99, 90C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09836v1",
            "title": "Wheeler maps",
            "updated": "2023-08-18T22:04:53Z",
            "published": "2023-08-18T22:04:53Z",
            "summary": "Motivated by challenges in pangenomic read alignment, we propose a\ngeneralization of Wheeler graphs that we call Wheeler maps. A Wheeler map\nstores a text $T[1..n]$ and an assignment of tags to the characters of $T$ such\nthat we can preprocess a pattern $P[1..m]$ and then, given $i$ and $j$, quickly\nreturn all the distinct tags labeling the first characters of the occurrences\nof $P[i..j]$ in $T$. For the applications that most interest us, characters\nwith long common contexts are likely to have the same tag, so we consider the\nnumber $t$ of runs in the list of tags sorted by their characters' positions in\nthe Burrows-Wheeler Transform (BWT) of $T$. We show how, given a straight-line\nprogram with $g$ rules for $T$, we can build an $O(g + r + t)$-space Wheeler\nmap, where $r$ is the number of runs in the BWT of $T$, with which we can\npreprocess a pattern $P[1..m]$ in $O(m \\log n)$ time and then return the $k$\ndistinct tags for $P[i..j]$ in optimal $O(k)$ time for any given $i$ and $j$.\nWe show various further results related to prioritizing the most frequent tags.",
            "author": [
                "Andrej Bal\u00e1z",
                "Travis Gagie",
                "Adri\u00e1n Goga",
                "Simon Heumos",
                "Gonzalo Navarro",
                "Alessia Petescia",
                "Jouni Sir\u00e9n"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09836v1",
                "http://arxiv.org/pdf/2308.09836v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09831v1",
            "title": "Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung\n  Cancer (NSCLC) Patient Survival Prediction",
            "updated": "2023-08-18T21:42:52Z",
            "published": "2023-08-18T21:42:52Z",
            "summary": "Cancer prognosis and survival outcome predictions are crucial for therapeutic\nresponse estimation and for stratifying patients into various treatment groups.\nMedical domains concerned with cancer prognosis are abundant with multiple\nmodalities, including pathological image data and non-image data such as\ngenomic information. To date, multimodal learning has shown potential to\nenhance clinical prediction model performance by extracting and aggregating\ninformation from different modalities of the same subject. This approach could\noutperform single modality learning, thus improving computer-aided diagnosis\nand prognosis in numerous medical applications. In this work, we propose a\ncross-modality attention-based multimodal fusion pipeline designed to integrate\nmodality-specific knowledge for patient survival prediction in non-small cell\nlung cancer (NSCLC). Instead of merely concatenating or summing up the features\nfrom different modalities, our method gauges the importance of each modality\nfor feature fusion with cross-modality relationship when infusing the\nmultimodal features. Compared with single modality, which achieved c-index of\n0.5772 and 0.5885 using solely tissue image data or RNA-seq data, respectively,\nthe proposed fusion approach achieved c-index 0.6587 in our experiment,\nshowcasing the capability of assimilating modality-specific knowledge from\nvaried modalities.",
            "author": [
                "Ruining Deng",
                "Nazim Shaikh",
                "Gareth Shannon",
                "Yao Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09831v1",
                "http://arxiv.org/pdf/2308.09831v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09829v1",
            "title": "Learning from A Single Graph is All You Need for Near-Shortest Path\n  Routing in Wireless Networks",
            "updated": "2023-08-18T21:35:45Z",
            "published": "2023-08-18T21:35:45Z",
            "summary": "We propose a learning algorithm for local routing policies that needs only a\nfew data samples obtained from a single graph while generalizing to all random\ngraphs in a standard model of wireless networks. We thus solve the all-pairs\nnear-shortest path problem by training deep neural networks (DNNs) that\nefficiently and scalably learn routing policies that are local, i.e., they only\nconsider node states and the states of neighboring nodes. Remarkably, one of\nthese DNNs we train learns a policy that exactly matches the performance of\ngreedy forwarding; another generally outperforms greedy forwarding. Our\nalgorithm design exploits network domain knowledge in several ways: First, in\nthe selection of input features and, second, in the selection of a ``seed\ngraph'' and subsamples from its shortest paths. The leverage of domain\nknowledge provides theoretical explainability of why the seed graph and node\nsubsampling suffice for learning that is efficient, scalable, and\ngeneralizable. Simulation-based results on uniform random graphs with diverse\nsizes and densities empirically corroborate that using samples generated from a\nfew routing paths in a modest-sized seed graph quickly learns a model that is\ngeneralizable across (almost) all random graphs in the wireless network model.",
            "author": [
                "Yung-Fu Chen",
                "Sen Lin",
                "Anish Arora"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09829v1",
                "http://arxiv.org/pdf/2308.09829v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09798v1",
            "title": "Unveiling the Collaborative Patterns of Artificial Intelligence\n  Applications in Human Resource Management: A Social Network Analysis Approach",
            "updated": "2023-08-18T19:56:36Z",
            "published": "2023-08-18T19:56:36Z",
            "summary": "The integration of artificial intelligence (AI) into human resource\nmanagement (HRM) strategies has become increasingly common due to technological\nadvancements. This has spurred a new field of research focused on evaluating\nthe impact of AI adoption on business and individual outcomes, as well as how\nto evaluate AI-enabled HRM practices. However, there is limited\ncross-disciplinary research in this area, causing a fragmented body of\nknowledge. To address this issue, social network analysis has been recognized\nas a tool for analyzing and researching large-scale social phenomena in HRM.\nThe study of scientific co-authorship networks is one application of social\nnetwork analysis that can help identify the main components and trends in this\nfield. Using social network analysis indicators, the current study examined the\nAI&HRM co-authorship network, which consists of 43,789 members and 81,891\nscientific collaborations. The study analyzed articles related to AI&HRM\npublished between 2000 and 2023 extracted from the WOS citation database.\nThrough centrality measures, the most important members of the \"AI&HRM\"\nco-authorship network were identified using the TOPSIS method, which identified\ntwenty prominent researchers in this field. The study also examined the\nkeywords \"AI&HRM\" and the scientific cooperation network of nations,\nuniversities, and communities. Overall, this study highlights the importance of\ncross-disciplinary research and social network analysis in understanding the\nimplications of AI adoption in HRM.",
            "author": [
                "Mehrdad Maghsoudi",
                "Motahareh Kamrani Shahri",
                "Mehrdad Agha Mohammad Ali Kermani",
                "Rahim Khanizad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09798v1",
                "http://arxiv.org/pdf/2308.09798v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09797v2",
            "title": "On diversifying stable assignments",
            "updated": "2023-08-28T10:58:45Z",
            "published": "2023-08-18T19:56:09Z",
            "summary": "We consider the stable assignment problem on a graph with nonnegative real\ncapacities on the edges and quotas on the vertices, in which the preferences of\nagents are given via diversifying choice functions. We prove that for any input\nof the problem, there exists exactly one stable assignment, and propose a\npolynomial time algorithm to find it.",
            "author": [
                "Alexander V. Karzanov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09797v2",
                "http://arxiv.org/pdf/2308.09797v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "91C02, 91C78"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09766v1",
            "title": "Time Series Predictions in Unmonitored Sites: A Survey of Machine\n  Learning Techniques in Water Resources",
            "updated": "2023-08-18T18:30:33Z",
            "published": "2023-08-18T18:30:33Z",
            "summary": "Prediction of dynamic environmental variables in unmonitored sites remains a\nlong-standing challenge for water resources science. The majority of the\nworld's freshwater resources have inadequate monitoring of critical\nenvironmental variables needed for management. Yet, the need to have widespread\npredictions of hydrological variables such as river flow and water quality has\nbecome increasingly urgent due to climate and land use change over the past\ndecades, and their associated impacts on water resources. Modern machine\nlearning methods increasingly outperform their process-based and empirical\nmodel counterparts for hydrologic time series prediction with their ability to\nextract information from large, diverse data sets. We review relevant\nstate-of-the art applications of machine learning for streamflow, water\nquality, and other water resources prediction and discuss opportunities to\nimprove the use of machine learning with emerging methods for incorporating\nwatershed characteristics into deep learning models, transfer learning, and\nincorporating process knowledge into machine learning models. The analysis here\nsuggests most prior efforts have been focused on deep learning learning\nframeworks built on many sites for predictions at daily time scales in the\nUnited States, but that comparisons between different classes of machine\nlearning methods are few and inadequate. We identify several open questions for\ntime series predictions in unmonitored sites that include incorporating dynamic\ninputs and site characteristics, mechanistic understanding and spatial context,\nand explainable AI techniques in modern machine learning frameworks.",
            "author": [
                "Jared D. Willard",
                "Charuleka Varadharajan",
                "Xiaowei Jia",
                "Vipin Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09766v1",
                "http://arxiv.org/pdf/2308.09766v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T07",
                "I.2.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09736v1",
            "title": "Directed Percolation Criticality in Eternal Inflation",
            "updated": "2023-08-18T18:00:00Z",
            "published": "2023-08-18T18:00:00Z",
            "summary": "False-vacuum eternal inflation can be described as a random walk on the\nnetwork of vacua of the string landscape. In this paper we show that the\nproblem can be mapped naturally to a problem of directed percolation. The\nmapping relies on two general and well-justified approximations for transition\nrates: 1.~the downward approximation, which neglects ``upward\" transitions, as\nthese are generally exponentially suppressed; 2. the dominant decay channel\napproximation, which capitalizes on the fact that tunneling rates are\nexponentially staggered. Lacking detailed knowledge of the string landscape, we\nmodel the network of vacua as random graphs with arbitrary degree distribution,\nincluding Erd\\\"os-R\\'enyi and scale-free graphs. As a complementary approach,\nwe also model regions of the landscape as regular lattices, specifically Bethe\nlattices. We find that the uniform-in-time probabilities proposed in our\nprevious work favor regions of the landscape poised at the directed percolation\nphase transition. This raises the tantalizing prospect of deriving universal\nstatistical distributions for physical observables, characterized by critical\nexponents that are insensitive to the details of the underlying landscape. We\nillustrate this with the cosmological constant, and show that the resulting\ndistribution peaks as a power-law for small positive vacuum energy, with a\ncritical exponent uniquely determined by the random graph universality class.",
            "author": [
                "Justin Khoury",
                "Sam S. C. Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09736v1",
                "http://arxiv.org/pdf/2308.09736v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "astro-ph.CO",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09704v1",
            "title": "Generating Hard Ising Instances With Planted Solutions Using\n  Post-Quantum Cryptographic Protocols",
            "updated": "2023-08-18T17:55:37Z",
            "published": "2023-08-18T17:55:37Z",
            "summary": "In this paper we present a novel method to generate hard instances with\nplanted solutions based on the public-private McEliece post-quantum\ncryptographic protocol. Unlike other planting methods rooted in the\ninfinite-size statistical analysis, our cryptographic protocol generates\ninstances which are all hard (in cryptographic terms), with the hardness tuned\nby the size of the private key, and with a guaranteed unique ground state. More\nimportantly, because of the private-public key protocol, planted solutions\ncannot be easily recovered by a direct inspection of the planted instances\nwithout the knowledge of the private key used to generate them, therefore\nmaking our protocol suitable to test and evaluate quantum devices without the\nrisk of \"backdoors\" being exploited.",
            "author": [
                "Salvatore Mandr\u00e0",
                "Gianni Mossi",
                "Eleanor G. Rieffel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09704v1",
                "http://arxiv.org/pdf/2308.09704v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09703v1",
            "title": "Counting and Sampling Labeled Chordal Graphs in Polynomial Time",
            "updated": "2023-08-18T17:54:09Z",
            "published": "2023-08-18T17:54:09Z",
            "summary": "We present the first polynomial-time algorithm to exactly compute the number\nof labeled chordal graphs on n vertices. Our algorithm solves a more general\nproblem: given n and omega as input, it computes the number of omega-colorable\nlabeled chordal graphs on n vertices, using O(n^7) arithmetic operations. A\nstandard sampling-to-counting reduction then yields a polynomial-time exact\nsampler that generates an omega-colorable labeled chordal graph on n vertices\nuniformly at random. Our counting algorithm improves upon the previous best\nresult by Wormald (1985), which computes the number of labeled chordal graphs\non n vertices in time exponential in n.\n  An implementation of the polynomial-time counting algorithm gives the number\nof labeled chordal graphs on up to 30 vertices in less than three minutes on a\nstandard desktop computer. Previously, the number of labeled chordal graphs was\nonly known for graphs on up to 15 vertices.",
            "author": [
                "Ursula Hebert-Johnson",
                "Daniel Lokshtanov",
                "Eric Vigoda"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09703v1",
                "http://arxiv.org/pdf/2308.09703v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09699v1",
            "title": "Emergent hydrodynamic behaviour of few strongly interacting fermions",
            "updated": "2023-08-18T17:46:21Z",
            "published": "2023-08-18T17:46:21Z",
            "summary": "Hydrodynamics provides a successful framework to effectively describe the\ndynamics of complex many-body systems ranging from subnuclear to cosmological\nscales by introducing macroscopic quantities such as particle densities and\nfluid velocities. According to textbook knowledge, it requires coarse graining\nover microscopic constituents to define a macroscopic fluid cell, which is\nlarge compared to the interparticle spacing and the mean free path. In\naddition, the entire system must consist of many such fluid cells. The latter\nrequirement on the system size has been challenged by experiments on\nhigh-energy heavy-ion collisions, where collective particle emission, typically\nassociated with the formation of a hydrodynamic medium, has been observed with\nfew tens of final-state particles. Here, we demonstrate emergence of\nhydrodynamics in a system with significantly less constituents. Our observation\nchallenges the requirements for a hydrodynamic description, as in our system\nall relevant length scales, i.e. the system size, the inter-particle spacing,\nand the mean free path are comparable. The single particle resolution,\ndeterministic control over particle number and interaction strength in our\nexperiment allow us to explore the boundaries between a microscopic description\nand a hydrodynamic framework in unprecedented detail.",
            "author": [
                "Sandra Brandstetter",
                "Philipp Lunt",
                "Carl Heintze",
                "Giuliano Giacalone",
                "Lars H. Heyen",
                "Maciej Ga\u0142ka",
                "Keerthan Subramanian",
                "Marvin Holten",
                "Philipp M. Preiss",
                "Stefan Floerchinger",
                "Selim Jochim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09699v1",
                "http://arxiv.org/pdf/2308.09699v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas",
                "nucl-ex",
                "nucl-th",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09696v1",
            "title": "Metric and strong metric dimension in inclusion ideal graphs of\n  commutative rings",
            "updated": "2023-08-18T17:45:08Z",
            "published": "2023-08-18T17:45:08Z",
            "summary": "The inclusion ideal graph of a commutative unitary ring $R$ is the\n(undirected) graph $In(R)$ whose vertices all non-trivial ideals of $R$ and two\ndistinct vertices are adjacent if and only if one of them is a proper subset of\nthe other one. In this paper, the metric dimension of $In(R)$ is discussed.\nMoreover, the structure of the resolving graph of $In(R)$ is characterized and\nas an application, we compute the strong metric dimension of $In(R)$.",
            "author": [
                "E. Dodongeh",
                "A. Moussavi",
                "R. Nikandish"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09696v1",
                "http://arxiv.org/pdf/2308.09696v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09690v2",
            "title": "Random Walks, Conductance, and Resistance for the Connection Graph\n  Laplacian",
            "updated": "2023-08-21T01:24:25Z",
            "published": "2023-08-18T17:37:39Z",
            "summary": "We investigate the concept of effective resistance in connection graphs,\nexpanding its traditional application from undirected graphs. We propose a\nrobust definition of effective resistance in connection graphs by focusing on\nthe duality of Dirichlet-type and Poisson-type problems on connection graphs.\nAdditionally, we delve into random walks, taking into account both node\ntransitions and vector rotations. This approach introduces novel concepts of\neffective conductance and resistance matrices for connection graphs, capturing\nmean rotation matrices corresponding to random walk transitions. Thereby, it\nprovides new theoretical insights for network analysis and optimization.",
            "author": [
                "Alexander Cloninger",
                "Gal Mishne",
                "Andreas Oslandsbotn",
                "Sawyer Jack Robertson",
                "Zhengchao Wan",
                "Yusu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09690v2",
                "http://arxiv.org/pdf/2308.09690v2"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09687v3",
            "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
            "updated": "2023-11-24T09:13:54Z",
            "published": "2023-08-18T17:29:23Z",
            "summary": "We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by >31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.",
            "author": [
                "Maciej Besta",
                "Nils Blach",
                "Ales Kubicek",
                "Robert Gerstenberger",
                "Lukas Gianinazzi",
                "Joanna Gajda",
                "Tomasz Lehmann",
                "Michal Podstawski",
                "Hubert Niewiadomski",
                "Piotr Nyczyk",
                "Torsten Hoefler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09687v3",
                "http://arxiv.org/pdf/2308.09687v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09683v2",
            "title": "Near-linear time samplers for matroid independent sets with applications",
            "updated": "2023-09-27T14:11:32Z",
            "published": "2023-08-18T17:10:47Z",
            "summary": "We give a $\\widetilde{O}(n)$ time almost uniform sampler for independent sets\nof a matroid, whose ground set has $n$ elements and is given by an independence\noracle. As a consequence, one can sample connected spanning subgraphs of a\ngiven graph $G=(V,E)$ in $\\widetilde{O}(|E|)$ time. This leads to improved\nrunning time on estimating all-terminal network reliability. Furthermore, we\ngeneralise this near-linear time sampler to the random cluster model with $q\\le\n1$.",
            "author": [
                "Xiaoyu Chen",
                "Heng Guo",
                "Xinyuan Zhang",
                "Zongrui Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09683v2",
                "http://arxiv.org/pdf/2308.09683v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10705v1",
            "title": "Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion\n  Modeling",
            "updated": "2023-08-18T16:41:57Z",
            "published": "2023-08-18T16:41:57Z",
            "summary": "Most of the previous 3D human pose estimation work relied on the powerful\nmemory capability of the network to obtain suitable 2D-3D mappings from the\ntraining data. Few works have studied the modeling of human posture deformation\nin motion. In this paper, we propose a new modeling method for human pose\ndeformations and design an accompanying diffusion-based motion prior. Inspired\nby the field of non-rigid structure-from-motion, we divide the task of\nreconstructing 3D human skeletons in motion into the estimation of a 3D\nreference skeleton, and a frame-by-frame skeleton deformation. A mixed\nspatial-temporal NRSfMformer is used to simultaneously estimate the 3D\nreference skeleton and the skeleton deformation of each frame from 2D\nobservations sequence, and then sum them to obtain the pose of each frame.\nSubsequently, a loss term based on the diffusion model is used to ensure that\nthe pipeline learns the correct prior motion knowledge. Finally, we have\nevaluated our proposed method on mainstream datasets and obtained superior\nresults outperforming the state-of-the-art.",
            "author": [
                "Haorui Ji",
                "Hui Deng",
                "Yuchao Dai",
                "Hongdong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10705v1",
                "http://arxiv.org/pdf/2308.10705v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09663v1",
            "title": "GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent\n  Space Reconstruction",
            "updated": "2023-08-18T16:30:51Z",
            "published": "2023-08-18T16:30:51Z",
            "summary": "Self-supervised learning with masked autoencoders has recently gained\npopularity for its ability to produce effective image or textual\nrepresentations, which can be applied to various downstream tasks without\nretraining. However, we observe that the current masked autoencoder models lack\ngood generalization ability on graph data. To tackle this issue, we propose a\nnovel graph masked autoencoder framework called GiGaMAE. Different from\nexisting masked autoencoders that learn node presentations by explicitly\nreconstructing the original graph components (e.g., features or edges), in this\npaper, we propose to collaboratively reconstruct informative and integrated\nlatent embeddings. By considering embeddings encompassing graph topology and\nattribute information as reconstruction targets, our model could capture more\ngeneralized and comprehensive knowledge. Furthermore, we introduce a mutual\ninformation based reconstruction loss that enables the effective reconstruction\nof multiple targets. This learning objective allows us to differentiate between\nthe exclusive knowledge learned from a single target and common knowledge\nshared by multiple targets. We evaluate our method on three downstream tasks\nwith seven datasets as benchmarks. Extensive experiments demonstrate the\nsuperiority of GiGaMAE against state-of-the-art baselines. We hope our results\nwill shed light on the design of foundation models on graph-structured data.\nOur code is available at: https://github.com/sycny/GiGaMAE.",
            "author": [
                "Yucheng Shi",
                "Yushun Dong",
                "Qiaoyu Tan",
                "Jundong Li",
                "Ninghao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09663v1",
                "http://arxiv.org/pdf/2308.09663v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09662v3",
            "title": "Red-Teaming Large Language Models using Chain of Utterances for\n  Safety-Alignment",
            "updated": "2023-08-30T10:21:00Z",
            "published": "2023-08-18T16:27:04Z",
            "summary": "Larger language models (LLMs) have taken the world by storm with their\nmassive multi-tasking capabilities simply by optimizing over a next-word\nprediction objective. With the emergence of their properties and encoded\nknowledge, the risk of LLMs producing harmful outputs increases, making them\nunfit for scalable deployment for the public. In this work, we propose a new\nsafety evaluation benchmark RED-EVAL that carries out red-teaming. We show that\neven widely deployed models are susceptible to the Chain of Utterances-based\n(CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and\nChatGPT to unethically respond to more than 65% and 73% of harmful queries. We\nalso demonstrate the consistency of the RED-EVAL across 8 open-source LLMs in\ngenerating harmful responses in more than 86% of the red-teaming attempts.\nNext, we propose RED-INSTRUCT--An approach for the safety alignment of LLMs. It\nconstitutes two phases: 1) HARMFULQA data collection: Leveraging CoU prompting,\nwe collect a dataset that consists of 1.9K harmful questions covering a wide\nrange of topics, 9.5K safe and 7.3K harmful conversations from ChatGPT; 2)\nSAFE-ALIGN: We demonstrate how the conversational dataset can be used for the\nsafety alignment of LLMs by minimizing the negative log-likelihood over helpful\nresponses and penalizing over harmful responses by gradient accent over sample\nloss. Our model STARLING, a fine-tuned Vicuna-7B, is observed to be more safely\naligned when evaluated on RED-EVAL and HHH benchmarks while preserving the\nutility of the baseline models (TruthfulQA, MMLU, and BBH).",
            "author": [
                "Rishabh Bhardwaj",
                "Soujanya Poria"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09662v3",
                "http://arxiv.org/pdf/2308.09662v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09650v1",
            "title": "Collision Isolation and Identification Using Proprioceptive Sensing for\n  Parallel Robots to Enable Human-Robot Collaboration",
            "updated": "2023-08-18T16:11:48Z",
            "published": "2023-08-18T16:11:48Z",
            "summary": "Parallel robots (PRs) allow for higher speeds in human-robot collaboration\ndue to their lower moving masses but are more prone to unintended contact. For\na safe reaction, knowledge of the location and force of a collision is useful.\nA novel algorithm for collision isolation and identification with\nproprioceptive information for a real PR is the scope of this work. To classify\nthe collided body, the effects of contact forces at the links and platform of\nthe PR are analyzed using a kinetostatic projection. This insight enables the\nderivation of features from the line of action of the estimated external force.\nThe significance of these features is confirmed in experiments for various load\ncases. A feedforward neural network (FNN) classifies the collided body based on\nthese physically modeled features. Generalization with the FNN to 300k load\ncases on the whole robot structure in other joint angle configurations is\nsuccessfully performed with a collision-body classification accuracy of 84% in\nthe experiments. Platform collisions are isolated and identified with an\nexplicit solution, while a particle filter estimates the location and force of\na contact on a kinematic chain. Updating the particle filter with estimated\nexternal joint torques leads to an isolation error of less than 3cm and an\nidentification error of 4N in a real-world experiment.",
            "author": [
                "Aran Mohammad",
                "Moritz Schappler",
                "Tobias Ortmaier"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09650v1",
                "http://arxiv.org/pdf/2308.09650v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09645v1",
            "title": "The damage number of the Cartesian product of graphs",
            "updated": "2023-08-18T16:06:22Z",
            "published": "2023-08-18T16:06:22Z",
            "summary": "We consider a variation of Cops and Robber, introduced in [D. Cox and A.\nSanaei, The damage number of a graph, [Aust. J. of Comb. 75(1) (2019) 1-16]\nwhere vertices visited by a robber are considered damaged and a single cop aims\nto minimize the number of distinct vertices damaged by a robber. Motivated by\nthe interesting relationships that often emerge between input graphs and their\nCartesian product, we study the damage number of the Cartesian product of\ngraphs. We provide a general upper bound and consider the damage number of the\nproduct of two trees or cycles. We also consider graphs with small damage\nnumber.",
            "author": [
                "Melissa A. Huggan",
                "Margaret-Ellen Messinger",
                "Amanda Porter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09645v1",
                "http://arxiv.org/pdf/2308.09645v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C57, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09644v1",
            "title": "A Potts model approach to unsupervised graph clustering with Graph\n  Neural Networks",
            "updated": "2023-08-18T16:02:15Z",
            "published": "2023-08-18T16:02:15Z",
            "summary": "Numerous approaches have been explored for graph clustering, including those\nwhich optimize a global criteria such as modularity. More recently, Graph\nNeural Networks (GNNs), which have produced state-of-the-art results in graph\nanalysis tasks such as node classification and link prediction, have been\napplied for unsupervised graph clustering using these modularity-based metrics.\nModularity, though robust for many practical applications, suffers from the\nresolution limit problem, in which optimization may fail to identify clusters\nsmaller than a scale that is dependent on properties of the network. In this\npaper, we propose a new GNN framework which draws from the Potts model in\nphysics to overcome this limitation. Experiments on a variety of real world\ndatasets show that this model achieves state-of-the-art clustering results.",
            "author": [
                "Co Tran",
                "Mo Badawy",
                "Tyler McDonnell"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09644v1",
                "http://arxiv.org/pdf/2308.09644v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09625v1",
            "title": "Multi-Weighted Reachability Games",
            "updated": "2023-08-18T15:36:59Z",
            "published": "2023-08-18T15:36:59Z",
            "summary": "We study two-player multi-weighted reachability games played on a finite\ndirected graph, where an agent, called P1, has several quantitative\nreachability objectives that he wants to optimize against an antagonistic\nenvironment, called P2. In this setting, we ask what cost profiles P1 can\nensure regardless of the opponent's behavior. Cost profiles are compared thanks\nto: (i) a lexicographic order that ensures the unicity of an upper value and\n(ii) a componentwise order for which we consider the Pareto frontier. We\nsynthesize (i) lexico-optimal strategies and (ii) Pareto-optimal strategies.\nThe strategies are obtained thanks to a fixpoint algorithm which also computes\nthe upper value in polynomial time and the Pareto frontier in exponential time.\nFinally, the constrained existence problem is proved in P for the lexicographic\norder and PSPACE-complete for the componentwise order.",
            "author": [
                "Thomas Brihaye",
                "Aline Goeminne"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09625v1",
                "http://arxiv.org/pdf/2308.09625v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09613v1",
            "title": "A scalable clustering algorithm to approximate graph cuts",
            "updated": "2023-08-18T15:14:59Z",
            "published": "2023-08-18T15:14:59Z",
            "summary": "Due to its computational complexity, graph cuts for cluster detection and\nidentification are used mostly in the form of convex relaxations. We propose to\nutilize the original graph cuts such as Ratio, Normalized or Cheeger Cut in\norder to detect clusters in weighted undirected graphs by restricting the graph\ncut minimization to the subset of $st$-MinCut partitions. Incorporating a\nvertex selection technique and restricting optimization to tightly connected\nclusters, we therefore combine the efficient computability of $st$-MinCuts and\nthe intrinsic properties of Gomory-Hu trees with the cut quality of the\noriginal graph cuts, leading to linear runtime in the number of vertices and\nquadratic in the number of edges. Already in simple scenarios, the resulting\nalgorithm Xist is able to approximate graph cut values better empirically than\nspectral clustering or comparable algorithms, even for large network datasets.\nWe showcase its applicability by segmenting images from cell biology and\nprovide empirical studies of runtime and classification rate.",
            "author": [
                "Leo Suchan",
                "Housen Li",
                "Axel Munk"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09613v1",
                "http://arxiv.org/pdf/2308.09613v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "68W25 (Primary), 68R10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09596v1",
            "title": "Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks\n  for Node Classification",
            "updated": "2023-08-18T14:45:28Z",
            "published": "2023-08-18T14:45:28Z",
            "summary": "Graph neural networks (GNNs) are increasingly used in critical human\napplications for predicting node labels in attributed graphs. Their ability to\naggregate features from nodes' neighbors for accurate classification also has\nthe capacity to exacerbate existing biases in data or to introduce new ones\ntowards members from protected demographic groups. Thus, it is imperative to\nquantify how GNNs may be biased and to what extent their harmful effects may be\nmitigated. To this end, we propose two new GNN-agnostic interventions namely,\n(i) PFR-AX which decreases the separability between nodes in protected and\nnon-protected groups, and (ii) PostProcess which updates model predictions\nbased on a blackbox policy to minimize differences between error rates across\ndemographic groups. Through a large set of experiments on four datasets, we\nframe the efficacies of our approaches (and three variants) in terms of their\nalgorithmic fairness-accuracy tradeoff and benchmark our results against three\nstrong baseline interventions on three state-of-the-art GNN models. Our results\nshow that no single intervention offers a universally optimal tradeoff, but\nPFR-AX and PostProcess provide granular control and improve model confidence\nwhen correctly predicting positive outcomes for nodes in protected groups.",
            "author": [
                "Arpit Merchant",
                "Carlos Castillo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09596v1",
                "http://arxiv.org/pdf/2308.09596v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09585v1",
            "title": "Bounding Clique Size in Squares of Planar Graphs",
            "updated": "2023-08-18T14:23:47Z",
            "published": "2023-08-18T14:23:47Z",
            "summary": "Wegner conjectured that if $G$ is a planar graph with maximum degree\n$\\Delta\\ge 8$, then $\\chi(G^2)\\le \\left\\lfloor \\frac32\\Delta\\right\\rfloor +1$.\nThis problem has received much attention, but remains open for all $\\Delta\\ge\n8$. Here we prove an analogous bound on $\\omega(G^2)$: If $G$ is a plane graph\nwith $\\Delta(G)\\ge 36$, then $\\omega(G^2)\\le \\lfloor\\frac32\\Delta(G)\\rfloor+1$.\nIn fact, this is a corollary of the following lemma, which is our main result.\nIf $G$ is a plane graph with $\\Delta(G)\\ge 19$ and $S$ is a maximal clique in\n$G^2$ with $|S|\\ge \\Delta(G)+20$, then there exist $x,y,z\\in V(G)$ such that\n$S=\\{w:|N[w]\\cap\\{x,y,z\\}|\\ge 2\\}$.",
            "author": [
                "Daniel W. Cranston"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09585v1",
                "http://arxiv.org/pdf/2308.09585v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09570v1",
            "title": "Investigating the Interplay between Features and Structures in Graph\n  Learning",
            "updated": "2023-08-18T14:02:56Z",
            "published": "2023-08-18T14:02:56Z",
            "summary": "In the past, the dichotomy between homophily and heterophily has inspired\nresearch contributions toward a better understanding of Deep Graph Networks'\ninductive bias. In particular, it was believed that homophily strongly\ncorrelates with better node classification predictions of message-passing\nmethods. More recently, however, researchers pointed out that such dichotomy is\ntoo simplistic as we can construct node classification tasks where graphs are\ncompletely heterophilic but the performances remain high. Most of these works\nhave also proposed new quantitative metrics to understand when a graph\nstructure is useful, which implicitly or explicitly assume the correlation\nbetween node features and target labels. Our work empirically investigates what\nhappens when this strong assumption does not hold, by formalising two\ngenerative processes for node classification tasks that allow us to build and\nstudy ad-hoc problems. To quantitatively measure the influence of the node\nfeatures on the target labels, we also use a metric we call Feature\nInformativeness. We construct six synthetic tasks and evaluate the performance\nof six models, including structure-agnostic ones. Our findings reveal that\npreviously defined metrics are not adequate when we relax the above assumption.\nOur contribution to the workshop aims at presenting novel research findings\nthat could help advance our understanding of the field.",
            "author": [
                "Daniele Castellana",
                "Federico Errica"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09570v1",
                "http://arxiv.org/pdf/2308.09570v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09561v2",
            "title": "ShockHash: Towards Optimal-Space Minimal Perfect Hashing Beyond\n  Brute-Force",
            "updated": "2023-11-13T12:39:31Z",
            "published": "2023-08-18T13:51:36Z",
            "summary": "A minimal perfect hash function (MPHF) maps a set $S$ of $n$ keys to the\nfirst $n$ integers without collisions. There is a lower bound of\n$n\\log_2e-O(\\log n)$ bits of space needed to represent an MPHF. A matching\nupper bound is obtained using the brute-force algorithm that tries random hash\nfunctions until stumbling on an MPHF and stores that function's seed. In\nexpectation, $e^n\\textrm{poly}(n)$ seeds need to be tested. The most\nspace-efficient previous algorithms for constructing MPHFs all use such a\nbrute-force approach as a basic building block.\n  In this paper, we introduce ShockHash - Small, heavily overloaded cuckoo hash\ntables. ShockHash uses two hash functions $h_0$ and $h_1$, hoping for the\nexistence of a function $f : S \\rightarrow \\{0,1\\}$ such that $x \\mapsto\nh_{f(x)}(x)$ is an MPHF on $S$. In graph terminology, ShockHash generates\n$n$-edge random graphs until stumbling on a pseudoforest - a graph where each\ncomponent contains as many edges as nodes. Using cuckoo hashing, ShockHash then\nderives an MPHF from the pseudoforest in linear time. It uses a 1-bit retrieval\ndata structure to store $f$ using $n + o(n)$ bits.\n  By carefully analyzing the probability that a random graph is a pseudoforest,\nwe show that ShockHash needs to try only $(e/2)^n\\textrm{poly}(n)$ hash\nfunction seeds in expectation, reducing the space for storing the seed by\nroughly $n$ bits. This makes ShockHash almost a factor $2^n$ faster than\nbrute-force, while maintaining the asymptotically optimal space consumption. An\nimplementation within the RecSplit framework yields the currently most space\nefficient MPHFs, i.e., competing approaches need about two orders of magnitude\nmore work to achieve the same space.",
            "author": [
                "Hans-Peter Lehmann",
                "Peter Sanders",
                "Stefan Walzer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09561v2",
                "http://arxiv.org/pdf/2308.09561v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09558v1",
            "title": "Genomic reproducibility in the bioinformatics era",
            "updated": "2023-08-18T13:43:36Z",
            "published": "2023-08-18T13:43:36Z",
            "summary": "In biomedical research, validation of a new scientific discovery is tied to\nthe reproducibility of its experimental results. However, in genomics, the\ndefinition and implementation of reproducibility still remain imprecise. Here,\nwe argue that genomic reproducibility, defined as the ability of bioinformatics\ntools to maintain consistent genomics results across technical replicates, is\nkey to generating scientific knowledge and enabling medical applications. We\nfirst discuss different concepts of reproducibility and then focus on\nreproducibility in the context of genomics, aiming to establish clear\ndefinitions of relevant terms. We then focus on the role of bioinformatics\ntools and their impact on genomic reproducibility and assess methods of\nevaluating bioinformatics tools in terms of genomic reproducibility. Lastly, we\nsuggest best practices for enhancing genomic reproducibility, with an emphasis\non assessing the performance of bioinformatics tools through rigorous testing\nacross multiple technical replicates.",
            "author": [
                "Pelin Icer Baykal",
                "Pawe\u0142 P. \u0141abaj",
                "Florian Markowetz",
                "Lynn M. Schriml",
                "Daniel J. Stekhoven",
                "Serghei Mangul",
                "Niko Beerenwinkel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09558v1",
                "http://arxiv.org/pdf/2308.09558v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09547v1",
            "title": "Test Code Refactoring Unveiled: Where and How Does It Affect Test Code\n  Quality and Effectiveness?",
            "updated": "2023-08-18T13:25:53Z",
            "published": "2023-08-18T13:25:53Z",
            "summary": "Context. Refactoring has been widely investigated in the past in relation to\nproduction code quality, yet still little is known on how developers apply\nrefactoring on test code. Specifically, there is still a lack of investigation\ninto how developers typically refactor test code and its effects on test code\nquality and effectiveness. Objective. This paper presents a research agenda\naimed to bridge this gap of knowledge by investigating (1) whether test\nrefactoring actually targets test classes affected by quality and effectiveness\nconcerns and (2) the extent to which refactoring contributes to the improvement\nof test code quality and effectiveness. Method. We plan to conduct an\nexploratory mining software repository study to collect test refactoring data\nof open-source Java projects from GitHub and statistically analyze them in\ncombination with quality metrics, test smells, and code/mutation coverage\nindicators. Furthermore, we will measure how refactoring operations impact the\nquality and effectiveness of test code.",
            "author": [
                "Luana Martins",
                "Valeria Pontillo",
                "Heitor Costa",
                "Filomena Ferrucci",
                "Fabio Palomba",
                "Ivan Machado"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09547v1",
                "http://arxiv.org/pdf/2308.09547v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09544v3",
            "title": "Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free\n  Continual Learning",
            "updated": "2023-11-04T14:06:24Z",
            "published": "2023-08-18T13:22:59Z",
            "summary": "In this work, we investigate exemplar-free class incremental learning (CIL)\nwith knowledge distillation (KD) as a regularization strategy, aiming to\nprevent forgetting. KD-based methods are successfully used in CIL, but they\noften struggle to regularize the model without access to exemplars of the\ntraining data from previous tasks. Our analysis reveals that this issue\noriginates from substantial representation shifts in the teacher network when\ndealing with out-of-distribution data. This causes large errors in the KD loss\ncomponent, leading to performance degradation in CIL models. Inspired by recent\ntest-time adaptation methods, we introduce Teacher Adaptation (TA), a method\nthat concurrently updates the teacher and the main models during incremental\ntraining. Our method seamlessly integrates with KD-based CIL approaches and\nallows for consistent enhancement of their performance across multiple\nexemplar-free CIL benchmarks. The source code for our method is available at\nhttps://github.com/fszatkowski/cl-teacher-adaptation.",
            "author": [
                "Filip Szatkowski",
                "Mateusz Pyla",
                "Marcin Przewi\u0119\u017alikowski",
                "Sebastian Cygert",
                "Bart\u0142omiej Twardowski",
                "Tomasz Trzci\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09544v3",
                "http://arxiv.org/pdf/2308.09544v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09525v1",
            "title": "Improving 3D Pose Estimation for Sign Language",
            "updated": "2023-08-18T13:05:10Z",
            "published": "2023-08-18T13:05:10Z",
            "summary": "This work addresses 3D human pose reconstruction in single images. We present\na method that combines Forward Kinematics (FK) with neural networks to ensure a\nfast and valid prediction of 3D pose. Pose is represented as a hierarchical\ntree/graph with nodes corresponding to human joints that model their physical\nlimits. Given a 2D detection of keypoints in the image, we lift the skeleton to\n3D using neural networks to predict both the joint rotations and bone lengths.\nThese predictions are then combined with skeletal constraints using an FK layer\nimplemented as a network layer in PyTorch. The result is a fast and accurate\napproach to the estimation of 3D skeletal pose. Through quantitative and\nqualitative evaluation, we demonstrate the method is significantly more\naccurate than MediaPipe in terms of both per joint positional error and visual\nappearance. Furthermore, we demonstrate generalization over different datasets.\nThe implementation in PyTorch runs at between 100-200 milliseconds per image\n(including CNN detection) using CPU only.",
            "author": [
                "Maksym Ivashechkin",
                "Oscar Mendez",
                "Richard Bowden"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09525v1",
                "http://arxiv.org/pdf/2308.09525v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09517v1",
            "title": "Transitivity-Preserving Graph Representation Learning for Bridging Local\n  Connectivity and Role-based Similarity",
            "updated": "2023-08-18T12:49:57Z",
            "published": "2023-08-18T12:49:57Z",
            "summary": "Graph representation learning (GRL) methods, such as graph neural networks\nand graph transformer models, have been successfully used to analyze\ngraph-structured data, mainly focusing on node classification and link\nprediction tasks. However, the existing studies mostly only consider local\nconnectivity while ignoring long-range connectivity and the roles of nodes. In\nthis paper, we propose Unified Graph Transformer Networks (UGT) that\neffectively integrate local and global structural information into fixed-length\nvector representations. First, UGT learns local structure by identifying the\nlocal substructures and aggregating features of the $k$-hop neighborhoods of\neach node. Second, we construct virtual edges, bridging distant nodes with\nstructural similarity to capture the long-range dependencies. Third, UGT learns\nunified representations through self-attention, encoding structural distance\nand $p$-step transition probability between node pairs. Furthermore, we propose\na self-supervised learning task that effectively learns transition probability\nto fuse local and global structural features, which could then be transferred\nto other downstream tasks. Experimental results on real-world benchmark\ndatasets over various downstream tasks showed that UGT significantly\noutperformed baselines that consist of state-of-the-art models. In addition,\nUGT reaches the expressive power of the third-order Weisfeiler-Lehman\nisomorphism test (3d-WL) in distinguishing non-isomorphic graph pairs. The\nsource code is available at\nhttps://github.com/NSLab-CUK/Unified-Graph-Transformer.",
            "author": [
                "Van Thuy Hoang",
                "O-Joun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09517v1",
                "http://arxiv.org/pdf/2308.09517v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09502v1",
            "title": "Semantic relatedness in DBpedia: A comparative and experimental\n  assessment",
            "updated": "2023-08-18T12:26:10Z",
            "published": "2023-08-18T12:26:10Z",
            "summary": "Evaluating semantic relatedness of Web resources is still an open challenge.\nThis paper focuses on knowledge-based methods, which represent an alternative\nto corpus-based approaches, and rely in general on the availability of\nknowledge graphs. In particular, we have selected 10 methods from the existing\nliterature, that have been organized according to it adjacent resources, triple\npatterns, and triple weights-based methods. They have been implemented and\nevaluated by using DBpedia as reference RDF knowledge graph. Since DBpedia is\ncontinuously evolving, the experimental results provided by these methods in\nthe literature are not comparable. For this reason, in this work, such methods\nhave been experimented by running them all at once on the same DBpedia release\nand against 14 well-known golden datasets. On the basis of the correlation\nvalues with human judgment obtained according to the experimental results,\nweighting the RDF triples in combination with evaluating all the directed paths\nlinking the compared resources is the best strategy in order to compute\nsemantic relatedness in DBpedia.",
            "author": [
                "Anna Formica",
                "Francesco Taglino"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.ins.2022.11.025",
                "http://arxiv.org/abs/2308.09502v1",
                "http://arxiv.org/pdf/2308.09502v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09501v1",
            "title": "Anonymous Refugee Housing with Upper-Bounds",
            "updated": "2023-08-18T12:16:36Z",
            "published": "2023-08-18T12:16:36Z",
            "summary": "Knop and Schierreich [AAMAS '23] recently introduced a novel model of refugee\nhousing and specifically asked for the computational complexity picture of the\nfollowing variant. Given a topology modelled as an undirected graph, a set of\ninhabitants, a number of refugees $R$, an assignment of inhabitants to houses\nof the topology, and an upper-bound for every inhabitant, find a set $\\pi$ of\nunoccupied houses of size $R$ intended such that the number of refugees in the\nneighbourhood of every inhabitant is at most its upper-bound. If such a set\n$\\pi$ exists, we say that the instance admits an inhabitant-respecting housing.\n  In this paper, we show that the existence of inhabitant-respecting housing is\nnot guaranteed even under several further restrictions of the upper-bounds.\nThen, we focus on the computational complexity of deciding whether\ninhabitant-respecting housing exists. To this end, we provide tractable\nalgorithms for several restrictions of the topology. We complement these\nresults with appropriate hardness results and running-time lower-bounds.\nFurthermore, we introduce a relaxed (or approximate) version of the\ninhabitant-respecting housing, where we allow at most $t$ upper-bounds to be\nexceeded.",
            "author": [
                "\u0160imon Schierreich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09501v1",
                "http://arxiv.org/pdf/2308.09501v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09499v1",
            "title": "Bridged-GNN: Knowledge Bridge Learning for Effective Knowledge Transfer",
            "updated": "2023-08-18T12:14:51Z",
            "published": "2023-08-18T12:14:51Z",
            "summary": "The data-hungry problem, characterized by insufficiency and low-quality of\ndata, poses obstacles for deep learning models. Transfer learning has been a\nfeasible way to transfer knowledge from high-quality external data of source\ndomains to limited data of target domains, which follows a domain-level\nknowledge transfer to learn a shared posterior distribution. However, they are\nusually built on strong assumptions, e.g., the domain invariant posterior\ndistribution, which is usually unsatisfied and may introduce noises, resulting\nin poor generalization ability on target domains. Inspired by Graph Neural\nNetworks (GNNs) that aggregate information from neighboring nodes, we redefine\nthe paradigm as learning a knowledge-enhanced posterior distribution for target\ndomains, namely Knowledge Bridge Learning (KBL). KBL first learns the scope of\nknowledge transfer by constructing a Bridged-Graph that connects knowledgeable\nsamples to each target sample and then performs sample-wise knowledge transfer\nvia GNNs.KBL is free from strong assumptions and is robust to noises in the\nsource data. Guided by KBL, we propose the Bridged-GNN} including an Adaptive\nKnowledge Retrieval module to build Bridged-Graph and a Graph Knowledge\nTransfer module. Comprehensive experiments on both un-relational and relational\ndata-hungry scenarios demonstrate the significant improvements of Bridged-GNN\ncompared with SOTA methods",
            "author": [
                "Wendong Bi",
                "Xueqi Cheng",
                "Bingbing Xu",
                "Xiaoqian Sun",
                "Li Xu",
                "Huawei Shen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614796",
                "http://arxiv.org/abs/2308.09499v1",
                "http://arxiv.org/pdf/2308.09499v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09492v2",
            "title": "Predicting Properties of Oxide Glasses Using Informed Neural Networks",
            "updated": "2023-10-16T13:35:29Z",
            "published": "2023-08-18T12:02:11Z",
            "summary": "Many modern-day applications require the development of new materials with\nspecific properties. In particular, the design of new glass compositions is of\ngreat industrial interest. Current machine learning methods for learning the\ncomposition-property relationship of glasses promise to save on expensive\ntrial-and-error approaches. Even though quite large datasets on the composition\nof glasses and their properties already exist (i.e., with more than 350,000\nsamples), they cover only a very small fraction of the space of all possible\nglass compositions. This limits the applicability of purely data-driven models\nfor property prediction purposes and necessitates the development of models\nwith high extrapolation power. In this paper, we propose a neural network model\nwhich incorporates prior scientific and expert knowledge in its learning\npipeline. This informed learning approach leads to an improved extrapolation\npower compared to blind (uninformed) neural network models. To demonstrate\nthis, we train our models to predict three different material properties, that\nis, the glass transition temperature, the Young's modulus (at room\ntemperature), and the shear modulus of binary oxide glasses which do not\ncontain sodium. As representatives for conventional blind neural network\napproaches we use five different feed-forward neural networks of varying widths\nand depths. For each property, we set up model ensembles of multiple trained\nmodels and show that, on average, our proposed informed model performs better\nin extrapolating the three properties of previously unseen sodium borate glass\nsamples than all five conventional blind models.",
            "author": [
                "Gregor Maier",
                "Jan Hamaekers",
                "Dominik-Sergio Martilotti",
                "Benedikt Ziebarth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09492v2",
                "http://arxiv.org/pdf/2308.09492v2"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.dis-nn",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09491v1",
            "title": "A note on removable edges in near-bricks",
            "updated": "2023-08-18T12:00:36Z",
            "published": "2023-08-18T12:00:36Z",
            "summary": "An edge $e$ of a matching covered graph $G$ is removable if $G-e$ is also\nmatching covered. Carvalho, Lucchesi, and Murty showed that every brick $G$\ndifferent from $K_4$ and $\\overline{C_6}$ has at least $\\Delta-2$ removable\nedges, where $\\Delta$ is the maximum degree of $G$. In this paper, we\ngeneralize the result to irreducible near-bricks, where a graph is irreducible\nif it contains no induced odd path of length three or more.",
            "author": [
                "Deyu Wu",
                "Yipei Zhang",
                "Xiumei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09491v1",
                "http://arxiv.org/pdf/2308.09491v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09487v3",
            "title": "Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High\n  Attack Success Rate in the Absence of Training Data",
            "updated": "2023-10-14T13:30:41Z",
            "published": "2023-08-18T11:49:33Z",
            "summary": "To successfully launch backdoor attacks, injected data needs to be correctly\nlabeled; otherwise, they can be easily detected by even basic data filters.\nHence, the concept of clean-label attacks was introduced, which is more\ndangerous as it doesn't require changing the labels of injected data. To the\nbest of our knowledge, the existing clean-label backdoor attacks largely relies\non an understanding of the entire training set or a portion of it. However, in\npractice, it is very difficult for attackers to have it because of training\ndatasets often collected from multiple independent sources. Unlike all current\nclean-label attacks, we propose a novel clean label method called 'Poison Dart\nFrog'. Poison Dart Frog does not require access to any training data; it only\nnecessitates knowledge of the target class for the attack, such as 'frog'. On\nCIFAR10, Tiny-ImageNet, and TSRD, with a mere 0.1\\%, 0.025\\%, and 0.4\\%\npoisoning rate of the training set size, respectively, Poison Dart Frog\nachieves a high Attack Success Rate compared to LC, HTBA, BadNets, and Blend.\nFurthermore, compared to the state-of-the-art attack, NARCISSUS, Poison Dart\nFrog achieves similar attack success rates without any training data. Finally,\nwe demonstrate that four typical backdoor defense algorithms struggle to\ncounter Poison Dart Frog.",
            "author": [
                "Binhao Ma",
                "Jiahui Wang",
                "Dejun Wang",
                "Bo Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09487v3",
                "http://arxiv.org/pdf/2308.09487v3"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09478v1",
            "title": "Summary of the 3rd International Workshop on Requirements Engineering\n  and Testing",
            "updated": "2023-08-18T11:32:23Z",
            "published": "2023-08-18T11:32:23Z",
            "summary": "The RET (Requirements Engineering and Testing) workshop series provides a\nmeeting point for researchers and practitioners from the two separate fields of\nRequirements Engineering (RE) and Testing. The goal is to improve the\nconnection and alignment of these two areas through an exchange of ideas,\nchallenges, practices, experiences and results. The long term aim is to build a\ncommunity and a body of knowledge within the intersection of RE and Testing,\ni.e. RET. The 3rd workshop was held in co-location with REFSQ 2016 in\nGothenburg, Sweden. The workshop continued in the same interactive vein as the\npredecessors and included a keynote, paper presentations with ample time for\ndiscussions, and panels. In order to create an RET knowledge base, this\ncrosscutting area elicits contributions from both RE and Testing, and from both\nresearchers and practitioners. A range of papers were presented from short\npositions papers to full research papers that cover connections between the two\nfields.",
            "author": [
                "Michael Unterkalmsteiner",
                "Gregory Gay",
                "Michael Felderer",
                "Elizabeth Bjarnason",
                "Markus Borg",
                "Mirko Morandini"
            ],
            "link": [
                "http://dx.doi.org/10.1145/2934240.2934249",
                "http://arxiv.org/abs/2308.09478v1",
                "http://arxiv.org/pdf/2308.09478v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11029v2",
            "title": "RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for\n  Emotion Recognition",
            "updated": "2023-08-31T04:36:30Z",
            "published": "2023-08-18T11:29:12Z",
            "summary": "Emotion recognition in conversation (ERC) has received increasing attention\nfrom researchers due to its wide range of applications.As conversation has a\nnatural graph structure,numerous approaches used to model ERC based on graph\nconvolutional networks (GCNs) have yielded significant results.However,the\naggregation approach of traditional GCNs suffers from the node information\nredundancy problem,leading to node discriminant information\nloss.Additionally,single-layer GCNs lack the capacity to capture long-range\ncontextual information from the graph. Furthermore,the majority of approaches\nare based on textual modality or stitching together different modalities,\nresulting in a weak ability to capture interactions between modalities. To\naddress these problems, we present the relational bilevel aggregation graph\nconvolutional network (RBA-GCN), which consists of three modules: the graph\ngeneration module (GGM), similarity-based cluster building module (SCBM) and\nbilevel aggregation module (BiAM). First, GGM constructs a novel graph to\nreduce the redundancy of target node information.Then,SCBM calculates the node\nsimilarity in the target node and its structural neighborhood, where noisy\ninformation with low similarity is filtered out to preserve the discriminant\ninformation of the node. Meanwhile, BiAM is a novel aggregation method that can\npreserve the information of nodes during the aggregation process. This module\ncan construct the interaction between different modalities and capture\nlong-range contextual information based on similarity clusters. On both the\nIEMOCAP and MELD datasets, the weighted average F1 score of RBA-GCN has a\n2.17$\\sim$5.21\\% improvement over that of the most advanced method.Our code is\navailable at https://github.com/luftmenscher/RBA-GCN and our article with the\nsame name has been published in IEEE/ACM Transactions on Audio,Speech,and\nLanguage Processing,vol.31,2023",
            "author": [
                "Lin Yuan",
                "Guoheng Huang",
                "Fenghuan Li",
                "Xiaochen Yuan",
                "Chi-Man Pun",
                "Guo Zhong"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TASLP.2023.3284509",
                "http://arxiv.org/abs/2308.11029v2",
                "http://arxiv.org/pdf/2308.11029v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09475v1",
            "title": "Video-Instrument Synergistic Network for Referring Video Instrument\n  Segmentation in Robotic Surgery",
            "updated": "2023-08-18T11:24:06Z",
            "published": "2023-08-18T11:24:06Z",
            "summary": "Robot-assisted surgery has made significant progress, with instrument\nsegmentation being a critical factor in surgical intervention quality. It\nserves as the building block to facilitate surgical robot navigation and\nsurgical education for the next generation of operating intelligence. Although\nexisting methods have achieved accurate instrument segmentation results, they\nsimultaneously generate segmentation masks for all instruments, without the\ncapability to specify a target object and allow an interactive experience. This\nwork explores a new task of Referring Surgical Video Instrument Segmentation\n(RSVIS), which aims to automatically identify and segment the corresponding\nsurgical instruments based on the given language expression. To achieve this,\nwe devise a novel Video-Instrument Synergistic Network (VIS-Net) to learn both\nvideo-level and instrument-level knowledge to boost performance, while previous\nwork only used video-level information. Meanwhile, we design a Graph-based\nRelation-aware Module (GRM) to model the correlation between multi-modal\ninformation (i.e., textual description and video frame) to facilitate the\nextraction of instrument-level information. We are also the first to produce\ntwo RSVIS datasets to promote related research. Our method is verified on these\ndatasets, and experimental results exhibit that the VIS-Net can significantly\noutperform existing state-of-the-art referring segmentation methods. Our code\nand our datasets will be released upon the publication of this work.",
            "author": [
                "Hongqiu Wang",
                "Lei Zhu",
                "Guang Yang",
                "Yike Guo",
                "Shichen Zhang",
                "Bo Xu",
                "Yueming Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09475v1",
                "http://arxiv.org/pdf/2308.09475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09474v2",
            "title": "AI Hilbert: A New Paradigm for Scientific Discovery by Unifying Data and\n  Background Knowledge",
            "updated": "2023-09-23T11:50:07Z",
            "published": "2023-08-18T11:19:41Z",
            "summary": "The discovery of scientific formulae that parsimoniously explain natural\nphenomena and align with existing background theory is a key goal in science.\nHistorically, scientists have derived natural laws by manipulating equations\nbased on existing knowledge, forming new equations, and verifying them\nexperimentally. In recent years, data-driven scientific discovery has emerged\nas a viable competitor in settings with large amounts of experimental data.\nUnfortunately, data-driven methods often fail to discover valid laws when data\nis noisy or scarce. Accordingly, recent works combine regression and reasoning\nto eliminate formulae inconsistent with background theory. However, the problem\nof searching over the space of formulae consistent with background theory to\nfind one that fits the data best is not well-solved. We propose a solution to\nthis problem when all axioms and scientific laws are expressible via polynomial\nequalities and inequalities and argue that our approach is widely applicable.\nWe further model notions of minimal complexity using binary variables and\nlogical constraints, solve polynomial optimization problems via mixed-integer\nlinear or semidefinite optimization, and prove the validity of our scientific\ndiscoveries in a principled manner using Positivestellensatz certificates.\nRemarkably, the optimization techniques leveraged in this paper allow our\napproach to run in polynomial time with fully correct background theory, or\nnon-deterministic polynomial (NP) time with partially correct background\ntheory. We demonstrate that some famous scientific laws, including Kepler's\nThird Law of Planetary Motion, the Hagen-Poiseuille Equation, and the Radiated\nGravitational Wave Power equation, can be derived in a principled manner from\nbackground axioms and experimental data.",
            "author": [
                "Ryan Cory-Wright",
                "Bachir El Khadir",
                "Cristina Cornelio",
                "Sanjeeb Dash",
                "Lior Horesh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09474v2",
                "http://arxiv.org/pdf/2308.09474v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09472v1",
            "title": "Vision Relation Transformer for Unbiased Scene Graph Generation",
            "updated": "2023-08-18T11:15:31Z",
            "published": "2023-08-18T11:15:31Z",
            "summary": "Recent years have seen a growing interest in Scene Graph Generation (SGG), a\ncomprehensive visual scene understanding task that aims to predict entity\nrelationships using a relation encoder-decoder pipeline stacked on top of an\nobject encoder-decoder backbone. Unfortunately, current SGG methods suffer from\nan information loss regarding the entities local-level cues during the relation\nencoding process. To mitigate this, we introduce the Vision rElation\nTransfOrmer (VETO), consisting of a novel local-level entity relation encoder.\nWe further observe that many existing SGG methods claim to be unbiased, but are\nstill biased towards either head or tail classes. To overcome this bias, we\nintroduce a Mutually Exclusive ExperT (MEET) learning strategy that captures\nimportant relation features without bias towards head or tail classes.\nExperimental results on the VG and GQA datasets demonstrate that VETO + MEET\nboosts the predictive performance by up to 47 percentage over the state of the\nart while being 10 times smaller.",
            "author": [
                "Gopika Sudhakaran",
                "Devendra Singh Dhami",
                "Kristian Kersting",
                "Stefan Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09472v1",
                "http://arxiv.org/pdf/2308.09472v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09443v1",
            "title": "Quantitative Reachability Stackelberg-Pareto Synthesis is\n  NEXPTIME-Complete",
            "updated": "2023-08-18T10:17:18Z",
            "published": "2023-08-18T10:17:18Z",
            "summary": "In this paper, we deepen the study of two-player Stackelberg games played on\ngraphs in which Player $0$ announces a strategy and Player $1$, having several\nobjectives, responds rationally by following plays providing him Pareto-optimal\npayoffs given the strategy of Player $0$. The Stackelberg-Pareto synthesis\nproblem, asking whether Player $0$ can announce a strategy which satisfies his\nobjective, whatever the rational response of Player $1$, has been recently\ninvestigated for $\\omega$-regular objectives. We solve this problem for\nweighted graph games and quantitative reachability objectives such that Player\n$0$ wants to reach his target set with a total cost less than some given upper\nbound. We show that it is NEXPTIME-complete, as for Boolean reachability\nobjectives.",
            "author": [
                "Thomas Brihaye",
                "V\u00e9ronique Bruy\u00e8re",
                "Gaspard Reghem"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09443v1",
                "http://arxiv.org/pdf/2308.09443v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09440v3",
            "title": "Scope is all you need: Transforming LLMs for HPC Code",
            "updated": "2023-09-29T16:11:13Z",
            "published": "2023-08-18T10:12:03Z",
            "summary": "With easier access to powerful compute resources, there is a growing trend in\nthe field of AI for software development to develop larger and larger language\nmodels (LLMs) to address a variety of programming tasks. Even LLMs applied to\ntasks from the high-performance computing (HPC) domain are huge in size (e.g.,\nbillions of parameters) and demand expensive compute resources for training. We\nfound this design choice confusing - why do we need large LLMs trained on\nnatural languages and programming languages unrelated to HPC for HPC-specific\ntasks? In this line of work, we aim to question design choices made by existing\nLLMs by developing smaller LLMs for specific domains - we call them\ndomain-specific LLMs. Specifically, we start off with HPC as a domain and\npropose a novel tokenizer named Tokompiler, designed specifically for\npreprocessing code in HPC and compilation-centric tasks. Tokompiler leverages\nknowledge of language primitives to generate language-oriented tokens,\nproviding a context-aware understanding of code structure while avoiding human\nsemantics attributed to code structures completely. We applied Tokompiler to\npre-train two state-of-the-art models, SPT-Code and Polycoder, for a Fortran\ncode corpus mined from GitHub. We evaluate the performance of these models\nagainst the conventional LLMs. Results demonstrate that Tokompiler\nsignificantly enhances code completion accuracy and semantic understanding\ncompared to traditional tokenizers in normalized-perplexity tests, down to ~1\nperplexity score. This research opens avenues for further advancements in\ndomain-specific LLMs, catering to the unique demands of HPC and compilation\ntasks.",
            "author": [
                "Tal Kadosh",
                "Niranjan Hasabnis",
                "Vy A. Vo",
                "Nadav Schneider",
                "Neva Krien",
                "Abdul Wasay",
                "Nesreen Ahmed",
                "Ted Willke",
                "Guy Tamir",
                "Yuval Pinter",
                "Timothy Mattson",
                "Gal Oren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09440v3",
                "http://arxiv.org/pdf/2308.09440v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09425v1",
            "title": "Sampling Random Cycle-Rooted Spanning Forests on Infinite Graphs",
            "updated": "2023-08-18T09:49:59Z",
            "published": "2023-08-18T09:49:59Z",
            "summary": "On a finite graph, there is a natural family of Boltzmann probability\nmeasures on cycle-rooted spanning forests, parametrized by weights on cycles.\nFor a certain subclass of those weights, we construct Gibbs measures in\ninfinite volume, as limits of probability measures on cycle-rooted spanning\nforests of increasing sequences of finite graphs. Those probability measures\nextend the family of already known random spanning forests and can be sampled\nby a random walks algorithm which generalizes Wilson's algorithm. We show that,\nunlike for uniform spanning forests, almost surely, all connected components\nare finite and two-points correlations decrease exponentially fast with the\ndistance.",
            "author": [
                "H\u00e9lo\u00efse Constantin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09425v1",
                "http://arxiv.org/pdf/2308.09425v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60B10, 60C05, 82B20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09421v2",
            "title": "MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection",
            "updated": "2023-09-26T06:43:56Z",
            "published": "2023-08-18T09:39:52Z",
            "summary": "In the field of monocular 3D detection, it is common practice to utilize\nscene geometric clues to enhance the detector's performance. However, many\nexisting works adopt these clues explicitly such as estimating a depth map and\nback-projecting it into 3D space. This explicit methodology induces sparsity in\n3D representations due to the increased dimensionality from 2D to 3D, and leads\nto substantial information loss, especially for distant and occluded objects.\nTo alleviate this issue, we propose MonoNeRD, a novel detection framework that\ncan infer dense 3D geometry and occupancy. Specifically, we model scenes with\nSigned Distance Functions (SDF), facilitating the production of dense 3D\nrepresentations. We treat these representations as Neural Radiance Fields\n(NeRF) and then employ volume rendering to recover RGB images and depth maps.\nTo the best of our knowledge, this work is the first to introduce volume\nrendering for M3D, and demonstrates the potential of implicit reconstruction\nfor image-based 3D perception. Extensive experiments conducted on the KITTI-3D\nbenchmark and Waymo Open Dataset demonstrate the effectiveness of MonoNeRD.\nCodes are available at https://github.com/cskkxjk/MonoNeRD.",
            "author": [
                "Junkai Xu",
                "Liang Peng",
                "Haoran Cheng",
                "Hao Li",
                "Wei Qian",
                "Ke Li",
                "Wenxiao Wang",
                "Deng Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09421v2",
                "http://arxiv.org/pdf/2308.09421v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.11028v1",
            "title": "More on the $2$-restricted optimal pebbling number",
            "updated": "2023-08-18T09:35:25Z",
            "published": "2023-08-18T09:35:25Z",
            "summary": "Let $G=(V,E)$ be a simple graph. A function $f:V\\rightarrow \\mathbb{N}\\cup\n\\{0\\}$ is called a configuration of pebbles on the vertices of $G$ and the\nweight of $f$ is $w(f)=\\sum_{u\\in V}f(u)$ which is just the total number of\npebbles assigned to vertices. A pebbling step from a vertex $u$ to one of its\nneighbors $v$ reduces $f(u)$ by two and increases $f(v)$ by one. A pebbling\nconfiguration $f$ is said to be solvable if for every vertex $ v $, there\nexists a sequence (possibly empty) of pebbling moves that results in a pebble\non $v$. A pebbling configuration $f$ is a $t$-restricted pebbling configuration\n(abbreviated $t$RPC) if $f(v)\\leq t$ for all $v\\in V$. The $t$-restricted\noptimal pebbling number $\\pi_t^*(G)$ is the minimum weight of a solvable $t$RPC\non $G$. Chellali et.al. [Discrete Appl. Math. 221 (2017) 46-53] characterized\nconnected graphs $G$ having small $2$-restricted optimal pebbling numbers and\ncharacterization of graphs $G$ with $\\pi_2^*(G)=5$ stated as an open problem.\nIn this paper, we solve this problem. We improve the upper bound of the\n$2$-restricted optimal pebbling number of trees of order $n$. Also, we study\n$2$-restricted optimal pebbling number of some grid graphs, corona and\nneighborhood corona of two specific graphs.",
            "author": [
                "Saeid Alikhani",
                "Fatemeh Aghaei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11028v1",
                "http://arxiv.org/pdf/2308.11028v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2309.12334v2",
            "title": "Deep Knowledge Tracing is an implicit dynamic multidimensional item\n  response theory model",
            "updated": "2023-12-05T08:52:09Z",
            "published": "2023-08-18T09:32:49Z",
            "summary": "Knowledge tracing consists in predicting the performance of some students on\nnew questions given their performance on previous questions, and can be a prior\nstep to optimizing assessment and learning. Deep knowledge tracing (DKT) is a\ncompetitive model for knowledge tracing relying on recurrent neural networks,\neven if some simpler models may match its performance. However, little is known\nabout why DKT works so well. In this paper, we frame deep knowledge tracing as\na encoderdecoder architecture. This viewpoint not only allows us to propose\nbetter models in terms of performance, simplicity or expressivity but also\nopens up promising avenues for future research directions. In particular, we\nshow on several small and large datasets that a simpler decoder, with possibly\nfewer parameters than the one used by DKT, can predict student performance\nbetter.",
            "author": [
                "Jill-J\u00eann Vie",
                "Hisashi Kashima"
            ],
            "link": [
                "http://arxiv.org/abs/2309.12334v2",
                "http://arxiv.org/pdf/2309.12334v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09413v1",
            "title": "A Graph-based Stratified Sampling Methodology for the Analysis of\n  (Underground) Forums",
            "updated": "2023-08-18T09:28:28Z",
            "published": "2023-08-18T09:28:28Z",
            "summary": "[Context] Researchers analyze underground forums to study abuse and\ncybercrime activities. Due to the size of the forums and the domain expertise\nrequired to identify criminal discussions, most approaches employ supervised\nmachine learning techniques to automatically classify the posts of interest.\n[Goal] Human annotation is costly. How to select samples to annotate that\naccount for the structure of the forum? [Method] We present a methodology to\ngenerate stratified samples based on information about the centrality\nproperties of the population and evaluate classifier performance. [Result] We\nobserve that by employing a sample obtained from a uniform distribution of the\npost degree centrality metric, we maintain the same level of precision but\nsignificantly increase the recall (+30%) compared to a sample whose\ndistribution is respecting the population stratification. We find that\nclassifiers trained with similar samples disagree on the classification of\ncriminal activities up to 33% of the time when deployed on the entire forum.",
            "author": [
                "Giorgio Di Tizio",
                "Gilberto Atondo Siu",
                "Alice Hutchings",
                "Fabio Massacci"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIFS.2023.3304424",
                "http://arxiv.org/abs/2308.09413v1",
                "http://arxiv.org/pdf/2308.09413v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.13447v1",
            "title": "Scientific knowledge production of blockchain: A bibliometric and\n  lexicometric review",
            "updated": "2023-08-18T09:19:26Z",
            "published": "2023-08-18T09:19:26Z",
            "summary": "While recent reviews of blockchain technology have focused on the latest\ndevelopments in cryptocurrency and their derivative impacts, less attention has\nbeen given to analysing their knowledge paths and boundaries based on past\nresearch to guide their development. To address this gap, we conducted both a\nbibliometric study of 2525 articles and a lexicometric study of 123 articles.\nThe bibliometric study provided holistic insights into the evolution and\ndistribution of blockchain research, including influential researchers and\ncountries, discipline composition, knowledge development trends, and emerging\nfrontiers. The lexicometric study identified the boundary concept structure\nwith a quantitative textual approach, extracting the strongest signifying\nepistemic communities. Our findings indicate that blockchain research draws\nfrom four major disciplines, making it a multidisciplinary field. With the\nincreasing maturity and development of technological infrastructure, the\napplication and management of blockchain become increasingly relevant issues.\nOur analysis suggests that blockchain can be considered more of a boundary\nobject than a disruptive change from knowledge perspectives. Therefore, this\npaper proposes a comprehensive understanding of the development path and\nepistemic concepts of blockchain research.",
            "author": [
                "Wilfrid Azan",
                "Yuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13447v1",
                "http://arxiv.org/pdf/2308.13447v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09399v1",
            "title": "Fair Allocation Algorithms for Indivisible Items under Structured\n  Conflict Constraints",
            "updated": "2023-08-18T08:59:19Z",
            "published": "2023-08-18T08:59:19Z",
            "summary": "We consider the fair allocation of indivisible items to several agents with\nadditional conflict constraints. These are represented by a conflict graph\nwhere each item corresponds to a vertex of the graph and edges in the graph\nrepresent incompatible pairs of items which should not be allocated to the same\nagent. This setting combines the issues of Partition and Independent Set and\ncan be seen as a partial coloring of the conflict graph. In the resulting\noptimization problem each agent has its own valuation function for the profits\nof the items. We aim at maximizing the lowest total profit obtained by any of\nthe agents. In a previous paper this problem was shown to be strongly \\NP-hard\nfor several well-known graph classes, e.g., bipartite graphs and their line\ngraphs. On the other hand, it was shown that pseudo-polynomial time algorithms\nexist for the classes of chordal graphs, cocomparability graphs, biconvex\nbipartite graphs, and graphs of bounded treewidth. In this contribution we\nextend this line of research by developing pseudo-polynomial time algorithms\nthat solve the problem for the class of convex bipartite conflict graphs,\ngraphs of bounded clique-width, and graphs of bounded tree-independence number.\nThe algorithms are based on dynamic programming and also permit fully\npolynomial-time approximation schemes (FPTAS).",
            "author": [
                "Nina Chiarelli",
                "Matja\u017e Krnc",
                "Martin Milani\u010d",
                "Ulrich Pferschy",
                "Joachim Schauer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09399v1",
                "http://arxiv.org/pdf/2308.09399v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.CC",
                "math.OC",
                "90C27, 05C85, 90C47, 91B32, 90C39, 68Q25, 68W25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09382v1",
            "title": "Hypergraphs with irrational Tur\u00e1n density and many extremal\n  configurations",
            "updated": "2023-08-18T08:25:09Z",
            "published": "2023-08-18T08:25:09Z",
            "summary": "Unlike graphs, determining Tur\\'{a}n densities of hypergraphs is known to be\nnotoriously hard in general. The essential reason is that for many classical\nfamilies of $r$-uniform hypergraphs $\\mathcal{F}$, there are perhaps many\nnear-extremal $\\mathcal{M}_t$-free configurations with very different\nstructure. Such a phenomenon is called not stable, and Liu and Mubayi gave a\nfirst not stable example. Another perhaps reason is that little is known about\nthe set consisting of all possible Tur\\'{a}n densities which has cardinality of\nthe continuum. Let $t\\ge 2$ be an integer. In this paper, we construct a finite\nfamily $\\mathcal{M}_t$ of 3-uniform hypergraphs such that the Tur\\'{a}n density\nof $\\mathcal{M}_t$ is irrational, and there are $t$ near-extremal\n$\\mathcal{M}_t$-free configurations that are far from each other in\nedit-distance. This is the first not stable example that has an irrational\nTur\\'{a}n density. It also provides a new phenomenon about feasible region\nfunctions.",
            "author": [
                "Jianfeng Hou",
                "Heng Li",
                "Guanghui Wang",
                "Yixiao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09382v1",
                "http://arxiv.org/pdf/2308.09382v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09375v2",
            "title": "Image Processing and Machine Learning for Hyperspectral Unmixing: An\n  Overview and the HySUPP Python Package",
            "updated": "2023-10-06T07:58:27Z",
            "published": "2023-08-18T08:10:41Z",
            "summary": "Spectral pixels are often a mixture of the pure spectra of the materials,\ncalled endmembers, due to the low spatial resolution of hyperspectral sensors,\ndouble scattering, and intimate mixtures of materials in the scenes. Unmixing\nestimates the fractional abundances of the endmembers within the pixel.\nDepending on the prior knowledge of endmembers, linear unmixing can be divided\ninto three main groups: supervised, semi-supervised, and unsupervised (blind)\nlinear unmixing. Advances in Image processing and machine learning\nsubstantially affected unmixing. This paper provides an overview of advanced\nand conventional unmixing approaches. Additionally, we draw a critical\ncomparison between advanced and conventional techniques from the three\ncategories. We compare the performance of the unmixing techniques on three\nsimulated and two real datasets. The experimental results reveal the advantages\nof different unmixing categories for different unmixing scenarios. Moreover, we\nprovide an open-source Python-based package available at\nhttps://github.com/BehnoodRasti/HySUPP to reproduce the results.",
            "author": [
                "Behnood Rasti",
                "Alexandre Zouaoui",
                "Julien Mairal",
                "Jocelyn Chanussot"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09375v2",
                "http://arxiv.org/pdf/2308.09375v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09356v1",
            "title": "The Last Success Problem with a Single Sample",
            "updated": "2023-08-18T07:37:52Z",
            "published": "2023-08-18T07:37:52Z",
            "summary": "The last success problem is an optimal stopping problem that aims to maximize\nthe probability of stopping on the last success in a sequence of $n$ Bernoulli\ntrials. In a typical setting where complete information about the distributions\nis available, Bruss provided an optimal stopping policy ensuring a winning\nprobability of $1/e$. However, assuming complete knowledge of the distributions\nis unrealistic in many practical applications. In this paper, we investigate a\nvariant of the last success problem where we have single-sample access from\neach distribution instead of having comprehensive knowledge of the\ndistributions. Nuti and Vondr\\'{a}k demonstrated that a winning probability\nexceeding $1/4$ is unachievable for this setting, but it remains unknown\nwhether a stopping policy that meets this bound exists. We reveal that Bruss's\npolicy, when applied with the estimated success probabilities, cannot ensure a\nwinning probability greater than $(1-e^{-4})/4\\approx 0.2454~(< 1/4)$,\nirrespective of the estimations from the given samples. Nevertheless, we\ndemonstrate that by setting the threshold the second-to-last success in samples\nand stopping on the first success observed \\emph{after} this threshold, a\nwinning probability of $1/4$ can be guaranteed.",
            "author": [
                "Toru Yoshinaga",
                "Yasushi Kawase"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09356v1",
                "http://arxiv.org/pdf/2308.09356v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09351v1",
            "title": "RLIPv2: Fast Scaling of Relational Language-Image Pre-training",
            "updated": "2023-08-18T07:17:09Z",
            "published": "2023-08-18T07:17:09Z",
            "summary": "Relational Language-Image Pre-training (RLIP) aims to align vision\nrepresentations with relational texts, thereby advancing the capability of\nrelational reasoning in computer vision tasks. However, hindered by the slow\nconvergence of RLIPv1 architecture and the limited availability of existing\nscene graph data, scaling RLIPv1 is challenging. In this paper, we propose\nRLIPv2, a fast converging model that enables the scaling of relational\npre-training to large-scale pseudo-labelled scene graph data. To enable fast\nscaling, RLIPv2 introduces Asymmetric Language-Image Fusion (ALIF), a mechanism\nthat facilitates earlier and deeper gated cross-modal fusion with sparsified\nlanguage encoding layers. ALIF leads to comparable or better performance than\nRLIPv1 in a fraction of the time for pre-training and fine-tuning. To obtain\nscene graph data at scale, we extend object detection datasets with free-form\nrelation labels by introducing a captioner (e.g., BLIP) and a designed Relation\nTagger. The Relation Tagger assigns BLIP-generated relation texts to region\npairs, thus enabling larger-scale relational pre-training. Through extensive\nexperiments conducted on Human-Object Interaction Detection and Scene Graph\nGeneration, RLIPv2 shows state-of-the-art performance on three benchmarks under\nfully-finetuning, few-shot and zero-shot settings. Notably, the largest RLIPv2\nachieves 23.29mAP on HICO-DET without any fine-tuning, yields 32.22mAP with\njust 1% data and yields 45.09mAP with 100% data. Code and models are publicly\navailable at https://github.com/JacobYuan7/RLIPv2.",
            "author": [
                "Hangjie Yuan",
                "Shiwei Zhang",
                "Xiang Wang",
                "Samuel Albanie",
                "Yining Pan",
                "Tao Feng",
                "Jianwen Jiang",
                "Dong Ni",
                "Yingya Zhang",
                "Deli Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09351v1",
                "http://arxiv.org/pdf/2308.09351v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09346v1",
            "title": "Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching",
            "updated": "2023-08-18T07:07:36Z",
            "published": "2023-08-18T07:07:36Z",
            "summary": "Class prototype construction and matching are core aspects of few-shot action\nrecognition. Previous methods mainly focus on designing spatiotemporal relation\nmodeling modules or complex temporal alignment algorithms. Despite the\npromising results, they ignored the value of class prototype construction and\nmatching, leading to unsatisfactory performance in recognizing similar\ncategories in every task. In this paper, we propose GgHM, a new framework with\nGraph-guided Hybrid Matching. Concretely, we learn task-oriented features by\nthe guidance of a graph neural network during class prototype construction,\noptimizing the intra- and inter-class feature correlation explicitly. Next, we\ndesign a hybrid matching strategy, combining frame-level and tuple-level\nmatching to classify videos with multivariate styles. We additionally propose a\nlearnable dense temporal modeling module to enhance the video feature temporal\nrepresentation to build a more solid foundation for the matching process. GgHM\nshows consistent improvements over other challenging baselines on several\nfew-shot datasets, demonstrating the effectiveness of our method. The code will\nbe publicly available at https://github.com/jiazheng-xing/GgHM.",
            "author": [
                "Jiazheng Xing",
                "Mengmeng Wang",
                "Yudi Ruan",
                "Bofan Chen",
                "Yaowei Guo",
                "Boyu Mu",
                "Guang Dai",
                "Jingdong Wang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09346v1",
                "http://arxiv.org/pdf/2308.09346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09735v2",
            "title": "CTP:A Causal Interpretable Model for Non-Communicable Disease\n  Progression Prediction",
            "updated": "2023-09-22T05:54:02Z",
            "published": "2023-08-18T06:58:31Z",
            "summary": "Non-communicable disease is the leading cause of death, emphasizing the need\nfor accurate prediction of disease progression and informed clinical\ndecision-making. Machine learning (ML) models have shown promise in this domain\nby capturing non-linear patterns within patient features. However, existing\nML-based models cannot provide causal interpretable predictions and estimate\ntreatment effects, limiting their decision-making perspective. In this study,\nwe propose a novel model called causal trajectory prediction (CTP) to tackle\nthe limitation. The CTP model combines trajectory prediction and causal\ndiscovery to enable accurate prediction of disease progression trajectories and\nuncover causal relationships between features. By incorporating a causal graph\ninto the prediction process, CTP ensures that ancestor features are not\ninfluenced by the treatment of descendant features, thereby enhancing the\ninterpretability of the model. By estimating the bounds of treatment effects,\neven in the presence of unmeasured confounders, the CTP provides valuable\ninsights for clinical decision-making. We evaluate the performance of the CTP\nusing simulated and real medical datasets. Experimental results demonstrate\nthat our model achieves satisfactory performance, highlighting its potential to\nassist clinical decisions. Source code is in\n\\href{https://github.com/DanielSun94/CFPA}{here}.",
            "author": [
                "Zhoujian Sun",
                "Wenzhuo Zhang",
                "Zhengxing Huang",
                "Nai Ding",
                "Cheng Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09735v2",
                "http://arxiv.org/pdf/2308.09735v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09340v2",
            "title": "How Discriminative Are Your Qrels? How To Study the Statistical\n  Significance of Document Adjudication Methods",
            "updated": "2023-08-28T08:00:58Z",
            "published": "2023-08-18T06:52:07Z",
            "summary": "Creating test collections for offline retrieval evaluation requires human\neffort to judge documents' relevance. This expensive activity motivated much\nwork in developing methods for constructing benchmarks with fewer assessment\ncosts. In this respect, adjudication methods actively decide both which\ndocuments and the order in which experts review them, in order to better\nexploit the assessment budget or to lower it. Researchers evaluate the quality\nof those methods by measuring the correlation between the known gold ranking of\nsystems under the full collection and the observed ranking of systems under the\nlower-cost one. This traditional analysis ignores whether and how the low-cost\njudgements impact on the statistically significant differences among systems\nwith respect to the full collection. We fill this void by proposing a novel\nmethodology to evaluate how the low-cost adjudication methods preserve the\npairwise significant differences between systems as the full collection. In\nother terms, while traditional approaches look for stability in answering the\nquestion \"is system A better than system B?\", our proposed approach looks for\nstability in answering the question \"is system A significantly better than\nsystem B?\", which is the ultimate questions researchers need to answer to\nguarantee the generalisability of their results. Among other results, we found\nthat the best methods in terms of ranking of systems correlation do not always\nmatch those preserving statistical significance.",
            "author": [
                "David Otero",
                "Javier Parapar",
                "Nicola Ferro"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614916",
                "http://arxiv.org/abs/2308.09340v2",
                "http://arxiv.org/pdf/2308.09340v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09329v1",
            "title": "KESDT: knowledge enhanced shallow and deep Transformer for detecting\n  adverse drug reactions",
            "updated": "2023-08-18T06:10:11Z",
            "published": "2023-08-18T06:10:11Z",
            "summary": "Adverse drug reaction (ADR) detection is an essential task in the medical\nfield, as ADRs have a gravely detrimental impact on patients' health and the\nhealthcare system. Due to a large number of people sharing information on\nsocial media platforms, an increasing number of efforts focus on social media\ndata to carry out effective ADR detection. Despite having achieved impressive\nperformance, the existing methods of ADR detection still suffer from three main\nchallenges. Firstly, researchers have consistently ignored the interaction\nbetween domain keywords and other words in the sentence. Secondly, social media\ndatasets suffer from the challenges of low annotated data. Thirdly, the issue\nof sample imbalance is commonly observed in social media datasets. To solve\nthese challenges, we propose the Knowledge Enhanced Shallow and Deep\nTransformer(KESDT) model for ADR detection. Specifically, to cope with the\nfirst issue, we incorporate the domain keywords into the Transformer model\nthrough a shallow fusion manner, which enables the model to fully exploit the\ninteractive relationships between domain keywords and other words in the\nsentence. To overcome the low annotated data, we integrate the synonym sets\ninto the Transformer model through a deep fusion manner, which expands the size\nof the samples. To mitigate the impact of sample imbalance, we replace the\nstandard cross entropy loss function with the focal loss function for effective\nmodel training. We conduct extensive experiments on three public datasets\nincluding TwiMed, Twitter, and CADEC. The proposed KESDT outperforms\nstate-of-the-art baselines on F1 values, with relative improvements of 4.87%,\n47.83%, and 5.73% respectively, which demonstrates the effectiveness of our\nproposed KESDT.",
            "author": [
                "Yunzhi Qiu",
                "Xiaokun Zhang",
                "Weiwei Wang",
                "Tongxuan Zhang",
                "Bo Xu",
                "Hongfei Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09329v1",
                "http://arxiv.org/pdf/2308.09329v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09327v1",
            "title": "Unlimited Knowledge Distillation for Action Recognition in the Dark",
            "updated": "2023-08-18T06:04:39Z",
            "published": "2023-08-18T06:04:39Z",
            "summary": "Dark videos often lose essential information, which causes the knowledge\nlearned by networks is not enough to accurately recognize actions. Existing\nknowledge assembling methods require massive GPU memory to distill the\nknowledge from multiple teacher models into a student model. In action\nrecognition, this drawback becomes serious due to much computation required by\nvideo process. Constrained by limited computation source, these approaches are\ninfeasible. To address this issue, we propose an unlimited knowledge\ndistillation (UKD) in this paper. Compared with existing knowledge assembling\nmethods, our UKD can effectively assemble different knowledge without\nintroducing high GPU memory consumption. Thus, the number of teaching models\nfor distillation is unlimited. With our UKD, the network's learned knowledge\ncan be remarkably enriched. Our experiments show that the single stream network\ndistilled with our UKD even surpasses a two-stream network. Extensive\nexperiments are conducted on the ARID dataset.",
            "author": [
                "Ruibing Jin",
                "Guosheng Lin",
                "Min Wu",
                "Jie Lin",
                "Zhengguo Li",
                "Xiaoli Li",
                "Zhenghua Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09327v1",
                "http://arxiv.org/pdf/2308.09327v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09324v1",
            "title": "AutoLog: A Log Sequence Synthesis Framework for Anomaly Detection",
            "updated": "2023-08-18T05:56:18Z",
            "published": "2023-08-18T05:56:18Z",
            "summary": "The rapid progress of modern computing systems has led to a growing interest\nin informative run-time logs. Various log-based anomaly detection techniques\nhave been proposed to ensure software reliability. However, their\nimplementation in the industry has been limited due to the lack of high-quality\npublic log resources as training datasets.\n  While some log datasets are available for anomaly detection, they suffer from\nlimitations in (1) comprehensiveness of log events; (2) scalability over\ndiverse systems; and (3) flexibility of log utility. To address these\nlimitations, we propose AutoLog, the first automated log generation methodology\nfor anomaly detection. AutoLog uses program analysis to generate run-time log\nsequences without actually running the system. AutoLog starts with probing\ncomprehensive logging statements associated with the call graphs of an\napplication. Then, it constructs execution graphs for each method after pruning\nthe call graphs to find log-related execution paths in a scalable manner.\nFinally, AutoLog propagates the anomaly label to each acquired execution path\nbased on human knowledge. It generates flexible log sequences by walking along\nthe log execution paths with controllable parameters. Experiments on 50 popular\nJava projects show that AutoLog acquires significantly more (9x-58x) log events\nthan existing log datasets from the same system, and generates log messages\nmuch faster (15x) with a single machine than existing passive data collection\napproaches. We hope AutoLog can facilitate the benchmarking and adoption of\nautomated log analysis techniques.",
            "author": [
                "Yintong Huo",
                "Yichen Li",
                "Yuxin Su",
                "Pinjia He",
                "Zifan Xie",
                "Michael R. Lyu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09324v1",
                "http://arxiv.org/pdf/2308.09324v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09320v1",
            "title": "Distributed Robust Learning-Based Backstepping Control Aided with\n  Neurodynamics for Consensus Formation Tracking of Underwater Vessels",
            "updated": "2023-08-18T05:45:13Z",
            "published": "2023-08-18T05:45:13Z",
            "summary": "This paper addresses distributed robust learning-based control for consensus\nformation tracking of multiple underwater vessels, in which the system\nparameters of the marine vessels are assumed to be entirely unknown and subject\nto the modeling mismatch, oceanic disturbances, and noises. Towards this end,\ngraph theory is used to allow us to synthesize the distributed controller with\na stability guarantee. Due to the fact that the parameter uncertainties only\narise in the vessels' dynamic model, the backstepping control technique is then\nemployed. Subsequently, to overcome the difficulties in handling time-varying\nand unknown systems, an online learning procedure is developed in the proposed\ndistributed formation control protocol. Moreover, modeling errors,\nenvironmental disturbances, and measurement noises are considered and tackled\nby introducing a neurodynamics model in the controller design to obtain a\nrobust solution. Then, the stability analysis of the overall closed-loop system\nunder the proposed scheme is provided to ensure the robust adaptive performance\nat the theoretical level. Finally, extensive simulation experiments are\nconducted to further verify the efficacy of the presented distributed control\nprotocol.",
            "author": [
                "Tao Yan",
                "Zhe Xu",
                "Simon X. Yang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TCYB.2023.3299222",
                "http://arxiv.org/abs/2308.09320v1",
                "http://arxiv.org/pdf/2308.09320v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09313v2",
            "title": "Domain Adaptive Code Completion via Language Models and Decoupled Domain\n  Databases",
            "updated": "2023-09-20T04:33:09Z",
            "published": "2023-08-18T05:25:55Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable performance in code\ncompletion. However, due to the lack of domain-specific knowledge, they may not\nbe optimal in completing code that requires intensive domain knowledge for\nexample completing the library names. Although there are several works that\nhave confirmed the effectiveness of fine-tuning techniques to adapt language\nmodels for code completion in specific domains. They are limited by the need\nfor constant fine-tuning of the model when the project is in constant\niteration.\n  To address this limitation, in this paper, we propose $k$NM-LM, a\nretrieval-augmented language model (R-LM), that integrates domain knowledge\ninto language models without fine-tuning. Different from previous techniques,\nour approach is able to automatically adapt to different language models and\ndomains. Specifically, it utilizes the in-domain code to build the\nretrieval-based database decoupled from LM, and then combines it with LM\nthrough Bayesian inference to complete the code. The extensive experiments on\nthe completion of intra-project and intra-scenario have confirmed that $k$NM-LM\nbrings about appreciable enhancements when compared to CodeGPT and UnixCoder. A\ndeep analysis of our tool including the responding speed, storage usage,\nspecific type code completion, and API invocation completion has confirmed that\n$k$NM-LM provides satisfactory performance, which renders it highly appropriate\nfor domain adaptive code completion. Furthermore, our approach operates without\nthe requirement for direct access to the language model's parameters. As a\nresult, it can seamlessly integrate with black-box code completion models,\nmaking it easy to integrate our approach as a plugin to further enhance the\nperformance of these models.",
            "author": [
                "Ze Tang",
                "Jidong Ge",
                "Shangqing Liu",
                "Tingwei Zhu",
                "Tongtong Xu",
                "Liguo Huang",
                "Bin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09313v2",
                "http://arxiv.org/pdf/2308.09313v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09311v1",
            "title": "Lip Reading for Low-resource Languages by Learning and Combining General\n  Speech Knowledge and Language-specific Knowledge",
            "updated": "2023-08-18T05:19:03Z",
            "published": "2023-08-18T05:19:03Z",
            "summary": "This paper proposes a novel lip reading framework, especially for\nlow-resource languages, which has not been well addressed in the previous\nliterature. Since low-resource languages do not have enough video-text paired\ndata to train the model to have sufficient power to model lip movements and\nlanguage, it is regarded as challenging to develop lip reading models for\nlow-resource languages. In order to mitigate the challenge, we try to learn\ngeneral speech knowledge, the ability to model lip movements, from a\nhigh-resource language through the prediction of speech units. It is known that\ndifferent languages partially share common phonemes, thus general speech\nknowledge learned from one language can be extended to other languages. Then,\nwe try to learn language-specific knowledge, the ability to model language, by\nproposing Language-specific Memory-augmented Decoder (LMDecoder). LMDecoder\nsaves language-specific audio features into memory banks and can be trained on\naudio-text paired data which is more easily accessible than video-text paired\ndata. Therefore, with LMDecoder, we can transform the input speech units into\nlanguage-specific audio features and translate them into texts by utilizing the\nlearned rich language knowledge. Finally, by combining general speech knowledge\nand language-specific knowledge, we can efficiently develop lip reading models\neven for low-resource languages. Through extensive experiments using five\nlanguages, English, Spanish, French, Italian, and Portuguese, the effectiveness\nof the proposed method is evaluated.",
            "author": [
                "Minsu Kim",
                "Jeong Hun Yeo",
                "Jeongsoo Choi",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09311v1",
                "http://arxiv.org/pdf/2308.09311v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.SD",
                "eess.AS",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09309v1",
            "title": "Meta-learning enhanced next POI recommendation by leveraging check-ins\n  from auxiliary cities",
            "updated": "2023-08-18T05:07:41Z",
            "published": "2023-08-18T05:07:41Z",
            "summary": "Most existing point-of-interest (POI) recommenders aim to capture user\npreference by employing city-level user historical check-ins, thus facilitating\nusers' exploration of the city. However, the scarcity of city-level user\ncheck-ins brings a significant challenge to user preference learning. Although\nprior studies attempt to mitigate this challenge by exploiting various context\ninformation, e.g., spatio-temporal information, they ignore to transfer the\nknowledge (i.e., common behavioral pattern) from other relevant cities (i.e.,\nauxiliary cities). In this paper, we investigate the effect of knowledge\ndistilled from auxiliary cities and thus propose a novel Meta-learning Enhanced\nnext POI Recommendation framework (MERec). The MERec leverages the correlation\nof check-in behaviors among various cities into the meta-learning paradigm to\nhelp infer user preference in the target city, by holding the principle of\n\"paying more attention to more correlated knowledge\". Particularly, a\ncity-level correlation strategy is devised to attentively capture common\npatterns among cities, so as to transfer more relevant knowledge from more\ncorrelated cities. Extensive experiments verify the superiority of the proposed\nMERec against state-of-the-art algorithms.",
            "author": [
                "Jinze Wang",
                "Lu Zhang",
                "Zhu Sun",
                "Yew-Soon Ong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09309v1",
                "http://arxiv.org/pdf/2308.09309v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09308v3",
            "title": "Differentiable Retrieval Augmentation via Generative Language Modeling\n  for E-commerce Query Intent Classification",
            "updated": "2023-09-15T09:27:20Z",
            "published": "2023-08-18T05:05:35Z",
            "summary": "Retrieval augmentation, which enhances downstream models by a knowledge\nretriever and an external corpus instead of by merely increasing the number of\nmodel parameters, has been successfully applied to many natural language\nprocessing (NLP) tasks such as text classification, question answering and so\non. However, existing methods that separately or asynchronously train the\nretriever and downstream model mainly due to the non-differentiability between\nthe two parts, usually lead to degraded performance compared to end-to-end\njoint training. In this paper, we propose Differentiable Retrieval Augmentation\nvia Generative lANguage modeling(Dragan), to address this problem by a novel\ndifferentiable reformulation. We demonstrate the effectiveness of our proposed\nmethod on a challenging NLP task in e-commerce search, namely query intent\nclassification. Both the experimental results and ablation study show that the\nproposed method significantly and reasonably improves the state-of-the-art\nbaselines on both offline evaluation and online A/B test.",
            "author": [
                "Chenyu Zhao",
                "Yunjiang Jiang",
                "Yiming Qiu",
                "Han Zhang",
                "Wen-Yun Yang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615210",
                "http://arxiv.org/abs/2308.09308v3",
                "http://arxiv.org/pdf/2308.09308v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL",
                "H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09306v1",
            "title": "DiffDis: Empowering Generative Diffusion Model with Cross-Modal\n  Discrimination Capability",
            "updated": "2023-08-18T05:03:48Z",
            "published": "2023-08-18T05:03:48Z",
            "summary": "Recently, large-scale diffusion models, e.g., Stable diffusion and DallE2,\nhave shown remarkable results on image synthesis. On the other hand,\nlarge-scale cross-modal pre-trained models (e.g., CLIP, ALIGN, and FILIP) are\ncompetent for various downstream tasks by learning to align vision and language\nembeddings. In this paper, we explore the possibility of jointly modeling\ngeneration and discrimination. Specifically, we propose DiffDis to unify the\ncross-modal generative and discriminative pretraining into one single framework\nunder the diffusion process. DiffDis first formulates the image-text\ndiscriminative problem as a generative diffusion process of the text embedding\nfrom the text encoder conditioned on the image. Then, we propose a novel\ndual-stream network architecture, which fuses the noisy text embedding with the\nknowledge of latent images from different scales for image-text discriminative\nlearning. Moreover, the generative and discriminative tasks can efficiently\nshare the image-branch network structure in the multi-modality model.\nBenefiting from diffusion-based unified training, DiffDis achieves both better\ngeneration ability and cross-modal semantic alignment in one architecture.\nExperimental results show that DiffDis outperforms single-task models on both\nthe image generation and the image-text discriminative tasks, e.g., 1.65%\nimprovement on average accuracy of zero-shot classification over 12 datasets\nand 2.42 improvement on FID of zero-shot image synthesis.",
            "author": [
                "Runhui Huang",
                "Jianhua Han",
                "Guansong Lu",
                "Xiaodan Liang",
                "Yihan Zeng",
                "Wei Zhang",
                "Hang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09306v1",
                "http://arxiv.org/pdf/2308.09306v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09304v1",
            "title": "Mass and infinite dimensional geometry",
            "updated": "2023-08-18T04:59:32Z",
            "published": "2023-08-18T04:59:32Z",
            "summary": "I unravel an elegant geometric meaning of the mass of the lowest energy\nexcited state of a renormalizable quantized field theory by studying the\nweighted geometry of the classical configuration space of the theory. A\nsuitably defined regularized Bakry-Emery Ricci curvature of these infinite\ndimensional spaces controls the spectra of the corresponding quantum\nHamiltonians. The Ricci curvature part of the full Bakry-Emery Ricci curvature\nappears to be purely quantum in nature. This geometric contribution to the\nspectra in the context of quantum field theory has not been studied previously\nto my knowledge. Assuming the existence of rigorous quantization, I present a\nfew problems starting from massive free particles to the non-abelian Yang-Mills\ntheory. A remarkable property is observed in the large $N$ Yang-Mills theory,\nwhere a non-trivial mass gap is preserved. This occurs due to the fact that the\nregularized Bakry-Emery Ricci curvature that is responsible for the gap of the\nconfiguration space scales as $g^{2}_{YM}N=\\lambda$ ('t Hooft coupling) that\nremains invariant.",
            "author": [
                "Puskar Mondal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09304v1",
                "http://arxiv.org/pdf/2308.09304v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09303v1",
            "title": "Online Class Incremental Learning on Stochastic Blurry Task Boundary via\n  Mask and Visual Prompt Tuning",
            "updated": "2023-08-18T04:52:56Z",
            "published": "2023-08-18T04:52:56Z",
            "summary": "Continual learning aims to learn a model from a continuous stream of data,\nbut it mainly assumes a fixed number of data and tasks with clear task\nboundaries. However, in real-world scenarios, the number of input data and\ntasks is constantly changing in a statistical way, not a static way. Although\nrecently introduced incremental learning scenarios having blurry task\nboundaries somewhat address the above issues, they still do not fully reflect\nthe statistical properties of real-world situations because of the fixed ratio\nof disjoint and blurry samples. In this paper, we propose a new Stochastic\nincremental Blurry task boundary scenario, called Si-Blurry, which reflects the\nstochastic properties of the real-world. We find that there are two major\nchallenges in the Si-Blurry scenario: (1) inter- and intra-task forgettings and\n(2) class imbalance problem. To alleviate them, we introduce Mask and Visual\nPrompt tuning (MVP). In MVP, to address the inter- and intra-task forgetting\nissues, we propose a novel instance-wise logit masking and contrastive visual\nprompt tuning loss. Both of them help our model discern the classes to be\nlearned in the current batch. It results in consolidating the previous\nknowledge. In addition, to alleviate the class imbalance problem, we introduce\na new gradient similarity-based focal loss and adaptive feature scaling to ease\noverfitting to the major classes and underfitting to the minor classes.\nExtensive experiments show that our proposed MVP significantly outperforms the\nexisting state-of-the-art methods in our challenging Si-Blurry scenario.",
            "author": [
                "Jun-Yeong Moon",
                "Keon-Hee Park",
                "Jung Uk Kim",
                "Gyeong-Moon Park"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09303v1",
                "http://arxiv.org/pdf/2308.09303v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09297v1",
            "title": "NAPA-VQ: Neighborhood Aware Prototype Augmentation with Vector\n  Quantization for Continual Learning",
            "updated": "2023-08-18T04:47:39Z",
            "published": "2023-08-18T04:47:39Z",
            "summary": "Catastrophic forgetting; the loss of old knowledge upon acquiring new\nknowledge, is a pitfall faced by deep neural networks in real-world\napplications. Many prevailing solutions to this problem rely on storing\nexemplars (previously encountered data), which may not be feasible in\napplications with memory limitations or privacy constraints. Therefore, the\nrecent focus has been on Non-Exemplar based Class Incremental Learning (NECIL)\nwhere a model incrementally learns about new classes without using any past\nexemplars. However, due to the lack of old data, NECIL methods struggle to\ndiscriminate between old and new classes causing their feature representations\nto overlap. We propose NAPA-VQ: Neighborhood Aware Prototype Augmentation with\nVector Quantization, a framework that reduces this class overlap in NECIL. We\ndraw inspiration from Neural Gas to learn the topological relationships in the\nfeature space, identifying the neighboring classes that are most likely to get\nconfused with each other. This neighborhood information is utilized to enforce\nstrong separation between the neighboring classes as well as to generate old\nclass representative prototypes that can better aid in obtaining a\ndiscriminative decision boundary between old and new classes. Our comprehensive\nexperiments on CIFAR-100, TinyImageNet, and ImageNet-Subset demonstrate that\nNAPA-VQ outperforms the State-of-the-art NECIL methods by an average\nimprovement of 5%, 2%, and 4% in accuracy and 10%, 3%, and 9% in forgetting\nrespectively. Our code can be found in https://github.com/TamashaM/NAPA-VQ.git.",
            "author": [
                "Tamasha Malepathirana",
                "Damith Senanayake",
                "Saman Halgamuge"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09297v1",
                "http://arxiv.org/pdf/2308.09297v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09296v2",
            "title": "CARLA: Self-supervised Contrastive Representation Learning for Time\n  Series Anomaly Detection",
            "updated": "2023-12-03T10:05:50Z",
            "published": "2023-08-18T04:45:56Z",
            "summary": "One main challenge in time series anomaly detection (TAD) is the lack of\nlabelled data in many real-life scenarios. Most of the existing anomaly\ndetection methods focus on learning the normal behaviour of unlabelled time\nseries in an unsupervised manner. The normal boundary is often defined tightly,\nresulting in slight deviations being classified as anomalies, consequently\nleading to a high false positive rate and a limited ability to generalise\nnormal patterns. To address this, we introduce a novel end-to-end\nself-supervised ContrAstive Representation Learning approach for time series\nAnomaly detection (CARLA). While existing contrastive learning methods assume\nthat augmented time series windows are positive samples and temporally distant\nwindows are negative samples, we argue that these assumptions are limited as\naugmentation of time series can transform them to negative samples, and a\ntemporally distant window can represent a positive sample. Our contrastive\napproach leverages existing generic knowledge about time series anomalies and\ninjects various types of anomalies as negative samples. Therefore, CARLA not\nonly learns normal behaviour but also learns deviations indicating anomalies.\nIt creates similar representations for temporally closed windows and distinct\nones for anomalies. Additionally, it leverages the information about\nrepresentations' neighbours through a self-supervised approach to classify\nwindows based on their nearest/furthest neighbours to further enhance the\nperformance of anomaly detection. In extensive tests on seven major real-world\ntime series anomaly detection datasets, CARLA shows superior performance over\nstate-of-the-art self-supervised and unsupervised TAD methods. Our research\nshows the potential of contrastive representation learning to advance time\nseries anomaly detection.",
            "author": [
                "Zahra Zamanzadeh Darban",
                "Geoffrey I. Webb",
                "Shirui Pan",
                "Charu C. Aggarwal",
                "Mahsa Salehi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09296v2",
                "http://arxiv.org/pdf/2308.09296v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09292v1",
            "title": "Graph-based Alignment and Uniformity for Recommendation",
            "updated": "2023-08-18T04:33:36Z",
            "published": "2023-08-18T04:33:36Z",
            "summary": "Collaborative filtering-based recommender systems (RecSys) rely on learning\nrepresentations for users and items to predict preferences accurately.\nRepresentation learning on the hypersphere is a promising approach due to its\ndesirable properties, such as alignment and uniformity. However, the sparsity\nissue arises when it encounters RecSys. To address this issue, we propose a\nnovel approach, graph-based alignment and uniformity (GraphAU), that explicitly\nconsiders high-order connectivities in the user-item bipartite graph. GraphAU\naligns the user/item embedding to the dense vector representations of\nhigh-order neighbors using a neighborhood aggregator, eliminating the need to\ncompute the burdensome alignment to high-order neighborhoods individually. To\naddress the discrepancy in alignment losses, GraphAU includes a layer-wise\nalignment pooling module to integrate alignment losses layer-wise. Experiments\non four datasets show that GraphAU significantly alleviates the sparsity issue\nand achieves state-of-the-art performance. We open-source GraphAU at\nhttps://github.com/YangLiangwei/GraphAU.",
            "author": [
                "Liangwei Yang",
                "Zhiwei Liu",
                "Chen Wang",
                "Mingdai Yang",
                "Xiaolong Liu",
                "Jing Ma",
                "Philip S. Yu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615185",
                "http://arxiv.org/abs/2308.09292v1",
                "http://arxiv.org/pdf/2308.09292v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09285v2",
            "title": "RFDforFin: Robust Deep Forgery Detection for GAN-generated Fingerprint\n  Images",
            "updated": "2023-09-13T14:27:42Z",
            "published": "2023-08-18T04:05:18Z",
            "summary": "With the rapid development of the image generation technologies, the\nmalicious abuses of the GAN-generated fingerprint images poses a significant\nthreat to the public safety in certain circumstances. Although the existing\nuniversal deep forgery detection approach can be applied to detect the fake\nfingerprint images, they are easily attacked and have poor robustness.\nMeanwhile, there is no specifically designed deep forgery detection method for\nfingerprint images. In this paper, we propose the first deep forgery detection\napproach for fingerprint images, which combines unique ridge features of\nfingerprint and generation artifacts of the GAN-generated images, to the best\nof our knowledge. Specifically, we firstly construct a ridge stream, which\nexploits the grayscale variations along the ridges to extract unique\nfingerprint-specific features. Then, we construct a generation artifact stream,\nin which the FFT-based spectrums of the input fingerprint images are exploited,\nto extract more robust generation artifact features. At last, the unique ridge\nfeatures and generation artifact features are fused for binary classification\n(i.e., real or fake). Comprehensive experiments demonstrate that our proposed\napproach is effective and robust with low complexities.",
            "author": [
                "Hui Miao",
                "Yuanfang Guo",
                "Yunhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09285v2",
                "http://arxiv.org/pdf/2308.09285v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09284v1",
            "title": "The Fine-Grained Complexity of CFL Reachability",
            "updated": "2023-08-18T03:52:27Z",
            "published": "2023-08-18T03:52:27Z",
            "summary": "Many problems in static program analysis can be modeled as the context-free\nlanguage (CFL) reachability problem on directed labeled graphs. The CFL\nreachability problem can be generally solved in time $O(n^3)$, where $n$ is the\nnumber of vertices in the graph, with some specific cases that can be solved\nfaster. In this work, we ask the following question: given a specific CFL, what\nis the exact exponent in the monomial of the running time? In other words, for\nwhich cases do we have linear, quadratic or cubic algorithms, and are there\nproblems with intermediate runtimes? This question is inspired by recent\nefforts to classify classic problems in terms of their exact polynomial\ncomplexity, known as {\\em fine-grained complexity}. Although recent efforts\nhave shown some conditional lower bounds (mostly for the class of combinatorial\nalgorithms), a general picture of the fine-grained complexity landscape for CFL\nreachability is missing.\n  Our main contribution is lower bound results that pinpoint the exact running\ntime of several classes of CFLs or specific CFLs under widely believed lower\nbound conjectures (Boolean Matrix Multiplication and $k$-Clique). We\nparticularly focus on the family of Dyck-$k$ languages (which are strings with\nwell-matched parentheses), a fundamental class of CFL reachability problems. We\npresent new lower bounds for the case of sparse input graphs where the number\nof edges $m$ is the input parameter, a common setting in the database\nliterature. For this setting, we show a cubic lower bound for Andersen's\nPointer Analysis which significantly strengthens prior known results.",
            "author": [
                "Paraschos Koutris",
                "Shaleen Deep"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09284v1",
                "http://arxiv.org/pdf/2308.09284v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09267v3",
            "title": "Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based\n  Verification Approach",
            "updated": "2023-09-28T16:35:58Z",
            "published": "2023-08-18T03:12:59Z",
            "summary": "Large Language Models (LLMs) have showcased impressive reasoning\ncapabilities, particularly when guided by specifically designed prompts in\ncomplex reasoning tasks such as math word problems. These models typically\nsolve tasks using a chain-of-thought approach, which not only bolsters their\nreasoning abilities but also provides valuable insights into their\nproblem-solving process. However, there is still significant room for enhancing\nthe reasoning abilities of LLMs. Some studies suggest that the integration of\nan LLM output verifier can boost reasoning accuracy without necessitating\nadditional model training. In this paper, we follow these studies and introduce\na novel graph-based method to further augment the reasoning capabilities of\nLLMs. We posit that multiple solutions to a reasoning task, generated by an\nLLM, can be represented as a reasoning graph due to the logical connections\nbetween intermediate steps from different reasoning paths. Therefore, we\npropose the Reasoning Graph Verifier (RGV) to analyze and verify the solutions\ngenerated by LLMs. By evaluating these graphs, models can yield more accurate\nand reliable results.Our experimental results show that our graph-based\nverification method not only significantly enhances the reasoning abilities of\nLLMs but also outperforms existing verifier methods in terms of improving these\nmodels' reasoning performance.",
            "author": [
                "Lang Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09267v3",
                "http://arxiv.org/pdf/2308.09267v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09262v2",
            "title": "Multi-Task Pseudo-Label Learning for Non-Intrusive Speech Quality\n  Assessment Model",
            "updated": "2023-09-11T06:04:58Z",
            "published": "2023-08-18T02:36:21Z",
            "summary": "This study proposes a multi-task pseudo-label learning (MPL)-based\nnon-intrusive speech quality assessment model called MTQ-Net. MPL consists of\ntwo stages: obtaining pseudo-label scores from a pretrained model and\nperforming multi-task learning. The 3QUEST metrics, namely Speech-MOS (S-MOS),\nNoise-MOS (N-MOS), and General-MOS (G-MOS), are the assessment targets. The\npretrained MOSA-Net model is utilized to estimate three pseudo labels:\nperceptual evaluation of speech quality (PESQ), short-time objective\nintelligibility (STOI), and speech distortion index (SDI). Multi-task learning\nis then employed to train MTQ-Net by combining a supervised loss (derived from\nthe difference between the estimated score and the ground-truth label) and a\nsemi-supervised loss (derived from the difference between the estimated score\nand the pseudo label), where the Huber loss is employed as the loss function.\nExperimental results first demonstrate the advantages of MPL compared to\ntraining a model from scratch and using a direct knowledge transfer mechanism.\nSecond, the benefit of the Huber loss for improving the predictive ability of\nMTQ-Net is verified. Finally, the MTQ-Net with the MPL approach exhibits higher\noverall predictive power compared to other SSL-based speech assessment models.",
            "author": [
                "Ryandhimas E. Zezario",
                "Bo-Ren Brian Bai",
                "Chiou-Shann Fuh",
                "Hsin-Min Wang",
                "Yu Tsao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09262v2",
                "http://arxiv.org/pdf/2308.09262v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09259v2",
            "title": "FRGNN: Mitigating the Impact of Distribution Shift on Graph Neural\n  Networks via Test-Time Feature Reconstruction",
            "updated": "2023-10-13T09:41:45Z",
            "published": "2023-08-18T02:34:37Z",
            "summary": "Due to inappropriate sample selection and limited training data, a\ndistribution shift often exists between the training and test sets. This shift\ncan adversely affect the test performance of Graph Neural Networks (GNNs).\nExisting approaches mitigate this issue by either enhancing the robustness of\nGNNs to distribution shift or reducing the shift itself. However, both\napproaches necessitate retraining the model, which becomes unfeasible when the\nmodel structure and parameters are inaccessible. To address this challenge, we\npropose FR-GNN, a general framework for GNNs to conduct feature reconstruction.\nFRGNN constructs a mapping relationship between the output and input of a\nwell-trained GNN to obtain class representative embeddings and then uses these\nembeddings to reconstruct the features of labeled nodes. These reconstructed\nfeatures are then incorporated into the message passing mechanism of GNNs to\ninfluence the predictions of unlabeled nodes at test time. Notably, the\nreconstructed node features can be directly utilized for testing the\nwell-trained model, effectively reducing the distribution shift and leading to\nimproved test performance. This remarkable achievement is attained without any\nmodifications to the model structure or parameters. We provide theoretical\nguarantees for the effectiveness of our framework. Furthermore, we conduct\ncomprehensive experiments on various public datasets. The experimental results\ndemonstrate the superior performance of FRGNN in comparison to multiple\ncategories of baseline methods.",
            "author": [
                "Rui Ding",
                "Jielong Yang",
                "Feng Ji",
                "Xionghu Zhong",
                "Linbo Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09259v2",
                "http://arxiv.org/pdf/2308.09259v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09250v1",
            "title": "Capacity Bounds for Hyperbolic Neural Network Representations of Latent\n  Tree Structures",
            "updated": "2023-08-18T02:24:32Z",
            "published": "2023-08-18T02:24:32Z",
            "summary": "We study the representation capacity of deep hyperbolic neural networks\n(HNNs) with a ReLU activation function. We establish the first proof that HNNs\ncan $\\varepsilon$-isometrically embed any finite weighted tree into a\nhyperbolic space of dimension $d$ at least equal to $2$ with prescribed\nsectional curvature $\\kappa<0$, for any $\\varepsilon> 1$ (where $\\varepsilon=1$\nbeing optimal). We establish rigorous upper bounds for the network complexity\non an HNN implementing the embedding. We find that the network complexity of\nHNN implementing the graph representation is independent of the representation\nfidelity/distortion. We contrast this result against our lower bounds on\ndistortion which any ReLU multi-layer perceptron (MLP) must exert when\nembedding a tree with $L>2^d$ leaves into a $d$-dimensional Euclidean space,\nwhich we show at least $\\Omega(L^{1/d})$; independently of the depth, width,\nand (possibly discontinuous) activation function defining the MLP.",
            "author": [
                "Anastasis Kratsios",
                "Ruiyang Hong",
                "Haitz S\u00e1ez de Oc\u00e1riz Borde"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09250v1",
                "http://arxiv.org/pdf/2308.09250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM",
                "cs.NA",
                "cs.NE",
                "math.MG",
                "math.NA",
                "68T07, 30L05, 68R12, 05C05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09241v1",
            "title": "Susceptibility indicator for chiral topological orders emergent from\n  correlated fermions",
            "updated": "2023-08-18T02:01:10Z",
            "published": "2023-08-18T02:01:10Z",
            "summary": "Chiral topological orders formed in correlated fermion systems have been\nwidely explored. However, the mechanism on how they emerge from interacting\nfermions is still unclear. Here, we propose a susceptibility condition. Under\nthis condition, we show that chiral topological orders can spontaneously take\nplace in correlated fermion systems. The condition leads to a low-energy\neffective theory of bosons with strong frustration, mimicking the flat band\nsystems. The frustration then melts the long-range orders and results in\ntopological orders with time-reversal symmetry breaking. We apply the theory to\nstrongly-correlated semiconductors doped to the metallic phase. A novel\nexcitonic topological order with semionic excitations and chiral excitonic edge\nstate is revealed, which goes beyond the common knowledge that excitonic phases\nare generally formed in semimetals or semiconductors. These results demonstrate\nan unprecedented indicator for chiral topological orders, which bridges the\nexisting gap between interacting fermions and correlated topological matter.",
            "author": [
                "Rui Wang",
                "Tao Yang",
                "Baigeng Wang",
                "X. C. Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09241v1",
                "http://arxiv.org/pdf/2308.09241v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09230v1",
            "title": "CCFace: Classification Consistency for Low-Resolution Face Recognition",
            "updated": "2023-08-18T01:24:52Z",
            "published": "2023-08-18T01:24:52Z",
            "summary": "In recent years, deep face recognition methods have demonstrated impressive\nresults on in-the-wild datasets. However, these methods have shown a\nsignificant decline in performance when applied to real-world low-resolution\nbenchmarks like TinyFace or SCFace. To address this challenge, we propose a\nnovel classification consistency knowledge distillation approach that transfers\nthe learned classifier from a high-resolution model to a low-resolution\nnetwork. This approach helps in finding discriminative representations for\nlow-resolution instances. To further improve the performance, we designed a\nknowledge distillation loss using the adaptive angular penalty inspired by the\nsuccess of the popular angular margin loss function. The adaptive penalty\nreduces overfitting on low-resolution samples and alleviates the convergence\nissue of the model integrated with data augmentation. Additionally, we utilize\nan asymmetric cross-resolution learning approach based on the state-of-the-art\nsemi-supervised representation learning paradigm to improve discriminability on\nlow-resolution instances and prevent them from forming a cluster. Our proposed\nmethod outperforms state-of-the-art approaches on low-resolution benchmarks,\nwith a three percent improvement on TinyFace while maintaining performance on\nhigh-resolution benchmarks.",
            "author": [
                "Mohammad Saeed Ebrahimi Saadabadi",
                "Sahar Rahimi Malakshan",
                "Hossein Kashiani",
                "Nasser M. Nasrabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09230v1",
                "http://arxiv.org/pdf/2308.09230v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09229v1",
            "title": "Mitigating the Risk of Knowledge Leakage in Knowledge Intensive\n  Organizations: a Mobile Device Perspective",
            "updated": "2023-08-18T01:22:31Z",
            "published": "2023-08-18T01:22:31Z",
            "summary": "In the current knowledge economy, knowledge represents the most strategically\nsignificant resource of organizations. Knowledge-intensive activities advance\ninnovation and create and sustain economic rent and competitive advantage. In\norder to sustain competitive advantage, organizations must protect knowledge\nfrom leakage to third parties, particularly competitors. However, the number\nand scale of leakage incidents reported in news media as well as industry\nwhitepapers suggests that modern organizations struggle with the protection of\nsensitive data and organizational knowledge. The increasing use of mobile\ndevices and technologies by knowledge workers across the organizational\nperimeter has dramatically increased the attack surface of organizations, and\nthe corresponding level of risk exposure. While much of the literature has\nfocused on technology risks that lead to information leakage, human risks that\nlead to knowledge leakage are relatively understudied. Further, not much is\nknown about strategies to mitigate the risk of knowledge leakage using mobile\ndevices, especially considering the human aspect. Specifically, this research\nstudy identified three gaps in the current literature (1) lack of in-depth\nstudies that provide specific strategies for knowledge-intensive organizations\nbased on their varied risk levels. Most of the analysed studies provide\nhigh-level strategies that are presented in a generalised manner and fail to\nidentify specific strategies for different organizations and risk levels. (2)\nlack of research into management of knowledge in the context of mobile devices.\nAnd (3) lack of research into the tacit dimension of knowledge as the majority\nof the literature focuses on formal and informal strategies to protect explicit\n(codified) knowledge.",
            "author": [
                "Carlos Andres Agudelo Serna"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09229v1",
                "http://arxiv.org/pdf/2308.09229v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.10713v2",
            "title": "LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis",
            "updated": "2023-08-24T03:46:53Z",
            "published": "2023-08-18T00:33:29Z",
            "summary": "Facial expression analysis is an important tool for human-computer\ninteraction. In this paper, we introduce LibreFace, an open-source toolkit for\nfacial expression analysis. This open-source toolbox offers real-time and\noffline analysis of facial behavior through deep learning models, including\nfacial action unit (AU) detection, AU intensity estimation, and facial\nexpression recognition. To accomplish this, we employ several techniques,\nincluding the utilization of a large-scale pre-trained network, feature-wise\nknowledge distillation, and task-specific fine-tuning. These approaches are\ndesigned to effectively and accurately analyze facial expressions by leveraging\nvisual information, thereby facilitating the implementation of real-time\ninteractive applications. In terms of Action Unit (AU) intensity estimation, we\nachieve a Pearson Correlation Coefficient (PCC) of 0.63 on DISFA, which is 7%\nhigher than the performance of OpenFace 2.0 while maintaining highly-efficient\ninference that runs two times faster than OpenFace 2.0. Despite being compact,\nour model also demonstrates competitive performance to state-of-the-art facial\nexpression analysis methods on AffecNet, FFHQ, and RAF-DB. Our code will be\nreleased at https://github.com/ihp-lab/LibreFace",
            "author": [
                "Di Chang",
                "Yufeng Yin",
                "Zongjian Li",
                "Minh Tran",
                "Mohammad Soleymani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.10713v2",
                "http://arxiv.org/pdf/2308.10713v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09215v1",
            "title": "Improved bounds for embedding certain configurations in subsets of\n  vector spaces over finite fields",
            "updated": "2023-08-18T00:20:35Z",
            "published": "2023-08-18T00:20:35Z",
            "summary": "The fourth listed author and Hans Parshall (\\cite{IosevichParshall}) proved\nthat if $E \\subset {\\mathbb F}_q^d$, $d \\ge 2$, and $G$ is a connected graph on\n$k+1$ vertices such that the largest degree of any vertex is $m$, then if $|E|\n\\ge C q^{m+\\frac{d-1}{2}}$, for any $t>0$, there exist $k+1$ points $x^1,\n\\dots, x^{k+1}$ in $E$ such that $||x^i-x^j||=t$ if the $i$'th vertex is\nconnected to the $j$'th vertex by an edge in $G$. In this paper, we give\nseveral indications that the maximum degree is not always the right notion of\ncomplexity and prove several concrete results to obtain better exponents than\nthe Iosevich-Parshall result affords. This can be viewed as a step towards\nunderstanding the right notion of complexity for graph embeddings in subsets of\nvector spaces over finite fields.",
            "author": [
                "Paige Bright",
                "Xinyu Fang",
                "Barrett Heritage",
                "Alex Iosevich",
                "Maxwell Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09215v1",
                "http://arxiv.org/pdf/2308.09215v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "52C10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09214v2",
            "title": "Path convergence of Markov chains on large graphs",
            "updated": "2023-10-15T16:35:08Z",
            "published": "2023-08-18T00:13:59Z",
            "summary": "We consider two classes of natural stochastic processes on finite unlabeled\ngraphs. These are Euclidean stochastic optimization algorithms on the adjacency\nmatrix of weighted graphs and a modified version of the Metropolis MCMC\nalgorithm on stochastic block models over unweighted graphs. In both cases we\nshow that, as the size of the graph goes to infinity, the random trajectories\nof the stochastic processes converge to deterministic curves on the space of\nmeasure-valued graphons. Measure-valued graphons, introduced by Lov\\'{a}sz and\nSzegedy in \\cite{lovasz2010decorated}, are a refinement of the concept of\ngraphons that can distinguish between two infinite exchangeable arrays that\ngive rise to the same graphon limit. We introduce new metrics on this space\nwhich provide us with a natural notion of convergence for our limit theorems.\nThis notion is equivalent to the convergence of infinite-exchangeable arrays.\nUnder suitable assumptions and a specified time-scaling, the Metropolis chain\nadmits a diffusion limit as the number of vertices go to infinity. We then\ndemonstrate that, in an appropriately formulated zero-noise limit, the\nstochastic process of adjacency matrices of this diffusion converges to a\ndeterministic gradient flow curve on the space of graphons introduced\nin\\cite{Oh2023}. A novel feature of this approach is that it provides a precise\nexponential convergence rate for the Metropolis chain in a certain limiting\nregime. The connection between a natural Metropolis chain commonly used in\nexponential random graph models and gradient flows on graphons, to the best of\nour knowledge, is new in the literature as well.",
            "author": [
                "Siva Athreya",
                "Soumik Pal",
                "Raghav Somani",
                "Raghavendra Tripathi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09214v2",
                "http://arxiv.org/pdf/2308.09214v2"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "stat.ML",
                "05C80, 60K35, 65C05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09210v1",
            "title": "Efficient Algorithms for Attributed Graph Alignment with Vanishing Edge\n  Correlation",
            "updated": "2023-08-17T23:32:51Z",
            "published": "2023-08-17T23:32:51Z",
            "summary": "Graph alignment refers to the task of finding the vertex correspondence\nbetween two positively correlated graphs. Extensive study has been done on\npolynomial-time algorithms for the graph alignment problem under the\nErd\\H{o}s--R\\'enyi graph pair model, where the two graphs are\nErd\\H{o}s--R\\'enyi graphs with edge probability $q_\\mathrm{u}$, correlated\nunder certain vertex correspondence. To achieve exact recovery of the vertex\ncorrespondence, all existing algorithms at least require the edge correlation\ncoefficient $\\rho_\\mathrm{u}$ between the two graphs to satisfy\n$\\rho_\\mathrm{u} > \\sqrt{\\alpha}$, where $\\alpha \\approx 0.338$ is Otter's\ntree-counting constant. Moreover, it is conjectured in [1] that no\npolynomial-time algorithm can achieve exact recovery under weak edge\ncorrelation $\\rho_\\mathrm{u}<\\sqrt{\\alpha}$.\n  In this paper, we show that with a vanishing amount of additional attribute\ninformation, exact recovery is polynomial-time feasible under vanishing edge\ncorrelation $\\rho_\\mathrm{u} \\ge n^{-\\Theta(1)}$. We identify a local tree\nstructure, which incorporates one layer of user information and one layer of\nattribute information, and apply the subgraph counting technique to such\nstructures. A polynomial-time algorithm is proposed that recovers the vertex\ncorrespondence for all but a vanishing fraction of vertices. We then further\nrefine the algorithm output to achieve exact recovery. The motivation for\nconsidering additional attribute information comes from the widely available\nside information in real-world applications, such as the user's birthplace and\neducational background on LinkedIn and Twitter social networks.",
            "author": [
                "Ziao Wang",
                "Weina Wang",
                "Lele Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09210v1",
                "http://arxiv.org/pdf/2308.09210v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09198v1",
            "title": "Half-Hop: A graph upsampling approach for slowing down message passing",
            "updated": "2023-08-17T22:24:15Z",
            "published": "2023-08-17T22:24:15Z",
            "summary": "Message passing neural networks have shown a lot of success on\ngraph-structured data. However, there are many instances where message passing\ncan lead to over-smoothing or fail when neighboring nodes belong to different\nclasses. In this work, we introduce a simple yet general framework for\nimproving learning in message passing neural networks. Our approach essentially\nupsamples edges in the original graph by adding \"slow nodes\" at each edge that\ncan mediate communication between a source and a target node. Our method only\nmodifies the input graph, making it plug-and-play and easy to use with existing\nmodels. To understand the benefits of slowing down message passing, we provide\ntheoretical and empirical analyses. We report results on several supervised and\nself-supervised benchmarks, and show improvements across the board, notably in\nheterophilic conditions where adjacent nodes are more likely to have different\nlabels. Finally, we show how our approach can be used to generate augmentations\nfor self-supervised learning, where slow nodes are randomly introduced into\ndifferent edges in the graph to generate multi-scale views with variable path\nlengths.",
            "author": [
                "Mehdi Azabou",
                "Venkataramana Ganesh",
                "Shantanu Thakoor",
                "Chi-Heng Lin",
                "Lakshmi Sathidevi",
                "Ran Liu",
                "Michal Valko",
                "Petar Veli\u010dkovi\u0107",
                "Eva L. Dyer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09198v1",
                "http://arxiv.org/pdf/2308.09198v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09185v1",
            "title": "The planar Tur\u00e1n number of $\\{K_4,C_5\\}$ and $\\{K_4,C_6\\}$",
            "updated": "2023-08-17T21:08:57Z",
            "published": "2023-08-17T21:08:57Z",
            "summary": "Let $\\mathcal{H}$ be a set of graphs. The planar Tur\\'an number,\n$ex_\\mathcal{P}(n,\\mathcal{H})$, is the maximum number of edges in an\n$n$-vertex planar graph which does not contain any member of $\\mathcal{H}$ as a\nsubgraph. When $\\mathcal{H}=\\{H\\}$ has only one element, we usually write\n$ex_\\mathcal{P}(n,H)$ instead. The topic of extremal planar graphs was\ninitiated by Dowden (2016). He obtained sharp upper bound for both\n$ex_\\mathcal{P}(n,C_5)$ and $ex_\\mathcal{P}(n,K_4)$. Later on, we obtained\nsharper bound for $ex_\\mathcal{P}(n,\\{K_4,C_7\\})$. In this paper, we give upper\nbounds of $ex_\\mathcal{P}(n,\\{K_4,C_5\\})\\leq {15\\over 7}(n-2)$ and\n$ex_\\mathcal{P}(n,\\{K_4,C_6\\})\\leq {7\\over 3}(n-2)$. We also give constructions\nwhich show the bounds are tight for infinitely many graphs.",
            "author": [
                "Ervin Gy\u0151ri",
                "Alan Li",
                "Runtian Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09185v1",
                "http://arxiv.org/pdf/2308.09185v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09731v1",
            "title": "ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based\n  Healthcare Decision Support using ChatGPT",
            "updated": "2023-08-17T20:50:46Z",
            "published": "2023-08-17T20:50:46Z",
            "summary": "This study presents an innovative approach to the application of large\nlanguage models (LLMs) in clinical decision-making, focusing on OpenAI's\nChatGPT. Our approach introduces the use of contextual prompts-strategically\ndesigned to include task description, feature description, and crucially,\nintegration of domain knowledge-for high-quality binary classification tasks\neven in data-scarce scenarios. The novelty of our work lies in the utilization\nof domain knowledge, obtained from high-performing interpretable ML models, and\nits seamless incorporation into prompt design. By viewing these ML models as\nmedical experts, we extract key insights on feature importance to aid in\ndecision-making processes. This interplay of domain knowledge and AI holds\nsignificant promise in creating a more insightful diagnostic tool.\n  Additionally, our research explores the dynamics of zero-shot and few-shot\nprompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT\nwith traditional supervised ML models in different data conditions, we aim to\nprovide insights into the effectiveness of prompt engineering strategies under\nvaried data availability. In essence, this paper bridges the gap between AI and\nhealthcare, proposing a novel methodology for LLMs application in clinical\ndecision support systems. It highlights the transformative potential of\neffective prompt design, domain knowledge integration, and flexible learning\napproaches in enhancing automated decision-making.",
            "author": [
                "Fatemeh Nazary",
                "Yashar Deldjoo",
                "Tommaso Di Noia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09731v1",
                "http://arxiv.org/pdf/2308.09731v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09180v1",
            "title": "How Does Pruning Impact Long-Tailed Multi-Label Medical Image\n  Classifiers?",
            "updated": "2023-08-17T20:40:30Z",
            "published": "2023-08-17T20:40:30Z",
            "summary": "Pruning has emerged as a powerful technique for compressing deep neural\nnetworks, reducing memory usage and inference time without significantly\naffecting overall performance. However, the nuanced ways in which pruning\nimpacts model behavior are not well understood, particularly for long-tailed,\nmulti-label datasets commonly found in clinical settings. This knowledge gap\ncould have dangerous implications when deploying a pruned model for diagnosis,\nwhere unexpected model behavior could impact patient well-being. To fill this\ngap, we perform the first analysis of pruning's effect on neural networks\ntrained to diagnose thorax diseases from chest X-rays (CXRs). On two large CXR\ndatasets, we examine which diseases are most affected by pruning and\ncharacterize class \"forgettability\" based on disease frequency and\nco-occurrence behavior. Further, we identify individual CXRs where uncompressed\nand heavily pruned models disagree, known as pruning-identified exemplars\n(PIEs), and conduct a human reader study to evaluate their unifying qualities.\nWe find that radiologists perceive PIEs as having more label noise, lower image\nquality, and higher diagnosis difficulty. This work represents a first step\ntoward understanding the impact of pruning on model behavior in deep\nlong-tailed, multi-label medical image classification. All code, model weights,\nand data access instructions can be found at\nhttps://github.com/VITA-Group/PruneCXR.",
            "author": [
                "Gregory Holste",
                "Ziyu Jiang",
                "Ajay Jaiswal",
                "Maria Hanna",
                "Shlomo Minkowitz",
                "Alan C. Legasto",
                "Joanna G. Escalon",
                "Sharon Steinberger",
                "Mark Bittman",
                "Thomas C. Shen",
                "Ying Ding",
                "Ronald M. Summers",
                "George Shih",
                "Yifan Peng",
                "Zhangyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09180v1",
                "http://arxiv.org/pdf/2308.09180v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09179v1",
            "title": "Versatile Multi-Contact Planning and Control for Legged\n  Loco-Manipulation",
            "updated": "2023-08-17T20:35:21Z",
            "published": "2023-08-17T20:35:21Z",
            "summary": "Loco-manipulation planning skills are pivotal for expanding the utility of\nrobots in everyday environments. These skills can be assessed based on a\nsystem's ability to coordinate complex holistic movements and multiple contact\ninteractions when solving different tasks. However, existing approaches have\nbeen merely able to shape such behaviors with hand-crafted state machines,\ndensely engineered rewards, or pre-recorded expert demonstrations. Here, we\npropose a minimally-guided framework that automatically discovers whole-body\ntrajectories jointly with contact schedules for solving general\nloco-manipulation tasks in pre-modeled environments. The key insight is that\nmulti-modal problems of this nature can be formulated and treated within the\ncontext of integrated Task and Motion Planning (TAMP). An effective bilevel\nsearch strategy is achieved by incorporating domain-specific rules and\nadequately combining the strengths of different planning techniques: trajectory\noptimization and informed graph search coupled with sampling-based planning. We\nshowcase emergent behaviors for a quadrupedal mobile manipulator exploiting\nboth prehensile and non-prehensile interactions to perform real-world tasks\nsuch as opening/closing heavy dishwashers and traversing spring-loaded doors.\nThese behaviors are also deployed on the real system using a two-layer\nwhole-body tracking controller.",
            "author": [
                "Jean-Pierre Sleiman",
                "Farbod Farshidian",
                "Marco Hutter"
            ],
            "link": [
                "http://dx.doi.org/10.1126/scirobotics.adg5014",
                "http://arxiv.org/abs/2308.09179v1",
                "http://arxiv.org/pdf/2308.09179v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2308.09176v1",
            "title": "First spatio-spectral Bayesian imaging of SN1006 in X-ray",
            "updated": "2023-08-17T20:28:37Z",
            "published": "2023-08-17T20:28:37Z",
            "summary": "Supernovae are an important source of energy in the interstellar medium.\nYoung remnants of supernovae have a peak emission in the X-ray region, making\nthem interesting objects for X-ray observations. In particular, the supernova\nremnant SN1006 is of great interest due to its historical record, proximity and\nbrightness. It has therefore been studied by several X-ray telescopes.\nImproving the X-ray imaging of this and other remnants is important but\nchallenging as it requires to address a spatially varying instrument response\nin order to achieve a high signal-to-noise ratio. Here, we use Chandra\nobservations to demonstrate the capabilities of Bayesian image reconstruction\nusing information field theory. Our objective is to reconstruct denoised,\ndeconvolved and spatio-spectral resolved images from X-ray observations and to\ndecompose the emission into different morphologies, namely diffuse and\npoint-like. Further, we aim to fuse data from different detectors and pointings\ninto a mosaic and quantify the uncertainty of our result. Utilizing prior\nknowledge on the spatial and spectral correlation structure of the two\ncomponents, diffuse emission and point sources, the presented method allows the\neffective decomposition of the signal into these. In order to accelerate the\nimaging process, we introduce a multi-step approach, in which the spatial\nreconstruction obtained for a single energy range is used to derive an informed\nstarting point for the full spatio-spectral reconstruction. The method is\napplied to 11 Chandra observations of SN1006 from 2008 and 2012, providing a\ndetailed, denoised and decomposed view of the remnant. In particular, the\nseparated view of the diffuse emission should provide new insights into its\ncomplex small-scale structures in the center of the remnant and at the shock\nfront profiles.",
            "author": [
                "Margret Westerkamp",
                "Vincent Eberle",
                "Matteo Guardiani",
                "Philipp Frank",
                "Lukas Platz",
                "Philipp Arras",
                "Jakob Knollm\u00fcller",
                "Julia Stadler",
                "Torsten En\u00dflin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09176v1",
                "http://arxiv.org/pdf/2308.09176v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    }
]