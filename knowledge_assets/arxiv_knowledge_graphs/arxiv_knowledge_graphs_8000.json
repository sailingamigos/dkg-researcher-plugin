[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09165v1",
            "title": "Connected components of the topological surgery graph of a unicellular\n  collection",
            "updated": "2023-08-17T19:47:55Z",
            "published": "2023-08-17T19:47:55Z",
            "summary": "A unicellular collection on a surface is a collection of curves whose\ncomplement is a single disk. There is a natural surgery operation on\nunicellular collections, endowing the set of such with a graph structure where\nthe edge relation is given by surgery. Here we determine the connected\ncomponents of this graph, showing that they are enumerated by a certain\nhomological \"surgery invariant\". Our approach is group-theoretic and proceeds\nby understanding the action of the mapping class group on unicellular\ncollections. In the course of our arguments, we determine simple generating\nsets for the stabilizer in the mapping class group of a mod-$2$ homology class,\nwhich may be of independent interest.",
            "author": [
                "Nick Salter",
                "Abdoul Karim Sane"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09165v1",
                "http://arxiv.org/pdf/2308.09165v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09158v1",
            "title": "ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model\n  Reuse",
            "updated": "2023-08-17T19:12:13Z",
            "published": "2023-08-17T19:12:13Z",
            "summary": "The rapid expansion of foundation pre-trained models and their fine-tuned\ncounterparts has significantly contributed to the advancement of machine\nlearning. Leveraging pre-trained models to extract knowledge and expedite\nlearning in real-world tasks, known as \"Model Reuse\", has become crucial in\nvarious applications. Previous research focuses on reusing models within a\ncertain aspect, including reusing model weights, structures, and hypothesis\nspaces. This paper introduces ZhiJian, a comprehensive and user-friendly\ntoolbox for model reuse, utilizing the PyTorch backend. ZhiJian presents a\nnovel paradigm that unifies diverse perspectives on model reuse, encompassing\ntarget architecture construction with PTM, tuning target model with PTM, and\nPTM-based inference. This empowers deep learning practitioners to explore\ndownstream tasks and identify the complementary advantages among different\nmethods. ZhiJian is readily accessible at\nhttps://github.com/zhangyikaii/lamda-zhijian facilitating seamless utilization\nof pre-trained models and streamlining the model reuse process for researchers\nand developers.",
            "author": [
                "Yi-Kai Zhang",
                "Lu Ren",
                "Chao Yi",
                "Qi-Wei Wang",
                "De-Chuan Zhan",
                "Han-Jia Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09158v1",
                "http://arxiv.org/pdf/2308.09158v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09157v1",
            "title": "Accelerating Aggregation Queries on Unstructured Streams of Data",
            "updated": "2023-08-17T19:11:33Z",
            "published": "2023-08-17T19:11:33Z",
            "summary": "Analysts and scientists are interested in querying streams of video, audio,\nand text to extract quantitative insights. For example, an urban planner may\nwish to measure congestion by querying the live feed from a traffic camera.\nPrior work has used deep neural networks (DNNs) to answer such queries in the\nbatch setting. However, much of this work is not suited for the streaming\nsetting because it requires access to the entire dataset before a query can be\nsubmitted or is specific to video. Thus, to the best of our knowledge, no prior\nwork addresses the problem of efficiently answering queries over multiple\nmodalities of streams.\n  In this work we propose InQuest, a system for accelerating aggregation\nqueries on unstructured streams of data with statistical guarantees on query\naccuracy. InQuest leverages inexpensive approximation models (\"proxies\") and\nsampling techniques to limit the execution of an expensive high-precision model\n(an \"oracle\") to a subset of the stream. It then uses the oracle predictions to\ncompute an approximate query answer in real-time. We theoretically analyzed\nInQuest and show that the expected error of its query estimates converges on\nstationary streams at a rate inversely proportional to the oracle budget. We\nevaluated our algorithm on six real-world video and text datasets and show that\nInQuest achieves the same root mean squared error (RMSE) as two streaming\nbaselines with up to 5.0x fewer oracle invocations. We further show that\nInQuest can achieve up to 1.9x lower RMSE at a fixed number of oracle\ninvocations than a state-of-the-art batch setting algorithm.",
            "author": [
                "Matthew Russo",
                "Tatsunori Hashimoto",
                "Daniel Kang",
                "Yi Sun",
                "Matei Zaharia"
            ],
            "link": [
                "http://dx.doi.org/10.14778/3611479.3611496",
                "http://arxiv.org/abs/2308.09157v1",
                "http://arxiv.org/pdf/2308.09157v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09156v1",
            "title": "Characterizing Information Seeking Events in Health-Related Social\n  Discourse",
            "updated": "2023-08-17T19:08:42Z",
            "published": "2023-08-17T19:08:42Z",
            "summary": "Social media sites have become a popular platform for individuals to seek and\nshare health information. Despite the progress in natural language processing\nfor social media mining, a gap remains in analyzing health-related texts on\nsocial discourse in the context of events. Event-driven analysis can offer\ninsights into different facets of healthcare at an individual and collective\nlevel, including treatment options, misconceptions, knowledge gaps, etc. This\npaper presents a paradigm to characterize health-related information-seeking in\nsocial discourse through the lens of events. Events here are board categories\ndefined with domain experts that capture the trajectory of the\ntreatment/medication. To illustrate the value of this approach, we analyze\nReddit posts regarding medications for Opioid Use Disorder (OUD), a critical\nglobal health concern. To the best of our knowledge, this is the first attempt\nto define event categories for characterizing information-seeking in OUD social\ndiscourse. Guided by domain experts, we develop TREAT-ISE, a novel multilabel\ntreatment information-seeking event dataset to analyze online discourse on an\nevent-based framework. This dataset contains Reddit posts on\ninformation-seeking events related to recovery from OUD, where each post is\nannotated based on the type of events. We also establish a strong performance\nbenchmark (77.4% F1 score) for the task by employing several machine learning\nand deep learning classifiers. Finally, we thoroughly investigate the\nperformance and errors of ChatGPT on this task, providing valuable insights\ninto the LLM's capabilities and ongoing characterization efforts.",
            "author": [
                "Omar Sharif",
                "Madhusudan Basak",
                "Tanzia Parvin",
                "Ava Scharfstein",
                "Alphonso Bradham",
                "Jacob T. Borodovsky",
                "Sarah E. Lord",
                "Sarah Masud Preum"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09156v1",
                "http://arxiv.org/pdf/2308.09156v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09124v1",
            "title": "Linearity of Relation Decoding in Transformer Language Models",
            "updated": "2023-08-17T17:59:19Z",
            "published": "2023-08-17T17:59:19Z",
            "summary": "Much of the knowledge encoded in transformer language models (LMs) may be\nexpressed in terms of relations: relations between words and their synonyms,\nentities and their attributes, etc. We show that, for a subset of relations,\nthis computation is well-approximated by a single linear transformation on the\nsubject representation. Linear relation representations may be obtained by\nconstructing a first-order approximation to the LM from a single prompt, and\nthey exist for a variety of factual, commonsense, and linguistic relations.\nHowever, we also identify many cases in which LM predictions capture relational\nknowledge accurately, but this knowledge is not linearly encoded in their\nrepresentations. Our results thus reveal a simple, interpretable, but\nheterogeneously deployed knowledge representation strategy in transformer LMs.",
            "author": [
                "Evan Hernandez",
                "Arnab Sen Sharma",
                "Tal Haklay",
                "Kevin Meng",
                "Martin Wattenberg",
                "Jacob Andreas",
                "Yonatan Belinkov",
                "David Bau"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09124v1",
                "http://arxiv.org/pdf/2308.09124v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09115v1",
            "title": "MaScQA: A Question Answering Dataset for Investigating Materials Science\n  Knowledge of Large Language Models",
            "updated": "2023-08-17T17:51:05Z",
            "published": "2023-08-17T17:51:05Z",
            "summary": "Information extraction and textual comprehension from materials literature\nare vital for developing an exhaustive knowledge base that enables accelerated\nmaterials discovery. Language models have demonstrated their capability to\nanswer domain-specific questions and retrieve information from knowledge bases.\nHowever, there are no benchmark datasets in the materials domain that can\nevaluate the understanding of the key concepts by these language models. In\nthis work, we curate a dataset of 650 challenging questions from the materials\ndomain that require the knowledge and skills of a materials student who has\ncleared their undergraduate degree. We classify these questions based on their\nstructure and the materials science domain-based subcategories. Further, we\nevaluate the performance of GPT-3.5 and GPT-4 models on solving these questions\nvia zero-shot and chain of thought prompting. It is observed that GPT-4 gives\nthe best performance (~62% accuracy) as compared to GPT-3.5. Interestingly, in\ncontrast to the general observation, no significant improvement in accuracy is\nobserved with the chain of thought prompting. To evaluate the limitations, we\nperformed an error analysis, which revealed conceptual errors (~64%) as the\nmajor contributor compared to computational errors (~36%) towards the reduced\nperformance of LLMs. We hope that the dataset and analysis performed in this\nwork will promote further research in developing better materials science\ndomain-specific LLMs and strategies for information extraction.",
            "author": [
                "Mohd Zaki",
                "Jayadeva",
                "Mausam",
                "N. M. Anoop Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09115v1",
                "http://arxiv.org/pdf/2308.09115v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09108v1",
            "title": "Spectral information criterion for automatic elbow detection",
            "updated": "2023-08-17T17:18:45Z",
            "published": "2023-08-17T17:18:45Z",
            "summary": "We introduce a generalized information criterion that contains other\nwell-known information criteria, such as Bayesian information Criterion (BIC)\nand Akaike information criterion (AIC), as special cases. Furthermore, the\nproposed spectral information criterion (SIC) is also more general than the\nother information criteria, e.g., since the knowledge of a likelihood function\nis not strictly required. SIC extracts geometric features of the error curve\nand, as a consequence, it can be considered an automatic elbow detector. SIC\nprovides a subset of all possible models, with a cardinality that often is much\nsmaller than the total number of possible models. The elements of this subset\nare elbows of the error curve. A practical rule for selecting a unique model\nwithin the sets of elbows is suggested as well. Theoretical invariance\nproperties of SIC are analyzed. Moreover, we test SIC in ideal scenarios where\nprovides always the optimal expected results. We also test SIC in several\nnumerical experiments: some involving synthetic data, and two experiments\ninvolving real datasets. They are all real-world applications such as\nclustering, variable selection, or polynomial order selection, to name a few.\nThe results show the benefits of the proposed scheme. Matlab code related to\nthe experiments is also provided. Possible future research lines are finally\ndiscussed.",
            "author": [
                "L. Martino",
                "R. San Millan-Castillo",
                "E. Morgado"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.eswa.2023.120705",
                "http://arxiv.org/abs/2308.09108v1",
                "http://arxiv.org/pdf/2308.09108v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.AI",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09105v1",
            "title": "Learning Lightweight Object Detectors via Multi-Teacher Progressive\n  Distillation",
            "updated": "2023-08-17T17:17:08Z",
            "published": "2023-08-17T17:17:08Z",
            "summary": "Resource-constrained perception systems such as edge computing and\nvision-for-robotics require vision models to be both accurate and lightweight\nin computation and memory usage. While knowledge distillation is a proven\nstrategy to enhance the performance of lightweight classification models, its\napplication to structured outputs like object detection and instance\nsegmentation remains a complicated task, due to the variability in outputs and\ncomplex internal network modules involved in the distillation process. In this\npaper, we propose a simple yet surprisingly effective sequential approach to\nknowledge distillation that progressively transfers the knowledge of a set of\nteacher detectors to a given lightweight student. To distill knowledge from a\nhighly accurate but complex teacher model, we construct a sequence of teachers\nto help the student gradually adapt. Our progressive strategy can be easily\ncombined with existing detection distillation mechanisms to consistently\nmaximize student performance in various settings. To the best of our knowledge,\nwe are the first to successfully distill knowledge from Transformer-based\nteacher detectors to convolution-based students, and unprecedentedly boost the\nperformance of ResNet-50 based RetinaNet from 36.5% to 42.0% AP and Mask R-CNN\nfrom 38.2% to 42.5% AP on the MS COCO benchmark.",
            "author": [
                "Shengcao Cao",
                "Mengtian Li",
                "James Hays",
                "Deva Ramanan",
                "Yi-Xiong Wang",
                "Liang-Yan Gui"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09105v1",
                "http://arxiv.org/pdf/2308.09105v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09102v1",
            "title": "Universal and Automatic Elbow Detection for Learning the Effective\n  Number of Components in Model Selection Problems",
            "updated": "2023-08-17T17:02:53Z",
            "published": "2023-08-17T17:02:53Z",
            "summary": "We design a Universal Automatic Elbow Detector (UAED) for deciding the\neffective number of components in model selection problems. The relationship\nwith the information criteria widely employed in the literature is also\ndiscussed. The proposed UAED does not require the knowledge of a likelihood\nfunction and can be easily applied in diverse applications, such as regression\nand classification, feature and/or order selection, clustering, and dimension\nreduction. Several experiments involving synthetic and real data show the\nadvantages of the proposed scheme with benchmark techniques in the literature.",
            "author": [
                "E. Morgado",
                "L. Martino",
                "R. San Millan-Castillo"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.dsp.2023.104103",
                "http://arxiv.org/abs/2308.09102v1",
                "http://arxiv.org/pdf/2308.09102v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "eess.SP",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09729v4",
            "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large\n  Language Models",
            "updated": "2023-09-15T12:49:00Z",
            "published": "2023-08-17T16:59:50Z",
            "summary": "LLMs usually exhibit limitations in their ability to incorporate new\nknowledge, the generation of hallucinations, and the transparency of their\ndecision-making process. In this paper, we explore how to prompt LLMs with\nknowledge graphs (KG), working as a remedy to engage LLMs with up-to-date\nknowledge and elicit the reasoning pathways from LLMs. Specifically, we build a\nprompting pipeline that endows LLMs with the capability of comprehending KG\ninputs and inferring with a combined implicit knowledge and the retrieved\nexternal knowledge. In addition, we investigate eliciting the mind map on which\nLLMs perform the reasoning and generate the answers. It is identified that the\nproduced mind map exhibits the reasoning pathways of LLMs grounded on the\nontology of knowledge, hence bringing the prospects of probing and gauging LLM\ninference in production. The experiments on three question & answering datasets\nalso show that MindMap prompting leads to a striking empirical gain. For\ninstance, prompting a GPT-3.5 with MindMap yields an overwhelming performance\nover GPT-4 consistently. We also demonstrate that with structured facts\nretrieved from KG, MindMap can outperform a series of\nprompting-with-document-retrieval methods, benefiting from more accurate,\nconcise, and comprehensive knowledge from KGs. To reproduce our results and\nextend the framework further, we make our codebase available at\nhttps://github.com/wyl.willing/MindMap.",
            "author": [
                "Yilin Wen",
                "Zifeng Wang",
                "Jimeng Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09729v4",
                "http://arxiv.org/pdf/2308.09729v4"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09097v3",
            "title": "Synchrony patterns in Laplacian networks",
            "updated": "2023-10-06T20:22:36Z",
            "published": "2023-08-17T16:49:17Z",
            "summary": "A network of coupled dynamical systems is represented by a graph whose\nvertices represent individual cells and whose edges represent couplings between\ncells. Motivated by the impact of synchronization results of the Kuramoto\nnetworks, we introduce the generalized class of Laplacian networks, governed by\nmappings whose Jacobian at any point is a symmetric matrix with row entries\nsumming to zero. By recognizing this matrix with a weighted Laplacian of the\nassociated graph, we derive the optimal estimates of its positive, null and\nnegative eigenvalues directly from the graph topology. Furthermore, we provide\na characterization of the mappings that define Laplacian networks. Lastly, we\ndiscuss stability of equilibria inside synchrony subspaces for two types of\nLaplacian network on a ring with some extra couplings.",
            "author": [
                "Tiago Amorim",
                "Miriam Manoel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09097v3",
                "http://arxiv.org/pdf/2308.09097v3"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "34C15, 37G40, 82B20, 34D06"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09090v1",
            "title": "Data-driven Integrated Sensing and Communication: Recent Advances,\n  Challenges, and Future Prospects",
            "updated": "2023-08-17T16:39:17Z",
            "published": "2023-08-17T16:39:17Z",
            "summary": "Integrated Sensing and Communication (ISAC), combined with data-driven\napproaches, has emerged as a highly significant field, garnering considerable\nattention from academia and industry. Its potential to enable wide-scale\napplications in the future sixth-generation (6G) networks has led to extensive\nrecent research efforts. Machine learning (ML) techniques, including\n$K$-nearest neighbors (KNN), support vector machines (SVM), deep learning (DL)\narchitectures, and reinforcement learning (RL) algorithms, have been deployed\nto address various design aspects of ISAC and its diverse applications.\nTherefore, this paper aims to explore integrating various ML techniques into\nISAC systems, covering various applications. These applications span\nintelligent vehicular networks, encompassing unmanned aerial vehicles (UAVs)\nand autonomous cars, as well as radar applications, localization and tracking,\nmillimeter wave (mmWave) and Terahertz (THz) communication, and beamforming.\nThe contributions of this paper lie in its comprehensive survey of ML-based\nworks in the ISAC domain and its identification of challenges and future\nresearch directions. By synthesizing the existing knowledge and proposing new\nresearch avenues, this survey serves as a valuable resource for researchers,\npractitioners, and stakeholders involved in advancing the capabilities of ISAC\nsystems in the context of 6G networks.",
            "author": [
                "Hammam Salem",
                "MD Muzakkir Quamar",
                "Adeb Mansoor",
                "Mohammed Elrashidy",
                "Nasir Saeed",
                "Mudassir Masood"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09090v1",
                "http://arxiv.org/pdf/2308.09090v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09087v1",
            "title": "Modeling Edge Features with Deep Bayesian Graph Networks",
            "updated": "2023-08-17T16:29:17Z",
            "published": "2023-08-17T16:29:17Z",
            "summary": "We propose an extension of the Contextual Graph Markov Model, a deep and\nprobabilistic machine learning model for graphs, to model the distribution of\nedge features. Our approach is architectural, as we introduce an additional\nBayesian network mapping edge features into discrete states to be used by the\noriginal model. In doing so, we are also able to build richer graph\nrepresentations even in the absence of edge features, which is confirmed by the\nperformance improvements on standard graph classification benchmarks. Moreover,\nwe successfully test our proposal in a graph regression scenario where edge\nfeatures are of fundamental importance, and we show that the learned edge\nrepresentation provides substantial performance improvements against the\noriginal model on three link prediction tasks. By keeping the computational\ncomplexity linear in the number of edges, the proposed model is amenable to\nlarge-scale graph processing.",
            "author": [
                "Daniele Atzeni",
                "Federico Errica",
                "Davide Bacciu",
                "Alessio Micheli"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN52387.2021.9533430",
                "http://arxiv.org/abs/2308.09087v1",
                "http://arxiv.org/pdf/2308.09087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09075v1",
            "title": "Fast Decision Support for Air Traffic Management at Urban Air Mobility\n  Vertiports using Graph Learning",
            "updated": "2023-08-17T16:05:44Z",
            "published": "2023-08-17T16:05:44Z",
            "summary": "Urban Air Mobility (UAM) promises a new dimension to decongested, safe, and\nfast travel in urban and suburban hubs. These UAM aircraft are conceived to\noperate from small airports called vertiports each comprising multiple\ntake-off/landing and battery-recharging spots. Since they might be situated in\ndense urban areas and need to handle many aircraft landings and take-offs each\nhour, managing this schedule in real-time becomes challenging for a traditional\nair-traffic controller but instead calls for an automated solution. This paper\nprovides a novel approach to this problem of Urban Air Mobility - Vertiport\nSchedule Management (UAM-VSM), which leverages graph reinforcement learning to\ngenerate decision-support policies. Here the designated physical spots within\nthe vertiport's airspace and the vehicles being managed are represented as two\nseparate graphs, with feature extraction performed through a graph\nconvolutional network (GCN). Extracted features are passed onto perceptron\nlayers to decide actions such as continue to hover or cruise, continue idling\nor take-off, or land on an allocated vertiport spot. Performance is measured\nbased on delays, safety (no. of collisions) and battery consumption. Through\nrealistic simulations in AirSim applied to scaled down multi-rotor vehicles,\nour results demonstrate the suitability of using graph reinforcement learning\nto solve the UAM-VSM problem and its superiority to basic reinforcement\nlearning (with graph embeddings) or random choice baselines.",
            "author": [
                "Prajit KrisshnaKumar",
                "Jhoel Witter",
                "Steve Paul",
                "Hanvit Cho",
                "Karthik Dantu",
                "Souma Chowdhury"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09075v1",
                "http://arxiv.org/pdf/2308.09075v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09061v1",
            "title": "Fostering User Engagement in the Critical Reflection of Arguments",
            "updated": "2023-08-17T15:48:23Z",
            "published": "2023-08-17T15:48:23Z",
            "summary": "A natural way to resolve different points of view and form opinions is\nthrough exchanging arguments and knowledge. Facing the vast amount of available\ninformation on the internet, people tend to focus on information consistent\nwith their beliefs. Especially when the issue is controversial, information is\noften selected that does not challenge one's beliefs. To support a fair and\nunbiased opinion-building process, we propose a chatbot system that engages in\na deliberative dialogue with a human. In contrast to persuasive systems, the\nenvisioned chatbot aims to provide a diverse and representative overview -\nembedded in a conversation with the user. To account for a reflective and\nunbiased exploration of the topic, we enable the system to intervene if the\nuser is too focused on their pre-existing opinion. Therefore we propose a model\nto estimate the users' reflective engagement (RUE), defined as their critical\nthinking and open-mindedness. We report on a user study with 58 participants to\ntest our model and the effect of the intervention mechanism, discuss the\nimplications of the results, and present perspectives for future work. The\nresults show a significant effect on both user reflection and total user focus,\nproving our proposed approach's validity.",
            "author": [
                "Klaus Weber",
                "Annalena Aicher",
                "Wolfang Minker",
                "Stefan Ultes",
                "Elisabeth Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09061v1",
                "http://arxiv.org/pdf/2308.09061v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09043v2",
            "title": "Kernel-Based Tests for Likelihood-Free Hypothesis Testing",
            "updated": "2023-11-23T23:39:55Z",
            "published": "2023-08-17T15:24:03Z",
            "summary": "Given $n$ observations from two balanced classes, consider the task of\nlabeling an additional $m$ inputs that are known to all belong to \\emph{one} of\nthe two classes. Special cases of this problem are well-known: with complete\nknowledge of class distributions ($n=\\infty$) the problem is solved optimally\nby the likelihood-ratio test; when $m=1$ it corresponds to binary\nclassification; and when $m\\approx n$ it is equivalent to two-sample testing.\nThe intermediate settings occur in the field of likelihood-free inference,\nwhere labeled samples are obtained by running forward simulations and the\nunlabeled sample is collected experimentally. In recent work it was discovered\nthat there is a fundamental trade-off between $m$ and $n$: increasing the data\nsample $m$ reduces the amount $n$ of training/simulation data needed. In this\nwork we (a) introduce a generalization where unlabeled samples come from a\nmixture of the two classes -- a case often encountered in practice; (b) study\nthe minimax sample complexity for non-parametric classes of densities under\n\\textit{maximum mean discrepancy} (MMD) separation; and (c) investigate the\nempirical performance of kernels parameterized by neural networks on two tasks:\ndetection of the Higgs boson and detection of planted DDPM generated images\namidst CIFAR-10 images. For both problems we confirm the existence of the\ntheoretically predicted asymmetric $m$ vs $n$ trade-off.",
            "author": [
                "Patrik R\u00f3bert Gerber",
                "Tianze Jiang",
                "Yury Polyanskiy",
                "Rui Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09043v2",
                "http://arxiv.org/pdf/2308.09043v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09018v1",
            "title": "Fingerprinting Defects in Hexagonal Boron Nitride via Multi-Phonon\n  Excitation",
            "updated": "2023-08-17T14:47:09Z",
            "published": "2023-08-17T14:47:09Z",
            "summary": "Single photon emitters in hexagonal boron nitride have gathered a lot of\nattention due to their favourable emission properties and the manifold of\npossible applications. Despite extensive scientific effort, the exact atomic\norigin of these emitters has remained unkown thus far. Recently, several\nstudies have tied the emission in the yellow spectral region to carbon-related\ndefects, but the exact atomic structure of the defects remains elusive. In this\nstudy, photoluminescence emission and excitation spectroscopy is performed on a\nlarge number of emitters within this region. By comparison of the experimental\ndata with theoretical predictions, the origin of yellow single photon emission\nin hexagonal boron nitride is determined. Knowledge of this atomic structure\nand its optical properties is crucial for the reliable implementation of these\nemitters in quantum technologies.",
            "author": [
                "Pablo Tieben",
                "Andreas W. Schell"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09018v1",
                "http://arxiv.org/pdf/2308.09018v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mtrl-sci",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09012v1",
            "title": "FashionLOGO: Prompting Multimodal Large Language Models for Fashion Logo\n  Embeddings",
            "updated": "2023-08-17T14:30:26Z",
            "published": "2023-08-17T14:30:26Z",
            "summary": "Logo embedding plays a crucial role in various e-commerce applications by\nfacilitating image retrieval or recognition, such as intellectual property\nprotection and product search. However, current methods treat logo embedding as\na purely visual problem, which may limit their performance in real-world\nscenarios. A notable issue is that the textual knowledge embedded in logo\nimages has not been adequately explored. Therefore, we propose a novel approach\nthat leverages textual knowledge as an auxiliary to improve the robustness of\nlogo embedding. The emerging Multimodal Large Language Models (MLLMs) have\ndemonstrated remarkable capabilities in both visual and textual understanding\nand could become valuable visual assistants in understanding logo images.\nInspired by this observation, our proposed method, FashionLOGO, aims to utilize\nMLLMs to enhance fashion logo embedding. We explore how MLLMs can improve logo\nembedding by prompting them to generate explicit textual knowledge through\nthree types of prompts, including image OCR, brief captions, and detailed\ndescriptions prompts, in a zero-shot setting. We adopt a cross-attention\ntransformer to enable image embedding queries to learn supplementary knowledge\nfrom textual embeddings automatically. To reduce computational costs, we only\nuse the image embedding model in the inference stage, similar to traditional\ninference pipelines. Our extensive experiments on three real-world datasets\ndemonstrate that FashionLOGO learns generalized and robust logo embeddings,\nachieving state-of-the-art performance in all benchmark datasets. Furthermore,\nwe conduct comprehensive ablation studies to demonstrate the performance\nimprovements resulting from the introduction of MLLMs.",
            "author": [
                "Yulin Su",
                "Min Yang",
                "Minghui Qiu",
                "Jing Wang",
                "Tao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09012v1",
                "http://arxiv.org/pdf/2308.09012v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09011v1",
            "title": "Characterizing bipartite distance-regularized graphs with vertices of\n  eccentricity 4",
            "updated": "2023-08-17T14:25:49Z",
            "published": "2023-08-17T14:25:49Z",
            "summary": "The characterization of bipartite distance-regularized graphs, where some\nvertices have eccentricity less than four, in terms of the incidence structures\nof which they are incidence graphs, is known. In this paper we prove that there\nis a one-to-one correspondence between the incidence graphs of quasi-symmetric\nSPBIBDs with parameters $(v,b,r,k, \\lambda_1,0)$ of type $(k-1,t)$ with\nintersection numbers $x=0$ and $y>0$, where $0< y\\leq t<k$ , and bipartite\ndistance-regularized graphs with $D=D'=4$.",
            "author": [
                "Blas Fern\u00e1ndez",
                "Marija Maksimovi\u0107",
                "Sanja Rukavina"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09011v1",
                "http://arxiv.org/pdf/2308.09011v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09000v3",
            "title": "DealMVC: Dual Contrastive Calibration for Multi-view Clustering",
            "updated": "2023-11-07T02:38:17Z",
            "published": "2023-08-17T14:14:28Z",
            "summary": "Benefiting from the strong view-consistent information mining capacity,\nmulti-view contrastive clustering has attracted plenty of attention in recent\nyears. However, we observe the following drawback, which limits the clustering\nperformance from further improvement. The existing multi-view models mainly\nfocus on the consistency of the same samples in different views while ignoring\nthe circumstance of similar but different samples in cross-view scenarios. To\nsolve this problem, we propose a novel Dual contrastive calibration network for\nMulti-View Clustering (DealMVC). Specifically, we first design a fusion\nmechanism to obtain a global cross-view feature. Then, a global contrastive\ncalibration loss is proposed by aligning the view feature similarity graph and\nthe high-confidence pseudo-label graph. Moreover, to utilize the diversity of\nmulti-view information, we propose a local contrastive calibration loss to\nconstrain the consistency of pair-wise view features. The feature structure is\nregularized by reliable class information, thus guaranteeing similar samples\nhave similar features in different views. During the training procedure, the\ninteracted cross-view feature is jointly optimized at both local and global\nlevels. In comparison with other state-of-the-art approaches, the comprehensive\nexperimental results obtained from eight benchmark datasets provide substantial\nvalidation of the effectiveness and superiority of our algorithm. We release\nthe code of DealMVC at https://github.com/xihongyang1999/DealMVC on GitHub.",
            "author": [
                "Xihong Yang",
                "Jiaqi Jin",
                "Siwei Wang",
                "Ke Liang",
                "Yue Liu",
                "Yi Wen",
                "Suyuan Liu",
                "Sihang Zhou",
                "Xinwang Liu",
                "En Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09000v3",
                "http://arxiv.org/pdf/2308.09000v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08990v1",
            "title": "Semantic Information for Object Detection",
            "updated": "2023-08-17T13:53:29Z",
            "published": "2023-08-17T13:53:29Z",
            "summary": "In this paper, we demonstrate that the concept of Semantic Consistency and\nthe ensuing method of Knowledge-Aware Re-Optimization can be adapted for the\nproblem of object detection in intricate traffic scenes. Furthermore, we\nintroduce a novel method for extracting a knowledge graph from a dataset of\nimages provided with instance-level annotations, and integrate this new\nknowledge graph with the existing semantic consistency model. Combining both\nthis novel hybrid knowledge graph and the preexisting methods of frequency\nanalysis and external knowledge graph as sources for semantic information, we\ninvestigate the effectiveness of knowledge-aware re-optimization on the\nFaster-RCNN and DETR object detection models. We find that limited but\nconsistent improvements in precision and or recall can be achieved using this\nmethod for all combinations of model and method studied.",
            "author": [
                "Jean-Francois Nies"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08990v1",
                "http://arxiv.org/pdf/2308.08990v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09727v1",
            "title": "Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank",
            "updated": "2023-08-17T13:29:57Z",
            "published": "2023-08-17T13:29:57Z",
            "summary": "Traffic forecasting is a critical service in Intelligent Transportation\nSystems (ITS). Utilizing deep models to tackle this task relies heavily on data\nfrom traffic sensors or vehicle devices, while some cities might lack device\nsupport and thus have few available data. So, it is necessary to learn from\ndata-rich cities and transfer the knowledge to data-scarce cities in order to\nimprove the performance of traffic forecasting. To address this problem, we\npropose a cross-city few-shot traffic forecasting framework via Traffic Pattern\nBank (TPB) due to that the traffic patterns are similar across cities. TPB\nutilizes a pre-trained traffic patch encoder to project raw traffic data from\ndata-rich cities into high-dimensional space, from which a traffic pattern bank\nis generated through clustering. Then, the traffic data of the data-scarce city\ncould query the traffic pattern bank and explicit relations between them are\nconstructed. The metaknowledge is aggregated based on these relations and an\nadjacency matrix is constructed to guide a downstream spatial-temporal model in\nforecasting future traffic. The frequently used meta-training framework Reptile\nis adapted to find a better initial parameter for the learnable modules.\nExperiments on real-world traffic datasets show that TPB outperforms existing\nmethods and demonstrates the effectiveness of our approach in cross-city\nfew-shot traffic forecasting.",
            "author": [
                "Zhanyu Liu",
                "Guanjie Zheng",
                "Yanwei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09727v1",
                "http://arxiv.org/pdf/2308.09727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08970v1",
            "title": "Geodetic Graphs: Experiments and New Constructions",
            "updated": "2023-08-17T13:20:15Z",
            "published": "2023-08-17T13:20:15Z",
            "summary": "In 1962 Ore initiated the study of geodetic graphs. A graph is called\ngeodetic if the shortest path between every pair of vertices is unique. In the\nsubsequent years a wide range of papers appeared investigating their peculiar\nproperties. Yet, a complete classification of geodetic graphs is out of reach.\n  In this work we present a program enumerating all geodetic graphs of a given\nsize. Using our program, we succeed to find all geodetic graphs with up to 25\nvertices and all regular geodetic graphs with up to 32 vertices. This leads to\nthe discovery of two new infinite families of geodetic graphs.",
            "author": [
                "Florian Stober",
                "Armin Wei\u00df"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08970v1",
                "http://arxiv.org/pdf/2308.08970v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08966v2",
            "title": "Weakly and Strongly Fan-Planar Graphs",
            "updated": "2023-08-30T19:31:32Z",
            "published": "2023-08-17T13:13:58Z",
            "summary": "We study two notions of fan-planarity introduced by (Cheong et al., GD22),\ncalled weak and strong fan-planarity, which separate two non-equivalent\ndefinitions of fan-planarity in the literature. We prove that not every weakly\nfan-planar graph is strongly fan-planar, while the upper bound on the edge\ndensity is the same for both families.",
            "author": [
                "Otfried Cheong",
                "Henry F\u00f6rster",
                "Julia Katheder",
                "Maximilian Pfister",
                "Lena Schlipf"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08966v2",
                "http://arxiv.org/pdf/2308.08966v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08963v3",
            "title": "CONVERT:Contrastive Graph Clustering with Reliable Augmentation",
            "updated": "2023-10-20T08:14:23Z",
            "published": "2023-08-17T13:07:09Z",
            "summary": "Contrastive graph node clustering via learnable data augmentation is a hot\nresearch spot in the field of unsupervised graph learning. The existing methods\nlearn the sampling distribution of a pre-defined augmentation to generate\ndata-driven augmentations automatically. Although promising clustering\nperformance has been achieved, we observe that these strategies still rely on\npre-defined augmentations, the semantics of the augmented graph can easily\ndrift. The reliability of the augmented view semantics for contrastive learning\ncan not be guaranteed, thus limiting the model performance. To address these\nproblems, we propose a novel CONtrastiVe Graph ClustEring network with Reliable\nAugmenTation (CONVERT). Specifically, in our method, the data augmentations are\nprocessed by the proposed reversible perturb-recover network. It distills\nreliable semantic information by recovering the perturbed latent embeddings.\nMoreover, to further guarantee the reliability of semantics, a novel semantic\nloss is presented to constrain the network via quantifying the perturbation and\nrecovery. Lastly, a label-matching mechanism is designed to guide the model by\nclustering information through aligning the semantic labels and the selected\nhigh-confidence clustering pseudo labels. Extensive experimental results on\nseven datasets demonstrate the effectiveness of the proposed method. We release\nthe code and appendix of CONVERT at https://github.com/xihongyang1999/CONVERT\non GitHub.",
            "author": [
                "Xihong Yang",
                "Cheng Tan",
                "Yue Liu",
                "Ke Liang",
                "Siwei Wang",
                "Sihang Zhou",
                "Jun Xia",
                "Stan Z. Li",
                "Xinwang Liu",
                "En Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08963v3",
                "http://arxiv.org/pdf/2308.08963v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.11761v1",
            "title": "KnowledGPT: Enhancing Large Language Models with Retrieval and Storage\n  Access on Knowledge Bases",
            "updated": "2023-08-17T13:07:00Z",
            "published": "2023-08-17T13:07:00Z",
            "summary": "Large language models (LLMs) have demonstrated impressive impact in the field\nof natural language processing, but they still struggle with several issues\nregarding, such as completeness, timeliness, faithfulness and adaptability.\nWhile recent efforts have focuses on connecting LLMs with external knowledge\nsources, the integration of knowledge bases (KBs) remains understudied and\nfaces several challenges. In this paper, we introduce KnowledGPT, a\ncomprehensive framework to bridge LLMs with various knowledge bases,\nfacilitating both the retrieval and storage of knowledge. The retrieval process\nemploys the program of thought prompting, which generates search language for\nKBs in code format with pre-defined functions for KB operations. Besides\nretrieval, KnowledGPT offers the capability to store knowledge in a\npersonalized KB, catering to individual user demands. With extensive\nexperiments, we show that by integrating LLMs with KBs, KnowledGPT properly\nanswers a broader range of questions requiring world knowledge compared with\nvanilla LLMs, utilizing both knowledge existing in widely-known KBs and\nextracted into personalized KBs.",
            "author": [
                "Xintao Wang",
                "Qianwen Yang",
                "Yongting Qiu",
                "Jiaqing Liang",
                "Qianyu He",
                "Zhouhong Gu",
                "Yanghua Xiao",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11761v1",
                "http://arxiv.org/pdf/2308.11761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08961v1",
            "title": "On the Evaluation of Neural Code Translation: Taxonomy and Benchmark",
            "updated": "2023-08-17T13:05:27Z",
            "published": "2023-08-17T13:05:27Z",
            "summary": "In recent years, neural code translation has gained increasing attention.\nWhile most of the research focuses on improving model architectures and\ntraining processes, we notice that the evaluation process and benchmark for\ncode translation models are severely limited: they primarily treat source code\nas natural languages and provide a holistic accuracy score while disregarding\nthe full spectrum of model capabilities across different translation types and\ncomplexity. In this paper, we present a comprehensive investigation of four\nstate-of-the-art models and analyze in-depth the advantages and limitations of\nthree existing benchmarks. Based on the empirical results, we develop a\ntaxonomy that categorizes code translation tasks into four primary types\naccording to their complexity and knowledge dependence: token level (type 1),\nsyntactic level (type 2), library level (type 3), and algorithm level (type 4).\nWe then conduct a thorough analysis of how existing approaches perform across\nthese four categories. Our findings indicate that while state-of-the-art code\ntranslation models excel in type-1 and type-2 translations, they struggle with\nknowledge-dependent ones such as type-3 and type-4. Existing benchmarks are\nbiased towards trivial translations, such as keyword mapping. To overcome these\nlimitations, we construct G-TransEval, a new benchmark by manually curating\ntype-3 and type-4 translation pairs and unit test cases. Results on our new\nbenchmark suggest that G-TransEval can exhibit more comprehensive and\nfiner-grained capability of code translation models and thus provide a more\nrigorous evaluation. Our studies also provide more insightful findings and\nsuggestions for future research, such as building type-3 and type-4 training\ndata and ensembling multiple pretraining approaches.",
            "author": [
                "Mingsheng Jiao",
                "Tingrui Yu",
                "Xuan Li",
                "Guanjie Qiu",
                "Xiaodong Gu",
                "Beijun Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08961v1",
                "http://arxiv.org/pdf/2308.08961v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08960v1",
            "title": "Minimum Path Cover: The Power of Parameterization",
            "updated": "2023-08-17T13:02:51Z",
            "published": "2023-08-17T13:02:51Z",
            "summary": "Computing a minimum path cover (MPC) of a directed acyclic graph (DAG) is a\nfundamental problem with a myriad of applications, including reachability.\nAlthough it is known how to solve the problem by a simple reduction to minimum\nflow, recent theoretical advances exploit this idea to obtain algorithms\nparameterized by the number of paths of an MPC, known as the width. These\nresults obtain fast [M\\\"akinen et al., TALG] and even linear time [C\\'aceres et\nal., SODA 2022] algorithms in the small-width regime.\n  In this paper, we present the first publicly available high-performance\nimplementation of state-of-the-art MPC algorithms, including the parameterized\napproaches. Our experiments on random DAGs show that parameterized algorithms\nare orders-of-magnitude faster on dense graphs. Additionally, we present new\npre-processing heuristics based on transitive edge sparsification. We show that\nour heuristics improve MPC-solvers by orders-of-magnitude.",
            "author": [
                "Manuel C\u00e1ceres",
                "Brendan Mumey",
                "Santeri Toivonen",
                "Alexandru I. Tomescu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08960v1",
                "http://arxiv.org/pdf/2308.08960v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08959v1",
            "title": "Partial Homoscedasticity in Causal Discovery with Linear Models",
            "updated": "2023-08-17T12:59:39Z",
            "published": "2023-08-17T12:59:39Z",
            "summary": "Recursive linear structural equation models and the associated directed\nacyclic graphs (DAGs) play an important role in causal discovery. The classic\nidentifiability result for this class of models states that when only\nobservational data is available, each DAG can be identified only up to a Markov\nequivalence class. In contrast, recent work has shown that the DAG can be\nuniquely identified if the errors in the model are homoscedastic, i.e., all\nhave the same variance. This equal variance assumption yields methods that, if\nappropriate, are highly scalable and also sheds light on fundamental\ninformation-theoretic limits and optimality in causal discovery. In this paper,\nwe fill the gap that exists between the two previously considered cases, which\nassume the error variances to be either arbitrary or all equal. Specifically,\nwe formulate a framework of partial homoscedasticity, in which the variables\nare partitioned into blocks and each block shares the same error variance. For\nany such groupwise equal variances assumption, we characterize when two DAGs\ngive rise to identical Gaussian linear structural equation models. Furthermore,\nwe show how the resulting distributional equivalence classes may be represented\nusing a completed partially directed acyclic graph (CPDAG), and we give an\nalgorithm to efficiently construct this CPDAG. In a simulation study, we\ndemonstrate that greedy search provides an effective way to learn the CPDAG and\nexploit partial knowledge about homoscedasticity of errors in structural\nequation models.",
            "author": [
                "Jun Wu",
                "Mathias Drton"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08959v1",
                "http://arxiv.org/pdf/2308.08959v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08945v1",
            "title": "Interpretable Graph Neural Networks for Tabular Data",
            "updated": "2023-08-17T12:35:02Z",
            "published": "2023-08-17T12:35:02Z",
            "summary": "Data in tabular format is frequently occurring in real-world applications.\nGraph Neural Networks (GNNs) have recently been extended to effectively handle\nsuch data, allowing feature interactions to be captured through representation\nlearning. However, these approaches essentially produce black-box models, in\nthe form of deep neural networks, precluding users from following the logic\nbehind the model predictions. We propose an approach, called IGNNet\n(Interpretable Graph Neural Network for tabular data), which constrains the\nlearning algorithm to produce an interpretable model, where the model shows how\nthe predictions are exactly computed from the original input features. A\nlarge-scale empirical investigation is presented, showing that IGNNet is\nperforming on par with state-of-the-art machine-learning algorithms that target\ntabular data, including XGBoost, Random Forests, and TabNet. At the same time,\nthe results show that the explanations obtained from IGNNet are aligned with\nthe true Shapley values of the features without incurring any additional\ncomputational overhead.",
            "author": [
                "Amr Alkhatib",
                "Sofiane Ennadir",
                "Henrik Bostr\u00f6m",
                "Michalis Vazirgiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08945v1",
                "http://arxiv.org/pdf/2308.08945v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08944v2",
            "title": "Maximum chordal subgraphs of random graphs",
            "updated": "2023-09-11T12:43:28Z",
            "published": "2023-08-17T12:29:41Z",
            "summary": "We find asymptotics of the maximum size of a chordal subgraph in a binomial\nrandom graph $G(n,p)$, for $p=\\mathrm{const}$ and $p=n^{-\\alpha+o(1)}$.",
            "author": [
                "Michael Krivelevich",
                "Maksim Zhukovskii"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08944v2",
                "http://arxiv.org/pdf/2308.08944v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08918v1",
            "title": "IMM: An Imitative Reinforcement Learning Approach with Predictive\n  Representation Learning for Automatic Market Making",
            "updated": "2023-08-17T11:04:09Z",
            "published": "2023-08-17T11:04:09Z",
            "summary": "Market making (MM) has attracted significant attention in financial trading\nowing to its essential function in ensuring market liquidity. With strong\ncapabilities in sequential decision-making, Reinforcement Learning (RL)\ntechnology has achieved remarkable success in quantitative trading.\nNonetheless, most existing RL-based MM methods focus on optimizing single-price\nlevel strategies which fail at frequent order cancellations and loss of queue\npriority. Strategies involving multiple price levels align better with actual\ntrading scenarios. However, given the complexity that multi-price level\nstrategies involves a comprehensive trading action space, the challenge of\neffectively training profitable RL agents for MM persists. Inspired by the\nefficient workflow of professional human market makers, we propose Imitative\nMarket Maker (IMM), a novel RL framework leveraging both knowledge from\nsuboptimal signal-based experts and direct policy interactions to develop\nmulti-price level MM strategies efficiently. The framework start with\nintroducing effective state and action representations adept at encoding\ninformation about multi-price level orders. Furthermore, IMM integrates a\nrepresentation learning unit capable of capturing both short- and long-term\nmarket trends to mitigate adverse selection risk. Subsequently, IMM formulates\nan expert strategy based on signals and trains the agent through the\nintegration of RL and imitation learning techniques, leading to efficient\nlearning. Extensive experimental results on four real-world market datasets\ndemonstrate that IMM outperforms current RL-based market making strategies in\nterms of several financial criteria. The findings of the ablation study\nsubstantiate the effectiveness of the model components.",
            "author": [
                "Hui Niu",
                "Siyuan Li",
                "Jiahao Zheng",
                "Zhouchi Lin",
                "Jian Li",
                "Jian Guo",
                "Bo An"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08918v1",
                "http://arxiv.org/pdf/2308.08918v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08911v1",
            "title": "Towards Filling the Gap in Conversational Search: From Passage Retrieval\n  to Conversational Response Generation",
            "updated": "2023-08-17T10:54:47Z",
            "published": "2023-08-17T10:54:47Z",
            "summary": "Research on conversational search has so far mostly focused on query\nrewriting and multi-stage passage retrieval. However, synthesizing the top\nretrieved passages into a complete, relevant, and concise response is still an\nopen challenge. Having snippet-level annotations of relevant passages would\nenable both (1) the training of response generation models that are able to\nground answers in actual statements and (2) the automatic evaluation of the\ngenerated responses in terms of completeness. In this paper, we address the\nproblem of collecting high-quality snippet-level answer annotations for two of\nthe TREC Conversational Assistance track datasets. To ensure quality, we first\nperform a preliminary annotation study, employing different task designs,\ncrowdsourcing platforms, and workers with different qualifications. Based on\nthe outcomes of this study, we refine our annotation protocol before proceeding\nwith the full-scale data collection. Overall, we gather annotations for 1.8k\nquestion-paragraph pairs, each annotated by three independent crowd workers.\nThe process of collecting data at this magnitude also led to multiple insights\nabout the problem that can inform the design of future response-generation\nmethods. This is an extended version of the article published with the same\ntitle in the Proceedings of CIKM'23.",
            "author": [
                "Weronika \u0141ajewska",
                "Krisztian Balog"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615132",
                "http://arxiv.org/abs/2308.08911v1",
                "http://arxiv.org/pdf/2308.08911v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08904v1",
            "title": "Development of a Knowledge Graph Embeddings Model for Pain",
            "updated": "2023-08-17T10:27:43Z",
            "published": "2023-08-17T10:27:43Z",
            "summary": "Pain is a complex concept that can interconnect with other concepts such as a\ndisorder that might cause pain, a medication that might relieve pain, and so\non. To fully understand the context of pain experienced by either an individual\nor across a population, we may need to examine all concepts related to pain and\nthe relationships between them. This is especially useful when modeling pain\nthat has been recorded in electronic health records. Knowledge graphs represent\nconcepts and their relations by an interlinked network, enabling semantic and\ncontext-based reasoning in a computationally tractable form. These graphs can,\nhowever, be too large for efficient computation. Knowledge graph embeddings\nhelp to resolve this by representing the graphs in a low-dimensional vector\nspace. These embeddings can then be used in various downstream tasks such as\nclassification and link prediction. The various relations associated with pain\nwhich are required to construct such a knowledge graph can be obtained from\nexternal medical knowledge bases such as SNOMED CT, a hierarchical systematic\nnomenclature of medical terms. A knowledge graph built in this way could be\nfurther enriched with real-world examples of pain and its relations extracted\nfrom electronic health records. This paper describes the construction of such\nknowledge graph embedding models of pain concepts, extracted from the\nunstructured text of mental health electronic health records, combined with\nexternal knowledge created from relations described in SNOMED CT, and their\nevaluation on a subject-object link prediction task. The performance of the\nmodels was compared with other baseline models.",
            "author": [
                "Jaya Chaturvedi",
                "Tao Wang",
                "Sumithra Velupillai",
                "Robert Stewart",
                "Angus Roberts"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08904v1",
                "http://arxiv.org/pdf/2308.08904v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08895v1",
            "title": "Existence results for some nonlinear elliptic systems on graphs",
            "updated": "2023-08-17T10:02:26Z",
            "published": "2023-08-17T10:02:26Z",
            "summary": "In this paper, several nonlinear elliptic systems are investigated on graphs.\nOne type of the sobolev embedding theorem and a new version of the strong\nmaximum principle are established. Then, by using the variational method, the\nexistence of different types of solutions to some elliptic systems is\nconfirmed. Such problems extend the existence results on closed Riemann surface\nto graphs and extend the existence results for one single equation on graphs\n[A. Grigor'yan, Y. Lin, Y. Yang, J. Differential Equations, 2016] to nonlinear\nelliptic systems on graphs. Such problems can also be viewed as one type of\ndiscrete version of the elliptic systems on Euclidean space and Riemannian\nmanifold.",
            "author": [
                "Shoudong Man"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08895v1",
                "http://arxiv.org/pdf/2308.08895v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35A15, 35J50, 35R02"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08890v1",
            "title": "Mixed causality graphs for continuous-time stationary processes",
            "updated": "2023-08-17T09:54:42Z",
            "published": "2023-08-17T09:54:42Z",
            "summary": "In this paper, we introduce different concepts of Granger non-causality and\ncontemporaneous uncorrelation for stationary continuous-time processes to model\nthe different dependencies between the component series of multivariate time\nseries models. Several equivalent characterisations for the different\ndefinitions are given, in particular by linear projections. We then define two\nmixed graphs based on different definitions of causality and contemporaneous\nuncorrelation, the (mixed) causality graph and the local (mixed) causality\ngraph, to visualise and to analyse the different dependencies in stationary\ncontinuous-time processes. In these graphs, the components of the process are\nrepresented by vertices, directed edges between the vertices indicate causal\ninfluences and undirected edges indicate contemporaneous uncorrelation between\nthe component processes. Further, we introduce various notions of causal Markov\nproperties in analogy to Eichler (2012), which relate the different dependence\nstructures of subprocesses, and we derive sufficient criteria for the (local)\ncausality graph to satisfy them. Finally, as an example, the popular\nmultivariate continuous-time AR (MCAR) processes satisfy our assumptions. For\nMCAR processes we show that the (local) causality graphs can be characterised\nexplicitly by the model parameters.",
            "author": [
                "Vicky Fasen-Hartmann",
                "Lea Schenk"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08890v1",
                "http://arxiv.org/pdf/2308.08890v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "math.PR",
                "stat.TH",
                "62H22, 62M10 (Primary) 62M20 (Secondary)",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08873v3",
            "title": "Accelerating Training Time with Feature Enforcing- Physics Informed\n  Neural Network (FE-PINN): Utilizing Boundary Conditions as Prior Knowledge\n  for Faster Convergence",
            "updated": "2023-09-27T07:43:29Z",
            "published": "2023-08-17T09:10:07Z",
            "summary": "In this study, Feature Enforcing Physics Informed Neural Network FEPINN is\nintroduced, which is a data free framework that enables a neural network to\nlearn boundary conditions before solving continuity and momentum partial\ndifferential equations PDEs. A new sampling approach is represented, which\nselects domain points as a function of different initial weight states of\nneural networks initialized with the Xavier scheme. The study hypothesizes that\nusing an initial weight state with lower variance is beneficial when learning\nsimple patterns, such as boundary conditions. After training the neural network\nto learn boundary conditions, the complexity of the model is increased by\nadding new layers on top of the neural network. FE-PINN is used to solve two\nbenchmarks, 2D flow over a cylinder and an inverse problem of determining the\ninlet velocity for a 2D flow over a cylinder. It is found that FE-PINN trains\nabout two times faster than vanilla PINN for both benchmarks, even when the\nvanilla PINN uses optimal weight values in the loss function obtained by random\nsearch. Moreover, FE-PINN's loss function is balanced due to its prior\nknowledge of boundary conditions, eliminating the need for loss weighting. For\ninstance, learning no slip boundary conditions on side walls with FE-PINN\nbefore the main training loop is 574 times faster than loss weighting process\nin vanilla PINN. In conclusion, FE-PINN offers a fast and accurate tool for\nsolving various PDEs across different fields.",
            "author": [
                "Mahyar Jahaninasab",
                "Mohamad Ali Bijarchi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08873v3",
                "http://arxiv.org/pdf/2308.08873v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08872v1",
            "title": "Towards Semi-supervised Learning with Non-random Missing Labels",
            "updated": "2023-08-17T09:09:36Z",
            "published": "2023-08-17T09:09:36Z",
            "summary": "Semi-supervised learning (SSL) tackles the label missing problem by enabling\nthe effective usage of unlabeled data. While existing SSL methods focus on the\ntraditional setting, a practical and challenging scenario called label Missing\nNot At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled\ndata fall into different class distributions resulting in biased label\nimputation, which deteriorates the performance of SSL models. In this work,\nclass transition tracking based Pseudo-Rectifying Guidance (PRG) is devised for\nMNAR. We explore the class-level guidance information obtained by the Markov\nrandom walk, which is modeled on a dynamically created graph built over the\nclass tracking matrix. PRG unifies the historical information of class\ndistribution and class transitions caused by the pseudo-rectifying procedure to\nmaintain the model's unbiased enthusiasm towards assigning pseudo-labels to all\nclasses, so as the quality of pseudo-labels on both popular classes and rare\nclasses in MNAR could be improved. Finally, we show the superior performance of\nPRG across a variety of MNAR scenarios, outperforming the latest SSL approaches\ncombining bias removal solutions by a large margin. Code and model weights are\navailable at https://github.com/NJUyued/PRG4SSL-MNAR.",
            "author": [
                "Yue Duan",
                "Zhen Zhao",
                "Lei Qi",
                "Luping Zhou",
                "Lei Wang",
                "Yinghuan Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08872v1",
                "http://arxiv.org/pdf/2308.08872v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08870v1",
            "title": "Sensitivity and Dynamic Distance Oracles via Generic Matrices and\n  Frobenius Form",
            "updated": "2023-08-17T09:02:45Z",
            "published": "2023-08-17T09:02:45Z",
            "summary": "Algebraic techniques have had an important impact on graph algorithms so far.\nPorting them, e.g., the matrix inverse, into the dynamic regime improved\nbest-known bounds for various dynamic graph problems. In this paper, we develop\nnew algorithms for another cornerstone algebraic primitive, the Frobenius\nnormal form (FNF). We apply our developments to dynamic and fault-tolerant\nexact distance oracle problems on directed graphs.\n  For generic matrices $A$ over a finite field accompanied by an FNF, we show\n(1) an efficient data structure for querying submatrices of the first $k\\geq 1$\npowers of $A$, and (2) a near-optimal algorithm updating the FNF explicitly\nunder rank-1 updates.\n  By representing an unweighted digraph using a generic matrix over a\nsufficiently large field (obtained by random sampling) and leveraging the\ndeveloped FNF toolbox, we obtain: (a) a conditionally optimal distance\nsensitivity oracle (DSO) in the case of single-edge or single-vertex failures,\nproviding a partial answer to the open question of Gu and Ren [ICALP'21], (b) a\nmultiple-failures DSO improving upon the state of the art (vd. Brand and\nSaranurak [FOCS'19]) wrt. both preprocessing and query time, (c) improved\ndynamic distance oracles in the case of single-edge updates, and (d) a dynamic\ndistance oracle supporting vertex updates, i.e., changing all edges incident to\na single vertex, in $\\tilde{O}(n^2)$ worst-case time and distance queries in\n$\\tilde{O}(n)$ time.",
            "author": [
                "Adam Karczmarz",
                "Piotr Sankowski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08870v1",
                "http://arxiv.org/pdf/2308.08870v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08868v1",
            "title": "Computing complexity measures of degenerate graphs",
            "updated": "2023-08-17T09:01:47Z",
            "published": "2023-08-17T09:01:47Z",
            "summary": "We show that the VC-dimension of a graph can be computed in time $n^{\\log\nd+1} d^{O(d)}$, where $d$ is the degeneracy of the input graph. The core idea\nof our algorithm is a data structure to efficiently query the number of\nvertices that see a specific subset of vertices inside of a (small) query set.\nThe construction of this data structure takes time $O(d2^dn)$, afterwards\nqueries can be computed efficiently using fast M\\\"obius inversion.\n  This data structure turns out to be useful for a range of tasks, especially\nfor finding bipartite patterns in degenerate graphs, and we outline an\nefficient algorithms for counting the number of times specific patterns occur\nin a graph. The largest factor in the running time of this algorithm is\n$O(n^c)$, where $c$ is a parameter of the pattern we call its left covering\nnumber.\n  Concrete applications of this algorithm include counting the number of\n(non-induced) bicliques in linear time, the number of co-matchings in quadratic\ntime, as well as a constant-factor approximation of the ladder index in linear\ntime.\n  Finally, we supplement our theoretical results with several implementations\nand run experiments on more than 200 real-world datasets -- the largest of\nwhich has 8 million edges -- where we obtain interesting insights into the\nVC-dimension of real-world networks.",
            "author": [
                "P\u00e5l Gr\u00f8n\u00e5s Drange",
                "Patrick Greaves",
                "Irene Muzi",
                "Felix Reidl"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08868v1",
                "http://arxiv.org/pdf/2308.08868v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "05C85",
                "F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08834v1",
            "title": "Planar Doodles: Their Properties, Codes and Classification",
            "updated": "2023-08-17T07:52:18Z",
            "published": "2023-08-17T07:52:18Z",
            "summary": "We present those properties of planar doodles, especially when regarded as\n4-valent graphs, that enable us to classify them into {\\it prime} and {\\it\nsuper prime} doodles by analogy to a knot sum. We describe a method for\npartially characterising a doodle diagram by a {\\it doodle code} that describes\nthe complementary regions of the diagram and use that code to enumerate all\npossible prime and super prime doodle diagrams via their dual graph. In\naddition we explore the relationship between planar doodles and twin groups,\nand note that a theorem of Tutte means that super prime doodles have a\nHamiltonian circuit. We hope to expand upon this last point in a follow-up\npaper.",
            "author": [
                "Andrew Bartholomew",
                "Roger Fenn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08834v1",
                "http://arxiv.org/pdf/2308.08834v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "05C10, 05A05, 05B30, 57M15, 57M25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08829v1",
            "title": "A new multi-metric approach for quantifying global biodiscovery and\n  conservation priorities reveals overlooked hotspots for amphibians",
            "updated": "2023-08-17T07:42:27Z",
            "published": "2023-08-17T07:42:27Z",
            "summary": "Undocumented species represent one of the largest hurdles for conservation\nefforts due to the uncertainty they introduce into conservation planning. Until\nthe distribution of earth's biodiversity is better understood, substantial\nconjecture will continue to be required for protecting species from\nanthropogenic extinction. Therefore, we developed a novel approach for\nidentifying regions with promising biodiscovery prospects, linked to\nintegrative conservation priorities, which we illustrate using amphibians. Our\napproach builds on previous estimates of biodiscovery priorities by\nsimultaneously (1) considering linkages between spatio-environmental variables\nand biodiversity, (2) accounting for the negative relationship between past\nsampling intensity and future biodiscovery potential, (3) incorporating a\npriori knowledge about global species distribution patterns, (4) addressing\nspatial autocorrelation in community composition, and (5) weighting theoretical\nundocumented species by their predicted levels of conservation need. Using\nboosted regression trees and 50km^2 map pixels spread across the global range\nof amphibians, we identified several regions likely to contain many\nundocumented amphibian species and conservation needs, including the Southeast\nAsian Archipelago, humid portions of sub-Saharan Africa, and undersampled\nportions of the Amazon, Andes Mountains, and Central America. We also ranked\ntop-scoring ecoregions by their mean and maximum biodiscovery potential and\nfound that the top-20 ranked ecoregions were most concentrated in the Southeast\nAsian Archipelago and tropical Africa for undocumented species richness, and in\ntropical Africa and tropical South America for integrative undocumented\namphibian conservation needs. However, high-scoring pixels tended to be widely\ndistributed across different ecoregions for both biodiscovery scoring\napproaches.",
            "author": [
                "Sky Button",
                "Ama\u00ebl Borz\u00e9e"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08829v1",
                "http://arxiv.org/pdf/2308.08829v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08825v1",
            "title": "Controlling Federated Learning for Covertness",
            "updated": "2023-08-17T07:16:41Z",
            "published": "2023-08-17T07:16:41Z",
            "summary": "A learner aims to minimize a function $f$ by repeatedly querying a\ndistributed oracle that provides noisy gradient evaluations. At the same time,\nthe learner seeks to hide $\\arg\\min f$ from a malicious eavesdropper that\nobserves the learner's queries. This paper considers the problem of\n\\textit{covert} or \\textit{learner-private} optimization, where the learner has\nto dynamically choose between learning and obfuscation by exploiting the\nstochasticity. The problem of controlling the stochastic gradient algorithm for\ncovert optimization is modeled as a Markov decision process, and we show that\nthe dynamic programming operator has a supermodular structure implying that the\noptimal policy has a monotone threshold structure. A computationally efficient\npolicy gradient algorithm is proposed to search for the optimal querying policy\nwithout knowledge of the transition probabilities. As a practical application,\nour methods are demonstrated on a hate speech classification task in a\nfederated setting where an eavesdropper can use the optimal weights to generate\ntoxic content, which is more easily misclassified. Numerical results show that\nwhen the learner uses the optimal policy, an eavesdropper can only achieve a\nvalidation accuracy of $52\\%$ with no information and $69\\%$ when it has a\npublic dataset with 10\\% positive samples compared to $83\\%$ when the learner\nemploys a greedy policy.",
            "author": [
                "Adit Jain",
                "Vikram Krishnamurthy"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08825v1",
                "http://arxiv.org/pdf/2308.08825v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08823v1",
            "title": "Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active\n  Learning",
            "updated": "2023-08-17T07:06:54Z",
            "published": "2023-08-17T07:06:54Z",
            "summary": "Graph Active Learning (GAL), which aims to find the most informative nodes in\ngraphs for annotation to maximize the Graph Neural Networks (GNNs) performance,\nhas attracted many research efforts but remains non-trivial challenges. One\nmajor challenge is that existing GAL strategies may introduce semantic\nconfusion to the selected training set, particularly when graphs are noisy.\nSpecifically, most existing methods assume all aggregating features to be\nhelpful, ignoring the semantically negative effect between inter-class edges\nunder the message-passing mechanism. In this work, we present Semantic-aware\nActive learning framework for Graphs (SAG) to mitigate the semantic confusion\nproblem. Pairwise similarities and dissimilarities of nodes with semantic\nfeatures are introduced to jointly evaluate the node influence. A new\nprototype-based criterion and query policy are also designed to maintain\ndiversity and class balance of the selected nodes, respectively. Extensive\nexperiments on the public benchmark graphs and a real-world financial dataset\ndemonstrate that SAG significantly improves node classification performances\nand consistently outperforms previous methods. Moreover, comprehensive analysis\nand ablation study also verify the effectiveness of the proposed framework.",
            "author": [
                "Tianmeng Yang",
                "Min Zhou",
                "Yujing Wang",
                "Zhengjie Lin",
                "Lujia Pan",
                "Bin Cui",
                "Yunhai Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08823v1",
                "http://arxiv.org/pdf/2308.08823v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08822v1",
            "title": "MixBag: Bag-Level Data Augmentation for Learning from Label Proportions",
            "updated": "2023-08-17T07:06:50Z",
            "published": "2023-08-17T07:06:50Z",
            "summary": "Learning from label proportions (LLP) is a promising weakly supervised\nlearning problem. In LLP, a set of instances (bag) has label proportions, but\nno instance-level labels are given. LLP aims to train an instance-level\nclassifier by using the label proportions of the bag. In this paper, we propose\na bag-level data augmentation method for LLP called MixBag, based on the key\nobservation from our preliminary experiments; that the instance-level\nclassification accuracy improves as the number of labeled bags increases even\nthough the total number of instances is fixed. We also propose a confidence\ninterval loss designed based on statistical theory to use the augmented bags\neffectively. To the best of our knowledge, this is the first attempt to propose\nbag-level data augmentation for LLP. The advantage of MixBag is that it can be\napplied to instance-level data augmentation techniques and any LLP method that\nuses the proportion loss. Experimental results demonstrate this advantage and\nthe effectiveness of our method.",
            "author": [
                "Takanori Asanomi",
                "Shinnosuke Matsuo",
                "Daiki Suehiro",
                "Ryoma Bise"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08822v1",
                "http://arxiv.org/pdf/2308.08822v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08808v1",
            "title": "Entrepreneurial Higher Education Education, Knowledge and Wealth\n  Creation",
            "updated": "2023-08-17T06:36:25Z",
            "published": "2023-08-17T06:36:25Z",
            "summary": "This book presents detailed discussion on the role of higher education in\nterms of serving basic knowledge creation, teaching, and doing applied research\nfor commercialization. The book presents an historical account on how this\nchallenge was addressed earlier in education history, the cases of successful\nacademic commercialization, the marriage between basic and applied science and\nhow universities develop economies of the regions and countries. This book also\ndiscusses cultural and social challenges in research commercialization and\npathways to break the status quo.",
            "author": [
                "Rahmat Ullah",
                "Rashid Aftab",
                "Saeed Siyal",
                "Kashif Zaheer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08808v1",
                "http://arxiv.org/pdf/2308.08808v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC",
                "14J26"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08805v1",
            "title": "Bayesian Variational Time-lapse Full-waveform Inversion",
            "updated": "2023-08-17T06:32:05Z",
            "published": "2023-08-17T06:32:05Z",
            "summary": "Time-lapse seismic full-waveform inversion (FWI) provides estimates of\ndynamic changes in the subsurface by performing multiple seismic surveys at\ndifferent times. Since FWI problems are highly non-linear and non-unique, it is\nimportant to quantify uncertainties in such estimates to allow robust decision\nmaking. Markov chain Monte Carlo (McMC) methods have been used for this\npurpose, but due to their high computational cost, those studies often require\nan accurate baseline model and estimates of the locations of potential velocity\nchanges, and neglect uncertainty in the baseline velocity model. Such detailed\nand accurate prior information is not always available in practice.\n  In this study we use an efficient optimization method called stochastic Stein\nvariational gradient descent (sSVGD) to solve time-lapse FWI problems without\nassuming such prior knowledge, and to estimate uncertainty both in the baseline\nvelocity model and the velocity change. We test two Bayesian strategies:\nseparate Bayesian inversions for each seismic survey, and a single join\ninversion for baseline and repeat surveys, and compare the methods with the\nstandard linearised double difference inversion. The results demonstrate that\nall three methods can produce accurate velocity change estimates in the case of\nhaving fixed (exactly repeatable) acquisition geometries, but that the two\nBayesian methods generate more accurate results when the acquisition geometry\nchanges between surveys. Furthermore the joint inversion provides the most\naccurate velocity change and uncertainty estimates in all cases. We therefore\nconclude that Bayesian time-lapse inversion, especially adopting a joint\ninversion strategy, may be useful to image and monitor the subsurface changes,\nin particular where uncertainty in the results might lead to significantly\ndifferent decisions.",
            "author": [
                "Xin Zhang",
                "Andrew Curtis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08805v1",
                "http://arxiv.org/pdf/2308.08805v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08799v1",
            "title": "Capturing Popularity Trends: A Simplistic Non-Personalized Approach for\n  Enhanced Item Recommendation",
            "updated": "2023-08-17T06:20:03Z",
            "published": "2023-08-17T06:20:03Z",
            "summary": "Recommender systems have been gaining increasing research attention over the\nyears. Most existing recommendation methods focus on capturing users'\npersonalized preferences through historical user-item interactions, which may\npotentially violate user privacy. Additionally, these approaches often overlook\nthe significance of the temporal fluctuation in item popularity that can sway\nusers' decision-making. To bridge this gap, we propose Popularity-Aware\nRecommender (PARE), which makes non-personalized recommendations by predicting\nthe items that will attain the highest popularity. PARE consists of four\nmodules, each focusing on a different aspect: popularity history, temporal\nimpact, periodic impact, and side information. Finally, an attention layer is\nleveraged to fuse the outputs of four modules. To our knowledge, this is the\nfirst work to explicitly model item popularity in recommendation systems.\nExtensive experiments show that PARE performs on par or even better than\nsophisticated state-of-the-art recommendation methods. Since PARE prioritizes\nitem popularity over personalized user preferences, it can enhance existing\nrecommendation methods as a complementary component. Our experiments\ndemonstrate that integrating PARE with existing recommendation methods\nsignificantly surpasses the performance of standalone models, highlighting\nPARE's potential as a complement to existing recommendation methods.\nFurthermore, the simplicity of PARE makes it immensely practical for industrial\napplications and a valuable baseline for future research.",
            "author": [
                "Jiazheng Jing",
                "Yinan Zhang",
                "Xin Zhou",
                "Zhiqi Shen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614801",
                "http://arxiv.org/abs/2308.08799v1",
                "http://arxiv.org/pdf/2308.08799v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08798v1",
            "title": "Slitherlink Signatures",
            "updated": "2023-08-17T06:17:04Z",
            "published": "2023-08-17T06:17:04Z",
            "summary": "Let $G$ be a planar graph and let $C$ be a cycle in $G$. Inside of each\nfinite face of $G$, we write down the number of edges of that face which belong\nto $C$. This is the signature of $C$ in $G$. The notion of a signature arises\nnaturally in the context of Slitherlink puzzles. The signature of a cycle does\nnot always determine it uniquely. We focus on the ambiguity of signatures in\nthe case when $G$ is a rectangular grid of unit square cells. We describe all\ngrids which admit an ambiguous signature. For each such grid, we then determine\nthe greatest possible difference between two cycles with the same signature on\nit. We also study the possible values of the total number of cycles which fit a\ngiven signature. We discuss various related questions as well.",
            "author": [
                "Nikolai Beluhov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08798v1",
                "http://arxiv.org/pdf/2308.08798v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C10, 05C38"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.16707v2",
            "title": "A Taxonomy for Blockchain-based Decentralized Physical Infrastructure\n  Networks (DePIN)",
            "updated": "2023-10-13T04:22:06Z",
            "published": "2023-08-17T05:08:43Z",
            "summary": "As digitalization and technological advancements continue to shape the\ninfrastructure landscape, the emergence of blockchain-based decentralized\nphysical infrastructure networks (DePINs) has gained prominence. However, a\nsystematic categorization of DePIN components and their interrelationships is\nstill missing. To address this gap, we conduct a literature review and analysis\nof existing frameworks and derived a taxonomy of DePIN systems from a\nconceptual architecture. Our taxonomy encompasses three key dimensions:\ndistributed ledger technology, cryptoeconomic design and physicial\ninfrastructure network. Within each dimension, we identify and define relevant\ncomponents and attributes, establishing a clear hierarchical structure.\nMoreover, we illustrate the relationships and dependencies among the identified\ncomponents, highlighting the interplay between governance models, hardware\narchitectures, networking protocols, token mechanisms, and distributed ledger\ntechnologies. This taxonomy provides a foundation for understanding and\nclassifying diverse DePIN networks, serving as a basis for future research and\nfacilitating knowledge exchange, fostering collaboration and standardization\nwithin the emerging field of decentralized physical infrastructure networks.",
            "author": [
                "Mark C. Ballandies",
                "Hongyang Wang",
                "Andrew Chung Chee Law",
                "Joshua C. Yang",
                "Christophe G\u00f6sken",
                "Michael Andrew"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16707v2",
                "http://arxiv.org/pdf/2309.16707v2"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.CY",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.16706v1",
            "title": "AIR: Threats of Adversarial Attacks on Deep Learning-Based Information\n  Recovery",
            "updated": "2023-08-17T04:55:02Z",
            "published": "2023-08-17T04:55:02Z",
            "summary": "A wireless communications system usually consists of a transmitter which\ntransmits the information and a receiver which recovers the original\ninformation from the received distorted signal. Deep learning (DL) has been\nused to improve the performance of the receiver in complicated channel\nenvironments and state-of-the-art (SOTA) performance has been achieved.\nHowever, its robustness has not been investigated. In order to evaluate the\nrobustness of DL-based information recovery models under adversarial\ncircumstances, we investigate adversarial attacks on the SOTA DL-based\ninformation recovery model, i.e., DeepReceiver. We formulate the problem as an\noptimization problem with power and peak-to-average power ratio (PAPR)\nconstraints. We design different adversarial attack methods according to the\nadversary's knowledge of DeepReceiver's model and/or testing samples. Extensive\nexperiments show that the DeepReceiver is vulnerable to the designed attack\nmethods in all of the considered scenarios. Even in the scenario of both model\nand test sample restricted, the adversary can attack the DeepReceiver and\nincrease its bit error rate (BER) above 10%. It can also be found that the\nDeepReceiver is vulnerable to adversarial perturbations even with very low\npower and limited PAPR. These results suggest that defense measures should be\ntaken to enhance the robustness of DeepReceiver.",
            "author": [
                "Jinyin Chen",
                "Jie Ge",
                "Shilian Zheng",
                "Linhui Ye",
                "Haibin Zheng",
                "Weiguo Shen",
                "Keqiang Yue",
                "Xiaoniu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16706v1",
                "http://arxiv.org/pdf/2309.16706v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09724v1",
            "title": "Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge\n  Transfer",
            "updated": "2023-08-17T04:46:38Z",
            "published": "2023-08-17T04:46:38Z",
            "summary": "Most state-of-the-art deep domain adaptation techniques align source and\ntarget samples in a global fashion. That is, after alignment, each source\nsample is expected to become similar to any target sample. However, global\nalignment may not always be optimal or necessary in practice. For example,\nconsider cross-domain fraud detection, where there are two types of\ntransactions: credit and non-credit. Aligning credit and non-credit\ntransactions separately may yield better performance than global alignment, as\ncredit transactions are unlikely to exhibit patterns similar to non-credit\ntransactions. To enable such fine-grained domain adaption, we propose a novel\nKnowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We\nprovide the theoretical insight that KISA minimizes the shared expected loss\nwhich is the premise for the success of domain adaptation methods. (2) We\npropose the knowledge-inspired subdomain division problem that plays a crucial\nrole in fine-grained domain adaption. (3) We design a knowledge fusion network\nto exploit diverse domain knowledge. Extensive experiments demonstrate that\nKISA achieves remarkable results on fraud detection and traffic demand\nprediction tasks.",
            "author": [
                "Liyue Chen",
                "Linian Wang",
                "Jinyu Xu",
                "Shuai Chen",
                "Weiqiang Wang",
                "Wenbiao Zhao",
                "Qiyu Li",
                "Leye Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09724v1",
                "http://arxiv.org/pdf/2308.09724v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08778v1",
            "title": "Environment Diversification with Multi-head Neural Network for Invariant\n  Learning",
            "updated": "2023-08-17T04:33:38Z",
            "published": "2023-08-17T04:33:38Z",
            "summary": "Neural networks are often trained with empirical risk minimization; however,\nit has been shown that a shift between training and testing distributions can\ncause unpredictable performance degradation. On this issue, a research\ndirection, invariant learning, has been proposed to extract invariant features\ninsensitive to the distributional changes. This work proposes EDNIL, an\ninvariant learning framework containing a multi-head neural network to absorb\ndata biases. We show that this framework does not require prior knowledge about\nenvironments or strong assumptions about the pre-trained model. We also reveal\nthat the proposed algorithm has theoretical connections to recent studies\ndiscussing properties of variant and invariant features. Finally, we\ndemonstrate that models trained with EDNIL are empirically more robust against\ndistributional shifts.",
            "author": [
                "Bo-Wei Huang",
                "Keng-Te Liao",
                "Chang-Sheng Kao",
                "Shou-De Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08778v1",
                "http://arxiv.org/pdf/2308.08778v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08777v1",
            "title": "A Direct Measurement of Hard Two-Photon Exchange with Electrons and\n  Positrons at CLAS12",
            "updated": "2023-08-17T04:28:26Z",
            "published": "2023-08-17T04:28:26Z",
            "summary": "One of the most surprising discoveries made at Jefferson Lab has been the\ndiscrepancy in the determinations of the proton's form factor ratio $\\mu_p\nG_E^p/G_M^p$ between unpolarized cross section measurements and the\npolarization transfer technique. Over two decades later, the discrepancy not\nonly persists but has been confirmed at higher momentum transfers now\naccessible in the 12-GeV era. The leading hypothesis for the cause of this\ndiscrepancy, a non-negligible contribution from hard two-photon exchange, has\nneither been conclusively proven or disproven. This state of uncertainty not\nonly clouds our knowledge of one-dimensional nucleon structure but also poses a\nmajor concern for our field's efforts to map out the three-dimensional nuclear\nstructure. A better understanding of multi-photon exchange over a wide phase\nspace is needed. We propose making comprehensive measurements of two-photon\nexchange over a wide range in momentum transfer and scattering angle using the\nCLAS12 detector. Specifically, we will measure the ratio of positron-proton to\nelectron-proton elastic scattering cross sections, using the proposed positron\nbeam upgrade for CEBAF. The experiment will use 2.2, 4.4, and 6.6 GeV lepton\nbeams incident on the standard CLAS12 unpolarized hydrogen target. Data will be\ncollected by the CLAS12 detector in its standard configuration, except for a\nmodified trigger to allow the recording of events with beam leptons scattered\ninto the CLAS12 central detector. The sign of the beam charge, as well as the\npolarity of the CLAS12 solenoid and toroid, will be reversed several times in\norder to suppress systematics associated with local detector efficiency and\ntime-dependent detector performance. The proposed high-precision determination\nof two-photon effects will be...",
            "author": [
                "A. Schmidt",
                "W. J. Briscoe",
                "O. Cortes",
                "L. Earnest",
                "G. N. Grauvogel",
                "S. Ratliff",
                "E. M. Seroka",
                "P. Sharp",
                "I. I. Strakovsky",
                "G. Niculescu",
                "S. Diehl",
                "P. G. Blunden",
                "E. Cline",
                "I. Korover",
                "T. Kutz",
                "S. N. Santiesteban",
                "C. Fogler",
                "L. B. Weinstein",
                "D. Marchand",
                "S. Niccolai",
                "E. Voutier",
                "A. D'Angelo",
                "J. C. Bernauer",
                "R. Singh",
                "V. Burkert",
                "F. Hauenstein",
                "D. W. Higinbotham",
                "D. Nguyen",
                "E. Pasyuk",
                "H. Szumila-Vance",
                "X. Wei",
                "D. Keller"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08777v1",
                "http://arxiv.org/pdf/2308.08777v1"
            ],
            "primary_category": "nucl-ex",
            "category": [
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08775v1",
            "title": "Learning to In-paint: Domain Adaptive Shape Completion for 3D Organ\n  Segmentation",
            "updated": "2023-08-17T04:19:13Z",
            "published": "2023-08-17T04:19:13Z",
            "summary": "We aim at incorporating explicit shape information into current 3D organ\nsegmentation models. Different from previous works, we formulate shape learning\nas an in-painting task, which is named Masked Label Mask Modeling (MLM).\nThrough MLM, learnable mask tokens are fed into transformer blocks to complete\nthe label mask of organ. To transfer MLM shape knowledge to target, we further\npropose a novel shape-aware self-distillation with both in-painting\nreconstruction loss and pseudo loss. Extensive experiments on five public organ\nsegmentation datasets show consistent improvements over prior arts with at\nleast 1.2 points gain in the Dice score, demonstrating the effectiveness of our\nmethod in challenging unsupervised domain adaptation scenarios including: (1)\nIn-domain organ segmentation; (2) Unseen domain segmentation and (3) Unseen\norgan segmentation. We hope this work will advance shape analysis and geometric\nlearning in medical imaging.",
            "author": [
                "Mingjin Chen",
                "Yongkang He",
                "Yongyi Lu",
                "Zhijing Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08775v1",
                "http://arxiv.org/pdf/2308.08775v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08769v1",
            "title": "Chat-3D: Data-efficiently Tuning Large Language Model for Universal\n  Dialogue of 3D Scenes",
            "updated": "2023-08-17T03:52:15Z",
            "published": "2023-08-17T03:52:15Z",
            "summary": "3D scene understanding has gained significant attention due to its wide range\nof applications. However, existing methods for 3D scene understanding are\nlimited to specific downstream tasks, which hinders their practicality in\nreal-world applications. This paper presents Chat-3D, which combines the 3D\nvisual perceptual ability of pre-trained 3D representations and the impressive\nreasoning and conversation capabilities of advanced LLMs to achieve the first\nuniversal dialogue systems for 3D scenes. Specifically, we align 3D\nrepresentations into the feature space of LLMs, thus enabling LLMs to perceive\nthe 3D world. Given the scarcity of 3D scene-text data, we propose a\nthree-stage training strategy to efficiently utilize the available data for\nbetter alignment. To enhance the reasoning ability and develop a user-friendly\ninteraction scheme, we further construct a high-quality object-centric 3D\ninstruction dataset and design an associated object-centric prompt. Our\nexperiments show that Chat-3D achieves an impressive ability to comprehend\ndiverse instructions for 3D scenes, engage in intricate spatial reasoning, and\nincorporate external knowledge into its responses. Chat-3D achieves a 75.6%\nrelative score compared with GPT-4 on the constructed instruction dataset.",
            "author": [
                "Zehan Wang",
                "Haifeng Huang",
                "Yang Zhao",
                "Ziang Zhang",
                "Zhou Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08769v1",
                "http://arxiv.org/pdf/2308.08769v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08768v1",
            "title": "A tight linear chromatic bound for ($P_3\\cup P_2, W_4$)-free graphs",
            "updated": "2023-08-17T03:51:53Z",
            "published": "2023-08-17T03:51:53Z",
            "summary": "For two vertex disjoint graphs $H$ and $F$, we use $H\\cup F$ to denote the\ngraph with vertex set $V(H)\\cup V(F)$ and edge set $E(H)\\cup E(F)$, and use\n$H+F$ to denote the graph with vertex set $V(H)\\cup V(F)$ and edge set\n$E(H)\\cup E(F)\\cup\\{xy\\;|\\; x\\in V(H), y\\in V(F)$$\\}$. A $W_4$ is the graph\n$K_1+C_4$. In this paper, we prove that $\\chi(G)\\le 2\\omega(G)$ if $G$ is a\n($P_3\\cup P_2, W_4$)-free graph. This bound is tight when $\\omega =2$ and $3$,\nand improves the main result of Wang and Zhang. Also, this bound partially\ngeneralizes some results of Prashant {\\em et al.}.",
            "author": [
                "Rui Li",
                "Jinfeng Li",
                "Di Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08768v1",
                "http://arxiv.org/pdf/2308.08768v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08767v1",
            "title": "Graph Neural Network Backend for Speaker Recognition",
            "updated": "2023-08-17T03:50:37Z",
            "published": "2023-08-17T03:50:37Z",
            "summary": "Currently, most speaker recognition backends, such as cosine, linear\ndiscriminant analysis (LDA), or probabilistic linear discriminant analysis\n(PLDA), make decisions by calculating similarity or distance between enrollment\nand test embeddings which are already extracted from neural networks. However,\nfor each embedding, the local structure of itself and its neighbor embeddings\nin the low-dimensional space is different, which may be helpful for the\nrecognition but is often ignored. In order to take advantage of it, we propose\na graph neural network (GNN) backend to mine latent relationships among\nembeddings for classification. We assume all the embeddings as nodes on a\ngraph, and their edges are computed based on some similarity function, such as\ncosine, LDA+cosine, or LDA+PLDA. We study different graph settings and explore\nvariants of GNN to find a better message passing and aggregation way to\naccomplish the recognition task. Experimental results on NIST SRE14 i-vector\nchallenging, VoxCeleb1-O, VoxCeleb1-E, and VoxCeleb1-H datasets demonstrate\nthat our proposed GNN backends significantly outperform current mainstream\nmethods.",
            "author": [
                "Liang He",
                "Ruida Li",
                "Mengqi Niu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08767v1",
                "http://arxiv.org/pdf/2308.08767v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.11645v2",
            "title": "Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using\n  EEG Data: A Dynamic Survival Analysis Framework with Competing Risks",
            "updated": "2023-12-01T03:32:25Z",
            "published": "2023-08-17T03:46:23Z",
            "summary": "Patients resuscitated from cardiac arrest who enter a coma are at high risk\nof death. Forecasting neurological outcomes of these patients (the task of\nneurological prognostication) could help with treatment decisions. In this\npaper, we propose, to the best of our knowledge, the first dynamic framework\nfor neurological prognostication of post-cardiac-arrest comatose patients using\nEEG data: our framework makes predictions for a patient over time as more EEG\ndata become available, and different training patients' available EEG time\nseries could vary in length. Predictions are phrased in terms of either\ntime-to-event outcomes (time-to-awakening or time-to-death) or as the patient's\nprobability of awakening or of dying across multiple time horizons. Our\nframework uses any dynamic survival analysis model that supports competing\nrisks in the form of estimating patient-level cumulative incidence functions.\nWe consider three competing risks as to what happens first to a patient:\nawakening, being withdrawn from life-sustaining therapies (and thus\ndeterministically dying), or dying (by other causes). We demonstrate our\nframework by benchmarking three existing dynamic survival analysis models that\nsupport competing risks on a real dataset of 922 patients. Our main\nexperimental findings are that: (1) the classical Fine and Gray model which\nonly uses a patient's static features and summary statistics from the patient's\nlatest hour's worth of EEG data is highly competitive, achieving accuracy\nscores as high as the recently developed Dynamic-DeepHit model that uses\nsubstantially more of the patient's EEG data; and (2) in an ablation study, we\nshow that our choice of modeling three competing risks results in a model that\nis at least as accurate while learning more information than simpler models\n(using two competing risks or a standard survival analysis setup with no\ncompeting risks).",
            "author": [
                "Xiaobin Shen",
                "Jonathan Elmer",
                "George H. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11645v2",
                "http://arxiv.org/pdf/2308.11645v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08763v1",
            "title": "Observational entropy with general quantum priors",
            "updated": "2023-08-17T03:32:42Z",
            "published": "2023-08-17T03:32:42Z",
            "summary": "Observational entropy captures both the intrinsic uncertainty of a\nthermodynamic state and the lack of knowledge due to coarse-graining. We\ndemonstrate two interpretations of observational entropy, one as the\nstatistical deficiency resulted from a measurement, the other one as the\ndifficulty to infer the input state from the measurement statistics by quantum\nBayesian retrodiction. These interpretations reveal that the observational\nentropy implicitly includes a uniform reference prior, from which we propose\nfully quantum generalizations by replacing the uniform prior by arbitrary\nquantum states. We propose three candidates for this generalization, discuss\ntheir properties, and show one of them gives a unified expression relating both\ninterpretations.",
            "author": [
                "Ge Bai",
                "Dominik \u0160afr\u00e1nek",
                "Joseph Schindler",
                "Francesco Buscemi",
                "Valerio Scarani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08763v1",
                "http://arxiv.org/pdf/2308.08763v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08752v1",
            "title": "Null controllability of two kinds of coupled parabolic systems with\n  switching control",
            "updated": "2023-08-17T03:02:54Z",
            "published": "2023-08-17T03:02:54Z",
            "summary": "The focus of this paper is on the null controllability of two kinds of\ncoupled systems including both degenerate and non-degenerate equations with\nswitching control. We first establish the observability inequality for\nmeasurable subsets in time for such coupled system, and then by the HUM method\nto obtain the null controllability. Next, we investigate the null\ncontrollability of such coupled system for segmented time intervals. Notably,\nthese results are obtained through spectral inequalities rather than using the\nmethod of Carleman estimates. Such coupled systems with switching control, to\nthe best of our knowledge, are among the first to discuss.",
            "author": [
                "Yuanhang Liu",
                "Weijia Wu",
                "Donghui Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08752v1",
                "http://arxiv.org/pdf/2308.08752v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "93B05, 93B07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08747v2",
            "title": "An Empirical Study of Catastrophic Forgetting in Large Language Models\n  During Continual Fine-tuning",
            "updated": "2023-08-21T08:18:24Z",
            "published": "2023-08-17T02:53:23Z",
            "summary": "Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning\nwhen a model forgets previously learned information as it learns new\ninformation. As large language models (LLMs) have shown excellent performance,\nit is interesting to uncover whether CF exists in the continual fine-tuning of\nLLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs'\nknowledge, from the perspectives of domain knowledge, reasoning, and reading\ncomprehension. The experiments demonstrate that catastrophic forgetting is\ngenerally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale\nincreases, the severity of forgetting also intensifies. Comparing the\ndecoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers\nless forgetting and maintains more knowledge. We also observe that LLMs can\nmitigate language bias (e.g. gender bias) during continual fine-tuning.\nMoreover, we find that ALPACA can maintain more knowledge and capacity compared\nwith LLAMA during the continual fine-tuning, which implies that general\ninstruction tuning can help mitigate the forgetting phenomenon of LLMs in the\nfurther fine-tuning process.",
            "author": [
                "Yun Luo",
                "Zhen Yang",
                "Fandong Meng",
                "Yafu Li",
                "Jie Zhou",
                "Yue Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08747v2",
                "http://arxiv.org/pdf/2308.08747v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08746v1",
            "title": "SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation",
            "updated": "2023-08-17T02:51:01Z",
            "published": "2023-08-17T02:51:01Z",
            "summary": "The Segment Anything Model (SAM) is a powerful foundation model that has\nrevolutionised image segmentation. To apply SAM to surgical instrument\nsegmentation, a common approach is to locate precise points or boxes of\ninstruments and then use them as prompts for SAM in a zero-shot manner.\nHowever, we observe two problems with this naive pipeline: (1) the domain gap\nbetween natural objects and surgical instruments leads to poor generalisation\nof SAM; and (2) SAM relies on precise point or box locations for accurate\nsegmentation, requiring either extensive manual guidance or a well-performing\nspecialist detector for prompt preparation, which leads to a complex\nmulti-stage pipeline. To address these problems, we introduce SurgicalSAM, a\nnovel end-to-end efficient-tuning approach for SAM to effectively integrate\nsurgical-specific information with SAM's pre-trained knowledge for improved\ngeneralisation. Specifically, we propose a lightweight prototype-based class\nprompt encoder for tuning, which directly generates prompt embeddings from\nclass prototypes and eliminates the use of explicit prompts for improved\nrobustness and a simpler pipeline. In addition, to address the low inter-class\nvariance among surgical instrument categories, we propose contrastive prototype\nlearning, further enhancing the discrimination of the class prototypes for more\naccurate class prompting. The results of extensive experiments on both\nEndoVis2018 and EndoVis2017 datasets demonstrate that SurgicalSAM achieves\nstate-of-the-art performance while only requiring a small number of tunable\nparameters. The source code will be released at\nhttps://github.com/wenxi-yue/SurgicalSAM.",
            "author": [
                "Wenxi Yue",
                "Jing Zhang",
                "Kun Hu",
                "Yong Xia",
                "Jiebo Luo",
                "Zhiyong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08746v1",
                "http://arxiv.org/pdf/2308.08746v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08742v2",
            "title": "PMET: Precise Model Editing in a Transformer",
            "updated": "2023-08-22T03:19:16Z",
            "published": "2023-08-17T02:33:43Z",
            "summary": "Model editing techniques modify a minor proportion of knowledge in Large\nLanguage Models (LLMs) at a relatively low cost, which have demonstrated\nnotable success. Existing methods assume Transformer Layer (TL) hidden states\nare values of key-value memories of the Feed-Forward Network (FFN). They\nusually optimize the TL hidden states to memorize target knowledge and use it\nto update the weights of the FFN in LLMs. However, the information flow of TL\nhidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN,\nand residual connections. Existing methods neglect the fact that the TL hidden\nstates contains information not specifically required for FFN. Consequently,\nthe performance of model editing decreases. To achieve more precise model\nediting, we analyze hidden states of MHSA and FFN, finding that MHSA encodes\ncertain general knowledge extraction patterns. This implies that MHSA weights\ndo not require updating when new knowledge is introduced. Based on above\nfindings, we introduce PMET, which simultaneously optimizes Transformer\nComponent (TC, namely MHSA and FFN) hidden states, while only using the\noptimized TC hidden states of FFN to precisely update FFN weights. Our\nexperiments demonstrate that PMET exhibits state-of-the-art performance on both\nthe COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the\neffectiveness of our enhancements, further reinforcing the finding that the\nMHSA encodes certain general knowledge extraction patterns and indicating its\nstorage of a small amount of factual knowledge. Our code is available at\nhttps://github.com/xpq-tech/PMET.git.",
            "author": [
                "Xiaopeng Li",
                "Shasha Li",
                "Shezheng Song",
                "Jing Yang",
                "Jun Ma",
                "Jie Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08742v2",
                "http://arxiv.org/pdf/2308.08742v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08733v1",
            "title": "A note on complementary knowledge spaces",
            "updated": "2023-08-17T02:09:17Z",
            "published": "2023-08-17T02:09:17Z",
            "summary": "The pair $(Q, \\mathscr{K})$ is a {\\it knowledge space} if\n$\\bigcup\\mathscr{K}=Q$ and $\\mathscr{K}$ is closed under union, where $Q$ is a\nnonempty set and $\\mathscr{K}$ is a family of subsets of $Q$. A knowledge space\n$(Q, \\mathscr{K})$ is called {\\it complementary} if there exists a non-discrete\nknowledge space $(Q, \\mathscr{L})$ such that the following (i) and (ii)\nsatisfy:\n  (i) for any $q\\in Q$, there are finitely many $K_{1}, \\cdots, K_{n}\\in\n\\mathscr{K}$ and $L_{1}, \\cdots, L_{m}\\in \\mathscr{L}$ such that\n$$(\\bigcap_{i=1}^{n}K_{i})\\cap (\\bigcap_{j=1}^{m}L_{j})=\\{q\\};$$ (ii)\n$\\mathscr{K}\\cap \\mathscr{L}=\\{\\emptyset, Q\\}$.\n  In this paper, the existence of a complementary knowledge space for each\nknowledge space is proved, and a method of the construction of complementary\nfinite knowledge spaces is given.",
            "author": [
                "Fucai Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08733v1",
                "http://arxiv.org/pdf/2308.08733v1"
            ],
            "primary_category": "math.GM",
            "category": [
                "math.GM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08731v1",
            "title": "Learning Through Guidance: Knowledge Distillation for Endoscopic Image\n  Classification",
            "updated": "2023-08-17T02:02:11Z",
            "published": "2023-08-17T02:02:11Z",
            "summary": "Endoscopy plays a major role in identifying any underlying abnormalities\nwithin the gastrointestinal (GI) tract. There are multiple GI tract diseases\nthat are life-threatening, such as precancerous lesions and other intestinal\ncancers. In the usual process, a diagnosis is made by a medical expert which\ncan be prone to human errors and the accuracy of the test is also entirely\ndependent on the expert's level of experience. Deep learning, specifically\nConvolution Neural Networks (CNNs) which are designed to perform automatic\nfeature learning without any prior feature engineering, has recently reported\ngreat benefits for GI endoscopy image analysis. Previous research has developed\nmodels that focus only on improving performance, as such, the majority of\nintroduced models contain complex deep network architectures with a large\nnumber of parameters that require longer training times. However, there is a\nlack of focus on developing lightweight models which can run in low-resource\nenvironments, which are typically encountered in medical clinics. We\ninvestigate three KD-based learning frameworks, response-based, feature-based,\nand relation-based mechanisms, and introduce a novel multi-head attention-based\nfeature fusion mechanism to support relation-based learning. Compared to the\nexisting relation-based methods that follow simplistic aggregation techniques\nof multi-teacher response/feature-based knowledge, we adopt the multi-head\nattention technique to provide flexibility towards localising and transferring\nimportant details from each teacher to better guide the student. We perform\nextensive evaluations on two widely used public datasets, KVASIR-V2 and\nHyper-KVASIR, and our experimental results signify the merits of our proposed\nrelation-based framework in achieving an improved lightweight model (only 51.8k\ntrainable parameters) that can run in a resource-limited environment.",
            "author": [
                "Harshala Gammulle",
                "Yubo Chen",
                "Sridha Sridharan",
                "Travis Klein",
                "Clinton Fookes"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08731v1",
                "http://arxiv.org/pdf/2308.08731v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08728v1",
            "title": "LLM-FuncMapper: Function Identification for Interpreting Complex Clauses\n  in Building Codes via LLM",
            "updated": "2023-08-17T01:58:04Z",
            "published": "2023-08-17T01:58:04Z",
            "summary": "As a vital stage of automated rule checking (ARC), rule interpretation of\nregulatory texts requires considerable effort. However, interpreting regulatory\nclauses with implicit properties or complex computational logic is still\nchallenging due to the lack of domain knowledge and limited expressibility of\nconventional logic representations. Thus, LLM-FuncMapper, an approach to\nidentifying predefined functions needed to interpret various regulatory clauses\nbased on the large language model (LLM), is proposed. First, by systematically\nanalysis of building codes, a series of atomic functions are defined to capture\nshared computational logics of implicit properties and complex constraints,\ncreating a database of common blocks for interpreting regulatory clauses. Then,\na prompt template with the chain of thought is developed and further enhanced\nwith a classification-based tuning strategy, to enable common LLMs for\neffective function identification. Finally, the proposed approach is validated\nwith statistical analysis, experiments, and proof of concept. Statistical\nanalysis reveals a long-tail distribution and high expressibility of the\ndeveloped function database, with which almost 100% of computer-processible\nclauses can be interpreted and represented as computer-executable codes.\nExperiments show that LLM-FuncMapper achieve promising results in identifying\nrelevant predefined functions for rule interpretation. Further proof of concept\nin automated rule interpretation also demonstrates the possibility of\nLLM-FuncMapper in interpreting complex regulatory clauses. To the best of our\nknowledge, this study is the first attempt to introduce LLM for understanding\nand interpreting complex regulatory clauses, which may shed light on further\nadoption of LLM in the construction domain.",
            "author": [
                "Zhe Zheng",
                "Ke-Yin Chen",
                "Xin-Yu Cao",
                "Xin-Zheng Lu",
                "Jia-Rui Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08728v1",
                "http://arxiv.org/pdf/2308.08728v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08702v1",
            "title": "Finding a Second Wind: Speeding Up Graph Traversal Queries in RDBMSs\n  Using Column-Oriented Processing",
            "updated": "2023-08-16T23:17:20Z",
            "published": "2023-08-16T23:17:20Z",
            "summary": "Recursive queries and recursive derived tables constitute an important part\nof the SQL standard. Their efficient processing is important for many real-life\napplications that rely on graph or hierarchy traversal. Position-enabled\ncolumn-stores offer a novel opportunity to improve run times for this type of\nqueries. Such systems allow the engine to explicitly use data positions (row\nids) inside its core and thus, enable novel efficient implementations of query\nplan operators.\n  In this paper, we present an approach that significantly speeds up recursive\nquery processing inside RDBMSes. Its core idea is to employ a particular aspect\nof column-store technology (late materialization) which enables the query\nengine to manipulate data positions during query execution. Based on it, we\npropose two sets of Volcano-style operators intended to process different query\ncases.\n  In order validate our ideas, we have implemented the proposed approach in\nPosDB, an RDBMS column-store with SQL support. We experimentally demonstrate\nthe viability of our approach by providing a comparison with PostgreSQL.\nExperiments show that for breadth-first search: 1) our position-based approach\nyields up to 6x better results than PostgreSQL, 2) our tuple-based one results\nin only 3x improvement when using a special rewriting technique, but it can\nwork in a larger number of cases, and 3) both approaches can't be emulated in\nrow-stores efficiently.",
            "author": [
                "Mikhail Firsov",
                "Michael Polyntsov",
                "Kirill Smirnov",
                "George Chernishev"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08702v1",
                "http://arxiv.org/pdf/2308.08702v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.PF",
                "H.2.4; E.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08694v2",
            "title": "Bounds for Characters of the Symmetric Group: A Hypercontractive\n  Approach",
            "updated": "2023-09-29T14:53:37Z",
            "published": "2023-08-16T22:48:00Z",
            "summary": "Finding upper bounds for character ratios is a fundamental problem in\nasymptotic group theory. Previous bounds in the symmetric group have led to\nremarkable applications in unexpected domains. The existing approaches\npredominantly relied on algebraic methods, whereas our approach combines\nanalytic and algebraic tools. Specifically, we make use of a tool called\n`hypercontractivity for global functions' from the theory of Boolean functions.\nBy establishing sharp upper bounds on the $L^p$-norms of characters of the\nsymmetric group, we improve existing results on character ratios from the work\nof Larsen and Shalev [Larsen M., Shalev A. Characters of the symmetric group:\nsharp bounds and applications. Invent. math. 174 645-687 (2008)]. We use our\nnorm bounds to bound Kronecker coefficients, Fourier coefficients of class\nfunctions, product mixing of normal sets, and mixing time of normal Cayley\ngraphs. Our approach bypasses the need for the $S_n$-specific\nMurnaghan--Nakayama rule. Instead we leverage more flexible representation\ntheoretic tools, such as Young's branching rule, which potentially extend the\napplicability of our method to groups beyond $S_n$.",
            "author": [
                "Noam Lifshitz",
                "Avichai Marmor"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08694v2",
                "http://arxiv.org/pdf/2308.08694v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.FA",
                "math.GR",
                "math.PR",
                "math.RT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08690v1",
            "title": "Improved Approximation Algorithms for Steiner Connectivity Augmentation\n  Problems",
            "updated": "2023-08-16T22:25:11Z",
            "published": "2023-08-16T22:25:11Z",
            "summary": "The Weighted Connectivity Augmentation Problem is the problem of augmenting\nthe edge-connectivity of a given graph by adding links of minimum total cost.\nThis work focuses on connectivity augmentation problems in the Steiner setting,\nwhere we are not interested in the connectivity between all nodes of the graph,\nbut only the connectivity between a specified subset of terminals.\n  We consider two related settings. In the Steiner Augmentation of a Graph\nproblem ($k$-SAG), we are given a $k$-edge-connected subgraph $H$ of a graph\n$G$. The goal is to augment $H$ by including links and nodes from $G$ of\nminimum cost so that the edge-connectivity between nodes of $H$ increases by 1.\nIn the Steiner Connectivity Augmentation Problem ($k$-SCAP), we are given a\nSteiner $k$-edge-connected graph connecting terminals $R$, and we seek to add\nlinks of minimum cost to create a Steiner $(k+1)$-edge-connected graph for $R$.\nNote that $k$-SAG is a special case of $k$-SCAP.\n  All of the above problems can be approximated to within a factor of 2 using\ne.g. Jain's iterative rounding algorithm for Survivable Network Design. In this\nwork, we leverage the framework of Traub and Zenklusen to give a $(1 + \\ln{2}\n+\\varepsilon)$-approximation for the Steiner Ring Augmentation Problem (SRAP):\ngiven a cycle $H = (V(H),E)$ embedded in a larger graph $G = (V, E \\cup L)$ and\na subset of terminals $R \\subseteq V(H)$, choose a subset of links $S \\subseteq\nL$ of minimum cost so that $(V, E \\cup S)$ has 3 pairwise edge-disjoint paths\nbetween every pair of terminals.\n  We show this yields a polynomial time algorithm with approximation ratio $(1\n+ \\ln{2} + \\varepsilon)$ for $2$-SCAP. We obtain an improved approximation\nguarantee of $(1.5+\\varepsilon)$ for SRAP in the case that $R = V(H)$, which\nyields a $(1.5+\\varepsilon)$-approximation for $k$-SAG for any $k$.",
            "author": [
                "Daniel Hathcock",
                "Michael Zlatin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08690v1",
                "http://arxiv.org/pdf/2308.08690v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08674v1",
            "title": "Approximating Min-Diameter: Standard and Bichromatic",
            "updated": "2023-08-16T20:58:43Z",
            "published": "2023-08-16T20:58:43Z",
            "summary": "The min-diameter of a directed graph $G$ is a measure of the largest distance\nbetween nodes. It is equal to the maximum min-distance $d_{min}(u,v)$ across\nall pairs $u,v \\in V(G)$, where $d_{min}(u,v) = \\min(d(u,v), d(v,u))$. Our work\nprovides a $O(m^{1.426}n^{0.288})$-time $3/2$-approximation algorithm for\nmin-diameter in DAGs, and a faster $O(m^{0.713}n)$-time\nalmost-$3/2$-approximation variant. (An almost-$\\alpha$-approximation algorithm\ndetermines the min-diameter to within a multiplicative factor of $\\alpha$ plus\nconstant additive error.) By a conditional lower bound result of [Abboud et al,\nSODA 2016], a better than $3/2$-approximation can't be achieved in truly\nsubquadratic time under the Strong Exponential Time Hypothesis (SETH), so our\nresult is conditionally tight. We additionally obtain a new conditional lower\nbound for min-diameter approximation in general directed graphs, showing that\nunder SETH, one cannot achieve an approximation factor below 2 in truly\nsubquadratic time. We also present the first study of approximating bichromatic\nmin-diameter, which is the maximum min-distance between oppositely colored\nvertices in a 2-colored graph.",
            "author": [
                "Aaron Berger",
                "Jenny Kaufmann",
                "Virginia Vassilevska Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08674v1",
                "http://arxiv.org/pdf/2308.08674v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08670v2",
            "title": "Improved Approximation Bounds for Minimum Weight Cycle in the CONGEST\n  Model",
            "updated": "2023-11-06T18:05:48Z",
            "published": "2023-08-16T20:41:53Z",
            "summary": "Minimum Weight Cycle (MWC) is the problem of finding a simple cycle of\nminimum weight in a graph $G=(V,E)$. This is a fundamental graph problem with\nclassical sequential algorithms that run in $\\tilde{O}(n^3)$ and\n$\\tilde{O}(mn)$ time where $n=|V|$ and $m=|E|$. In recent years this problem\nhas received significant attention in the context of hardness through fine\ngrained sequential complexity as well as in design of faster sequential\napproximation algorithms.\n  For computing minimum weight cycle in the distributed CONGEST model,\nnear-linear in $n$ lower and upper bounds on round complexity are known for\ndirected graphs (weighted and unweighted), and for undirected weighted graphs;\nthese lower bounds also apply to any $(2-\\epsilon)$-approximation algorithm.\nThis paper focuses on round complexity bounds for approximating MWC in the\nCONGEST model: For coarse approximations we show that for any constant $\\alpha\n>1$, computing an $\\alpha$-approximation of MWC requires $\\Omega (\\frac{\\sqrt\nn}{\\log n})$ rounds on weighted undirected graphs and on directed graphs, even\nif unweighted.\n  We complement these lower bounds with a sublinear\n$\\tilde{O}(n^{2/3}+D)$-round algorithm to compute a\n$(2+\\epsilon)$-approximation of undirected weighted MWC. We also give a\n$\\tilde{O}(n^{4/5}+D)$-round algorithm to compute 2-approximate directed\nunweighted MWC and $(2+\\epsilon)$-approximate directed weighted MWC. To obtain\nthe sublinear round bounds, we design an efficient algorithm for computing\n$(1+\\epsilon)$-approximate shortest paths from $k$ sources in directed and\nweighted graphs, which is of independent interest. We present an algorithm that\nruns in $\\tilde{O}(\\sqrt{nk} + D)$ rounds if $k \\ge n^{1/3}$ and\n$\\tilde{O}(\\sqrt{nk} + k^{2/5}n^{2/5+o(1)}D^{2/5} + D)$ rounds if $k<n^{1/3}$,\nwhich smoothly interpolates between the best known upper bounds for SSSP when\n$k=1$ and APSP when $k=n$.",
            "author": [
                "Vignesh Manoharan",
                "Vijaya Ramachandran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08670v2",
                "http://arxiv.org/pdf/2308.08670v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08669v1",
            "title": "SkinDistilViT: Lightweight Vision Transformer for Skin Lesion\n  Classification",
            "updated": "2023-08-16T20:39:06Z",
            "published": "2023-08-16T20:39:06Z",
            "summary": "Skin cancer is a treatable disease if discovered early. We provide a\nproduction-specific solution to the skin cancer classification problem that\nmatches human performance in melanoma identification by training a vision\ntransformer on melanoma medical images annotated by experts. Since inference\ncost, both time and memory wise is important in practice, we employ knowledge\ndistillation to obtain a model that retains 98.33% of the teacher's balanced\nmulti-class accuracy, at a fraction of the cost. Memory-wise, our model is\n49.60% smaller than the teacher. Time-wise, our solution is 69.25% faster on\nGPU and 97.96% faster on CPU. By adding classification heads at each level of\nthe transformer and employing a cascading distillation process, we improve the\nbalanced multi-class accuracy of the base model by 2.1%, while creating a range\nof models of various sizes but comparable performance. We provide the code at\nhttps://github.com/Longman-Stan/SkinDistilVit.",
            "author": [
                "Vlad-Constantin Lungu-Stan",
                "Dumitru-Clementin Cercel",
                "Florin Pop"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08669v1",
                "http://arxiv.org/pdf/2308.08669v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08666v1",
            "title": "BREATHE: Second-Order Gradients and Heteroscedastic Emulation based\n  Design Space Exploration",
            "updated": "2023-08-16T20:33:57Z",
            "published": "2023-08-16T20:33:57Z",
            "summary": "Researchers constantly strive to explore larger and more complex search\nspaces in various scientific studies and physical experiments. However, such\ninvestigations often involve sophisticated simulators or time-consuming\nexperiments that make exploring and observing new design samples challenging.\nPrevious works that target such applications are typically sample-inefficient\nand restricted to vector search spaces. To address these limitations, this work\nproposes a constrained multi-objective optimization (MOO) framework, called\nBREATHE, that searches not only traditional vector-based design spaces but also\ngraph-based design spaces to obtain best-performing graphs. It leverages\nsecond-order gradients and actively trains a heteroscedastic surrogate model\nfor sample-efficient optimization. In a single-objective vector optimization\napplication, it leads to 64.1% higher performance than the next-best baseline,\nrandom forest regression. In graph-based search, BREATHE outperforms the\nnext-best baseline, i.e., a graphical version of Gaussian-process-based\nBayesian optimization, with up to 64.9% higher performance. In a MOO task, it\nachieves up to 21.9$\\times$ higher hypervolume than the state-of-the-art\nmethod, multi-objective Bayesian optimization (MOBOpt). BREATHE also\noutperforms the baseline methods on most standard MOO benchmark applications.",
            "author": [
                "Shikhar Tuli",
                "Niraj K. Jha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08666v1",
                "http://arxiv.org/pdf/2308.08666v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08646v2",
            "title": "Global and local CLTs for linear spectral statistics of general sample\n  covariance matrices when the dimension is much larger than the sample size\n  with applications",
            "updated": "2023-08-21T01:08:49Z",
            "published": "2023-08-16T19:45:19Z",
            "summary": "In this paper, under the assumption that the dimension is much larger than\nthe sample size, i.e., $p \\asymp n^{\\alpha}, \\alpha>1,$ we consider the\n(unnormalized) sample covariance matrices $Q = \\Sigma^{1/2} XX^*\\Sigma^{1/2}$,\nwhere $X=(x_{ij})$ is a $p \\times n$ random matrix with centered i.i.d entries\nwhose variances are $(pn)^{-1/2}$, and $\\Sigma$ is the deterministic population\ncovariance matrix. We establish two classes of central limit theorems (CLTs)\nfor the linear spectral statistics (LSS) for $Q,$ the global CLTs on the\nmacroscopic scales and the local CLTs on the mesoscopic scales. We prove that\nthe LSS converge to some Gaussian processes whose mean and covariance functions\ndepending on $\\Sigma$, the ratio $p/n$ and the test functions, can be\nidentified explicitly on both macroscopic and mesoscopic scales. We also show\nthat even though the global CLTs depend on the fourth cumulant of $x_{ij},$ the\nlocal CLTs do not. Based on these results, we propose two classes of statistics\nfor testing the structures of $\\Sigma,$ the global statistics and the local\nstatistics, and analyze their superior power under general local alternatives.\nTo our best knowledge, the local LSS testing statistics which do not rely on\nthe fourth moment of $x_{ij},$ is used for the first time in hypothesis testing\nwhile the literature mostly uses the global statistics and requires the prior\nknowledge of the fourth cumulant. Numerical simulations also confirm the\naccuracy and powerfulness of our proposed statistics and illustrate better\nperformance compared to the existing methods in the literature.",
            "author": [
                "Xiucai Ding",
                "Zhenggang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08646v2",
                "http://arxiv.org/pdf/2308.08646v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08640v1",
            "title": "Non-Rigid Designators in Epistemic and Temporal Free Description Logics\n  (Extended Version)",
            "updated": "2023-08-16T19:27:47Z",
            "published": "2023-08-16T19:27:47Z",
            "summary": "Definite descriptions, such as 'the smallest planet in the Solar System',\nhave been recently recognised as semantically transparent devices for object\nidentification in knowledge representation formalisms. Along with individual\nnames, they have been introduced also in the context of description logic\nlanguages, enriching the expressivity of standard nominal constructors.\nMoreover, in the first-order modal logic literature, definite descriptions have\nbeen widely investigated for their non-rigid behaviour, which allows them to\ndenote different objects at different states. In this direction, we introduce\nepistemic and temporal extensions of standard description logics, with nominals\nand the universal role, additionally equipped with definite descriptions\nconstructors. Regarding names and descriptions, in these languages we allow\nfor: possible lack of denotation, ensured by partial models, coming from free\nlogic semantics as a generalisation of the classical ones; and non-rigid\ndesignation features, obtained by assigning to terms distinct values across\nstates, as opposed to the standard rigidity condition on individual\nexpressions. In the absence of the rigid designator assumption, we show that\nthe satisfiability problem for epistemic free description logics is\nNExpTime-complete, while satisfiability for temporal free description logics\nover linear time structures is undecidable.",
            "author": [
                "Alessandro Artale",
                "Andrea Mazzullo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08640v1",
                "http://arxiv.org/pdf/2308.08640v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08628v1",
            "title": "Learning the meanings of function words from grounded language using a\n  visual question answering model",
            "updated": "2023-08-16T18:53:39Z",
            "published": "2023-08-16T18:53:39Z",
            "summary": "Interpreting a seemingly-simple function word like \"or\", \"behind\", or \"more\"\ncan require logical, numerical, and relational reasoning. How are such words\nlearned by children? Prior acquisition theories have often relied on positing a\nfoundation of innate knowledge. Yet recent neural-network based visual question\nanswering models apparently can learn to use function words as part of\nanswering questions about complex visual scenes. In this paper, we study what\nthese models learn about function words, in the hope of better understanding\nhow the meanings of these words can be learnt by both models and children. We\nshow that recurrent models trained on visually grounded language learn gradient\nsemantics for function words requiring spacial and numerical reasoning.\nFurthermore, we find that these models can learn the meanings of logical\nconnectives \"and\" and \"or\" without any prior knowledge of logical reasoning, as\nwell as early evidence that they can develop the ability to reason about\nalternative expressions when interpreting language. Finally, we show that word\nlearning difficulty is dependent on frequency in models' input. Our findings\noffer evidence that it is possible to learn the meanings of function words in\nvisually grounded context by using non-symbolic general statistical learning\nalgorithms, without any prior knowledge of linguistic meaning.",
            "author": [
                "Eva Portelance",
                "Michael C. Frank",
                "Dan Jurafsky"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08628v1",
                "http://arxiv.org/pdf/2308.08628v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7; I.2.6; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08620v1",
            "title": "Group Identification via Transitional Hypergraph Convolution with\n  Cross-view Self-supervised Learning",
            "updated": "2023-08-16T18:24:54Z",
            "published": "2023-08-16T18:24:54Z",
            "summary": "With the proliferation of social media, a growing number of users search for\nand join group activities in their daily life. This develops a need for the\nstudy on the group identification (GI) task, i.e., recommending groups to\nusers. The major challenge in this task is how to predict users' preferences\nfor groups based on not only previous group participation of users but also\nusers' interests in items. Although recent developments in Graph Neural\nNetworks (GNNs) accomplish embedding multiple types of objects in graph-based\nrecommender systems, they, however, fail to address this GI problem\ncomprehensively. In this paper, we propose a novel framework named Group\nIdentification via Transitional Hypergraph Convolution with Graph\nSelf-supervised Learning (GTGS). We devise a novel transitional hypergraph\nconvolution layer to leverage users' preferences for items as prior knowledge\nwhen seeking their group preferences. To construct comprehensive user/group\nrepresentations for GI task, we design the cross-view self-supervised learning\nto encourage the intrinsic consistency between item and group preferences for\neach user, and the group-based regularization to enhance the distinction among\ngroup embeddings. Experimental results on three benchmark datasets verify the\nsuperiority of GTGS. Additional detailed investigations are conducted to\ndemonstrate the effectiveness of the proposed framework.",
            "author": [
                "Mingdai Yang",
                "Zhiwei Liu",
                "Liangwei Yang",
                "Xiaolong Liu",
                "Chen Wang",
                "Hao Peng",
                "Philip S. Yu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614902",
                "http://arxiv.org/abs/2308.08620v1",
                "http://arxiv.org/pdf/2308.08620v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08614v1",
            "title": "Boosting Logical Reasoning in Large Language Models through a New\n  Framework: The Graph of Thought",
            "updated": "2023-08-16T18:13:27Z",
            "published": "2023-08-16T18:13:27Z",
            "summary": "Recent advancements in large-scale models, such as GPT-4, have showcased\nremarkable capabilities in addressing standard queries. However, when facing\ncomplex problems that require multi-step logical reasoning, their accuracy\ndramatically decreases. Current research has explored the realm of\n\\textit{prompting engineering} to bolster the inferential capacities of these\nmodels. Our paper unveils a pioneering prompting technique, dubbed\n\\textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating\nchallenges: the 24-point game, resolution of high-degree polynomial equations,\nand derivation of formulas for recursive sequences, our method outperformed\nGPT-4, achieving accuracy improvements of $89.7\\%$, $86\\%$, and $56\\%$ for each\nrespective task. Moreover, when juxtaposed with the state-of-the-art (SOTA)\nprompting method, \\textit{Tree of Thought (ToT)}, our approach registered an\naverage accuracy boost of $23\\%$, $24\\%$, and $15\\%$.",
            "author": [
                "Bin Lei",
                "pei-Hung Lin",
                "Chunhua Liao",
                "Caiwen Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08614v1",
                "http://arxiv.org/pdf/2308.08614v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08611v1",
            "title": "Integrating Renewable Energy in Agriculture: A Deep Reinforcement\n  Learning-based Approach",
            "updated": "2023-08-16T18:03:33Z",
            "published": "2023-08-16T18:03:33Z",
            "summary": "This article investigates the use of Deep Q-Networks (DQNs) to optimize\ndecision-making for photovoltaic (PV) systems installations in the agriculture\nsector. The study develops a DQN framework to assist agricultural investors in\nmaking informed decisions considering factors such as installation budget,\ngovernment incentives, energy requirements, system cost, and long-term\nbenefits. By implementing a reward mechanism, the DQN learns to make\ndata-driven decisions on PV integration. The analysis provides a comprehensive\nunderstanding of how DQNs can support investors in making decisions about PV\ninstallations in agriculture. This research has significant implications for\npromoting sustainable and efficient farming practices while also paving the way\nfor future advancements in this field. By leveraging DQNs, agricultural\ninvestors can make optimized decisions that improve energy efficiency, reduce\nenvironmental impact, and enhance profitability. This study contributes to the\nadvancement of PV integration in agriculture and encourages further innovation\nin this promising area.",
            "author": [
                "A. Wahid",
                "I faiud",
                "K. Mason"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08611v1",
                "http://arxiv.org/pdf/2308.08611v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08609v1",
            "title": "Pair density wave superconductivity: a microscopic model in two\n  dimensions",
            "updated": "2023-08-16T18:03:02Z",
            "published": "2023-08-16T18:03:02Z",
            "summary": "Pair-density-wave (PDW) superconductivity is a long-sought exotic state with\noscillating superconducting order parameter without the need of applying\nexternal magnetic field. So far it has been rare in establishing a\ntwo-dimensional (2D) microscopic model with such exotic long-range order in its\nground state. Here we propose to study PDW superconductivity in a minimal model\nof spinless fermions on the honeycomb lattice with nearest-neighbor (NN) and\nnext-nearest-neighbor (NNN) interaction $V_1$ and $V_2$, respectively. By\nperforming a state-of-the-art density-matrix renormalization group (DMRG) study\nof this $t$-$V_1$-$V_2$ model at finite doping on six-leg and eight-leg\nhoneycomb cylinders, we showed that the ground state exhibits PDW ordering\n(namely quasi-long-range order with a divergent PDW susceptibility). Remarkably\nthis PDW state persists on the wider cylinder with 2D-like Fermi surfaces (FS).\nTo the best of our knowledge, this is probably the first controlled numerical\nevidence of PDW in systems with 2D-like FS.",
            "author": [
                "Yi-Fan Jiang",
                "Hong Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08609v1",
                "http://arxiv.org/pdf/2308.08609v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08604v1",
            "title": "A study of $v$-number for some monomial ideals",
            "updated": "2023-08-16T18:00:49Z",
            "published": "2023-08-16T18:00:49Z",
            "summary": "In this paper, we give formulas for $v$-number of edge ideals of some graphs\nlike path, cycle, 1-clique sum of a path and a cycle, 1-clique sum of two\ncycles and join of two graphs. For an $\\mathfrak{m}$-primary monomial ideal\n$I\\subset S=K[x_1,\\ldots,x_t]$, we provide an explicit expression of $v$-number\nof $I$, denoted by $v(I)$, and give an upper bound of $v(I)$ in terms of the\ndegree of its generators. We show that for a monomial ideal $I$, $v(I^{n+1})$\nis bounded above by a linear polynomial for large $n$ and for certain classes\nof monomial ideals, the upper bound is achieved for all $n\\geq 1$. For\n$\\mathfrak m$-primary monomial ideal $I$ we prove that $v(I)\\leq$ reg$(S/I)$\nand their difference can be arbitrarily large.",
            "author": [
                "Prativa Biswas",
                "Mousumi Mandal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08604v1",
                "http://arxiv.org/pdf/2308.08604v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "05E40, 13F20, 13F55, 05C38, 05C69"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08510v1",
            "title": "Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater",
            "updated": "2023-08-16T17:07:37Z",
            "published": "2023-08-16T17:07:37Z",
            "summary": "Robots play a critical role as the physical agent of human operators in\nexploring the ocean. However, it remains challenging to grasp objects reliably\nwhile fully submerging under a highly pressurized aquatic environment with\nlittle visible light, mainly due to the fluidic interference on the tactile\nmechanics between the finger and object surfaces. This study investigates the\ntransferability of grasping knowledge from on-land to underwater via a\nvision-based soft robotic finger that learns 6D forces and torques (FT) using a\nSupervised Variational Autoencoder (SVAE). A high-framerate camera captures the\nwhole-body deformations while a soft robotic finger interacts with physical\nobjects on-land and underwater. Results show that the trained SVAE model\nlearned a series of latent representations of the soft mechanics transferrable\nfrom land to water, presenting a superior adaptation to the changing\nenvironments against commercial FT sensors. Soft, delicate, and reactive\ngrasping enabled by tactile intelligence enhances the gripper's underwater\ninteraction with improved reliability and robustness at a much-reduced cost,\npaving the path for learning-based intelligent grasping to support fundamental\nscientific discoveries in environmental and ocean research.",
            "author": [
                "Ning Guo",
                "Xudong Han",
                "Xiaobo Liu",
                "Shuqiao Zhong",
                "Zhiyuan Zhou",
                "Jian Lin",
                "Jiansheng Dai",
                "Fang Wan",
                "Chaoyang Song"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08510v1",
                "http://arxiv.org/pdf/2308.08510v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08475v1",
            "title": "Data Navigator: An accessibility-centered data navigation toolkit",
            "updated": "2023-08-16T16:28:36Z",
            "published": "2023-08-16T16:28:36Z",
            "summary": "Making data visualizations accessible for people with disabilities remains a\nsignificant challenge in current practitioner efforts. Existing visualizations\noften lack an underlying navigable structure, fail to engage necessary input\nmodalities, and rely heavily on visual-only rendering practices. These\nlimitations exclude people with disabilities, especially users of assistive\ntechnologies. To address these challenges, we present Data Navigator: a system\nbuilt on a dynamic graph structure, enabling developers to construct navigable\nlists, trees, graphs, and flows as well as spatial, diagrammatic, and\ngeographic relations. Data Navigator supports a wide range of input modalities:\nscreen reader, keyboard, speech, gesture detection, and even fabricated\nassistive devices. We present 3 case examples with Data Navigator,\ndemonstrating we can provide accessible navigation structures on top of raster\nimages, integrate with existing toolkits at scale, and rapidly develop novel\nprototypes. Data Navigator is a step towards making accessible data\nvisualizations easier to design and implement.",
            "author": [
                "Frank Elavsky",
                "Lucas Nadolskis",
                "Dominik Moritz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08475v1",
                "http://arxiv.org/pdf/2308.08475v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08469v3",
            "title": "LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with\n  Pre-Trained LLMs",
            "updated": "2023-10-12T09:58:03Z",
            "published": "2023-08-16T16:19:50Z",
            "summary": "In this work, we leverage pre-trained Large Language Models (LLMs) to enhance\ntime-series forecasting. Mirroring the growing interest in unifying models for\nNatural Language Processing and Computer Vision, we envision creating an\nanalogous model for long-term time-series forecasting. Due to limited\nlarge-scale time-series data for building robust foundation models, our\napproach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By\ncombining time-series patching with temporal encoding, we have enhanced the\ncapability of LLMs to handle time-series data effectively. Inspired by the\nsupervised fine-tuning in chatbot domains, we prioritize a two-stage\nfine-tuning process: first conducting supervised fine-tuning to orient the LLM\ntowards time-series data, followed by task-specific downstream fine-tuning.\nFurthermore, to unlock the flexibility of pre-trained LLMs without extensive\nparameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT)\ntechniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art\nresults in long-term forecasting. Our model has also shown exceptional\ncapabilities as both a robust representation learner and an effective few-shot\nlearner, thanks to the knowledge transferred from the pre-trained LLM.",
            "author": [
                "Ching Chang",
                "Wen-Chih Peng",
                "Tien-Fu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08469v3",
                "http://arxiv.org/pdf/2308.08469v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08466v2",
            "title": "Graphing methods for Kendall's \u03c4",
            "updated": "2023-09-01T08:55:11Z",
            "published": "2023-08-16T16:13:47Z",
            "summary": "Ranked data is commonly used in research across many fields of study\nincluding medicine, biology, psychology, and economics. One common statistic\nused for analyzing ranked data is Kendall's {\\tau} coefficient, a\nnon-parametric measure of rank correlation which describes the strength of the\nassociation between two monotonic continuous or ordinal variables. While the\nmathematics involved in calculating Kendall's {\\tau} is well-established, there\nare relatively few graphing methods available to visualize the results. Here,\nwe describe a visualization method and provide an interactive app for graphing\nKendall's {\\tau} which uses a series of rigid Euclidean transformations along a\nCartesian plane to map rank pairs into discrete quadrants. The resulting graph\nprovides a visualization of rank correlation which helps display the proportion\nof concordant and discordant pairs. Moreover, this method highlights other key\nfeatures of the data which are not represented by Kendall's {\\tau} alone but\nmay nevertheless be meaningful, such as the relationship between discrete pairs\nof observations. We demonstrate the effectiveness of our approach through\nseveral examples and compare our results to other visualization methods.",
            "author": [
                "Nicholas D. Edwards",
                "Enzo de Jong",
                "Stephen T. Ferguson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08466v2",
                "http://arxiv.org/pdf/2308.08466v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08457v1",
            "title": "A New Magneto-Micropolar Boundary Layer Model for Liquid Flows -- Effect\n  of Micromagnetorotation (MMR)",
            "updated": "2023-08-16T16:03:40Z",
            "published": "2023-08-16T16:03:40Z",
            "summary": "In this paper, we present a micropolar continuum model based on the theory of\nmagnetohydrodynamics. In particular, the effect of micromagnetorotation (MMR)\nis taken into account in the derivation of an initial-boundary value problem\n(i-bvp) within magneto-micorpolar flows. MMR is a phenomenon that is related to\nthe micromotions of the magnetic liquid particles in the presence of externally\napplied magnetic field. In all previous investigations magnetization was\nsupposed to be parallel to applied magnetic field therefore its effect in the\nlateral direction is neglected. This assumption is not correct in\nmagnetic-micropolar flows. Since, magnetic-micropolar flows are anisotropic in\nnature. Here, we present a model accounting for this MMR effect. The\nconstitutive equation for the MMR is described and the governing system of flow\ndynamics is described in the form of PDEs. Boundary layer flow assumptions are\nused to derive an initial-boundary value problem in ODEs. As a consequence, two\nnewly defined parameters arises that are related to the MMR. The effects of\nthese parameters on the flow characteristics are investigated. The developed\ni-bvp is solved through the shooting method using MATLAB routines. Effects of\nMMR are analyzed on the miro-rotational and hydrodynamic velocities profiles.\nSome interesting features of the flow are observed. Results are presented\nthrough graphs and discussed in detail. It is worth mentioning that the model\npresented is first of its kind in the literature and has a great potential in\ninvestigating boundary layer flows within micropolar continuum with other\nphysical aspects of the flow pertinent to engineering and biomedical\napplications.",
            "author": [
                "Muhammad Sabeel Khan",
                "Isma Hameed"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08457v1",
                "http://arxiv.org/pdf/2308.08457v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math-ph",
                "math.MP",
                "math.NA",
                "76D10, 76M55",
                "J.2; I.6.3; G.1.7; G.1.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08423v1",
            "title": "Multiplicative deconvolution under unknown error distribution",
            "updated": "2023-08-16T15:11:34Z",
            "published": "2023-08-16T15:11:34Z",
            "summary": "We consider a multiplicative deconvolution problem, in which the density $f$\nor the survival function $S^X$ of a strictly positive random variable $X$ is\nestimated nonparametrically based on an i.i.d. sample from a noisy observation\n$Y = X\\cdot U$ of $X$. The multiplicative measurement error $U$ is supposed to\nbe independent of $X$. The objective of this work is to construct a fully\ndata-driven estimation procedure when the error density $f^U$ is unknown. We\nassume that in addition to the i.i.d. sample from $Y$, we have at our disposal\nan additional i.i.d. sample drawn independently from the error distribution.\nThe proposed estimation procedure combines the estimation of the Mellin\ntransformation of the density $f$ and a regularisation of the inverse of the\nMellin transform by a spectral cut-off. The derived risk bounds and oracle-type\ninequalities cover both - the estimation of the density $f$ as well as the\nsurvival function $S^X$. The main issue addressed in this work is the\ndata-driven choice of the cut-off parameter using a model selection approach.\nWe discuss conditions under which the fully data-driven estimator can attain\nthe oracle-risk up to a constant without any previous knowledge of the error\ndistribution. We compute convergences rates under classical smoothness\nassumptions. We illustrate the estimation strategy by a simulation study with\ndifferent choices of distributions.",
            "author": [
                "Sergio Brenner Miguel",
                "Jan Johannes",
                "Maximilian Siebel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08423v1",
                "http://arxiv.org/pdf/2308.08423v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08414v1",
            "title": "Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer",
            "updated": "2023-08-16T15:00:50Z",
            "published": "2023-08-16T15:00:50Z",
            "summary": "Video-language pre-trained models have shown remarkable success in guiding\nvideo question-answering (VideoQA) tasks. However, due to the length of video\nsequences, training large-scale video-based models incurs considerably higher\ncosts than training image-based ones. This motivates us to leverage the\nknowledge from image-based pretraining, despite the obvious gaps between image\nand video domains. To bridge these gaps, in this paper, we propose Tem-Adapter,\nwhich enables the learning of temporal dynamics and complex semantics by a\nvisual Temporal Aligner and a textual Semantic Aligner. Unlike conventional\npretrained knowledge adaptation methods that only concentrate on the downstream\ntask objective, the Temporal Aligner introduces an extra language-guided\nautoregressive task aimed at facilitating the learning of temporal\ndependencies, with the objective of predicting future states based on\nhistorical clues and language guidance that describes event progression.\nBesides, to reduce the semantic gap and adapt the textual representation for\nbetter event description, we introduce a Semantic Aligner that first designs a\ntemplate to fuse question and answer pairs as event descriptions and then\nlearns a Transformer decoder with the whole video sequence as guidance for\nrefinement. We evaluate Tem-Adapter and different pre-train transferring\nmethods on two VideoQA benchmarks, and the significant performance improvement\ndemonstrates the effectiveness of our method.",
            "author": [
                "Guangyi Chen",
                "Xiao Liu",
                "Guangrun Wang",
                "Kun Zhang",
                "Philip H. S. Torr",
                "Xiao-Ping Zhang",
                "Yansong Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08414v1",
                "http://arxiv.org/pdf/2308.08414v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08413v1",
            "title": "Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value\n  Extraction",
            "updated": "2023-08-16T14:58:12Z",
            "published": "2023-08-16T14:58:12Z",
            "summary": "Existing attribute-value extraction (AVE) models require large quantities of\nlabeled data for training. However, new products with new attribute-value pairs\nenter the market every day in real-world e-Commerce. Thus, we formulate AVE in\nmulti-label few-shot learning (FSL), aiming to extract unseen attribute value\npairs based on a small number of training examples. We propose a\nKnowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks,\nleveraging the generated label description and category information to learn\nmore discriminative prototypes. Besides, KEAF integrates with hybrid attention\nto reduce noise and capture more informative semantics for each class by\ncalculating the label-relevant and query-related weights. To achieve\nmulti-label inference, KEAF further learns a dynamic threshold by integrating\nthe semantic information from both the support set and the query set. Extensive\nexperiments with ablation studies conducted on two datasets demonstrate that\nKEAF outperforms other SOTA models for information extraction in FSL. The code\ncan be found at: https://github.com/gjiaying/KEAF",
            "author": [
                "Jiaying Gong",
                "Wei-Te Chen",
                "Hoda Eldardiry"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615142",
                "http://arxiv.org/abs/2308.08413v1",
                "http://arxiv.org/pdf/2308.08413v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08402v1",
            "title": "Scaling description of frictionless dense suspensions under\n  inhomogeneous flow",
            "updated": "2023-08-16T14:42:53Z",
            "published": "2023-08-16T14:42:53Z",
            "summary": "Predicting the rheology of dense suspensions under inhomogeneous flow is\ncrucial in many industrial and geophysical applications, yet the conventional\n`$\\mu(J)$' framework is limited to homogeneous conditions in which the shear\nrate and solids fraction are spatially invariant. To address this shortcoming,\nwe use particle-based simulations of frictionless dense suspensions to derive\nnew constitutive laws that unify the rheological response under both\nhomogeneous and inhomogeneous conditions. By defining a new dimensionless\nnumber associated with particle velocity fluctuations and combining it with the\nviscous number, the macroscopic friction and the solids fraction, we obtain\nscaling relations that collapse data from homogeneous and inhomogeneous\nsimulations. The relations allow prediction of the steady state velocity,\nstress and volume fraction fields using only knowledge of the applied driving\nforce.",
            "author": [
                "Bhanu Prasad Bhowmik",
                "Christopher Ness"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08402v1",
                "http://arxiv.org/pdf/2308.08402v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08397v1",
            "title": "Asymptotic behavior of Laplacian eigenvalues of subspace inclusion\n  graphs",
            "updated": "2023-08-16T14:29:31Z",
            "published": "2023-08-16T14:29:31Z",
            "summary": "Let $\\text{Fl}_{n,q}$ be the simplicial complex whose vertices are the\nnon-trivial subspaces of $\\mathbb{F}_q^n$ and whose simplices correspond to\nfamilies of subspaces forming a flag. Let $\\Delta^{+}_k(\\text{Fl}_{n,q})$ be\nthe $k$-dimensional weighted upper Laplacian on $ \\text{Fl}_{n,q}$. The\nspectrum of $\\Delta^{+}_k(\\text{Fl}_{n,q})$ was first studied by Garland, who\nobtained a lower bound on its non-zero eigenvalues. Here, we focus on the $k=0$\ncase. We determine the asymptotic behavior of the eigenvalues of\n$\\Delta_{0}^{+}(\\text{Fl}_{n,q})$ as $q$ tends to infinity. In particular, we\nshow that for large enough $q$, $\\Delta_{0}^{+}(\\text{Fl}_{n,q})$ has exactly\n$\\left\\lfloor n^2/4\\right\\rfloor+2$ distinct eigenvalues, and that every\neigenvalue $\\lambda\\neq 0,n-1$ of $\\Delta_{0}^{+}(\\text{Fl}_{n,q})$ tends to\n$n-2$ as $q$ goes to infinity. This solves the $0$-dimensional case of a\nconjecture of Papikian.",
            "author": [
                "Alan Lew"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08397v1",
                "http://arxiv.org/pdf/2308.08397v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08390v2",
            "title": "Testing Partial Instrument Monotonicity",
            "updated": "2023-08-24T22:12:09Z",
            "published": "2023-08-16T14:22:51Z",
            "summary": "When multi-dimensional instruments are used to identify and estimate causal\neffects, the monotonicity condition may not hold due to heterogeneity in the\npopulation. Under a partial monotonicity condition, which only requires the\nmonotonicity to hold for each instrument separately holding all the other\ninstruments fixed, the 2SLS estimand can still be a positively weighted average\nof LATEs. In this paper, we provide a simple nonparametric test for partial\ninstrument monotonicity. We demonstrate the good finite sample properties of\nthe test through Monte Carlo simulations. We then apply the test to monetary\nincentives and distance from results centers as instruments for the knowledge\nof HIV status.",
            "author": [
                "Hongyi Jiang",
                "Zhenting Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08390v2",
                "http://arxiv.org/pdf/2308.08390v2"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08373v1",
            "title": "Approximation Algorithms for Norm Multiway Cut",
            "updated": "2023-08-16T13:55:10Z",
            "published": "2023-08-16T13:55:10Z",
            "summary": "We consider variants of the classic Multiway Cut problem. Multiway Cut asks\nto partition a graph $G$ into $k$ parts so as to separate $k$ given terminals.\nRecently, Chandrasekaran and Wang (ESA 2021) introduced $\\ell_p$-norm Multiway,\na generalization of the problem, in which the goal is to minimize the $\\ell_p$\nnorm of the edge boundaries of $k$ parts. We provide an $O(\\log^{1/2}\nn\\log^{1/2+1/p} k)$ approximation algorithm for this problem, improving upon\nthe approximation guarantee of $O(\\log^{3/2} n \\log^{1/2} k)$ due to\nChandrasekaran and Wang.\n  We also introduce and study Norm Multiway Cut, a further generalization of\nMultiway Cut. We assume that we are given access to an oracle, which answers\ncertain queries about the norm. We present an $O(\\log^{1/2} n \\log^{7/2} k)$\napproximation algorithm with a weaker oracle and an $O(\\log^{1/2} n \\log^{5/2}\nk)$ approximation algorithm with a stronger oracle. Additionally, we show that\nwithout any oracle access, there is no $n^{1/4-\\varepsilon}$ approximation\nalgorithm for every $\\varepsilon > 0$ assuming the Hypergraph Dense-vs-Random\nConjecture.",
            "author": [
                "Charlie Carlson",
                "Jafar Jafarov",
                "Konstantin Makarychev",
                "Yury Makarychev",
                "Liren Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08373v1",
                "http://arxiv.org/pdf/2308.08373v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08371v1",
            "title": "PDPK: A Framework to Synthesise Process Data and Corresponding\n  Procedural Knowledge for Manufacturing",
            "updated": "2023-08-16T13:50:23Z",
            "published": "2023-08-16T13:50:23Z",
            "summary": "Procedural knowledge describes how to accomplish tasks and mitigate problems.\nSuch knowledge is commonly held by domain experts, e.g. operators in\nmanufacturing who adjust parameters to achieve quality targets. To the best of\nour knowledge, no real-world datasets containing process data and corresponding\nprocedural knowledge are publicly available, possibly due to corporate\napprehensions regarding the loss of knowledge advances. Therefore, we provide a\nframework to generate synthetic datasets that can be adapted to different\ndomains. The design choices are inspired by two real-world datasets of\nprocedural knowledge we have access to. Apart from containing representations\nof procedural knowledge in Resource Description Framework (RDF)-compliant\nknowledge graphs, the framework simulates parametrisation processes and\nprovides consistent process data. We compare established embedding methods on\nthe resulting knowledge graphs, detailing which out-of-the-box methods have the\npotential to represent procedural knowledge. This provides a baseline which can\nbe used to increase the comparability of future work. Furthermore, we validate\nthe overall characteristics of a synthesised dataset by comparing the results\nto those achievable on a real-world dataset. The framework and evaluation code,\nas well as the dataset used in the evaluation, are available open source.",
            "author": [
                "Richard Nordsieck",
                "Andr\u00e9 Schweizer",
                "Michael Heider",
                "J\u00f6rg H\u00e4hner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08371v1",
                "http://arxiv.org/pdf/2308.08371v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08360v1",
            "title": "Independent Distribution Regularization for Private Graph Embedding",
            "updated": "2023-08-16T13:32:43Z",
            "published": "2023-08-16T13:32:43Z",
            "summary": "Learning graph embeddings is a crucial task in graph mining tasks. An\neffective graph embedding model can learn low-dimensional representations from\ngraph-structured data for data publishing benefiting various downstream\napplications such as node classification, link prediction, etc. However, recent\nstudies have revealed that graph embeddings are susceptible to attribute\ninference attacks, which allow attackers to infer private node attributes from\nthe learned graph embeddings. To address these concerns, privacy-preserving\ngraph embedding methods have emerged, aiming to simultaneously consider primary\nlearning and privacy protection through adversarial learning. However, most\nexisting methods assume that representation models have access to all sensitive\nattributes in advance during the training stage, which is not always the case\ndue to diverse privacy preferences. Furthermore, the commonly used adversarial\nlearning technique in privacy-preserving representation learning suffers from\nunstable training issues. In this paper, we propose a novel approach called\nPrivate Variational Graph AutoEncoders (PVGAE) with the aid of independent\ndistribution penalty as a regularization term. Specifically, we split the\noriginal variational graph autoencoder (VGAE) to learn sensitive and\nnon-sensitive latent representations using two sets of encoders. Additionally,\nwe introduce a novel regularization to enforce the independence of the\nencoders. We prove the theoretical effectiveness of regularization from the\nperspective of mutual information. Experimental results on three real-world\ndatasets demonstrate that PVGAE outperforms other baselines in private\nembedding learning regarding utility performance and privacy protection.",
            "author": [
                "Qi Hu",
                "Yangqiu Song"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614933",
                "http://arxiv.org/abs/2308.08360v1",
                "http://arxiv.org/pdf/2308.08360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08344v1",
            "title": "Graph Out-of-Distribution Generalization with Controllable Data\n  Augmentation",
            "updated": "2023-08-16T13:10:27Z",
            "published": "2023-08-16T13:10:27Z",
            "summary": "Graph Neural Network (GNN) has demonstrated extraordinary performance in\nclassifying graph properties. However, due to the selection bias of training\nand testing data (e.g., training on small graphs and testing on large graphs,\nor training on dense graphs and testing on sparse graphs), distribution\ndeviation is widespread. More importantly, we often observe \\emph{hybrid\nstructure distribution shift} of both scale and density, despite of one-sided\nbiased data partition. The spurious correlations over hybrid distribution\ndeviation degrade the performance of previous GNN methods and show large\ninstability among different datasets. To alleviate this problem, we propose\n\\texttt{OOD-GMixup} to jointly manipulate the training distribution with\n\\emph{controllable data augmentation} in metric space. Specifically, we first\nextract the graph rationales to eliminate the spurious correlations due to\nirrelevant information. Secondly, we generate virtual samples with perturbation\non graph rationale representation domain to obtain potential OOD training\nsamples. Finally, we propose OOD calibration to measure the distribution\ndeviation of virtual samples by leveraging Extreme Value Theory, and further\nactively control the training distribution by emphasizing the impact of virtual\nOOD samples. Extensive studies on several real-world datasets on graph\nclassification demonstrate the superiority of our proposed method over\nstate-of-the-art baselines.",
            "author": [
                "Bin Lu",
                "Xiaoying Gan",
                "Ze Zhao",
                "Shiyu Liang",
                "Luoyi Fu",
                "Xinbing Wang",
                "Chenghu Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08344v1",
                "http://arxiv.org/pdf/2308.08344v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08334v1",
            "title": "Learning Logic Programs by Discovering Higher-Order Abstractions",
            "updated": "2023-08-16T12:50:10Z",
            "published": "2023-08-16T12:50:10Z",
            "summary": "Discovering novel abstractions is important for human-level AI. We introduce\nan approach to discover higher-order abstractions, such as map, filter, and\nfold. We focus on inductive logic programming, which induces logic programs\nfrom examples and background knowledge. We introduce the higher-order\nrefactoring problem, where the goal is to compress a logic program by\nintroducing higher-order abstractions. We implement our approach in STEVIE,\nwhich formulates the higher-order refactoring problem as a constraint\noptimisation problem. Our experimental results on multiple domains, including\nprogram synthesis and visual reasoning, show that, compared to no refactoring,\nSTEVIE can improve predictive accuracies by 27% and reduce learning times by\n47%. We also show that STEVIE can discover abstractions that transfer to\ndifferent domains",
            "author": [
                "C\u00e9line Hocquette",
                "Sebastijan Duman\u010di\u0107",
                "Andrew Cropper"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08334v1",
                "http://arxiv.org/pdf/2308.08334v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16105v1",
            "title": "A Privacy-preserving Central Bank Ledger for Central Bank Digital\n  Currency",
            "updated": "2023-08-16T12:33:08Z",
            "published": "2023-08-16T12:33:08Z",
            "summary": "Retail central bank digital currency (rCBDC) is seen as a key upgrade of the\nmonetary system in the 21st century. However, privacy concerns are the main\nimpediment to rCBDC's development and roll-out. On the one hand, the rights of\npeople to keep their transactions private should be protected, including\nagainst central bank surveillance. On the other hand, the central bank needs to\nensure that no over-issuance of money or other frauds occur, demanding a\ncertain form of knowledge of rCBDC transactions to safeguard against malicious\nusers. This work focuses on rCBDC architectures based on the unspent\ntransaction output (UTXO) data model and tackles the research problem of\npreserving a sufficient degree of privacy for UTXO transaction records while\nallowing the central bank to verify their correctness. User privacy is not\nadequately addressed in the UTXO-based rCBDC architectures. Using evolving\npublic keys as pseudonyms to hide the real identities of users only solves the\nprivacy issue partially. Some information could still be leaked out. This work\ninvestigates techniques to address the shortcomings of the pseudonym approach.\nFirst, a Pedersen commitment scheme is applied to hide the transaction values\nof a UTXO transaction while allowing the central bank to verify that no\nover-issuance of rCBDC has occurred in the transaction.This work uses a Schnorr\nsignature to prove no over-issuance of money, which reduces overheads and\nenables a non-interactive proof. Then, Coinjoin is applied to aggregate UTXO\ntransactions from different users into one larger UTXO transaction to obfuscate\nthe payer-payee relationship while preserving the correctness of the amount of\nmoney flow. This work applies k-anonymity to analyse the privacy guarantee of\nCoinjoin. By modelling the transaction traffic by a Poisson process, the\ntrade-off between anonymity and transaction confirmation time of Coinjoin is\nanalysed.",
            "author": [
                "Wang Mong Tikvah Chan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16105v1",
                "http://arxiv.org/pdf/2311.16105v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "E.3; G.3; K.4.1; K.4.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08311v2",
            "title": "Graph Gradient Diffusion",
            "updated": "2023-10-27T10:06:25Z",
            "published": "2023-08-16T12:15:11Z",
            "summary": "We analyze graph dynamical systems with odd analytic coupling. The set of\nequilibria is union of manifolds, which can intersect and have different\ndimension. The geometry of this set depends on the coupling function, as well\nas several properties of the underlying graph, such as homology, coverings,\nconnectivity and symmetry. Equilibrium stability can change among the manifolds\nof equilibria and within a single manifold of equilibria. The gradient\nstructure and topological bifurcation theory can be leveraged to establish\nLyapunov, asymptotic, and linear stability.",
            "author": [
                "Davide Sclosa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08311v2",
                "http://arxiv.org/pdf/2308.08311v2"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.CO",
                "math.DG",
                "34A34 (Primary) 05C50, 14P15 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08307v1",
            "title": "Integrating cognitive map learning and active inference for planning in\n  ambiguous environments",
            "updated": "2023-08-16T12:10:23Z",
            "published": "2023-08-16T12:10:23Z",
            "summary": "Living organisms need to acquire both cognitive maps for learning the\nstructure of the world and planning mechanisms able to deal with the challenges\nof navigating ambiguous environments. Although significant progress has been\nmade in each of these areas independently, the best way to integrate them is an\nopen research question. In this paper, we propose the integration of a\nstatistical model of cognitive map formation within an active inference agent\nthat supports planning under uncertainty. Specifically, we examine the\nclone-structured cognitive graph (CSCG) model of cognitive map formation and\ncompare a naive clone graph agent with an active inference-driven clone graph\nagent, in three spatial navigation scenarios. Our findings demonstrate that\nwhile both agents are effective in simple scenarios, the active inference agent\nis more effective when planning in challenging scenarios, in which sensory\nobservations provide ambiguous information about location.",
            "author": [
                "Toon Van de Maele",
                "Bart Dhoedt",
                "Tim Verbelen",
                "Giovanni Pezzulo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08307v1",
                "http://arxiv.org/pdf/2308.08307v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08300v1",
            "title": "Hierarchical High-Point Energy Flow Network for Jet Tagging",
            "updated": "2023-08-16T11:59:44Z",
            "published": "2023-08-16T11:59:44Z",
            "summary": "Jet substructure observable basis is a systematic and powerful tool for\nanalyzing the internal energy distribution of constituent particles within a\njet. In this work, we propose a novel method to insert neural networks into jet\nsubstructure basis as a simple yet efficient interpretable IRC-safe deep\nlearning framework to discover discriminative jet observables. The Energy Flow\nPolynomial (EFP) could be computed with a certain summation order, resulting in\na reorganized form which exhibits hierarchical IRC-safety. Thus inserting\nnon-linear functions after the separate summation could significantly extend\nthe scope of IRC-safe jet substructure observables, where neural networks can\ncome into play as an important role. Based on the structure of the simplest\nclass of EFPs which corresponds to path graphs, we propose the Hierarchical\nEnergy Flow Networks and the Local Hierarchical Energy Flow Networks. These two\narchitectures exhibit remarkable discrimination performance on the top tagging\ndataset and quark-gluon dataset compared to other benchmark algorithms even\nonly utilizing the kinematic information of constituent particles.",
            "author": [
                "Wei Shen",
                "Daohan Wang",
                "Jin Min Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08300v1",
                "http://arxiv.org/pdf/2308.08300v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08292v1",
            "title": "Techniques for Improving the Energy Efficiency of Mobile Apps: A\n  Taxonomy and Systematic Literature Review",
            "updated": "2023-08-16T11:37:46Z",
            "published": "2023-08-16T11:37:46Z",
            "summary": "Building energy efficient software is an increasingly important task for\nmobile developers. However, a cumulative body of knowledge of techniques that\nsupport this goal does not exist. We conduct a systematic literature review to\ngather information on existing techniques that allow developers to increase\nenergy efficiency in mobile apps. Based on a synthesis of the 91 included\nprimary studies, we propose a taxonomy of techniques for improving the energy\nefficiency in mobile apps. The taxonomy includes seven main categories of\ntechniques and serves as a collection of available methods for developers and\nas a reference guide for software testers when performing energy efficiency\ntesting by the means of benchmark tests.",
            "author": [
                "Stefan Huber",
                "Tobias Lorey",
                "Michael Felderer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08292v1",
                "http://arxiv.org/pdf/2308.08292v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08285v1",
            "title": "Pre-training with Large Language Model-based Document Expansion for\n  Dense Passage Retrieval",
            "updated": "2023-08-16T11:10:43Z",
            "published": "2023-08-16T11:10:43Z",
            "summary": "In this paper, we systematically study the potential of pre-training with\nLarge Language Model(LLM)-based document expansion for dense passage retrieval.\nConcretely, we leverage the capabilities of LLMs for document expansion, i.e.\nquery generation, and effectively transfer expanded knowledge to retrievers\nusing pre-training strategies tailored for passage retrieval. These strategies\ninclude contrastive learning and bottlenecked query generation. Furthermore, we\nincorporate a curriculum learning strategy to reduce the reliance on LLM\ninferences. Experimental results demonstrate that pre-training with LLM-based\ndocument expansion significantly boosts the retrieval performance on\nlarge-scale web-search tasks. Our work shows strong zero-shot and out-of-domain\nretrieval abilities, making it more widely applicable for retrieval when\ninitializing with no human-labeled data.",
            "author": [
                "Guangyuan Ma",
                "Xing Wu",
                "Peng Wang",
                "Zijia Lin",
                "Songlin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08285v1",
                "http://arxiv.org/pdf/2308.08285v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08259v1",
            "title": "Graph Relation Aware Continual Learning",
            "updated": "2023-08-16T09:53:20Z",
            "published": "2023-08-16T09:53:20Z",
            "summary": "Continual graph learning (CGL) studies the problem of learning from an\ninfinite stream of graph data, consolidating historical knowledge, and\ngeneralizing it to the future task. At once, only current graph data are\navailable. Although some recent attempts have been made to handle this task, we\nstill face two potential challenges: 1) most of existing works only manipulate\non the intermediate graph embedding and ignore intrinsic properties of graphs.\nIt is non-trivial to differentiate the transferred information across graphs.\n2) recent attempts take a parameter-sharing policy to transfer knowledge across\ntime steps or progressively expand new architecture given shifted graph\ndistribution. Learning a single model could loss discriminative information for\neach graph task while the model expansion scheme suffers from high model\ncomplexity. In this paper, we point out that latent relations behind graph\nedges can be attributed as an invariant factor for the evolving graphs and the\nstatistical information of latent relations evolves. Motivated by this, we\ndesign a relation-aware adaptive model, dubbed as RAM-CG, that consists of a\nrelation-discovery modular to explore latent relations behind edges and a\ntask-awareness masking classifier to accounts for the shifted. Extensive\nexperiments show that RAM-CG provides significant 2.2%, 6.9% and 6.6% accuracy\nimprovements over the state-of-the-art results on CitationNet, OGBN-arxiv and\nTWITCH dataset, respective.",
            "author": [
                "Qinghua Shen",
                "Weijieying Ren",
                "Wei Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08259v1",
                "http://arxiv.org/pdf/2308.08259v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.16702v1",
            "title": "Prediction and Interpretation of Vehicle Trajectories in the Graph\n  Spectral Domain",
            "updated": "2023-08-16T09:26:32Z",
            "published": "2023-08-16T09:26:32Z",
            "summary": "This work provides a comprehensive analysis and interpretation of the graph\nspectral representation of traffic scenarios. Based on a spatio-temporal\nvehicle interaction graph, an observed traffic scenario can be transformed into\nthe graph spectral domain by means of the multidimensional Graph Fourier\nTransformation. Since these spectral scenario representations have shown to\nsuccessfully incorporate the complex and interactive nature of traffic\nscenarios, the beneficial feature representation is employed for the purpose of\npredicting vehicle trajectories. This work introduces GFTNNv2, a deep learning\nnetwork predicting vehicle trajectories in the graph spectral domain.\nEvaluation of the GFTNNv2 on the publicly available datasets highD and NGSIM\nshows a performance gain of up to 25% in comparison to state-of-the-art\nprediction approaches.",
            "author": [
                "Marion Neumeier",
                "Sebastian Dorn",
                "Michael Botsch",
                "Wolfgang Utschick"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16702v1",
                "http://arxiv.org/pdf/2309.16702v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08240v1",
            "title": "Boundes for Boxicity of some classes of graphs",
            "updated": "2023-08-16T09:15:43Z",
            "published": "2023-08-16T09:15:43Z",
            "summary": "Let $box(G)$ be the boxicity of a graph $G$, $G[H_1,H_2,\\ldots, H_n]$ be the\n$G$-generalized join graph of $n$-pairwise disjoint graphs $H_1,H_2,\\ldots,\nH_n$, $G^d_k$ be a circular clique graph (where $k\\geq 2d$) and $\\Gamma(R)$ be\nthe zero-divisor graph of a commutative ring $R$. In this paper, we prove that\n$\\chi(G^d_k)\\geq box(G^d_k)$, for all $k$ and $d$ with $k\\geq 2d$. This\ngeneralizes the results proved in \\cite{Aki}. Also we obtain that\n$box(G[H_1,H_2,\\ldots,H_n])\\leq \\mathop\\sum\\limits_{i=1}^nbox(H_i)$. As a\nconsequence of this result, we obtain a bound for boxicity of zero-divisor\ngraph of a finite commutative ring with unity. In particular, if $R$ is a\nfinite commutative non-zero reduced ring with unity, then $\\chi(\\Gamma(R))\\leq\nbox(\\Gamma(R))\\leq 2^{\\chi(\\Gamma(R))}-2$. where $\\chi(\\Gamma(R))$ is the\nchromatic number of $\\Gamma(R)$. Moreover, we show that if $N=\n\\prod\\limits_{i=1}^{a}p_i^{2n_i} \\prod\\limits_{j=1}^{b}q_j^{2m_j+1}$ is a\ncomposite number, where $p_i$'s and $q_j$'s are distinct prime numbers, then\n$box(\\Gamma(\\mathbb{Z}_N))\\leq\n\\big(\\mathop\\prod\\limits_{i=1}^{a}(2n_i+1)\\mathop\\prod\\limits_{j=1}^{b}(2m_j+2)\\big)-\\big(\\mathop\\prod\\limits_{i=1}^{a}(n_i+1)\\mathop\\prod\\limits_{j=1}^{b}(m_j+1)\\big)-1$,\nwhere $\\mathbb{Z}_N$ is the ring of integers modulo $N$. Further, we prove\nthat, $box(\\Gamma(\\mathbb{Z}_N))=1$ if and only if either $N=p^n$ for some\nprime number $p$ and some positive integer $n\\geq 2$ or $N=2p$ for some odd\nprime number $p$.",
            "author": [
                "T. Kavaskar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08240v1",
                "http://arxiv.org/pdf/2308.08240v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08235v1",
            "title": "The Expressive Power of Graph Neural Networks: A Survey",
            "updated": "2023-08-16T09:12:21Z",
            "published": "2023-08-16T09:12:21Z",
            "summary": "Graph neural networks (GNNs) are effective machine learning models for many\ngraph-related applications. Despite their empirical success, many research\nefforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive\npower. Early works in this domain mainly focus on studying the graph\nisomorphism recognition ability of GNNs, and recent works try to leverage the\nproperties such as subgraph counting and connectivity learning to characterize\nthe expressive power of GNNs, which are more practical and closer to\nreal-world. However, no survey papers and open-source repositories\ncomprehensively summarize and discuss models in this important direction. To\nfill the gap, we conduct a first survey for models for enhancing expressive\npower under different forms of definition. Concretely, the models are reviewed\nbased on three categories, i.e., Graph feature enhancement, Graph topology\nenhancement, and GNNs architecture enhancement.",
            "author": [
                "Bingxu Zhang",
                "Changjun Fan",
                "Shixuan Liu",
                "Kuihua Huang",
                "Xiang Zhao",
                "Jincai Huang",
                "Zhong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08235v1",
                "http://arxiv.org/pdf/2308.08235v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08234v1",
            "title": "Challenges and Opportunities of Using Transformer-Based Multi-Task\n  Learning in NLP Through ML Lifecycle: A Survey",
            "updated": "2023-08-16T09:11:00Z",
            "published": "2023-08-16T09:11:00Z",
            "summary": "The increasing adoption of natural language processing (NLP) models across\nindustries has led to practitioners' need for machine learning systems to\nhandle these models efficiently, from training to serving them in production.\nHowever, training, deploying, and updating multiple models can be complex,\ncostly, and time-consuming, mainly when using transformer-based pre-trained\nlanguage models. Multi-Task Learning (MTL) has emerged as a promising approach\nto improve efficiency and performance through joint training, rather than\ntraining separate models. Motivated by this, we first provide an overview of\ntransformer-based MTL approaches in NLP. Then, we discuss the challenges and\nopportunities of using MTL approaches throughout typical ML lifecycle phases,\nspecifically focusing on the challenges related to data engineering, model\ndevelopment, deployment, and monitoring phases. This survey focuses on\ntransformer-based MTL architectures and, to the best of our knowledge, is novel\nin that it systematically analyses how transformer-based MTL in NLP fits into\nML lifecycle phases. Furthermore, we motivate research on the connection\nbetween MTL and continual learning (CL), as this area remains unexplored. We\nbelieve it would be practical to have a model that can handle both MTL and CL,\nas this would make it easier to periodically re-train the model, update it due\nto distribution shifts, and add new capabilities to meet real-world\nrequirements.",
            "author": [
                "Lovre Torbarina",
                "Tin Ferkovic",
                "Lukasz Roguski",
                "Velimir Mihelcic",
                "Bruno Sarlija",
                "Zeljko Kraljevic"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08234v1",
                "http://arxiv.org/pdf/2308.08234v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08204v1",
            "title": "MoCoSA: Momentum Contrast for Knowledge Graph Completion with\n  Structure-Augmented Pre-trained Language Models",
            "updated": "2023-08-16T08:09:10Z",
            "published": "2023-08-16T08:09:10Z",
            "summary": "Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts\nwithin knowledge graphs and automatically infer missing links. Existing methods\ncan mainly be categorized into structure-based or description-based. On the one\nhand, structure-based methods effectively represent relational facts in\nknowledge graphs using entity embeddings. However, they struggle with\nsemantically rich real-world entities due to limited structural information and\nfail to generalize to unseen entities. On the other hand, description-based\nmethods leverage pre-trained language models (PLMs) to understand textual\ninformation. They exhibit strong robustness towards unseen entities. However,\nthey have difficulty with larger negative sampling and often lag behind\nstructure-based methods. To address these issues, in this paper, we propose\nMomentum Contrast for knowledge graph completion with Structure-Augmented\npre-trained language models (MoCoSA), which allows the PLM to perceive the\nstructural information by the adaptable structure encoder. To improve learning\nefficiency, we proposed momentum hard negative and intra-relation negative\nsampling. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance in terms of mean reciprocal rank (MRR), with\nimprovements of 2.5% on WN18RR and 21% on OpenBG500.",
            "author": [
                "Jiabang He",
                "Liu Jia",
                "Lei Wang",
                "Xiyao Li",
                "Xing Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08204v1",
                "http://arxiv.org/pdf/2308.08204v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08202v1",
            "title": "Norm and time optimal control problems of stochastic heat equations",
            "updated": "2023-08-16T08:06:52Z",
            "published": "2023-08-16T08:06:52Z",
            "summary": "This paper investigates the norm and time optimal control problems for\nstochastic heat equations. We begin by presenting a characterization of the\nnorm optimal control, followed by a discussion of its properties. We then\nexplore the equivalence between the norm optimal control and time optimal\ncontrol, and subsequently establish the bang-bang property of the time optimal\ncontrol. These problems, to the best of our knowledge, are among the first to\ndiscuss in the stochastic case.",
            "author": [
                "Yuanhang Liu",
                "Donghui Yang",
                "Jie Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08202v1",
                "http://arxiv.org/pdf/2308.08202v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "49J21, 93B05, 93E20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08198v1",
            "title": "DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting",
            "updated": "2023-08-16T07:58:02Z",
            "published": "2023-08-16T07:58:02Z",
            "summary": "Subgraph counting is the problem of counting the occurrences of a given query\ngraph in a large target graph. Large-scale subgraph counting is useful in\nvarious domains, such as motif counting for social network analysis and loop\ncounting for money laundering detection on transaction networks. Recently, to\naddress the exponential runtime complexity of scalable subgraph counting,\nneural methods are proposed. However, existing neural counting approaches fall\nshort in three aspects. Firstly, the counts of the same query can vary from\nzero to millions on different target graphs, posing a much larger challenge\nthan most graph regression tasks. Secondly, current scalable graph neural\nnetworks have limited expressive power and fail to efficiently distinguish\ngraphs in count prediction. Furthermore, existing neural approaches cannot\npredict the occurrence position of queries in the target graph.\n  Here we design DeSCo, a scalable neural deep subgraph counting pipeline,\nwhich aims to accurately predict the query count and occurrence position on any\ntarget graph after one-time training. Firstly, DeSCo uses a novel canonical\npartition and divides the large target graph into small neighborhood graphs.\nThe technique greatly reduces the count variation while guaranteeing no missing\nor double-counting. Secondly, neighborhood counting uses an expressive\nsubgraph-based heterogeneous graph neural network to accurately perform\ncounting in each neighborhood. Finally, gossip propagation propagates\nneighborhood counts with learnable gates to harness the inductive biases of\nmotif counts. DeSCo is evaluated on eight real-world datasets from various\ndomains. It outperforms state-of-the-art neural methods with 137x improvement\nin the mean squared error of count prediction, while maintaining the polynomial\nruntime complexity.",
            "author": [
                "Tianyu Fu",
                "Chiyue Wei",
                "Yu Wang",
                "Rex Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08198v1",
                "http://arxiv.org/pdf/2308.08198v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "I.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08190v1",
            "title": "Modelling the Spread of COVID-19 in Indoor Spaces using Automated\n  Probabilistic Planning",
            "updated": "2023-08-16T07:41:53Z",
            "published": "2023-08-16T07:41:53Z",
            "summary": "The coronavirus disease 2019 (COVID-19) pandemic has been ongoing for around\n3 years, and has infected over 750 million people and caused over 6 million\ndeaths worldwide at the time of writing. Throughout the pandemic, several\nstrategies for controlling the spread of the disease have been debated by\nhealthcare professionals, government authorities, and international bodies. To\nanticipate the potential impact of the disease, and to simulate the\neffectiveness of different mitigation strategies, a robust model of disease\nspread is needed. In this work, we explore a novel approach based on\nprobabilistic planning and dynamic graph analysis to model the spread of\nCOVID-19 in indoor spaces. We endow the planner with means to control the\nspread of the disease through non-pharmaceutical interventions (NPIs) such as\nmandating masks and vaccines, and we compare the impact of crowds and capacity\nlimits on the spread of COVID-19 in these settings. We demonstrate that the use\nof probabilistic planning is effective in predicting the amount of infections\nthat are likely to occur in shared spaces, and that automated planners have the\npotential to design competent interventions to limit the spread of the disease.\nOur code is fully open-source and is available at:\nhttps://github.com/mharmanani/prob-planning-covid19 .",
            "author": [
                "Mohamed Harmanani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08190v1",
                "http://arxiv.org/pdf/2308.08190v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08176v1",
            "title": "RSpell: Retrieval-augmented Framework for Domain Adaptive Chinese\n  Spelling Check",
            "updated": "2023-08-16T07:12:23Z",
            "published": "2023-08-16T07:12:23Z",
            "summary": "Chinese Spelling Check (CSC) refers to the detection and correction of\nspelling errors in Chinese texts. In practical application scenarios, it is\nimportant to make CSC models have the ability to correct errors across\ndifferent domains. In this paper, we propose a retrieval-augmented spelling\ncheck framework called RSpell, which searches corresponding domain terms and\nincorporates them into CSC models. Specifically, we employ pinyin fuzzy\nmatching to search for terms, which are combined with the input and fed into\nthe CSC model. Then, we introduce an adaptive process control mechanism to\ndynamically adjust the impact of external knowledge on the model. Additionally,\nwe develop an iterative strategy for the RSpell framework to enhance reasoning\ncapabilities. We conducted experiments on CSC datasets in three domains: law,\nmedicine, and official document writing. The results demonstrate that RSpell\nachieves state-of-the-art performance in both zero-shot and fine-tuning\nscenarios, demonstrating the effectiveness of the retrieval-augmented CSC\nframework. Our code is available at https://github.com/47777777/Rspell.",
            "author": [
                "Siqi Song",
                "Qi Lv",
                "Lei Geng",
                "Ziqiang Cao",
                "Guohong Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08176v1",
                "http://arxiv.org/pdf/2308.08176v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08174v1",
            "title": "Accelerating Generic Graph Neural Networks via Architecture, Compiler,\n  Partition Method Co-Design",
            "updated": "2023-08-16T07:05:47Z",
            "published": "2023-08-16T07:05:47Z",
            "summary": "Graph neural networks (GNNs) have shown significant accuracy improvements in\na variety of graph learning domains, sparking considerable research interest.\nTo translate these accuracy improvements into practical applications, it is\nessential to develop high-performance and efficient hardware acceleration for\nGNN models. However, designing GNN accelerators faces two fundamental\nchallenges: the high bandwidth requirement of GNN models and the diversity of\nGNN models. Previous works have addressed the first challenge by using more\nexpensive memory interfaces to achieve higher bandwidth. For the second\nchallenge, existing works either support specific GNN models or have generic\ndesigns with poor hardware utilization.\n  In this work, we tackle both challenges simultaneously. First, we identify a\nnew type of partition-level operator fusion, which we utilize to internally\nreduce the high bandwidth requirement of GNNs. Next, we introduce\npartition-level multi-threading to schedule the concurrent processing of graph\npartitions, utilizing different hardware resources. To further reduce the extra\non-chip memory required by multi-threading, we propose fine-grained graph\npartitioning to generate denser graph partitions. Importantly, these three\nmethods make no assumptions about the targeted GNN models, addressing the\nchallenge of model variety. We implement these methods in a framework called\nSwitchBlade, consisting of a compiler, a graph partitioner, and a hardware\naccelerator. Our evaluation demonstrates that SwitchBlade achieves an average\nspeedup of $1.85\\times$ and energy savings of $19.03\\times$ compared to the\nNVIDIA V100 GPU. Additionally, SwitchBlade delivers performance comparable to\nstate-of-the-art specialized accelerators.",
            "author": [
                "Shuwen Lu",
                "Zhihui Zhang",
                "Cong Guo",
                "Jingwen Leng",
                "Yangjie Zhou",
                "Minyi Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08174v1",
                "http://arxiv.org/pdf/2308.08174v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08173v1",
            "title": "Expressivity of Graph Neural Networks Through the Lens of Adversarial\n  Robustness",
            "updated": "2023-08-16T07:05:41Z",
            "published": "2023-08-16T07:05:41Z",
            "summary": "We perform the first adversarial robustness study into Graph Neural Networks\n(GNNs) that are provably more powerful than traditional Message Passing Neural\nNetworks (MPNNs). In particular, we use adversarial robustness as a tool to\nuncover a significant gap between their theoretically possible and empirically\nachieved expressive power. To do so, we focus on the ability of GNNs to count\nspecific subgraph patterns, which is an established measure of expressivity,\nand extend the concept of adversarial robustness to this task. Based on this,\nwe develop efficient adversarial attacks for subgraph counting and show that\nmore powerful GNNs fail to generalize even to small perturbations to the\ngraph's structure. Expanding on this, we show that such architectures also fail\nto count substructures on out-of-distribution graphs.",
            "author": [
                "Francesco Campi",
                "Lukas Gosch",
                "Tom Wollschl\u00e4ger",
                "Yan Scholten",
                "Stephan G\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08173v1",
                "http://arxiv.org/pdf/2308.08173v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08171v2",
            "title": "Learning to Pivot as a Smart Expert",
            "updated": "2023-08-31T15:26:23Z",
            "published": "2023-08-16T07:00:51Z",
            "summary": "Linear programming has been practically solved mainly by simplex and interior\npoint methods. Compared with the weakly polynomial complexity obtained by the\ninterior point methods, the existence of strongly polynomial bounds for the\nlength of the pivot path generated by the simplex methods remains a mystery. In\nthis paper, we propose two novel pivot experts that leverage both global and\nlocal information of the linear programming instances for the primal simplex\nmethod and show their excellent performance numerically. The experts can be\nregarded as a benchmark to evaluate the performance of classical pivot rules,\nalthough they are hard to directly implement. To tackle this challenge, we\nemploy a graph convolutional neural network model, trained via imitation\nlearning, to mimic the behavior of the pivot expert. Our pivot rule, learned\nempirically, displays a significant advantage over conventional methods in\nvarious linear programming problems, as demonstrated through a series of\nrigorous experiments.",
            "author": [
                "Tianhao Liu",
                "Shanwen Pu",
                "Dongdong Ge",
                "Yinyu Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08171v2",
                "http://arxiv.org/pdf/2308.08171v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08170v1",
            "title": "Network Centralities in Quantum Entanglement Distribution due to User\n  Preferences",
            "updated": "2023-08-16T07:00:09Z",
            "published": "2023-08-16T07:00:09Z",
            "summary": "Quantum networks are of great interest of late which apply quantum mechanics\nto transfer information securely. One of the key properties which are exploited\nis entanglement to transfer information from one network node to another.\nApplications like quantum teleportation rely on the entanglement between the\nconcerned nodes. Thus, efficient entanglement distribution among network nodes\nis of utmost importance. Several entanglement distribution methods have been\nproposed in the literature which primarily rely on attributes, such as,\nfidelities, link layer network topologies, proactive distribution, etc. This\npaper studies the centralities of the network when the link layer topology of\nentanglements (referred to as entangled graph) is driven by usage patterns of\npeer-to-peer connections between remote nodes (referred to as connection graph)\nwith different characteristics. Three different distributions (uniform,\ngaussian, and power law) are considered for the connection graph where the two\nnodes are selected from the same distribution. For the entangled graph, both\nreactive and proactive entanglements are employed to form a random graph.\nResults show that the edge centralities (measured as usage frequencies of\nindividual edges during entanglement distribution) of the entangled graph\nfollow power law distributions whereas the growth in entanglements with\nconnections and node centralities (degrees of nodes) are monomolecularly\ndistributed for most of the scenarios. These findings will help in quantum\nresource management, e.g., quantum technology with high reliability and lower\ndecoherence time may be allocated to edges with high centralities.",
            "author": [
                "Dibakar Das",
                "Shiva Kumar Malapaka",
                "Jyotsna Bapat",
                "Debabrata Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08170v1",
                "http://arxiv.org/pdf/2308.08170v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08166v1",
            "title": "On graphs with no induced $P_5$ or $K_5-e$",
            "updated": "2023-08-16T06:38:53Z",
            "published": "2023-08-16T06:38:53Z",
            "summary": "In this paper, we are interested in some problems related to chromatic number\nand clique number for the class of $(P_5,K_5-e)$-free graphs, and prove the\nfollowing. $(a)$ If $G$ is a connected ($P_5,K_5-e$)-free graph with\n$\\omega(G)\\geq 7$, then either $G$ is the complement of a bipartite graph or\n$G$ has a clique cut-set. Moreover, there is a connected ($P_5,K_5-e$)-free\nimperfect graph $H$ with $\\omega(H)=6$ and has no clique cut-set. This\nstrengthens a result of Malyshev and Lobanova [Disc. Appl. Math. 219 (2017)\n158--166]. $(b)$ If $G$ is a ($P_5,K_5-e$)-free graph with $\\omega(G)\\geq 4$,\nthen $\\chi(G)\\leq \\max\\{7, \\omega(G)\\}$. Moreover, the bound is tight when\n$\\omega(G)\\notin \\{4,5,6\\}$. This result together with known results partially\nanswers a question of Ju and Huang [arXiv:2303.18003 [math.CO] 2023], and also\nimproves a result of Xu [Manuscript 2022].\n  While the \"Chromatic Number Problem\" is known to be $NP$-hard for the class\nof $P_5$-free graphs, our results together with some known results imply that\nthe \"Chromatic Number Problem\" can be solved in polynomial time for the class\nof ($P_5,K_5-e$)-free graphs which may be independent interest.",
            "author": [
                "Arnab Char",
                "T. Karthick"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08166v1",
                "http://arxiv.org/pdf/2308.08166v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08163v2",
            "title": "Characteristics of networks generated by kernel growing neural gas",
            "updated": "2023-08-25T14:43:36Z",
            "published": "2023-08-16T06:11:27Z",
            "summary": "This research aims to develop kernel GNG, a kernelized version of the growing\nneural gas (GNG) algorithm, and to investigate the features of the networks\ngenerated by the kernel GNG. The GNG is an unsupervised artificial neural\nnetwork that can transform a dataset into an undirected graph, thereby\nextracting the features of the dataset as a graph. The GNG is widely used in\nvector quantization, clustering, and 3D graphics. Kernel methods are often used\nto map a dataset to feature space, with support vector machines being the most\nprominent application. This paper introduces the kernel GNG approach and\nexplores the characteristics of the networks generated by kernel GNG. Five\nkernels, including Gaussian, Laplacian, Cauchy, inverse multiquadric, and log\nkernels, are used in this study. The results of this study show that the\naverage degree and the average clustering coefficient decrease as the kernel\nparameter increases for Gaussian, Laplacian, Cauchy, and IMQ kernels. If we\navoid more edges and a higher clustering coefficient (or more triangles), the\nkernel GNG with a larger value of the parameter will be more appropriate.",
            "author": [
                "Kazuhisa Fujita"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08163v2",
                "http://arxiv.org/pdf/2308.08163v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.11032v1",
            "title": "AI For Fraud Awareness",
            "updated": "2023-08-16T05:45:34Z",
            "published": "2023-08-16T05:45:34Z",
            "summary": "In today's world, with the rise of numerous social platforms, it has become\nrelatively easy for anyone to spread false information and lure people into\ntraps. Fraudulent schemes and traps are growing rapidly in the investment\nworld. Due to this, countries and individuals face huge financial risks. We\npresent an awareness system with the use of machine learning and gamification\ntechniques to educate the people about investment scams and traps. Our system\napplies machine learning techniques to provide a personalized learning\nexperience to the user. The system chooses distinct game-design elements and\nscams from the knowledge pool crafted by domain experts for each individual.\nThe objective of the research project is to reduce inequalities in all\ncountries by educating investors via Active Learning. Our goal is to assist the\nregulators in assuring a conducive environment for a fair, efficient, and\ninclusive capital market. In the paper, we discuss the impact of the problem,\nprovide implementation details, and showcase the potentiality of the system\nthrough preliminary experiments and results.",
            "author": [
                "Prabh Simran Singh Baweja",
                "Orathai Sangpetch",
                "Akkarit Sangpetch"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11032v1",
                "http://arxiv.org/pdf/2308.11032v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08148v1",
            "title": "Hierarchical Topological Ordering with Conditional Independence Test for\n  Limited Time Series",
            "updated": "2023-08-16T05:01:33Z",
            "published": "2023-08-16T05:01:33Z",
            "summary": "Learning directed acyclic graphs (DAGs) to identify causal relations\nunderlying observational data is crucial but also poses significant challenges.\nRecently, topology-based methods have emerged as a two-step approach to\ndiscovering DAGs by first learning the topological ordering of variables and\nthen eliminating redundant edges, while ensuring that the graph remains\nacyclic. However, one limitation is that these methods would generate numerous\nspurious edges that require subsequent pruning. To overcome this limitation, in\nthis paper, we propose an improvement to topology-based methods by introducing\nlimited time series data, consisting of only two cross-sectional records that\nneed not be adjacent in time and are subject to flexible timing. By\nincorporating conditional instrumental variables as exogenous interventions, we\naim to identify descendant nodes for each variable. Following this line, we\npropose a hierarchical topological ordering algorithm with conditional\nindependence test (HT-CIT), which enables the efficient learning of sparse DAGs\nwith a smaller search space compared to other popular approaches. The HT-CIT\nalgorithm greatly reduces the number of edges that need to be pruned. Empirical\nresults from synthetic and real-world datasets demonstrate the superiority of\nthe proposed HT-CIT algorithm.",
            "author": [
                "Anpeng Wu",
                "Haoxuan Li",
                "Kun Kuang",
                "Keli Zhang",
                "Fei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08148v1",
                "http://arxiv.org/pdf/2308.08148v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08147v1",
            "title": "MDDial: A Multi-turn Differential Diagnosis Dialogue Dataset with\n  Reliability Evaluation",
            "updated": "2023-08-16T04:56:55Z",
            "published": "2023-08-16T04:56:55Z",
            "summary": "Dialogue systems for Automatic Differential Diagnosis (ADD) have a wide range\nof real-life applications. These dialogue systems are promising for providing\neasy access and reducing medical costs. Building end-to-end ADD dialogue\nsystems requires dialogue training datasets. However, to the best of our\nknowledge, there is no publicly available ADD dialogue dataset in English\n(although non-English datasets exist). Driven by this, we introduce MDDial, the\nfirst differential diagnosis dialogue dataset in English which can aid to build\nand evaluate end-to-end ADD dialogue systems. Additionally, earlier studies\npresent the accuracy of diagnosis and symptoms either individually or as a\ncombined weighted score. This method overlooks the connection between the\nsymptoms and the diagnosis. We introduce a unified score for the ADD system\nthat takes into account the interplay between symptoms and diagnosis. This\nscore also indicates the system's reliability. To the end, we train two\nmoderate-size of language models on MDDial. Our experiments suggest that while\nthese language models can perform well on many natural language understanding\ntasks, including dialogue tasks in the general domain, they struggle to relate\nrelevant symptoms and disease and thus have poor performance on MDDial. MDDial\nwill be released publicly to aid the study of ADD dialogue research.",
            "author": [
                "Srija Macherla",
                "Man Luo",
                "Mihir Parmar",
                "Chitta Baral"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08147v1",
                "http://arxiv.org/pdf/2308.08147v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08125v1",
            "title": "Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals",
            "updated": "2023-08-16T03:31:30Z",
            "published": "2023-08-16T03:31:30Z",
            "summary": "Millimeter wave (mmWave) based speech recognition provides more possibility\nfor audio-related applications, such as conference speech transcription and\neavesdropping. However, considering the practicality in real scenarios, latency\nand recognizable vocabulary size are two critical factors that cannot be\noverlooked. In this paper, we propose Radio2Text, the first mmWave-based system\nfor streaming automatic speech recognition (ASR) with a vocabulary size\nexceeding 13,000 words. Radio2Text is based on a tailored streaming Transformer\nthat is capable of effectively learning representations of speech-related\nfeatures, paving the way for streaming ASR with a large vocabulary. To\nalleviate the deficiency of streaming networks unable to access entire future\ninputs, we propose the Guidance Initialization that facilitates the transfer of\nfeature knowledge related to the global context from the non-streaming\nTransformer to the tailored streaming Transformer through weight inheritance.\nFurther, we propose a cross-modal structure based on knowledge distillation\n(KD), named cross-modal KD, to mitigate the negative effect of low quality\nmmWave signals on recognition performance. In the cross-modal KD, the audio\nstreaming Transformer provides feature and response guidance that inherit\nfruitful and accurate speech information to supervise the training of the\ntailored radio streaming Transformer. The experimental results show that our\nRadio2Text can achieve a character error rate of 5.7% and a word error rate of\n9.4% for the recognition of a vocabulary consisting of over 13,000 words.",
            "author": [
                "Running Zhao",
                "Jiangtao Yu",
                "Hang Zhao",
                "Edith C. H. Ngai"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610873",
                "http://arxiv.org/abs/2308.08125v1",
                "http://arxiv.org/pdf/2308.08125v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.HC",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08097v1",
            "title": "S-Mixup: Structural Mixup for Graph Neural Networks",
            "updated": "2023-08-16T02:08:46Z",
            "published": "2023-08-16T02:08:46Z",
            "summary": "Existing studies for applying the mixup technique on graphs mainly focus on\ngraph classification tasks, while the research in node classification is still\nunder-explored. In this paper, we propose a novel mixup augmentation for node\nclassification called Structural Mixup (S-Mixup). The core idea is to take into\naccount the structural information while mixing nodes. Specifically, S-Mixup\nobtains pseudo-labels for unlabeled nodes in a graph along with their\nprediction confidence via a Graph Neural Network (GNN) classifier. These serve\nas the criteria for the composition of the mixup pool for both inter and\nintra-class mixups. Furthermore, we utilize the edge gradient obtained from the\nGNN training and propose a gradient-based edge selection strategy for selecting\nedges to be attached to the nodes generated by the mixup. Through extensive\nexperiments on real-world benchmark datasets, we demonstrate the effectiveness\nof S-Mixup evaluated on the node classification task. We observe that S-Mixup\nenhances the robustness and generalization performance of GNNs, especially in\nheterophilous situations. The source code of S-Mixup can be found at\n\\url{https://github.com/SukwonYun/S-Mixup}",
            "author": [
                "Junghurn Kim",
                "Sukwon Yun",
                "Chanyoung Park"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615280",
                "http://arxiv.org/abs/2308.08097v1",
                "http://arxiv.org/pdf/2308.08097v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08082v1",
            "title": "A novel hybrid protocol for semiquantum key distribution and semiquantum\n  secret sharing",
            "updated": "2023-08-16T00:37:50Z",
            "published": "2023-08-16T00:37:50Z",
            "summary": "In this paper, a novel hybrid protocol for semiquantum key distribution\n(SQKD) and semiquantum secret sharing (SQSS) was constructed by using GHZ-like\nstates. This protocol is capable of establishing two different private keys\nbetween one quantum party and two semiquantum parties respectively, and making\ntwo semiquantum parties share another private key of the quantum party in the\nmeanwhile. The usages of delay lines, Pauli operations, Hadamard gates and\nquantum entanglement swapping are not required. Moreover, the semiquantum\nparties are not necessary to be equipped with any quantum memory. We validate\nin detail that this protocol resists various attacks from Eve, including the\nTrojan horse attacks, the entangle-measure attack, the double controlled-not\n(CNOT) attacks, the measure-resend attack and the intercept-resend attack. To\nour best knowledge, this protocol is the only protocol which possesses the\nfunctions of both SQKD and SQSS simultaneously until now.",
            "author": [
                "Tian-Yu Ye",
                "Xiao Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08082v1",
                "http://arxiv.org/pdf/2308.08082v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08073v1",
            "title": "Hamilton-Jacobi equations in metric spaces",
            "updated": "2023-08-15T23:58:46Z",
            "published": "2023-08-15T23:58:46Z",
            "summary": "These are lecture notes for our minicourse at OIST Summer Graduate School\n\"Analysis and Partial Differential Equations\" on June 12-17, 2023. We give an\noverview and collect a few important results concerning the well-posedness of\nHamilton-Jacobi equations in metric spaces, especially several recently\nproposed notions of metric viscosity solutions to the eikonal equation. Basic\nknowledge about metric spaces and a review of viscosity solution theory in the\nEuclidean spaces are also presented.",
            "author": [
                "Qing Liu",
                "Xiaodan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08073v1",
                "http://arxiv.org/pdf/2308.08073v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35R15, 49L25, 35F30, 35D40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08072v1",
            "title": "Decentralized Graph Neural Network for Privacy-Preserving Recommendation",
            "updated": "2023-08-15T23:56:44Z",
            "published": "2023-08-15T23:56:44Z",
            "summary": "Building a graph neural network (GNN)-based recommender system without\nviolating user privacy proves challenging. Existing methods can be divided into\nfederated GNNs and decentralized GNNs. But both methods have undesirable\neffects, i.e., low communication efficiency and privacy leakage. This paper\nproposes DGREC, a novel decentralized GNN for privacy-preserving\nrecommendations, where users can choose to publicize their interactions. It\nincludes three stages, i.e., graph construction, local gradient calculation,\nand global gradient passing. The first stage builds a local inner-item\nhypergraph for each user and a global inter-user graph. The second stage models\nuser preference and calculates gradients on each local device. The third stage\ndesigns a local differential privacy mechanism named secure gradient-sharing,\nwhich proves strong privacy-preserving of users' private data. We conduct\nextensive experiments on three public datasets to validate the consistent\nsuperiority of our framework.",
            "author": [
                "Xiaolin Zheng",
                "Zhongyu Wang",
                "Chaochao Chen",
                "Jiashu Qian",
                "Yao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08072v1",
                "http://arxiv.org/pdf/2308.08072v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08071v1",
            "title": "Freshness or Accuracy, Why Not Both? Addressing Delayed Feedback via\n  Dynamic Graph Neural Networks",
            "updated": "2023-08-15T23:49:07Z",
            "published": "2023-08-15T23:49:07Z",
            "summary": "The delayed feedback problem is one of the most pressing challenges in\npredicting the conversion rate since users' conversions are always delayed in\nonline commercial systems. Although new data are beneficial for continuous\ntraining, without complete feedback information, i.e., conversion labels,\ntraining algorithms may suffer from overwhelming fake negatives. Existing\nmethods tend to use multitask learning or design data pipelines to solve the\ndelayed feedback problem. However, these methods have a trade-off between data\nfreshness and label accuracy. In this paper, we propose Delayed Feedback\nModeling by Dynamic Graph Neural Network (DGDFEM). It includes three stages,\ni.e., preparing a data pipeline, building a dynamic graph, and training a CVR\nprediction model. In the model training, we propose a novel graph convolutional\nmethod named HLGCN, which leverages both high-pass and low-pass filters to deal\nwith conversion and non-conversion relationships. The proposed method achieves\nboth data freshness and label accuracy. We conduct extensive experiments on\nthree industry datasets, which validate the consistent superiority of our\nmethod.",
            "author": [
                "Xiaolin Zheng",
                "Zhongyu Wang",
                "Chaochao Chen",
                "Feng Zhu",
                "Jiashu Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08071v1",
                "http://arxiv.org/pdf/2308.08071v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08061v1",
            "title": "The Costly Dilemma: Generalization, Evaluation and Cost-Optimal\n  Deployment of Large Language Models",
            "updated": "2023-08-15T22:26:58Z",
            "published": "2023-08-15T22:26:58Z",
            "summary": "When deploying machine learning models in production for any\nproduct/application, there are three properties that are commonly desired.\nFirst, the models should be generalizable, in that we can extend it to further\nuse cases as our knowledge of the domain area develops. Second they should be\nevaluable, so that there are clear metrics for performance and the calculation\nof those metrics in production settings are feasible. Finally, the deployment\nshould be cost-optimal as far as possible. In this paper we propose that these\nthree objectives (i.e. generalization, evaluation and cost-optimality) can\noften be relatively orthogonal and that for large language models, despite\ntheir performance over conventional NLP models, enterprises need to carefully\nassess all the three factors before making substantial investments in this\ntechnology. We propose a framework for generalization, evaluation and\ncost-modeling specifically tailored to large language models, offering insights\ninto the intricacies of development, deployment and management for these large\nlanguage models.",
            "author": [
                "Abi Aryan",
                "Aakash Kumar Nain",
                "Andrew McMahon",
                "Lucas Augusto Meyer",
                "Harpreet Singh Sahota"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08061v1",
                "http://arxiv.org/pdf/2308.08061v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08050v1",
            "title": "Exploring the Potential of Qutrits for Quantum Optimization of Graph\n  Coloring",
            "updated": "2023-08-15T21:31:37Z",
            "published": "2023-08-15T21:31:37Z",
            "summary": "Recent hardware demonstrations and advances in circuit compilation have made\nquantum computing with higher-dimensional systems (qudits) on near-term devices\nan attractive possibility. Some problems have more natural or optimal encodings\nusing qudits over qubits. We explore this potential by formulating graph\n3-coloring, a well-known and difficult problem with practical applications,\nusing qutrits, and solve it using the quantum approximate optimization\nalgorithm (QAOA). Qutrit-based cost and mixer Hamiltonians are constructed\nalong with appropriate quantum circuits using qutrit gates. We run noiseless\nsimulations using PennyLane to compare the formulation against qubit-based\nQAOA, and analyze the solution quality and resources required. Preliminary\nresults show that the qutrit encoding finds more accurate solutions with a\ncomparable set of hyperparameters, uses half as many qudits, and has a notably\nsmaller circuit depth per layer than an efficient qubit encoding. This work\nsuggests that qutrits may be useful in solving some problems on near-term\ndevices, however further work is required to assess their potential in a noisy\nenvironment.",
            "author": [
                "Gabriel Bottrill",
                "Mudit Pandey",
                "Olivia Di Matteo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08050v1",
                "http://arxiv.org/pdf/2308.08050v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08047v1",
            "title": "Correlated vs. Uncorrelated Randomness in Adversarial Congestion Team\n  Games",
            "updated": "2023-08-15T21:20:38Z",
            "published": "2023-08-15T21:20:38Z",
            "summary": "We consider team zero-sum network congestion games with $n$ senders playing\nagainst $k$ interceptors over a graph $G$. The senders aim to minimize their\ncollective cost of sending messages over paths in $G$, which is an aggregation\nof edge costs, while the interceptors aim to maximize the collective cost by\nincreasing some of these edge costs. To evade the interceptors, the senders\nwill usually use randomized strategies. We consider two cases, the correlated\ncase when senders have access to a shared source of randomness, and the\nuncorrelated case, when each sender has access to only its own source of\nrandomness. We study the additional cost that uncorrelated senders have to\nbear, specifically by comparing the costs incurred by senders in cost-minimal\nNash Equilibria when senders can and cannot share randomness.\n  We prove that for an intuitive strict subset of cost functions, the ratio\nbetween correlated and uncorrelated costs at equilibrium is\n$O(\\min(m_c(G),n))$, where $m_c(G)$ is the mincut size of $G$. This bound is\nmuch milder compared to the most general case, where an upper bound of\n$\\Omega((m_c(G))^{n-1})$ on the ratio is known. We show that the senders can\napproximate their optimal play by playing simple strategies which select paths\nuniformly at random from subsets of disjoint paths. We then focus on two\nnatural cost functions. For the first, we prove that one of the simple\nstrategies above is an optimal strategy for senders over graphs with disjoint\npaths. In complete contrast, for the second cost function we prove that none of\nthese simple strategies is optimal for the senders over these graphs, unless\nthe game instance admits a trivial optimal senders strategy.",
            "author": [
                "Idan Orzech",
                "Martin Rinard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08047v1",
                "http://arxiv.org/pdf/2308.08047v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08046v1",
            "title": "Regret Lower Bounds in Multi-agent Multi-armed Bandit",
            "updated": "2023-08-15T21:20:24Z",
            "published": "2023-08-15T21:20:24Z",
            "summary": "Multi-armed Bandit motivates methods with provable upper bounds on regret and\nalso the counterpart lower bounds have been extensively studied in this\ncontext. Recently, Multi-agent Multi-armed Bandit has gained significant\ntraction in various domains, where individual clients face bandit problems in a\ndistributed manner and the objective is the overall system performance,\ntypically measured by regret. While efficient algorithms with regret upper\nbounds have emerged, limited attention has been given to the corresponding\nregret lower bounds, except for a recent lower bound for adversarial settings,\nwhich, however, has a gap with let known upper bounds. To this end, we herein\nprovide the first comprehensive study on regret lower bounds across different\nsettings and establish their tightness. Specifically, when the graphs exhibit\ngood connectivity properties and the rewards are stochastically distributed, we\ndemonstrate a lower bound of order $O(\\log T)$ for instance-dependent bounds\nand $\\sqrt{T}$ for mean-gap independent bounds which are tight. Assuming\nadversarial rewards, we establish a lower bound $O(T^{\\frac{2}{3}})$ for\nconnected graphs, thereby bridging the gap between the lower and upper bound in\nthe prior work. We also show a linear regret lower bound when the graph is\ndisconnected. While previous works have explored these settings with upper\nbounds, we provide a thorough study on tight lower bounds.",
            "author": [
                "Mengfan Xu",
                "Diego Klabjan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08046v1",
                "http://arxiv.org/pdf/2308.08046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08041v1",
            "title": "Typical sofic entropy and local limits for free group shift systems",
            "updated": "2023-08-15T21:06:04Z",
            "published": "2023-08-15T21:06:04Z",
            "summary": "We show that for any invariant measure $\\mu$ on a free group shift system,\nthere are two numbers $h^\\flat \\leq h^\\sharp$ which in some sense are the\ntypical upper and lower sofic entropy values. We also give a condition under\nwhich $h^\\flat = h^\\sharp = \\mathrm{f}(\\mu)$, where $\\mathrm{f}$ is the\nannealed entropy (also called the f invariant). This can be used to compute\ntypical local limits of finitary Gibbs states over sequences of random regular\ngraphs. As examples, we work out typical local limits of the Ising and Potts\nmodels.\n  We also show that, for Markov chains, the Kesten--Stigum second-eigenvalue\nreconstruction criterion actually implies there are no good models over a\ntypical sofic approximation (i.e. $h^\\sharp = -\\infty$). In particular, we have\nan exact value for the typical entropy $h^\\flat = h^\\sharp$ of the\nfree-boundary Ising state: it is equal to the annealed entropy $\\mathrm{f}$ for\ninteraction strengths up to the reconstruction threshold, after which it drops\nabruptly to $-\\infty$.",
            "author": [
                "Christopher Shriver"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08041v1",
                "http://arxiv.org/pdf/2308.08041v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08038v2",
            "title": "Deep Learning Framework for Spleen Volume Estimation from 2D\n  Cross-sectional Views",
            "updated": "2023-08-17T16:21:02Z",
            "published": "2023-08-15T20:58:42Z",
            "summary": "Abnormal spleen enlargement (splenomegaly) is regarded as a clinical\nindicator for a range of conditions, including liver disease, cancer and blood\ndiseases. While spleen length measured from ultrasound images is a commonly\nused surrogate for spleen size, spleen volume remains the gold standard metric\nfor assessing splenomegaly and the severity of related clinical conditions.\nComputed tomography is the main imaging modality for measuring spleen volume,\nbut it is less accessible in areas where there is a high prevalence of\nsplenomegaly (e.g., the Global South). Our objective was to enable automated\nspleen volume measurement from 2D cross-sectional segmentations, which can be\nobtained from ultrasound imaging. In this study, we describe a variational\nautoencoder-based framework to measure spleen volume from single- or dual-view\n2D spleen segmentations. We propose and evaluate three volume estimation\nmethods within this framework. We also demonstrate how 95% confidence intervals\nof volume estimates can be produced to make our method more clinically useful.\nOur best model achieved mean relative volume accuracies of 86.62% and 92.58%\nfor single- and dual-view segmentations, respectively, surpassing the\nperformance of the clinical standard approach of linear regression using manual\nmeasurements and a comparative deep learning-based 2D-3D reconstruction-based\napproach. The proposed spleen volume estimation framework can be integrated\ninto standard clinical workflows which currently use 2D ultrasound images to\nmeasure spleen length. To the best of our knowledge, this is the first work to\nachieve direct 3D spleen volume estimation from 2D spleen segmentations.",
            "author": [
                "Zhen Yuan",
                "Esther Puyol-Anton",
                "Haran Jogeesvaran",
                "Baba Inusa",
                "Andrew P. King"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08038v2",
                "http://arxiv.org/pdf/2308.08038v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08028v1",
            "title": "A Graph Analysis of the Impact of COVID-19 on Emergency Housing Shelter\n  Access Patterns",
            "updated": "2023-08-15T20:34:56Z",
            "published": "2023-08-15T20:34:56Z",
            "summary": "This paper investigates how COVID-19 disrupted emergency housing shelter\naccess patterns in Calgary, Canada and what aspects of these changes persist to\nthe present day. This analysis will utilize aggregated shelter access data for\nover 40,000 individuals from seven major urban shelters dating from 2018 to the\npresent. A graph theoretic approach will be used to examine the journeys of\nindividuals between shelters before, during and after the COVID-19 lockdown\nperiod. This approach treats shelters as nodes in a graph and a person's\ntransition between shelter as an arrow or edge between nodes. This perspective\nis used to create both timeline and network diagrams that visualize shelter use\nand the flow of people between shelters. Statistical results are also presented\nthat illustrate the differences between the cohorts of people who only used\nshelter pre/post-lockdown, people who stayed in shelter during lockdown and\npeople who used shelter for the first time during lockdown. The results\ndemonstrate not only how a complex system of care responded to the pandemic but\nalso the characteristics of the people most likely to continue to rely on that\nsystem during an emergency.",
            "author": [
                "Geoffrey G. Messier"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08028v1",
                "http://arxiv.org/pdf/2308.08028v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08015v1",
            "title": "A basic introduction to ultrastable optical cavities for laser\n  stabilization",
            "updated": "2023-08-15T20:07:50Z",
            "published": "2023-08-15T20:07:50Z",
            "summary": "We give a simple introduction to the properties and use of ultrastable\noptical cavities, which are increasingly common in atomic and molecular physics\nlaboratories for stabilizing the frequency of lasers to linewidths at the kHz\nlevel or below. Although the physics of Fabry-Perot interferometers is part of\nstandard optics curricula, the specificities of ultrastable optical cavities,\nsuch as their high finesse, fixed length, and the need to operate under vacuum,\ncan make their use appear relatively challenging to newcomers. Our aim in this\nwork is to bridge the gap between generic knowledge about Fabry-Perot\nresonators and the specialized literature about ultrastable cavities. The\nintended audience includes students setting up an ultrastable cavity in a\nresearch laboratory for the first time and instructors designing advanced\nlaboratory courses on optics and laser stabilization techniques.",
            "author": [
                "Jamie A. Boyd",
                "Thierry Lahaye"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08015v1",
                "http://arxiv.org/pdf/2308.08015v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cond-mat.quant-gas",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08004v1",
            "title": "The Mastery Rubric for Statistics and Data Science: promoting coherence\n  and consistency in data science education and training",
            "updated": "2023-08-15T19:36:52Z",
            "published": "2023-08-15T19:36:52Z",
            "summary": "Consensus based publications of both competencies and undergraduate\ncurriculum guidance documents targeting data science instruction for higher\neducation have recently been published. Recommendations for curriculum features\nfrom diverse sources may not result in consistent training across programs. A\nMastery Rubric was developed that prioritizes the promotion and documentation\nof formal growth as well as the development of independence needed for the 13\nrequisite knowledge, skills, and abilities for professional practice in\nstatistics and data science, SDS. The Mastery Rubric, MR, driven curriculum can\nemphasize computation, statistics, or a third discipline in which the other\nwould be deployed or, all three can be featured. The MR SDS supports each of\nthese program structures while promoting consistency with international,\nconsensus based, curricular recommendations for statistics and data science,\nand allows 'statistics', 'data science', and 'statistics and data science'\ncurricula to consistently educate students with a focus on increasing learners\nindependence. The Mastery Rubric construct integrates findings from the\nlearning sciences, cognitive and educational psychology, to support teachers\nand students through the learning enterprise. The MR SDS will support higher\neducation as well as the interests of business, government, and academic work\nforce development, bringing a consistent framework to address challenges that\nexist for a domain that is claimed to be both an independent discipline and\npart of other disciplines, including computer science, engineering, and\nstatistics. The MR-SDS can be used for development or revision of an evaluable\ncurriculum that will reliably support the preparation of early e.g.,\nundergraduate degree programs, middle e.g., upskilling and training programs,\nand late e.g., doctoral level training practitioners.",
            "author": [
                "Rochelle E. Tractenberg",
                "Donna LaLonde",
                "Suzanne Thornton"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08004v1",
                "http://arxiv.org/pdf/2308.08004v1"
            ],
            "primary_category": "stat.OT",
            "category": [
                "stat.OT",
                "62R07, 9700, 97B70, 97C30, 97kxx, 97m10",
                "E.0; E.m; G.3; J.0; J.m; K.3; K.7; K.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07988v1",
            "title": "ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning\n  Questions to Facilitate Deeper Understanding",
            "updated": "2023-08-15T18:44:47Z",
            "published": "2023-08-15T18:44:47Z",
            "summary": "Academic reading is a key component of higher education, and serves as a\nbasis for critical thinking, knowledge acquisition and effective communication.\nResearch shows many students struggle with comprehension and analysis tasks\nwith academic texts, despite the central importance of academic reading to\nsuccess in higher education. Undergraduates and researchers need to internalize\ndense literature to scaffold their own work upon it. This reading task is\ntime-consuming and difficult to do. Oftentimes, students struggle to actively\nand critically engage and as a result attain merely a cursory understanding of\na paper's contents, or worse, incorrectly interpret the text. How, then, can we\nprovide a means to more easily digest a text whilst also facilitating\nmeaningful, critical engagement and understanding? This paper locates itself\nwithin the broader field of Human-Computer Interaction (HCI) to implement an\naugmented reading interface that leverages the power of ChatGPT to\nintelligently generate and co-locate comprehension and analysis questions in an\nacademic paper, thereby making the paper more digestible with the end goal of\nfacilitating deeper understanding, and developing critical reading skills.",
            "author": [
                "Liam Richards Maldonado"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07988v1",
                "http://arxiv.org/pdf/2308.07988v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07973v1",
            "title": "\"Beware of deception\": Detecting Half-Truth and Debunking it through\n  Controlled Claim Editing",
            "updated": "2023-08-15T18:21:26Z",
            "published": "2023-08-15T18:21:26Z",
            "summary": "The prevalence of half-truths, which are statements containing some truth but\nthat are ultimately deceptive, has risen with the increasing use of the\ninternet. To help combat this problem, we have created a comprehensive pipeline\nconsisting of a half-truth detection model and a claim editing model. Our\napproach utilizes the T5 model for controlled claim editing; \"controlled\" here\nmeans precise adjustments to select parts of a claim. Our methodology achieves\nan average BLEU score of 0.88 (on a scale of 0-1) and a disinfo-debunk score of\n85% on edited claims. Significantly, our T5-based approach outperforms other\nLanguage Models such as GPT2, RoBERTa, PEGASUS, and Tailor, with average\nimprovements of 82%, 57%, 42%, and 23% in disinfo-debunk scores, respectively.\nBy extending the LIAR PLUS dataset, we achieve an F1 score of 82% for the\nhalf-truth detection model, setting a new benchmark in the field. While\nprevious attempts have been made at half-truth detection, our approach is, to\nthe best of our knowledge, the first to attempt to debunk half-truths.",
            "author": [
                "Sandeep Singamsetty",
                "Nishtha Madaan",
                "Sameep Mehta",
                "Varad Bhatnagar",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07973v1",
                "http://arxiv.org/pdf/2308.07973v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07972v1",
            "title": "PKE-RRT: Efficient Multi-Goal Path Finding Algorithm Driven by\n  Multi-Task Learning Model",
            "updated": "2023-08-15T18:21:08Z",
            "published": "2023-08-15T18:21:08Z",
            "summary": "Multi-goal path finding (MGPF) aims to find a closed and collision-free path\nto visit a sequence of goals orderly. As a physical travelling salesman\nproblem, an undirected complete graph with accurate weights is crucial for\ndetermining the visiting order. Lack of prior knowledge of local paths between\nvertices poses challenges in meeting the optimality and efficiency requirements\nof algorithms. In this study, a multi-task learning model designated Prior\nKnowledge Extraction (PKE), is designed to estimate the local path length\nbetween pairwise vertices as the weights of the graph. Simultaneously, a\npromising region and a guideline are predicted as heuristics for the\npath-finding process. Utilizing the outputs of the PKE model, a variant of\nRapidly-exploring Random Tree (RRT) is proposed known as PKE-RRT. It\neffectively tackles the MGPF problem by a local planner incorporating a\nprioritized visiting order, which is obtained from the complete graph.\nFurthermore, the predicted region and guideline facilitate efficient\nexploration of the tree structure, enabling the algorithm to rapidly provide a\nsub-optimal solution. Extensive numerical experiments demonstrate the\noutstanding performance of the PKE-RRT for the MGPF problem with a different\nnumber of goals, in terms of calculation time, path cost, sample number, and\nsuccess rate.",
            "author": [
                "Yuan Huang",
                "Cheng-Tien Tsao",
                "Kairui Gu",
                "Hee-Hyol Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07972v1",
                "http://arxiv.org/pdf/2308.07972v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07915v1",
            "title": "High-threshold and low-overhead fault-tolerant quantum memory",
            "updated": "2023-08-15T17:55:12Z",
            "published": "2023-08-15T17:55:12Z",
            "summary": "Quantum error correction becomes a practical possibility only if the physical\nerror rate is below a threshold value that depends on a particular quantum\ncode, syndrome measurement circuit, and a decoding algorithm. Here we present\nan end-to-end quantum error correction protocol that implements fault-tolerant\nmemory based on a family of LDPC codes with a high encoding rate that achieves\nan error threshold of $0.8\\%$ for the standard circuit-based noise model. This\nis on par with the surface code which has remained an uncontested leader in\nterms of its high error threshold for nearly 20 years. The full syndrome\nmeasurement cycle for a length-$n$ code in our family requires $n$ ancillary\nqubits and a depth-7 circuit composed of nearest-neighbor CNOT gates. The\nrequired qubit connectivity is a degree-6 graph that consists of two\nedge-disjoint planar subgraphs. As a concrete example, we show that 12 logical\nqubits can be preserved for ten million syndrome cycles using 288 physical\nqubits in total, assuming the physical error rate of $0.1\\%$. We argue that\nachieving the same level of error suppression on 12 logical qubits with the\nsurface code would require more than 4000 physical qubits. Our findings bring\ndemonstrations of a low-overhead fault-tolerant quantum memory within the reach\nof near-term quantum processors.",
            "author": [
                "Sergey Bravyi",
                "Andrew W. Cross",
                "Jay M. Gambetta",
                "Dmitri Maslov",
                "Patrick Rall",
                "Theodore J. Yoder"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07915v1",
                "http://arxiv.org/pdf/2308.07915v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07902v1",
            "title": "Through the Lens of Core Competency: Survey on Evaluation of Large\n  Language Models",
            "updated": "2023-08-15T17:40:34Z",
            "published": "2023-08-15T17:40:34Z",
            "summary": "From pre-trained language model (PLM) to large language model (LLM), the\nfield of natural language processing (NLP) has witnessed steep performance\ngains and wide practical uses. The evaluation of a research field guides its\ndirection of improvement. However, LLMs are extremely hard to thoroughly\nevaluate for two reasons. First of all, traditional NLP tasks become inadequate\ndue to the excellent performance of LLM. Secondly, existing evaluation tasks\nare difficult to keep up with the wide range of applications in real-world\nscenarios. To tackle these problems, existing works proposed various benchmarks\nto better evaluate LLMs. To clarify the numerous evaluation tasks in both\nacademia and industry, we investigate multiple papers concerning LLM\nevaluations. We summarize 4 core competencies of LLM, including reasoning,\nknowledge, reliability, and safety. For every competency, we introduce its\ndefinition, corresponding benchmarks, and metrics. Under this competency\narchitecture, similar tasks are combined to reflect corresponding ability,\nwhile new tasks can also be easily added into the system. Finally, we give our\nsuggestions on the future direction of LLM's evaluation.",
            "author": [
                "Ziyu Zhuang",
                "Qiguang Chen",
                "Longxuan Ma",
                "Mingda Li",
                "Yi Han",
                "Yushan Qian",
                "Haopeng Bai",
                "Zixian Feng",
                "Weinan Zhang",
                "Ting Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07902v1",
                "http://arxiv.org/pdf/2308.07902v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07898v1",
            "title": "A Foundation LAnguage-Image model of the Retina (FLAIR): Encoding expert\n  knowledge in text supervision",
            "updated": "2023-08-15T17:39:52Z",
            "published": "2023-08-15T17:39:52Z",
            "summary": "Foundation vision-language models are currently transforming computer vision,\nand are on the rise in medical imaging fueled by their very promising\ngeneralization capabilities. However, the initial attempts to transfer this new\nparadigm to medical imaging have shown less impressive performances than those\nobserved in other domains, due to the significant domain shift and the complex,\nexpert domain knowledge inherent to medical-imaging tasks. Motivated by the\nneed for domain-expert foundation models, we present FLAIR, a pre-trained\nvision-language model for universal retinal fundus image understanding. To this\nend, we compiled 37 open-access, mostly categorical fundus imaging datasets\nfrom various sources, with up to 97 different target conditions and 284,660\nimages. We integrate the expert's domain knowledge in the form of descriptive\ntextual prompts, during both pre-training and zero-shot inference, enhancing\nthe less-informative categorical supervision of the data. Such a textual\nexpert's knowledge, which we compiled from the relevant clinical literature and\ncommunity standards, describes the fine-grained features of the pathologies as\nwell as the hierarchies and dependencies between them. We report comprehensive\nevaluations, which illustrate the benefit of integrating expert knowledge and\nthe strong generalization capabilities of FLAIR under difficult scenarios with\ndomain shifts or unseen categories. When adapted with a lightweight linear\nprobe, FLAIR outperforms fully-trained, dataset-focused models, more so in the\nfew-shot regimes. Interestingly, FLAIR outperforms by a large margin more\ngeneralist, larger-scale image-language models, which emphasizes the potential\nof embedding experts' domain knowledge and the limitations of generalist models\nin medical imaging.",
            "author": [
                "Julio Silva-Rodriguez",
                "Hadi Chakor",
                "Riadh Kobbi",
                "Jose Dolz",
                "Ismail Ben Ayed"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07898v1",
                "http://arxiv.org/pdf/2308.07898v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07895v2",
            "title": "Roses Have Thorns: Understanding the Downside of Oncological Care\n  Delivery Through Visual Analytics and Sequential Rule Mining",
            "updated": "2023-09-26T22:19:52Z",
            "published": "2023-08-15T17:36:18Z",
            "summary": "Personalized head and neck cancer therapeutics have greatly improved survival\nrates for patients, but are often leading to understudied long-lasting symptoms\nwhich affect quality of life. Sequential rule mining (SRM) is a promising\nunsupervised machine learning method for predicting longitudinal patterns in\ntemporal data which, however, can output many repetitive patterns that are\ndifficult to interpret without the assistance of visual analytics. We present a\ndata-driven, human-machine analysis visual system developed in collaboration\nwith SRM model builders in cancer symptom research, which facilitates\nmechanistic knowledge discovery in large scale, multivariate cohort symptom\ndata. Our system supports multivariate predictive modeling of post-treatment\nsymptoms based on during-treatment symptoms. It supports this goal through an\nSRM, clustering, and aggregation back end, and a custom front end to help\ndevelop and tune the predictive models. The system also explains the resulting\npredictions in the context of therapeutic decisions typical in personalized\ncare delivery. We evaluate the resulting models and system with an\ninterdisciplinary group of modelers and head and neck oncology researchers. The\nresults demonstrate that our system effectively supports clinical and symptom\nresearch.",
            "author": [
                "Carla Floricel",
                "Andrew Wentzel",
                "Abdallah Mohamed",
                "C. David Fuller",
                "Guadalupe Canahuate",
                "G. Elisabeta Marai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07895v2",
                "http://arxiv.org/pdf/2308.07895v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07889v1",
            "title": "A Comprehensive Study on Knowledge Graph Embedding over Relational\n  Patterns Based on Rule Learning",
            "updated": "2023-08-15T17:30:57Z",
            "published": "2023-08-15T17:30:57Z",
            "summary": "Knowledge Graph Embedding (KGE) has proven to be an effective approach to\nsolving the Knowledge Graph Completion (KGC) task. Relational patterns which\nrefer to relations with specific semantics exhibiting graph patterns are an\nimportant factor in the performance of KGE models. Though KGE models'\ncapabilities are analyzed over different relational patterns in theory and a\nrough connection between better relational patterns modeling and better\nperformance of KGC has been built, a comprehensive quantitative analysis on KGE\nmodels over relational patterns remains absent so it is uncertain how the\ntheoretical support of KGE to a relational pattern contributes to the\nperformance of triples associated to such a relational pattern. To address this\nchallenge, we evaluate the performance of 7 KGE models over 4 common relational\npatterns on 2 benchmarks, then conduct an analysis in theory, entity frequency,\nand part-to-whole three aspects and get some counterintuitive conclusions.\nFinally, we introduce a training-free method Score-based Patterns Adaptation\n(SPA) to enhance KGE models' performance over various relational patterns. This\napproach is simple yet effective and can be applied to KGE models without\nadditional training. Our experimental results demonstrate that our method\ngenerally enhances performance over specific relational patterns. Our source\ncode is available from GitHub at\nhttps://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns.",
            "author": [
                "Long Jin",
                "Zhen Yao",
                "Mingyang Chen",
                "Huajun Chen",
                "Wen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07889v1",
                "http://arxiv.org/pdf/2308.07889v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07883v1",
            "title": "Towards Temporal Edge Regression: A Case Study on Agriculture Trade\n  Between Nations",
            "updated": "2023-08-15T17:13:16Z",
            "published": "2023-08-15T17:13:16Z",
            "summary": "Recently, Graph Neural Networks (GNNs) have shown promising performance in\ntasks on dynamic graphs such as node classification, link prediction and graph\nregression. However, few work has studied the temporal edge regression task\nwhich has important real-world applications. In this paper, we explore the\napplication of GNNs to edge regression tasks in both static and dynamic\nsettings, focusing on predicting food and agriculture trade values between\nnations. We introduce three simple yet strong baselines and comprehensively\nevaluate one static and three dynamic GNN models using the UN Trade dataset.\nOur experimental results reveal that the baselines exhibit remarkably strong\nperformance across various settings, highlighting the inadequacy of existing\nGNNs. We also find that TGN outperforms other GNN models, suggesting TGN is a\nmore appropriate choice for edge regression tasks. Moreover, we note that the\nproportion of negative edges in the training samples significantly affects the\ntest performance. The companion source code can be found at:\nhttps://github.com/scylj1/GNN_Edge_Regression.",
            "author": [
                "Lekang Jiang",
                "Caiqi Zhang",
                "Farimah Poursafaei",
                "Shenyang Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07883v1",
                "http://arxiv.org/pdf/2308.07883v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07876v1",
            "title": "Synthesizing Political Zero-Shot Relation Classification via Codebook\n  Knowledge, NLI, and ChatGPT",
            "updated": "2023-08-15T16:41:53Z",
            "published": "2023-08-15T16:41:53Z",
            "summary": "Recent supervised models for event coding vastly outperform pattern-matching\nmethods. However, their reliance solely on new annotations disregards the vast\nknowledge within expert databases, hindering their applicability to\nfine-grained classification. To address these limitations, we explore zero-shot\napproaches for political event ontology relation classification, by leveraging\nknowledge from established annotation codebooks. Our study encompasses both\nChatGPT and a novel natural language inference (NLI) based approach named ZSP.\nZSP adopts a tree-query framework that deconstructs the task into context,\nmodality, and class disambiguation levels. This framework improves\ninterpretability, efficiency, and adaptability to schema changes. By conducting\nextensive experiments on our newly curated datasets, we pinpoint the\ninstability issues within ChatGPT and highlight the superior performance of\nZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained\nRootcode classification. ZSP demonstrates competitive performance compared to\nsupervised BERT models, positioning it as a valuable tool for event record\nvalidation and ontology development. Our work underscores the potential of\nleveraging transfer learning and existing expertise to enhance the efficiency\nand scalability of research in the field.",
            "author": [
                "Yibo Hu",
                "Erick Skorupa Parolin",
                "Latifur Khan",
                "Patrick T. Brandt",
                "Javier Osorio",
                "Vito J. D'Orazio"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07876v1",
                "http://arxiv.org/pdf/2308.07876v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07873v2",
            "title": "Near-Optimal Last-iterate Convergence of Policy Optimization in Zero-sum\n  Polymatrix Markov games",
            "updated": "2023-08-16T17:17:48Z",
            "published": "2023-08-15T16:40:10Z",
            "summary": "Computing approximate Nash equilibria in multi-player general-sum Markov\ngames is a computationally intractable task. However, multi-player Markov games\nwith certain cooperative or competitive structures might circumvent this\nintractability. In this paper, we focus on multi-player zero-sum polymatrix\nMarkov games, where players interact in a pairwise fashion while remain overall\ncompetitive. To the best of our knowledge, we propose the first policy\noptimization algorithm called Entropy-Regularized\nOptimistic-Multiplicative-Weights-Update (ER-OMWU) for finding approximate Nash\nequilibria in finite-horizon zero-sum polymatrix Markov games with full\ninformation feedback. We provide last-iterate convergence guarantees for\nfinding an $\\epsilon$-approximate Nash equilibrium within\n$\\tilde{O}(1/\\epsilon)$ iterations, which is near-optimal compared to the\noptimal $O(1/\\epsilon)$ iteration complexity in two-player zero-sum Markov\ngames, which is a degenerate case of zero-sum polymatrix games with only two\nplayers involved. Our algorithm combines the regularized and optimistic\nlearning dynamics with separated smooth value update within a single loop,\nwhere players update strategies in a symmetric and almost uncoupled manner. It\nprovides a natural dynamics for finding equilibria and is more probable to be\nadapted to a sample-efficient and fully decentralized implementation where only\npartial information feedback is available in the future.",
            "author": [
                "Zailin Ma",
                "Jiansheng Yang",
                "Zhihua Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07873v2",
                "http://arxiv.org/pdf/2308.07873v2"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07867v1",
            "title": "Graph-Structured Kernel Design for Power Flow Learning using Gaussian\n  Processes",
            "updated": "2023-08-15T16:34:37Z",
            "published": "2023-08-15T16:34:37Z",
            "summary": "This paper presents a physics-inspired graph-structured kernel designed for\npower flow learning using Gaussian Process (GP). The kernel, named the\nvertex-degree kernel (VDK), relies on latent decomposition of voltage-injection\nrelationship based on the network graph or topology. Notably, VDK design avoids\nthe need to solve optimization problems for kernel search. To enhance\nefficiency, we also explore a graph-reduction approach to obtain a VDK\nrepresentation with lesser terms. Additionally, we propose a novel\nnetwork-swipe active learning scheme, which intelligently selects sequential\ntraining inputs to accelerate the learning of VDK. Leveraging the additive\nstructure of VDK, the active learning algorithm performs a block-descent type\nprocedure on GP's predictive variance, serving as a proxy for information gain.\nSimulations demonstrate that the proposed VDK-GP achieves more than two fold\nsample complexity reduction, compared to full GP on medium scale 500-Bus and\nlarge scale 1354-Bus power systems. The network-swipe algorithm outperforms\nmean performance of 500 random trials on test predictions by two fold for\nmedium-sized 500-Bus systems and best performance of 25 random trials for\nlarge-scale 1354-Bus systems by 10%. Moreover, we demonstrate that the proposed\nmethod's performance for uncertainty quantification applications with\ndistributionally shifted testing data sets.",
            "author": [
                "Parikshit Pareek",
                "Deepjyoti Deka",
                "Sidhant Misra"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07867v1",
                "http://arxiv.org/pdf/2308.07867v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07948v1",
            "title": "Leveraging Symmetries in Pick and Place",
            "updated": "2023-08-15T16:16:29Z",
            "published": "2023-08-15T16:16:29Z",
            "summary": "Robotic pick and place tasks are symmetric under translations and rotations\nof both the object to be picked and the desired place pose. For example, if the\npick object is rotated or translated, then the optimal pick action should also\nrotate or translate. The same is true for the place pose; if the desired place\npose changes, then the place action should also transform accordingly. A\nrecently proposed pick and place framework known as Transporter Net captures\nsome of these symmetries, but not all. This paper analytically studies the\nsymmetries present in planar robotic pick and place and proposes a method of\nincorporating equivariant neural models into Transporter Net in a way that\ncaptures all symmetries. The new model, which we call Equivariant Transporter\nNet, is equivariant to both pick and place symmetries and can immediately\ngeneralize pick and place knowledge to different pick and place poses. We\nevaluate the new model empirically and show that it is much more sample\nefficient than the non-symmetric version, resulting in a system that can\nimitate demonstrated pick and place behavior using very few human\ndemonstrations on a variety of imitation learning tasks.",
            "author": [
                "Haojie Huang",
                "Dian Wang",
                "Arsh Tangri",
                "Robin Walters",
                "Robert Platt"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07948v1",
                "http://arxiv.org/pdf/2308.07948v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07851v1",
            "title": "An imperceptible connection between the Clebsch--Gordan coefficients of\n  $U_q(\\mathfrak{sl}_2)$ and the Terwilliger algebras of Grassmann graphs",
            "updated": "2023-08-15T15:55:18Z",
            "published": "2023-08-15T15:55:18Z",
            "summary": "The Clebsch--Gordan coefficients of $U(\\mathfrak{sl}_2)$ are expressible in\nterms of Hahn polynomials. The phenomenon can be explained by an algebra\nhomomorphism from the universal Hahn algebra $\\mathcal H$ into\n$U(\\mathfrak{sl}_2)\\otimes U(\\mathfrak{sl}_2)$. Let $\\Omega$ denote a finite\nset and $2^\\Omega$ denote the power set of $\\Omega$. It is generally known that\n$\\mathbb C^{2^\\Omega}$ supports a $U(\\mathfrak{sl}_2)$-module. Fix an element\n$x_0\\in 2^\\Omega$. By the linear isomorphism $\\mathbb C^{2^\\Omega}\\to \\mathbb\nC^{2^{\\Omega\\setminus x_0}}\\otimes \\mathbb C^{2^{x_0}}$ given by $x\\mapsto\n(x\\setminus x_0)\\otimes (x\\cap x_0)$ for all $x\\in 2^\\Omega$, this induces a\n$U(\\mathfrak{sl}_2)\\otimes U(\\mathfrak{sl}_2)$-module structure on $\\mathbb\nC^{2^\\Omega}$. Pulling back via the algebra homomorphism $\\mathcal H\\to\nU(\\mathfrak{sl}_2)\\otimes U(\\mathfrak{sl}_2)$, the $U(\\mathfrak{sl}_2)\\otimes\nU(\\mathfrak{sl}_2)$-module $\\mathbb C^{2^\\Omega}$ forms an $\\mathcal H$-module.\nThe $\\mathcal H$-module $\\mathbb C^{2^\\Omega}$ enfolds the Terwilliger algebra\nof a Johnson graph. This result connects these two seemingly irrelevant topics:\nThe Clebsch--Gordan coefficients of $U(\\mathfrak{sl}_2)$ and the Terwilliger\nalgebras of Johnson graphs. Unfortunately some steps break down in the\n$q$-analog case. By making detours, the imperceptible connection between the\nClebsch--Gordan coefficients of $U_q(\\mathfrak{sl}_2)$ and the Terwilliger\nalgebras of Grassmann graphs is successfully disclosed in this paper.",
            "author": [
                "Hau-Wen Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07851v1",
                "http://arxiv.org/pdf/2308.07851v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.QA",
                "05E30, 06A11, 16G30, 17B37, 33D45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07834v1",
            "title": "Simple and Efficient Partial Graph Adversarial Attack: A New Perspective",
            "updated": "2023-08-15T15:23:36Z",
            "published": "2023-08-15T15:23:36Z",
            "summary": "As the study of graph neural networks becomes more intensive and\ncomprehensive, their robustness and security have received great research\ninterest. The existing global attack methods treat all nodes in the graph as\ntheir attack targets. Although existing methods have achieved excellent\nresults, there is still considerable space for improvement. The key problem is\nthat the current approaches rigidly follow the definition of global attacks.\nThey ignore an important issue, i.e., different nodes have different robustness\nand are not equally resilient to attacks. From a global attacker's view, we\nshould arrange the attack budget wisely, rather than wasting them on highly\nrobust nodes. To this end, we propose a totally new method named partial graph\nattack (PGA), which selects the vulnerable nodes as attack targets. First, to\nselect the vulnerable items, we propose a hierarchical target selection policy,\nwhich allows attackers to only focus on easy-to-attack nodes. Then, we propose\na cost-effective anchor-picking policy to pick the most promising anchors for\nadding or removing edges, and a more aggressive iterative greedy-based attack\nmethod to perform more efficient attacks. Extensive experimental results\ndemonstrate that PGA can achieve significant improvements in both attack effect\nand attack efficiency compared to other existing graph global attack methods.",
            "author": [
                "Guanghui Zhu",
                "Mengyu Chen",
                "Chunfeng Yuan",
                "Yihua Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07834v1",
                "http://arxiv.org/pdf/2308.07834v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07827v2",
            "title": "Learning Better Keypoints for Multi-Object 6DoF Pose Estimation",
            "updated": "2023-11-10T02:42:47Z",
            "published": "2023-08-15T15:11:13Z",
            "summary": "We address the problem of keypoint selection, and find that the performance\nof 6DoF pose estimation methods can be improved when pre-defined keypoint\nlocations are learned, rather than being heuristically selected as has been the\nstandard approach. We found that accuracy and efficiency can be improved by\ntraining a graph network to select a set of disperse keypoints with similarly\ndistributed votes. These votes, learned by a regression network to accumulate\nevidence for the keypoint locations, can be regressed more accurately compared\nto previous heuristic keypoint algorithms. The proposed KeyGNet, supervised by\na combined loss measuring both Wasserstein distance and dispersion, learns the\ncolor and geometry features of the target objects to estimate optimal keypoint\nlocations. Experiments demonstrate the keypoints selected by KeyGNet improved\nthe accuracy for all evaluation metrics of all seven datasets tested, for three\nkeypoint voting methods. The challenging Occlusion LINEMOD dataset notably\nimproved ADD(S) by +16.4% on PVN3D, and all core BOP datasets showed an AR\nimprovement for all objects, of between +1% and +21.5%. There was also a\nnotable increase in performance when transitioning from single object to\nmultiple object training using KeyGNet keypoints, essentially eliminating the\nSISO-MIMO gap for Occlusion LINEMOD.",
            "author": [
                "Yangzheng Wu",
                "Michael Greenspan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07827v2",
                "http://arxiv.org/pdf/2308.07827v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07946v3",
            "title": "DSFNet: Dual-GCN and Location-fused Self-attention with Weighted Fast\n  Normalized Fusion for Polyps Segmentation",
            "updated": "2023-11-27T13:49:02Z",
            "published": "2023-08-15T15:07:14Z",
            "summary": "Polyps segmentation poses a significant challenge in medical imaging due to\nthe flat surface of polyps and their texture similarity to surrounding tissues.\nThis similarity gives rise to difficulties in establishing a clear boundary\nbetween polyps and the surrounding mucosa, leading to complications such as\nlocal overexposure and the presence of bright spot reflections in imaging. To\ncounter this problem, we propose a new dual graph convolution network\n(Dual-GCN) and location self-attention mechanisms with weighted fast\nnormalization fusion model, named DSFNet. First, we introduce a feature\nenhancement block module based on Dual-GCN module to enhance local spatial and\nstructural information extraction with fine granularity. Second, we introduce a\nlocation fused self-attention module to enhance the model's awareness and\ncapacity to capture global information. Finally, the weighted fast normalized\nfusion method with trainable weights is introduced to efficiently integrate the\nfeature maps from encoder, bottleneck, and decoder, thus promoting information\ntransmission and facilitating the semantic consistency. Experimental results\nshow that the proposed model surpasses other state-of-the-art models in gold\nstandard indicators, such as Dice, MAE, and IoU. Both quantitative and\nqualitative analysis indicate that the proposed model demonstrates exceptional\ncapability in polyps segmentation and has great potential clinical\nsignificance. We have shared our code on anonymous website for evaluation.",
            "author": [
                "Juntong Fan",
                "Debesh Jha",
                "Tieyong Zeng",
                "Dayang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07946v3",
                "http://arxiv.org/pdf/2308.07946v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07817v2",
            "title": "Quantifying the Cost of Learning in Queueing Systems",
            "updated": "2023-10-27T15:18:28Z",
            "published": "2023-08-15T14:50:12Z",
            "summary": "Queueing systems are widely applicable stochastic models with use cases in\ncommunication networks, healthcare, service systems, etc. Although their\noptimal control has been extensively studied, most existing approaches assume\nperfect knowledge of the system parameters. Of course, this assumption rarely\nholds in practice where there is parameter uncertainty, thus motivating a\nrecent line of work on bandit learning for queueing systems. This nascent\nstream of research focuses on the asymptotic performance of the proposed\nalgorithms.\n  In this paper, we argue that an asymptotic metric, which focuses on\nlate-stage performance, is insufficient to capture the intrinsic statistical\ncomplexity of learning in queueing systems which typically occurs in the early\nstage. Instead, we propose the Cost of Learning in Queueing (CLQ), a new metric\nthat quantifies the maximum increase in time-averaged queue length caused by\nparameter uncertainty. We characterize the CLQ of a single queue multi-server\nsystem, and then extend these results to multi-queue multi-server systems and\nnetworks of queues. In establishing our results, we propose a unified analysis\nframework for CLQ that bridges Lyapunov and bandit analysis, provides\nguarantees for a wide range of algorithms, and could be of independent\ninterest.",
            "author": [
                "Daniel Freund",
                "Thodoris Lykouris",
                "Wentao Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07817v2",
                "http://arxiv.org/pdf/2308.07817v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "cs.PF",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07816v2",
            "title": "FedCache: A Knowledge Cache-driven Federated Learning Architecture for\n  Personalized Edge Intelligence",
            "updated": "2023-08-31T08:03:54Z",
            "published": "2023-08-15T14:48:23Z",
            "summary": "Edge Intelligence (EI) allows Artificial Intelligence (AI) applications to\nrun at the edge, where data analysis and decision-making can be performed in\nreal-time and close to data sources. To protect data privacy and unify data\nsilos among end devices in EI, Federated Learning (FL) is proposed for\ncollaborative training of shared AI models across devices without compromising\ndata privacy. However, the prevailing FL approaches cannot guarantee model\ngeneralization and adaptation on heterogeneous clients. Recently, Personalized\nFederated Learning (PFL) has drawn growing awareness in EI, as it enables a\nproductive balance between local-specific training requirements inherent in\ndevices and global-generalized optimization objectives for satisfactory\nperformance. However, most existing PFL methods are based on the Parameters\nInteraction-based Architecture (PIA) represented by FedAvg, which causes\nunaffordable communication burdens due to large-scale parameters transmission\nbetween devices and the edge server. In contrast, Logits Interaction-based\nArchitecture (LIA) allows to update model parameters with logits transfer and\ngains the advantages of communication lightweight and heterogeneous on-device\nmodel allowance compared to PIA. Nevertheless, previous LIA methods attempt to\nachieve satisfactory performance either relying on unrealistic public datasets\nor increasing communication overhead for additional information transmission\nother than logits. To tackle this dilemma, we propose a knowledge cache-driven\nPFL architecture, named FedCache, which reserves a knowledge cache on the\nserver for fetching personalized knowledge from the samples with similar hashes\nto each given on-device sample. During the training phase, ensemble\ndistillation is applied to on-device models for constructive optimization with\npersonalized knowledge transferred from the server-side knowledge cache.",
            "author": [
                "Zhiyuan Wu",
                "Sheng Sun",
                "Yuwei Wang",
                "Min Liu",
                "Ke Xu",
                "Wen Wang",
                "Xuefeng Jiang",
                "Bo Gao",
                "Jinda Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07816v2",
                "http://arxiv.org/pdf/2308.07816v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08453v1",
            "title": "Tightest Admissible Shortest Path",
            "updated": "2023-08-15T14:39:05Z",
            "published": "2023-08-15T14:39:05Z",
            "summary": "The shortest path problem in graphs is fundamental to AI. Nearly all variants\nof the problem and relevant algorithms that solve them ignore edge-weight\ncomputation time and its common relation to weight uncertainty. This implies\nthat taking these factors into consideration can potentially lead to a\nperformance boost in relevant applications. Recently, a generalized framework\nfor weighted directed graphs was suggested, where edge-weight can be computed\n(estimated) multiple times, at increasing accuracy and run-time expense. We\nbuild on this framework to introduce the problem of finding the tightest\nadmissible shortest path (TASP); a path with the tightest suboptimality bound\non the optimal cost. This is a generalization of the shortest path problem to\nbounded uncertainty, where edge-weight uncertainty can be traded for\ncomputational cost. We present a complete algorithm for solving TASP, with\nguarantees on solution quality. Empirical evaluation supports the effectiveness\nof this approach.",
            "author": [
                "Eyal Weiss",
                "Ariel Felner",
                "Gal A. Kaminka"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08453v1",
                "http://arxiv.org/pdf/2308.08453v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.AI",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07806v1",
            "title": "Covariate-Assisted Bayesian Graph Learning for Heterogeneous Data",
            "updated": "2023-08-15T14:33:04Z",
            "published": "2023-08-15T14:33:04Z",
            "summary": "In a traditional Gaussian graphical model, data homogeneity is routinely\nassumed with no extra variables affecting the conditional independence. In\nmodern genomic datasets, there is an abundance of auxiliary information, which\noften gets under-utilized in determining the joint dependency structure. In\nthis article, we consider a Bayesian approach to model undirected graphs\nunderlying heterogeneous multivariate observations with additional assistance\nfrom covariates. Building on product partition models, we propose a novel\ncovariate-dependent Gaussian graphical model that allows graphs to vary with\ncovariates so that observations whose covariates are similar share a similar\nundirected graph. To efficiently embed Gaussian graphical models into our\nproposed framework, we explore both Gaussian likelihood and pseudo-likelihood\nfunctions. For Gaussian likelihood, a G-Wishart distribution is used as a\nnatural conjugate prior, and for the pseudo-likelihood, a product of\nGaussian-conditionals is used. Moreover, the proposed model has large prior\nsupport and is flexible to approximate any $\\nu$-H\\\"{o}lder conditional\nvariance-covariance matrices with $\\nu\\in(0,1]$. We further show that based on\nthe theory of fractional likelihood, the rate of posterior contraction is\nminimax optimal assuming the true density to be a Gaussian mixture with a known\nnumber of components. The efficacy of the approach is demonstrated via\nsimulation studies and an analysis of a protein network for a breast cancer\ndataset assisted by mRNA gene expression as covariates.",
            "author": [
                "Yabo Niu",
                "Yang Ni",
                "Debdeep Pati",
                "Bani K. Mallick"
            ],
            "link": [
                "http://dx.doi.org/10.1080/01621459.2023.2233744",
                "http://arxiv.org/abs/2308.07806v1",
                "http://arxiv.org/pdf/2308.07806v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07801v1",
            "title": "Combinatorial QFT on graphs: first quantization formalism",
            "updated": "2023-08-15T14:27:15Z",
            "published": "2023-08-15T14:27:15Z",
            "summary": "We study a combinatorial model of the quantum scalar field with polynomial\npotential on a graph. In the first quantization formalism, the value of a\nFeynman graph is given by a sum over maps from the Feynman graph to the\nspacetime graph (mapping edges to paths). This picture interacts naturally with\nAtiyah-Segal-like cutting-gluing of spacetime graphs. In particular, one has\ncombinatorial counterparts of the known gluing formulae for Green's functions\nand (zeta-regularized) determinants of Laplacians.",
            "author": [
                "Ivan Contreras",
                "Santosh Kandel",
                "Pavel Mnev",
                "Konstantin Wernli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07801v1",
                "http://arxiv.org/pdf/2308.07801v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "hep-th",
                "math.CO",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07799v1",
            "title": "Handwritten Stenography Recognition and the LION Dataset",
            "updated": "2023-08-15T14:25:53Z",
            "published": "2023-08-15T14:25:53Z",
            "summary": "Purpose: In this paper, we establish a baseline for handwritten stenography\nrecognition, using the novel LION dataset, and investigate the impact of\nincluding selected aspects of stenographic theory into the recognition process.\nWe make the LION dataset publicly available with the aim of encouraging future\nresearch in handwritten stenography recognition.\n  Methods: A state-of-the-art text recognition model is trained to establish a\nbaseline. Stenographic domain knowledge is integrated by applying four\ndifferent encoding methods that transform the target sequence into\nrepresentations, which approximate selected aspects of the writing system.\nResults are further improved by integrating a pre-training scheme, based on\nsynthetic data.\n  Results: The baseline model achieves an average test character error rate\n(CER) of 29.81% and a word error rate (WER) of 55.14%. Test error rates are\nreduced significantly by combining stenography-specific target sequence\nencodings with pre-training and fine-tuning, yielding CERs in the range of\n24.5% - 26% and WERs of 44.8% - 48.2%.\n  Conclusion: The obtained results demonstrate the challenging nature of\nstenography recognition. Integrating stenography-specific knowledge, in\nconjunction with pre-training and fine-tuning on synthetic data, yields\nconsiderable improvements. Together with our precursor study on the subject,\nthis is the first work to apply modern handwritten text recognition to\nstenography. The dataset and our code are publicly available via Zenodo.",
            "author": [
                "Raphaela Heil",
                "Malin Nauwerck"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07799v1",
                "http://arxiv.org/pdf/2308.07799v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07798v1",
            "title": "Solving optimization problems with local light shift encoding on Rydberg\n  quantum annealers",
            "updated": "2023-08-15T14:24:45Z",
            "published": "2023-08-15T14:24:45Z",
            "summary": "We provide a non-unit disk framework to solve combinatorial optimization\nproblems such as Maximum Cut (Max-Cut) and Maximum Independent Set (MIS) on a\nRydberg quantum annealer. Our setup consists of a many-body interacting Rydberg\nsystem where locally controllable light shifts are applied to individual qubits\nin order to map the graph problem onto the Ising spin model. Exploiting the\nflexibility that optical tweezers offer in terms of spatial arrangement, our\nnumerical simulations implement the local-detuning protocol while globally\ndriving the Rydberg annealer to the desired many-body ground state, which is\nalso the solution to the optimization problem. Using optimal control methods,\nthese solutions are obtained for prototype graphs with varying sizes at time\nscales well within the system lifetime and with approximation ratios close to\none. The non-blockade approach facilitates the encoding of graph problems with\nspecific topologies that can be realized in two-dimensional Rydberg\nconfigurations and is applicable to both unweighted as well as weighted graphs.\nA comparative analysis with fast simulated annealing is provided which\nhighlights the advantages of our scheme in terms of system size, hardness of\nthe graph, and the number of iterations required to converge to the solution.",
            "author": [
                "Kapil Goswami",
                "Rick Mukherjee",
                "Herwig Ott",
                "Peter Schmelcher"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07798v1",
                "http://arxiv.org/pdf/2308.07798v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn",
                "cond-mat.quant-gas",
                "cs.CC",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07786v1",
            "title": "Box dimension of generalized affine fractal interpolation functions (II)",
            "updated": "2023-08-15T14:07:24Z",
            "published": "2023-08-15T14:07:24Z",
            "summary": "Let $f$ be a generalized affine fractal interpolation function with vertical\nscaling functions. In this paper, we first estimate $\\mathrm{dim}_B \\Gamma f$,\nthe box dimension of the graph of $f$, by the sum function of vertical scaling\nfunctions. Then we estimate $\\mathrm{dim}_B \\Gamma f$ by the limits of spectral\nradii of vertical scaling matrices under certain conditions. As an application,\nwe study the box dimension of the graph of a generalized Weierstrass-type\nfunction.",
            "author": [
                "Lai Jiang",
                "Huo-Jun Ruan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07786v1",
                "http://arxiv.org/pdf/2308.07786v1"
            ],
            "primary_category": "math.CA",
            "category": [
                "math.CA",
                "math.DS",
                "math.MG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07779v1",
            "title": "Do We Fully Understand Students' Knowledge States? Identifying and\n  Mitigating Answer Bias in Knowledge Tracing",
            "updated": "2023-08-15T13:56:29Z",
            "published": "2023-08-15T13:56:29Z",
            "summary": "Knowledge tracing (KT) aims to monitor students' evolving knowledge states\nthrough their learning interactions with concept-related questions, and can be\nindirectly evaluated by predicting how students will perform on future\nquestions. In this paper, we observe that there is a common phenomenon of\nanswer bias, i.e., a highly unbalanced distribution of correct and incorrect\nanswers for each question. Existing models tend to memorize the answer bias as\na shortcut for achieving high prediction performance in KT, thereby failing to\nfully understand students' knowledge states. To address this issue, we approach\nthe KT task from a causality perspective. A causal graph of KT is first\nestablished, from which we identify that the impact of answer bias lies in the\ndirect causal effect of questions on students' responses. A novel\nCOunterfactual REasoning (CORE) framework for KT is further proposed, which\nseparately captures the total causal effect and direct causal effect during\ntraining, and mitigates answer bias by subtracting the latter from the former\nin testing. The CORE framework is applicable to various existing KT models, and\nwe implement it based on the prevailing DKT, DKVMN, and AKT models,\nrespectively. Extensive experiments on three benchmark datasets demonstrate the\neffectiveness of CORE in making the debiased inference for KT.",
            "author": [
                "Chaoran Cui",
                "Hebo Ma",
                "Chen Zhang",
                "Chunyun Zhang",
                "Yumo Yao",
                "Meng Chen",
                "Yuling Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07779v1",
                "http://arxiv.org/pdf/2308.07779v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07777v1",
            "title": "Enhancing Visually-Rich Document Understanding via Layout Structure\n  Modeling",
            "updated": "2023-08-15T13:53:52Z",
            "published": "2023-08-15T13:53:52Z",
            "summary": "In recent years, the use of multi-modal pre-trained Transformers has led to\nsignificant advancements in visually-rich document understanding. However,\nexisting models have mainly focused on features such as text and vision while\nneglecting the importance of layout relationship between text nodes. In this\npaper, we propose GraphLayoutLM, a novel document understanding model that\nleverages the modeling of layout structure graph to inject document layout\nknowledge into the model. GraphLayoutLM utilizes a graph reordering algorithm\nto adjust the text sequence based on the graph structure. Additionally, our\nmodel uses a layout-aware multi-head self-attention layer to learn document\nlayout knowledge. The proposed model enables the understanding of the spatial\narrangement of text elements, improving document comprehension. We evaluate our\nmodel on various benchmarks, including FUNSD, XFUND and CORD, and achieve\nstate-of-the-art results among these datasets. Our experimental results\ndemonstrate that our proposed method provides a significant improvement over\nexisting approaches and showcases the importance of incorporating layout\ninformation into document understanding models. We also conduct an ablation\nstudy to investigate the contribution of each component of our model. The\nresults show that both the graph reordering algorithm and the layout-aware\nmulti-head self-attention layer play a crucial role in achieving the best\nperformance.",
            "author": [
                "Qiwei Li",
                "Zuchao Li",
                "Xiantao Cai",
                "Bo Du",
                "Hai Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07777v1",
                "http://arxiv.org/pdf/2308.07777v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07774v2",
            "title": "A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection",
            "updated": "2023-10-15T15:16:25Z",
            "published": "2023-08-15T13:49:12Z",
            "summary": "A key component of many graph neural networks (GNNs) is the pooling\noperation, which seeks to reduce the size of a graph while preserving important\nstructural information. However, most existing graph pooling strategies rely on\nan assignment matrix obtained by employing a GNN layer, which is characterized\nby trainable parameters, often leading to significant computational complexity\nand a lack of interpretability in the pooling process. In this paper, we\npropose an unsupervised graph encoder-decoder model to detect abnormal nodes\nfrom graphs by learning an anomaly scoring function to rank nodes based on\ntheir degree of abnormality. In the encoding stage, we design a novel pooling\nmechanism, named LCPool, which leverages locality-constrained linear coding for\nfeature encoding to find a cluster assignment matrix by solving a least-squares\noptimization problem with a locality regularization term. By enforcing locality\nconstraints during the coding process, LCPool is designed to be free from\nlearnable parameters, capable of efficiently handling large graphs, and can\neffectively generate a coarser graph representation while retaining the most\nsignificant structural characteristics of the graph. In the decoding stage, we\npropose an unpooling operation, called LCUnpool, to reconstruct both the\nstructure and nodal features of the original graph. We conduct empirical\nevaluations of our method on six benchmark datasets using several evaluation\nmetrics, and the results demonstrate its superiority over state-of-the-art\nanomaly detection approaches.",
            "author": [
                "Mahsa Mesgaran",
                "A. Ben Hamza"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07774v2",
                "http://arxiv.org/pdf/2308.07774v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07772v1",
            "title": "MOLE: MOdular Learning FramEwork via Mutual Information Maximization",
            "updated": "2023-08-15T13:48:16Z",
            "published": "2023-08-15T13:48:16Z",
            "summary": "This paper is to introduce an asynchronous and local learning framework for\nneural networks, named Modular Learning Framework (MOLE). This framework\nmodularizes neural networks by layers, defines the training objective via\nmutual information for each module, and sequentially trains each module by\nmutual information maximization. MOLE makes the training become local\noptimization with gradient-isolated across modules, and this scheme is more\nbiologically plausible than BP. We run experiments on vector-, grid- and\ngraph-type data. In particular, this framework is capable of solving both\ngraph- and node-level tasks for graph-type data. Therefore, MOLE has been\nexperimentally proven to be universally applicable to different types of data.",
            "author": [
                "Tianchao Li",
                "Yulong Pei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07772v1",
                "http://arxiv.org/pdf/2308.07772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07770v1",
            "title": "Multi-scale Promoted Self-adjusting Correlation Learning for Facial\n  Action Unit Detection",
            "updated": "2023-08-15T13:43:48Z",
            "published": "2023-08-15T13:43:48Z",
            "summary": "Facial Action Unit (AU) detection is a crucial task in affective computing\nand social robotics as it helps to identify emotions expressed through facial\nexpressions. Anatomically, there are innumerable correlations between AUs,\nwhich contain rich information and are vital for AU detection. Previous methods\nused fixed AU correlations based on expert experience or statistical rules on\nspecific benchmarks, but it is challenging to comprehensively reflect complex\ncorrelations between AUs via hand-crafted settings. There are alternative\nmethods that employ a fully connected graph to learn these dependencies\nexhaustively. However, these approaches can result in a computational explosion\nand high dependency with a large dataset. To address these challenges, this\npaper proposes a novel self-adjusting AU-correlation learning (SACL) method\nwith less computation for AU detection. This method adaptively learns and\nupdates AU correlation graphs by efficiently leveraging the characteristics of\ndifferent levels of AU motion and emotion representation information extracted\nin different stages of the network. Moreover, this paper explores the role of\nmulti-scale learning in correlation information extraction, and design a simple\nyet effective multi-scale feature learning (MSFL) method to promote better\nperformance in AU detection. By integrating AU correlation information with\nmulti-scale features, the proposed method obtains a more robust feature\nrepresentation for the final AU detection. Extensive experiments show that the\nproposed method outperforms the state-of-the-art methods on widely used AU\ndetection benchmark datasets, with only 28.7\\% and 12.0\\% of the parameters and\nFLOPs of the best method, respectively. The code for this method is available\nat \\url{https://github.com/linuxsino/Self-adjusting-AU}.",
            "author": [
                "Xin Liu",
                "Kaishen Yuan",
                "Xuesong Niu",
                "Jingang Shi",
                "Zitong Yu",
                "Huanjing Yue",
                "Jingyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07770v1",
                "http://arxiv.org/pdf/2308.07770v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07752v1",
            "title": "Self-Supervised Dynamic Hypergraph Recommendation based on\n  Hyper-Relational Knowledge Graph",
            "updated": "2023-08-15T13:12:19Z",
            "published": "2023-08-15T13:12:19Z",
            "summary": "Knowledge graphs (KGs) are commonly used as side information to enhance\ncollaborative signals and improve recommendation quality. In the context of\nknowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged\nas promising solutions for modeling factual and semantic information in KGs.\nHowever, the long-tail distribution of entities leads to sparsity in\nsupervision signals, which weakens the quality of item representation when\nutilizing KG enhancement. Additionally, the binary relation representation of\nKGs simplifies hyper-relational facts, making it challenging to model complex\nreal-world information. Furthermore, the over-smoothing phenomenon results in\nindistinguishable representations and information loss. To address these\nchallenges, we propose the SDK (Self-Supervised Dynamic Hypergraph\nRecommendation based on Hyper-Relational Knowledge Graph) framework. This\nframework establishes a cross-view hypergraph self-supervised learning\nmechanism for KG enhancement. Specifically, we model hyper-relational facts in\nKGs to capture interdependencies between entities under complete semantic\nconditions. With the refined representation, a hypergraph is dynamically\nconstructed to preserve features in the deep vector space, thereby alleviating\nthe over-smoothing problem. Furthermore, we mine external supervision signals\nfrom both the global perspective of the hypergraph and the local perspective of\ncollaborative filtering (CF) to guide the model prediction process. Extensive\nexperiments conducted on different datasets demonstrate the superiority of the\nSDK framework over state-of-the-art models. The results showcase its ability to\nalleviate the effects of over-smoothing and supervision signal sparsity.",
            "author": [
                "Yi Liu",
                "Hongrui Xuan",
                "Bohan Li",
                "Meng Wang",
                "Tong Chen",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07752v1",
                "http://arxiv.org/pdf/2308.07752v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07749v1",
            "title": "Dancing Avatar: Pose and Text-Guided Human Motion Videos Synthesis with\n  Image Diffusion Model",
            "updated": "2023-08-15T13:00:42Z",
            "published": "2023-08-15T13:00:42Z",
            "summary": "The rising demand for creating lifelike avatars in the digital realm has led\nto an increased need for generating high-quality human videos guided by textual\ndescriptions and poses. We propose Dancing Avatar, designed to fabricate human\nmotion videos driven by poses and textual cues. Our approach employs a\npretrained T2I diffusion model to generate each video frame in an\nautoregressive fashion. The crux of innovation lies in our adept utilization of\nthe T2I diffusion model for producing video frames successively while\npreserving contextual relevance. We surmount the hurdles posed by maintaining\nhuman character and clothing consistency across varying poses, along with\nupholding the background's continuity amidst diverse human movements. To ensure\nconsistent human appearances across the entire video, we devise an intra-frame\nalignment module. This module assimilates text-guided synthesized human\ncharacter knowledge into the pretrained T2I diffusion model, synergizing\ninsights from ChatGPT. For preserving background continuity, we put forth a\nbackground alignment pipeline, amalgamating insights from segment anything and\nimage inpainting techniques. Furthermore, we propose an inter-frame alignment\nmodule that draws inspiration from an auto-regressive pipeline to augment\ntemporal consistency between adjacent frames, where the preceding frame guides\nthe synthesis process of the current frame. Comparisons with state-of-the-art\nmethods demonstrate that Dancing Avatar exhibits the capacity to generate human\nvideos with markedly superior quality, both in terms of human and background\nfidelity, as well as temporal coherence compared to existing state-of-the-art\napproaches.",
            "author": [
                "Bosheng Qin",
                "Wentao Ye",
                "Qifan Yu",
                "Siliang Tang",
                "Yueting Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07749v1",
                "http://arxiv.org/pdf/2308.07749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07724v1",
            "title": "New constructions of non-regular cospectral graphs",
            "updated": "2023-08-15T12:00:07Z",
            "published": "2023-08-15T12:00:07Z",
            "summary": "We consider two types of joins of graphs $G_{1}$ and $G_{2}$, $G_{1}\\veebar\nG_{2}$ - the Neighbors Splitting Join and $G_{1}\\underset{=}{\\lor}G_{2}$ - the\nNon Neighbors Splitting Join, and compute the adjacency characteristic\npolynomial, the Laplacian characteristic polynomial and the signless Laplacian\ncharacteristic polynomial of these joins. When $G_{1}$ and $G_{2}$ are regular,\nwe compute the adjacency spectrum, the Laplacian spectrum, the signless\nLaplacian spectrum of $G_{1}\\underset{=}{\\lor}G_{2}$ and the normalized\nLaplacian spectrum of $G_{1}\\veebar G_{2}$ and $G_{1}\\underset{=}{\\lor}G_{2}$.\nWe use these results to construct non regular, non isomorphic graphs that are\ncospectral with respect to the four matrices: adjacency, Laplacian , signless\nLaplacian and normalized Laplacian.",
            "author": [
                "Suliman Hamud",
                "Abraham Berman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07724v1",
                "http://arxiv.org/pdf/2308.07724v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07723v1",
            "title": "Extended Preintegration for Relative State Estimation of Leader-Follower\n  Platform",
            "updated": "2023-08-15T11:55:35Z",
            "published": "2023-08-15T11:55:35Z",
            "summary": "Relative state estimation using exteroceptive sensors suffers from\nlimitations of the field of view (FOV) and false detection, that the\nproprioceptive sensor (IMU) data are usually engaged to compensate. Recently\nego-motion constraint obtained by Inertial measurement unit (IMU)\npreintegration has been extensively used in simultaneous localization and\nmapping (SLAM) to alleviate the computation burden. This paper introduces an\nextended preintegration incorporating the IMU preintegration of two platforms\nto formulate the motion constraint of relative state. One merit of this\nanalytic constraint is that it can be seamlessly integrated into the unified\ngraph optimization framework to implement the relative state estimation in a\nhigh-performance real-time tracking thread, another point is a full smoother\ndesign with this precise constraint to optimize the 3D coordinate and refine\nthe state for the refinement thread. We compare extensively in simulations the\nproposed algorithms with two existing approaches to confirm our outperformance.\nIn the real virtual reality (VR) application design with the proposed\nestimator, we properly realize the visual tracking of the six degrees of\nfreedom (6DoF) controller suitable for almost all scenarios, including the\nchallenging environment with missing features, light mutation, dynamic scenes,\netc. The demo video is at https://www.youtube.com/watch?v=0idb9Ls2iAM. For the\nbenefit of the community, we make the source code public.",
            "author": [
                "Ruican Xia",
                "Hailong Pei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07723v1",
                "http://arxiv.org/pdf/2308.07723v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07722v1",
            "title": "Analysis of stochastic probing methods for estimating the trace of\n  functions of sparse symmetric matrices",
            "updated": "2023-08-15T11:54:19Z",
            "published": "2023-08-15T11:54:19Z",
            "summary": "We consider the problem of estimating the trace of a matrix function $f(A)$.\nIn certain situations, in particular if $f(A)$ cannot be well approximated by a\nlow-rank matrix, combining probing methods based on graph colorings with\nstochastic trace estimation techniques can yield accurate approximations at\nmoderate cost. So far, such methods have not been thoroughly analyzed, though,\nbut were rather used as efficient heuristics by practitioners. In this\nmanuscript, we perform a detailed analysis of stochastic probing methods and,\nin particular, expose conditions under which the expected approximation error\nin the stochastic probing method scales more favorably with the dimension of\nthe matrix than the error in non-stochastic probing. Extending results from [E.\nAune, D. P. Simpson, J. Eidsvik, Parameter estimation in high dimensional\nGaussian distributions, Stat. Comput., 24, pp. 247--263, 2014], we also\ncharacterize situations in which using just one stochastic vector is always --\nnot only in expectation -- better than the deterministic probing method.\nSeveral numerical experiments illustrate our theory and compare with existing\nmethods.",
            "author": [
                "Andreas Frommer",
                "Michele Rinelli",
                "Marcel Schweitzer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07722v1",
                "http://arxiv.org/pdf/2308.07722v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07718v1",
            "title": "Global biasing using a Hardware-based artificial Zeeman term in Spinwave\n  Ising Machines",
            "updated": "2023-08-15T11:51:39Z",
            "published": "2023-08-15T11:51:39Z",
            "summary": "A spinwave Ising machine (SWIM) is a newly proposed type of time-multiplexed\nhardware solver for combinatorial optimization that employs feedback coupling\nand phase sensitive amplification to map an Ising Hamiltonian into\nphase-binarized propagating spin-wave RF pulses in an Yttrium-Iron-Garnet (YIG)\nfilm. In this work, we increase the mathematical complexity of the SWIM by\nadding a global Zeeman term to a 4-spin MAX-CUT Hamiltonian using a continuous\nexternal electrical signal with the same frequency as the spin pulses and phase\nlocked with with one of the two possible states. We are able to induce\nferromagnetic ordering in both directions of the spin states despite\nantiferromagnetic pairwise coupling. Embedding a planar antiferromagnetic spin\nsystem in a magnetic field has been proven to increase the complexity of the\ngraph associated to its Hamiltonian and thus this straightforward\nimplementation helps explore higher degrees of complexity in this evolving\nsolver.",
            "author": [
                "Victor H. Gonz\u00e1lez",
                "Artem Litvinenko",
                "Roman Khymyn",
                "Johan \u00c5kerman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07718v1",
                "http://arxiv.org/pdf/2308.07718v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "nlin.PS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07711v3",
            "title": "SPM: Structured Pretraining and Matching Architectures for Relevance\n  Modeling in Meituan Search",
            "updated": "2023-08-27T11:21:38Z",
            "published": "2023-08-15T11:45:34Z",
            "summary": "In e-commerce search, relevance between query and documents is an essential\nrequirement for satisfying user experience. Different from traditional\ne-commerce platforms that offer products, users search on life service\nplatforms such as Meituan mainly for product providers, which usually have\nabundant structured information, e.g. name, address, category, thousands of\nproducts. Modeling search relevance with these rich structured contents is\nchallenging due to the following issues: (1) there is language distribution\ndiscrepancy among different fields of structured document, making it difficult\nto directly adopt off-the-shelf pretrained language model based methods like\nBERT. (2) different fields usually have different importance and their length\nvary greatly, making it difficult to extract document information helpful for\nrelevance matching.\n  To tackle these issues, in this paper we propose a novel two-stage\npretraining and matching architecture for relevance matching with rich\nstructured documents. At pretraining stage, we propose an effective pretraining\nmethod that employs both query and multiple fields of document as inputs,\nincluding an effective information compression method for lengthy fields. At\nrelevance matching stage, a novel matching method is proposed by leveraging\ndomain knowledge in search query to generate more effective document\nrepresentations for relevance scoring. Extensive offline experiments and online\nA/B tests on millions of users verify that the proposed architectures\neffectively improve the performance of relevance modeling. The model has\nalready been deployed online, serving the search traffic of Meituan for over a\nyear.",
            "author": [
                "Wen Zan",
                "Yaopeng Han",
                "Xiaotian Jiang",
                "Yao Xiao",
                "Yang Yang",
                "Dayao Chen",
                "Sheng Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615500",
                "http://arxiv.org/abs/2308.07711v3",
                "http://arxiv.org/pdf/2308.07711v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07709v1",
            "title": "Joint measurement of the ultra-high-energy neutrino spectrum and cross\n  section",
            "updated": "2023-08-15T11:32:42Z",
            "published": "2023-08-15T11:32:42Z",
            "summary": "Soon, a new generation of neutrino telescopes, presently under planning, will\ntarget the discovery of ultra-high-energy (UHE) neutrinos of cosmic origin,\nwith energies higher than 100 PeV, that promise unique insight into\nastrophysics and particle physics. Yet, predictions of the UHE neutrino flux\nand interaction cross section -- whose measurement is co-dependent -- are laden\nwith significant uncertainty that, if unaddressed, could misrepresent the\ncapabilities to measure one or the other. To address this, we advocate for the\njoint measurement of the UHE neutrino spectrum and neutrino-nucleon cross\nsection, including of their energy dependence, without assuming prior knowledge\nof either. We illustrate our methods by adopting empirical parametrizations of\nthe neutrino spectrum, in forecasts geared to the planned radio array of the\nIceCube-Gen2 neutrino telescope. We warn against using simple parametrizations\n-- a simple power law or one augmented with an exponential cut-off -- that\nmight fail to capture features of the spectrum that are commonplace in the\npredictions. We argue instead for the use of flexible parametrizations -- a\npiecewise power law or an interpolating polynomial -- that ensure accuracy. We\nreport loose design targets for the detector energy and angular resolution that\nare compatible with those under present consideration.",
            "author": [
                "Victor B. Valera",
                "Mauricio Bustamante",
                "Olga Mena"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07709v1",
                "http://arxiv.org/pdf/2308.07709v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "hep-ex",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07703v1",
            "title": "Challenges and Opportunities in Data Visualization Education: A Call to\n  Action",
            "updated": "2023-08-15T11:21:23Z",
            "published": "2023-08-15T11:21:23Z",
            "summary": "This paper is a call to action for research and discussion on data\nvisualization education. As visualization evolves and spreads through our\nprofessional and personal lives, we need to understand how to support and\nempower a broad and diverse community of learners in visualization. Data\nVisualization is a diverse and dynamic discipline that combines knowledge from\ndifferent fields, is tailored to suit diverse audiences and contexts, and\nfrequently incorporates tacit knowledge. This complex nature leads to a series\nof interrelated challenges for data visualization education. Driven by a lack\nof consolidated knowledge, overview, and orientation for visualization\neducation, the 21 authors of this paper-educators and researchers in data\nvisualization-identify and describe 19 challenges informed by our collective\npractical experience. We organize these challenges around seven themes People,\nGoals & Assessment, Environment, Motivation, Methods, Materials, and Change.\nAcross these themes, we formulate 43 research questions to address these\nchallenges. As part of our call to action, we then conclude with 5\ncross-cutting opportunities and respective action items: embrace\nDIVERSITY+INCLUSION, build COMMUNITIES, conduct RESEARCH, act AGILE, and relish\nRESPONSIBILITY. We aim to inspire researchers, educators and learners to drive\nvisualization education forward and discuss why, how, who and where we educate,\nas we learn to use visualization to address challenges across many scales and\nmany domains in a rapidly changing world: viseducationchallenges.github.io.",
            "author": [
                "Benjamin Bach",
                "Mandy Keck",
                "Fateme Rajabiyazdi",
                "Tatiana Losev",
                "Isabel Meirelles",
                "Jason Dykes",
                "Robert S. Laramee",
                "Mashael AlKadi",
                "Christina Stoiber",
                "Samuel Huron",
                "Charles Perin",
                "Luiz Morais",
                "Wolfgang Aigner",
                "Doris Kosminsky",
                "Magdalena Boucher",
                "S\u00f8ren Knudsen",
                "Areti Manataki",
                "Jan Aerts",
                "Uta Hinrichs",
                "Jonathan C. Roberts",
                "Sheelagh Carpendale"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07703v1",
                "http://arxiv.org/pdf/2308.07703v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07696v1",
            "title": "Scaling of Components in Critical Geometric Random Graphs on 2-dim Torus",
            "updated": "2023-08-15T10:54:32Z",
            "published": "2023-08-15T10:54:32Z",
            "summary": "We consider random graphs on the set of $N^2$ vertices placed on the discrete\n$2$-dimensional torus. The edges between pairs of vertices are independent, and\ntheir probabilities decay with the distance $\\rho$ between these vertices as\n$(N\\rho)^{-1}$. This is an example of an inhomogeneous random graph which is\nnot of rank 1. The reported previously results on the sub- and super-critical\ncases of this model exhibit great similarity to the classical\nErd\\H{o}s-R\\'{e}nyi graphs.\n  Here we study the critical phase. A diffusion approximation for the size of\nthe largest connected component rescaled with $(N^2)^{-2/3}$ is derived. This\ncompletes the proof that in all regimes the model is within the same class as\nErd\\H{o}s-R\\'{e}nyi graph with respect to scaling of the largest component.",
            "author": [
                "Vasilii Goriachkin",
                "Tatyana Turova"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07696v1",
                "http://arxiv.org/pdf/2308.07696v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "05C80, 60G42, 60G50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07690v1",
            "title": "Entanglement, quantum correlators and connectivity in graph states",
            "updated": "2023-08-15T10:42:07Z",
            "published": "2023-08-15T10:42:07Z",
            "summary": "In this work, we present a comprehensive exploration of the entanglement and\ngraph connectivity properties of graph states. We quantify the entanglement in\npseudo graph states using the entanglement distance, a recently introduced\nmeasure of entanglement. Additionally, we propose a novel approach to probe the\nunderlying graph connectivity of genuine graph states, using quantum\ncorrelators of Pauli matrices. Our findings also reveal interesting\nimplications for measurement processes, demonstrating the equivalence of\ncertain projective measurements. Finally, we emphasize the simplicity of data\nanalysis within this framework. This work contributes to a deeper understanding\nof the entanglement and connectivity properties of graph states, offering\nvaluable insights for quantum information processing and quantum computing\napplications. In this work, we do not resort to the celebrated stabilizer\nformalism, which is the framework typically preferred for the study of this\ntype of state; on the contrary, our approach is solely based on the concepts of\nexpectation values, quantum correlations and projective measurement, which have\nthe advantage of being very intuitive and fundamental tools of quantum theory.",
            "author": [
                "Arthur Vesperini",
                "Roberto Franzosi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07690v1",
                "http://arxiv.org/pdf/2308.07690v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07684v1",
            "title": "Transitive path decompositions of Cartesian products of complete graphs",
            "updated": "2023-08-15T10:29:06Z",
            "published": "2023-08-15T10:29:06Z",
            "summary": "An $H$-decomposition of a graph $\\Gamma$ is a partition of its edge set into\nsubgraphs isomorphic to $H$. A transitive decomposition is a special kind of\n$H$-decomposition that is highly symmetrical in the sense that the subgraphs\n(copies of $H$) are preserved and transitively permuted by a group of\nautomorphisms of $\\Gamma$. This paper concerns transitive $H$-decompositions of\nthe graph $K_n \\Box K_n$ where $H$ is a path. When $n$ is an odd prime, we\npresent a construction for a transitive path decomposition where the paths in\nthe decomposition are arbitrary large.",
            "author": [
                "Ajani De Vas Gunasekara",
                "Alice Devillers"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07684v1",
                "http://arxiv.org/pdf/2308.07684v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.GR",
                "05C38, 05E20, 05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07677v1",
            "title": "Uniquely Distinguishing Colorable Graphs",
            "updated": "2023-08-15T09:54:57Z",
            "published": "2023-08-15T09:54:57Z",
            "summary": "A graph is called uniquely distinguishing colorable if there is only one\npartition of vertices of the graph that forms distinguishing coloring with the\nsmallest possible colors. In this paper, we study the unique colorability of\nthe distinguishing coloring of a graph and its applications in computing the\ndistinguishing chromatic number of disconnected graphs. We introduce two\nfamilies of uniquely distinguishing colorable graphs, namely type 1 and type 2,\nand show that every disconnected uniquely distinguishing colorable graph is the\nunion of two isomorphic graphs of type 2. We obtain some results on bipartite\nuniquely distinguishing colorable graphs and show that any uniquely\ndistinguishing $n$-colorable tree with $ n \\geq 3$ is a star graph. For a\nconnected graph $G$, we prove that $\\chi_D(G\\cup G)=\\chi_D(G)+1$ if and only if\n$G$ is uniquely distinguishing colorable of type 1. Also, a characterization of\nall graphs $G$ of order $n$ with the property that $\\chi_{D}(G\\cup G) =\n\\chi_{D}(G) = k$, where $k=n-2, n-1, n$, is given in this paper. Moreover, we\ndetermine all graphs $G$ of order $n$ with the property that $\\chi_{D}(G\\cup G)\n= \\chi_{D}(G)+1 = \\ell$, where $\\ell=n-1, n, n+1$. Finally, we investigate the\nfamily of connected graphs $G$ with $\\chi_{D}(G\\cup G) = \\chi_{D}(G)+1 = 3$.",
            "author": [
                "M. Korivand",
                "N. Soltankhah",
                "K. Khashyarmanesh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07677v1",
                "http://arxiv.org/pdf/2308.07677v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07676v1",
            "title": "Maat: Performance Metric Anomaly Anticipation for Cloud Services with\n  Conditional Diffusion",
            "updated": "2023-08-15T09:50:15Z",
            "published": "2023-08-15T09:50:15Z",
            "summary": "Ensuring the reliability and user satisfaction of cloud services necessitates\nprompt anomaly detection followed by diagnosis.\n  Existing techniques for anomaly detection focus solely on real-time\ndetection, meaning that anomaly alerts are issued as soon as anomalies occur.\n  However, anomalies can propagate and escalate into failures, making\nfaster-than-real-time anomaly detection highly desirable for expediting\ndownstream analysis and intervention.\n  This paper proposes Maat, the first work to address anomaly anticipation of\nperformance metrics in cloud services.\n  Maat adopts a novel two-stage paradigm for anomaly anticipation, consisting\nof metric forecasting and anomaly detection on forecasts.\n  The metric forecasting stage employs a conditional denoising diffusion model\nto enable multi-step forecasting in an auto-regressive manner.\n  The detection stage extracts anomaly-indicating features based on domain\nknowledge and applies isolation forest with incremental learning to detect\nupcoming anomalies.\n  Thus, our method can uncover anomalies that better conform to human\nexpertise.\n  Evaluation on three publicly available datasets demonstrates that Maat can\nanticipate anomalies faster than real-time comparatively or more effectively\ncompared with state-of-the-art real-time anomaly detectors.\n  We also present cases highlighting Maat's success in forecasting abnormal\nmetrics and discovering anomalies.",
            "author": [
                "Cheryl Lee",
                "Tianyi Yang",
                "Zhuangbin Chen",
                "Yuxin Su",
                "Michael R. Lyu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07676v1",
                "http://arxiv.org/pdf/2308.07676v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07667v1",
            "title": "Ramsey-type results on parameters related to domination",
            "updated": "2023-08-15T09:33:34Z",
            "published": "2023-08-15T09:33:34Z",
            "summary": "There is a philosophy to discover Ramsey-type theorem: given a graph\nparameter $\\mu$, characterize the family $\\HH$ of graphs which satisfies that\nevery $\\HH$-free graph $G$ has bounded parameter $\\mu$. The classical Ramsey's\ntheorem deals the parameter $\\mu$ as the number of vertices. It also has a\ncorresponding connected version. This Ramsey-type problem on domination number\nhas been solved by Furuya. We will use this result to handle more parameters\nrelated to domination.",
            "author": [
                "Jin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07667v1",
                "http://arxiv.org/pdf/2308.07667v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07653v3",
            "title": "Connectivity Graph-Codes",
            "updated": "2023-09-06T23:19:05Z",
            "published": "2023-08-15T09:02:45Z",
            "summary": "The symmetric difference of two graphs $G_1,G_2$ on the same set of vertices\n$V$ is the graph on $V$ whose set of edges are all edges that belong to exactly\none of the two graphs $G_1,G_2$. For a fixed graph $H$ call a collection ${\\cal\nG}$ of spanning subgraphs of $H$ a connectivity code for $H$ if the symmetric\ndifference of any two distinct subgraphs in ${\\cal G}$ is a connected spanning\nsubgraph of $H$. It is easy to see that the maximum possible cardinality of\nsuch a collection is at most $2^{k'(H)} \\leq 2^{\\delta(H)}$, where $k'(H)$ is\nthe edge-connectivity of $H$ and $\\delta(H)$ is its minimum degree. We show\nthat equality holds for any $d$-regular (mild) expander, and observe that\nequality does not hold in several natural examples including any large cubic\ngraph, the square of a long cycle and products of a small clique with a long\ncycle.",
            "author": [
                "Noga Alon"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07653v3",
                "http://arxiv.org/pdf/2308.07653v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05D05, 05D40, 94B25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07633v3",
            "title": "A Survey on Model Compression for Large Language Models",
            "updated": "2023-09-17T16:38:18Z",
            "published": "2023-08-15T08:31:05Z",
            "summary": "Large Language Models (LLMs) have revolutionized natural language processing\ntasks with remarkable success. However, their formidable size and computational\ndemands present significant challenges for practical deployment, especially in\nresource-constrained environments. As these challenges become increasingly\npertinent, the field of model compression has emerged as a pivotal research\narea to alleviate these limitations. This paper presents a comprehensive survey\nthat navigates the landscape of model compression techniques tailored\nspecifically for LLMs. Addressing the imperative need for efficient deployment,\nwe delve into various methodologies, encompassing quantization, pruning,\nknowledge distillation, and more. Within each of these techniques, we highlight\nrecent advancements and innovative approaches that contribute to the evolving\nlandscape of LLM research. Furthermore, we explore benchmarking strategies and\nevaluation metrics that are essential for assessing the effectiveness of\ncompressed LLMs. By providing insights into the latest developments and\npractical implications, this survey serves as an invaluable resource for both\nresearchers and practitioners. As LLMs continue to evolve, this survey aims to\nfacilitate enhanced efficiency and real-world applicability, establishing a\nfoundation for future advancements in the field.",
            "author": [
                "Xunyu Zhu",
                "Jian Li",
                "Yong Liu",
                "Can Ma",
                "Weiping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07633v3",
                "http://arxiv.org/pdf/2308.07633v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07628v1",
            "title": "Software Engineering Knowledge Areas in Startup Companies: A Mapping\n  Study",
            "updated": "2023-08-15T08:26:02Z",
            "published": "2023-08-15T08:26:02Z",
            "summary": "Background - Startup companies are becoming important suppliers of innovative\nand software intensive products. The failure rate among startups is high due to\nlack of resources, immaturity, multiple influences and dynamic technologies.\nHowever, software product engineering is the core activity in startups,\ntherefore inadequacies in applied engineering practices might be a significant\ncontributing factor for high failure rates. Aim - This study identifies and\ncategorizes software engineering knowledge areas utilized in startups to map\nout the state-of-art, identifying gaps for further research. Method - We\nperform a systematic literature mapping study, applying snowball sampling to\nidentify relevant primary studies. Results - We have identified 54 practices\nfrom 14 studies. Although 11 of 15 main knowledge areas from SWEBOK are\ncovered, a large part of categories is not. Conclusions - Existing research\ndoes not provide reliable support for software engineering in any phase of a\nstartup life cycle. Transfer of results to other startups is difficult due to\nlow rigor in current studies.",
            "author": [
                "Eriks Klotins",
                "Michael Unterkalmsteiner",
                "Tony Gorschek"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-319-18612-2_3",
                "http://arxiv.org/abs/2308.07628v1",
                "http://arxiv.org/pdf/2308.07628v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07625v1",
            "title": "Backpropagation Path Search On Adversarial Transferability",
            "updated": "2023-08-15T08:21:20Z",
            "published": "2023-08-15T08:21:20Z",
            "summary": "Deep neural networks are vulnerable to adversarial examples, dictating the\nimperativeness to test the model's robustness before deployment. Transfer-based\nattackers craft adversarial examples against surrogate models and transfer them\nto victim models deployed in the black-box situation. To enhance the\nadversarial transferability, structure-based attackers adjust the\nbackpropagation path to avoid the attack from overfitting the surrogate model.\nHowever, existing structure-based attackers fail to explore the convolution\nmodule in CNNs and modify the backpropagation graph heuristically, leading to\nlimited effectiveness. In this paper, we propose backPropagation pAth Search\n(PAS), solving the aforementioned two problems. We first propose SkipConv to\nadjust the backpropagation path of convolution by structural\nreparameterization. To overcome the drawback of heuristically designed\nbackpropagation paths, we further construct a DAG-based search space, utilize\none-step approximation for path evaluation and employ Bayesian Optimization to\nsearch for the optimal path. We conduct comprehensive experiments in a wide\nrange of transfer settings, showing that PAS improves the attack success rate\nby a huge margin for both normally trained and defense models.",
            "author": [
                "Zhuoer Xu",
                "Zhangxuan Gu",
                "Jianping Zhang",
                "Shiwen Cui",
                "Changhua Meng",
                "Weiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07625v1",
                "http://arxiv.org/pdf/2308.07625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07615v2",
            "title": "Self-supervised Hypergraphs for Learning Multiple World Interpretations",
            "updated": "2023-08-21T14:48:09Z",
            "published": "2023-08-15T07:51:53Z",
            "summary": "We present a method for learning multiple scene representations given a small\nlabeled set, by exploiting the relationships between such representations in\nthe form of a multi-task hypergraph. We also show how we can use the hypergraph\nto improve a powerful pretrained VisTransformer model without any additional\nlabeled data. In our hypergraph, each node is an interpretation layer (e.g.,\ndepth or segmentation) of the scene. Within each hyperedge, one or several\ninput nodes predict the layer at the output node. Thus, each node could be an\ninput node in some hyperedges and an output node in others. In this way,\nmultiple paths can reach the same node, to form ensembles from which we obtain\nrobust pseudolabels, which allow self-supervised learning in the hypergraph. We\ntest different ensemble models and different types of hyperedges and show\nsuperior performance to other multi-task graph models in the field. We also\nintroduce Dronescapes, a large video dataset captured with UAVs in different\ncomplex real-world scenes, with multiple representations, suitable for\nmulti-task learning.",
            "author": [
                "Alina Marcu",
                "Mihai Pirvu",
                "Dragos Costea",
                "Emanuela Haller",
                "Emil Slusanschi",
                "Ahmed Nabil Belbachir",
                "Rahul Sukthankar",
                "Marius Leordeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07615v2",
                "http://arxiv.org/pdf/2308.07615v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07609v1",
            "title": "Three alternative model-building strategies using quasi-Hermitian\n  time-dependent observables",
            "updated": "2023-08-15T07:35:42Z",
            "published": "2023-08-15T07:35:42Z",
            "summary": "A $(K+1)-$plet of non-Hermitian and time-dependent operators (say,\n$\\Lambda_j(t)$, $j=0,1,\\ldots,K$) can be interpreted as the set of observables\ncharacterizing a unitary quantum system. What is required is the existence of a\nself-adjoint and, in general, time-dependent operator (say, $\\Theta(t)$ called\ninner product metric) making the operators quasi-Hermitian,\n$\\Lambda_j^\\dagger(t)\\Theta(t)=\\Theta(t)\\Lambda_j(t)$. The theory (called\nnon-Hermitian interaction-picture, NIP) requires a separate description of the\nevolution of the states $\\psi(t)$ (realized, via Schr\\\"{o}dinger-type equation,\nby a generator, say, $G(t)$) and of the observables themselves (a different\ngenerator (say, $\\Sigma(t)(t)$) occurs in the related non-Hermitian\nHeisenberg-type equation). Every $\\Lambda_j(t)$ (and, in particular,\nHamiltonian $H(t)=\\Lambda_0(t)$) appears isospectral to its hypothetical\nisospectral and self-adjoint (but, by assumption, prohibitively\nuser-unfriendly) avatar $\\lambda_j(t)=\\Omega(t)\\Lambda_j(t)\\Omega^{-1}(t)$ with\n$\\Omega^\\dagger(t)\\Omega(t)=\\Theta(t)$. In our paper the key role played by\nidentity $H(t)=G(t)+\\Sigma(t)$ is shown to imply that there exist just three\nalternative meaningful implementations of the NIP approach, viz., ``number\none'' (a ``dynamical'' strategy based on the knowledge of $H(t)$), ``number\ntwo'' (a ``kinematical'' one, based on the Coriolis force $\\Sigma(t)$) and\n``number three'' (in the literature, such a construction based on $G(t)$ is\nmost popular but, paradoxically, it is also most complicated).",
            "author": [
                "Miloslav Znojil"
            ],
            "link": [
                "http://dx.doi.org/10.3390/sym15081596",
                "http://arxiv.org/abs/2308.07609v1",
                "http://arxiv.org/pdf/2308.07609v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07608v1",
            "title": "Extremal problems for disjoint graphs",
            "updated": "2023-08-15T07:34:12Z",
            "published": "2023-08-15T07:34:12Z",
            "summary": "For a simple graph $F$, let $\\mathrm{EX}(n, F)$ and $\\mathrm{EX_{sp}}(n,F)$\nbe the set of graphs with the maximum number of edges and the set of graphs\nwith the maximum spectral radius in an $n$-vertex graph without any copy of the\ngraph $F$, respectively. Let $F$ be a graph with\n$\\mathrm{ex}(n,F)=e(T_{n,r})+O(1)$. In this paper, we show that\n$\\mathrm{EX_{sp}}(n,kF)\\subseteq \\mathrm{EX}(n,kF)$ for sufficiently large $n$.\nThis generalizes a result of Wang, Kang and Xue [J. Comb. Theory, Ser. B,\n159(2023) 20-41]. We also determine the extremal graphs of $kF$ in term of the\nextremal graphs of $F$.",
            "author": [
                "Zhenyu Ni",
                "Jing Wang",
                "Liying Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07608v1",
                "http://arxiv.org/pdf/2308.07608v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07593v1",
            "title": "AKVSR: Audio Knowledge Empowered Visual Speech Recognition by\n  Compressing Audio Knowledge of a Pretrained Model",
            "updated": "2023-08-15T06:38:38Z",
            "published": "2023-08-15T06:38:38Z",
            "summary": "Visual Speech Recognition (VSR) is the task of predicting spoken words from\nsilent lip movements. VSR is regarded as a challenging task because of the\ninsufficient information on lip movements. In this paper, we propose an Audio\nKnowledge empowered Visual Speech Recognition framework (AKVSR) to complement\nthe insufficient speech information of visual modality by using audio modality.\nDifferent from the previous methods, the proposed AKVSR 1) utilizes rich audio\nknowledge encoded by a large-scale pretrained audio model, 2) saves the\nlinguistic information of audio knowledge in compact audio memory by discarding\nthe non-linguistic information from the audio through quantization, and 3)\nincludes Audio Bridging Module which can find the best-matched audio features\nfrom the compact audio memory, which makes our training possible without audio\ninputs, once after the compact audio memory is composed. We validate the\neffectiveness of the proposed method through extensive experiments, and achieve\nnew state-of-the-art performances on the widely-used datasets, LRS2 and LRS3.",
            "author": [
                "Jeong Hun Yeo",
                "Minsu Kim",
                "Jeongsoo Choi",
                "Dae Hoe Kim",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07593v1",
                "http://arxiv.org/pdf/2308.07593v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "eess.AS",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07592v1",
            "title": "Graph-Segmenter: Graph Transformer with Boundary-aware Attention for\n  Semantic Segmentation",
            "updated": "2023-08-15T06:30:19Z",
            "published": "2023-08-15T06:30:19Z",
            "summary": "The transformer-based semantic segmentation approaches, which divide the\nimage into different regions by sliding windows and model the relation inside\neach window, have achieved outstanding success. However, since the relation\nmodeling between windows was not the primary emphasis of previous work, it was\nnot fully utilized. To address this issue, we propose a Graph-Segmenter,\nincluding a Graph Transformer and a Boundary-aware Attention module, which is\nan effective network for simultaneously modeling the more profound relation\nbetween windows in a global view and various pixels inside each window as a\nlocal one, and for substantial low-cost boundary adjustment. Specifically, we\ntreat every window and pixel inside the window as nodes to construct graphs for\nboth views and devise the Graph Transformer. The introduced boundary-aware\nattention module optimizes the edge information of the target objects by\nmodeling the relationship between the pixel on the object's edge. Extensive\nexperiments on three widely used semantic segmentation datasets (Cityscapes,\nADE-20k and PASCAL Context) demonstrate that our proposed network, a Graph\nTransformer with Boundary-aware Attention, can achieve state-of-the-art\nsegmentation performance.",
            "author": [
                "Zizhang Wu",
                "Yuanzhu Gan",
                "Tianhao Xu",
                "Fan Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s11704-023-2563-5",
                "http://arxiv.org/abs/2308.07592v1",
                "http://arxiv.org/pdf/2308.07592v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07591v1",
            "title": "Q-Learning for Continuous State and Action MDPs under Average Cost\n  Criteria",
            "updated": "2023-08-15T06:24:53Z",
            "published": "2023-08-15T06:24:53Z",
            "summary": "For infinite-horizon average-cost criterion problems, we present several\napproximation and reinforcement learning results for Markov Decision Processes\nwith standard Borel spaces. Toward this end, (i) we first provide a\ndiscretization based approximation method for fully observed Markov Decision\nProcesses (MDPs) with continuous spaces under average cost criteria, and we\nprovide error bounds for the approximations when the dynamics are only weakly\ncontinuous under certain ergodicity assumptions. In particular, we relax the\ntotal variation condition given in prior work to weak continuity as well as\nWasserstein continuity conditions. (ii) We provide synchronous and asynchronous\nQ-learning algorithms for continuous spaces via quantization, and establish\ntheir convergence. (iii) We show that the convergence is to the optimal Q\nvalues of the finite approximate models constructed via quantization. Our\nQ-learning convergence results and their convergence to near optimality are new\nfor continuous spaces, and the proof method is new even for finite spaces, to\nour knowledge.",
            "author": [
                "Ali Devran Kara",
                "Serdar Yuksel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07591v1",
                "http://arxiv.org/pdf/2308.07591v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07584v1",
            "title": "Existence of solutions for a poly-Laplacian system involving\n  concave-convex nonlinearity on locally finite graphs",
            "updated": "2023-08-15T06:15:48Z",
            "published": "2023-08-15T06:15:48Z",
            "summary": "We investigate the existence of two nontrivial solutions for a poly-Laplacian\nsystem involving concave-convex nonlinearity and parameters with Dirichlet\nboundary value condition on the locally finite graph. By using the mountain\npass theorem and Ekeland's variational principle, we obtain that system has at\nleast one non-semi-trivial solution of positive energy and one non-semi-trivial\nsolution of negative energy, respectively. We also obtain an estimate about\nsemi-trivial solutions. Moreover, by using a result in [10] which is based on\nthe fibering maps and the method of Nehari manifold, we obtain the existence of\nground state solution to the single equation corresponding to poly-Laplacian\nsystem. Especially, we present the concrete range of parameters in all of\nresults.",
            "author": [
                "Ping Yang",
                "Xingyong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07584v1",
                "http://arxiv.org/pdf/2308.07584v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07579v1",
            "title": "Connectivity of Markoff mod-p graphs and maximal divisors",
            "updated": "2023-08-15T05:34:46Z",
            "published": "2023-08-15T05:34:46Z",
            "summary": "Markoff mod-$p$ graphs are conjectured to be connected for all primes $p$. In\nthis paper, we use results of Chen and Bourgain, Gamburd, and Sarnak to confirm\nthe conjecture for all $p > 3.448\\cdot10^{392}$. We also provide a method that\nquickly verifies connectivity for many primes below this bound. In our study of\nMarkoff mod-$p$ graphs we introduce the notion of \\emph{maximal divisors} of a\nnumber. We prove sharp asymptotic and explicit upper bounds on the number of\nmaximal divisors, which ultimately improves the Markoff graph $p$-bound by\nroughly 140 orders of magnitude as compared with an approach using all\ndivisors.",
            "author": [
                "Jillian Eddy",
                "Elena Fuchs",
                "Matthew Litman",
                "Daniel Martin",
                "Nico Tripeny"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07579v1",
                "http://arxiv.org/pdf/2308.07579v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07578v2",
            "title": "Understanding User Behavior in Volumetric Video Watching: Dataset,\n  Analysis and Prediction",
            "updated": "2023-08-16T14:12:43Z",
            "published": "2023-08-15T05:33:48Z",
            "summary": "Volumetric video emerges as a new attractive video paradigm in recent years\nsince it provides an immersive and interactive 3D viewing experience with six\ndegree-of-freedom (DoF). Unlike traditional 2D or panoramic videos, volumetric\nvideos require dense point clouds, voxels, meshes, or huge neural models to\ndepict volumetric scenes, which results in a prohibitively high bandwidth\nburden for video delivery. Users' behavior analysis, especially the viewport\nand gaze analysis, then plays a significant role in prioritizing the content\nstreaming within users' viewport and degrading the remaining content to\nmaximize user QoE with limited bandwidth. Although understanding user behavior\nis crucial, to the best of our best knowledge, there are no available 3D\nvolumetric video viewing datasets containing fine-grained user interactivity\nfeatures, not to mention further analysis and behavior prediction. In this\npaper, we for the first time release a volumetric video viewing behavior\ndataset, with a large scale, multiple dimensions, and diverse conditions. We\nconduct an in-depth analysis to understand user behaviors when viewing\nvolumetric videos. Interesting findings on user viewport, gaze, and motion\npreference related to different videos and users are revealed. We finally\ndesign a transformer-based viewport prediction model that fuses the features of\nboth gaze and motion, which is able to achieve high accuracy at various\nconditions. Our prediction model is expected to further benefit volumetric\nvideo streaming optimization. Our dataset, along with the corresponding\nvisualization tools is accessible at\nhttps://cuhksz-inml.github.io/user-behavior-in-vv-watching/",
            "author": [
                "Kaiyuan Hu",
                "Haowen Yang",
                "Yili Jin",
                "Junhua Liu",
                "Yongting Chen",
                "Miao Zhang",
                "Fangxin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07578v2",
                "http://arxiv.org/pdf/2308.07578v2"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07571v1",
            "title": "Ske2Grid: Skeleton-to-Grid Representation Learning for Action\n  Recognition",
            "updated": "2023-08-15T04:49:11Z",
            "published": "2023-08-15T04:49:11Z",
            "summary": "This paper presents Ske2Grid, a new representation learning framework for\nimproved skeleton-based action recognition. In Ske2Grid, we define a regular\nconvolution operation upon a novel grid representation of human skeleton, which\nis a compact image-like grid patch constructed and learned through three novel\ndesigns. Specifically, we propose a graph-node index transform (GIT) to\nconstruct a regular grid patch through assigning the nodes in the skeleton\ngraph one by one to the desired grid cells. To ensure that GIT is a bijection\nand enrich the expressiveness of the grid representation, an up-sampling\ntransform (UPT) is learned to interpolate the skeleton graph nodes for filling\nthe grid patch to the full. To resolve the problem when the one-step UPT is\naggressive and further exploit the representation capability of the grid patch\nwith increasing spatial size, a progressive learning strategy (PLS) is proposed\nwhich decouples the UPT into multiple steps and aligns them to multiple paired\nGITs through a compact cascaded design learned progressively. We construct\nnetworks upon prevailing graph convolution networks and conduct experiments on\nsix mainstream skeleton-based action recognition datasets. Experiments show\nthat our Ske2Grid significantly outperforms existing GCN-based solutions under\ndifferent benchmark settings, without bells and whistles. Code and models are\navailable at https://github.com/OSVAI/Ske2Grid",
            "author": [
                "Dongqi Cai",
                "Yangyuxuan Kang",
                "Anbang Yao",
                "Yurong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07571v1",
                "http://arxiv.org/pdf/2308.07571v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07546v1",
            "title": "3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D\n  Point Cloud Attack",
            "updated": "2023-08-15T03:29:31Z",
            "published": "2023-08-15T03:29:31Z",
            "summary": "With the maturity of depth sensors, the vulnerability of 3D point cloud\nmodels has received increasing attention in various applications such as\nautonomous driving and robot navigation. Previous 3D adversarial attackers\neither follow the white-box setting to iteratively update the coordinate\nperturbations based on gradients, or utilize the output model logits to\nestimate noisy gradients in the black-box setting. However, these attack\nmethods are hard to be deployed in real-world scenarios since realistic 3D\napplications will not share any model details to users. Therefore, we explore a\nmore challenging yet practical 3D attack setting, \\textit{i.e.}, attacking\npoint clouds with black-box hard labels, in which the attacker can only have\naccess to the prediction label of the input. To tackle this setting, we propose\na novel 3D attack method, termed \\textbf{3D} \\textbf{H}ard-label\natt\\textbf{acker} (\\textbf{3DHacker}), based on the developed decision boundary\nalgorithm to generate adversarial samples solely with the knowledge of class\nlabels. Specifically, to construct the class-aware model decision boundary,\n3DHacker first randomly fuses two point clouds of different classes in the\nspectral domain to craft their intermediate sample with high imperceptibility,\nthen projects it onto the decision boundary via binary search. To restrict the\nfinal perturbation size, 3DHacker further introduces an iterative optimization\nstrategy to move the intermediate sample along the decision boundary for\ngenerating adversarial point clouds with smallest trivial perturbations.\nExtensive evaluations show that, even in the challenging hard-label setting,\n3DHacker still competitively outperforms existing 3D attacks regarding the\nattack performance as well as adversary quality.",
            "author": [
                "Yunbo Tao",
                "Daizong Liu",
                "Pan Zhou",
                "Yulai Xie",
                "Wei Du",
                "Wei Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07546v1",
                "http://arxiv.org/pdf/2308.07546v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07543v1",
            "title": "The $\u03b1$-index of graphs without intersecting triangles/quadrangles\n  as a minor",
            "updated": "2023-08-15T03:18:04Z",
            "published": "2023-08-15T03:18:04Z",
            "summary": "The $A_{\\alpha}$-matrix of a graph $G$ is the convex linear combination of\nthe adjacency matrix $A(G)$ and the diagonal matrix of vertex degrees $D(G)$,\ni.e., $A_{\\alpha}(G) = \\alpha D(G) + (1 - \\alpha)A(G)$, where $0\\leq\\alpha\n\\leq1$. The $\\alpha$-index of $G$ is the largest eigenvalue of $A_\\alpha(G)$.\nParticularly, the matrix $A_0(G)$ (resp. $2A_{\\frac{1}{2}}(G)$) is exactly the\nadjacency matrix (resp. signless Laplacian matrix) of $G$. He, Li and Feng\n[arXiv:2301.06008 (2023)] determined the extremal graphs with maximum adjacency\nspectral radius among all graphs of sufficiently large order without\nintersecting triangles and quadrangles as a minor, respectively. Motivated by\nthe above results of He, Li and Feng, in this paper we characterize the\nextremal graphs with maximum $\\alpha$-index among all graphs of sufficiently\nlarge order without intersecting triangles and quadrangles as a minor for any\n$0<\\alpha<1$, respectively. As by-products, we determine the extremal graphs\nwith maximum signless Laplacian radius among all graphs of sufficiently large\norder without intersecting triangles and quadrangles as a minor, respectively.",
            "author": [
                "Yanting Zhang",
                "Ligong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07543v1",
                "http://arxiv.org/pdf/2308.07543v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07537v1",
            "title": "AttMOT: Improving Multiple-Object Tracking by Introducing Auxiliary\n  Pedestrian Attributes",
            "updated": "2023-08-15T02:39:39Z",
            "published": "2023-08-15T02:39:39Z",
            "summary": "Multi-object tracking (MOT) is a fundamental problem in computer vision with\nnumerous applications, such as intelligent surveillance and automated driving.\nDespite the significant progress made in MOT, pedestrian attributes, such as\ngender, hairstyle, body shape, and clothing features, which contain rich and\nhigh-level information, have been less explored. To address this gap, we\npropose a simple, effective, and generic method to predict pedestrian\nattributes to support general Re-ID embedding. We first introduce AttMOT, a\nlarge, highly enriched synthetic dataset for pedestrian tracking, containing\nover 80k frames and 6 million pedestrian IDs with different time, weather\nconditions, and scenarios. To the best of our knowledge, AttMOT is the first\nMOT dataset with semantic attributes. Subsequently, we explore different\napproaches to fuse Re-ID embedding and pedestrian attributes, including\nattention mechanisms, which we hope will stimulate the development of\nattribute-assisted MOT. The proposed method AAM demonstrates its effectiveness\nand generality on several representative pedestrian multi-object tracking\nbenchmarks, including MOT17 and MOT20, through experiments on the AttMOT\ndataset. When applied to state-of-the-art trackers, AAM achieves consistent\nimprovements in MOTA, HOTA, AssA, IDs, and IDF1 scores. For instance, on MOT17,\nthe proposed method yields a +1.1 MOTA, +1.7 HOTA, and +1.8 IDF1 improvement\nwhen used with FairMOT. To encourage further research on attribute-assisted\nMOT, we will release the AttMOT dataset.",
            "author": [
                "Yunhao Li",
                "Zhen Xiao",
                "Lin Yang",
                "Dan Meng",
                "Xin Zhou",
                "Heng Fan",
                "Libo Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07537v1",
                "http://arxiv.org/pdf/2308.07537v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08563v1",
            "title": "KMF: Knowledge-Aware Multi-Faceted Representation Learning for Zero-Shot\n  Node Classification",
            "updated": "2023-08-15T02:38:08Z",
            "published": "2023-08-15T02:38:08Z",
            "summary": "Recently, Zero-Shot Node Classification (ZNC) has been an emerging and\ncrucial task in graph data analysis. This task aims to predict nodes from\nunseen classes which are unobserved in the training process. Existing work\nmainly utilizes Graph Neural Networks (GNNs) to associate features' prototypes\nand labels' semantics thus enabling knowledge transfer from seen to unseen\nclasses. However, the multi-faceted semantic orientation in the\nfeature-semantic alignment has been neglected by previous work, i.e. the\ncontent of a node usually covers diverse topics that are relevant to the\nsemantics of multiple labels. It's necessary to separate and judge the semantic\nfactors that tremendously affect the cognitive ability to improve the\ngenerality of models. To this end, we propose a Knowledge-Aware Multi-Faceted\nframework (KMF) that enhances the richness of label semantics via the extracted\nKG (Knowledge Graph)-based topics. And then the content of each node is\nreconstructed to a topic-level representation that offers multi-faceted and\nfine-grained semantic relevancy to different labels. Due to the particularity\nof the graph's instance (i.e., node) representation, a novel geometric\nconstraint is developed to alleviate the problem of prototype drift caused by\nnode information aggregation. Finally, we conduct extensive experiments on\nseveral public graph datasets and design an application of zero-shot\ncross-domain recommendation. The quantitative results demonstrate both the\neffectiveness and generalization of KMF with the comparison of state-of-the-art\nbaselines.",
            "author": [
                "Likang Wu",
                "Junji Jiang",
                "Hongke Zhao",
                "Hao Wang",
                "Defu Lian",
                "Mengdi Zhang",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08563v1",
                "http://arxiv.org/pdf/2308.08563v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.12299v1",
            "title": "Inverse Lithography Physics-informed Deep Neural Level Set for Mask\n  Optimization",
            "updated": "2023-08-15T01:56:22Z",
            "published": "2023-08-15T01:56:22Z",
            "summary": "As the feature size of integrated circuits continues to decrease, optical\nproximity correction (OPC) has emerged as a crucial resolution enhancement\ntechnology for ensuring high printability in the lithography process. Recently,\nlevel set-based inverse lithography technology (ILT) has drawn considerable\nattention as a promising OPC solution, showcasing its powerful pattern\nfidelity, especially in advanced process. However, massive computational time\nconsumption of ILT limits its applicability to mainly correcting partial layers\nand hotspot regions. Deep learning (DL) methods have shown great potential in\naccelerating ILT. However, lack of domain knowledge of inverse lithography\nlimits the ability of DL-based algorithms in process window (PW) enhancement\nand etc. In this paper, we propose an inverse lithography physics-informed deep\nneural level set (ILDLS) approach for mask optimization. This approach utilizes\nlevel set based-ILT as a layer within the DL framework and iteratively conducts\nmask prediction and correction to significantly enhance printability and PW in\ncomparison with results from pure DL and ILT. With this approach, computation\ntime is reduced by a few orders of magnitude versus ILT. By gearing up DL with\nknowledge of inverse lithography physics, ILDLS provides a new and efficient\nmask optimization solution.",
            "author": [
                "Xing-Yu Ma",
                "Shaogang Hao"
            ],
            "link": [
                "http://dx.doi.org/10.1364/AO.503332",
                "http://arxiv.org/abs/2308.12299v1",
                "http://arxiv.org/pdf/2308.12299v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07517v1",
            "title": "Synergi: A Mixed-Initiative System for Scholarly Synthesis and\n  Sensemaking",
            "updated": "2023-08-15T01:09:39Z",
            "published": "2023-08-15T01:09:39Z",
            "summary": "Efficiently reviewing scholarly literature and synthesizing prior art are\ncrucial for scientific progress. Yet, the growing scale of publications and the\nburden of knowledge make synthesis of research threads more challenging than\never. While significant research has been devoted to helping scholars interact\nwith individual papers, building research threads scattered across multiple\npapers remains a challenge. Most top-down synthesis (and LLMs) make it\ndifficult to personalize and iterate on the output, while bottom-up synthesis\nis costly in time and effort. Here, we explore a new design space of\nmixed-initiative workflows. In doing so we develop a novel computational\npipeline, Synergi, that ties together user input of relevant seed threads with\ncitation graphs and LLMs, to expand and structure them, respectively. Synergi\nallows scholars to start with an entire threads-and-subthreads structure\ngenerated from papers relevant to their interests, and to iterate and customize\non it as they wish. In our evaluation, we find that Synergi helps scholars\nefficiently make sense of relevant threads, broaden their perspectives, and\nincreases their curiosity. We discuss future design implications for\nthread-based, mixed-initiative scholarly synthesis support tools.",
            "author": [
                "Hyeonsu B. Kang",
                "Sherry Tongshuang Wu",
                "Joseph Chee Chang",
                "Aniket Kittur"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3586183.3606759",
                "http://arxiv.org/abs/2308.07517v1",
                "http://arxiv.org/pdf/2308.07517v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07514v1",
            "title": "Eigenvalues of laplacian matrices of the cycles with one\n  negative-weighted edge",
            "updated": "2023-08-15T00:54:55Z",
            "published": "2023-08-15T00:54:55Z",
            "summary": "We study the individual behavior of the eigenvalues of the laplacian matrices\nof the cyclic graph of order $n$, where one edge has weight\n$\\alpha\\in\\mathbb{C}$, with $\\operatorname{Re}(\\alpha)<0$, and all the others\nhave weights $1$. This paper is a sequel of a previous one where we considered\n$\\operatorname{Re}(\\alpha) \\in[0,1]$ (Eigenvalues of laplacian matrices of the\ncycles with one weighted edge, Linear Algebra Appl. 653, 2022, 86--115). We\nprove that for $\\operatorname{Re}(\\alpha)<0$ and\n$n>\\operatorname{Re}(\\alpha-1)/\\operatorname{Re}(\\alpha)$, one eigenvalue is\nnegative while the others belong to $[0,4]$ and are distributed as the function\n$x\\mapsto 4\\sin^2(x/2)$. Additionally, we prove that as $n$ tends to $\\infty$,\nthe outlier eigenvalue converges exponentially to\n$4\\operatorname{Re}(\\alpha)^2/(2\\operatorname{Re}(\\alpha)-1)$. We give exact\nformulas for the half of the inner eigenvalues, while for the others we justify\nthe convergence of Newton's method and fixed-point iteration method. We find\nasymptotic expansions, as $n$ tends to $\\infty$, both for the eigenvalues\nbelonging to $[0,4]$ and the outlier. We also compute the eigenvectors and\ntheir norms.",
            "author": [
                "S. M. Grudsky",
                "E. A. Maximenko",
                "A. Soto-Gonz\u00e1lez"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07514v1",
                "http://arxiv.org/pdf/2308.07514v1"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math.RA",
                "05C50, 47B36, 15A18, 15B05, 41A60, 65F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07511v1",
            "title": "Distilling Knowledge from Resource Management Algorithms to Neural\n  Networks: A Unified Training Assistance Approach",
            "updated": "2023-08-15T00:30:58Z",
            "published": "2023-08-15T00:30:58Z",
            "summary": "As a fundamental problem, numerous methods are dedicated to the optimization\nof signal-to-interference-plus-noise ratio (SINR), in a multi-user setting.\nAlthough traditional model-based optimization methods achieve strong\nperformance, the high complexity raises the research of neural network (NN)\nbased approaches to trade-off the performance and complexity. To fully leverage\nthe high performance of traditional model-based methods and the low complexity\nof the NN-based method, a knowledge distillation (KD) based algorithm\ndistillation (AD) method is proposed in this paper to improve the performance\nand convergence speed of the NN-based method, where traditional SINR\noptimization methods are employed as ``teachers\" to assist the training of NNs,\nwhich are ``students\", thus enhancing the performance of unsupervised and\nreinforcement learning techniques. This approach aims to alleviate common\nissues encountered in each of these training paradigms, including the\ninfeasibility of obtaining optimal solutions as labels and overfitting in\nsupervised learning, ensuring higher convergence performance in unsupervised\nlearning, and improving training efficiency in reinforcement learning.\nSimulation results demonstrate the enhanced performance of the proposed\nAD-based methods compared to traditional learning methods. Remarkably, this\nresearch paves the way for the integration of traditional optimization insights\nand emerging NN techniques in wireless communication system optimization.",
            "author": [
                "Longfei Ma",
                "Nan Cheng",
                "Xiucheng Wang",
                "Zhisheng Yin",
                "Haibo Zhou",
                "Wei Quan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07511v1",
                "http://arxiv.org/pdf/2308.07511v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07504v1",
            "title": "ICAFusion: Iterative Cross-Attention Guided Feature Fusion for\n  Multispectral Object Detection",
            "updated": "2023-08-15T00:02:10Z",
            "published": "2023-08-15T00:02:10Z",
            "summary": "Effective feature fusion of multispectral images plays a crucial role in\nmulti-spectral object detection. Previous studies have demonstrated the\neffectiveness of feature fusion using convolutional neural networks, but these\nmethods are sensitive to image misalignment due to the inherent deffciency in\nlocal-range feature interaction resulting in the performance degradation. To\naddress this issue, a novel feature fusion framework of dual cross-attention\ntransformers is proposed to model global feature interaction and capture\ncomplementary information across modalities simultaneously. This framework\nenhances the discriminability of object features through the query-guided\ncross-attention mechanism, leading to improved performance. However, stacking\nmultiple transformer blocks for feature enhancement incurs a large number of\nparameters and high spatial complexity. To handle this, inspired by the human\nprocess of reviewing knowledge, an iterative interaction mechanism is proposed\nto share parameters among block-wise multimodal transformers, reducing model\ncomplexity and computation cost. The proposed method is general and effective\nto be integrated into different detection frameworks and used with different\nbackbones. Experimental results on KAIST, FLIR, and VEDAI datasets show that\nthe proposed method achieves superior performance and faster inference, making\nit suitable for various practical scenarios. Code will be available at\nhttps://github.com/chanchanchan97/ICAFusion.",
            "author": [
                "Jifeng Shen",
                "Yifei Chen",
                "Yue Liu",
                "Xin Zuo",
                "Heng Fan",
                "Wankou Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07504v1",
                "http://arxiv.org/pdf/2308.07504v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07496v1",
            "title": "ST-MLP: A Cascaded Spatio-Temporal Linear Framework with\n  Channel-Independence Strategy for Traffic Forecasting",
            "updated": "2023-08-14T23:34:59Z",
            "published": "2023-08-14T23:34:59Z",
            "summary": "The criticality of prompt and precise traffic forecasting in optimizing\ntraffic flow management in Intelligent Transportation Systems (ITS) has drawn\nsubstantial scholarly focus. Spatio-Temporal Graph Neural Networks (STGNNs)\nhave been lauded for their adaptability to road graph structures. Yet, current\nresearch on STGNNs architectures often prioritizes complex designs, leading to\nelevated computational burdens with only minor enhancements in accuracy. To\naddress this issue, we propose ST-MLP, a concise spatio-temporal model solely\nbased on cascaded Multi-Layer Perceptron (MLP) modules and linear layers.\nSpecifically, we incorporate temporal information, spatial information and\npredefined graph structure with a successful implementation of the\nchannel-independence strategy - an effective technique in time series\nforecasting. Empirical results demonstrate that ST-MLP outperforms\nstate-of-the-art STGNNs and other models in terms of accuracy and computational\nefficiency. Our finding encourages further exploration of more concise and\neffective neural network architectures in the field of traffic forecasting.",
            "author": [
                "Zepu Wang",
                "Yuqi Nie",
                "Peng Sun",
                "Nam H. Nguyen",
                "John Mulvey",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07496v1",
                "http://arxiv.org/pdf/2308.07496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07480v1",
            "title": "OCDaf: Ordered Causal Discovery with Autoregressive Flows",
            "updated": "2023-08-14T22:17:33Z",
            "published": "2023-08-14T22:17:33Z",
            "summary": "We propose OCDaf, a novel order-based method for learning causal graphs from\nobservational data. We establish the identifiability of causal graphs within\nmultivariate heteroscedastic noise models, a generalization of additive noise\nmodels that allow for non-constant noise variances. Drawing upon the structural\nsimilarities between these models and affine autoregressive normalizing flows,\nwe introduce a continuous search algorithm to find causal structures. Our\nexperiments demonstrate state-of-the-art performance across the Sachs and\nSynTReN benchmarks in Structural Hamming Distance (SHD) and Structural\nIntervention Distance (SID). Furthermore, we validate our identifiability\ntheory across various parametric and nonparametric synthetic datasets and\nshowcase superior performance compared to existing baselines.",
            "author": [
                "Hamidreza Kamkari",
                "Vahid Zehtab",
                "Vahid Balazadeh",
                "Rahul G. Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07480v1",
                "http://arxiv.org/pdf/2308.07480v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07476v2",
            "title": "Dependent rounding with strong negative-correlation, and scheduling on\n  unrelated machines to minimize completion time",
            "updated": "2023-10-19T22:28:13Z",
            "published": "2023-08-14T22:08:15Z",
            "summary": "We describe a new dependent-rounding algorithmic framework for bipartite\ngraphs. Given a fractional assignment $y$ of values to edges of graph $G = (U\n\\cup V, E)$, the algorithms return an integral solution $Y$ such that each\nright-node $v \\in V$ has at most one neighboring edge $f$ with $Y_f = 1$, and\nwhere the variables $Y_e$ also satisfy broad nonpositive-correlation\nproperties. In particular, for any edges $e_1, e_2$ sharing a left-node $u \\in\nU$, the variables $Y_{e_1}, Y_{e_2}$ have strong negative-correlation\nproperties, i.e. the expectation of $Y_{e_1} Y_{e_2}$ is significantly below\n$y_{e_1} y_{e_2}$.\n  This algorithm is based on generating negatively-correlated Exponential\nrandom variables and using them in a contention-resolution scheme inspired by\nan algorithm Im & Shadloo (2020). Our algorithm gives stronger and much more\nflexible negative correlation properties.\n  Dependent rounding schemes with negative correlation properties have been\nused for approximation algorithms for job-scheduling on unrelated machines to\nminimize weighted completion times (Bansal, Srinivasan, & Svensson (2021), Im &\nShadloo (2020), Im & Li (2023)). Using our new dependent-rounding algorithm,\namong other improvements, we obtain a $1.4$-approximation for this problem.\nThis significantly improves over the prior $1.45$-approximation ratio of Im &\nLi (2023).",
            "author": [
                "David G. Harris"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07476v2",
                "http://arxiv.org/pdf/2308.07476v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07473v1",
            "title": "On Supermodular Contracts and Dense Subgraphs",
            "updated": "2023-08-14T21:57:25Z",
            "published": "2023-08-14T21:57:25Z",
            "summary": "We study the combinatorial contract design problem, introduced and studied by\nDutting et. al. (2021, 2022), in both the single and multi-agent settings.\nPrior work has examined the problem when the principal's utility function is\nsubmodular in the actions chosen by the agent(s).\n  We complement this emerging literature with an examination of the problem\nwhen the principal's utility is supermodular.\n  In the single-agent setting, we obtain a strongly polynomial time algorithm\nfor the optimal contract.\n  This stands in contrast to the NP-hardness of the problem with submodular\nprincipal utility due to Dutting et. al. (2021).\n  This result has two technical components, the first of which applies beyond\nsupermodular or submodular utilities.\n  This result strengthens and simplifies analogous enumeration algorithms from\nDutting et. al. (2021), and applies to any nondecreasing valuation function for\nthe principal.\n  Second, we show that supermodular valuations lead to a polynomial number of\nbreakpoints, analogous to a similar result by Dutting et. al. (2021) for gross\nsubstitutes valuations.\n  In the multi-agent setting, we obtain a mixed bag of positive and negative\nresults.\n  First, we show that it is NP-hard to obtain any finite multiplicative\napproximation, or an additive FPTAS.\n  This stands in contrast to the submodular case, where efficient computation\nof approximately optimal contracts was shown by Dutting et. al. (2022).\n  Second, we derive an additive PTAS for the problem in the instructive special\ncase of graph-based supermodular valuations, and equal costs.\n  En-route to this result, we discover an intimate connection between the\nmulti-agent contract problem and the notorious k-densest subgraph problem.\n  We build on and combine techniques from the literature on dense subgraph\nproblems to obtain our additive PTAS.",
            "author": [
                "Ramiro Deo-Campo Vuong",
                "Shaddin Dughmi",
                "Neel Patel",
                "Aditya Prasad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07473v1",
                "http://arxiv.org/pdf/2308.07473v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07471v1",
            "title": "Approximations for the Steiner Multicycle Problem",
            "updated": "2023-08-14T21:51:09Z",
            "published": "2023-08-14T21:51:09Z",
            "summary": "The Steiner Multicycle problem consists of, given a complete graph, a weight\nfunction on its vertices, and a collection of pairwise disjoint non-unitary\nsets called terminal sets, finding a minimum weight collection of\nvertex-disjoint cycles in the graph such that, for every terminal set, all of\nits vertices are in a same cycle of the collection. This problem generalizes\nthe Traveling Salesman problem and therefore is hard to approximate in general.\nOn the practical side, it models a collaborative less-than-truckload problem\nwith pickup and delivery locations. Using an algorithm for the Survivable\nNetwork Design problem and T -joins, we obtain a 3-approximation for the metric\ncase, improving on the previous best 4-approximation. Furthermore, we present\nan (11/9)-approximation for the particular case of the Steiner Multicycle in\nwhich each edge weight is 1 or 2. This algorithm can be adapted to obtain a\n(7/6)-approximation when every terminal set contains at least 4 vertices.\nFinally, we devise an O(lg n)-approximation algorithm for the asymmetric\nversion of the problem.",
            "author": [
                "Cristina G. Fernandes",
                "Carla N. Lintzmayer",
                "Phablo F. S. Moura"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07471v1",
                "http://arxiv.org/pdf/2308.07471v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07468v1",
            "title": "Reducing Training Demands for 3D Gait Recognition with Deep Koopman\n  Operator Constraints",
            "updated": "2023-08-14T21:39:33Z",
            "published": "2023-08-14T21:39:33Z",
            "summary": "Deep learning research has made many biometric recognition solution viable,\nbut it requires vast training data to achieve real-world generalization. Unlike\nother biometric traits, such as face and ear, gait samples cannot be easily\ncrawled from the web to form massive unconstrained datasets. As the human body\nhas been extensively studied for different digital applications, one can rely\non prior shape knowledge to overcome data scarcity. This work follows the\nrecent trend of fitting a 3D deformable body model into gait videos using deep\nneural networks to obtain disentangled shape and pose representations for each\nframe. To enforce temporal consistency in the network, we introduce a new\nLinear Dynamical Systems (LDS) module and loss based on Koopman operator\ntheory, which provides an unsupervised motion regularization for the periodic\nnature of gait, as well as a predictive capacity for extending gait sequences.\nWe compare LDS to the traditional adversarial training approach and use the USF\nHumanID and CASIA-B datasets to show that LDS can obtain better accuracy with\nless training data. Finally, we also show that our 3D modeling approach is much\nbetter than other 3D gait approaches in overcoming viewpoint variation under\nnormal, bag-carrying and clothing change conditions.",
            "author": [
                "Cole Hill",
                "Mauricio Pamplona Segundo",
                "Sudeep Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07468v1",
                "http://arxiv.org/pdf/2308.07468v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07942v1",
            "title": "Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis",
            "updated": "2023-08-14T21:01:29Z",
            "published": "2023-08-14T21:01:29Z",
            "summary": "The task of inductive knowledge graph completion requires models to learn\ninference patterns from a training graph, which can then be used to make\npredictions on a disjoint test graph. Rule-based methods seem like a natural\nfit for this task, but in practice they significantly underperform\nstate-of-the-art methods based on Graph Neural Networks (GNNs), such as NBFNet.\nWe hypothesise that the underperformance of rule-based methods is due to two\nfactors: (i) implausible entities are not ranked at all and (ii) only the most\ninformative path is taken into account when determining the confidence in a\ngiven link prediction answer. To analyse the impact of these factors, we study\na number of variants of a rule-based approach, which are specifically aimed at\naddressing the aforementioned issues. We find that the resulting models can\nachieve a performance which is close to that of NBFNet. Crucially, the\nconsidered variants only use a small fraction of the evidence that NBFNet\nrelies on, which means that they largely keep the interpretability advantage of\nrule-based methods. Moreover, we show that a further variant, which does look\nat the full KG, consistently outperforms NBFNet.",
            "author": [
                "Akash Anil",
                "V\u00edctor Guti\u00e9rrez-Basulto",
                "Yazm\u00edn Iba\u00f1\u00e9z-Garc\u00eda",
                "Steven Schockaert"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07942v1",
                "http://arxiv.org/pdf/2308.07942v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07444v1",
            "title": "The Performance of Transferability Metrics does not Translate to Medical\n  Tasks",
            "updated": "2023-08-14T20:34:52Z",
            "published": "2023-08-14T20:34:52Z",
            "summary": "Transfer learning boosts the performance of medical image analysis by\nenabling deep learning (DL) on small datasets through the knowledge acquired\nfrom large ones. As the number of DL architectures explodes, exhaustively\nattempting all candidates becomes unfeasible, motivating cheaper alternatives\nfor choosing them. Transferability scoring methods emerge as an enticing\nsolution, allowing to efficiently calculate a score that correlates with the\narchitecture accuracy on any target dataset. However, since transferability\nscores have not been evaluated on medical datasets, their use in this context\nremains uncertain, preventing them from benefiting practitioners. We fill that\ngap in this work, thoroughly evaluating seven transferability scores in three\nmedical applications, including out-of-distribution scenarios. Despite\npromising results in general-purpose datasets, our results show that no\ntransferability score can reliably and consistently estimate target performance\nin medical contexts, inviting further work in that direction.",
            "author": [
                "Levy Chaves",
                "Alceu Bissoto",
                "Eduardo Valle",
                "Sandra Avila"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07444v1",
                "http://arxiv.org/pdf/2308.07444v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07441v1",
            "title": "Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of\n  Nitrogen Oxides",
            "updated": "2023-08-14T20:26:23Z",
            "published": "2023-08-14T20:26:23Z",
            "summary": "Atmospheric nitrogen oxides (NOx) primarily from fuel combustion have\nrecognized acute and chronic health and environmental effects. Machine learning\n(ML) methods have significantly enhanced our capacity to predict NOx\nconcentrations at ground-level with high spatiotemporal resolution but may\nsuffer from high estimation bias since they lack physical and chemical\nknowledge about air pollution dynamics. Chemical transport models (CTMs)\nleverage this knowledge; however, accurate predictions of ground-level\nconcentrations typically necessitate extensive post-calibration. Here, we\npresent a physics-informed deep learning framework that encodes\nadvection-diffusion mechanisms and fluid dynamics constraints to jointly\npredict NO2 and NOx and reduce ML model bias by 21-42%. Our approach captures\nfine-scale transport of NO2 and NOx, generates robust spatial extrapolation,\nand provides explicit uncertainty estimation. The framework fuses\nknowledge-driven physicochemical principles of CTMs with the predictive power\nof ML for air quality exposure, health, and policy applications. Our approach\noffers significant improvements over purely data-driven ML methods and has\nunprecedented bias reduction in joint NO2 and NOx prediction.",
            "author": [
                "Lianfa Li",
                "Roxana Khalili",
                "Frederick Lurmann",
                "Nathan Pavlovic",
                "Jun Wu",
                "Yan Xu",
                "Yisi Liu",
                "Karl O'Sharkey",
                "Beate Ritz",
                "Luke Oman",
                "Meredith Franklin",
                "Theresa Bastain",
                "Shohreh F. Farzan",
                "Carrie Breton",
                "Rima Habre"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07441v1",
                "http://arxiv.org/pdf/2308.07441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07439v2",
            "title": "Interaction-Aware Personalized Vehicle Trajectory Prediction Using\n  Temporal Graph Neural Networks",
            "updated": "2023-08-16T01:29:39Z",
            "published": "2023-08-14T20:20:26Z",
            "summary": "Accurate prediction of vehicle trajectories is vital for advanced driver\nassistance systems and autonomous vehicles. Existing methods mainly rely on\ngeneric trajectory predictions derived from large datasets, overlooking the\npersonalized driving patterns of individual drivers. To address this gap, we\npropose an approach for interaction-aware personalized vehicle trajectory\nprediction that incorporates temporal graph neural networks. Our method\nutilizes Graph Convolution Networks (GCN) and Long Short-Term Memory (LSTM) to\nmodel the spatio-temporal interactions between target vehicles and their\nsurrounding traffic. To personalize the predictions, we establish a pipeline\nthat leverages transfer learning: the model is initially pre-trained on a\nlarge-scale trajectory dataset and then fine-tuned for each driver using their\nspecific driving data. We employ human-in-the-loop simulation to collect\npersonalized naturalistic driving trajectories and corresponding surrounding\nvehicle trajectories. Experimental results demonstrate the superior performance\nof our personalized GCN-LSTM model, particularly for longer prediction\nhorizons, compared to its generic counterpart. Moreover, the personalized model\noutperforms individual models created without pre-training, emphasizing the\nsignificance of pre-training on a large dataset to avoid overfitting. By\nincorporating personalization, our approach enhances trajectory prediction\naccuracy.",
            "author": [
                "Amr Abdelraouf",
                "Rohit Gupta",
                "Kyungtae Han"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07439v2",
                "http://arxiv.org/pdf/2308.07439v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07422v1",
            "title": "Ubiquity of power sums in graph profiles",
            "updated": "2023-08-14T19:27:36Z",
            "published": "2023-08-14T19:27:36Z",
            "summary": "Graph density profiles are fundamental objects in extremal combinatorics.\nVery few profiles are fully known, and all are two-dimensional. We show that\neven in high dimensions ratios of graph densities and numbers often form the\npower-sum profile (the limit of the image of the power-sum map) studied\nrecently by Acevedo, Blekherman, Debus and Riener. Our choice of graphs is\nmotivated by recent work by Blekherman, Raymond and Wei on undecidability of\npolynomial inequalities in graph densities. While the ratios do not determine\nthe complete density profile, they contain high-dimensional information. For\ninstance, to reconstruct the density profile of $4k$-cycles from our results,\none needs to solve only one-parameter extremal problems, for any number of\n$4k$-cycles.",
            "author": [
                "Grigoriy Blekherman",
                "Annie Raymond"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07422v1",
                "http://arxiv.org/pdf/2308.07422v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35, 05C65, 14P99"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07420v1",
            "title": "Multiple-Hypothesis Path Planning with Uncertain Object Detections",
            "updated": "2023-08-14T19:19:47Z",
            "published": "2023-08-14T19:19:47Z",
            "summary": "Path planning in obstacle-dense environments is a key challenge in robotics,\nand depends on inferring scene attributes and associated uncertainties. We\npresent a multiple-hypothesis path planner designed to navigate complex\nenvironments using obstacle detections. Path hypotheses are generated by\nreasoning about uncertainty and range, as initial detections are typically at\nfar ranges with high uncertainty, before subsequent detections reduce this\nuncertainty. Given estimated obstacles, we build a graph of pairwise\nconnections between objects based on the probability that the robot can safely\npass between the pair. The graph is updated in real time and pruned of unsafe\npaths, providing probabilistic safety guarantees. The planner generates path\nhypotheses over this graph, then trades between safety and path length to\nintelligently optimize the best route. We evaluate our planner on randomly\ngenerated simulated forests, and find that in the most challenging\nenvironments, it increases the navigation success rate over an A* baseline from\n20% to 75%. Results indicate that the use of evolving, range-based uncertainty\nand multiple hypotheses are critical for navigating dense environments.",
            "author": [
                "Brian H. Wang",
                "Beatriz Asfora",
                "Rachel Zheng",
                "Aaron Peng",
                "Jacopo Banfi",
                "Mark Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07420v1",
                "http://arxiv.org/pdf/2308.07420v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07416v1",
            "title": "DiffHopp: A Graph Diffusion Model for Novel Drug Design via Scaffold\n  Hopping",
            "updated": "2023-08-14T19:08:34Z",
            "published": "2023-08-14T19:08:34Z",
            "summary": "Scaffold hopping is a drug discovery strategy to generate new chemical\nentities by modifying the core structure, the \\emph{scaffold}, of a known\nactive compound. This approach preserves the essential molecular features of\nthe original scaffold while introducing novel chemical elements or structural\nfeatures to enhance potency, selectivity, or bioavailability. However, there is\ncurrently a lack of generative models specifically tailored for this task,\nespecially in the pocket-conditioned context. In this work, we present\nDiffHopp, a conditional E(3)-equivariant graph diffusion model tailored for\nscaffold hopping given a known protein-ligand complex.",
            "author": [
                "Jos Torge",
                "Charles Harris",
                "Simon V. Mathis",
                "Pietro Lio"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07416v1",
                "http://arxiv.org/pdf/2308.07416v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07405v1",
            "title": "More on Rainbow Cliques in Edge-Colored Graphs",
            "updated": "2023-08-14T18:49:28Z",
            "published": "2023-08-14T18:49:28Z",
            "summary": "In an edge-colored graph $G$, a rainbow clique $K_k$ is a $k$-complete\nsubgraph in which all the edges have distinct colors. Let $e(G)$ and $c(G)$ be\nthe number of edges and colors in $G$, respectively. In this paper, we show\nthat for any $\\varepsilon>0$, if $e(G)+c(G) \\geq\n(1+\\frac{k-3}{k-2}+2\\varepsilon) {n\\choose 2}$ and $k\\geq 3$, then for\nsufficiently large $n$, the number of rainbow cliques $K_k$ in $G$ is\n$\\Omega(n^k)$.\n  We also characterize the extremal graphs $G$ without a rainbow clique $K_k$,\nfor $k=4,5$, when $e(G)+c(G)$ is maximum.\n  Our results not only address existing questions but also complete the\nfindings of Ehard and Mohr (Ehard and Mohr, Rainbow triangles and cliques in\nedge-colored graphs. {\\it European Journal of Combinatorics, 84:103037,2020}).",
            "author": [
                "Xiao-Chuan Liu",
                "Danni Peng",
                "Xu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07405v1",
                "http://arxiv.org/pdf/2308.07405v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07399v2",
            "title": "Bayesian inference of vorticity in unbounded flow from limited pressure\n  measurements",
            "updated": "2023-09-08T22:30:49Z",
            "published": "2023-08-14T18:36:16Z",
            "summary": "We study the instantaneous inference of an unbounded planar flow from sparse\nnoisy pressure measurements. The true flow field comprises one or more\nregularized point vortices of various strength and size. We interpret the true\nflow's measurements with a vortex estimator, also consisting of regularized\nvortices, and attempt to infer the positions and strengths of this estimator\nassuming little prior knowledge. The problem often has several possible\nsolutions, many due to a variety of symmetries. To deal with this ill-posedness\nand to quantify the uncertainty, we develop the vortex estimator in a Bayesian\nsetting. We use Markov-chain Monte Carlo and a Gaussian mixture model to sample\nand categorize the probable vortex states in the posterior distribution,\ntailoring the prior to avoid spurious solutions. Through experiments with one\nor more true vortices, we reveal many aspects of the vortex inference problem.\nWith fewer sensors than states, the estimator infers a manifold of\nequally-possible states. Using one more sensor than states ensures that no\ncases of rank deficiency arise. Uncertainty grows rapidly with distance when a\nvortex lies outside of the vicinity of the sensors. Vortex size cannot be\nreliably inferred, but the position and strength of a larger vortex can be\nestimated with a much smaller one. In estimates of multiple vortices their\nindividual signs are discernible because of the non-linear coupling in the\npressure. When the true vortex state is inferred from an estimator of fewer\nvortices, the estimate approximately aggregates the true vortices where\npossible.",
            "author": [
                "Jeff D. Eldredge",
                "Mathieu Le Provost"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07399v2",
                "http://arxiv.org/pdf/2308.07399v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07397v1",
            "title": "Spatial Invasion of Cooperative Parasites",
            "updated": "2023-08-14T18:33:56Z",
            "published": "2023-08-14T18:33:56Z",
            "summary": "In this paper we study invasion probabilities and invasion times of\ncooperative parasites spreading in spatially structured host populations. The\nspatial structure of the host population is given by a random geometric graph\non $[0,1]^n$, $n\\in \\mathbb{N}$, with a Poisson($N$)-distributed number of\nvertices and in which vertices are connected over an edge when they have a\ndistance of at most $r_N\\in \\Theta\\left(N^{\\frac{\\beta-1}{n}}\\right)$ for some\n$0<\\beta<1$ and $N\\rightarrow \\infty$. At a host infection many parasites are\ngenerated and parasites move along edges to neighbouring hosts. We assume that\nparasites have to cooperate to infect hosts, in the sense that at least two\nparasites need to attack a host simultaneously. We find lower and upper bounds\non the invasion probability of the parasites in terms of survival probabilities\nof branching processes with cooperation. Furthermore, we characterize the\nasymptotic invasion time.\n  An important ingredient of the proofs is a comparison with infection dynamics\nof cooperative parasites in host populations structured according to a complete\ngraph, i.e. in well-mixed host populations. For these infection processes we\ncan show that invasion probabilities are asymptotically equal to survival\nprobabilities of branching processes with cooperation.\n  Furthermore, we build in the proofs on techniques developed in [BP22], where\nan analogous invasion process has been studied for host populations structured\naccording to a configuration model.\n  We substantiate our results with simulations.",
            "author": [
                "Vianney Brouard",
                "Cornelia Pokalyuk",
                "Marco Seiler",
                "Hung Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07397v1",
                "http://arxiv.org/pdf/2308.07397v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "q-bio.PE",
                "60J80, 60J85, 92D30, 92D25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07396v1",
            "title": "Extremal solutions for Network Flow with Differential Constraints -- A\n  Generalization of Spanning Trees",
            "updated": "2023-08-14T18:31:33Z",
            "published": "2023-08-14T18:31:33Z",
            "summary": "In network flow problems, there is a well-known one-to-one relationship\nbetween extreme points of the feasibility region and trees in the associated\nundirected graph. The same is true for the dual differential problem. In this\npaper, we study problems where the constraints of both problems appear\nsimultaneously, a variant which is motivated by an application in the expansion\nplanning of energy networks. We show that all extreme points still directly\ncorrespond to graph-theoretical structures in the underlying network. The\nreverse is generally also true in all but certain exceptional cases. We\nfurthermore characterize graphs in which these exceptional cases never occur\nand present additional criteria for when those cases do not occur due to\nparameter values.",
            "author": [
                "Ren\u00e9 Brandenberg",
                "Paul Stursberg"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07396v1",
                "http://arxiv.org/pdf/2308.07396v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.OC",
                "05C21 (Primary) 90C35, 90B10, 05C83, 05C05 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07317v1",
            "title": "Platypus: Quick, Cheap, and Powerful Refinement of LLMs",
            "updated": "2023-08-14T17:59:56Z",
            "published": "2023-08-14T17:59:56Z",
            "summary": "We present $\\textbf{Platypus}$, a family of fine-tuned and merged Large\nLanguage Models (LLMs) that achieves the strongest performance and currently\nstands at first place in HuggingFace's Open LLM Leaderboard as of the release\ndate of this work. In this work we describe (1) our curated dataset\n$\\textbf{Open-Platypus}$, that is a subset of other open datasets and which\n$\\textit{we release to the public}$ (2) our process of fine-tuning and merging\nLoRA modules in order to conserve the strong prior of pretrained LLMs, while\nbringing specific domain knowledge to the surface (3) our efforts in checking\nfor test data leaks and contamination in the training data, which can inform\nfuture research. Specifically, the Platypus family achieves strong performance\nin quantitative LLM metrics across model sizes, topping the global Open LLM\nleaderboard while using just a fraction of the fine-tuning data and overall\ncompute that are required for other state-of-the-art fine-tuned LLMs. In\nparticular, a 13B Platypus model can be trained on $\\textit{a single}$ A100 GPU\nusing 25k questions in 5 hours. This is a testament of the quality of our\nOpen-Platypus dataset, and opens opportunities for more improvements in the\nfield. Project page: https://platypus-llm.github.io",
            "author": [
                "Ariel N. Lee",
                "Cole J. Hunter",
                "Nataniel Ruiz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07317v1",
                "http://arxiv.org/pdf/2308.07317v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07316v1",
            "title": "Jurassic World Remake: Bringing Ancient Fossils Back to Life via\n  Zero-Shot Long Image-to-Image Translation",
            "updated": "2023-08-14T17:59:31Z",
            "published": "2023-08-14T17:59:31Z",
            "summary": "With a strong understanding of the target domain from natural language, we\nproduce promising results in translating across large domain gaps and bringing\nskeletons back to life. In this work, we use text-guided latent diffusion\nmodels for zero-shot image-to-image translation (I2I) across large domain gaps\n(longI2I), where large amounts of new visual features and new geometry need to\nbe generated to enter the target domain. Being able to perform translations\nacross large domain gaps has a wide variety of real-world applications in\ncriminology, astrology, environmental conservation, and paleontology. In this\nwork, we introduce a new task Skull2Animal for translating between skulls and\nliving animals. On this task, we find that unguided Generative Adversarial\nNetworks (GANs) are not capable of translating across large domain gaps.\nInstead of these traditional I2I methods, we explore the use of guided\ndiffusion and image editing models and provide a new benchmark model,\nRevive-2I, capable of performing zero-shot I2I via text-prompting latent\ndiffusion models. We find that guidance is necessary for longI2I because, to\nbridge the large domain gap, prior knowledge about the target domain is needed.\nIn addition, we find that prompting provides the best and most scalable\ninformation about the target domain as classifier-guided diffusion models\nrequire retraining for specific use cases and lack stronger constraints on the\ntarget domain because of the wide variety of images they are trained on.",
            "author": [
                "Alexander Martin",
                "Haitian Zheng",
                "Jie An",
                "Jiebo Luo"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612708",
                "http://arxiv.org/abs/2308.07316v1",
                "http://arxiv.org/pdf/2308.07316v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "I.4; I.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07309v2",
            "title": "Reinforcing Security and Usability of Crypto-Wallet with Post-Quantum\n  Cryptography and Zero-Knowledge Proof",
            "updated": "2023-08-29T07:41:15Z",
            "published": "2023-08-14T17:54:20Z",
            "summary": "Crypto-wallets or digital asset wallets are a crucial aspect of managing\ncryptocurrencies and other digital assets such as NFTs. However, these wallets\nare not immune to security threats, particularly from the growing risk of\nquantum computing. The use of traditional public-key cryptography systems in\ndigital asset wallets makes them vulnerable to attacks from quantum computers,\nwhich may increase in the future. Moreover, current digital wallets require\nusers to keep track of seed-phrases, which can be challenging and lead to\nadditional security risks. To overcome these challenges, a new algorithm is\nproposed that uses post-quantum cryptography (PQC) and zero-knowledge proof\n(ZKP) to enhance the security of digital asset wallets. The research focuses on\nthe use of the Lattice-based Threshold Secret Sharing Scheme (LTSSS), Kyber\nAlgorithm for key generation and ZKP for wallet unlocking, providing a more\nsecure and user-friendly alternative to seed-phrase, brain and multi-sig\nprotocol wallets. This algorithm also includes several innovative security\nfeatures such as recovery of wallets in case of downtime of the server, and the\nability to rekey the private key associated with a specific username-password\ncombination, offering improved security and usability. The incorporation of PQC\nand ZKP provides a robust and comprehensive framework for securing digital\nassets in the present and future. This research aims to address the security\nchallenges faced by digital asset wallets and proposes practical solutions to\nensure their safety in the era of quantum computing.",
            "author": [
                "Yathin Kethepalli",
                "Rony Joseph",
                "Sai Raja Vajrala",
                "Jashwanth Vemula",
                "Nenavath Srinivas Naik"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07309v2",
                "http://arxiv.org/pdf/2308.07309v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07304v1",
            "title": "BehaVR: User Identification Based on VR Sensor Data",
            "updated": "2023-08-14T17:43:42Z",
            "published": "2023-08-14T17:43:42Z",
            "summary": "Virtual reality (VR) platforms enable a wide range of applications, however\npose unique privacy risks. In particular, VR devices are equipped with a rich\nset of sensors that collect personal and sensitive information (e.g., body\nmotion, eye gaze, hand joints, and facial expression), which can be used to\nuniquely identify a user, even without explicit identifiers. In this paper, we\nare interested in understanding the extent to which a user can be identified\nbased on data collected by different VR sensors. We consider adversaries with\ncapabilities that range from observing APIs available within a single VR app\n(app adversary) to observing all, or selected, sensor measurements across all\napps on the VR device (device adversary). To that end, we introduce BEHAVR, a\nframework for collecting and analyzing data from all sensor groups collected by\nall apps running on a VR device. We use BEHAVR to perform a user study and\ncollect data from real users that interact with popular real-world apps. We use\nthat data to build machine learning models for user identification, with\nfeatures extracted from sensor data available within and across apps. We show\nthat these models can identify users with an accuracy of up to 100%, and we\nreveal the most important features and sensor groups, depending on the\nfunctionality of the app and the strength of the adversary, as well as the\nminimum time needed for user identification. To the best of our knowledge,\nBEHAVR is the first to analyze user identification in VR comprehensively, i.e.,\nconsidering jointly all sensor measurements available on a VR device (whether\nwithin an app or across multiple apps), collected by real-world, as opposed to\ncustom-made, apps.",
            "author": [
                "Ismat Jarin",
                "Yu Duan",
                "Rahmadi Trimananda",
                "Hao Cui",
                "Salma Elmalaki",
                "Athina Markopoulou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07304v1",
                "http://arxiv.org/pdf/2308.07304v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07278v1",
            "title": "Local antimagic chromatic number of partite graphs",
            "updated": "2023-08-14T17:10:11Z",
            "published": "2023-08-14T17:10:11Z",
            "summary": "Let $G$ be a connected graph with $|V| = n$ and $|E| = m$. A bijection\n$f:E\\rightarrow \\{1,2,...,m\\}$ is called a local antimagic labeling of $G$ if\nfor any two adjacent vertices $u$ and $v$, $w(u) \\neq w(v)$, where $w(u) =\n\\sum_{e \\in E(u)}f(e)$, and $E(u)$ is the set of edges incident to $u$. Thus,\nany local antimagic labeling induces a proper vertex coloring of $G$ where the\nvertex $v$ is assigned the color $w(v)$. The local antimagic chromatic number\nis the minimum number of colors taken over all colorings induced by local\nantimagic labelings of $G$. Let $m,n > 1$. In this paper, the local antimagic\nchromatic number of a complete tripartite graph $K_{1,m,n}$, and $r$ copies of\na complete bipartite graph $K_{m,n}$ where $m \\not \\equiv n \\bmod 2$ are\ndetermined.",
            "author": [
                "C. R. Pavithra",
                "A. V. Prajeesh",
                "V. S. Sarath"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07278v1",
                "http://arxiv.org/pdf/2308.07278v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C78"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07272v1",
            "title": "Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt\n  Optimization for Few-shot Learning",
            "updated": "2023-08-14T16:58:50Z",
            "published": "2023-08-14T16:58:50Z",
            "summary": "Prompt-based pre-trained language models (PLMs) paradigm have succeeded\nsubstantially in few-shot natural language processing (NLP) tasks. However,\nprior discrete prompt optimization methods require expert knowledge to design\nthe base prompt set and identify high-quality prompts, which is costly,\ninefficient, and subjective. Meanwhile, existing continuous prompt optimization\nmethods improve the performance by learning the ideal prompts through the\ngradient information of PLMs, whose high computational cost, and low\nreadability and generalizability are often concerning. To address the research\ngap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt\nOptimization ($DP_2O$) method. We first design a multi-round dialogue alignment\nstrategy for readability prompt set generation based on GPT-4. Furthermore, we\npropose an efficient prompt screening metric to identify high-quality prompts\nwith linear complexity. Finally, we construct a reinforcement learning (RL)\nframework based on policy gradients to match the prompts to inputs optimally.\nBy training a policy network with only 0.67% of the PLM parameter size on the\ntasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA)\nmethod by 1.52% in accuracy on average on four open-source datasets. Moreover,\nsubsequent experiments also demonstrate that $DP_2O$ has good universality,\nrobustness, and generalization ability.",
            "author": [
                "Chengzhengxu Li",
                "Xiaoming Liu",
                "Yichen Wang",
                "Duyi Li",
                "Yu Lan",
                "Chao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07272v1",
                "http://arxiv.org/pdf/2308.07272v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07269v1",
            "title": "EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language\n  Models",
            "updated": "2023-08-14T16:52:42Z",
            "published": "2023-08-14T16:52:42Z",
            "summary": "Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy\nissues, which means they are unaware of unseen events or generate text with\nincorrect facts owing to the outdated/noisy data. To this end, many knowledge\nediting approaches for LLMs have emerged -- aiming to subtly inject/edit\nupdated knowledge or adjust undesired behavior while minimizing the impact on\nunrelated inputs. Nevertheless, due to significant differences among various\nknowledge editing methods and the variations in task setups, there is no\nstandard implementation framework available for the community, which hinders\npractitioners to apply knowledge editing to applications. To address these\nissues, we propose EasyEdit, an easy-to-use knowledge editing framework for\nLLMs. It supports various cutting-edge knowledge editing approaches and can be\nreadily apply to many well-known LLMs such as T5, GPT-J, LlaMA, etc.\nEmpirically, we report the knowledge editing results on LlaMA-2 with EasyEdit,\ndemonstrating that knowledge editing surpasses traditional fine-tuning in terms\nof reliability and generalization. We have released the source code on GitHub\nat https://github.com/zjunlp/EasyEdit, along with Google Colab tutorials and\ncomprehensive documentation for beginners to get started. Besides, we present\nan online system for real-time knowledge editing, and a demo video at\nhttp://knowlm.zjukg.cn/easyedit.mp4.",
            "author": [
                "Peng Wang",
                "Ningyu Zhang",
                "Xin Xie",
                "Yunzhi Yao",
                "Bozhong Tian",
                "Mengru Wang",
                "Zekun Xi",
                "Siyuan Cheng",
                "Kangwei Liu",
                "Guozhou Zheng",
                "Huajun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07269v1",
                "http://arxiv.org/pdf/2308.07269v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07253v1",
            "title": "Path-specific causal decomposition analysis with multiple correlated\n  mediator variables",
            "updated": "2023-08-14T16:39:57Z",
            "published": "2023-08-14T16:39:57Z",
            "summary": "A causal decomposition analysis allows researchers to determine whether the\ndifference in a health outcome between two groups can be attributed to a\ndifference in each group's distribution of one or more modifiable mediator\nvariables. With this knowledge, researchers and policymakers can focus on\ndesigning interventions that target these mediator variables. Existing methods\nfor causal decomposition analysis either focus on one mediator variable or\nassume that each mediator variable is conditionally independent given the group\nlabel and the mediator-outcome confounders. In this paper, we propose a\nflexible causal decomposition analysis method that can accommodate multiple\ncorrelated and interacting mediator variables, which are frequently seen in\nstudies of health behaviors and studies of environmental pollutants. We extend\na Monte Carlo-based causal decomposition analysis method to this setting by\nusing a multivariate mediator model that can accommodate any combination of\nbinary and continuous mediator variables. Furthermore, we state the causal\nassumptions needed to identify both joint and path-specific decomposition\neffects through each mediator variable. To illustrate the reduction in bias and\nconfidence interval width of the decomposition effects under our proposed\nmethod, we perform a simulation study. We also apply our approach to examine\nwhether differences in smoking status and dietary inflammation score explain\nany of the Black-White differences in incident diabetes using data from a\nnational cohort study.",
            "author": [
                "Melissa J. Smith",
                "Leslie A. McClure",
                "D. Leann Long"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07253v1",
                "http://arxiv.org/pdf/2308.07253v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07247v1",
            "title": "Can we Agree? On the Rash\u014dmon Effect and the Reliability of Post-Hoc\n  Explainable AI",
            "updated": "2023-08-14T16:32:24Z",
            "published": "2023-08-14T16:32:24Z",
            "summary": "The Rash\\=omon effect poses challenges for deriving reliable knowledge from\nmachine learning models. This study examined the influence of sample size on\nexplanations from models in a Rash\\=omon set using SHAP. Experiments on 5\npublic datasets showed that explanations gradually converged as the sample size\nincreased. Explanations from <128 samples exhibited high variability, limiting\nreliable knowledge extraction. However, agreement between models improved with\nmore data, allowing for consensus. Bagging ensembles often had higher\nagreement. The results provide guidance on sufficient data to trust\nexplanations. Variability at low samples suggests that conclusions may be\nunreliable without validation. Further work is needed with more model types,\ndata domains, and explanation methods. Testing convergence in neural networks\nand with model-specific explanation methods would be impactful. The approaches\nexplored here point towards principled techniques for eliciting knowledge from\nambiguous models.",
            "author": [
                "Clement Poiret",
                "Antoine Grigis",
                "Justin Thomas",
                "Marion Noulhiane"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07247v1",
                "http://arxiv.org/pdf/2308.07247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML",
                "H.1.1; I.6.4; I.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07241v3",
            "title": "Context-Aware Planning and Environment-Aware Memory for Instruction\n  Following Embodied Agents",
            "updated": "2023-08-22T02:20:22Z",
            "published": "2023-08-14T16:23:21Z",
            "summary": "Accomplishing household tasks requires to plan step-by-step actions\nconsidering the consequences of previous actions. However, the state-of-the-art\nembodied agents often make mistakes in navigating the environment and\ninteracting with proper objects due to imperfect learning by imitating experts\nor algorithmic planners without such knowledge. To improve both visual\nnavigation and object interaction, we propose to consider the consequence of\ntaken actions by CAPEAM (Context-Aware Planning and Environment-Aware Memory)\nthat incorporates semantic context (e.g., appropriate objects to interact with)\nin a sequence of actions, and the changed spatial arrangement and states of\ninteracted objects (e.g., location that the object has been moved to) in\ninferring the subsequent actions. We empirically show that the agent with the\nproposed CAPEAM achieves state-of-the-art performance in various metrics using\na challenging interactive instruction following benchmark in both seen and\nunseen environments by large margins (up to +10.70% in unseen env.).",
            "author": [
                "Byeonghwi Kim",
                "Jinyeon Kim",
                "Yuyeong Kim",
                "Cheolhong Min",
                "Jonghyun Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07241v3",
                "http://arxiv.org/pdf/2308.07241v3"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07235v1",
            "title": "KD-Club: An Efficient Exact Algorithm with New Coloring-based Upper\n  Bound for the Maximum k-Defective Clique Problem",
            "updated": "2023-08-14T16:17:29Z",
            "published": "2023-08-14T16:17:29Z",
            "summary": "The Maximum k-Defective Clique Problem (MDCP) aims to find a maximum\nk-defective clique in a given graph, where a k-defective clique is a relaxation\nclique missing at most k edges. MDCP is NP-hard and finds many real-world\napplications in analyzing dense but not necessarily complete subgraphs. Exact\nalgorithms for MDCP mainly follow the Branch-and-bound (BnB) framework, whose\nperformance heavily depends on the quality of the upper bound on the\ncardinality of a maximum k-defective clique. The state-of-the-art BnB MDCP\nalgorithms calculate the upper bound quickly but conservatively as they ignore\nmany possible missing edges. In this paper, we propose a novel CoLoring-based\nUpper Bound (CLUB) that uses graph coloring techniques ingeniously to detect\nindependent sets so as to detect missing edges ignored by the previous methods.\nWe then develop a new BnB algorithm for MDCP, called KD-Club, using CLUB in\nboth the preprocessing stage for graph reduction and the BnB searching process\nfor branch pruning. Extensive experiments show that KD-Club significantly\noutperforms state-of-the-art BnB MDCP algorithms on the number of solved\ninstances within the cut-off time, having much smaller search tree and shorter\nsolving time on various benchmarks.",
            "author": [
                "Jiongzhi Zheng",
                "Mingming Jin",
                "Kun He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07235v1",
                "http://arxiv.org/pdf/2308.07235v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07229v3",
            "title": "Compositional nonlinear audio signal processing with Volterra series",
            "updated": "2023-09-14T19:59:51Z",
            "published": "2023-08-14T16:05:38Z",
            "summary": "We develop a compositional theory of nonlinear audio signal processing based\non a categorification of the Volterra series. We begin by considering what it\nwould mean for the Volterra series to be functorial with respect to a base\ncategory whose objects are temperate distributions and whose morphisms are\ncertain linear transformations. This leads to formulae describing how the\noutcomes of nonlinear transformations are affected if their input signals are\nfirst linearly processed. We then consider how nonlinear audio systems change,\nand introduce as a model thereof a notion of morphism of Volterra series, which\nwe exhibit as a kind of lens map. We show how morphisms can be parameterized\nand used to generate indexed families of Volterra series, which are well-suited\nto model nonstationary or time-varying nonlinear phenomena. We then describe\nhow Volterra series and their morphisms organize into a category, which we call\nVolt. We exhibit the operations of sum, product, and series composition of\nVolterra series as monoidal products on Volt and identify, for each in turn,\nits corresponding universal property. We show, in particular, that the series\ncomposition of Volterra series is associative. We then bridge between our\nframework and a subject at the heart of audio signal processing: time-frequency\nanalysis. Specifically, we show that an equivalence between a certain class of\nsecond-order Volterra series and the bilinear time-frequency distributions\n(TFDs) can be extended to one between certain higher-order Volterra series and\nthe so-called polynomial TFDs. We end with prospects for future work, including\nthe incorporation of nonlinear system identification techniques and the\nextension of our theory to the settings of compositional graph and topological\naudio signal processing.",
            "author": [
                "Jake Araujo-Simon"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07229v3",
                "http://arxiv.org/pdf/2308.07229v3"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD",
                "cs.SY",
                "eess.SP",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07222v1",
            "title": "MM-GEF: Multi-modal representation meet collaborative filtering",
            "updated": "2023-08-14T15:47:36Z",
            "published": "2023-08-14T15:47:36Z",
            "summary": "In modern e-commerce, item content features in various modalities offer\naccurate yet comprehensive information to recommender systems. The majority of\nprevious work either focuses on learning effective item representation during\nmodelling user-item interactions, or exploring item-item relationships by\nanalysing multi-modal features. Those methods, however, fail to incorporate the\ncollaborative item-user-item relationships into the multi-modal feature-based\nitem structure. In this work, we propose a graph-based item structure\nenhancement method MM-GEF: Multi-Modal recommendation with Graph Early-Fusion,\nwhich effectively combines the latent item structure underlying multi-modal\ncontents with the collaborative signals. Instead of processing the content\nfeature in different modalities separately, we show that the early-fusion of\nmulti-modal features provides significant improvement. MM-GEF learns refined\nitem representations by injecting structural information obtained from both\nmulti-modal and collaborative signals. Through extensive experiments on four\npublicly available datasets, we demonstrate systematical improvements of our\nmethod over state-of-the-art multi-modal recommendation methods.",
            "author": [
                "Hao Wu",
                "Alejandro Ariza-Casabona",
                "Bart\u0142omiej Twardowski",
                "Tri Kurniawan Wijaya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07222v1",
                "http://arxiv.org/pdf/2308.07222v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07218v2",
            "title": "Packing $T$-connectors in graphs needs more connectivity",
            "updated": "2023-08-15T14:10:47Z",
            "published": "2023-08-14T15:38:18Z",
            "summary": "Strengthening the classical concept of Steiner trees, West and Wu [J. Combin.\nTheory Ser. B 102 (2012), 186--205] introduced the notion of a $T$-connector in\na graph $G$ with a set $T$ of terminals. They conjectured that if the set $T$\nis $3k$-edge-connected in $G$, then $G$ contains $k$ edge-disjoint\n$T$-connectors. We disprove this conjecture by constructing infinitely many\ncounterexamples for $k=1$ and for each even $k$.",
            "author": [
                "Roman \u010cada",
                "Adam Kabela",
                "Tom\u00e1\u0161 Kaiser",
                "Petr Vr\u00e1na"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07218v2",
                "http://arxiv.org/pdf/2308.07218v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C40 (Primary) 05C70 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07206v2",
            "title": "Spectroscopic survey of higher-lying states of $B_c$ meson family",
            "updated": "2023-10-23T09:28:44Z",
            "published": "2023-08-14T15:23:56Z",
            "summary": "In this work, we investigate the spectroscopy of higher $B_c$ mesons, with a\nspecial focus on the consideration of the unquenched effects. To account for\nsuch effects, we employ the modified Godfrey-Isgur model and introduce a\nscreening potential. The resulting mass spectrum of the concerned higher $B_c$\nstates is then presented, showing significant deviations after considering the\nunquenched effects. This emphasizes the importance of considering the\nunquenched effects when studying of the higher $B_c$ mesons. Furthermore, we\ndetermine the corresponding spatial wave functions of these $B_c$ mesons, which\nhave practical applications in subsequent studies of their decays. These decays\ninclude two-body Okuba-Zweig-Iizuka allowed strong decays, dipion transitions\nbetween $B_c$ mesons, radiative decays, and some typical weak decays. With the\nongoing high-luminosity upgrade of the Large Hadron Collider, we expect the\ndiscovery of additional $B_c$ states in the near future. The knowledge gained\nfrom the mass spectrum and the different decay modes will undoubtedly provide\nvaluable insights for future experimental explorations of these higher $B_c$\nmesons.",
            "author": [
                "Xue-Jian Li",
                "Yu-Shuai Li",
                "Fu-Lai Wang",
                "Xiang Liu"
            ],
            "link": [
                "http://dx.doi.org/10.1140/epjc/s10052-023-12237-9",
                "http://arxiv.org/abs/2308.07206v2",
                "http://arxiv.org/pdf/2308.07206v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07204v1",
            "title": "Algorithms for the Training of Neural Support Vector Machines",
            "updated": "2023-08-14T15:16:39Z",
            "published": "2023-08-14T15:16:39Z",
            "summary": "Neural support vector machines (NSVMs) allow for the incorporation of domain\nknowledge in the design of the model architecture. In this article we introduce\na set of training algorithms for NSVMs that leverage the Pegasos algorithm and\nprovide a proof of concept by solving a set of standard machine learning tasks.",
            "author": [
                "Lars Simon",
                "Manuel Radons"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07204v1",
                "http://arxiv.org/pdf/2308.07204v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T99"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07194v1",
            "title": "Star-critical Ramsey numbers and regular Ramsey numbers for stars",
            "updated": "2023-08-14T14:58:33Z",
            "published": "2023-08-14T14:58:33Z",
            "summary": "Let $G$ be a graph, $H$ be a subgraph of $G$, and let $G- H$ be the graph\nobtained from $G$ by removing a copy of $H$. Let $K_{1, n}$ be the star on $n+\n1$ vertices. Let $t\\geq 2$ be an integer and $H_{1}, \\dots, H_{t}$ and $H$ be\ngraphs, and let $H\\rightarrow (H_{1}, \\dots, H_{t})$ denote that every $t$\ncoloring of $E(H)$ yields a monochromatic copy of $H_{i}$ in color $i$ for some\n$i\\in [t]$. Ramsey number $r(H_{1}, \\dots, H_{t})$ is the minimum integer $N$\nsuch that $K_{N}\\rightarrow (H_{1}, \\dots, H_{t})$. Star-critical Ramsey number\n$r_{*}(H_{1}, \\dots, H_{t})$ is the minimum integer $k$ such that $K_{N}- K_{1,\nN- 1- k}\\rightarrow (H_{1}, \\dots, H_{t})$ where $N= r(H_{1}, \\dots, H_{t})$.\nLet $rr(H_{1}, \\dots, H_{t})$ be the regular Ramsey number for $H_{1}, \\dots,\nH_{t}$, which is the minimum integer $r$ such that if $G$ is an $r$-regular\ngraph on $r(H_{1}, \\dots, H_{t})$ vertices, then $G\\rightarrow (H_{1}, \\dots,\nH_{t})$. Let $m_{1}, \\dots, m_{t}$ be integers larger than one, exactly $k$ of\nwhich are even. In this paper, we prove that if $k\\geq 2$ is even, then\n$r_{*}(K_{1, m_{1}}, \\dots, K_{1, m_{t}})= \\sum_{i= 1}^{t} m_{i}- t+ 1-\n\\frac{k}{2}$ which disproves a conjecture of Budden and DeJonge in 2022.\nFurthermore, we prove that if $k\\geq 2$ is even, then $rr(K_{1, m_{1}}, \\dots,\nK_{1, m_{t}})= \\sum_{i= 1}^{t} m_{i}- t$. Otherwise, $rr(K_{1, m_{1}}, \\dots,\nK_{1, m_{t}})= \\sum_{i= 1}^{t} m_{i}- t+ 1$.",
            "author": [
                "Zhidan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07194v1",
                "http://arxiv.org/pdf/2308.07194v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07359v1",
            "title": "Improving ICD-based semantic similarity by accounting for varying\n  degrees of comorbidity",
            "updated": "2023-08-14T14:56:07Z",
            "published": "2023-08-14T14:56:07Z",
            "summary": "Finding similar patients is a common objective in precision medicine,\nfacilitating treatment outcome assessment and clinical decision support.\nChoosing widely-available patient features and appropriate mathematical methods\nfor similarity calculations is crucial. International Statistical\nClassification of Diseases and Related Health Problems (ICD) codes are used\nworldwide to encode diseases and are available for nearly all patients.\nAggregated as sets consisting of primary and secondary diagnoses they can\ndisplay a degree of comorbidity and reveal comorbidity patterns. It is possible\nto compute the similarity of patients based on their ICD codes by using\nsemantic similarity algorithms. These algorithms have been traditionally\nevaluated using a single-term expert rated data set.\n  However, real-word patient data often display varying degrees of documented\ncomorbidities that might impair algorithm performance. To account for this, we\npresent a scale term that considers documented comorbidity-variance. In this\nwork, we compared the performance of 80 combinations of established algorithms\nin terms of semantic similarity based on ICD-code sets. The sets have been\nextracted from patients with a C25.X (pancreatic cancer) primary diagnosis and\nprovide a variety of different combinations of ICD-codes. Using our scale term\nwe yielded the best results with a combination of level-based information\ncontent, Leacock & Chodorow concept similarity and bipartite graph matching for\nthe set similarities reaching a correlation of 0.75 with our expert's ground\ntruth. Our results highlight the importance of accounting for comorbidity\nvariance while demonstrating how well current semantic similarity algorithms\nperform.",
            "author": [
                "Jan Janosch Schneider",
                "Marius Adler",
                "Christoph Ammer-Herrmenau",
                "Alexander Otto K\u00f6nig",
                "Ulrich Sax",
                "Jonas H\u00fcgel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07359v1",
                "http://arxiv.org/pdf/2308.07359v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07187v2",
            "title": "Asymptotic nonnegative rank of matrices",
            "updated": "2023-09-10T07:32:09Z",
            "published": "2023-08-14T14:46:03Z",
            "summary": "The nonnegative rank of nonnegative matrices is an important quantity that\nappears in many fields, such as combinatorial optimization, communication\ncomplexity, and information theory. In this paper, we study the asymptotic\ngrowth of the nonnegative rank of a fixed nonnegative matrix under Kronecker\nproduct. This quantity is called the asymptotic nonnegative rank, which is\nalready studied in information theory. By applying the theory of asymptotic\nspectra of V. Strassen (J. Reine Angew. Math. 1988), we introduce the\nasymptotic spectrum of nonnegative matrices and give a dual characterization of\nthe asymptotic nonnegative rank. As the opposite of nonnegative rank, we\nintroduce the notion of the subrank of a nonnegative matrix and show that it is\nexactly equal to the size of the maximum induced matching of the bipartite\ngraph defined on the support of the matrix (therefore, independent of the value\nof entries). Finally, we show that two matrix parameters, namely rank and\nfractional cover number, belong to the asymptotic spectrum of nonnegative\nmatrices.",
            "author": [
                "Quoc-Tung Le",
                "Hoang Ta"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07187v2",
                "http://arxiv.org/pdf/2308.07187v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CC",
                "math.AC",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07183v2",
            "title": "On Thompson Problem",
            "updated": "2023-09-17T22:13:16Z",
            "published": "2023-08-14T14:42:28Z",
            "summary": "In 1987, the second author of this paper reported his conjecture, all finite\nsimple groups $S$ can be characterized uniformly using the order of $S$ and the\nset of element orders in $S$, to Prof. J. G. Thompson. In their communications,\nThompson posed his problem about the judgment of solvability of finite groups\n$G$. In this paper we give a positive answer for Thompson's problem if the\nprime graph of $G$ is not connection.",
            "author": [
                "Rulin Shen",
                "Wujie Shi",
                "Feng Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07183v2",
                "http://arxiv.org/pdf/2308.07183v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "20D06, 20D60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07358v1",
            "title": "Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural\n  Networks",
            "updated": "2023-08-14T14:39:13Z",
            "published": "2023-08-14T14:39:13Z",
            "summary": "Computational Fluid Dynamics (CFD) is widely used in different engineering\nfields, but accurate simulations are dependent upon proper meshing of the\nsimulation domain. While highly refined meshes may ensure precision, they come\nwith high computational costs. Similarly, adaptive remeshing techniques require\nmultiple simulations and come at a great computational cost. This means that\nthe meshing process is reliant upon expert knowledge and years of experience.\nAutomating mesh generation can save significant time and effort and lead to a\nfaster and more efficient design process. This paper presents a machine\nlearning-based scheme that utilizes Graph Neural Networks (GNN) and expert\nguidance to automatically generate CFD meshes for aircraft models. In this\nwork, we introduce a new 3D segmentation algorithm that outperforms two\nstate-of-the-art models, PointNet++ and PointMLP, for surface classification.\nWe also present a novel approach to project predictions from 3D mesh\nsegmentation models to CAD surfaces using the conformal predictions method,\nwhich provides marginal statistical guarantees and robust uncertainty\nquantification and handling. We demonstrate that the addition of conformal\npredictions effectively enables the model to avoid under-refinement, hence\nfailure, in CFD meshing even for weak and less accurate models. Finally, we\ndemonstrate the efficacy of our approach through a real-world case study that\ndemonstrates that our automatically generated mesh is comparable in quality to\nexpert-generated meshes and enables the solver to converge and produce accurate\nresults. Furthermore, we compare our approach to the alternative of adaptive\nremeshing in the same case study and find that our method is 5 times faster in\nthe overall process of simulation. The code and data for this project are made\npublicly available at https://github.com/ahnobari/AutoSurf.",
            "author": [
                "Amin Heyrani Nobari",
                "Justin Rey",
                "Suhas Kodali",
                "Matthew Jones",
                "Faez Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07358v1",
                "http://arxiv.org/pdf/2308.07358v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08459v1",
            "title": "Knowledge Prompt-tuning for Sequential Recommendation",
            "updated": "2023-08-14T14:31:33Z",
            "published": "2023-08-14T14:31:33Z",
            "summary": "Pre-trained language models (PLMs) have demonstrated strong performance in\nsequential recommendation (SR), which are utilized to extract general\nknowledge. However, existing methods still lack domain knowledge and struggle\nto capture users' fine-grained preferences. Meanwhile, many traditional SR\nmethods improve this issue by integrating side information while suffering from\ninformation loss. To summarize, we believe that a good recommendation system\nshould utilize both general and domain knowledge simultaneously. Therefore, we\nintroduce an external knowledge base and propose Knowledge Prompt-tuning for\nSequential Recommendation (\\textbf{KP4SR}). Specifically, we construct a set of\nrelationship templates and transform a structured knowledge graph (KG) into\nknowledge prompts to solve the problem of the semantic gap. However, knowledge\nprompts disrupt the original data structure and introduce a significant amount\nof noise. We further construct a knowledge tree and propose a knowledge tree\nmask, which restores the data structure in a mask matrix form, thus mitigating\nthe noise problem. We evaluate KP4SR on three real-world datasets, and\nexperimental results show that our approach outperforms state-of-the-art\nmethods on multiple evaluation metrics. Specifically, compared with PLM-based\nmethods, our method improves NDCG@5 and HR@5 by \\textcolor{red}{40.65\\%} and\n\\textcolor{red}{36.42\\%} on the books dataset, \\textcolor{red}{11.17\\%} and\n\\textcolor{red}{11.47\\%} on the music dataset, and \\textcolor{red}{22.17\\%} and\n\\textcolor{red}{19.14\\%} on the movies dataset, respectively. Our code is\npublicly available at the link:\n\\href{https://github.com/zhaijianyang/KP4SR}{\\textcolor{blue}{https://github.com/zhaijianyang/KP4SR}.}",
            "author": [
                "Jianyang Zhai",
                "Xiawu Zheng",
                "Chang-Dong Wang",
                "Hui Li",
                "Yonghong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08459v1",
                "http://arxiv.org/pdf/2308.08459v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07172v1",
            "title": "Economic complexity and the sustainability transition: A review of data,\n  methods, and literature",
            "updated": "2023-08-14T14:28:00Z",
            "published": "2023-08-14T14:28:00Z",
            "summary": "Economic Complexity (EC) methods have gained increasing popularity across\nfields and disciplines. In particular, the EC toolbox has proved particularly\npromising in the study of complex and interrelated phenomena, such as the\ntransition towards a greener economy. Using the EC approach, scholars have been\ninvestigating the relationship between EC and sustainability, proposing to\nidentify the distinguishing characteristics of green products and to assess the\nreadiness of productive and technological structures for the sustainability\ntransition. This article proposes to review and summarize the data, methods,\nand empirical literature that are relevant to the study of the sustainability\ntransition from an EC perspective. We review three distinct but connected\nblocks of literature on EC and environmental sustainability. First, we survey\nthe evidence linking measures of EC to indicators related to environmental\nsustainability. Second, we review articles that strive to assess the green\ncompetitiveness of productive systems. Third, we examine evidence on green\ntechnological development and its connection to non-green knowledge bases.\nFinally, we summarize the findings for each block and identify avenues for\nfurther research in this recent and growing body of empirical literature.",
            "author": [
                "Bernardo Caldarola",
                "Dario Mazzilli",
                "Lorenzo Napolitano",
                "Aurelio Patelli",
                "Angelica Sbardella"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07172v1",
                "http://arxiv.org/pdf/2308.07172v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07168v1",
            "title": "On the distances within cliques in a soft random geometric graph",
            "updated": "2023-08-14T14:21:42Z",
            "published": "2023-08-14T14:21:42Z",
            "summary": "We study the distances of edges within cliques in a soft random geometric\ngraph on a torus, where the vertices are points of a homogeneous Poisson point\nprocess, and far-away points are less likely to be connected than nearby\npoints. We obtain the scaling of the maximal distance between any two points\nwithin a clique of size $k$. Moreover, we show that asymptotically in all\ncliques with large distances, there is only one remote point and all other\npoints are nearby. Furthermore, we prove that a re-scaled version of the\nmaximal $k$-clique distance converges in distribution to a Fr\\'echet\ndistribution. Thereby, we describe the order of magnitude according to which\nthe largest distance between two points in a clique decreases with the clique\nsize.",
            "author": [
                "Ercan S\u00f6nmez",
                "Clara Stegehuis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07168v1",
                "http://arxiv.org/pdf/2308.07168v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07163v2",
            "title": "HyperSparse Neural Networks: Shifting Exploration to Exploitation\n  through Adaptive Regularization",
            "updated": "2023-08-16T06:52:21Z",
            "published": "2023-08-14T14:18:11Z",
            "summary": "Sparse neural networks are a key factor in developing resource-efficient\nmachine learning applications. We propose the novel and powerful sparse\nlearning method Adaptive Regularized Training (ART) to compress dense into\nsparse networks. Instead of the commonly used binary mask during training to\nreduce the number of model weights, we inherently shrink weights close to zero\nin an iterative manner with increasing weight regularization. Our method\ncompresses the pre-trained model knowledge into the weights of highest\nmagnitude. Therefore, we introduce a novel regularization loss named\nHyperSparse that exploits the highest weights while conserving the ability of\nweight exploration. Extensive experiments on CIFAR and TinyImageNet show that\nour method leads to notable performance gains compared to other sparsification\nmethods, especially in extremely high sparsity regimes up to 99.8 percent model\nsparsity. Additional investigations provide new insights into the patterns that\nare encoded in weights with high magnitudes.",
            "author": [
                "Patrick Glandorf",
                "Timo Kaiser",
                "Bodo Rosenhahn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07163v2",
                "http://arxiv.org/pdf/2308.07163v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07153v1",
            "title": "DELO: Deep Evidential LiDAR Odometry using Partial Optimal Transport",
            "updated": "2023-08-14T14:06:21Z",
            "published": "2023-08-14T14:06:21Z",
            "summary": "Accurate, robust, and real-time LiDAR-based odometry (LO) is imperative for\nmany applications like robot navigation, globally consistent 3D scene map\nreconstruction, or safe motion-planning. Though LiDAR sensor is known for its\nprecise range measurement, the non-uniform and uncertain point sampling density\ninduce structural inconsistencies. Hence, existing supervised and unsupervised\npoint set registration methods fail to establish one-to-one matching\ncorrespondences between LiDAR frames. We introduce a novel deep learning-based\nreal-time (approx. 35-40ms per frame) LO method that jointly learns accurate\nframe-to-frame correspondences and model's predictive uncertainty (PU) as\nevidence to safe-guard LO predictions. In this work, we propose (i) partial\noptimal transportation of LiDAR feature descriptor for robust LO estimation,\n(ii) joint learning of predictive uncertainty while learning odometry over\ndriving sequences, and (iii) demonstrate how PU can serve as evidence for\nnecessary pose-graph optimization when LO network is either under or over\nconfident. We evaluate our method on KITTI dataset and show competitive\nperformance, even superior generalization ability over recent state-of-the-art\napproaches. Source codes are available.",
            "author": [
                "Sk Aziz Ali",
                "Djamila Aouada",
                "Gerd Reis",
                "Didier Stricker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07153v1",
                "http://arxiv.org/pdf/2308.07153v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07151v1",
            "title": "Diffusion Based Augmentation for Captioning and Retrieval in Cultural\n  Heritage",
            "updated": "2023-08-14T13:59:04Z",
            "published": "2023-08-14T13:59:04Z",
            "summary": "Cultural heritage applications and advanced machine learning models are\ncreating a fruitful synergy to provide effective and accessible ways of\ninteracting with artworks. Smart audio-guides, personalized art-related content\nand gamification approaches are just a few examples of how technology can be\nexploited to provide additional value to artists or exhibitions. Nonetheless,\nfrom a machine learning point of view, the amount of available artistic data is\noften not enough to train effective models. Off-the-shelf computer vision\nmodules can still be exploited to some extent, yet a severe domain shift is\npresent between art images and standard natural image datasets used to train\nsuch models. As a result, this can lead to degraded performance. This paper\nintroduces a novel approach to address the challenges of limited annotated data\nand domain shifts in the cultural heritage domain. By leveraging generative\nvision-language models, we augment art datasets by generating diverse\nvariations of artworks conditioned on their captions. This augmentation\nstrategy enhances dataset diversity, bridging the gap between natural images\nand artworks, and improving the alignment of visual cues with knowledge from\ngeneral-purpose datasets. The generated variations assist in training vision\nand language models with a deeper understanding of artistic characteristics and\nthat are able to generate better captions with appropriate jargon.",
            "author": [
                "Dario Cioni",
                "Lorenzo Berlincioni",
                "Federico Becattini",
                "Alberto del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07151v1",
                "http://arxiv.org/pdf/2308.07151v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07146v1",
            "title": "CTP: Towards Vision-Language Continual Pretraining via Compatible\n  Momentum Contrast and Topology Preservation",
            "updated": "2023-08-14T13:53:18Z",
            "published": "2023-08-14T13:53:18Z",
            "summary": "Vision-Language Pretraining (VLP) has shown impressive results on diverse\ndownstream tasks by offline training on large-scale datasets. Regarding the\ngrowing nature of real-world data, such an offline training paradigm on\never-expanding data is unsustainable, because models lack the continual\nlearning ability to accumulate knowledge constantly. However, most continual\nlearning studies are limited to uni-modal classification and existing\nmulti-modal datasets cannot simulate continual non-stationary data stream\nscenarios. To support the study of Vision-Language Continual Pretraining\n(VLCP), we first contribute a comprehensive and unified benchmark dataset P9D\nwhich contains over one million product image-text pairs from 9 industries. The\ndata from each industry as an independent task supports continual learning and\nconforms to the real-world long-tail nature to simulate pretraining on web\ndata. We comprehensively study the characteristics and challenges of VLCP, and\npropose a new algorithm: Compatible momentum contrast with Topology\nPreservation, dubbed CTP. The compatible momentum model absorbs the knowledge\nof the current and previous-task models to flexibly update the modal feature.\nMoreover, Topology Preservation transfers the knowledge of embedding across\ntasks while preserving the flexibility of feature adjustment. The experimental\nresults demonstrate our method not only achieves superior performance compared\nwith other baselines but also does not bring an expensive training burden.\nDataset and codes are available at https://github.com/KevinLight831/CTP.",
            "author": [
                "Hongguang Zhu",
                "Yunchao Wei",
                "Xiaodan Liang",
                "Chunjie Zhang",
                "Yao Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07146v1",
                "http://arxiv.org/pdf/2308.07146v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07134v3",
            "title": "Natural Language is All a Graph Needs",
            "updated": "2023-08-24T03:54:45Z",
            "published": "2023-08-14T13:41:09Z",
            "summary": "The emergence of large-scale pre-trained language models, such as ChatGPT,\nhas revolutionized various research fields in artificial intelligence.\nTransformers-based large language models (LLMs) have gradually replaced CNNs\nand RNNs to unify fields of computer vision and natural language processing.\nCompared with the data that exists relatively independently such as images,\nvideos or texts, graph is a type of data that contains rich structural and\nrelational information. Meanwhile, natural language, as one of the most\nexpressive mediums, excels in describing complex structures. However, existing\nwork on incorporating graph learning problems into the generative language\nmodeling framework remains very limited. As the importance of large language\nmodels continues to grow, it becomes essential to explore whether LLMs can also\nreplace GNNs as the foundation model for graphs. In this paper, we propose\nInstructGLM (Instruction-finetuned Graph Language Model), systematically design\nhighly scalable prompts based on natural language instructions, and use natural\nlanguage to describe the geometric structure and node features of the graph for\ninstruction tuning an LLM to perform learning and inference on graphs in a\ngenerative manner. Our method exceeds all competitive GNN baselines on\nogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of\nour method and sheds light on generative large language models as the\nfoundation model for graph machine learning.",
            "author": [
                "Ruosong Ye",
                "Caiqi Zhang",
                "Runhui Wang",
                "Shuyuan Xu",
                "Yongfeng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07134v3",
                "http://arxiv.org/pdf/2308.07134v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07128v1",
            "title": "Hardy-Littlewood maximal operators on trees with bounded geometry",
            "updated": "2023-08-14T13:28:25Z",
            "published": "2023-08-14T13:28:25Z",
            "summary": "In this paper we study the $L^p$ boundedness of the centred and the uncentred\nHardy--Littlewood maximal operators on the class $\\Upsilon_{a,b}$, $2\\leq a\\leq\nb$, of trees with $(a,b)$-bounded geometry. We find the sharp range of $p$,\ndepending on $a$ and $b$, where the centred maximal operator is bounded on\n$L^p(\\mathfrak T)$ for all $\\mathfrak T$ in $\\Upsilon_{a,b}$. We show that\nthere exists a tree in $\\Upsilon_{a,b}$ for which the uncentred maximal\nfunction is bounded on $L^p$ if and only if $p=\\infty$. We also extend these\nresults to graphs which are strictly roughly isometric, in the sense of Kanai,\nto trees in the class $\\Upsilon_{a,b}$.",
            "author": [
                "Matteo Levi",
                "Stefano Meda",
                "Federico Santagati",
                "Maria Vallarino"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07128v1",
                "http://arxiv.org/pdf/2308.07128v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "math.CA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07119v1",
            "title": "On the Importance of Spatial Relations for Few-shot Action Recognition",
            "updated": "2023-08-14T12:58:02Z",
            "published": "2023-08-14T12:58:02Z",
            "summary": "Deep learning has achieved great success in video recognition, yet still\nstruggles to recognize novel actions when faced with only a few examples. To\ntackle this challenge, few-shot action recognition methods have been proposed\nto transfer knowledge from a source dataset to a novel target dataset with only\none or a few labeled videos. However, existing methods mainly focus on modeling\nthe temporal relations between the query and support videos while ignoring the\nspatial relations. In this paper, we find that the spatial misalignment between\nobjects also occurs in videos, notably more common than the temporal\ninconsistency. We are thus motivated to investigate the importance of spatial\nrelations and propose a more accurate few-shot action recognition method that\nleverages both spatial and temporal information. Particularly, a novel Spatial\nAlignment Cross Transformer (SA-CT) which learns to re-adjust the spatial\nrelations and incorporates the temporal information is contributed. Experiments\nreveal that, even without using any temporal information, the performance of\nSA-CT is comparable to temporal based methods on 3/4 benchmarks. To further\nincorporate the temporal information, we propose a simple yet effective\nTemporal Mixer module. The Temporal Mixer enhances the video representation and\nimproves the performance of the full SA-CT model, achieving very competitive\nresults. In this work, we also exploit large-scale pretrained models for\nfew-shot action recognition, providing useful insights for this research\ndirection.",
            "author": [
                "Yilun Zhang",
                "Yuqian Fu",
                "Xingjun Ma",
                "Lizhe Qi",
                "Jingjing Chen",
                "Zuxuan Wu",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07119v1",
                "http://arxiv.org/pdf/2308.07119v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07099v1",
            "title": "Kernelization for Spreading Points",
            "updated": "2023-08-14T12:23:53Z",
            "published": "2023-08-14T12:23:53Z",
            "summary": "We consider the following problem about dispersing points. Given a set of\npoints in the plane, the task is to identify whether by moving a small number\nof points by small distance, we can obtain an arrangement of points such that\nno pair of points is ``close\" to each other. More precisely, for a family of\n$n$ points, an integer $k$, and a real number $d > 0$, we ask whether at most\n$k$ points could be relocated, each point at distance at most $d$ from its\noriginal location, such that the distance between each pair of points is at\nleast a fixed constant, say $1$. A number of approximation algorithms for\nvariants of this problem, under different names like distant representatives,\ndisk dispersing, or point spreading, are known in the literature. However, to\nthe best of our knowledge, the parameterized complexity of this problem remains\nwidely unexplored. We make the first step in this direction by providing a\nkernelization algorithm that, in polynomial time, produces an equivalent\ninstance with $O(d^2k^3)$ points. As a byproduct of this result, we also design\na non-trivial fixed-parameter tractable (FPT) algorithm for the problem,\nparameterized by $k$ and $d$. Finally, we complement the result about\npolynomial kernelization by showing a lower bound that rules out the existence\nof a kernel whose size is polynomial in $k$ alone, unless $\\mathsf{NP}\n\\subseteq \\mathsf{coNP}/\\text{poly}$.",
            "author": [
                "Fedor V. Fomin",
                "Petr A. Golovach",
                "Tanmay Inamdar",
                "Saket Saurabh",
                "Meirav Zehavi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07099v1",
                "http://arxiv.org/pdf/2308.07099v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07939v2",
            "title": "Ada-QPacknet -- adaptive pruning with bit width reduction as an\n  efficient continual learning method without forgetting",
            "updated": "2023-10-01T15:43:45Z",
            "published": "2023-08-14T12:17:11Z",
            "summary": "Continual Learning (CL) is a process in which there is still huge gap between\nhuman and deep learning model efficiency. Recently, many CL algorithms were\ndesigned. Most of them have many problems with learning in dynamic and complex\nenvironments. In this work new architecture based approach Ada-QPacknet is\ndescribed. It incorporates the pruning for extracting the sub-network for each\ntask. The crucial aspect in architecture based CL methods is theirs capacity.\nIn presented method the size of the model is reduced by efficient linear and\nnonlinear quantisation approach. The method reduces the bit-width of the\nweights format. The presented results shows that low bit quantisation achieves\nsimilar accuracy as floating-point sub-network on a well-know CL scenarios. To\nour knowledge it is the first CL strategy which incorporates both compression\ntechniques pruning and quantisation for generating task sub-networks. The\npresented algorithm was tested on well-known episode combinations and compared\nwith most popular algorithms. Results show that proposed approach outperforms\nmost of the CL strategies in task and class incremental scenarios.",
            "author": [
                "Marcin Pietro\u0144",
                "Dominik \u017burek",
                "Kamil Faber",
                "Roberto Corizzo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07939v2",
                "http://arxiv.org/pdf/2308.07939v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07086v2",
            "title": "Diameter of classical groups generated by transvections",
            "updated": "2023-08-21T10:24:48Z",
            "published": "2023-08-14T11:29:12Z",
            "summary": "Let $G$ be a finite classical group generated by transvections, i.e., one of\n$\\operatorname{SL}_n(q)$, $\\operatorname{SU}_n(q)$,\n$\\operatorname{Sp}_{2n}(q)$, or $\\operatorname{O}^\\pm_{2n}(q)$ ($q$ even), and\nlet $X$ be a generating set for $G$ containing at least one transvection.\nBuilding on work of Garonzi, Halasi, and Somlai, we prove that the diameter of\nthe Cayley graph $\\operatorname{Cay}(G, X)$ is bounded by $(n \\log q)^C$ for\nsome constant $C$. This confirms Babai's conjecture on the diameter of finite\nsimple groups in the case of generating sets containing a transvection.\n  By combining this with a result of the author and Jezernik it follows that if\n$G$ is one of $\\operatorname{SL}_n(q)$, $\\operatorname{SU}_n(q)$,\n$\\operatorname{Sp}_{2n}(q)$ and $X$ contains three random generators then with\nhigh probability the diameter $\\operatorname{Cay}(G, X)$ is bounded by\n$n^{O(\\log q)}$. This confirms Babai's conjecture for non-orthogonal classical\nsimple groups over small fields and three random generators.",
            "author": [
                "Sean Eberhard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07086v2",
                "http://arxiv.org/pdf/2308.07086v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07085v1",
            "title": "Hue: A User-Adaptive Parser for Hybrid Logs",
            "updated": "2023-08-14T11:28:50Z",
            "published": "2023-08-14T11:28:50Z",
            "summary": "Log parsing, which extracts log templates from semi-structured logs and\nproduces structured logs, is the first and the most critical step in automated\nlog analysis. While existing log parsers have achieved decent results, they\nsuffer from two major limitations by design. First, they do not natively\nsupport hybrid logs that consist of both single-line logs and multi-line logs\n(\\eg Java Exception and Hadoop Counters). Second, they fall short in\nintegrating domain knowledge in parsing, making it hard to identify ambiguous\ntokens in logs. This paper defines a new research problem, \\textit{hybrid log\nparsing}, as a superset of traditional log parsing tasks, and proposes\n\\textit{Hue}, the first attempt for hybrid log parsing via a user-adaptive\nmanner. Specifically, Hue converts each log message to a sequence of special\nwildcards using a key casting table and determines the log types via line\naggregating and pattern extracting. In addition, Hue can effectively utilize\nuser feedback via a novel merge-reject strategy, making it possible to quickly\nadapt to complex and changing log templates. We evaluated Hue on three hybrid\nlog datasets and sixteen widely-used single-line log datasets (\\ie Loghub). The\nresults show that Hue achieves an average grouping accuracy of 0.845 on hybrid\nlogs, which largely outperforms the best results (0.563 on average) obtained by\nexisting parsers. Hue also exhibits SOTA performance on single-line log\ndatasets. Furthermore, Hue has been successfully deployed in a real production\nenvironment for daily hybrid log parsing.",
            "author": [
                "Junjielong Xu",
                "Qiuai Fu",
                "Zhouruixing Zhu",
                "Yutong Cheng",
                "Zhijing Li",
                "Yuchi Ma",
                "Pinjia He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07085v1",
                "http://arxiv.org/pdf/2308.07085v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07078v1",
            "title": "ICPC: Instance-Conditioned Prompting with Contrastive Learning for\n  Semantic Segmentation",
            "updated": "2023-08-14T11:21:47Z",
            "published": "2023-08-14T11:21:47Z",
            "summary": "Modern supervised semantic segmentation methods are usually finetuned based\non the supervised or self-supervised models pre-trained on ImageNet. Recent\nwork shows that transferring the knowledge from CLIP to semantic segmentation\nvia prompt learning can achieve promising performance. The performance boost\ncomes from the feature enhancement with multimodal alignment, i.e., the dot\nproduct between vision and text embeddings. However, how to improve the\nmultimodal alignment for better transfer performance in dense tasks remains\nunderexplored. In this work, we focus on improving the quality of vision-text\nalignment from two aspects of prompting design and loss function, and present\nan instance-conditioned prompting with contrastive learning (ICPC) framework.\nFirst, compared with the static prompt designs, we reveal that dynamic\nprompting conditioned on image content can more efficiently utilize the text\nencoder for complex dense tasks. Second, we propose an align-guided contrastive\nloss to refine the alignment of vision and text embeddings. We further propose\nlightweight multi-scale alignment for better performance. Extensive experiments\non three large-scale datasets (ADE20K, COCO-Stuff10k, and ADE20K-Full)\ndemonstrate that ICPC brings consistent improvements across diverse backbones.\nTaking ResNet-50 as an example, ICPC outperforms the state-of-the-art\ncounterpart by 1.71%, 1.05%, and 1.41% mIoU on the three datasets,\nrespectively.",
            "author": [
                "Chaohui Yu",
                "Qiang Zhou",
                "Zhibin Wang",
                "Fan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07078v1",
                "http://arxiv.org/pdf/2308.07078v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07064v1",
            "title": "Axiomatic Theory of Independence Relations in Model Theory",
            "updated": "2023-08-14T10:54:49Z",
            "published": "2023-08-14T10:54:49Z",
            "summary": "This course introduces the fruitful links between model theory and a\ncombinatoric of sets given by independence relations. An independence relation\non a set is a ternary relation between subsets. Chapter 1 should be considered\nas an introductory chapter. It does not mention first-order theories or\nformulas. It introduces independence relations in a naive set theory framework.\nIts goal is to get the reader familiar with basic axioms of independence\nrelations (which do not need an ambient theory to be stated) as well as\nintroduce closure operators and pregeometries. Chapter 2 introduces the\nmodel-theoretic context. The two main examples (algebraically closed fields and\nthe random graph) are described as well as independence relations in those\nexamples. Chapter 3 gives the axioms of independence relations in a\nmodel-theoretic context. It introduces the general toolbox of the\nmodel-theorists (indiscernible sequences, Ramsey/Erdos-Rado and compactness)\nand the independence relations of heirs/coheirs with two main applications:\nAdler's theorem of symmetry (how symmetry emerges from a weaker set of axioms,\nwhich is rooted in the work of Kim and Pillay) and a criterion for NSOP4 using\nstationary independence relations in the style of Conant. Independence\nrelations satisfying Adler's theorem of symmetry are here called 'Adler\nindependence relations' or AIR. Chapter 4 treats forking and dividing. It is\nproved that dividing independence is always stronger than any AIR (even though\nit is not an AIR in general) a connection between the independence theorem and\nforking independence, which holds in all generality and is based on\nKim-Pillay's approach. Then, simplicity is defined and the interesting\ndirection of the Kim-Pillay theorem (namely that the existence of an Adler\nindependence relation satisfying the independence theorem yields simplicity) is\ndeduced from earlier results.",
            "author": [
                "Christian d'Elb\u00e9e"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07064v1",
                "http://arxiv.org/pdf/2308.07064v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07063v1",
            "title": "Budget-constrained cut problems",
            "updated": "2023-08-14T10:53:53Z",
            "published": "2023-08-14T10:53:53Z",
            "summary": "The minimum and maximum cuts of an undirected edge-weighted graph are classic\nproblems in graph theory. While the Min-Cut Problem can be solved in P, the\nMax-Cut Problem is NP-Complete. Exact and heuristic methods have been developed\nfor solving them. For both problems, we introduce a natural extension in which\ncutting an edge induces a cost. Our goal is to find a cut that minimizes the\nsum of the cut weights but, at the same time, restricts its total cut cost to a\ngiven budget. We prove that both restricted problems are NPComplete and we also\nstudy some of its properties. Finally, we develop exact algorithms to solve\nboth as well as a non-exact algorithm for the min-cut case based on a\nLagreangean relaxation that generally provides optimal solutions. Their\nperformance is reported by an extensive computational experience.",
            "author": [
                "Justo Puerto",
                "Jos\u00e9 L. Sainz-Pardo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07063v1",
                "http://arxiv.org/pdf/2308.07063v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07058v1",
            "title": "Temporal clustering of social interactions trades-off disease spreading\n  and knowledge diffusion",
            "updated": "2023-08-14T10:37:51Z",
            "published": "2023-08-14T10:37:51Z",
            "summary": "Non-pharmaceutical measures such as preventive quarantines, remote working,\nschool and workplace closures, lockdowns, etc. have shown effectivenness from\nan epidemic control perspective; however they have also significant negative\nconsequences on social life and relationships, work routines, and community\nengagement. In particular, complex ideas, work and school collaborations,\ninnovative discoveries, and resilient norms formation and maintenance, which\noften require face-to-face interactions of two or more parties to be developed\nand synergically coordinated, are particularly affected. In this study, we\npropose an alternative hybrid solution that balances the slowdown of epidemic\ndiffusion with the preservation of face-to-face interactions. Our approach\ninvolves a two-step partitioning of the population. First, we tune the level of\nnode clustering, creating \"social bubbles\" with increased contacts within each\nbubble and fewer outside, while maintaining the average number of contacts in\neach network. Second, we tune the level of temporal clustering by pairing, for\na certain time interval, nodes from specific social bubbles. Our results\ndemonstrate that a hybrid approach can achieve better trade-offs between\nepidemic control and complex knowledge diffusion. The versatility of our model\nenables tuning and refining clustering levels to optimally achieve the desired\ntrade-off, based on the potentially changing characteristics of a disease or\nknowledge diffusion process.",
            "author": [
                "Giulia Cencetti",
                "Lorenzo Lucchini",
                "Gabriele Santin",
                "Federico Battiston",
                "Esteban Moro",
                "Alex Pentland",
                "Bruno Lepri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07058v1",
                "http://arxiv.org/pdf/2308.07058v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07056v6",
            "title": "VoxBlink: A Large Scale Speaker Verification Dataset on Camera",
            "updated": "2023-09-15T06:01:14Z",
            "published": "2023-08-14T10:31:29Z",
            "summary": "In this paper, we introduce a large-scale and high-quality audio-visual\nspeaker verification dataset, named VoxBlink. We propose an innovative and\nrobust automatic audio-visual data mining pipeline to curate this dataset,\nwhich contains 1.45M utterances from 38K speakers. Due to the inherent nature\nof automated data collection, introducing noisy data is inevitable. Therefore,\nwe also utilize a multi-modal purification step to generate a cleaner version\nof the VoxBlink, named VoxBlink-clean, comprising 18K identities and 1.02M\nutterances. In contrast to the VoxCeleb, the VoxBlink sources from short videos\nof ordinary users, and the covered scenarios can better align with real-life\nsituations. To our best knowledge, the VoxBlink dataset is one of the largest\npublicly available speaker verification datasets. Leveraging the VoxCeleb and\nVoxBlink-clean datasets together, we employ diverse speaker verification models\nwith multiple architectural backbones to conduct comprehensive evaluations on\nthe VoxCeleb test sets. Experimental results indicate a substantial enhancement\nin performance,ranging from 12% to 30% relatively, across various backbone\narchitectures upon incorporating the VoxBlink-clean into the training process.\nThe details of the dataset can be found on http://voxblink.github.io",
            "author": [
                "Yuke Lin",
                "Xiaoyi Qin",
                "Guoqing Zhao",
                "Ming Cheng",
                "Ning Jiang",
                "Haiyang Wu",
                "Ming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07056v6",
                "http://arxiv.org/pdf/2308.07056v6"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.MM",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07032v1",
            "title": "S3IM: Stochastic Structural SIMilarity and Its Unreasonable\n  Effectiveness for Neural Fields",
            "updated": "2023-08-14T09:45:28Z",
            "published": "2023-08-14T09:45:28Z",
            "summary": "Recently, Neural Radiance Field (NeRF) has shown great success in rendering\nnovel-view images of a given scene by learning an implicit representation with\nonly posed RGB images. NeRF and relevant neural field methods (e.g., neural\nsurface representation) typically optimize a point-wise loss and make\npoint-wise predictions, where one data point corresponds to one pixel.\nUnfortunately, this line of research failed to use the collective supervision\nof distant pixels, although it is known that pixels in an image or scene can\nprovide rich structural information. To the best of our knowledge, we are the\nfirst to design a nonlocal multiplex training paradigm for NeRF and relevant\nneural field methods via a novel Stochastic Structural SIMilarity (S3IM) loss\nthat processes multiple data points as a whole set instead of process multiple\ninputs independently. Our extensive experiments demonstrate the unreasonable\neffectiveness of S3IM in improving NeRF and neural surface representation for\nnearly free. The improvements of quality metrics can be particularly\nsignificant for those relatively difficult tasks: e.g., the test MSE loss\nunexpectedly drops by more than 90% for TensoRF and DVGO over eight novel view\nsynthesis tasks; a 198% F-score gain and a 64% Chamfer $L_{1}$ distance\nreduction for NeuS over eight surface reconstruction tasks. Moreover, S3IM is\nconsistently robust even with sparse inputs, corrupted images, and dynamic\nscenes.",
            "author": [
                "Zeke Xie",
                "Xindi Yang",
                "Yujie Yang",
                "Qi Sun",
                "Yixiang Jiang",
                "Haoran Wang",
                "Yunfeng Cai",
                "Mingming Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07032v1",
                "http://arxiv.org/pdf/2308.07032v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07029v1",
            "title": "A discretization scheme for path-dependent FBSDEs",
            "updated": "2023-08-14T09:36:27Z",
            "published": "2023-08-14T09:36:27Z",
            "summary": "This paper studies a discretization scheme for solutions to forward-backward\nstochastic differential equations (FBSDEs) with path-dependent coefficients. We\nshow the convergence of the Picard-type iteration to the FBDSE solution and\nprovide its convergence rate. To the best of our knowledge, this is the first\nresult of discretization scheme for path-dependent FBSDEs. Using this result,\nwe establish a numerical method for solutions to second-order parabolic\npath-dependent partial differential equations. To achieve this, weak\napproximation of martingale representation theorem (Cont, Rama, and Yi Lu.\n``Weak approximation of martingale representations.\" Stochastic Processes and\ntheir Applications 2016) is employed. Our results generalize the scheme for\nMarkovian cases in (Bender, Christian, and Robert Denk. ``A forward scheme for\nbackward SDEs.\" Stochastic processes and their applications, 2007)",
            "author": [
                "Jiuk Jang",
                "Hyungbin Park"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07029v1",
                "http://arxiv.org/pdf/2308.07029v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "q-fin.CP",
                "q-fin.MF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07026v1",
            "title": "AdvCLIP: Downstream-agnostic Adversarial Examples in Multimodal\n  Contrastive Learning",
            "updated": "2023-08-14T09:29:22Z",
            "published": "2023-08-14T09:29:22Z",
            "summary": "Multimodal contrastive learning aims to train a general-purpose feature\nextractor, such as CLIP, on vast amounts of raw, unlabeled paired image-text\ndata. This can greatly benefit various complex downstream tasks, including\ncross-modal image-text retrieval and image classification. Despite its\npromising prospect, the security issue of cross-modal pre-trained encoder has\nnot been fully explored yet, especially when the pre-trained encoder is\npublicly available for commercial use.\n  In this work, we propose AdvCLIP, the first attack framework for generating\ndownstream-agnostic adversarial examples based on cross-modal pre-trained\nencoders. AdvCLIP aims to construct a universal adversarial patch for a set of\nnatural images that can fool all the downstream tasks inheriting the victim\ncross-modal pre-trained encoder. To address the challenges of heterogeneity\nbetween different modalities and unknown downstream tasks, we first build a\ntopological graph structure to capture the relevant positions between target\nsamples and their neighbors. Then, we design a topology-deviation based\ngenerative adversarial network to generate a universal adversarial patch. By\nadding the patch to images, we minimize their embeddings similarity to\ndifferent modality and perturb the sample distribution in the feature space,\nachieving unviersal non-targeted attacks. Our results demonstrate the excellent\nattack performance of AdvCLIP on two types of downstream tasks across eight\ndatasets. We also tailor three popular defenses to mitigate AdvCLIP,\nhighlighting the need for new defense mechanisms to defend cross-modal\npre-trained encoders.",
            "author": [
                "Ziqi Zhou",
                "Shengshan Hu",
                "Minghui Li",
                "Hangtao Zhang",
                "Yechao Zhang",
                "Hai Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07026v1",
                "http://arxiv.org/pdf/2308.07026v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07351v1",
            "title": "IOB: Integrating Optimization Transfer and Behavior Transfer for\n  Multi-Policy Reuse",
            "updated": "2023-08-14T09:22:35Z",
            "published": "2023-08-14T09:22:35Z",
            "summary": "Humans have the ability to reuse previously learned policies to solve new\ntasks quickly, and reinforcement learning (RL) agents can do the same by\ntransferring knowledge from source policies to a related target task. Transfer\nRL methods can reshape the policy optimization objective (optimization\ntransfer) or influence the behavior policy (behavior transfer) using source\npolicies. However, selecting the appropriate source policy with limited samples\nto guide target policy learning has been a challenge. Previous methods\nintroduce additional components, such as hierarchical policies or estimations\nof source policies' value functions, which can lead to non-stationary policy\noptimization or heavy sampling costs, diminishing transfer effectiveness. To\naddress this challenge, we propose a novel transfer RL method that selects the\nsource policy without training extra components. Our method utilizes the Q\nfunction in the actor-critic framework to guide policy selection, choosing the\nsource policy with the largest one-step improvement over the current target\npolicy. We integrate optimization transfer and behavior transfer (IOB) by\nregularizing the learned policy to mimic the guidance policy and combining them\nas the behavior policy. This integration significantly enhances transfer\neffectiveness, surpasses state-of-the-art transfer RL baselines in benchmark\ntasks, and improves final performance and knowledge transferability in\ncontinual learning scenarios. Additionally, we show that our optimization\ntransfer technique is guaranteed to improve target policy learning.",
            "author": [
                "Siyuan Li",
                "Hao Li",
                "Jin Zhang",
                "Zhen Wang",
                "Peng Liu",
                "Chongjie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07351v1",
                "http://arxiv.org/pdf/2308.07351v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07013v2",
            "title": "Learning to Optimize LSM-trees: Towards A Reinforcement Learning based\n  Key-Value Store for Dynamic Workloads",
            "updated": "2023-09-17T08:55:09Z",
            "published": "2023-08-14T09:00:58Z",
            "summary": "LSM-trees are widely adopted as the storage backend of key-value stores.\nHowever, optimizing the system performance under dynamic workloads has not been\nsufficiently studied or evaluated in previous work. To fill the gap, we present\nRusKey, a key-value store with the following new features: (1) RusKey is a\nfirst attempt to orchestrate LSM-tree structures online to enable robust\nperformance under the context of dynamic workloads; (2) RusKey is the first\nstudy to use Reinforcement Learning (RL) to guide LSM-tree transformations; (3)\nRusKey includes a new LSM-tree design, named FLSM-tree, for an efficient\ntransition between different compaction policies -- the bottleneck of dynamic\nkey-value stores. We justify the superiority of the new design with theoretical\nanalysis; (4) RusKey requires no prior workload knowledge for system\nadjustment, in contrast to state-of-the-art techniques. Experiments show that\nRusKey exhibits strong performance robustness in diverse workloads, achieving\nup to 4x better end-to-end performance than the RocksDB system under various\nsettings.",
            "author": [
                "Dingheng Mo",
                "Fanchao Chen",
                "Siqiang Luo",
                "Caihua Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07013v2",
                "http://arxiv.org/pdf/2308.07013v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.11636v1",
            "title": "Aggregating Intrinsic Information to Enhance BCI Performance through\n  Federated Learning",
            "updated": "2023-08-14T08:59:44Z",
            "published": "2023-08-14T08:59:44Z",
            "summary": "Insufficient data is a long-standing challenge for Brain-Computer Interface\n(BCI) to build a high-performance deep learning model. Though numerous research\ngroups and institutes collect a multitude of EEG datasets for the same BCI\ntask, sharing EEG data from multiple sites is still challenging due to the\nheterogeneity of devices. The significance of this challenge cannot be\noverstated, given the critical role of data diversity in fostering model\nrobustness. However, existing works rarely discuss this issue, predominantly\ncentering their attention on model training within a single dataset, often in\nthe context of inter-subject or inter-session settings. In this work, we\npropose a hierarchical personalized Federated Learning EEG decoding (FLEEG)\nframework to surmount this challenge. This innovative framework heralds a new\nlearning paradigm for BCI, enabling datasets with disparate data formats to\ncollaborate in the model training process. Each client is assigned a specific\ndataset and trains a hierarchical personalized model to manage diverse data\nformats and facilitate information exchange. Meanwhile, the server coordinates\nthe training procedure to harness knowledge gleaned from all datasets, thus\nelevating overall performance. The framework has been evaluated in Motor\nImagery (MI) classification with nine EEG datasets collected by different\ndevices but implementing the same MI task. Results demonstrate that the\nproposed frame can boost classification performance up to 16.7% by enabling\nknowledge sharing between multiple datasets, especially for smaller datasets.\nVisualization results also indicate that the proposed framework can empower the\nlocal models to put a stable focus on task-related areas, yielding better\nperformance. To the best of our knowledge, this is the first end-to-end\nsolution to address this important challenge.",
            "author": [
                "Rui Liu",
                "Yuanyuan Chen",
                "Anran Li",
                "Yi Ding",
                "Han Yu",
                "Cuntai Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11636v1",
                "http://arxiv.org/pdf/2308.11636v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.DC",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06995v1",
            "title": "Powers of planar graphs, product structure, and blocking partitions",
            "updated": "2023-08-14T08:10:29Z",
            "published": "2023-08-14T08:10:29Z",
            "summary": "We prove that the $k$-power of any planar graph $G$ is contained in\n$H\\boxtimes P\\boxtimes K_{f(\\Delta(G),k)}$ for some graph $H$ with treewidth\n$15\\,288\\,899$, some path $P$, and some function $f$. This resolves an open\nproblem of Ossona de Mendez. In fact, we prove a more general result in terms\nof shallow minors that implies similar results for many `beyond planar' graph\nclasses, without dependence on $\\Delta(G)$. For example, we prove that every\n$k$-planar graph is contained in $H\\boxtimes P\\boxtimes K_{f(k)}$ for some\ngraph $H$ with treewidth $15\\,288\\,899$ and some path $P$, and some function\n$f$. This resolves an open problem of Dujmovi\\'c, Morin and Wood. We generalise\nall these results for graphs of bounded Euler genus, still with an absolute\nbound on the treewidth.\n  At the heart of our proof is the following new concept of independent\ninterest. An $\\ell$-blocking partition of a graph $G$ is a partition of $V(G)$\ninto connected sets such that every path of length greater than $\\ell$ in $G$\ncontains at least two vertices in one part. We prove that every graph of Euler\ngenus $g$ has a $894$-blocking partition with parts of size bounded by a\nfunction of $\\Delta(G)$ and $g$. Motivated by this result, we study blocking\npartitions in their own right. We show that every graph has a $2$-blocking\npartition with parts of size bounded by a function of $\\Delta(G)$ and\n$\\textrm{tw}(G)$. On the other hand, we show that 4-regular graphs do not have\n$\\ell$-blocking partitions with bounded size parts.",
            "author": [
                "Marc Distel",
                "Robert Hickingbotham",
                "Micha\u0142 T. Seweryn",
                "David R. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06995v1",
                "http://arxiv.org/pdf/2308.06995v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06975v3",
            "title": "Can Knowledge Graphs Simplify Text?",
            "updated": "2023-10-25T00:57:54Z",
            "published": "2023-08-14T07:20:49Z",
            "summary": "Knowledge Graph (KG)-to-Text Generation has seen recent improvements in\ngenerating fluent and informative sentences which describe a given KG. As KGs\nare widespread across multiple domains and contain important entity-relation\ninformation, and as text simplification aims to reduce the complexity of a text\nwhile preserving the meaning of the original text, we propose KGSimple, a novel\napproach to unsupervised text simplification which infuses KG-established\ntechniques in order to construct a simplified KG path and generate a concise\ntext which preserves the original input's meaning. Through an iterative and\nsampling KG-first approach, our model is capable of simplifying text when\nstarting from a KG by learning to keep important information while harnessing\nKG-to-text generation to output fluent and descriptive sentences. We evaluate\nvarious settings of the KGSimple model on currently-available KG-to-text\ndatasets, demonstrating its effectiveness compared to unsupervised text\nsimplification models which start with a given complex text. Our code is\navailable on GitHub.",
            "author": [
                "Anthony Colas",
                "Haodi Ma",
                "Xuanli He",
                "Yang Bai",
                "Daisy Zhe Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06975v3",
                "http://arxiv.org/pdf/2308.06975v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06972v1",
            "title": "3D Localization and Tracking Methods for Multi-Platform Radar Networks",
            "updated": "2023-08-14T07:09:51Z",
            "published": "2023-08-14T07:09:51Z",
            "summary": "Multi-platform radar networks (MPRNs) are an emerging sensing technology due\nto their ability to provide improved surveillance capabilities over plain\nmonostatic and bistatic systems. The design of advanced detection,\nlocalization, and tracking algorithms for efficient fusion of information\nobtained through multiple receivers has attracted much attention. However,\nconsiderable challenges remain. This article provides an overview on recent\nunconstrained and constrained localization techniques as well as multitarget\ntracking (MTT) algorithms tailored to MPRNs. In particular, two data-processing\nmethods are illustrated and explored in detail, one aimed at accomplishing\nlocalization tasks the other tracking functions. As to the former, assuming a\nMPRN with one transmitter and multiple receivers, the angular and range\nconstrained estimator (ARCE) algorithm capitalizes on the knowledge of the\ntransmitter antenna beamwidth. As to the latter, the scalable sum-product\nalgorithm (SPA) based MTT technique is presented. Additionally, a solution to\ncombine ARCE and SPA-based MTT is investigated in order to boost the accuracy\nof the overall surveillance system. Simulated experiments show the benefit of\nthe combined algorithm in comparison with the conventional baseline SPA-based\nMTT and the stand-alone ARCE localization, in a 3D sensing scenario.",
            "author": [
                "Angela Marino",
                "Giovanni Soldi",
                "Domenico Gaglione",
                "Augusto Aubry",
                "Paolo Braca",
                "Antonio De Maio",
                "Peter Willett"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06972v1",
                "http://arxiv.org/pdf/2308.06972v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06965v1",
            "title": "AutoAssign+: Automatic Shared Embedding Assignment in Streaming\n  Recommendation",
            "updated": "2023-08-14T06:43:59Z",
            "published": "2023-08-14T06:43:59Z",
            "summary": "In the domain of streaming recommender systems, conventional methods for\naddressing new user IDs or item IDs typically involve assigning initial ID\nembeddings randomly. However, this practice results in two practical\nchallenges: (i) Items or users with limited interactive data may yield\nsuboptimal prediction performance. (ii) Embedding new IDs or low-frequency IDs\nnecessitates consistently expanding the embedding table, leading to unnecessary\nmemory consumption. In light of these concerns, we introduce a reinforcement\nlearning-driven framework, namely AutoAssign+, that facilitates Automatic\nShared Embedding Assignment Plus. To be specific, AutoAssign+ utilizes an\nIdentity Agent as an actor network, which plays a dual role: (i) Representing\nlow-frequency IDs field-wise with a small set of shared embeddings to enhance\nthe embedding initialization, and (ii) Dynamically determining which ID\nfeatures should be retained or eliminated in the embedding table. The policy of\nthe agent is optimized with the guidance of a critic network. To evaluate the\neffectiveness of our approach, we perform extensive experiments on three\ncommonly used benchmark datasets. Our experiment results demonstrate that\nAutoAssign+ is capable of significantly enhancing recommendation performance by\nmitigating the cold-start problem. Furthermore, our framework yields a\nreduction in memory usage of approximately 20-30%, verifying its practical\neffectiveness and efficiency for streaming recommender systems.",
            "author": [
                "Ziru Liu",
                "Kecheng Chen",
                "Fengyi Song",
                "Bo Chen",
                "Xiangyu Zhao",
                "Huifeng Guo",
                "Ruiming Tang"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s10115-023-01951-1",
                "http://arxiv.org/abs/2308.06965v1",
                "http://arxiv.org/pdf/2308.06965v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06964v1",
            "title": "How inter-rater variability relates to aleatoric and epistemic\n  uncertainty: a case study with deep learning-based paraspinal muscle\n  segmentation",
            "updated": "2023-08-14T06:40:20Z",
            "published": "2023-08-14T06:40:20Z",
            "summary": "Recent developments in deep learning (DL) techniques have led to great\nperformance improvement in medical image segmentation tasks, especially with\nthe latest Transformer model and its variants. While labels from fusing\nmulti-rater manual segmentations are often employed as ideal ground truths in\nDL model training, inter-rater variability due to factors such as training\nbias, image noise, and extreme anatomical variability can still affect the\nperformance and uncertainty of the resulting algorithms. Knowledge regarding\nhow inter-rater variability affects the reliability of the resulting DL\nalgorithms, a key element in clinical deployment, can help inform better\ntraining data construction and DL models, but has not been explored\nextensively. In this paper, we measure aleatoric and epistemic uncertainties\nusing test-time augmentation (TTA), test-time dropout (TTD), and deep ensemble\nto explore their relationship with inter-rater variability. Furthermore, we\ncompare UNet and TransUNet to study the impacts of Transformers on model\nuncertainty with two label fusion strategies. We conduct a case study using\nmulti-class paraspinal muscle segmentation from T2w MRIs. Our study reveals the\ninterplay between inter-rater variability and uncertainties, affected by\nchoices of label fusion strategies and DL models.",
            "author": [
                "Parinaz Roshanzamir",
                "Hassan Rivaz",
                "Joshua Ahn",
                "Hamza Mirza",
                "Neda Naghdi",
                "Meagan Anstruther",
                "Michele C. Batti\u00e9",
                "Maryse Fortin",
                "Yiming Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06964v1",
                "http://arxiv.org/pdf/2308.06964v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "I.2.1, I.4.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07349v1",
            "title": "On a specific problem of partition of graph",
            "updated": "2023-08-14T06:38:59Z",
            "published": "2023-08-14T06:38:59Z",
            "summary": "In this short article, we consider a problem about $2$-partition of the\nvertices of a graph. If a graph admits such a partition into some 'small'\ngraphs, then the number of edges cross an arbitrary cut of the graph\n$e(S,S^{c})$ has a nice lower bound.",
            "author": [
                "Peisheng Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07349v1",
                "http://arxiv.org/pdf/2308.07349v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06961v3",
            "title": "Graph Structural Residuals: A Learning Approach to Diagnosis",
            "updated": "2023-10-10T10:56:22Z",
            "published": "2023-08-14T06:32:52Z",
            "summary": "Traditional model-based diagnosis relies on constructing explicit system\nmodels, a process that can be laborious and expertise-demanding. In this paper,\nwe propose a novel framework that combines concepts of model-based diagnosis\nwith deep graph structure learning. This data-driven approach leverages data to\nlearn the system's underlying structure and provide dynamic observations,\nrepresented by two distinct graph adjacency matrices. Our work facilitates a\nseamless integration of graph structure learning with model-based diagnosis by\nmaking three main contributions: (i) redefining the constructs of system\nrepresentation, observations, and faults (ii) introducing two distinct versions\nof a self-supervised graph structure learning model architecture and (iii)\ndemonstrating the potential of our data-driven diagnostic method through\nexperiments on a system of coupled oscillators.",
            "author": [
                "Jan Lukas Augustin",
                "Oliver Niggemann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06961v3",
                "http://arxiv.org/pdf/2308.06961v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06960v1",
            "title": "Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level\n  Tasks",
            "updated": "2023-08-14T06:32:02Z",
            "published": "2023-08-14T06:32:02Z",
            "summary": "Recently, graph neural networks (GNNs) have shown its unprecedented success\nin many graph-related tasks. However, GNNs face the label scarcity issue as\nother neural networks do. Thus, recent efforts try to pre-train GNNs on a\nlarge-scale unlabeled graph and adapt the knowledge from the unlabeled graph to\nthe target downstream task. The adaptation is generally achieved by fine-tuning\nthe pre-trained GNNs with a limited number of labeled data. Despite the\nimportance of fine-tuning, current GNNs pre-training works often ignore\ndesigning a good fine-tuning strategy to better leverage transferred knowledge\nand improve the performance on downstream tasks. Only few works start to\ninvestigate a better fine-tuning strategy for pre-trained GNNs. But their\ndesigns either have strong assumptions or overlook the data-aware issue for\nvarious downstream datasets. Therefore, we aim to design a better fine-tuning\nstrategy for pre-trained GNNs to improve the model performance in this paper.\nGiven a pre-trained GNN, we propose to search to fine-tune pre-trained graph\nneural networks for graph-level tasks (S2PGNN), which adaptively design a\nsuitable fine-tuning framework for the given labeled data on the downstream\ntask. To ensure the improvement brought by searching fine-tuning strategy, we\ncarefully summarize a proper search space of fine-tuning framework that is\nsuitable for GNNs. The empirical studies show that S2PGNN can be implemented on\nthe top of 10 famous pre-trained GNNs and consistently improve their\nperformance. Besides, S2PGNN achieves better performance than existing\nfine-tuning strategies within and outside the GNN area. Our code is publicly\navailable at \\url{https://anonymous.4open.science/r/code_icde2024-A9CB/}.",
            "author": [
                "Zhili Wang",
                "Shimin Di",
                "Lei Chen",
                "Xiaofang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06960v1",
                "http://arxiv.org/pdf/2308.06960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06958v1",
            "title": "Hydrogen Supply Infrastructure Network Planning Approach towards\n  Chicken-egg Conundrum",
            "updated": "2023-08-14T06:27:32Z",
            "published": "2023-08-14T06:27:32Z",
            "summary": "In the early commercialization stage of hydrogen fuel cell vehicles (HFCVs),\nreasonable hydrogen supply infrastructure (HSI) planning decisions is a premise\nfor promoting the popularization of HFCVs. However, there is a strong causality\nbetween HFCVs and hydrogen refueling stations (HRSs): the planning decisions of\nHRSs could affect the hydrogen refueling demand of HFCVs, and the growth of\ndemand would in turn stimulate the further investment in HRSs, which is also\nknown as the ``chicken and egg'' conundrum. Meanwhile, the hydrogen demand is\nuncertain with insufficient prior knowledge, and thus there is a\ndecision-dependent uncertainty (DDU) in the planning issue. This poses great\nchallenges to solving the optimization problem. To this end, this work\nestablishes a multi-network HSI planning model coordinating hydrogen, power,\nand transportation networks. Then, to reflect the causal relationship between\nHFCVs and HRSs effectively without sufficient historical data, a\ndistributionally robust optimization framework with decision-dependent\nuncertainty is developed. The uncertainty of hydrogen demand is modeled as a\nWasserstein ambiguity set with a decision-dependent empirical probability\ndistribution. Subsequently, to reduce the computational complexity caused by\nthe introduction of a large number of scenarios and high-dimensional nonlinear\nconstraints, we developed an improved distribution shaping method and\ntechniques of scenario and variable reduction to derive the solvable form with\nless computing burden. Finally, the simulation results demonstrate that this\nmethod can reduce costs by at least 10.4% compared with traditional methods and\nwill be more effective in large-scale HSI planning issues. Further, we put\nforward effective suggestions for the policymakers and investors to formulate\nrelevant policies and decisions.",
            "author": [
                "Haoran Deng",
                "Bo Yang",
                "Mo-Yuen Chow",
                "Gang Yao",
                "Cailian Chen",
                "Xinping Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06958v1",
                "http://arxiv.org/pdf/2308.06958v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06949v1",
            "title": "Kernel Based Reconstruction for Generalized Graph Signal Processing",
            "updated": "2023-08-14T05:56:07Z",
            "published": "2023-08-14T05:56:07Z",
            "summary": "In generalized graph signal processing (GGSP), the signal associated with\neach vertex in a graph is an element from a Hilbert space. In this paper, we\nstudy GGSP signal reconstruction as a kernel ridge regression (KRR) problem. By\ndevising an appropriate kernel, we show that this problem has a solution that\ncan be evaluated in a distributed way. We interpret the problem and solution\nusing both deterministic and Bayesian perspectives and link them to existing\ngraph signal processing and GGSP frameworks. We then provide an online\nimplementation via random Fourier features. Under the Bayesian framework, we\ninvestigate the statistical performance under the asymptotic sampling scheme.\nFinally, we validate our theory and methods on real-world datasets.",
            "author": [
                "Xingchao Jian",
                "Wee Peng Tay",
                "Yonina C. Eldar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06949v1",
                "http://arxiv.org/pdf/2308.06949v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06940v1",
            "title": "Moment Methods for Advection on Networks and an Application to Forest\n  Pest Life Cycle Models",
            "updated": "2023-08-14T05:10:09Z",
            "published": "2023-08-14T05:10:09Z",
            "summary": "This paper develops low-dimensional moment methods for advective problems on\nnetworks of domains. The evolution of a density function is described by a\nlinear advection-diffusion-reaction equation on each domain, combined via\nadvective flux coupling across domains in the network graph. The PDEs'\ncoefficients vary in time and across domains but they are fixed along each\ndomain. As a result, the solution on each domain is frequently close to a\nGaussian that moves, decays, and widens. For that reason, this work studies\nmoment methods that track only three degrees of freedom per domain -- in\ncontrast to traditional PDE discretization methods that tend to require many\nmore variables per domain. A simple ODE-based moment method is developed, as\nwell as an asymptotic-preserving scheme. We apply the methodology to an\napplication that models the life cycle of forest pests that undergo different\nlife stages and developmental pathways. The model is calibrated for the spotted\nlanternfly, an invasive species present in the Eastern USA. We showcase that\nthe moment method, despite its significant low-dimensionality, can successfully\nreproduce the prediction of the pest's establishment potential, compared to\nmuch higher-dimensional computational approaches.",
            "author": [
                "Rujeko Chinomona",
                "Kiera Kean",
                "Benjamin Seibold",
                "Jacob Woods"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06940v1",
                "http://arxiv.org/pdf/2308.06940v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "q-bio.PE",
                "65M99 (Primary) 35Q92, 92-10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06932v1",
            "title": "DIVAS: An LLM-based End-to-End Framework for SoC Security Analysis and\n  Policy-based Protection",
            "updated": "2023-08-14T04:21:10Z",
            "published": "2023-08-14T04:21:10Z",
            "summary": "Securing critical assets in a bus-based System-On-Chip (SoC) is imperative to\nmitigate potential vulnerabilities and prevent unauthorized access, ensuring\nthe integrity, availability, and confidentiality of the system. Ensuring\nsecurity throughout the SoC design process is a formidable task owing to the\ninherent intricacies in SoC designs and the dispersion of assets across diverse\nIPs. Large Language Models (LLMs), exemplified by ChatGPT (OpenAI) and BARD\n(Google), have showcased remarkable proficiency across various domains,\nincluding security vulnerability detection and prevention in SoC designs. In\nthis work, we propose DIVAS, a novel framework that leverages the knowledge\nbase of LLMs to identify security vulnerabilities from user-defined SoC\nspecifications, map them to the relevant Common Weakness Enumerations (CWEs),\nfollowed by the generation of equivalent assertions, and employ security\nmeasures through enforcement of security policies. The proposed framework is\nimplemented using multiple ChatGPT and BARD models, and their performance was\nanalyzed while generating relevant CWEs from the SoC specifications provided.\nThe experimental results obtained from open-source SoC benchmarks demonstrate\nthe efficacy of our proposed framework.",
            "author": [
                "Sudipta Paria",
                "Aritra Dasgupta",
                "Swarup Bhunia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06932v1",
                "http://arxiv.org/pdf/2308.06932v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06925v1",
            "title": "CBA: Improving Online Continual Learning via Continual Bias Adaptor",
            "updated": "2023-08-14T04:03:51Z",
            "published": "2023-08-14T04:03:51Z",
            "summary": "Online continual learning (CL) aims to learn new knowledge and consolidate\npreviously learned knowledge from non-stationary data streams. Due to the\ntime-varying training setting, the model learned from a changing distribution\neasily forgets the previously learned knowledge and biases toward the newly\nreceived task. To address this problem, we propose a Continual Bias Adaptor\n(CBA) module to augment the classifier network to adapt to catastrophic\ndistribution change during training, such that the classifier network is able\nto learn a stable consolidation of previously learned tasks. In the testing\nstage, CBA can be removed which introduces no additional computation cost and\nmemory overhead. We theoretically reveal the reason why the proposed method can\neffectively alleviate catastrophic distribution shifts, and empirically\ndemonstrate its effectiveness through extensive experiments based on four\nrehearsal-based baselines and three public continual learning benchmarks.",
            "author": [
                "Quanziang Wang",
                "Renzhen Wang",
                "Yichen Wu",
                "Xixi Jia",
                "Deyu Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06925v1",
                "http://arxiv.org/pdf/2308.06925v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06911v1",
            "title": "GIT-Mol: A Multi-modal Large Language Model for Molecular Science with\n  Graph, Image, and Text",
            "updated": "2023-08-14T03:12:29Z",
            "published": "2023-08-14T03:12:29Z",
            "summary": "Large language models have made significant strides in natural language\nprocessing, paving the way for innovative applications including molecular\nrepresentation and generation. However, most existing single-modality\napproaches cannot capture the abundant and complex information in molecular\ndata. Here, we introduce GIT-Mol, a multi-modal large language model that\nintegrates the structure Graph, Image, and Text information, including the\nSimplified Molecular Input Line Entry System (SMILES) and molecular captions.\nTo facilitate the integration of multi-modal molecular data, we propose\nGIT-Former, a novel architecture capable of mapping all modalities into a\nunified latent space. Our study develops an innovative any-to-language\nmolecular translation strategy and achieves a 10%-15% improvement in molecular\ncaptioning, a 5%-10% accuracy increase in property prediction, and a 20% boost\nin molecule generation validity compared to baseline or single-modality models.",
            "author": [
                "Pengfei Liu",
                "Yiming Ren",
                "Zhixiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06911v1",
                "http://arxiv.org/pdf/2308.06911v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06910v1",
            "title": "Localized High-Concentration Electrolytes Get More Localized Through\n  Micelle-Like Structures",
            "updated": "2023-08-14T03:12:13Z",
            "published": "2023-08-14T03:12:13Z",
            "summary": "Liquid electrolytes in batteries are typically treated as macroscopically\nhomogeneous ionic transport media despite having complex chemical composition\nand atomistic solvation structures, leaving a knowledge gap of microstructural\ncharacteristics. Here, we reveal a unique micelle-like structure in a localized\nhigh-concentration electrolyte (LHCE), in which the solvent acts as a\nsurfactant between an insoluble salt in diluent. The miscibility of the solvent\nwith the diluent and simultaneous solubility of the salt results in a\nmicelle-like structure with a smeared interface and an increased salt\nconcentration at the centre of the salt-solvent clusters that extends the salt\nsolubility. These intermingling miscibility effects have temperature\ndependencies, wherein an exemplified LHCE peaks in localized cluster salt\nconcentration near room temperature and is utilized to form a stable\nsolid-electrolyte interphase (SEI) on Li-metal anode. These findings serve as a\nguide to predicting a stable ternary phase diagram and connecting the\nelectrolyte microstructure with electrolyte formulation and formation protocols\nto form stable SEI for enhanced battery cyclability.",
            "author": [
                "Corey M. Efaw",
                "Qisheng Wu",
                "Ningshengjie Gao",
                "Yugang Zhang",
                "Haoyu Zhou",
                "Kevin Gering",
                "Michael F. Hurley",
                "Hui Xiong",
                "Enyuan Hu",
                "Xia Cao",
                "Wu Xu",
                "Ji-Guang Zhang",
                "Eric J. Dufek",
                "Jie Xiao",
                "Xiao-Qing Yang",
                "Jun Liu",
                "Yue Qi",
                "Bin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06910v1",
                "http://arxiv.org/pdf/2308.06910v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06895v1",
            "title": "Federated Classification in Hyperbolic Spaces via Secure Aggregation of\n  Convex Hulls",
            "updated": "2023-08-14T02:25:48Z",
            "published": "2023-08-14T02:25:48Z",
            "summary": "Hierarchical and tree-like data sets arise in many applications, including\nlanguage processing, graph data mining, phylogeny and genomics. It is known\nthat tree-like data cannot be embedded into Euclidean spaces of finite\ndimension with small distortion. This problem can be mitigated through the use\nof hyperbolic spaces. When such data also has to be processed in a distributed\nand privatized setting, it becomes necessary to work with new federated\nlearning methods tailored to hyperbolic spaces. As an initial step towards the\ndevelopment of the field of federated learning in hyperbolic spaces, we propose\nthe first known approach to federated classification in hyperbolic spaces. Our\ncontributions are as follows. First, we develop distributed versions of convex\nSVM classifiers for Poincar\\'e discs. In this setting, the information conveyed\nfrom clients to the global classifier are convex hulls of clusters present in\nindividual client data. Second, to avoid label switching issues, we introduce a\nnumber-theoretic approach for label recovery based on the so-called integer\n$B_h$ sequences. Third, we compute the complexity of the convex hulls in\nhyperbolic spaces to assess the extent of data leakage; at the same time, in\norder to limit the communication cost for the hulls, we propose a new\nquantization method for the Poincar\\'e disc coupled with Reed-Solomon-like\nencoding. Fourth, at server level, we introduce a new approach for aggregating\nconvex hulls of the clients based on balanced graph partitioning. We test our\nmethod on a collection of diverse data sets, including hierarchical single-cell\nRNA-seq data from different patients distributed across different repositories\nthat have stringent privacy constraints. The classification accuracy of our\nmethod is up to $\\sim 11\\%$ better than its Euclidean counterpart,\ndemonstrating the importance of privacy-preserving learning in hyperbolic\nspaces.",
            "author": [
                "Saurav Prakash",
                "Jin Sima",
                "Chao Pan",
                "Eli Chien",
                "Olgica Milenkovic"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06895v1",
                "http://arxiv.org/pdf/2308.06895v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06878v1",
            "title": "AutoSeqRec: Autoencoder for Efficient Sequential Recommendation",
            "updated": "2023-08-14T01:23:37Z",
            "published": "2023-08-14T01:23:37Z",
            "summary": "Sequential recommendation demonstrates the capability to recommend items by\nmodeling the sequential behavior of users. Traditional methods typically treat\nusers as sequences of items, overlooking the collaborative relationships among\nthem. Graph-based methods incorporate collaborative information by utilizing\nthe user-item interaction graph. However, these methods sometimes face\nchallenges in terms of time complexity and computational efficiency. To address\nthese limitations, this paper presents AutoSeqRec, an incremental\nrecommendation model specifically designed for sequential recommendation tasks.\nAutoSeqRec is based on autoencoders and consists of an encoder and three\ndecoders within the autoencoder architecture. These components consider both\nthe user-item interaction matrix and the rows and columns of the item\ntransition matrix. The reconstruction of the user-item interaction matrix\ncaptures user long-term preferences through collaborative filtering. In\naddition, the rows and columns of the item transition matrix represent the item\nout-degree and in-degree hopping behavior, which allows for modeling the user's\nshort-term interests. When making incremental recommendations, only the input\nmatrices need to be updated, without the need to update parameters, which makes\nAutoSeqRec very efficient. Comprehensive evaluations demonstrate that\nAutoSeqRec outperforms existing methods in terms of accuracy, while showcasing\nits robustness and efficiency.",
            "author": [
                "Sijia Liu",
                "Jiahao Liu",
                "Hansu Gu",
                "Dongsheng Li",
                "Tun Lu",
                "Peng Zhang",
                "Ning Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06878v1",
                "http://arxiv.org/pdf/2308.06878v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06869v1",
            "title": "Shape-Graph Matching Network (SGM-net): Registration for Statistical\n  Shape Analysis",
            "updated": "2023-08-14T00:42:03Z",
            "published": "2023-08-14T00:42:03Z",
            "summary": "This paper focuses on the statistical analysis of shapes of data objects\ncalled shape graphs, a set of nodes connected by articulated curves with\narbitrary shapes. A critical need here is a constrained registration of points\n(nodes to nodes, edges to edges) across objects. This, in turn, requires\noptimization over the permutation group, made challenging by differences in\nnodes (in terms of numbers, locations) and edges (in terms of shapes,\nplacements, and sizes) across objects. This paper tackles this registration\nproblem using a novel neural-network architecture and involves an unsupervised\nloss function developed using the elastic shape metric for curves. This\narchitecture results in (1) state-of-the-art matching performance and (2) an\norder of magnitude reduction in the computational cost relative to baseline\napproaches. We demonstrate the effectiveness of the proposed approach using\nboth simulated data and real-world 2D and 3D shape graphs. Code and data will\nbe made publicly available after review to foster research.",
            "author": [
                "Shenyuan Liang",
                "Mauricio Pamplona Segundo",
                "Sathyanarayanan N. Aakur",
                "Sudeep Sarkar",
                "Anuj Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06869v1",
                "http://arxiv.org/pdf/2308.06869v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.11635v1",
            "title": "Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive\n  Learning for Cross-Subject EEG-based Emotion Recognition",
            "updated": "2023-08-13T23:54:40Z",
            "published": "2023-08-13T23:54:40Z",
            "summary": "Electroencephalography (EEG) is an objective tool for emotion recognition\nwith promising applications. However, the scarcity of labeled data remains a\nmajor challenge in this field, limiting the widespread use of EEG-based emotion\nrecognition. In this paper, a semi-supervised Dual-stream Self-Attentive\nAdversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed\nto tackle the challenge of limited labeled data in cross-subject EEG-based\nemotion recognition. The DS-AGC framework includes two parallel streams for\nextracting non-structural and structural EEG features. The non-structural\nstream incorporates a semi-supervised multi-domain adaptation method to\nalleviate distribution discrepancy among labeled source domain, unlabeled\nsource domain, and unknown target domain. The structural stream develops a\ngraph contrastive learning method to extract effective graph-based feature\nrepresentation from multiple EEG channels in a semi-supervised manner. Further,\na self-attentive fusion module is developed for feature fusion, sample\nselection, and emotion recognition, which highlights EEG features more relevant\nto emotions and data samples in the labeled source domain that are closer to\nthe target domain. Extensive experiments conducted on two benchmark databases\n(SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out\ncross-validation evaluation scheme show that the proposed model outperforms\nexisting methods under different incomplete label conditions (with an average\nimprovement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its\neffectiveness in addressing the label scarcity problem in cross-subject\nEEG-based emotion recognition.",
            "author": [
                "Weishan Ye",
                "Zhiguo Zhang",
                "Min Zhang",
                "Fei Teng",
                "Li Zhang",
                "Linling Li",
                "Gan Huang",
                "Jianhong Wang",
                "Dong Ni",
                "Zhen Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.11635v1",
                "http://arxiv.org/pdf/2308.11635v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.13534v1",
            "title": "Building Trust in Conversational AI: A Comprehensive Review and Solution\n  Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge\n  Graph",
            "updated": "2023-08-13T22:47:51Z",
            "published": "2023-08-13T22:47:51Z",
            "summary": "Conversational AI systems have emerged as key enablers of human-like\ninteractions across diverse sectors. Nevertheless, the balance between\nlinguistic nuance and factual accuracy has proven elusive. In this paper, we\nfirst introduce LLMXplorer, a comprehensive tool that provides an in-depth\nreview of over 150 Large Language Models (LLMs), elucidating their myriad\nimplications ranging from social and ethical to regulatory, as well as their\napplicability across industries. Building on this foundation, we propose a\nnovel functional architecture that seamlessly integrates the structured\ndynamics of Knowledge Graphs with the linguistic capabilities of LLMs.\nValidated using real-world AI news data, our architecture adeptly blends\nlinguistic sophistication with factual rigour and further strengthens data\nsecurity through Role-Based Access Control. This research provides insights\ninto the evolving landscape of conversational AI, emphasizing the imperative\nfor systems that are efficient, transparent, and trustworthy.",
            "author": [
                "Ahtsham Zafar",
                "Venkatesh Balavadhani Parthasarathy",
                "Chan Le Van",
                "Saad Shahid",
                "Aafaq Iqbal khan",
                "Arsalan Shahid"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13534v1",
                "http://arxiv.org/pdf/2308.13534v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06838v4",
            "title": "Generalizing Topological Graph Neural Networks with Paths",
            "updated": "2023-10-20T04:51:01Z",
            "published": "2023-08-13T19:45:20Z",
            "summary": "While Graph Neural Networks (GNNs) have made significant strides in diverse\nareas, they are hindered by a theoretical constraint known as the\n1-Weisfeiler-Lehman test. Even though latest advancements in higher-order GNNs\ncan overcome this boundary, they typically center around certain graph\ncomponents like cliques or cycles. However, our investigation goes a different\nroute. We put emphasis on paths, which are inherent in every graph. We are able\nto construct a more general topological perspective and form a bridge to\ncertain established theories about other topological domains. Interestingly,\nwithout any assumptions on graph sub-structures, our approach surpasses earlier\ntechniques in this field, achieving state-of-the-art performance on several\nbenchmarks.",
            "author": [
                "Quang Truong",
                "Peter Chin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06838v4",
                "http://arxiv.org/pdf/2308.06838v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06833v1",
            "title": "A Van Kampen type obstruction for string graphs",
            "updated": "2023-08-13T18:46:36Z",
            "published": "2023-08-13T18:46:36Z",
            "summary": "In this paper we prove that a graph is a string graph (the intersection graph\nof curves in the plane) if and only if it admits a drawing in the plane with\ncertain properties. This also allows us to define an algebraic obstruction,\nsimilar to the Van Kampen obstruction to embeddability, which must vanish for\nevery string graph. However, unlike in the case of graph planarity this\nobstruction is incomplete.",
            "author": [
                "Moshe White"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06833v1",
                "http://arxiv.org/pdf/2308.06833v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06827v1",
            "title": "Reinforcement Graph Clustering with Unknown Cluster Number",
            "updated": "2023-08-13T18:12:28Z",
            "published": "2023-08-13T18:12:28Z",
            "summary": "Deep graph clustering, which aims to group nodes into disjoint clusters by\nneural networks in an unsupervised manner, has attracted great attention in\nrecent years. Although the performance has been largely improved, the excellent\nperformance of the existing methods heavily relies on an accurately predefined\ncluster number, which is not always available in the real-world scenario. To\nenable the deep graph clustering algorithms to work without the guidance of the\npredefined cluster number, we propose a new deep graph clustering method termed\nReinforcement Graph Clustering (RGC). In our proposed method, cluster number\ndetermination and unsupervised representation learning are unified into a\nuniform framework by the reinforcement learning mechanism. Concretely, the\ndiscriminative node representations are first learned with the contrastive\npretext task. Then, to capture the clustering state accurately with both local\nand global information in the graph, both node and cluster states are\nconsidered. Subsequently, at each state, the qualities of different cluster\nnumbers are evaluated by the quality network, and the greedy action is executed\nto determine the cluster number. In order to conduct feedback actions, the\nclustering-oriented reward function is proposed to enhance the cohesion of the\nsame clusters and separate the different clusters. Extensive experiments\ndemonstrate the effectiveness and efficiency of our proposed method. The source\ncode of RGC is shared at https://github.com/yueliu1999/RGC and a collection\n(papers, codes and, datasets) of deep graph clustering is shared at\nhttps://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github.",
            "author": [
                "Yue Liu",
                "Ke Liang",
                "Jun Xia",
                "Xihong Yang",
                "Sihang Zhou",
                "Meng Liu",
                "Xinwang Liu",
                "Stan Z. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06827v1",
                "http://arxiv.org/pdf/2308.06827v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06823v1",
            "title": "Exploration of graphs with excluded minors",
            "updated": "2023-08-13T17:41:09Z",
            "published": "2023-08-13T17:41:09Z",
            "summary": "We study the online graph exploration problem proposed by Kalyanasundaram and\nPruhs (1994) and prove a constant competitive ratio on minor-free graphs. This\nresult encompasses and significantly extends the graph classes that were\npreviously known to admit a constant competitive ratio. The main ingredient of\nour proof is that we find a connection between the performance of the\nparticular exploration algorithm Blocking and the existence of light spanners.\nConversely, we exploit this connection to construct light spanners of bounded\ngenus graphs. In particular, we achieve a lightness that improves on the best\nknown upper bound for genus g>0 and recovers the known tight bound for the\nplanar case (g=0).",
            "author": [
                "Julia Baligacs",
                "Yann Disser",
                "Irene Heinrich",
                "Pascal Schweitzer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06823v1",
                "http://arxiv.org/pdf/2308.06823v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06819v1",
            "title": "SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network\n  Intrusion Detection",
            "updated": "2023-08-13T17:23:36Z",
            "published": "2023-08-13T17:23:36Z",
            "summary": "Machine Learning (ML) can be incredibly valuable to automate anomaly\ndetection and cyber-attack classification, improving the way that Network\nIntrusion Detection (NID) is performed. However, despite the benefits of ML\nmodels, they are highly susceptible to adversarial cyber-attack examples\nspecifically crafted to exploit them. A wide range of adversarial attacks have\nbeen created and researchers have worked on various defense strategies to\nsafeguard ML models, but most were not intended for the specific constraints of\na communication network and its communication protocols, so they may lead to\nunrealistic examples in the NID domain. This Systematization of Knowledge (SoK)\nconsolidates and summarizes the state-of-the-art adversarial learning\napproaches that can generate realistic examples and could be used in real ML\ndevelopment and deployment scenarios with real network traffic flows. This SoK\nalso describes the open challenges regarding the use of adversarial ML in the\nNID domain, defines the fundamental properties that are required for an\nadversarial example to be realistic, and provides guidelines for researchers to\nensure that their future experiments are adequate for a real communication\nnetwork.",
            "author": [
                "Jo\u00e3o Vitorino",
                "Isabel Pra\u00e7a",
                "Eva Maia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06819v1",
                "http://arxiv.org/pdf/2308.06819v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06817v1",
            "title": "The Asymptotic Capacity of $X$-Secure $T$-Private Linear Computation\n  with Graph Based Replicated Storage",
            "updated": "2023-08-13T17:20:08Z",
            "published": "2023-08-13T17:20:08Z",
            "summary": "The problem of $X$-secure $T$-private linear computation with graph based\nreplicated storage (GXSTPLC) is to enable the user to retrieve a linear\ncombination of messages privately from a set of $N$ distributed servers where\nevery message is only allowed to store among a subset of servers subject to an\n$X$-security constraint, i.e., any groups of up to $X$ colluding servers must\nreveal nothing about the messages. Besides, any groups of up to $T$ servers\ncannot learn anything about the coefficients of the linear combination\nretrieved by the user. In this work, we completely characterize the asymptotic\ncapacity of GXSTPLC, i.e., the supremum of average number of desired symbols\nretrieved per downloaded symbol, in the limit as the number of messages $K$\napproaches infinity. Specifically, it is shown that a prior linear programming\nbased upper bound on the asymptotic capacity of GXSTPLC due to Jia and Jafar is\ntight by constructing achievability schemes. Notably, our achievability scheme\nalso settles the exact capacity (i.e., for finite $K$) of $X$-secure linear\ncombination with graph based replicated storage (GXSLC). Our achievability\nproof builds upon an achievability scheme for a closely related problem named\nasymmetric $\\mathbf{X}$-secure $\\mathbf{T}$-private linear computation with\ngraph based replicated storage (Asymm-GXSTPLC) that guarantees non-uniform\nsecurity and privacy levels across messages and coefficients. In particular, by\ncarefully designing Asymm-GXSTPLC settings for GXSTPLC problems, the\ncorresponding Asymm-GXSTPLC schemes can be reduced to asymptotic capacity\nachieving schemes for GXSTPLC. In regard to the achievability scheme for\nAsymm-GXSTPLC, interesting aspects of our construction include a novel query\nand answer design which makes use of a Vandermonde decomposition of Cauchy\nmatrices, and a trade-off among message replication, security and privacy\nthresholds.",
            "author": [
                "Haobo Jia",
                "Zhuqing Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06817v1",
                "http://arxiv.org/pdf/2308.06817v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06801v2",
            "title": "SAILOR: Structural Augmentation Based Tail Node Representation Learning",
            "updated": "2023-08-15T01:08:11Z",
            "published": "2023-08-13T16:04:03Z",
            "summary": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nrepresentation learning for graphs recently. However, the effectiveness of\nGNNs, which capitalize on the key operation of message propagation, highly\ndepends on the quality of the topology structure. Most of the graphs in\nreal-world scenarios follow a long-tailed distribution on their node degrees,\nthat is, a vast majority of the nodes in the graph are tail nodes with only a\nfew connected edges. GNNs produce inferior node representations for tail nodes\nsince they lack structural information. In the pursuit of promoting the\nexpressiveness of GNNs for tail nodes, we explore how the deficiency of\nstructural information deteriorates the performance of tail nodes and propose a\ngeneral Structural Augmentation based taIL nOde Representation learning\nframework, dubbed as SAILOR, which can jointly learn to augment the graph\nstructure and extract more informative representations for tail nodes.\nExtensive experiments on public benchmark datasets demonstrate that SAILOR can\nsignificantly improve the tail node representations and outperform the\nstate-of-the-art baselines.",
            "author": [
                "Jie Liao",
                "Jintang Li",
                "Liang Chen",
                "Bingzhe Wu",
                "Yatao Bian",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06801v2",
                "http://arxiv.org/pdf/2308.06801v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06797v1",
            "title": "A Zero-Knowledge Revocable Credential Verification Protocol Using\n  Attribute-Based Encryption",
            "updated": "2023-08-13T15:45:23Z",
            "published": "2023-08-13T15:45:23Z",
            "summary": "We introduce a zero-knowledge credential verification protocol leveraging on\nCiphertext Policy Attribute-Based Encryption. The protocol supports revocation\nthrough cryptographic accumulators.",
            "author": [
                "Giovanni Bartolomeo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06797v1",
                "http://arxiv.org/pdf/2308.06797v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06785v1",
            "title": "Formal Verification of Intersection Safety for Automated Driving",
            "updated": "2023-08-13T14:53:59Z",
            "published": "2023-08-13T14:53:59Z",
            "summary": "We build on our recent work on formalization of responsibility-sensitive\nsafety (RSS) and present the first formal framework that enables mathematical\nproofs of the safety of control strategies in intersection scenarios.\nIntersection scenarios are challenging due to the complex interaction between\nvehicles; to cope with it, we extend the program logic dFHL in the previous\nwork and introduce a novel formalism of hybrid control flow graphs on which our\nalgorithm can automatically discover an RSS condition that ensures safety. An\nRSS condition thus discovered is experimentally evaluated; we observe that it\nis safe (as our safety proof says) and is not overly conservative.",
            "author": [
                "James Haydon",
                "Martin Bondu",
                "Clovis Eberhart",
                "J\u00e9r\u00e9my Dubut",
                "Ichiro Hasuo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06785v1",
                "http://arxiv.org/pdf/2308.06785v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06782v1",
            "title": "PentestGPT: An LLM-empowered Automatic Penetration Testing Tool",
            "updated": "2023-08-13T14:35:50Z",
            "published": "2023-08-13T14:35:50Z",
            "summary": "Penetration testing, a crucial industrial practice for ensuring system\nsecurity, has traditionally resisted automation due to the extensive expertise\nrequired by human professionals. Large Language Models (LLMs) have shown\nsignificant advancements in various domains, and their emergent abilities\nsuggest their potential to revolutionize industries. In this research, we\nevaluate the performance of LLMs on real-world penetration testing tasks using\na robust benchmark created from test machines with platforms. Our findings\nreveal that while LLMs demonstrate proficiency in specific sub-tasks within the\npenetration testing process, such as using testing tools, interpreting outputs,\nand proposing subsequent actions, they also encounter difficulties maintaining\nan integrated understanding of the overall testing scenario.\n  In response to these insights, we introduce PentestGPT, an LLM-empowered\nautomatic penetration testing tool that leverages the abundant domain knowledge\ninherent in LLMs. PentestGPT is meticulously designed with three\nself-interacting modules, each addressing individual sub-tasks of penetration\ntesting, to mitigate the challenges related to context loss. Our evaluation\nshows that PentestGPT not only outperforms LLMs with a task-completion increase\nof 228.6\\% compared to the \\gptthree model among the benchmark targets but also\nproves effective in tackling real-world penetration testing challenges. Having\nbeen open-sourced on GitHub, PentestGPT has garnered over 4,700 stars and\nfostered active community engagement, attesting to its value and impact in both\nthe academic and industrial spheres.",
            "author": [
                "Gelei Deng",
                "Yi Liu",
                "V\u00edctor Mayoral-Vilches",
                "Peng Liu",
                "Yuekang Li",
                "Yuan Xu",
                "Tianwei Zhang",
                "Yang Liu",
                "Martin Pinzger",
                "Stefan Rass"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06782v1",
                "http://arxiv.org/pdf/2308.06782v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06764v1",
            "title": "Few-shot Class-incremental Learning: A Survey",
            "updated": "2023-08-13T13:01:21Z",
            "published": "2023-08-13T13:01:21Z",
            "summary": "Few-shot Class-Incremental Learning (FSCIL) presents a unique challenge in\nmachine learning, as it necessitates the continuous learning of new classes\nfrom sparse labeled training samples without forgetting previous knowledge.\nWhile this field has seen recent progress, it remains an active area of\nexploration. This paper aims to provide a comprehensive and systematic review\nof FSCIL. In our in-depth examination, we delve into various facets of FSCIL,\nencompassing the problem definition, the discussion of primary challenges of\nunreliable empirical risk minimization and the stability-plasticity dilemma,\ngeneral schemes, and relevant problems of incremental learning and few-shot\nlearning. Besides, we offer an overview of benchmark datasets and evaluation\nmetrics. Furthermore, we introduce the classification methods in FSCIL from\ndata-based, structure-based, and optimization-based approaches and the object\ndetection methods in FSCIL from anchor-free and anchor-based approaches. Beyond\nthese, we illuminate several promising research directions within FSCIL that\nmerit further investigation.",
            "author": [
                "Jinghua Zhang",
                "Li Liu",
                "Olli Silven",
                "Matti Pietik\u00e4inen",
                "Dewen Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06764v1",
                "http://arxiv.org/pdf/2308.06764v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06762v2",
            "title": "Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance\n  from High-Quality Isotropic Volumes",
            "updated": "2023-12-04T08:08:05Z",
            "published": "2023-08-13T12:51:15Z",
            "summary": "Accurate tissue segmentation of thick-slice fetal brain magnetic resonance\n(MR) scans is crucial for both reconstruction of isotropic brain MR volumes and\nthe quantification of fetal brain development. However, this task is\nchallenging due to the use of thick-slice scans in clinically-acquired fetal\nbrain data. To address this issue, we propose to leverage high-quality\nisotropic fetal brain MR volumes (and also their corresponding annotations) as\nguidance for segmentation of thick-slice scans. Due to existence of significant\ndomain gap between high-quality isotropic volume (i.e., source data) and\nthick-slice scans (i.e., target data), we employ a domain adaptation technique\nto achieve the associated knowledge transfer (from high-quality <source>\nvolumes to thick-slice <target> scans). Specifically, we first register the\navailable high-quality isotropic fetal brain MR volumes across different\ngestational weeks to construct longitudinally-complete source data. To capture\ndomain-invariant information, we then perform Fourier decomposition to extract\nimage content and style codes. Finally, we propose a novel Cycle-Consistent\nDomain Adaptation Network (C2DA-Net) to efficiently transfer the knowledge\nlearned from high-quality isotropic volumes for accurate tissue segmentation of\nthick-slice scans. Our C2DA-Net can fully utilize a small set of annotated\nisotropic volumes to guide tissue segmentation on unannotated thick-slice\nscans. Extensive experiments on a large-scale dataset of 372 clinically\nacquired thick-slice MR scans demonstrate that our C2DA-Net achieves much\nbetter performance than cutting-edge methods quantitatively and qualitatively.",
            "author": [
                "Shijie Huang",
                "Xukun Zhang",
                "Zhiming Cui",
                "He Zhang",
                "Geng Chen",
                "Dinggang Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06762v2",
                "http://arxiv.org/pdf/2308.06762v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06755v1",
            "title": "Influence Function Based Second-Order Channel Pruning-Evaluating True\n  Loss Changes For Pruning Is Possible Without Retraining",
            "updated": "2023-08-13T12:23:06Z",
            "published": "2023-08-13T12:23:06Z",
            "summary": "A challenge of channel pruning is designing efficient and effective criteria\nto select channels to prune. A widely used criterion is minimal performance\ndegeneration. To accurately evaluate the truth performance degeneration\nrequires retraining the survived weights to convergence, which is prohibitively\nslow. Hence existing pruning methods use previous weights (without retraining)\nto evaluate the performance degeneration. However, we observe the loss changes\ndiffer significantly with and without retraining. It motivates us to develop a\ntechnique to evaluate true loss changes without retraining, with which channels\nto prune can be selected more reliably and confidently. We first derive a\nclosed-form estimator of the true loss change per pruning mask change, using\ninfluence functions without retraining. Influence function which is from robust\nstatistics reveals the impacts of a training sample on the model's prediction\nand is repurposed by us to assess impacts on true loss changes. We then show\nhow to assess the importance of all channels simultaneously and develop a novel\nglobal channel pruning algorithm accordingly. We conduct extensive experiments\nto verify the effectiveness of the proposed algorithm. To the best of our\nknowledge, we are the first that shows evaluating true loss changes for pruning\nwithout retraining is possible. This finding will open up opportunities for a\nseries of new paradigms to emerge that differ from existing pruning methods.\nThe code is available at https://github.com/hrcheng1066/IFSO.",
            "author": [
                "Hongrong Cheng",
                "Miao Zhang",
                "Javen Qinfeng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06755v1",
                "http://arxiv.org/pdf/2308.06755v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06744v4",
            "title": "Token-Scaled Logit Distillation for Ternary Weight Generative Language\n  Models",
            "updated": "2023-12-03T03:29:37Z",
            "published": "2023-08-13T11:07:55Z",
            "summary": "Generative Language Models (GLMs) have shown impressive performance in tasks\nsuch as text generation, understanding, and reasoning. However, the large model\nsize poses challenges for practical deployment. To solve this problem,\nQuantization-Aware Training (QAT) has become increasingly popular. However,\ncurrent QAT methods for generative models have resulted in a noticeable loss of\naccuracy. To counteract this issue, we propose a novel knowledge distillation\nmethod specifically designed for GLMs. Our method, called token-scaled logit\ndistillation, prevents overfitting and provides superior learning from the\nteacher model and ground truth. This research marks the first evaluation of\nternary weight quantization-aware training of large-scale GLMs with less than\n1.0 degradation in perplexity and achieves enhanced accuracy in tasks like\ncommon-sense QA and arithmetic reasoning as well as natural language\nunderstanding. Our code is available at https://github.com/aiha-lab/TSLD.",
            "author": [
                "Minsoo Kim",
                "Sihwa Lee",
                "Janghwan Lee",
                "Sukjin Hong",
                "Du-Seong Chang",
                "Wonyong Sung",
                "Jungwook Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06744v4",
                "http://arxiv.org/pdf/2308.06744v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06719v1",
            "title": "3D Scene Graph Prediction on Point Clouds Using Knowledge Graphs",
            "updated": "2023-08-13T08:20:17Z",
            "published": "2023-08-13T08:20:17Z",
            "summary": "3D scene graph prediction is a task that aims to concurrently predict object\nclasses and their relationships within a 3D environment. As these environments\nare primarily designed by and for humans, incorporating commonsense knowledge\nregarding objects and their relationships can significantly constrain and\nenhance the prediction of the scene graph. In this paper, we investigate the\napplication of commonsense knowledge graphs for 3D scene graph prediction on\npoint clouds of indoor scenes. Through experiments conducted on a real-world\nindoor dataset, we demonstrate that integrating external commonsense knowledge\nvia the message-passing method leads to a 15.0 % improvement in scene graph\nprediction accuracy with external knowledge and $7.96\\%$ with internal\nknowledge when compared to state-of-the-art algorithms. We also tested in the\nreal world with 10 frames per second for scene graph generation to show the\nusage of the model in a more realistic robotics setting.",
            "author": [
                "Yiding Qiu",
                "Henrik I. Christensen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06719v1",
                "http://arxiv.org/pdf/2308.06719v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06717v1",
            "title": "Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden\n  Rewards",
            "updated": "2023-08-13T08:12:01Z",
            "published": "2023-08-13T08:12:01Z",
            "summary": "In practice, incentive providers (i.e., principals) often cannot observe the\nreward realizations of incentivized agents, which is in contrast to many\nprincipal-agent models that have been previously studied. This information\nasymmetry challenges the principal to consistently estimate the agent's unknown\nrewards by solely watching the agent's decisions, which becomes even more\nchallenging when the agent has to learn its own rewards. This complex setting\nis observed in various real-life scenarios ranging from renewable energy\nstorage contracts to personalized healthcare incentives. Hence, it offers not\nonly interesting theoretical questions but also wide practical relevance. This\npaper explores a repeated adverse selection game between a self-interested\nlearning agent and a learning principal. The agent tackles a multi-armed bandit\n(MAB) problem to maximize their expected reward plus incentive. On top of the\nagent's learning, the principal trains a parallel algorithm and faces a\ntrade-off between consistently estimating the agent's unknown rewards and\nmaximizing their own utility by offering adaptive incentives to lead the agent.\nFor a non-parametric model, we introduce an estimator whose only input is the\nhistory of principal's incentives and agent's choices. We unite this estimator\nwith a proposed data-driven incentive policy within a MAB framework. Without\nrestricting the type of the agent's algorithm, we prove finite-sample\nconsistency of the estimator and a rigorous regret bound for the principal by\nconsidering the sequential externality imposed by the agent. Lastly, our\ntheoretical results are reinforced by simulations justifying applicability of\nour framework to green energy aggregator contracts.",
            "author": [
                "Ilgin Dogan",
                "Zuo-Jun Max Shen",
                "Anil Aswani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06717v1",
                "http://arxiv.org/pdf/2308.06717v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.GT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06714v1",
            "title": "Learning on Graphs with Out-of-Distribution Nodes",
            "updated": "2023-08-13T08:10:23Z",
            "published": "2023-08-13T08:10:23Z",
            "summary": "Graph Neural Networks (GNNs) are state-of-the-art models for performing\nprediction tasks on graphs. While existing GNNs have shown great performance on\nvarious tasks related to graphs, little attention has been paid to the scenario\nwhere out-of-distribution (OOD) nodes exist in the graph during training and\ninference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes\nwith labels unseen from the training set. Since a lot of networks are\nautomatically constructed by programs, real-world graphs are often noisy and\nmay contain nodes from unknown distributions. In this work, we define the\nproblem of graph learning with out-of-distribution nodes. Specifically, we aim\nto accomplish two tasks: 1) detect nodes which do not belong to the known\ndistribution and 2) classify the remaining nodes to be one of the known\nclasses. We demonstrate that the connection patterns in graphs are informative\nfor outlier detection, and propose Out-of-Distribution Graph Attention Network\n(OODGAT), a novel GNN model which explicitly models the interaction between\ndifferent kinds of nodes and separate inliers from outliers during feature\npropagation. Extensive experiments show that OODGAT outperforms existing\noutlier detection methods by a large margin, while being better or comparable\nin terms of in-distribution classification.",
            "author": [
                "Yu Song",
                "Donglin Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3534678.3539457",
                "http://arxiv.org/abs/2308.06714v1",
                "http://arxiv.org/pdf/2308.06714v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06712v1",
            "title": "Compositional Feature Augmentation for Unbiased Scene Graph Generation",
            "updated": "2023-08-13T08:02:14Z",
            "published": "2023-08-13T08:02:14Z",
            "summary": "Scene Graph Generation (SGG) aims to detect all the visual relation triplets\n<sub, pred, obj> in a given image. With the emergence of various advanced\ntechniques for better utilizing both the intrinsic and extrinsic information in\neach relation triplet, SGG has achieved great progress over the recent years.\nHowever, due to the ubiquitous long-tailed predicate distributions, today's SGG\nmodels are still easily biased to the head predicates. Currently, the most\nprevalent debiasing solutions for SGG are re-balancing methods, e.g., changing\nthe distributions of original training samples. In this paper, we argue that\nall existing re-balancing strategies fail to increase the diversity of the\nrelation triplet features of each predicate, which is critical for robust SGG.\nTo this end, we propose a novel Compositional Feature Augmentation (CFA)\nstrategy, which is the first unbiased SGG work to mitigate the bias issue from\nthe perspective of increasing the diversity of triplet features. Specifically,\nwe first decompose each relation triplet feature into two components: intrinsic\nfeature and extrinsic feature, which correspond to the intrinsic\ncharacteristics and extrinsic contexts of a relation triplet, respectively.\nThen, we design two different feature augmentation modules to enrich the\nfeature diversity of original relation triplets by replacing or mixing up\neither their intrinsic or extrinsic features from other samples. Due to its\nmodel-agnostic nature, CFA can be seamlessly incorporated into various SGG\nframeworks. Extensive ablations have shown that CFA achieves a new\nstate-of-the-art performance on the trade-off between different metrics.",
            "author": [
                "Lin Li",
                "Guikun Chen",
                "Jun Xiao",
                "Yi Yang",
                "Chunping Wang",
                "Long Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06712v1",
                "http://arxiv.org/pdf/2308.06712v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06707v1",
            "title": "Condition-Adaptive Graph Convolution Learning for Skeleton-Based Gait\n  Recognition",
            "updated": "2023-08-13T07:51:59Z",
            "published": "2023-08-13T07:51:59Z",
            "summary": "Graph convolutional networks have been widely applied in skeleton-based gait\nrecognition. A key challenge in this task is to distinguish the individual\nwalking styles of different subjects across various views. Existing\nstate-of-the-art methods employ uniform convolutions to extract features from\ndiverse sequences and ignore the effects of viewpoint changes. To overcome\nthese limitations, we propose a condition-adaptive graph (CAG) convolution\nnetwork that can dynamically adapt to the specific attributes of each skeleton\nsequence and the corresponding view angle. In contrast to using fixed weights\nfor all joints and sequences, we introduce a joint-specific filter learning\n(JSFL) module in the CAG method, which produces sequence-adaptive filters at\nthe joint level. The adaptive filters capture fine-grained patterns that are\nunique to each joint, enabling the extraction of diverse spatial-temporal\ninformation about body parts. Additionally, we design a view-adaptive topology\nlearning (VATL) module that generates adaptive graph topologies. These graph\ntopologies are used to correlate the joints adaptively according to the\nspecific view conditions. Thus, CAG can simultaneously adjust to various\nwalking styles and viewpoints. Experiments on the two most widely used datasets\n(i.e., CASIA-B and OU-MVLP) show that CAG surpasses all previous skeleton-based\nmethods. Moreover, the recognition performance can be enhanced by simply\ncombining CAG with appearance-based methods, demonstrating the ability of CAG\nto provide useful complementary information.The source code will be available\nat https://github.com/OliverHxh/CAG.",
            "author": [
                "Xiaohu Huang",
                "Xinggang Wang",
                "Zhidianqiu Jin",
                "Bo Yang",
                "Botao He",
                "Bin Feng",
                "Wenyu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06707v1",
                "http://arxiv.org/pdf/2308.06707v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06696v1",
            "title": "MACO: A Modality Adversarial and Contrastive Framework for\n  Modality-missing Multi-modal Knowledge Graph Completion",
            "updated": "2023-08-13T06:29:38Z",
            "published": "2023-08-13T06:29:38Z",
            "summary": "Recent years have seen significant advancements in multi-modal knowledge\ngraph completion (MMKGC). MMKGC enhances knowledge graph completion (KGC) by\nintegrating multi-modal entity information, thereby facilitating the discovery\nof unobserved triples in the large-scale knowledge graphs (KGs). Nevertheless,\nexisting methods emphasize the design of elegant KGC models to facilitate\nmodality interaction, neglecting the real-life problem of missing modalities in\nKGs. The missing modality information impedes modal interaction, consequently\nundermining the model's performance. In this paper, we propose a modality\nadversarial and contrastive framework (MACO) to solve the modality-missing\nproblem in MMKGC. MACO trains a generator and discriminator adversarially to\ngenerate missing modality features that can be incorporated into the MMKGC\nmodel. Meanwhile, we design a cross-modal contrastive loss to improve the\nperformance of the generator. Experiments on public benchmarks with further\nexplorations demonstrate that MACO could achieve state-of-the-art results and\nserve as a versatile framework to bolster various MMKGC models. Our code and\nbenchmark data are available at https://github.com/zjukg/MACO.",
            "author": [
                "Yichi Zhang",
                "Zhuo Chen",
                "Wen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06696v1",
                "http://arxiv.org/pdf/2308.06696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06694v1",
            "title": "Impartial and Partizan Restricted Chocolate Bar Games",
            "updated": "2023-08-13T06:14:21Z",
            "published": "2023-08-13T06:14:21Z",
            "summary": "In this paper, we consider impartial and partizan restricted chocolate bar\ngames. In impartial restricted chocolate bar games, players cut a chocolate bar\ninto two pieces along any horizontal or vertical line and eat whichever piece\nis smaller. If the two pieces are the same size, a player can eat either one.\nIn constrast, partizan restricted chocolate bar games include players\ndesignated as Left and Right and chocolate bars with black and white stripes.\nLeft cuts the chocolate bar in two as above and eats the part with fewer black\nblocks. Similarly, Right cuts the bar and eats the part with fewer white\nblocks. A player loses when they cannot eat the remaining chocolate bar. We\nprovide formulas that describe the winning positions of the previous player,\nRight, and Left players. We also present an interesting similarity in the\ngraphs of previous players' winning positions for impartial and partizan\nchocolate bar games.",
            "author": [
                "Ryohei Miyadera",
                "Shoei Takahashi. Aoi Murakami",
                "Akito Tsujii",
                "Hikaru Manabe"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06694v1",
                "http://arxiv.org/pdf/2308.06694v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06692v1",
            "title": "SimMatchV2: Semi-Supervised Learning with Graph Consistency",
            "updated": "2023-08-13T05:56:36Z",
            "published": "2023-08-13T05:56:36Z",
            "summary": "Semi-Supervised image classification is one of the most fundamental problem\nin computer vision, which significantly reduces the need for human labor. In\nthis paper, we introduce a new semi-supervised learning algorithm - SimMatchV2,\nwhich formulates various consistency regularizations between labeled and\nunlabeled data from the graph perspective. In SimMatchV2, we regard the\naugmented view of a sample as a node, which consists of a label and its\ncorresponding representation. Different nodes are connected with the edges,\nwhich are measured by the similarity of the node representations. Inspired by\nthe message passing and node classification in graph theory, we propose four\ntypes of consistencies, namely 1) node-node consistency, 2) node-edge\nconsistency, 3) edge-edge consistency, and 4) edge-node consistency. We also\nuncover that a simple feature normalization can reduce the gaps of the feature\nnorm between different augmented views, significantly improving the performance\nof SimMatchV2. Our SimMatchV2 has been validated on multiple semi-supervised\nlearning benchmarks. Notably, with ResNet-50 as our backbone and 300 epochs of\ntraining, SimMatchV2 achieves 71.9\\% and 76.2\\% Top-1 Accuracy with 1\\% and\n10\\% labeled examples on ImageNet, which significantly outperforms the previous\nmethods and achieves state-of-the-art performance. Code and pre-trained models\nare available at\n\\href{https://github.com/mingkai-zheng/SimMatchV2}{https://github.com/mingkai-zheng/SimMatchV2}.",
            "author": [
                "Mingkai Zheng",
                "Shan You",
                "Lang Huang",
                "Chen Luo",
                "Fei Wang",
                "Chen Qian",
                "Chang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06692v1",
                "http://arxiv.org/pdf/2308.06692v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06685v1",
            "title": "Video Captioning with Aggregated Features Based on Dual Graphs and Gated\n  Fusion",
            "updated": "2023-08-13T05:18:08Z",
            "published": "2023-08-13T05:18:08Z",
            "summary": "The application of video captioning models aims at translating the content of\nvideos by using accurate natural language. Due to the complex nature inbetween\nobject interaction in the video, the comprehensive understanding of\nspatio-temporal relations of objects remains a challenging task. Existing\nmethods often fail in generating sufficient feature representations of video\ncontent. In this paper, we propose a video captioning model based on dual\ngraphs and gated fusion: we adapt two types of graphs to generate feature\nrepresentations of video content and utilize gated fusion to further understand\nthese different levels of information. Using a dual-graphs model to generate\nappearance features and motion features respectively can utilize the content\ncorrelation in frames to generate various features from multiple perspectives.\nAmong them, dual-graphs reasoning can enhance the content correlation in frame\nsequences to generate advanced semantic features; The gated fusion, on the\nother hand, aggregates the information in multiple feature representations for\ncomprehensive video content understanding. The experiments conducted on worldly\nused datasets MSVD and MSR-VTT demonstrate state-of-the-art performance of our\nproposed approach.",
            "author": [
                "Yutao Jin",
                "Bin Liu",
                "Jing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06685v1",
                "http://arxiv.org/pdf/2308.06685v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06670v1",
            "title": "Graphs with degree sequence $\\{m^{m-1},n^{n-1}\\}$ and $\\{m^n,n^m\\}$",
            "updated": "2023-08-13T03:06:48Z",
            "published": "2023-08-13T03:06:48Z",
            "summary": "In this paper we study the class of graphs $G_{m,n}$ that have the same\ndegree sequence as two disjoint cliques $K_m$ and $K_n$, as well as the class\n$\\overline G_{m,n}$ of the complements of such graphs. We establish various\nproperties of $G_{m,n}$ and $\\overline G_{m,n}$ related to recognition,\nconnectivity, diameter, bipartiteness, Hamiltonicity, and pancyclicity. We also\nshow that several classical optimization problems on these graphs are NP-hard.",
            "author": [
                "Boris Brimkov",
                "Valentin Brimkov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06670v1",
                "http://arxiv.org/pdf/2308.06670v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06665v1",
            "title": "Unsupervised Adaptation of Polyp Segmentation Models via Coarse-to-Fine\n  Self-Supervision",
            "updated": "2023-08-13T02:37:08Z",
            "published": "2023-08-13T02:37:08Z",
            "summary": "Unsupervised Domain Adaptation~(UDA) has attracted a surge of interest over\nthe past decade but is difficult to be used in real-world applications.\nConsidering the privacy-preservation issues and security concerns, in this\nwork, we study a practical problem of Source-Free Domain Adaptation (SFDA),\nwhich eliminates the reliance on annotated source data. Current SFDA methods\nfocus on extracting domain knowledge from the source-trained model but neglects\nthe intrinsic structure of the target domain. Moreover, they typically utilize\npseudo labels for self-training in the target domain, but suffer from the\nnotorious error accumulation problem. To address these issues, we propose a new\nSFDA framework, called Region-to-Pixel Adaptation Network~(RPANet), which\nlearns the region-level and pixel-level discriminative representations through\ncoarse-to-fine self-supervision. The proposed RPANet consists of two modules,\nForeground-aware Contrastive Learning (FCL) and Confidence-Calibrated\nPseudo-Labeling (CCPL), which explicitly address the key challenges of ``how to\ndistinguish'' and ``how to refine''. To be specific, FCL introduces a\nsupervised contrastive learning paradigm in the region level to contrast\ndifferent region centroids across different target images, which efficiently\ninvolves all pseudo labels while robust to noisy samples. CCPL designs a novel\nfusion strategy to reduce the overconfidence problem of pseudo labels by fusing\ntwo different target predictions without introducing any additional network\nmodules. Extensive experiments on three cross-domain polyp segmentation tasks\nreveal that RPANet significantly outperforms state-of-the-art SFDA and UDA\nmethods without access to source data, revealing the potential of SFDA in\nmedical applications.",
            "author": [
                "Jiexiang Wang",
                "Chaoqi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06665v1",
                "http://arxiv.org/pdf/2308.06665v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18630v1",
            "title": "SATHUR: Self Augmenting Task Hallucinal Unified Representation for\n  Generalized Class Incremental Learning",
            "updated": "2023-08-13T00:17:13Z",
            "published": "2023-08-13T00:17:13Z",
            "summary": "Class Incremental Learning (CIL) is inspired by the human ability to learn\nnew classes without forgetting previous ones. CIL becomes more challenging in\nreal-world scenarios when the samples in each incremental step are imbalanced.\nThis creates another branch of problem, called Generalized Class Incremental\nLearning (GCIL) where each incremental step is structured more realistically.\nGrow When Required (GWR) network, a type of Self-Organizing Map (SOM),\ndynamically create and remove nodes and edges for adaptive learning. GWR\nperforms incremental learning from feature vectors extracted by a Convolutional\nNeural Network (CNN), which acts as a feature extractor. The inherent ability\nof GWR to form distinct clusters, each corresponding to a class in the feature\nvector space, regardless of the order of samples or class imbalances, is well\nsuited to achieving GCIL. To enhance GWR's classification performance, a\nhigh-quality feature extractor is required. However, when the convolutional\nlayers are adapted at each incremental step, the GWR nodes corresponding to\nprior knowledge are subject to near-invalidation. This work introduces the Self\nAugmenting Task Hallucinal Unified Representation (SATHUR), which\nre-initializes the GWR network at each incremental step, aligning it with the\ncurrent feature extractor. Comprehensive experimental results demonstrate that\nour proposed method significantly outperforms other state-of-the-art GCIL\nmethods on CIFAR-100 and CORe50 datasets.",
            "author": [
                "Sathursan Kanagarajah",
                "Thanuja Ambegoda",
                "Ranga Rodrigo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18630v1",
                "http://arxiv.org/pdf/2311.18630v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06653v1",
            "title": "Smart Knowledge Transfer using Google-like Search",
            "updated": "2023-08-12T23:38:34Z",
            "published": "2023-08-12T23:38:34Z",
            "summary": "To address the issue of rising software maintenance cost due to program\ncomprehension challenges, we propose SMARTKT (Smart Knowledge Transfer), a\nsearch framework, which extracts and integrates knowledge related to various\naspects of an application in form of a semantic graph. This graph supports\nsyntax and semantic queries and converts the process of program comprehension\ninto a {\\em google-like} search problem.",
            "author": [
                "Srijoni Majumdar",
                "Partha Pratim Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06653v1",
                "http://arxiv.org/pdf/2308.06653v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06651v1",
            "title": "In-plane Hall effect in rutile oxide films induced by the Lorentz force",
            "updated": "2023-08-12T23:05:07Z",
            "published": "2023-08-12T23:05:07Z",
            "summary": "The conventional Hall effect is linearly proportional to the field component\nor magnetization component perpendicular to a film. Despite the increasing\ntheoretical proposals on the Hall effect to the in-plane field or magnetization\nin various special systems induced by the Berry curvature, such an\nunconventional Hall effect has only been experimentally reported in Weyl\nsemimetals and in a heterodimensional superlattice. Here, we report an\nunambiguous experimental observation of the in-plane Hall effect (IPHE) in\ncentrosymmetric rutile RuO2 and IrO2 single-crystal films under an in-plane\nmagnetic field. The measured Hall resistivity is found to be proportional to\nthe component of the applied in-plane magnetic field along a particular crystal\naxis and to be independent of the current direction or temperature. Both the\nexperimental observations and theoretical calculations confirm that the IPHE in\nrutile oxide films is induced by the Lorentz force. Our findings can be\ngeneralized to ferromagnetic materials for the discovery of in-plane anomalous\nHall effects and quantum anomalous Hall effects. In addition to significantly\nexpanding knowledge of the Hall effect, this work opens the door to explore new\nmembers in the Hall effect family.",
            "author": [
                "Yongwei Cui",
                "Zhaoqing Li",
                "Haoran Chen",
                "Yue Chen",
                "Yunzhuo Wu",
                "Ke Pei",
                "Tong Wu",
                "Nian Xie",
                "Renchao Che",
                "Xuepeng Qiu",
                "Yi Liu",
                "Zhe Yuan",
                "Yizheng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06651v1",
                "http://arxiv.org/pdf/2308.06651v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06644v2",
            "title": "Accelerating Diffusion-based Combinatorial Optimization Solvers by\n  Progressive Distillation",
            "updated": "2023-08-22T22:25:54Z",
            "published": "2023-08-12T21:25:24Z",
            "summary": "Graph-based diffusion models have shown promising results in terms of\ngenerating high-quality solutions to NP-complete (NPC) combinatorial\noptimization (CO) problems. However, those models are often inefficient in\ninference, due to the iterative evaluation nature of the denoising diffusion\nprocess. This paper proposes to use progressive distillation to speed up the\ninference by taking fewer steps (e.g., forecasting two steps ahead within a\nsingle step) during the denoising process. Our experimental results show that\nthe progressively distilled model can perform inference 16 times faster with\nonly 0.019% degradation in performance on the TSP-50 dataset.",
            "author": [
                "Junwei Huang",
                "Zhiqing Sun",
                "Yiming Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06644v2",
                "http://arxiv.org/pdf/2308.06644v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06635v1",
            "title": "3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking",
            "updated": "2023-08-12T19:19:58Z",
            "published": "2023-08-12T19:19:58Z",
            "summary": "Tracking 3D objects accurately and consistently is crucial for autonomous\nvehicles, enabling more reliable downstream tasks such as trajectory prediction\nand motion planning. Based on the substantial progress in object detection in\nrecent years, the tracking-by-detection paradigm has become a popular choice\ndue to its simplicity and efficiency. State-of-the-art 3D multi-object tracking\n(MOT) approaches typically rely on non-learned model-based algorithms such as\nKalman Filter but require many manually tuned parameters. On the other hand,\nlearning-based approaches face the problem of adapting the training to the\nonline setting, leading to inevitable distribution mismatch between training\nand inference as well as suboptimal performance. In this work, we propose\n3DMOTFormer, a learned geometry-based 3D MOT framework building upon the\ntransformer architecture. We use an Edge-Augmented Graph Transformer to reason\non the track-detection bipartite graph frame-by-frame and conduct data\nassociation via edge classification. To reduce the distribution mismatch\nbetween training and inference, we propose a novel online training strategy\nwith an autoregressive and recurrent forward pass as well as sequential batch\noptimization. Using CenterPoint detections, our approach achieves 71.2% and\n68.2% AMOTA on the nuScenes validation and test split, respectively. In\naddition, a trained 3DMOTFormer model generalizes well across different object\ndetectors. Code is available at: https://github.com/dsx0511/3DMOTFormer.",
            "author": [
                "Shuxiao Ding",
                "Eike Rehder",
                "Lukas Schneider",
                "Marius Cordts",
                "Juergen Gall"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06635v1",
                "http://arxiv.org/pdf/2308.06635v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06622v1",
            "title": "DFM-X: Augmentation by Leveraging Prior Knowledge of Shortcut Learning",
            "updated": "2023-08-12T17:39:10Z",
            "published": "2023-08-12T17:39:10Z",
            "summary": "Neural networks are prone to learn easy solutions from superficial statistics\nin the data, namely shortcut learning, which impairs generalization and\nrobustness of models. We propose a data augmentation strategy, named DFM-X,\nthat leverages knowledge about frequency shortcuts, encoded in Dominant\nFrequencies Maps computed for image classification models. We randomly select\nX% training images of certain classes for augmentation, and process them by\nretaining the frequencies included in the DFMs of other classes. This strategy\ncompels the models to leverage a broader range of frequencies for\nclassification, rather than relying on specific frequency sets. Thus, the\nmodels learn more deep and task-related semantics compared to their counterpart\ntrained with standard setups. Unlike other commonly used augmentation\ntechniques which focus on increasing the visual variations of training data,\nour method targets exploiting the original data efficiently, by distilling\nprior knowledge about destructive learning behavior of models from data. Our\nexperimental results demonstrate that DFM-X improves robustness against common\ncorruptions and adversarial attacks. It can be seamlessly integrated with other\naugmentation techniques to further enhance the robustness of models.",
            "author": [
                "Shunxin Wang",
                "Christoph Brune",
                "Raymond Veldhuis",
                "Nicola Strisciuglio"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06622v1",
                "http://arxiv.org/pdf/2308.06622v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06599v1",
            "title": "Semantic Communications with Explicit Semantic Base for Image\n  Transmission",
            "updated": "2023-08-12T15:47:37Z",
            "published": "2023-08-12T15:47:37Z",
            "summary": "Semantic communications, aiming at ensuring the successful delivery of the\nmeaning of information, are expected to be one of the potential techniques for\nthe next generation communications. However, the knowledge forming and\nsynchronizing mechanism that enables semantic communication systems to extract\nand interpret the semantics of information according to the communication\nintents is still immature. In this paper, we propose a semantic image\ntransmission framework with explicit semantic base (Seb), where Sebs are\ngenerated and employed as the knowledge shared between the transmitter and the\nreceiver with flexible granularity. To represent images with Sebs, a novel\nSeb-based reference image generator is proposed to generate Sebs and then\ndecompose the transmitted images. To further encode/decode the residual\ninformation for precise image reconstruction, a Seb-based image encoder/decoder\nis proposed. The key components of the proposed framework are optimized jointly\nby end-to-end (E2E) training, where the loss function is dedicated designed to\ntackle the problem of nondifferentiable operation in Seb-based reference image\ngenerator by introducing a gradient approximation mechanism. Extensive\nexperiments show that the proposed framework outperforms state-of-art works by\n0.5 - 1.5 dB in peak signal-to-noise ratio (PSNR) w.r.t. different\nsignal-to-noise ratio (SNR).",
            "author": [
                "Yuan Zheng",
                "Fengyu Wang",
                "Wenjun Xu",
                "Miao Pan",
                "Ping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06599v1",
                "http://arxiv.org/pdf/2308.06599v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06597v1",
            "title": "Hadamard-Hitchcock decompositions: identifiability and computation",
            "updated": "2023-08-12T15:33:23Z",
            "published": "2023-08-12T15:33:23Z",
            "summary": "A Hadamard-Hitchcock decomposition of a multidimensional array is a\ndecomposition that expresses the latter as a Hadamard product of several tensor\nrank decompositions. Such decompositions can encode probability distributions\nthat arise from statistical graphical models associated to complete bipartite\ngraphs with one layer of observed random variables and one layer of hidden\nones, usually called restricted Boltzmann machines. We establish generic\nidentifiability of Hadamard-Hitchcock decompositions by exploiting the reshaped\nKruskal criterion for tensor rank decompositions. A flexible algorithm\nleveraging existing decomposition algorithms for tensor rank decomposition is\nintroduced for computing a Hadamard-Hitchcock decomposition. Numerical\nexperiments illustrate its computational performance and numerical accuracy.",
            "author": [
                "Alessandro Oneto",
                "Nick Vannieuwenhoven"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06597v1",
                "http://arxiv.org/pdf/2308.06597v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "cs.NA",
                "math.NA",
                "math.ST",
                "stat.TH",
                "15A69, 62E10, 14M99, 65Y20, 14N07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06585v1",
            "title": "Approximate Answering of Graph Queries",
            "updated": "2023-08-12T14:47:21Z",
            "published": "2023-08-12T14:47:21Z",
            "summary": "Knowledge graphs (KGs) are inherently incomplete because of incomplete world\nknowledge and bias in what is the input to the KG. Additionally, world\nknowledge constantly expands and evolves, making existing facts deprecated or\nintroducing new ones. However, we would still want to be able to answer queries\nas if the graph were complete. In this chapter, we will give an overview of\nseveral methods which have been proposed to answer queries in such a setting.\nWe will first provide an overview of the different query types which can be\nsupported by these methods and datasets typically used for evaluation, as well\nas an insight into their limitations. Then, we give an overview of the\ndifferent approaches and describe them in terms of expressiveness, supported\ngraph types, and inference capabilities.",
            "author": [
                "Michael Cochez",
                "Dimitrios Alivanistos",
                "Erik Arakelyan",
                "Max Berrendorf",
                "Daniel Daza",
                "Mikhail Galkin",
                "Pasquale Minervini",
                "Mathias Niepert",
                "Hongyu Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06585v1",
                "http://arxiv.org/pdf/2308.06585v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB",
                "cs.LO",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06582v1",
            "title": "Gated Attention Coding for Training High-performance and Efficient\n  Spiking Neural Networks",
            "updated": "2023-08-12T14:42:02Z",
            "published": "2023-08-12T14:42:02Z",
            "summary": "Spiking neural networks (SNNs) are emerging as an energy-efficient\nalternative to traditional artificial neural networks (ANNs) due to their\nunique spike-based event-driven nature. Coding is crucial in SNNs as it\nconverts external input stimuli into spatio-temporal feature sequences.\nHowever, most existing deep SNNs rely on direct coding that generates powerless\nspike representation and lacks the temporal dynamics inherent in human vision.\nHence, we introduce Gated Attention Coding (GAC), a plug-and-play module that\nleverages the multi-dimensional gated attention unit to efficiently encode\ninputs into powerful representations before feeding them into the SNN\narchitecture. GAC functions as a preprocessing layer that does not disrupt the\nspike-driven nature of the SNN, making it amenable to efficient neuromorphic\nhardware implementation with minimal modifications. Through an observer model\ntheoretical analysis, we demonstrate GAC's attention mechanism improves\ntemporal dynamics and coding efficiency. Experiments on CIFAR10/100 and\nImageNet datasets demonstrate that GAC achieves state-of-the-art accuracy with\nremarkable efficiency. Notably, we improve top-1 accuracy by 3.10\\% on CIFAR100\nwith only 6-time steps and 1.07\\% on ImageNet while reducing energy usage to\n66.9\\% of the previous works. To our best knowledge, it is the first time to\nexplore the attention-based dynamic coding scheme in deep SNNs, with\nexceptional effectiveness and efficiency on large-scale datasets.",
            "author": [
                "Xuerui Qiu",
                "Rui-Jie Zhu",
                "Yuhong Chou",
                "Zhaorui Wang",
                "Liang-jian Deng",
                "Guoqi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06582v1",
                "http://arxiv.org/pdf/2308.06582v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06566v1",
            "title": "4-bit Factorization Circuit Composed of Multiplier Units with\n  Superconducting Flux Qubits toward Quantum Annealing",
            "updated": "2023-08-12T13:24:46Z",
            "published": "2023-08-12T13:24:46Z",
            "summary": "Prime factorization (P = M*N) is considered to be a promising application in\nquantum computations. We perform 4-bit factorization in experiments using a\nsuperconducting flux qubit toward quantum annealing. Our proposed method uses a\nsuperconducting quantum circuit implementing a multiplier Hamiltonian, which\nprovides combinations of M and N as a factorization solution after quantum\nannealing when the integer P is initially set. The circuit comprises multiple\nmultiplier units combined with connection qubits. The key points are a native\nimplementation of the multiplier Hamiltonian to the superconducting quantum\ncircuit and its fabrication using a Nb multilayer process with a Josephson\njunction dedicated to the qubit. The 4-bit factorization circuit comprises 32\nsuperconducting flux qubits. Our method has superior scalability because the\nHamiltonian is implemented with fewer qubits than in conventional methods using\na chimera graph architecture. We perform experiments at 10 mK to clarify the\nvalidity of interconnections of a multiplier unit using qubits. We demonstrate\nexperiments at 4.2 K and simulations for the factorization of integers 4, 6,\nand 9.",
            "author": [
                "Daisuke Saida",
                "Mutsuo Hidaka",
                "Yuki Yamanashi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06566v1",
                "http://arxiv.org/pdf/2308.06566v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06564v2",
            "title": "EquiDiff: A Conditional Equivariant Diffusion Model For Trajectory\n  Prediction",
            "updated": "2023-08-29T06:25:48Z",
            "published": "2023-08-12T13:17:09Z",
            "summary": "Accurate trajectory prediction is crucial for the safe and efficient\noperation of autonomous vehicles. The growing popularity of deep learning has\nled to the development of numerous methods for trajectory prediction. While\ndeterministic deep learning models have been widely used, deep generative\nmodels have gained popularity as they learn data distributions from training\ndata and account for trajectory uncertainties. In this study, we propose\nEquiDiff, a deep generative model for predicting future vehicle trajectories.\nEquiDiff is based on the conditional diffusion model, which generates future\ntrajectories by incorporating historical information and random Gaussian noise.\nThe backbone model of EquiDiff is an SO(2)-equivariant transformer that fully\nutilizes the geometric properties of location coordinates. In addition, we\nemploy Recurrent Neural Networks and Graph Attention Networks to extract social\ninteractions from historical trajectories. To evaluate the performance of\nEquiDiff, we conduct extensive experiments on the NGSIM dataset. Our results\ndemonstrate that EquiDiff outperforms other baseline models in short-term\nprediction, but has slightly higher errors for long-term prediction.\nFurthermore, we conduct an ablation study to investigate the contribution of\neach component of EquiDiff to the prediction accuracy. Additionally, we present\na visualization of the generation process of our diffusion model, providing\ninsights into the uncertainty of the prediction.",
            "author": [
                "Kehua Chen",
                "Xianda Chen",
                "Zihan Yu",
                "Meixin Zhu",
                "Hai Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06564v2",
                "http://arxiv.org/pdf/2308.06564v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06552v2",
            "title": "MT4CrossOIE: Multi-stage Tuning for Cross-lingual Open Information\n  Extraction",
            "updated": "2023-09-20T14:37:38Z",
            "published": "2023-08-12T12:38:10Z",
            "summary": "Cross-lingual open information extraction aims to extract structured\ninformation from raw text across multiple languages. Previous work uses a\nshared cross-lingual pre-trained model to handle the different languages but\nunderuses the potential of the language-specific representation. In this paper,\nwe propose an effective multi-stage tuning framework called MT4CrossIE,\ndesigned for enhancing cross-lingual open information extraction by injecting\nlanguage-specific knowledge into the shared model. Specifically, the\ncross-lingual pre-trained model is first tuned in a shared semantic space\n(e.g., embedding matrix) in the fixed encoder and then other components are\noptimized in the second stage. After enough training, we freeze the pre-trained\nmodel and tune the multiple extra low-rank language-specific modules using\nmixture-of-LoRAs for model-based cross-lingual transfer. In addition, we\nleverage two-stage prompting to encourage the large language model (LLM) to\nannotate the multi-lingual raw data for data-based cross-lingual transfer. The\nmodel is trained with multi-lingual objectives on our proposed dataset\nOpenIE4++ by combing the model-based and data-based transfer techniques.\nExperimental results on various benchmarks emphasize the importance of\naggregating multiple plug-in-and-play language-specific modules and demonstrate\nthe effectiveness of MT4CrossIE in cross-lingual\nOIE\\footnote{\\url{https://github.com/CSJianYang/Multilingual-Multimodal-NLP}}.",
            "author": [
                "Tongliang Li",
                "Zixiang Wang",
                "Linzheng Chai",
                "Jian Yang",
                "Jiaqi Bai",
                "Yuwei Yin",
                "Jiaheng Liu",
                "Hongcheng Guo",
                "Liqun Yang",
                "Hebboul Zine el-abidine",
                "Zhoujun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06552v2",
                "http://arxiv.org/pdf/2308.06552v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06548v1",
            "title": "Revisiting Vision Transformer from the View of Path Ensemble",
            "updated": "2023-08-12T12:18:16Z",
            "published": "2023-08-12T12:18:16Z",
            "summary": "Vision Transformers (ViTs) are normally regarded as a stack of transformer\nlayers. In this work, we propose a novel view of ViTs showing that they can be\nseen as ensemble networks containing multiple parallel paths with different\nlengths. Specifically, we equivalently transform the traditional cascade of\nmulti-head self-attention (MSA) and feed-forward network (FFN) into three\nparallel paths in each transformer layer. Then, we utilize the identity\nconnection in our new transformer form and further transform the ViT into an\nexplicit multi-path ensemble network. From the new perspective, these paths\nperform two functions: the first is to provide the feature for the classifier\ndirectly, and the second is to provide the lower-level feature representation\nfor subsequent longer paths. We investigate the influence of each path for the\nfinal prediction and discover that some paths even pull down the performance.\nTherefore, we propose the path pruning and EnsembleScale skills for\nimprovement, which cut out the underperforming paths and re-weight the ensemble\ncomponents, respectively, to optimize the path combination and make the short\npaths focus on providing high-quality representation for subsequent paths. We\nalso demonstrate that our path combination strategies can help ViTs go deeper\nand act as high-pass filters to filter out partial low-frequency signals. To\nfurther enhance the representation of paths served for subsequent paths,\nself-distillation is applied to transfer knowledge from the long paths to the\nshort paths. This work calls for more future research to explain and design\nViTs from new perspectives.",
            "author": [
                "Shuning Chang",
                "Pichao Wang",
                "Hao Luo",
                "Fan Wang",
                "Mike Zheng Shou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06548v1",
                "http://arxiv.org/pdf/2308.06548v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06546v2",
            "title": "MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction",
            "updated": "2023-08-15T07:28:15Z",
            "published": "2023-08-12T12:03:41Z",
            "summary": "Extracting meaningful drug-related information chunks, such as adverse drug\nevents (ADE), is crucial for preventing morbidity and saving many lives. Most\nADEs are reported via an unstructured conversation with the medical context, so\napplying a general entity recognition approach is not sufficient enough. In\nthis paper, we propose a new multi-aspect cross-integration framework for drug\nentity/event detection by capturing and aligning different\ncontext/language/knowledge properties from drug-related documents. We first\nconstruct multi-aspect encoders to describe semantic, syntactic, and medical\ndocument contextual information by conducting those slot tagging tasks, main\ndrug entity/event detection, part-of-speech tagging, and general medical named\nentity recognition. Then, each encoder conducts cross-integration with other\ncontextual information in three ways: the key-value cross, attention cross, and\nfeedforward cross, so the multi-encoders are integrated in depth. Our model\noutperforms all SOTA on two widely used tasks, flat entity detection and\ndiscontinuous event extraction.",
            "author": [
                "Jie Yang",
                "Soyeon Caren Han",
                "Siqu Long",
                "Josiah Poon",
                "Goran Nenadic"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06546v2",
                "http://arxiv.org/pdf/2308.06546v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06537v1",
            "title": "Determining the Fundamental Failure Modes in Ni-rich Lithium Ion Battery\n  Cathodes",
            "updated": "2023-08-12T11:42:31Z",
            "published": "2023-08-12T11:42:31Z",
            "summary": "Challenges associated with in-service mechanical degradation of Li-ion\nbattery cathodes has prompted a transition from polycrystalline to single\ncrystal cathode materials. Whilst for single crystal materials,\ndislocation-assisted crack formation is assumed to be the dominating failure\nmechanism throughout battery life, there is little direct information about\ntheir mechanical behaviour, and mechanistic understanding remains elusive.\nHere, we demonstrated, using in situ micromechanical testing, direct\nmeasurement of local mechanical properties within LiNi0.8Mn0.1Co0.1O2 single\ncrystalline domains. We elucidated the dislocation slip systems, their critical\nstresses, and how slip facilitate cracking. We then compared single crystal and\npolycrystal deformation behaviour. Our findings answer two fundamental\nquestions critical to understanding cathode degradation: What dislocation slip\nsystems operate in Ni-rich cathode materials? And how does slip cause fracture?\nThis knowledge unlocks our ability to develop tools for lifetime prediction and\nfailure risk assessment, as well as in designing novel cathode materials with\nincreased toughness in-service.",
            "author": [
                "Siyang Wang",
                "Zonghao Shen",
                "Aigerim Omirkhan",
                "Oriol Gavalda-Diaz",
                "Mary P. Ryan",
                "Finn Giuliani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06537v1",
                "http://arxiv.org/pdf/2308.06537v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06535v1",
            "title": "Visualising category recoding and numeric redistributions",
            "updated": "2023-08-12T11:40:24Z",
            "published": "2023-08-12T11:40:24Z",
            "summary": "This paper proposes graphical representations of data and rationale\nprovenance in workflows that convert both category labels and associated\nnumeric data between distinct but semantically related taxonomies. We motivate\nthe graphical representations with a new task abstraction, the cross-taxonomy\ntransformation, and associated graph-based information structure, the crossmap.\nThe task abstraction supports the separation of category recoding and numeric\nredistribution decisions from the specifics of data manipulation in ex-post\ndata harmonisation. The crossmap structure is illustrated using an example\nconversion of numeric statistics from a country-specific taxonomy to an\ninternational classification standard. We discuss the opportunities and\nchallenges of using visualisation to audit and communicate cross-taxonomy\ntransformations and present candidate graphical representations.",
            "author": [
                "Cynthia A. Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06535v1",
                "http://arxiv.org/pdf/2308.06535v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06520v1",
            "title": "Parameterized Matroid-Constrained Maximum Coverage",
            "updated": "2023-08-12T10:20:48Z",
            "published": "2023-08-12T10:20:48Z",
            "summary": "In this paper, we introduce the concept of Density-Balanced Subset in a\nmatroid, in which independent sets can be sampled so as to guarantee that (i)\neach element has the same probability to be sampled, and (ii) those events are\nnegatively correlated. These Density-Balanced Subsets are subsets in the ground\nset of a matroid in which the traditional notion of uniform random sampling can\nbe extended. We then provide an application of this concept to the\nMatroid-Constrained Maximum Coverage problem. In this problem, given a matroid\n$\\mathcal{M} = (V, \\mathcal{I})$ of rank $k$ on a ground set $V$ and a coverage\nfunction $f$ on $V$, the goal is to find an independent set $S \\in \\mathcal{I}$\nmaximizing $f(S)$. This problem is an important special case of the\nmuch-studied submodular function maximization problem subject to a matroid\nconstraint; this is also a generalization of the maximum $k$-cover problem in a\ngraph. In this paper, assuming that the coverage function has a bounded\nfrequency $\\mu$ (i.e., any element of the underlying universe of the coverage\nfunction appears in at most $\\mu$ sets), we design a procedure, parameterized\nby some integer $\\rho$, to extract in polynomial time an approximate kernel of\nsize $\\rho \\cdot k$ that is guaranteed to contain a $1 - (\\mu - 1)/\\rho$\napproximation of the optimal solution. This procedure can then be used to get a\nFixed-Parameter Tractable Approximation Scheme (FPT-AS) providing a $1 -\n\\varepsilon$ approximation in time $(\\mu/\\varepsilon)^{O(k)} \\cdot |V|^{O(1)}$.\nThis generalizes and improves the results of [Manurangsi, 2019] and [Huang and\nSellier, 2022], providing the first FPT-AS working on an arbitrary matroid.\nMoreover, because of its simplicity, the kernel construction can be performed\nin the streaming setting.",
            "author": [
                "Fran\u00e7ois Sellier"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06520v1",
                "http://arxiv.org/pdf/2308.06520v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06512v1",
            "title": "HyperFormer: Enhancing Entity and Relation Interaction for\n  Hyper-Relational Knowledge Graph Completion",
            "updated": "2023-08-12T09:31:43Z",
            "published": "2023-08-12T09:31:43Z",
            "summary": "Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by\nassociating attribute-value qualifiers to triples, which effectively represent\nadditional fine-grained information about its associated triple.\nHyper-relational knowledge graph completion (HKGC) aims at inferring unknown\ntriples while considering its qualifiers. Most existing approaches to HKGC\nexploit a global-level graph structure to encode hyper-relational knowledge\ninto the graph convolution message passing process. However, the addition of\nmulti-hop information might bring noise into the triple prediction process. To\naddress this problem, we propose HyperFormer, a model that considers\nlocal-level sequential information, which encodes the content of the entities,\nrelations and qualifiers of a triple. More precisely, HyperFormer is composed\nof three different modules: an entity neighbor aggregator module allowing to\nintegrate the information of the neighbors of an entity to capture different\nperspectives of it; a relation qualifier aggregator module to integrate\nhyper-relational knowledge into the corresponding relation to refine the\nrepresentation of relational content; a convolution-based bidirectional\ninteraction module based on a convolutional operation, capturing pairwise\nbidirectional interactions of entity-relation, entity-qualifier, and\nrelation-qualifier. realize the depth perception of the content related to the\ncurrent statement. Furthermore, we introduce a Mixture-of-Experts strategy into\nthe feed-forward layers of HyperFormer to strengthen its representation\ncapabilities while reducing the amount of model parameters and computation.\nExtensive experiments on three well-known datasets with four different\nconditions demonstrate HyperFormer's effectiveness. Datasets and code are\navailable at https://github.com/zhiweihu1103/HKGC-HyperFormer.",
            "author": [
                "Zhiwei Hu",
                "V\u00edctor Guti\u00e9rrez-Basulto",
                "Zhiliang Xiang",
                "Ru Li",
                "Jeff Z. Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06512v1",
                "http://arxiv.org/pdf/2308.06512v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06501v1",
            "title": "NewsDialogues: Towards Proactive News Grounded Conversation",
            "updated": "2023-08-12T08:33:42Z",
            "published": "2023-08-12T08:33:42Z",
            "summary": "Hot news is one of the most popular topics in daily conversations. However,\nnews grounded conversation has long been stymied by the lack of well-designed\ntask definition and scarce data. In this paper, we propose a novel task,\nProactive News Grounded Conversation, in which a dialogue system can\nproactively lead the conversation based on some key topics of the news. In\naddition, both information-seeking and chit-chat scenarios are included\nrealistically, where the user may ask a series of questions about the news\ndetails or express their opinions and be eager to chat. To further develop this\nnovel task, we collect a human-to-human Chinese dialogue dataset\n\\ts{NewsDialogues}, which includes 1K conversations with a total of 14.6K\nutterances and detailed annotations for target topics and knowledge spans.\nFurthermore, we propose a method named Predict-Generate-Rank, consisting of a\ngenerator for grounded knowledge prediction and response generation, and a\nranker for the ranking of multiple responses to alleviate the exposure bias. We\nconduct comprehensive experiments to demonstrate the effectiveness of the\nproposed method and further present several key findings and challenges to\nprompt future research.",
            "author": [
                "Siheng Li",
                "Yichun Yin",
                "Cheng Yang",
                "Wangjie Jiang",
                "Yiwei Li",
                "Zesen Cheng",
                "Lifeng Shang",
                "Xin Jiang",
                "Qun Liu",
                "Yujiu Yang"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.findings-acl.224",
                "http://arxiv.org/abs/2308.06501v1",
                "http://arxiv.org/pdf/2308.06501v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06488v1",
            "title": "Generating Faithful Text From a Knowledge Graph with Noisy Reference\n  Text",
            "updated": "2023-08-12T07:12:45Z",
            "published": "2023-08-12T07:12:45Z",
            "summary": "Knowledge Graph (KG)-to-Text generation aims at generating fluent\nnatural-language text that accurately represents the information of a given\nknowledge graph. While significant progress has been made in this task by\nexploiting the power of pre-trained language models (PLMs) with appropriate\ngraph structure-aware modules, existing models still fall short of generating\nfaithful text, especially when the ground-truth natural-language text contains\nadditional information that is not present in the graph. In this paper, we\ndevelop a KG-to-text generation model that can generate faithful\nnatural-language text from a given graph, in the presence of noisy reference\ntext. Our framework incorporates two core ideas: Firstly, we utilize\ncontrastive learning to enhance the model's ability to differentiate between\nfaithful and hallucinated information in the text, thereby encouraging the\ndecoder to generate text that aligns with the input graph. Secondly, we empower\nthe decoder to control the level of hallucination in the generated text by\nemploying a controllable text generation technique. We evaluate our model's\nperformance through the standard quantitative metrics as well as a\nChatGPT-based quantitative and qualitative analysis. Our evaluation\ndemonstrates the superior performance of our model over state-of-the-art\nKG-to-text models on faithfulness.",
            "author": [
                "Tahsina Hashem",
                "Weiqing Wang",
                "Derry Tanti Wijaya",
                "Mohammed Eunus Ali",
                "Yuan-Fang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06488v1",
                "http://arxiv.org/pdf/2308.06488v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06484v1",
            "title": "A parallel algorithm for Delaunay triangulation of moving points on the\n  plane",
            "updated": "2023-08-12T06:48:07Z",
            "published": "2023-08-12T06:48:07Z",
            "summary": "Delaunay Triangulation(DT) is one of the important geometric problems that is\nused in various branches of knowledge such as computer vision, terrain\nmodeling, spatial clustering and networking. Kinetic data structures have\nbecome very important in computational geometry for dealing with moving\nobjects. However, when dealing with moving points, maintaining a dynamically\nchanging Delaunay triangulation can be challenging. So, In this case, we have\nto update triangulation repeatedly. If points move so far, it is better to\nrebuild the triangulation. One approach to handle moving points is to use an\nincremental algorithm. For the case that points move slowly, we can give a\nfaster algorithm than rebuilding it. Furthermore, sequential algorithms can be\ncomputationally expensive for large datasets. So, one way to compute as fast as\npossible is parallelism. In this paper, we propose a parallel algorithm for\nmoving points. we propose an algorithm that divides datasets into equal\npartitions and give every partition to one block. Each block satisfay the\nDelaunay constraints after each time step and uses delete and insert algorithms\nto do this. We show this algorithm works faster than serial algorithms.",
            "author": [
                "Nazanin Hadiniya",
                "Mohammad Ghodsi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06484v1",
                "http://arxiv.org/pdf/2308.06484v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06480v1",
            "title": "Context-aware Event Forecasting via Graph Disentanglement",
            "updated": "2023-08-12T06:23:41Z",
            "published": "2023-08-12T06:23:41Z",
            "summary": "Event forecasting has been a demanding and challenging task throughout the\nentire human history. It plays a pivotal role in crisis alarming and disaster\nprevention in various aspects of the whole society. The task of event\nforecasting aims to model the relational and temporal patterns based on\nhistorical events and makes forecasting to what will happen in the future. Most\nexisting studies on event forecasting formulate it as a problem of link\nprediction on temporal event graphs. However, such pure structured formulation\nsuffers from two main limitations: 1) most events fall into general and\nhigh-level types in the event ontology, and therefore they tend to be\ncoarse-grained and offers little utility which inevitably harms the forecasting\naccuracy; and 2) the events defined by a fixed ontology are unable to retain\nthe out-of-ontology contextual information. To address these limitations, we\npropose a novel task of context-aware event forecasting which incorporates\nauxiliary contextual information. First, the categorical context provides\nsupplementary fine-grained information to the coarse-grained events. Second and\nmore importantly, the context provides additional information towards specific\nsituation and condition, which is crucial or even determinant to what will\nhappen next. However, it is challenging to properly integrate context into the\nevent forecasting framework, considering the complex patterns in the\nmulti-context scenario. Towards this end, we design a novel framework named\nSeparation and Collaboration Graph Disentanglement (short as SeCoGD) for\ncontext-aware event forecasting. Since there is no available dataset for this\nnovel task, we construct three large-scale datasets based on GDELT.\nExperimental results demonstrate that our model outperforms a list of SOTA\nmethods.",
            "author": [
                "Yunshan Ma",
                "Chenchen Ye",
                "Zijian Wu",
                "Xiang Wang",
                "Yixin Cao",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3580305.3599285",
                "http://arxiv.org/abs/2308.06480v1",
                "http://arxiv.org/pdf/2308.06480v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06479v1",
            "title": "mmHawkeye: Passive UAV Detection with a COTS mmWave Radar",
            "updated": "2023-08-12T06:14:15Z",
            "published": "2023-08-12T06:14:15Z",
            "summary": "Small Unmanned Aerial Vehicles (UAVs) are becoming potential threats to\nsecurity-sensitive areas and personal privacy. A UAV can shoot photos at\nheight, but how to detect such an uninvited intruder is an open problem. This\npaper presents mmHawkeye, a passive approach for UAV detection with a COTS\nmillimeter wave (mmWave) radar. mmHawkeye doesn't require prior knowledge of\nthe type, motions, and flight trajectory of the UAV, while exploiting the\nsignal feature induced by the UAV's periodic micro-motion (PMM) for long-range\naccurate detection. The design is therefore effective in dealing with low-SNR\nand uncertain reflected signals from the UAV. mmHawkeye can further track the\nUAV's position with dynamic programming and particle filtering, and identify it\nwith a Long Short-Term Memory (LSTM) based detector. We implement mmHawkeye on\na commercial mmWave radar and evaluate its performance under varied settings.\nThe experimental results show that mmHawkeye has a detection accuracy of 95.8%\nand can realize detection at a range up to 80m.",
            "author": [
                "Jia Zhang",
                "Xin Na",
                "Rui Xi",
                "Yimiao Sun",
                "Yuan He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06479v1",
                "http://arxiv.org/pdf/2308.06479v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP",
                "C.2; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07340v1",
            "title": "Quantum secure non-malleable randomness encoder and its applications",
            "updated": "2023-08-12T05:23:44Z",
            "published": "2023-08-12T05:23:44Z",
            "summary": "\"Non-Malleable Randomness Encoder\"(NMRE) was introduced by Kanukurthi,\nObbattu, and Sekar~[KOS18] as a useful cryptographic primitive helpful in the\nconstruction of non-malleable codes. To the best of our knowledge, their\nconstruction is not known to be quantum secure.\n  We provide a construction of a first rate-$1/2$, $2$-split, quantum secure\nNMRE and use this in a black-box manner, to construct for the first time the\nfollowing:\n  1) rate $1/11$, $3$-split, quantum non-malleable code,\n  2) rate $1/3$, $3$-split, quantum secure non-malleable code,\n  3) rate $1/5$, $2$-split, average case quantum secure non-malleable code.",
            "author": [
                "Rishabh Batra",
                "Naresh Goud Boddu",
                "Rahul Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07340v1",
                "http://arxiv.org/pdf/2308.07340v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06465v1",
            "title": "California Exodus? A Network Model of Population Redistribution in the\n  United States",
            "updated": "2023-08-12T04:53:00Z",
            "published": "2023-08-12T04:53:00Z",
            "summary": "Motivated by debates about California's net migration loss, we employ valued\nexponential-family random graph models to analyze the inter-county migration\nflow networks in the United States. We introduce a protocol that visualizes the\ncomplex effects of potential underlying mechanisms, and perform in silico\nknockout experiments to quantify their contribution to the California Exodus.\nWe find that racial dynamics contribute to the California Exodus, urbanization\nameliorates it, and political climate and housing costs have little impact.\nMoreover, the severity of the California Exodus depends on how one measures it,\nand California is not the state with the most substantial population loss. The\npaper demonstrates how generative statistical models can provide mechanistic\ninsights beyond simple hypothesis-testing.",
            "author": [
                "Peng Huang",
                "Carter T. Butts"
            ],
            "link": [
                "http://dx.doi.org/10.1080/0022250X.2023.2284431",
                "http://arxiv.org/abs/2308.06465v1",
                "http://arxiv.org/pdf/2308.06465v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06461v1",
            "title": "A note on the singularity probability of random directed $d$-regular\n  graphs",
            "updated": "2023-08-12T03:57:28Z",
            "published": "2023-08-12T03:57:28Z",
            "summary": "In this note we show that the singular probability of the adjacency matrix of\na random $d$-regular graph on $n$ vertices, where $d$ is fixed and $n \\to\n\\infty$, is bounded by $n^{-1/3+o(1)}$. This improves a recent bound by Huang.\nOur method is based on the study of the singularity problem modulo a prime\ntogether with an inverse-type result on the decay of the characteristic\nfunction. The latter is related to the inverse Kneser's problem in\ncombinatorics.",
            "author": [
                "Hoi H. Nguyen",
                "Amanda Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06461v1",
                "http://arxiv.org/pdf/2308.06461v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06453v1",
            "title": "Multi-Label Knowledge Distillation",
            "updated": "2023-08-12T03:19:08Z",
            "published": "2023-08-12T03:19:08Z",
            "summary": "Existing knowledge distillation methods typically work by imparting the\nknowledge of output logits or intermediate feature maps from the teacher\nnetwork to the student network, which is very successful in multi-class\nsingle-label learning. However, these methods can hardly be extended to the\nmulti-label learning scenario, where each instance is associated with multiple\nsemantic labels, because the prediction probabilities do not sum to one and\nfeature maps of the whole example may ignore minor classes in such a scenario.\nIn this paper, we propose a novel multi-label knowledge distillation method. On\none hand, it exploits the informative semantic knowledge from the logits by\ndividing the multi-label learning problem into a set of binary classification\nproblems; on the other hand, it enhances the distinctiveness of the learned\nfeature representations by leveraging the structural information of label-wise\nembeddings. Experimental results on multiple benchmark datasets validate that\nthe proposed method can avoid knowledge counteraction among labels, thus\nachieving superior performance against diverse comparing methods. Our code is\navailable at: https://github.com/penghui-yang/L2D",
            "author": [
                "Penghui Yang",
                "Ming-Kun Xie",
                "Chen-Chen Zong",
                "Lei Feng",
                "Gang Niu",
                "Masashi Sugiyama",
                "Sheng-Jun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06453v1",
                "http://arxiv.org/pdf/2308.06453v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06448v1",
            "title": "Latent Random Steps as Relaxations of Max-Cut, Min-Cut, and More",
            "updated": "2023-08-12T02:47:57Z",
            "published": "2023-08-12T02:47:57Z",
            "summary": "Algorithms for node clustering typically focus on finding homophilous\nstructure in graphs. That is, they find sets of similar nodes with many edges\nwithin, rather than across, the clusters. However, graphs often also exhibit\nheterophilous structure, as exemplified by (nearly) bipartite and tripartite\ngraphs, where most edges occur across the clusters. Grappling with such\nstructure is typically left to the task of graph simplification. We present a\nprobabilistic model based on non-negative matrix factorization which unifies\nclustering and simplification, and provides a framework for modeling arbitrary\ngraph structure. Our model is based on factorizing the process of taking a\nrandom walk on the graph. It permits an unconstrained parametrization, allowing\nfor optimization via simple gradient descent. By relaxing the hard clustering\nto a soft clustering, our algorithm relaxes potentially hard clustering\nproblems to a tractable ones. We illustrate our algorithm's capabilities on a\nsynthetic graph, as well as simple unsupervised learning tasks involving\nbipartite and tripartite clustering of orthographic and phonological data.",
            "author": [
                "Sudhanshu Chanpuriya",
                "Cameron Musco"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06448v1",
                "http://arxiv.org/pdf/2308.06448v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06446v1",
            "title": "The S-rule and 1-d representation for the traversal of a planar graph in\n  AEC industry",
            "updated": "2023-08-12T02:45:00Z",
            "published": "2023-08-12T02:45:00Z",
            "summary": "Based on two trivial observations of the AEC industry, this paper proposes a\ntraversal method (\"S-rule\") and expression (\"1-dimensional-graph\") transformed\nfrom DFS. This traversal method conforms to the original cognitive logic of the\nAEC industry, and the 1-d expression has clear language characteristics while\ncompletely retaining the topological relationship of the planar graph : a\nsequence of finite symbols (vocabularies) under definite rules. Moreover, the\nlanguage can be restored to a standard 2-d form that is isomorphic to the\noriginal planar graph, thus ensuring its visualization characteristics.\nFragments of the 1-d language can be used as planar units for free combination\nand weighting, and as the data foundation to support advanced calculations\nincluding FEM and isomorphic matching. And after the 2-d graph is reduced to\n1-d, any 3-d or higher-dimensional graphs can also be reduced to 1 or 2\ndimensions. The first half of this paper (Chapter 1) takes the 4X4 standard\ngrid as an example to introduce the prototype of S-rule and 1-d expression, and\ngives the mapping rule from 1-d expression to its editable text form. In the\nsecond half of this paper, the rule and expression are gradually extended to\nnon-embedded planar graphs (Chapter 2) and embedded planar graphs (Chapter 3),\nand the \"grammar\" is finally summarized (Chapter 4).",
            "author": [
                "Luxin Luo",
                "Sida Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06446v1",
                "http://arxiv.org/pdf/2308.06446v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06444v3",
            "title": "TongueSAM: An Universal Tongue Segmentation Model Based on SAM with\n  Zero-Shot",
            "updated": "2023-12-06T02:11:15Z",
            "published": "2023-08-12T02:38:43Z",
            "summary": "Tongue segmentation serves as the primary step in automated TCM tongue\ndiagnosis, which plays a significant role in the diagnostic results. Currently,\nnumerous deep learning based methods have achieved promising results. However,\nwhen confronted with tongue images that differ from the training set or possess\nchallenging backgrounds, these methods demonstrate limited performance. To\naddress this issue, this paper proposes a universal tongue segmentation model\nnamed TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale\npretrained interactive segmentation model known for its powerful zero-shot\ngeneralization capability. Applying SAM to tongue segmentation leverages its\nlearned prior knowledge from natural images, enabling the achievement of\nzero-shot segmentation for various types of tongue images. In this study, a\nPrompt Generator based on object detection is integrated into SAM to enable an\nend-to-end automated tongue segmentation method. Experiments demonstrate that\nTongueSAM achieves exceptional performance across various of tongue\nsegmentation datasets, particularly under zero-shot. Even when dealing with\nchallenging background tongue images, TongueSAM achieves a mIoU of 95.23\\%\nunder zero-shot conditions, surpassing other segmentation methods. As far as we\nknow, this is the first application of large-scale pretrained model for tongue\nsegmentation. The project mentioned in this paper is currently publicly\navailable.",
            "author": [
                "Shan Cao",
                "Qunsheng Ruan",
                "Linjian Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06444v3",
                "http://arxiv.org/pdf/2308.06444v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06441v1",
            "title": "Calliope-Net: Automatic Generation of Graph Data Facts via Annotated\n  Node-link Diagrams",
            "updated": "2023-08-12T02:32:15Z",
            "published": "2023-08-12T02:32:15Z",
            "summary": "Graph or network data are widely studied in both data mining and\nvisualization communities to review the relationship among different entities\nand groups. The data facts derived from graph visual analysis are important to\nhelp understand the social structures of complex data, especially for data\njournalism. However, it is challenging for data journalists to discover graph\ndata facts and manually organize correlated facts around a meaningful topic due\nto the complexity of graph data and the difficulty to interpret graph\nnarratives. Therefore, we present an automatic graph facts generation system,\nCalliope-Net, which consists of a fact discovery module, a fact organization\nmodule, and a visualization module. It creates annotated node-link diagrams\nwith facts automatically discovered and organized from network data. A novel\nlayout algorithm is designed to present meaningful and visually appealing\nannotated graphs. We evaluate the proposed system with two case studies and an\nin-lab user study. The results show that Calliope-Net can benefit users in\ndiscovering and understanding graph data facts with visually pleasing annotated\nvisualizations.",
            "author": [
                "Qing Chen",
                "Nan Chen",
                "Wei Shuai",
                "Guande Wu",
                "Zhe Xu",
                "Hanghang Tong",
                "Nan Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06441v1",
                "http://arxiv.org/pdf/2308.06441v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.16698v1",
            "title": "Autonomous Guidance Navigation and Control of the VISORS\n  Formation-Flying Mission",
            "updated": "2023-08-12T01:44:44Z",
            "published": "2023-08-12T01:44:44Z",
            "summary": "Virtual Super-resolution Optics with Reconfigurable Swarms (VISORS) is a\ndistributed telescope mission for high-resolution imaging of the Sun using two\n6U CubeSats flying in formation in a Sun-synchronous low-Earth orbit. An optics\nspacecraft carries a photon sieve acting as a high-resolution lens in the\nextreme ultraviolet spectrum, while the image passing through the sieve is\nfocused on a detector spacecraft. This paper presents the newly conceived\ndesign of the on-board guidance, navigation and control (GNC) system, which is\nhighly autonomous, robust, passively safe, and validated under realistic\nmission simulations. The primary objective of the GNC system is to establish a\npassively safe and high-precision formation alignment at 40-meter separation,\nwith sub-centimeter relative navigation and position control accuracy, over\nrepeated observations of 10-second duration. Science mission success rates are\nassessed via Monte-Carlo analyses under realistically modelled uncertainties\nstemming from sensing errors, maneuver errors, unmodelled dynamics, and\nerroneous knowledge of internal spacecraft components. Precise real-time\nrelative navigation is achieved by carrier phase differential GPS with integer\nambiguity resolution. Precise control over short baselines is achieved via\nclosed-loop optimization-based stochastic model predictive control with\ncentimeter-level accuracy. Control at far range and during approach is achieved\nby closed-form impulsive control with meter-level accuracy. Passive safety is\nenforced throughout the mission to mitigate collision risks even under critical\nsubsystem failure. Beyond VISORS, this work also realizes the crucial insight\nthat the described GNC architecture is generalizable to other distributed space\nmissions where accuracy and fault-tolerant safety are key requirements, such as\nrendezvous, proximity operations, and swarming missions.",
            "author": [
                "Tommaso Guffanti",
                "Toby Bell",
                "Samuel Y. W. Low",
                "Mason Murray-Cooper",
                "Simone D'Amico"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16698v1",
                "http://arxiv.org/pdf/2309.16698v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06432v1",
            "title": "Learn Single-horizon Disease Evolution for Predictive Generation of\n  Post-therapeutic Neovascular Age-related Macular Degeneration",
            "updated": "2023-08-12T01:40:23Z",
            "published": "2023-08-12T01:40:23Z",
            "summary": "Most of the existing disease prediction methods in the field of medical image\nprocessing fall into two classes, namely image-to-category predictions and\nimage-to-parameter predictions. Few works have focused on image-to-image\npredictions. Different from multi-horizon predictions in other fields,\nophthalmologists prefer to show more confidence in single-horizon predictions\ndue to the low tolerance of predictive risk. We propose a single-horizon\ndisease evolution network (SHENet) to predictively generate post-therapeutic\nSD-OCT images by inputting pre-therapeutic SD-OCT images with neovascular\nage-related macular degeneration (nAMD). In SHENet, a feature encoder converts\nthe input SD-OCT images to deep features, then a graph evolution module\npredicts the process of disease evolution in high-dimensional latent space and\noutputs the predicted deep features, and lastly, feature decoder recovers the\npredicted deep features to SD-OCT images. We further propose an evolution\nreinforcement module to ensure the effectiveness of disease evolution learning\nand obtain realistic SD-OCT images by adversarial training. SHENet is validated\non 383 SD-OCT cubes of 22 nAMD patients based on three well-designed schemes\nbased on the quantitative and qualitative evaluations. Compared with other\ngenerative methods, the generative SD-OCT images of SHENet have the highest\nimage quality. Besides, SHENet achieves the best structure protection and\ncontent prediction. Qualitative evaluations also demonstrate that SHENet has a\nbetter visual effect than other methods. SHENet can generate post-therapeutic\nSD-OCT images with both high prediction performance and good image quality,\nwhich has great potential to help ophthalmologists forecast the therapeutic\neffect of nAMD.",
            "author": [
                "Yuhan Zhang",
                "Kun Huang",
                "Mingchao Li",
                "Songtao Yuan",
                "Qiang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06432v1",
                "http://arxiv.org/pdf/2308.06432v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06412v1",
            "title": "Improving Pseudo Labels for Open-Vocabulary Object Detection",
            "updated": "2023-08-11T23:03:50Z",
            "published": "2023-08-11T23:03:50Z",
            "summary": "Recent studies show promising performance in open-vocabulary object detection\n(OVD) using pseudo labels (PLs) from pretrained vision and language models\n(VLMs). However, PLs generated by VLMs are extremely noisy due to the gap\nbetween the pretraining objective of VLMs and OVD, which blocks further\nadvances on PLs. In this paper, we aim to reduce the noise in PLs and propose a\nmethod called online Self-training And a Split-and-fusion head for OVD\n(SAS-Det). First, the self-training finetunes VLMs to generate high quality PLs\nwhile prevents forgetting the knowledge learned in the pretraining. Second, a\nsplit-and-fusion (SAF) head is designed to remove the noise in localization of\nPLs, which is usually ignored in existing methods. It also fuses complementary\nknowledge learned from both precise ground truth and noisy pseudo labels to\nboost the performance. Extensive experiments demonstrate SAS-Det is both\nefficient and effective. Our pseudo labeling is 3 times faster than prior\nmethods. SAS-Det outperforms prior state-of-the-art models of the same scale by\na clear margin and achieves 37.4 AP$_{50}$ and 27.3 AP$_r$ on novel categories\nof the COCO and LVIS benchmarks, respectively.",
            "author": [
                "Shiyu Zhao",
                "Samuel Schulter",
                "Long Zhao",
                "Zhixing Zhang",
                "Vijay Kumar B. G",
                "Yumin Suh",
                "Manmohan Chandraker",
                "Dimitris N. Metaxas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06412v1",
                "http://arxiv.org/pdf/2308.06412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06411v1",
            "title": "Dialogue Possibilities between a Human Supervisor and UAM Air Traffic\n  Management: Route Alteration",
            "updated": "2023-08-11T23:01:59Z",
            "published": "2023-08-11T23:01:59Z",
            "summary": "This paper introduces a novel approach to detour management in Urban Air\nTraffic Management (UATM) using knowledge representation and reasoning. It aims\nto understand the complexities and requirements of UAM detours, enabling a\nmethod that quickly identifies safe and efficient routes in a carefully sampled\nenvironment. This method implemented in Answer Set Programming uses\nnon-monotonic reasoning and a two-phase conversation between a human manager\nand the UATM system, considering factors like safety and potential impacts. The\nrobustness and efficacy of the proposed method were validated through several\nqueries from two simulation scenarios, contributing to the symbiosis of human\nknowledge and advanced AI techniques. The paper provides an introduction,\nciting relevant studies, problem formulation, solution, discussions, and\nconcluding comments.",
            "author": [
                "Jeongseok Kim",
                "Kangjin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06411v1",
                "http://arxiv.org/pdf/2308.06411v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06403v1",
            "title": "Taboo and Collaborative Knowledge Production: Evidence from Wikipedia",
            "updated": "2023-08-11T21:58:23Z",
            "published": "2023-08-11T21:58:23Z",
            "summary": "By definition, people are reticent or even unwilling to talk about taboo\nsubjects. Because subjects like sexuality, health, and violence are taboo in\nmost cultures, important information on each of these subjects can be difficult\nto obtain. Are peer produced knowledge bases like Wikipedia a promising\napproach for providing people with information on taboo subjects? With its\nreliance on volunteers who might also be averse to taboo, can the peer\nproduction model produce high-quality information on taboo subjects? In this\npaper, we seek to understand the role of taboo in knowledge bases produced by\nvolunteers. We do so by developing a novel computational approach to identify\ntaboo subjects and by using this method to identify a set of articles on taboo\nsubjects in English Wikipedia. We find that articles on taboo subjects are more\npopular than non-taboo articles and that they are frequently vandalized.\nDespite frequent vandalism attacks, we also find that taboo articles are higher\nquality than non-taboo articles. We hypothesize that stigmatizing societal\nattitudes will lead contributors to taboo subjects to seek to be less\nidentifiable. Although our results are consistent with this proposal in several\nways, we surprisingly find that contributors make themselves more identifiable\nin others.",
            "author": [
                "Kaylea Champion",
                "Benjamin Mako Hill"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610090",
                "http://arxiv.org/abs/2308.06403v1",
                "http://arxiv.org/pdf/2308.06403v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06399v3",
            "title": "Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via\n  Mixed-Effect Models and Hierarchical Clustering",
            "updated": "2023-10-25T07:16:23Z",
            "published": "2023-08-11T21:46:45Z",
            "summary": "Maize is a major crop providing vital calories in sub-Saharan Africa, Asia\nand Latin America, with a global cultivation area of 197 million hectares in\n2021. Therefore, many statistical models (such as mixed-effect and random\ncoefficients models) and machine learning models (such as random forests and\ndeep learning architectures) have been developed to predict maize yield and how\nit is affected by genotype, environment and genotype-environment interaction\nfactors, including field management. However, these models do not fully\nleverage the network of causal relationships between these factors and the\nhierarchical structure of the agronomic data arising from data collection.\n  Bayesian networks (BNs) provide a powerful framework for modelling causal and\nprobabilistic relationships using directed acyclic graphs to illustrate the\nconnections between variables. This study introduces a novel approach that\nintegrates random effects into BN learning. Rooted in the linear mixed-effects\nmodels framework, it is particularly well-suited to hierarchical data. Results\nfrom a real-world agronomic trial suggest that the proposed approach enhances\nBN learning, leading to a more interpretable model and discovering new causal\nconnections. At the same time, the error rate of maize yield prediction is\nreduced from 28% to 17%. Therefore, we argue that BNs should be the tool of\nchoice to construct practical decision support tools for hierarchical agronomic\ndata that allow for causal inference.",
            "author": [
                "Lorenzo Valleggi",
                "Marco Scutari",
                "Federico Mattia Stefanini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06399v3",
                "http://arxiv.org/pdf/2308.06399v3"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06374v1",
            "title": "Large Language Models and Knowledge Graphs: Opportunities and Challenges",
            "updated": "2023-08-11T20:16:57Z",
            "published": "2023-08-11T20:16:57Z",
            "summary": "Large Language Models (LLMs) have taken Knowledge Representation -- and the\nworld -- by storm. This inflection point marks a shift from explicit knowledge\nrepresentation to a renewed focus on the hybrid representation of both explicit\nknowledge and parametric knowledge. In this position paper, we will discuss\nsome of the common debate points within the community on LLMs (parametric\nknowledge) and Knowledge Graphs (explicit knowledge) and speculate on\nopportunities and visions that the renewed focus brings, as well as related\nresearch topics and challenges.",
            "author": [
                "Jeff Z. Pan",
                "Simon Razniewski",
                "Jan-Christoph Kalo",
                "Sneha Singhania",
                "Jiaoyan Chen",
                "Stefan Dietze",
                "Hajira Jabeen",
                "Janna Omeliyanenko",
                "Wen Zhang",
                "Matteo Lissandrini",
                "Russa Biswas",
                "Gerard de Melo",
                "Angela Bonifati",
                "Edlira Vakaj",
                "Mauro Dragoni",
                "Damien Graux"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06374v1",
                "http://arxiv.org/pdf/2308.06374v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06362v2",
            "title": "Exotic eigenvalues and analytic resolvent for a graph with a shrinking\n  edge",
            "updated": "2023-09-29T21:27:33Z",
            "published": "2023-08-11T19:51:08Z",
            "summary": "We consider a metric graph consisting of two edges, one of which has length\n$\\varepsilon$ which we send to zero. On this graph we study the resolvent and\nspectrum of the Laplacian subject to a general vertex condition at the\nconnecting vertex. Despite the singular nature of the perturbation (by a short\nedge), we find that the resolvent depends analytically on the parameter\n$\\varepsilon$. In contrast, the negative eigenvalues escape to minus infinity\nat rates that could be fractional, namely, $\\varepsilon^0$,\n$\\varepsilon^{-2/3}$ or $\\varepsilon^{-1}$. These rates take place when the\ncorresponding eigenfunction localizes, respectively, only on the long edge, on\nboth edges, or only on the short edge.",
            "author": [
                "Gregory Berkolaiko",
                "Denis I. Borisov",
                "Marshall King"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s13324-023-00853-3",
                "http://arxiv.org/abs/2308.06362v2",
                "http://arxiv.org/pdf/2308.06362v2"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math-ph",
                "math.MP",
                "34B45, 34L15, 47A10, 81Q10, 81Q35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06358v1",
            "title": "CA2: Cyber Attacks Analytics",
            "updated": "2023-08-11T19:27:45Z",
            "published": "2023-08-11T19:27:45Z",
            "summary": "The VAST Challenge 2020 Mini-Challenge 1 requires participants to identify\nthe responsible white hat groups behind a fictional Internet outage. To address\nthis task, we have created a visual analytics system named CA2: Cyber Attacks\nAnalytics. This system is designed to efficiently compare and match subgraphs\nwithin an extensive graph containing anonymized profiles. Additionally, we\nshowcase an iterative workflow that utilizes our system's capabilities to\npinpoint the responsible group.",
            "author": [
                "Luyu Cheng",
                "Bairui Su",
                "Yumeng Xue",
                "Xiaoyu Liu",
                "Yunhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06358v1",
                "http://arxiv.org/pdf/2308.06358v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06262v1",
            "title": "Foundation Model is Efficient Multimodal Multitask Model Selector",
            "updated": "2023-08-11T17:54:44Z",
            "published": "2023-08-11T17:54:44Z",
            "summary": "This paper investigates an under-explored but important problem: given a\ncollection of pre-trained neural networks, predicting their performance on each\nmulti-modal task without fine-tuning them, such as image recognition,\nreferring, captioning, visual question answering, and text question answering.\nA brute-force approach is to finetune all models on all target datasets,\nbringing high computational costs. Although recent-advanced approaches employed\nlightweight metrics to measure models' transferability,they often depend\nheavily on the prior knowledge of a single task, making them inapplicable in a\nmulti-modal multi-task scenario. To tackle this issue, we propose an efficient\nmulti-task model selector (EMMS), which employs large-scale foundation models\nto transform diverse label formats such as categories, texts, and bounding\nboxes of different downstream tasks into a unified noisy label embedding. EMMS\ncan estimate a model's transferability through a simple weighted linear\nregression, which can be efficiently solved by an alternating minimization\nalgorithm with a convergence guarantee. Extensive experiments on 5 downstream\ntasks with 24 datasets show that EMMS is fast, effective, and generic enough to\nassess the transferability of pre-trained models, making it the first model\nselection method in the multi-task scenario. For instance, compared with the\nstate-of-the-art method LogME enhanced by our label embeddings, EMMS achieves\n9.0\\%, 26.3\\%, 20.1\\%, 54.8\\%, 12.2\\% performance gain on image recognition,\nreferring, captioning, visual question answering, and text question answering,\nwhile bringing 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock\ntime, respectively. The code is available at\nhttps://github.com/OpenGVLab/Multitask-Model-Selector.",
            "author": [
                "Fanqing Meng",
                "Wenqi Shao",
                "Zhanglin Peng",
                "Chonghe Jiang",
                "Kaipeng Zhang",
                "Yu Qiao",
                "Ping Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06262v1",
                "http://arxiv.org/pdf/2308.06262v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06261v1",
            "title": "Enhancing Network Management Using Code Generated by Large Language\n  Models",
            "updated": "2023-08-11T17:49:15Z",
            "published": "2023-08-11T17:49:15Z",
            "summary": "Analyzing network topologies and communication graphs plays a crucial role in\ncontemporary network management. However, the absence of a cohesive approach\nleads to a challenging learning curve, heightened errors, and inefficiencies.\nIn this paper, we introduce a novel approach to facilitate a\nnatural-language-based network management experience, utilizing large language\nmodels (LLMs) to generate task-specific code from natural language queries.\nThis method tackles the challenges of explainability, scalability, and privacy\nby allowing network operators to inspect the generated code, eliminating the\nneed to share network data with LLMs, and concentrating on application-specific\nrequests combined with general program synthesis techniques. We design and\nevaluate a prototype system using benchmark applications, showcasing high\naccuracy, cost-effectiveness, and the potential for further enhancements using\ncomplementary program synthesis techniques.",
            "author": [
                "Sathiya Kumaran Mani",
                "Yajie Zhou",
                "Kevin Hsieh",
                "Santiago Segarra",
                "Ranveer Chandra",
                "Srikanth Kandula"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06261v1",
                "http://arxiv.org/pdf/2308.06261v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06242v1",
            "title": "Tropicalizing the Graph Profile of Some Almost-Stars",
            "updated": "2023-08-11T17:19:16Z",
            "published": "2023-08-11T17:19:16Z",
            "summary": "Many important problems in extremal combinatorics can be stated as certifying\npolynomial inequalities in graph homomorphism numbers, and in particular, many\nask to certify pure binomial inequalities. For a fixed collection of graphs\n$\\mathcal{U}$, the tropicalization of the graph profile of $\\mathcal{U}$\nessentially records all valid pure binomial inequalities involving graph\nhomomorphism numbers for graphs in $\\mathcal{U}$. Building upon ideas and\ntechniques described by Blekherman and Raymond in 2022, we compute the\ntropicalization of the graph profile for $K_1$ and $S_{2,1^k}$-trees,\nalmost-star graphs with one branch containing two edges and $k$ branches\ncontaining one edge. This allows pure binomial inequalities in homomorphism\nnumbers (or densities) for these graphs to be verified through an explicit\nlinear program where the number of variables is equal to the number of edges in\nthe biggest $S_{2,1^k}$-tree involved.",
            "author": [
                "Maria Dasc\u0103lu",
                "Annie Raymond"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06242v1",
                "http://arxiv.org/pdf/2308.06242v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35, 90C35, 14T90"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06240v1",
            "title": "Superconducting nitridized-aluminum thin films",
            "updated": "2023-08-11T17:19:09Z",
            "published": "2023-08-11T17:19:09Z",
            "summary": "We report the direct observation of superconductivity in nitridized-aluminum\nthin films. The films are produced by sputtering deposition of aluminum in a\ncontrolled mixture of nitrogen diluted in argon. The concentration of applied\nnitrogen directly determines the properties of the superconducting thin films.\nWe observe samples displaying critical temperatures up to 3.38$\\pm$0.01 K and\nresilience to in-plane magnetic fields well above 1 T, with good\nreproducibility of the results. To our knowledge, this work represents the\nfirst unambiguous demonstration of tunable superconductivity in aluminum-based\nnitridized thin films. Our results put forward nitridized aluminum as a\npromising material to be employed in superconducting quantum circuits for\nquantum technology applications.",
            "author": [
                "Alba Torras-Coloma",
                "Leyre Mart\u00ednez de Olcoz",
                "Eva C\u00e9spedes",
                "Elia Bertoldo",
                "David L\u00f3pez-N\u00fa\u00f1ez",
                "Sagar Paul",
                "Wolfgang Wernsdorfer",
                "Gemma Rius",
                "Pol Forn-D\u00edaz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06240v1",
                "http://arxiv.org/pdf/2308.06240v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06235v1",
            "title": "KETM:A Knowledge-Enhanced Text Matching method",
            "updated": "2023-08-11T17:08:14Z",
            "published": "2023-08-11T17:08:14Z",
            "summary": "Text matching is the task of matching two texts and determining the\nrelationship between them, which has extensive applications in natural language\nprocessing tasks such as reading comprehension, and Question-Answering systems.\nThe mainstream approach is to compute text representations or to interact with\nthe text through attention mechanism, which is effective in text matching\ntasks. However, the performance of these models is insufficient for texts that\nrequire commonsense knowledge-based reasoning. To this end, in this paper, We\nintroduce a new model for text matching called the Knowledge Enhanced Text\nMatching model (KETM), to enrich contextual representations with real-world\ncommon-sense knowledge from external knowledge sources to enhance our model\nunderstanding and reasoning. First, we use Wiktionary to retrieve the text word\ndefinitions as our external knowledge. Secondly, we feed text and knowledge to\nthe text matching module to extract their feature vectors. The text matching\nmodule is used as an interaction module by integrating the encoder layer, the\nco-attention layer, and the aggregation layer. Specifically, the interaction\nprocess is iterated several times to obtain in-depth interaction information\nand extract the feature vectors of text and knowledge by multi-angle pooling.\nThen, we fuse text and knowledge using a gating mechanism to learn the ratio of\ntext and knowledge fusion by a neural network that prevents noise generated by\nknowledge. After that, experimental validation on four datasets are carried\nout, and the experimental results show that our proposed model performs well on\nall four datasets, and the performance of our method is improved compared to\nthe base model without adding external knowledge, which validates the\neffectiveness of our proposed method. The code is available at\nhttps://github.com/1094701018/KETM",
            "author": [
                "Kexin Jiang",
                "Yahui Zhao",
                "Guozhe Jin",
                "Zhenguo Zhang",
                "Rongyi Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06235v1",
                "http://arxiv.org/pdf/2308.06235v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06232v2",
            "title": "First-order Sobolev spaces, self-similar energies and energy measures on\n  the Sierpi\u0144ski carpet",
            "updated": "2023-11-29T08:00:58Z",
            "published": "2023-08-11T17:03:19Z",
            "summary": "We construct and investigate $(1, p)$-Sobolev space, $p$-energy, and the\ncorresponding $p$-energy measures on the planar Sierpi\\'{n}ski carpet for all\n$p \\in (1, \\infty)$. Our method is based on the idea of Kusuoka and Zhou\n[Probab. Theory Related Fields $\\textbf{93}$ (1992), no. 2, 169--196], where\nBrownian motion (the case $p = 2$) on self-similar sets including the planar\nSierpi\\'{n}ski carpet were constructed. Similar to this earlier work, we use a\nsequence of discrete graph approximations and the corresponding discrete\n$p$-energies to define the Sobolev space and $p$-energies. However, we need a\nnew approach to ensure that our $(1, p)$-Sobolev space has a dense set of\ncontinuous functions when $p$ is less than the Ahlfors regular conformal\ndimension. The new ingredients are the use of Loewner type estimates on\ncombinatorial modulus to obtain Poincar\\'e inequality and elliptic Harnack\ninequality on a sequence of approximating graphs. An important feature of our\nSobolev space is the self-similarity of our $p$-energy, which allows us to\ndefine corresponding $p$-energy measures on the planar Sierpi\\'{n}ski carpet.\nWe show that our Sobolev space can also be viewed as a Korevaar-Schoen type\nspace. We apply our results to the attainment problem for Ahlfors regular\nconformal dimension of the Sierpi\\'{n}ski carpet. In particular, we show that\nif the Ahlfors regular conformal dimension, say $\\dim_{\\mathrm{ARC}}$, is\nattained, then any optimal measure which attains $\\dim_{\\mathrm{ARC}}$ should\nbe comparable with the $\\dim_{\\mathrm{ARC}}$-energy measure of some function in\nour $(1, \\dim_{\\mathrm{ARC}})$-Sobolev space up to a multiplicative constant.\nIn this case, we also prove that the Newton-Sobolev space corresponding to any\noptimal measure and metric can be identified as our self-similar $(1,\n\\dim_{\\mathrm{ARC}})$-Sobolev space.",
            "author": [
                "Mathav Murugan",
                "Ryosuke Shimizu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06232v2",
                "http://arxiv.org/pdf/2308.06232v2"
            ],
            "primary_category": "math.MG",
            "category": [
                "math.MG",
                "math.AP",
                "math.FA",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06230v2",
            "title": "Measurement of the Positive Muon Anomalous Magnetic Moment to 0.20 ppm",
            "updated": "2023-10-04T13:56:17Z",
            "published": "2023-08-11T17:00:27Z",
            "summary": "We present a new measurement of the positive muon magnetic anomaly, $a_\\mu\n\\equiv (g_\\mu - 2)/2$, from the Fermilab Muon $g\\!-\\!2$ Experiment using data\ncollected in 2019 and 2020. We have analyzed more than 4 times the number of\npositrons from muon decay than in our previous result from 2018 data. The\nsystematic error is reduced by more than a factor of 2 due to better running\nconditions, a more stable beam, and improved knowledge of the magnetic field\nweighted by the muon distribution, $\\tilde{\\omega}'^{}_p$, and of the anomalous\nprecession frequency corrected for beam dynamics effects, $\\omega_a$. From the\nratio $\\omega_a / \\tilde{\\omega}'^{}_p$, together with precisely determined\nexternal parameters, we determine $a_\\mu = 116\\,592\\,057(25) \\times 10^{-11}$\n(0.21 ppm). Combining this result with our previous result from the 2018 data,\nwe obtain $a_\\mu\\text{(FNAL)} = 116\\,592\\,055(24) \\times 10^{-11}$ (0.20 ppm).\nThe new experimental world average is $a_\\mu (\\text{Exp}) =\n116\\,592\\,059(22)\\times 10^{-11}$ (0.19 ppm), which represents a factor of 2\nimprovement in precision.",
            "author": [
                "D. P. Aguillard",
                "T. Albahri",
                "D. Allspach",
                "A. Anisenkov",
                "K. Badgley",
                "S. Bae\u00dfler",
                "I. Bailey",
                "L. Bailey",
                "V. A. Baranov",
                "E. Barlas-Yucel",
                "T. Barrett",
                "E. Barzi",
                "F. Bedeschi",
                "M. Berz",
                "M. Bhattacharya",
                "H. P. Binney",
                "P. Bloom",
                "J. Bono",
                "E. Bottalico",
                "T. Bowcock",
                "S. Braun",
                "M. Bressler",
                "G. Cantatore",
                "R. M. Carey",
                "B. C. K. Casey",
                "D. Cauz",
                "R. Chakraborty",
                "A. Chapelain",
                "S. Chappa",
                "S. Charity",
                "C. Chen",
                "M. Cheng",
                "R. Chislett",
                "Z. Chu",
                "T. E. Chupp",
                "C. Claessens",
                "M. E. Convery",
                "S. Corrodi",
                "L. Cotrozzi",
                "J. D. Crnkovic",
                "S. Dabagov",
                "P. T. Debevec",
                "S. Di Falco",
                "G. Di Sciascio",
                "B. Drendel",
                "A. Driutti",
                "V. N. Duginov",
                "M. Eads",
                "A. Edmonds",
                "J. Esquivel",
                "M. Farooq",
                "R. Fatemi",
                "C. Ferrari",
                "M. Fertl",
                "A. T. Fienberg",
                "A. Fioretti",
                "D. Flay",
                "S. B. Foster",
                "H. Friedsam",
                "N. S. Froemming",
                "C. Gabbanini",
                "I. Gaines",
                "M. D. Galati",
                "S. Ganguly",
                "A. Garcia",
                "J. George",
                "L. K. Gibbons",
                "A. Gioiosa",
                "K. L. Giovanetti",
                "P. Girotti",
                "W. Gohn",
                "L. Goodenough",
                "T. Gorringe",
                "J. Grange",
                "S. Grant",
                "F. Gray",
                "S. Haciomeroglu",
                "T. Halewood-Leagas",
                "D. Hampai",
                "F. Han",
                "J. Hempstead",
                "D. W. Hertzog",
                "G. Hesketh",
                "E. Hess",
                "A. Hibbert",
                "Z. Hodge",
                "K. W. Hong",
                "R. Hong",
                "T. Hu",
                "Y. Hu",
                "M. Iacovacci",
                "M. Incagli",
                "P. Kammel",
                "M. Kargiantoulakis",
                "M. Karuza",
                "J. Kaspar",
                "D. Kawall",
                "L. Kelton",
                "A. Keshavarzi",
                "D. S. Kessler",
                "K. S. Khaw",
                "Z. Khechadoorian",
                "N. V. Khomutov",
                "B. Kiburg",
                "M. Kiburg",
                "O. Kim",
                "N. Kinnaird",
                "E. Kraegeloh",
                "V. A. Krylov",
                "N. A. Kuchinskiy",
                "K. R. Labe",
                "J. LaBounty",
                "M. Lancaster",
                "S. Lee",
                "B. Li",
                "D. Li",
                "L. Li",
                "I. Logashenko",
                "A. Lorente Campos",
                "Z. Lu",
                "A. Luc\u00e0",
                "G. Lukicov",
                "A. Lusiani",
                "A. L. Lyon",
                "B. MacCoy",
                "R. Madrak",
                "K. Makino",
                "S. Mastroianni",
                "J. P. Miller",
                "S. Miozzi",
                "B. Mitra",
                "J. P. Morgan",
                "W. M. Morse",
                "J. Mott",
                "A. Nath",
                "J. K. Ng",
                "H. Nguyen",
                "Y. Oksuzian",
                "Z. Omarov",
                "R. Osofsky",
                "S. Park",
                "G. Pauletta",
                "G. M. Piacentino",
                "R. N. Pilato",
                "K. T. Pitts",
                "B. Plaster",
                "D. Po\u010dani\u0107",
                "N. Pohlman",
                "C. C. Polly",
                "J. Price",
                "B. Quinn",
                "M. U. H. Qureshi",
                "S. Ramachandran",
                "E. Ramberg",
                "R. Reimann",
                "B. L. Roberts",
                "D. L. Rubin",
                "L. Santi",
                "C. Schlesier",
                "A. Schreckenberger",
                "Y. K. Semertzidis",
                "D. Shemyakin",
                "M. Sorbara",
                "J. Stapleton",
                "D. Still",
                "D. St\u00f6ckinger",
                "C. Stoughton",
                "D. Stratakis",
                "H. E. Swanson",
                "G. Sweetmore",
                "D. A. Sweigart",
                "M. J. Syphers",
                "D. A. Tarazona",
                "T. Teubner",
                "A. E. Tewsley-Booth",
                "V. Tishchenko",
                "N. H. Tran",
                "W. Turner",
                "E. Valetov",
                "D. Vasilkova",
                "G. Venanzoni",
                "V. P. Volnykh",
                "T. Walton",
                "A. Weisskopf",
                "L. Welty-Rieger",
                "P. Winter",
                "Y. Wu",
                "B. Yu",
                "M. Yucel",
                "Y. Zeng",
                "C. Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevLett.131.161802",
                "http://arxiv.org/abs/2308.06230v2",
                "http://arxiv.org/pdf/2308.06230v2"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06220v2",
            "title": "Nonlinear Permuted Granger Causality",
            "updated": "2023-09-17T20:54:38Z",
            "published": "2023-08-11T16:44:16Z",
            "summary": "Granger causal inference is a contentious but widespread method used in\nfields ranging from economics to neuroscience. The original definition\naddresses the notion of causality in time series by establishing functional\ndependence conditional on a specified model. Adaptation of Granger causality to\nnonlinear data remains challenging, and many methods apply in-sample tests that\ndo not incorporate out-of-sample predictability, leading to concerns of model\noverfitting. To allow for out-of-sample comparison, a measure of functional\nconnectivity is explicitly defined using permutations of the covariate set.\nArtificial neural networks serve as featurizers of the data to approximate any\narbitrary, nonlinear relationship, and consistent estimation of the variance\nfor each permutation is shown under certain conditions on the featurization\nprocess and the model residuals. Performance of the permutation method is\ncompared to penalized variable selection, naive replacement, and omission\ntechniques via simulation, and it is applied to neuronal responses of acoustic\nstimuli in the auditory cortex of anesthetized rats. Targeted use of the\nGranger causal framework, when prior knowledge of the causal mechanisms in a\ndataset are limited, can help to reveal potential predictive relationships\nbetween sets of variables that warrant further study.",
            "author": [
                "Noah D. Gade",
                "Jordan Rodu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06220v2",
                "http://arxiv.org/pdf/2308.06220v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06218v2",
            "title": "Splittings of One-Ended Groups with One-Ended Halfspaces and\n  Non-1-Acyclicity at Infinity",
            "updated": "2023-10-13T19:45:50Z",
            "published": "2023-08-11T16:38:53Z",
            "summary": "We introduce the notion of halfspaces associated to a group splitting, and\ninvestigate the relationship between the coarse geometry of the halfspaces and\nthe coarse geometry of the group. Roughly speaking, the halfspaces of a group\nsplitting are subgraphs of the Cayley graph obtained by pulling back the\nhalfspaces of the Bass--Serre tree. Our first theorem shows that (under mild\nconditions) any splitting of a one-ended group can be upgraded to a splitting\nwith one-ended halfspaces. Our second theorem demonstrates that a one-ended\ngroup usually has a JSJ splitting with one-ended halfspaces. And our third\ntheorem states that if a one-ended finitely presented group $G$ admits a\nsplitting with one-ended halfspaces such that some edge stabilizer has more\nthan one end, then $H^2(G,\\mathbb ZG)\\ne \\{0\\}$; in particular $G$ is not\nsimply connected at infinity.",
            "author": [
                "Michael Mihalik",
                "Sam Shepherd"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06218v2",
                "http://arxiv.org/pdf/2308.06218v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "20F65 (Primary) 20F69, 20E08 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06217v1",
            "title": "Continual Face Forgery Detection via Historical Distribution Preserving",
            "updated": "2023-08-11T16:37:31Z",
            "published": "2023-08-11T16:37:31Z",
            "summary": "Face forgery techniques have advanced rapidly and pose serious security\nthreats. Existing face forgery detection methods try to learn generalizable\nfeatures, but they still fall short of practical application. Additionally,\nfinetuning these methods on historical training data is resource-intensive in\nterms of time and storage. In this paper, we focus on a novel and challenging\nproblem: Continual Face Forgery Detection (CFFD), which aims to efficiently\nlearn from new forgery attacks without forgetting previous ones. Specifically,\nwe propose a Historical Distribution Preserving (HDP) framework that reserves\nand preserves the distributions of historical faces. To achieve this, we use\nuniversal adversarial perturbation (UAP) to simulate historical forgery\ndistribution, and knowledge distillation to maintain the distribution variation\nof real faces across different models. We also construct a new benchmark for\nCFFD with three evaluation protocols. Our extensive experiments on the\nbenchmarks show that our method outperforms the state-of-the-art competitors.",
            "author": [
                "Ke Sun",
                "Shen Chen",
                "Taiping Yao",
                "Xiaoshuai Sun",
                "Shouhong Ding",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06217v1",
                "http://arxiv.org/pdf/2308.06217v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06207v1",
            "title": "Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning\n  to boost Foundation Modals",
            "updated": "2023-08-11T16:13:04Z",
            "published": "2023-08-11T16:13:04Z",
            "summary": "Reasoning ability is one of the most crucial capabilities of a foundation\nmodel, signifying its capacity to address complex reasoning tasks.\nChain-of-Thought (CoT) technique is widely regarded as one of the effective\nmethods for enhancing the reasoning ability of foundation models and has\ngarnered significant attention. However, the reasoning process of CoT is\nlinear, step-by-step, similar to personal logical reasoning, suitable for\nsolving general and slightly complicated problems. On the contrary, the\nthinking pattern of an expert owns two prominent characteristics that cannot be\nhandled appropriately in CoT, i.e., high-order multi-hop reasoning and\nmultimodal comparative judgement. Therefore, the core motivation of this paper\nis transcending CoT to construct a reasoning paradigm that can think like an\nexpert. The hyperedge of a hypergraph could connect various vertices, making it\nnaturally suitable for modelling high-order relationships. Inspired by this,\nthis paper innovatively proposes a multimodal Hypergraph-of-Thought (HoT)\nreasoning paradigm, which enables the foundation models to possess the\nexpert-level ability of high-order multi-hop reasoning and multimodal\ncomparative judgement. Specifically, a textual hypergraph-of-thought is\nconstructed utilizing triple as the primary thought to model higher-order\nrelationships, and a hyperedge-of-thought is generated through multi-hop\nwalking paths to achieve multi-hop inference. Furthermore, we devise a visual\nhypergraph-of-thought to interact with the textual hypergraph-of-thought via\nCross-modal Co-Attention Graph Learning for multimodal comparative\nverification. Experimentations on the ScienceQA benchmark demonstrate the\nproposed HoT-based T5 outperforms CoT-based GPT3.5 and chatGPT, which is on par\nwith CoT-based GPT4 with a lower model size.",
            "author": [
                "Fanglong Yao",
                "Changyuan Tian",
                "Jintao Liu",
                "Zequn Zhang",
                "Qing Liu",
                "Li Jin",
                "Shuchao Li",
                "Xiaoyu Li",
                "Xian Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06207v1",
                "http://arxiv.org/pdf/2308.06207v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06203v2",
            "title": "Towards a Causal Probabilistic Framework for Prediction,\n  Action-Selection & Explanations for Robot Block-Stacking Tasks",
            "updated": "2023-09-29T00:19:11Z",
            "published": "2023-08-11T15:58:15Z",
            "summary": "Uncertainties in the real world mean that is impossible for system designers\nto anticipate and explicitly design for all scenarios that a robot might\nencounter. Thus, robots designed like this are fragile and fail outside of\nhighly-controlled environments. Causal models provide a principled framework to\nencode formal knowledge of the causal relationships that govern the robot's\ninteraction with its environment, in addition to probabilistic representations\nof noise and uncertainty typically encountered by real-world robots. Combined\nwith causal inference, these models permit an autonomous agent to understand,\nreason about, and explain its environment. In this work, we focus on the\nproblem of a robot block-stacking task due to the fundamental perception and\nmanipulation capabilities it demonstrates, required by many applications\nincluding warehouse logistics and domestic human support robotics. We propose a\nnovel causal probabilistic framework to embed a physics simulation capability\ninto a structural causal model to permit robots to perceive and assess the\ncurrent state of a block-stacking task, reason about the next-best action from\nplacement candidates, and generate post-hoc counterfactual explanations. We\nprovide exemplar next-best action selection results and outline planned\nexperimentation in simulated and real-world robot block-stacking tasks.",
            "author": [
                "Ricardo Cannizzaro",
                "Jonathan Routley",
                "Lars Kunze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06203v2",
                "http://arxiv.org/pdf/2308.06203v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "stat.AP",
                "stat.ML",
                "I.2.9; I.2.8; I.2.3; G.3; I.6.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06197v2",
            "title": "Complex Facial Expression Recognition Using Deep Knowledge Distillation\n  of Basic Features",
            "updated": "2023-11-05T23:34:25Z",
            "published": "2023-08-11T15:42:48Z",
            "summary": "Complex emotion recognition is a cognitive task that has so far eluded the\nsame excellent performance of other tasks that are at or above the level of\nhuman cognition. Emotion recognition through facial expressions is particularly\ndifficult due to the complexity of emotions expressed by the human face. For a\nmachine to approach the same level of performance in complex facial expression\nrecognition as a human, it may need to synthesise knowledge and understand new\nconcepts in real-time, as humans do. Humans are able to learn new concepts\nusing only few examples by distilling important information from memories.\nInspired by human cognition and learning, we propose a novel continual learning\nmethod for complex facial expression recognition that can accurately recognise\nnew compound expression classes using few training samples, by building on and\nretaining its knowledge of basic expression classes. In this work, we also use\nGradCAM visualisations to demonstrate the relationship between basic and\ncompound facial expressions. Our method leverages this relationship through\nknowledge distillation and a novel Predictive Sorting Memory Replay, to achieve\nthe current state-of-the-art in continual learning for complex facial\nexpression recognition, with 74.28% Overall Accuracy on new classes. We also\ndemonstrate that using continual learning for complex facial expression\nrecognition achieves far better performance than non-continual learning\nmethods, improving on state-of-the-art non-continual learning methods by\n13.95%. Our work is also the first to apply few-shot learning to complex facial\nexpression recognition, achieving the state-of-the-art with 100% accuracy using\nonly a single training sample per class.",
            "author": [
                "Angus Maiden",
                "Bahareh Nakisa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06197v2",
                "http://arxiv.org/pdf/2308.06197v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "68T45 (Primary) 68T07, 68T01, 68T05 (Secondary)",
                "I.2.1; I.2.10; I.2.6; I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06306v1",
            "title": "Towards Packaging Unit Detection for Automated Palletizing Tasks",
            "updated": "2023-08-11T15:37:38Z",
            "published": "2023-08-11T15:37:38Z",
            "summary": "For various automated palletizing tasks, the detection of packaging units is\na crucial step preceding the actual handling of the packaging units by an\nindustrial robot. We propose an approach to this challenging problem that is\nfully trained on synthetically generated data and can be robustly applied to\narbitrary real world packaging units without further training or setup effort.\nThe proposed approach is able to handle sparse and low quality sensor data, can\nexploit prior knowledge if available and generalizes well to a wide range of\nproducts and application scenarios. To demonstrate the practical use of our\napproach, we conduct an extensive evaluation on real-world data with a wide\nrange of different retail products. Further, we integrated our approach in a\nlab demonstrator and a commercial solution will be marketed through an\nindustrial partner.",
            "author": [
                "Markus V\u00f6lk",
                "Kilian Kleeberger",
                "Werner Kraus",
                "Richard Bormann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06306v1",
                "http://arxiv.org/pdf/2308.06306v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06184v1",
            "title": "Demazure weaves for reduced plabic graphs (with a proof that\n  Muller-Speyer twist is Donaldson-Thomas)",
            "updated": "2023-08-11T15:17:08Z",
            "published": "2023-08-11T15:17:08Z",
            "summary": "First, this article develops the theory of weaves and their cluster\nstructures for the affine cones of positroid varieties. In particular, we\nexplain how to construct a weave from a reduced plabic graph, show it is\nDemazure, compare their associated cluster structures, and prove that the\nconjugate surface of the graph is Hamiltonian isotopic to the Lagrangian\nfilling associated to the weave. The T-duality map for plabic graphs has a\nsurprising key role in the construction of these weaves. Second, we use the\nabove established bridge between weaves and reduced plabic graphs to show that\nthe Muller-Speyer twist map on positroid varieties is the Donaldson-Thomas\ntransformation. This latter statement implies that the Muller-Speyer twist is a\nquasi-cluster automorphism. An additional corollary of our results is that\ntarget labeled seeds and the source labeled seeds are related by a\nquasi-cluster transformation.",
            "author": [
                "Roger Casals",
                "Ian Le",
                "Melissa Sherman-Bennett",
                "Daping Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06184v1",
                "http://arxiv.org/pdf/2308.06184v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.RT",
                "math.SG",
                "13F60, 14M15, 53D12"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06305v1",
            "title": "Discovering Local Binary Pattern Equation for Foreground Object Removal\n  in Videos",
            "updated": "2023-08-11T15:04:06Z",
            "published": "2023-08-11T15:04:06Z",
            "summary": "Designing a novel Local Binary Pattern (LBP) process usually relies heavily\non human experts' knowledge and experience in the area. Even experts are often\nleft with tedious episodes of trial and error until they identify an optimal\nLBP for a particular dataset. To address this problem, we present a novel\nsymbolic regression able to automatically discover LBP formulas to remove the\nmoving parts of a scene by segmenting it into a background and a foreground.\nExperimental results conducted on real videos of outdoor urban scenes under\nvarious conditions show that the LBPs discovered by the proposed approach\nsignificantly outperform the previous state-of-the-art LBP descriptors both\nqualitatively and quantitatively. Our source code and data will be available\nonline.",
            "author": [
                "Caroline Pacheco do Espirito Silva",
                "Andrews Cordolino Sobral",
                "Antoine Vacavant",
                "Thierry Bouwmans",
                "Felippe De Souza"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06305v1",
                "http://arxiv.org/pdf/2308.06305v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06145v1",
            "title": "Finding Long Directed Cycles Is Hard Even When DFVS Is Small Or Girth Is\n  Large",
            "updated": "2023-08-11T14:10:15Z",
            "published": "2023-08-11T14:10:15Z",
            "summary": "We study the parameterized complexity of two classic problems on directed\ngraphs: Hamiltonian Cycle and its generalization {\\sc Longest Cycle}. Since\n2008, it is known that Hamiltonian Cycle is W[1]-hard when parameterized by\ndirected treewidth [Lampis et al., ISSAC'08]. By now, the question of whether\nit is FPT parameterized by the directed feedback vertex set (DFVS) number has\nbecome a longstanding open problem. In particular, the DFVS number is the\nlargest natural directed width measure studied in the literature. In this\npaper, we provide a negative answer to the question, showing that even for the\nDFVS number, the problem remains W[1]-hard. As a consequence, we also obtain\nthat Longest Cycle is W[1]-hard on directed graphs when parameterized\nmultiplicatively above girth, in contrast to the undirected case. This resolves\nan open question posed by Fomin et al. [ACM ToCT'21] and Gutin and Mnich\n[arXiv:2207.12278]. Our hardness results apply to the path versions of the\nproblems as well. On the positive side, we show that Longest Path parameterized\nmultiplicatively above girth} belongs to the class XP.",
            "author": [
                "Ashwin Jacob",
                "Micha\u0142 W\u0142odarczyk",
                "Meirav Zehavi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06145v1",
                "http://arxiv.org/pdf/2308.06145v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06139v1",
            "title": "Shared ancestry graphs and symbolic arboreal maps",
            "updated": "2023-08-11T13:59:39Z",
            "published": "2023-08-11T13:59:39Z",
            "summary": "A network $N$ on a finite set $X$, $|X|\\geq 2$, is a connected directed\nacyclic graph with leaf set $X$ in which every root in $N$ has outdegree at\nleast 2 and no vertex in $N$ has indegree and outdegree equal to 1; $N$ is\narboreal if the underlying unrooted, undirected graph of $N$ is a tree.\nNetworks are of interest in evolutionary biology since they are used, for\nexample, to represent the evolutionary history of a set $X$ of species whose\nancestors have exchanged genes in the past. For $M$ some arbitrary set of\nsymbols, $d:{X \\choose 2} \\to M \\cup \\{\\odot\\}$ is a symbolic arboreal map if\nthere exists some arboreal network $N$ whose vertices with outdegree two or\nmore are labelled by elements in $M$ and so that $d(\\{x,y\\})$, $\\{x,y\\} \\in {X\n\\choose 2}$, is equal to the label of the least common ancestor of $x$ and $y$\nin $N$ if this exists and $\\odot$ else. Important examples of symbolic arboreal\nmaps include the symbolic ultrametrics, which arise in areas such as game\ntheory, phylogenetics and cograph theory. In this paper we show that a map\n$d:{X \\choose 2} \\to M \\cup \\{\\odot\\}$ is a symbolic arboreal map if and only\nif $d$ satisfies certain 3- and 4-point conditions and the graph with vertex\nset $X$ and edge set consisting of those pairs $\\{x,y\\} \\in {X \\choose 2}$ with\n$d(\\{x,y\\}) \\neq \\odot$ is Ptolemaic. To do this, we introduce and prove a key\ntheorem concerning the shared ancestry graph for a network $N$ on $X$, where\nthis is the graph with vertex set $X$ and edge set consisting of those $\\{x,y\\}\n\\in {X \\choose 2}$ such that $x$ and $y$ share a common ancestor in $N$. In\nparticular, we show that for any connected graph $G$ with vertex set $X$ and\nedge clique cover $K$ in which there are no two distinct sets in $K$ with one a\nsubset of the other, there is some network with $|K|$ roots and leaf set $X$\nwhose shared ancestry graph is $G$.",
            "author": [
                "Katharina T. Huber",
                "Vincent Moulton",
                "Guillaume E. Scholz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06139v1",
                "http://arxiv.org/pdf/2308.06139v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C05, 05C20, 05C90"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07336v3",
            "title": "Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic",
            "updated": "2023-11-14T03:14:49Z",
            "published": "2023-08-11T13:15:35Z",
            "summary": "We study a synthetic corpus based approach for language models (LMs) to\nacquire logical deductive reasoning ability. The previous studies generated\ndeduction examples using specific sets of deduction rules. However, these rules\nwere limited or otherwise arbitrary, limiting the generalizability of acquired\nreasoning ability. We rethink this and adopt a well-grounded set of deduction\nrules based on formal logic theory, which can derive any other deduction rules\nwhen combined in a multistep way. Then, using the proposed corpora, which we\nname FLD (Formal Logic Deduction), we first evaluate and analyze the logical\nreasoning ability of the latest LLMs. Even GPT-4 can solve only half of the\nproblems, suggesting that pure logical reasoning isolated from knowledge is\nstill challenging for the LLMs, and additional training specialized in logical\nreasoning is indeed essential. We next empirically verify that LMs trained on\nFLD corpora acquire more generalizable reasoning ability. Furthermore, we\nidentify the aspects of reasoning ability on which deduction corpora can\nenhance LMs and those on which they cannot, and discuss future directions on\neach aspect. The released corpora serve both as learning resources and as\nchallenging benchmarks.",
            "author": [
                "Terufumi Morishita",
                "Gaku Morio",
                "Atsuki Yamaguchi",
                "Yasuhiro Sogawa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07336v3",
                "http://arxiv.org/pdf/2308.07336v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06113v1",
            "title": "A Uniform Representation of Classical and Quantum Source Code for Static\n  Code Analysis",
            "updated": "2023-08-11T13:03:32Z",
            "published": "2023-08-11T13:03:32Z",
            "summary": "The emergence of quantum computing raises the question of how to identify\n(security-relevant) programming errors during development. However, current\nstatic code analysis tools fail to model information specific to quantum\ncomputing. In this paper, we identify this information and propose to extend\nclassical code analysis tools accordingly. Among such tools, we identify the\nCode Property Graph to be very well suited for this task as it can be easily\nextended with quantum computing specific information. For our proof of concept,\nwe implemented a tool which includes information from the quantum world in the\ngraph and demonstrate its ability to analyze source code written in Qiskit and\nOpenQASM. Our tool brings together the information from the classical and\nquantum world, enabling analysis across both domains. By combining all relevant\ninformation into a single detailed analysis, this powerful tool can facilitate\ntackling future quantum source code analysis challenges.",
            "author": [
                "Maximilian Kaul",
                "Alexander K\u00fcchler",
                "Christian Banse"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06113v1",
                "http://arxiv.org/pdf/2308.06113v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06109v2",
            "title": "On maximal cliques in the graph of simplex codes",
            "updated": "2023-09-29T15:49:22Z",
            "published": "2023-08-11T12:52:40Z",
            "summary": "The induced subgraph of the corresponding Grassmann graph formed by simplex\ncodes is considered. We show that this graph, as the Grassmann graph, contains\ntwo types of maximal cliques. For any two cliques of the first type there is a\nmonomial linear automorphism transferring one of them to the other. Cliques of\nthe second type are more complicated and can contain different numbers of\nelements.",
            "author": [
                "Mariusz Kwiatkowski",
                "Mark Pankov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06109v2",
                "http://arxiv.org/pdf/2308.06109v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06103v1",
            "title": "Composable Function-preserving Expansions for Transformer Architectures",
            "updated": "2023-08-11T12:27:22Z",
            "published": "2023-08-11T12:27:22Z",
            "summary": "Training state-of-the-art neural networks requires a high cost in terms of\ncompute and time. Model scale is recognized to be a critical factor to achieve\nand improve the state-of-the-art. Increasing the scale of a neural network\nnormally requires restarting from scratch by randomly initializing all the\nparameters of the model, as this implies a change of architecture's parameters\nthat does not allow for a straightforward transfer of knowledge from smaller\nsize models. In this work, we propose six composable transformations to\nincrementally increase the size of transformer-based neural networks while\npreserving functionality, allowing to expand the capacity of the model as\nneeded. We provide proof of exact function preservation under minimal\ninitialization constraints for each transformation. The proposed methods may\nenable efficient training pipelines for larger and more powerful models by\nprogressively expanding the architecture throughout training.",
            "author": [
                "Andrea Gesmundo",
                "Kaitlin Maile"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06103v1",
                "http://arxiv.org/pdf/2308.06103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06100v1",
            "title": "Diffusion-based Visual Counterfactual Explanations -- Towards Systematic\n  Quantitative Evaluation",
            "updated": "2023-08-11T12:22:37Z",
            "published": "2023-08-11T12:22:37Z",
            "summary": "Latest methods for visual counterfactual explanations (VCE) harness the power\nof deep generative models to synthesize new examples of high-dimensional images\nof impressive quality. However, it is currently difficult to compare the\nperformance of these VCE methods as the evaluation procedures largely vary and\noften boil down to visual inspection of individual examples and small scale\nuser studies. In this work, we propose a framework for systematic, quantitative\nevaluation of the VCE methods and a minimal set of metrics to be used. We use\nthis framework to explore the effects of certain crucial design choices in the\nlatest diffusion-based generative models for VCEs of natural image\nclassification (ImageNet). We conduct a battery of ablation-like experiments,\ngenerating thousands of VCEs for a suite of classifiers of various complexity,\naccuracy and robustness. Our findings suggest multiple directions for future\nadvancements and improvements of VCE methods. By sharing our methodology and\nour approach to tackle the computational challenges of such a study on a\nlimited hardware setup (including the complete code base), we offer a valuable\nguidance for researchers in the field fostering consistency and transparency in\nthe assessment of counterfactual explanations.",
            "author": [
                "Philipp Vaeth",
                "Alexander M. Fruehwald",
                "Benjamin Paassen",
                "Magda Gregorova"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06100v1",
                "http://arxiv.org/pdf/2308.06100v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06072v1",
            "title": "Out-of-Distribution Detection for Monocular Depth Estimation",
            "updated": "2023-08-11T11:25:23Z",
            "published": "2023-08-11T11:25:23Z",
            "summary": "In monocular depth estimation, uncertainty estimation approaches mainly\ntarget the data uncertainty introduced by image noise. In contrast to prior\nwork, we address the uncertainty due to lack of knowledge, which is relevant\nfor the detection of data not represented by the training distribution, the\nso-called out-of-distribution (OOD) data. Motivated by anomaly detection, we\npropose to detect OOD images from an encoder-decoder depth estimation model\nbased on the reconstruction error. Given the features extracted with the fixed\ndepth encoder, we train an image decoder for image reconstruction using only\nin-distribution data. Consequently, OOD images result in a high reconstruction\nerror, which we use to distinguish between in- and out-of-distribution samples.\nWe built our experiments on the standard NYU Depth V2 and KITTI benchmarks as\nin-distribution data. Our post hoc method performs astonishingly well on\ndifferent models and outperforms existing uncertainty estimation approaches\nwithout modifying the trained encoder-decoder depth estimation model.",
            "author": [
                "Julia Hornauer",
                "Adrian Holzbock",
                "Vasileios Belagiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06072v1",
                "http://arxiv.org/pdf/2308.06072v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06070v1",
            "title": "The next case of Andr\u00e1sfai's conjecture",
            "updated": "2023-08-11T11:11:20Z",
            "published": "2023-08-11T11:11:20Z",
            "summary": "Let $\\mathrm{ex}(n,s)$ denote the maximum number of edges in a triangle-free\ngraph on $n$ vertices which contains no independent sets larger than $s$. The\nbehaviour of $\\mathrm{ex}(n,s)$ was first studied by Andr\\'asfai, who\nconjectured that for $s>n/3$ this function is determined by appropriately\nchosen blow-ups of so called Andr\\'asfai graphs. Moreover, he proved\n$\\mathrm{ex}(n, s)=n^2-4ns+5s^2$ for $s/n\\in [2/5, 1/2]$ and in earlier work we\nobtained $\\mathrm{ex}(n, s)=3n^2-15ns+20s^2$ for $s/n\\in [3/8, 2/5]$. Here we\nmake the next step in the quest to settle Andr\\'asfai's conjecture by proving\n$\\mathrm{ex}(n, s)=6n^2-32ns+44s^2$ for $s/n\\in [4/11, 3/8]$.",
            "author": [
                "Tomasz \u0141uczak",
                "Joanna Polcyn",
                "Christian Reiher"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06070v1",
                "http://arxiv.org/pdf/2308.06070v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C35, 05C69"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06301v1",
            "title": "Generalized Gr\u00f6tzsch Graphs",
            "updated": "2023-08-11T10:51:00Z",
            "published": "2023-08-11T10:51:00Z",
            "summary": "The aim of this paper is to present a generalization of Gr\\\"otzsch graph.\nInspired by structure of the Gr\\\"otzsch's graph, we present constructions of\ntwo families of graphs, $G_m$ and $H_m$ for odd and even values of $m$\nrespectively and on $n = 2m +1$ vertices. We show that each member of this\nfamily is non-planar, triangle-free, and Hamiltonian. Further, when $m$ is odd\nthe graph $G_m$ is maximal triangle-free, and when $m$ is even, the addition of\nexactly $\\frac{m}{2}$ edges makes the graph $H_m$ maximal triangle-free. We\nshow that $G_m$ is 4-chromatic and $H_m$ is 3-chromatic for all $m$. Further,\nwe note some other properties of these graphs and compare with Mycielski's\nconstruction.",
            "author": [
                "Ashish Upadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06301v1",
                "http://arxiv.org/pdf/2308.06301v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C10, 57M15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06058v2",
            "title": "Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence\n  and Variance Reduction",
            "updated": "2023-08-21T16:28:13Z",
            "published": "2023-08-11T10:17:29Z",
            "summary": "The recently proposed stochastic Polyak stepsize (SPS) and stochastic\nline-search (SLS) for SGD have shown remarkable effectiveness when training\nover-parameterized models. However, in non-interpolation settings, both\nalgorithms only guarantee convergence to a neighborhood of a solution which may\nresult in a worse output than the initial guess. While artificially decreasing\nthe adaptive stepsize has been proposed to address this issue (Orvieto et al.\n[2022]), this approach results in slower convergence rates for convex and\nover-parameterized models. In this work, we make two contributions: Firstly, we\npropose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which\nguarantee convergence in non-interpolation settings and maintain sub-linear and\nlinear convergence rates for convex and strongly convex functions when training\nover-parameterized models. AdaSLS requires no knowledge of problem-dependent\nparameters, and AdaSPS requires only a lower bound of the optimal function\nvalue as input. Secondly, we equip AdaSPS and AdaSLS with a novel variance\nreduction technique and obtain algorithms that require\n$\\smash{\\widetilde{\\mathcal{O}}}(n+1/\\epsilon)$ gradient evaluations to achieve\nan $\\mathcal{O}(\\epsilon)$-suboptimality for convex functions, which improves\nupon the slower $\\mathcal{O}(1/\\epsilon^2)$ rates of AdaSPS and AdaSLS without\nvariance reduction in the non-interpolation regimes. Moreover, our result\nmatches the fast rates of AdaSVRG but removes the inner-outer-loop structure,\nwhich is easier to implement and analyze. Finally, numerical experiments on\nsynthetic and real datasets validate our theory and demonstrate the\neffectiveness and robustness of our algorithms.",
            "author": [
                "Xiaowen Jiang",
                "Sebastian U. Stich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06058v2",
                "http://arxiv.org/pdf/2308.06058v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06053v4",
            "title": "Cost-effective On-device Continual Learning over Memory Hierarchy with\n  Miro",
            "updated": "2023-12-05T08:51:52Z",
            "published": "2023-08-11T10:05:53Z",
            "summary": "Continual learning (CL) trains NN models incrementally from a continuous\nstream of tasks. To remember previously learned knowledge, prior studies store\nold samples over a memory hierarchy and replay them when new tasks arrive. Edge\ndevices that adopt CL to preserve data privacy are typically energy-sensitive\nand thus require high model accuracy while not compromising energy efficiency,\ni.e., cost-effectiveness. Our work is the first to explore the design space of\nhierarchical memory replay-based CL to gain insights into achieving\ncost-effectiveness on edge devices. We present Miro, a novel system runtime\nthat carefully integrates our insights into the CL framework by enabling it to\ndynamically configure the CL system based on resource states for the best\ncost-effectiveness. To reach this goal, Miro also performs online profiling on\nparameters with clear accuracy-energy trade-offs and adapts to optimal values\nwith low overhead. Extensive evaluations show that Miro significantly\noutperforms baseline systems we build for comparison, consistently achieving\nhigher cost-effectiveness.",
            "author": [
                "Xinyue Ma",
                "Suyeon Jeong",
                "Minjia Zhang",
                "Di Wang",
                "Jonghyun Choi",
                "Myeongjae Jeon"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3570361.3613297",
                "http://arxiv.org/abs/2308.06053v4",
                "http://arxiv.org/pdf/2308.06053v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06044v1",
            "title": "Going Deep and Going Wide: Counting Logic and Homomorphism\n  Indistinguishability over Graphs of Bounded Treedepth and Treewidth",
            "updated": "2023-08-11T09:45:13Z",
            "published": "2023-08-11T09:45:13Z",
            "summary": "We study the expressive power of first-order logic with counting quantifiers,\nespecially the $k$-variable and quantifier-rank-$q$ fragment $\\mathsf{C}^k_q$,\nusing homomorphism indistinguishability. Recently, Dawar, Jakl, and Reggio\n(2021) proved that two graphs satisfy the same $\\mathsf{C}^k_q$-sentences if\nand only if they are homomorphism indistinguishable over the class\n$\\mathcal{T}^k_q$ of graphs admitting a $k$-pebble forest cover of depth $q$.\nTheir proof builds on the categorical framework of game comonads developed by\nAbramsky, Dawar, and Wang (2017). We reprove their result using elementary\ntechniques inspired by Dvo\\v{r}\\'ak (2010). Using these techniques we also give\na characterisation of guarded counting logic. Our main focus, however, is to\nprovide a graph theoretic analysis of the graph class $\\mathcal{T}^k_q$. This\nallows us to separate $\\mathcal{T}^k_q$ from the intersection of the graph\nclass $\\mathcal{TW}_{k-1}$, that is graphs of treewidth less or equal $k-1$,\nand $\\mathcal{TD}_q$, that is graphs of treedepth at most $q$ if $q$ is\nsufficiently larger than $k$. We are able to lift this separation to the\nsemantic separation of the respective homomorphism indistinguishability\nrelations. A part of this separation is to prove that the class\n$\\mathcal{TD}_q$ is homomorphism distinguishing closed, which was already\nconjectured by Roberson (2022).",
            "author": [
                "Eva Fluck",
                "Tim Seppelt",
                "Gian Luca Spitzer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06044v1",
                "http://arxiv.org/pdf/2308.06044v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06040v1",
            "title": "Algebraic connectivity of Kronecker products of line graphs",
            "updated": "2023-08-11T09:36:40Z",
            "published": "2023-08-11T09:36:40Z",
            "summary": "Let $X$ be a tree with $n$ vertices and $L(X)$ be its line graph. In this\nwork, we completely characterize the trees for which the algebraic connectivity\nof $L(X)\\times K_m$ is equal to $m-1$, where $\\times$ denotes the Kronecker\nproduct. We provide a few necessary and sufficient conditions for $L(X)\\times\nK_m$ to be Laplacian integral. The algebraic connectivity of $L(X)\\times K_m$,\nwhere $X$ is a tree of diameter $4$ and $k$-book graph is discussed.",
            "author": [
                "Shivani Chauhan",
                "A. Satyanarayana Reddy"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06040v1",
                "http://arxiv.org/pdf/2308.06040v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C05, 05C76"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06034v1",
            "title": "Age of Incorrect Information in Random Access Channels without Feedback",
            "updated": "2023-08-11T09:28:39Z",
            "published": "2023-08-11T09:28:39Z",
            "summary": "We focus on a system in which a set of two-state Markov sources report status\nupdate to a common receiver over a shared wireless channel. Inspired by\npractical IoT networks, we consider three variations of ALOHA as medium access\nprotocol: i) a random approach in which a source transmits regardless of its\nstatus, ii) a reactive scheme in which updates are sent only when a source\nchanges state, and iii) a hybrid solution which blends the two possibilities.\nWe consider different criteria to capture the ability of the receiver to\nmaintain an accurate perception of the tracked processes: average age of\nincorrect information (AoII), probability of missed detection (i.e., of not\ndetecting a source transition), and average duration of intervals over which\nthe receiver lingers with erroneous knowledge. We provide closed form\nanalytical expressions for all the metrics, highlighting non-trivial trade-offs\nand providing useful protocol design hints.",
            "author": [
                "Andrea Munari"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06034v1",
                "http://arxiv.org/pdf/2308.06034v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06026v1",
            "title": "Heating and ionization by non-thermal electrons in the upper atmospheres\n  of water-rich exoplanets",
            "updated": "2023-08-11T09:12:45Z",
            "published": "2023-08-11T09:12:45Z",
            "summary": "Context. The long-term evolution of an atmosphere and the remote\ndetectability of its chemical constituents are susceptible to how the\natmospheric gas responds to stellar irradiation. The response remains poorly\ncharacterized for water and its dissociation products, however, this knowledge\nis relevant to our understanding of hypothetical water-rich exoplanets. Aims:\nOur work investigates the effect of photoelectrons, namely, the non-thermal\nelectrons produced by photoionizing stellar radiation on the heating and\nionization of extended atmospheres dominated by the dissociation products of\nwater. Methods: We used a Monte Carlo model and up-to-date collision cross\nsections to simulate the slowing down of photoelectrons in O-H mixtures for a\nrange of fractional ionizations and photoelectron energies. Results: We find\nthat that the fraction of energy of a photoelectron that goes into heating is\nsimilar in a pure H gas and in O-H mixtures, except for very low fractional\nionizations, whereby the O atom remains an efficient sink of energy. The O-H\nmixtures will go on to produce more electrons because the O atom is\nparticularly susceptible to ionization. We quantified all that information and\npresent it in a way that can be easily incorporated into\nphotochemical-hydrodynamical models. Conclusions: Neglecting the role of\nphotoelectrons in models of water-rich atmospheres will result in\noverestimations of the atmospheric heating and, foreseeably, the mass-loss\nrates as well. It will also underestimate the rate at which the atmospheric gas\nbecomes ionized, which may have implications for the detection of extended\natmospheres with Lyman-{\\alpha} transmission spectroscopy. Our simulations for\nthe small exoplanets {\\pi} Men c and TRAPPIST-1 b reveal that they respond very\ndifferently to irradiation from their host stars, with water remaining in\nmolecular form at lower pressures in the latter case.",
            "author": [
                "A. Garc\u00eda Mu\u00f1oz"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202245766",
                "http://arxiv.org/abs/2308.06026v1",
                "http://arxiv.org/pdf/2308.06026v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06016v1",
            "title": "Integral closure and normality of edge ideals of some edge-weighted\n  graphs",
            "updated": "2023-08-11T08:45:53Z",
            "published": "2023-08-11T08:45:53Z",
            "summary": "Let $G_\\omega$ be an edge-weighted simple graph. In this paper, we give a\ncomplete characterization of the graph $G_\\omega$ whose edge ideal\n$I(G_\\omega)$ is integrally closed. We also show that if $G_\\omega$ is an\nedge-weighted star graph, a path or a cycle, and $I(G_\\omega)$ is integrally\nclosed, then $I(G_\\omega)$ is normal.",
            "author": [
                "Shiya Duan",
                "Guangjun Zhu",
                "Yijun Cui",
                "Jiaxin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06016v1",
                "http://arxiv.org/pdf/2308.06016v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "Primary 13B22, 13F20, Secondary 05C99, 05E4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07933v1",
            "title": "Evaluating Picture Description Speech for Dementia Detection using\n  Image-text Alignment",
            "updated": "2023-08-11T08:42:37Z",
            "published": "2023-08-11T08:42:37Z",
            "summary": "Using picture description speech for dementia detection has been studied for\n30 years. Despite the long history, previous models focus on identifying the\ndifferences in speech patterns between healthy subjects and patients with\ndementia but do not utilize the picture information directly. In this paper, we\npropose the first dementia detection models that take both the picture and the\ndescription texts as inputs and incorporate knowledge from large pre-trained\nimage-text alignment models. We observe the difference between dementia and\nhealthy samples in terms of the text's relevance to the picture and the focused\narea of the picture. We thus consider such a difference could be used to\nenhance dementia detection accuracy. Specifically, we use the text's relevance\nto the picture to rank and filter the sentences of the samples. We also\nidentified focused areas of the picture as topics and categorized the sentences\naccording to the focused areas. We propose three advanced models that\npre-processed the samples based on their relevance to the picture, sub-image,\nand focused areas. The evaluation results show that our advanced models, with\nknowledge of the picture and large image-text alignment models, achieve\nstate-of-the-art performance with the best detection accuracy at 83.44%, which\nis higher than the text-only baseline model at 79.91%. Lastly, we visualize the\nsample and picture results to explain the advantages of our models.",
            "author": [
                "Youxiang Zhu",
                "Nana Lin",
                "Xiaohui Liang",
                "John A. Batsis",
                "Robert M. Roth",
                "Brian MacWhinney"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07933v1",
                "http://arxiv.org/pdf/2308.07933v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06010v1",
            "title": "The $\\circ$ operation and $*$ operation of fan graphs",
            "updated": "2023-08-11T08:37:34Z",
            "published": "2023-08-11T08:37:34Z",
            "summary": "Let $G$ be a finite simple graph on the vertex set $V$ and let $I_G$ denote\nits edge ideal in the polynomial ring $S=\\mathbb{K}[x_V]$. In this paper, we\ncompute the depth and the Castelnuovo--Mumford regularity of $S/I_G$ when\n$G=F_{k}^{W}(K_n)$ is a $k$-fan graph, or $G=G_1\\circ G_2$ or $G=G_1* G_2$ is\nthe graph obtained from fan graphs $G_1$, $G_2$ by $\\circ$ operation or $*$\noperation, respectively.",
            "author": [
                "Guangjun Zhu",
                "Yijun Cui",
                "Yulong Yang",
                "Yi yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06010v1",
                "http://arxiv.org/pdf/2308.06010v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "Primary 13C15, 13A15, 13D02, Secondary 05E40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05978v2",
            "title": "CyberForce: A Federated Reinforcement Learning Framework for Malware\n  Mitigation",
            "updated": "2023-09-08T09:57:04Z",
            "published": "2023-08-11T07:25:12Z",
            "summary": "Recent research has shown that the integration of Reinforcement Learning (RL)\nwith Moving Target Defense (MTD) can enhance cybersecurity in\nInternet-of-Things (IoT) devices. Nevertheless, the practicality of existing\nwork is hindered by data privacy concerns associated with centralized data\nprocessing in RL, and the unsatisfactory time needed to learn right MTD\ntechniques that are effective against a rising number of heterogeneous zero-day\nattacks. Thus, this work presents CyberForce, a framework that combines\nFederated and Reinforcement Learning (FRL) to collaboratively and privately\nlearn suitable MTD techniques for mitigating zero-day attacks. CyberForce\nintegrates device fingerprinting and anomaly detection to reward or penalize\nMTD mechanisms chosen by an FRL-based agent. The framework has been deployed\nand evaluated in a scenario consisting of ten physical devices of a real IoT\nplatform affected by heterogeneous malware samples. A pool of experiments has\ndemonstrated that CyberForce learns the MTD technique mitigating each attack\nfaster than existing RL-based centralized approaches. In addition, when various\ndevices are exposed to different attacks, CyberForce benefits from knowledge\ntransfer, leading to enhanced performance and reduced learning time in\ncomparison to recent works. Finally, different aggregation algorithms used\nduring the agent learning process provide CyberForce with notable robustness to\nmalicious attacks.",
            "author": [
                "Chao Feng",
                "Alberto Huertas Celdran",
                "Pedro Miguel Sanchez Sanchez",
                "Jan Kreischer",
                "Jan von der Assen",
                "Gerome Bovet",
                "Gregorio Martinez Perez",
                "Burkhard Stiller"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05978v2",
                "http://arxiv.org/pdf/2308.05978v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05969v2",
            "title": "Learning nonparametric DAGs with incremental information via high-order\n  HSIC",
            "updated": "2023-09-14T08:42:33Z",
            "published": "2023-08-11T07:07:21Z",
            "summary": "Score-based methods for learning Bayesain networks(BN) aim to maximizing the\nglobal score functions. However, if local variables have direct and indirect\ndependence simultaneously, the global optimization on score functions misses\nedges between variables with indirect dependent relationship, of which scores\nare smaller than those with direct dependent relationship. In this paper, we\npresent an identifiability condition based on a determined subset of parents to\nidentify the underlying DAG. By the identifiability condition, we develop a\ntwo-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the\nglobal optimization. In the optimal phase, an optimization problem based on\nfirst-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated\nskeleton as the initial determined parents subset. In the tuning phase, the\nskeleton is locally tuned by deletion, addition and DAG-formalization\nstrategies using the theoretically proved incremental properties of high-order\nHSIC. Numerical experiments for different synthetic datasets and real-world\ndatasets show that the OT algorithm outperforms existing methods. Especially in\nSigmoid Mix model with the size of the graph being ${\\rm\\bf d=40}$, the\nstructure intervention distance (SID) of the OT algorithm is 329.7 smaller than\nthe one obtained by CAM, which indicates that the graph estimated by the OT\nalgorithm misses fewer edges compared with CAM.Source code of the OT algorithm\nis available at https://github.com/YafeiannWang/optimal-tune-algorithm.",
            "author": [
                "Yafei Wang",
                "Jianguo Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05969v2",
                "http://arxiv.org/pdf/2308.05969v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05961v1",
            "title": "Compositional Learning in Transformer-Based Human-Object Interaction\n  Detection",
            "updated": "2023-08-11T06:41:20Z",
            "published": "2023-08-11T06:41:20Z",
            "summary": "Human-object interaction (HOI) detection is an important part of\nunderstanding human activities and visual scenes. The long-tailed distribution\nof labeled instances is a primary challenge in HOI detection, promoting\nresearch in few-shot and zero-shot learning. Inspired by the combinatorial\nnature of HOI triplets, some existing approaches adopt the idea of\ncompositional learning, in which object and action features are learned\nindividually and re-composed as new training samples. However, these methods\nfollow the CNN-based two-stage paradigm with limited feature extraction\nability, and often rely on auxiliary information for better performance.\nWithout introducing any additional information, we creatively propose a\ntransformer-based framework for compositional HOI learning. Human-object pair\nrepresentations and interaction representations are re-composed across\ndifferent HOI instances, which involves richer contextual information and\npromotes the generalization of knowledge. Experiments show our simple but\neffective method achieves state-of-the-art performance, especially on rare HOI\nclasses.",
            "author": [
                "Zikun Zhuang",
                "Ruihao Qian",
                "Chi Xie",
                "Shuang Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05961v1",
                "http://arxiv.org/pdf/2308.05961v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05957v1",
            "title": "Node Embedding for Homophilous Graphs with ARGEW: Augmentation of Random\n  walks by Graph Edge Weights",
            "updated": "2023-08-11T06:19:23Z",
            "published": "2023-08-11T06:19:23Z",
            "summary": "Representing nodes in a network as dense vectors node embeddings is important\nfor understanding a given network and solving many downstream tasks. In\nparticular, for weighted homophilous graphs where similar nodes are connected\nwith larger edge weights, we desire node embeddings where node pairs with\nstrong weights have closer embeddings. Although random walk based node\nembedding methods like node2vec and node2vec+ do work for weighted networks via\nincluding edge weights in the walk transition probabilities, our experiments\nshow that the embedding result does not adequately reflect edge weights. In\nthis paper, we propose ARGEW (Augmentation of Random walks by Graph Edge\nWeights), a novel augmentation method for random walks that expands the corpus\nin such a way that nodes with larger edge weights end up with closer\nembeddings. ARGEW can work with any random walk based node embedding method,\nbecause it is independent of the random sampling strategy itself and works on\ntop of the already-performed walks. With several real-world networks, we\ndemonstrate that with ARGEW, compared to not using it, the desired pattern that\nnode pairs with larger edge weights have closer embeddings is much clearer. We\nalso examine ARGEW's performance in node classification: node2vec with ARGEW\noutperforms pure node2vec and is not sensitive to hyperparameters (i.e.\nconsistently good). In fact, it achieves similarly good results as supervised\nGCN, even without any node feature or label information during training.\nFinally, we explain why ARGEW works consistently well by exploring the\ncoappearance distributions using a synthetic graph with clear structural roles.",
            "author": [
                "Jun Hee Kim",
                "Jaeman Son",
                "Hyunsoo Kim",
                "Eunjo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05957v1",
                "http://arxiv.org/pdf/2308.05957v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05954v2",
            "title": "Perfect kernel and dynamics: from Bass-Serre theory to hyperbolic groups",
            "updated": "2023-10-03T13:26:18Z",
            "published": "2023-08-11T06:02:22Z",
            "summary": "We introduce several approaches to studying the Cantor-Bendixson\ndecomposition of and the dynamics on the (topological) space of subgroups for\nvarious families of countable groups.\n  In particular, we uncover the perfect kernel and the Cantor-Bendixson rank of\nthe space of subgroups of many new groups, including for instance infinitely\nended groups, limit groups, hyperbolic 3-manifold groups and many graphs of\ngroups. We also study the topological dynamics of the conjugation action on the\nperfect kernel, establishing the conditions for topological transitivity and\nhigher topological transitivity. As an application, we obtain many new examples\nof groups in the class A of Glasner and Monod, i.e. admitting faithful\ntransitive amenable actions. This includes for example right-angled Artin\ngroups, limit groups, C'(1/6) small cancellation groups, random groups at\ndensity d<1/6, and more generally all virtually compact special groups.",
            "author": [
                "P\u00e9n\u00e9lope Azuelos",
                "Damien Gaboriau"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05954v2",
                "http://arxiv.org/pdf/2308.05954v2"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.DS",
                "20E, 37B (Primary) 20F67, 20F65, 37B20 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05953v1",
            "title": "Reeb spaces of smooth functions on manifolds II",
            "updated": "2023-08-11T05:55:04Z",
            "published": "2023-08-11T05:55:04Z",
            "summary": "The Reeb space of a continuous function is the space of connected components\nof the level sets. In this paper we characterize those smooth functions on\nclosed manifolds whose Reeb spaces have the structure of a finite graph. We\nalso give several explicit examples of smooth functions on closed manifolds\nsuch that they themselves or their Reeb spaces have some interesting\nproperties.",
            "author": [
                "Osamu Saeki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05953v1",
                "http://arxiv.org/pdf/2308.05953v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "Primary 58K05, Secondary 58K30, 57R45, 57R70, 58K15, 54C30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05943v2",
            "title": "On Some Closure Properties of nc-eNCE Graph Grammars",
            "updated": "2023-08-15T15:49:48Z",
            "published": "2023-08-11T05:10:30Z",
            "summary": "In the study of automata and grammars, closure properties of the associated\nlanguages have been studied extensively. In particular, closure properties of\nvarious types of graph grammars have been examined in (Rozenberg and Welzl,\nInf. and Control,1986) and (Rozenberg and Welzl, Acta Informatica,1986). In\nthis paper we examine some critical closure properties of the nc-eNCE graph\ngrammars discussed in (Jayakrishna and Mathew, Symmetry 2023) and (Jayakrishna\nand Mathew, ICMICDS 2022).",
            "author": [
                "Jayakrishna Vijayakumar",
                "Lisa Mathew"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05943v2",
                "http://arxiv.org/pdf/2308.05943v2"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "math.CO",
                "68Q42(Primary) 68Q45, 68R10(SEcondary)",
                "F.4.2; G.2.2; F.4.3; F.1.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05942v1",
            "title": "Understanding and Remediating Open-Source License Incompatibilities in\n  the PyPI Ecosystem",
            "updated": "2023-08-11T04:57:54Z",
            "published": "2023-08-11T04:57:54Z",
            "summary": "The reuse and distribution of open-source software must be in compliance with\nits accompanying open-source license. In modern packaging ecosystems,\nmaintaining such compliance is challenging because a package may have a complex\nmulti-layered dependency graph with many packages, any of which may have an\nincompatible license. Although prior research finds that license\nincompatibilities are prevalent, empirical evidence is still scarce in some\nmodern packaging ecosystems (e.g., PyPI). It also remains unclear how\ndevelopers remediate the license incompatibilities in the dependency graphs of\ntheir packages (including direct and transitive dependencies), let alone any\nautomated approaches. To bridge this gap, we conduct a large-scale empirical\nstudy of license incompatibilities and their remediation practices in the PyPI\necosystem. We find that 7.27% of the PyPI package releases have license\nincompatibilities and 61.3% of them are caused by transitive dependencies,\ncausing challenges in their remediation; for remediation, developers can apply\none of the five strategies: migration, removal, pinning versions, changing\ntheir own licenses, and negotiation. Inspired by our findings, we propose\nSILENCE, an SMT-solver-based approach to recommend license incompatibility\nremediations with minimal costs in package dependency graph. Our evaluation\nshows that the remediations proposed by SILENCE can match 19 historical\nreal-world cases (except for migrations not covered by an existing knowledge\nbase) and have been accepted by five popular PyPI packages whose developers\nwere previously unaware of their license incompatibilities.",
            "author": [
                "Weiwei Xu",
                "Hao He",
                "Kai Gao",
                "Minghui Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05942v1",
                "http://arxiv.org/pdf/2308.05942v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05937v1",
            "title": "A Deep Recurrent-Reinforcement Learning Method for Intelligent\n  AutoScaling of Serverless Functions",
            "updated": "2023-08-11T04:41:19Z",
            "published": "2023-08-11T04:41:19Z",
            "summary": "Function-as-a-Service (FaaS) introduces a lightweight, function-based cloud\nexecution model that finds its relevance in applications like IoT-edge data\nprocessing and anomaly detection. While CSP offer a near-infinite function\nelasticity, these applications often experience fluctuating workloads and\nstricter performance constraints. A typical CSP strategy is to empirically\ndetermine and adjust desired function instances, \"autoscaling\", based on\nmonitoring-based thresholds such as CPU or memory, to cope with demand and\nperformance. However, threshold configuration either requires expert knowledge,\nhistorical data or a complete view of environment, making autoscaling a\nperformance bottleneck lacking an adaptable solution.RL algorithms are proven\nto be beneficial in analysing complex cloud environments and result in an\nadaptable policy that maximizes the expected objectives. Most realistic cloud\nenvironments usually involve operational interference and have limited\nvisibility, making them partially observable. A general solution to tackle\nobservability in highly dynamic settings is to integrate Recurrent units with\nmodel-free RL algorithms and model a decision process as a POMDP. Therefore, in\nthis paper, we investigate a model-free Recurrent RL agent for function\nautoscaling and compare it against the model-free Proximal Policy Optimisation\n(PPO) algorithm. We explore the integration of a LSTM network with the\nstate-of-the-art PPO algorithm to find that under our experimental and\nevaluation settings, recurrent policies were able to capture the environment\nparameters and show promising results for function autoscaling. We further\ncompare a PPO-based autoscaling agent with commercially used threshold-based\nfunction autoscaling and posit that a LSTM-based autoscaling agent is able to\nimprove throughput by 18%, function execution by 13% and account for 8.4% more\nfunction instances.",
            "author": [
                "Siddharth Agarwal",
                "Maria A. Rodriguez",
                "Rajkumar Buyya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05937v1",
                "http://arxiv.org/pdf/2308.05937v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05935v1",
            "title": "LittleMu: Deploying an Online Virtual Teaching Assistant via\n  Heterogeneous Sources Integration and Chain of Teach Prompts",
            "updated": "2023-08-11T04:36:26Z",
            "published": "2023-08-11T04:36:26Z",
            "summary": "Teaching assistants have played essential roles in the long history of\neducation. However, few MOOC platforms are providing human or virtual teaching\nassistants to support learning for massive online students due to the\ncomplexity of real-world online education scenarios and the lack of training\ndata. In this paper, we present a virtual MOOC teaching assistant, LittleMu\nwith minimum labeled training data, to provide question answering and chit-chat\nservices. Consisting of two interactive modules of heterogeneous retrieval and\nlanguage model prompting, LittleMu first integrates structural, semi- and\nunstructured knowledge sources to support accurate answers for a wide range of\nquestions. Then, we design delicate demonstrations named \"Chain of Teach\"\nprompts to exploit the large-scale pre-trained model to handle complex\nuncollected questions. Except for question answering, we develop other\neducational services such as knowledge-grounded chit-chat. We test the system's\nperformance via both offline evaluation and online deployment. Since May 2020,\nour LittleMu system has served over 80,000 users with over 300,000 queries from\nover 500 courses on XuetangX MOOC platform, which continuously contributes to a\nmore convenient and fair education. Our code, services, and dataset will be\navailable at https://github.com/THU-KEG/VTA.",
            "author": [
                "Shangqing Tu",
                "Zheyuan Zhang",
                "Jifan Yu",
                "Chunyang Li",
                "Siyu Zhang",
                "Zijun Yao",
                "Lei Hou",
                "Juanzi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05935v1",
                "http://arxiv.org/pdf/2308.05935v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05930v1",
            "title": "INR-Arch: A Dataflow Architecture and Compiler for Arbitrary-Order\n  Gradient Computations in Implicit Neural Representation Processing",
            "updated": "2023-08-11T04:24:39Z",
            "published": "2023-08-11T04:24:39Z",
            "summary": "An increasing number of researchers are finding use for nth-order gradient\ncomputations for a wide variety of applications, including graphics,\nmeta-learning (MAML), scientific computing, and most recently, implicit neural\nrepresentations (INRs). Recent work shows that the gradient of an INR can be\nused to edit the data it represents directly without needing to convert it back\nto a discrete representation. However, given a function represented as a\ncomputation graph, traditional architectures face challenges in efficiently\ncomputing its nth-order gradient due to the higher demand for computing power\nand higher complexity in data movement. This makes it a promising target for\nFPGA acceleration. In this work, we introduce INR-Arch, a framework that\ntransforms the computation graph of an nth-order gradient into a\nhardware-optimized dataflow architecture. We address this problem in two\nphases. First, we design a dataflow architecture that uses FIFO streams and an\noptimized computation kernel library, ensuring high memory efficiency and\nparallel computation. Second, we propose a compiler that extracts and optimizes\ncomputation graphs, automatically configures hardware parameters such as\nlatency and stream depths to optimize throughput, while ensuring deadlock-free\noperation, and outputs High-Level Synthesis (HLS) code for FPGA implementation.\nWe utilize INR editing as our benchmark, presenting results that demonstrate\n1.8-4.8x and 1.5-3.6x speedup compared to CPU and GPU baselines respectively.\nFurthermore, we obtain 3.1-8.9x and 1.7-4.3x lower memory usage, and 1.7-11.3x\nand 5.5-32.8x lower energy-delay product. Our framework will be made\nopen-source and available on GitHub.",
            "author": [
                "Stefan Abi-Karam",
                "Rishov Sarkar",
                "Dejia Xu",
                "Zhiwen Fan",
                "Zhangyang Wang",
                "Cong Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05930v1",
                "http://arxiv.org/pdf/2308.05930v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05898v1",
            "title": "Unveiling the Tricks: Automated Detection of Dark Patterns in Mobile\n  Applications",
            "updated": "2023-08-11T01:18:56Z",
            "published": "2023-08-11T01:18:56Z",
            "summary": "Mobile apps bring us many conveniences, such as online shopping and\ncommunication, but some use malicious designs called dark patterns to trick\nusers into doing things that are not in their best interest. Many works have\nbeen done to summarize the taxonomy of these patterns and some have tried to\nmitigate the problems through various techniques. However, these techniques are\neither time-consuming, not generalisable or limited to specific patterns. To\naddress these issues, we propose UIGuard, a knowledge-driven system that\nutilizes computer vision and natural language pattern matching to automatically\ndetect a wide range of dark patterns in mobile UIs. Our system relieves the\nneed for manually creating rules for each new UI/app and covers more types with\nsuperior performance. In detail, we integrated existing taxonomies into a\nconsistent one, conducted a characteristic analysis and distilled knowledge\nfrom real-world examples and the taxonomy. Our UIGuard consists of two\ncomponents, Property Extraction and Knowledge-Driven Dark Pattern Checker. We\ncollected the first dark pattern dataset, which contains 4,999 benign UIs and\n1,353 malicious UIs of 1,660 instances spanning 1,023 mobile apps. Our system\nachieves a superior performance in detecting dark patterns (micro averages:\n0.82 in precision, 0.77 in recall, 0.79 in F1 score). A user study involving 58\nparticipants further shows that \\tool{} significantly increases users'\nknowledge of dark patterns.",
            "author": [
                "Jieshan Chen",
                "Jiamou Sun",
                "Sidong Feng",
                "Zhenchang Xing",
                "Qinghua Lu",
                "Xiwei Xu",
                "Chunyang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05898v1",
                "http://arxiv.org/pdf/2308.05898v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05896v2",
            "title": "Semantic-embedded Similarity Prototype for Scene Recognition",
            "updated": "2023-10-20T01:40:58Z",
            "published": "2023-08-11T01:11:46Z",
            "summary": "Due to the high inter-class similarity caused by the complex composition and\nthe co-existing objects across scenes, numerous studies have explored object\nsemantic knowledge within scenes to improve scene recognition. However, a\nresulting challenge emerges as object information extraction techniques require\nheavy computational costs, thereby burdening the network considerably. This\nlimitation often renders object-assisted approaches incompatible with edge\ndevices in practical deployment. In contrast, this paper proposes a semantic\nknowledge-based similarity prototype, which can help the scene recognition\nnetwork achieve superior accuracy without increasing the computational cost in\npractice. It is simple and can be plug-and-played into existing pipelines. More\nspecifically, a statistical strategy is introduced to depict semantic knowledge\nin scenes as class-level semantic representations. These representations are\nused to explore correlations between scene classes, ultimately constructing a\nsimilarity prototype. Furthermore, we propose to leverage the similarity\nprototype to support network training from the perspective of Gradient Label\nSoftening and Batch-level Contrastive Loss, respectively. Comprehensive\nevaluations on multiple benchmarks show that our similarity prototype enhances\nthe performance of existing networks, all while avoiding any additional\ncomputational burden in practical deployments. Code and the statistical\nsimilarity prototype will be available soon.",
            "author": [
                "Chuanxin Song",
                "Hanbo Wu",
                "Xin Ma",
                "Yibin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05896v2",
                "http://arxiv.org/pdf/2308.05896v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05893v1",
            "title": "Learning to Team-Based Navigation: A Review of Deep Reinforcement\n  Learning Techniques for Multi-Agent Pathfinding",
            "updated": "2023-08-11T00:59:29Z",
            "published": "2023-08-11T00:59:29Z",
            "summary": "Multi-agent pathfinding (MAPF) is a critical field in many large-scale\nrobotic applications, often being the fundamental step in multi-agent systems.\nThe increasing complexity of MAPF in complex and crowded environments, however,\ncritically diminishes the effectiveness of existing solutions. In contrast to\nother studies that have either presented a general overview of the recent\nadvancements in MAPF or extensively reviewed Deep Reinforcement Learning (DRL)\nwithin multi-agent system settings independently, our work presented in this\nreview paper focuses on highlighting the integration of DRL-based approaches in\nMAPF. Moreover, we aim to bridge the current gap in evaluating MAPF solutions\nby addressing the lack of unified evaluation metrics and providing\ncomprehensive clarification on these metrics. Finally, our paper discusses the\npotential of model-based DRL as a promising future direction and provides its\nrequired foundational understanding to address current challenges in MAPF. Our\nobjective is to assist readers in gaining insight into the current research\ndirection, providing unified metrics for comparing different MAPF algorithms\nand expanding their knowledge of model-based DRL to address the existing\nchallenges in MAPF.",
            "author": [
                "Jaehoon Chung",
                "Jamil Fayyad",
                "Younes Al Younes",
                "Homayoun Najjaran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05893v1",
                "http://arxiv.org/pdf/2308.05893v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05889v1",
            "title": "DF2: Distribution-Free Decision-Focused Learning",
            "updated": "2023-08-11T00:44:46Z",
            "published": "2023-08-11T00:44:46Z",
            "summary": "Decision-focused learning (DFL) has recently emerged as a powerful approach\nfor predict-then-optimize problems by customizing a predictive model to a\ndownstream optimization task. However, existing end-to-end DFL methods are\nhindered by three significant bottlenecks: model mismatch error, sample average\napproximation error, and gradient approximation error. Model mismatch error\nstems from the misalignment between the model's parameterized predictive\ndistribution and the true probability distribution. Sample average\napproximation error arises when using finite samples to approximate the\nexpected optimization objective. Gradient approximation error occurs as DFL\nrelies on the KKT condition for exact gradient computation, while most methods\napproximate the gradient for backpropagation in non-convex objectives. In this\npaper, we present DF2 -- the first \\textit{distribution-free} decision-focused\nlearning method explicitly designed to address these three bottlenecks. Rather\nthan depending on a task-specific forecaster that requires precise model\nassumptions, our method directly learns the expected optimization function\nduring training. To efficiently learn the function in a data-driven manner, we\ndevise an attention-based model architecture inspired by the distribution-based\nparameterization of the expected objective. Our method is, to the best of our\nknowledge, the first to address all three bottlenecks within a single model. We\nevaluate DF2 on a synthetic problem, a wind power bidding problem, and a\nnon-convex vaccine distribution problem, demonstrating the effectiveness of\nDF2.",
            "author": [
                "Lingkai Kong",
                "Wenhao Mu",
                "Jiaming Cui",
                "Yuchen Zhuang",
                "B. Aditya Prakash",
                "Bo Dai",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05889v1",
                "http://arxiv.org/pdf/2308.05889v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05883v1",
            "title": "Empirical Bayes Estimation with Side Information: A Nonparametric\n  Integrative Tweedie Approach",
            "updated": "2023-08-11T00:24:45Z",
            "published": "2023-08-11T00:24:45Z",
            "summary": "We investigate the problem of compound estimation of normal means while\naccounting for the presence of side information. Leveraging the empirical Bayes\nframework, we develop a nonparametric integrative Tweedie (NIT) approach that\nincorporates structural knowledge encoded in multivariate auxiliary data to\nenhance the precision of compound estimation. Our approach employs convex\noptimization tools to estimate the gradient of the log-density directly,\nenabling the incorporation of structural constraints. We conduct theoretical\nanalyses of the asymptotic risk of NIT and establish the rate at which NIT\nconverges to the oracle estimator. As the dimension of the auxiliary data\nincreases, we accurately quantify the improvements in estimation risk and the\nassociated deterioration in convergence rate. The numerical performance of NIT\nis illustrated through the analysis of both simulated and real data,\ndemonstrating its superiority over existing methods.",
            "author": [
                "Jiajun Luo",
                "Trambak Banerjee",
                "Gourab Mukherjee",
                "Wenguang Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05883v1",
                "http://arxiv.org/pdf/2308.05883v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05882v1",
            "title": "GPLaSDI: Gaussian Process-based Interpretable Latent Space Dynamics\n  Identification through Deep Autoencoder",
            "updated": "2023-08-10T23:54:12Z",
            "published": "2023-08-10T23:54:12Z",
            "summary": "Numerically solving partial differential equations (PDEs) can be challenging\nand computationally expensive. This has led to the development of reduced-order\nmodels (ROMs) that are accurate but faster than full order models (FOMs).\nRecently, machine learning advances have enabled the creation of non-linear\nprojection methods, such as Latent Space Dynamics Identification (LaSDI). LaSDI\nmaps full-order PDE solutions to a latent space using autoencoders and learns\nthe system of ODEs governing the latent space dynamics. By interpolating and\nsolving the ODE system in the reduced latent space, fast and accurate ROM\npredictions can be made by feeding the predicted latent space dynamics into the\ndecoder. In this paper, we introduce GPLaSDI, a novel LaSDI-based framework\nthat relies on Gaussian process (GP) for latent space ODE interpolations. Using\nGPs offers two significant advantages. First, it enables the quantification of\nuncertainty over the ROM predictions. Second, leveraging this prediction\nuncertainty allows for efficient adaptive training through a greedy selection\nof additional training data points. This approach does not require prior\nknowledge of the underlying PDEs. Consequently, GPLaSDI is inherently\nnon-intrusive and can be applied to problems without a known PDE or its\nresidual. We demonstrate the effectiveness of our approach on the Burgers\nequation, Vlasov equation for plasma physics, and a rising thermal bubble\nproblem. Our proposed method achieves between 200 and 100,000 times speed-up,\nwith up to 7% relative error.",
            "author": [
                "Christophe Bonneville",
                "Youngsoo Choi",
                "Debojyoti Ghosh",
                "Jonathan L. Belof"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05882v1",
                "http://arxiv.org/pdf/2308.05882v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05880v1",
            "title": "Smart Data Mapping for Connecting Power System Model and Geospatial Data",
            "updated": "2023-08-10T23:46:53Z",
            "published": "2023-08-10T23:46:53Z",
            "summary": "Knowing the geospatial locations of power system model elements and linking\nload models with end users and their communities are the foundation for\nanalyzing system resilience and vulnerability to natural hazards. However,\npower system models and geospatial data for power grid assets are often\ndeveloped asynchronously without close coordination. Creating a direct mapping\nbetween the two is a challenging task, mainly due to heterogeneous data\nstructures, target uses, historical legacies, and human errors. This work aims\nto build an automatic data mapping workflow to connect the two, and to support\nenergy grid resilience studies for Puerto Rico. The primary steps in this\nworkflow include constructing graphs using geospatial data, and aligning them\nto the transmission networks defined in the power system data. The results have\nbeen evaluated against existing manual mapping practices for part of the Puerto\nRico Power Grid model to illustrate the performance of such auto-mapping\nsolutions.",
            "author": [
                "Xue Li",
                "Kishan Prudhvi Guddanti",
                "Samrat Acharya",
                "Patrick Royer",
                "Xiaoyuan Fan",
                "Marcelo Elizondo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05880v1",
                "http://arxiv.org/pdf/2308.05880v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06290v1",
            "title": "Are We Closing the Loop Yet? Gaps in the Generalizability of VIS4ML\n  Research",
            "updated": "2023-08-10T21:44:48Z",
            "published": "2023-08-10T21:44:48Z",
            "summary": "Visualization for machine learning (VIS4ML) research aims to help experts\napply their prior knowledge to develop, understand, and improve the performance\nof machine learning models. In conceiving VIS4ML systems, researchers\ncharacterize the nature of human knowledge to support human-in-the-loop tasks,\ndesign interactive visualizations to make ML components interpretable and\nelicit knowledge, and evaluate the effectiveness of human-model interchange. We\nsurvey recent VIS4ML papers to assess the generalizability of research\ncontributions and claims in enabling human-in-the-loop ML. Our results show\npotential gaps between the current scope of VIS4ML research and aspirations for\nits use in practice. We find that while papers motivate that VIS4ML systems are\napplicable beyond the specific conditions studied, conclusions are often\noverfitted to non-representative scenarios, are based on interactions with a\nsmall set of ML experts and well-understood datasets, fail to acknowledge\ncrucial dependencies, and hinge on decisions that lack justification. We\ndiscuss approaches to close the gap between aspirations and research claims and\nsuggest documentation practices to report generality constraints that better\nacknowledge the exploratory nature of VIS4ML research.",
            "author": [
                "Hariharan Subramonyam",
                "Jessica Hullman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06290v1",
                "http://arxiv.org/pdf/2308.06290v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05859v2",
            "title": "Posiform Planting: Generating QUBO Instances for Benchmarking",
            "updated": "2023-10-29T02:04:17Z",
            "published": "2023-08-10T21:23:41Z",
            "summary": "We are interested in benchmarking both quantum annealing and classical\nalgorithms for minimizing Quadratic Unconstrained Binary Optimization (QUBO)\nproblems. Such problems are NP-hard in general, implying that the exact minima\nof randomly generated instances are hard to find and thus typically unknown.\nWhile brute forcing smaller instances is possible, such instances are typically\nnot interesting due to being too easy for both quantum and classical\nalgorithms. In this contribution, we propose a novel method, called posiform\nplanting, for generating random QUBO instances of arbitrary size with known\noptimal solutions, and use those instances to benchmark the sampling quality of\nfour D-Wave quantum annealers utilizing different interconnection structures\n(Chimera, Pegasus, and Zephyr hardware graphs) as well as the simulated\nannealing algorithm. Posiform planting differs from many existing methods in\ntwo key ways. It ensures the uniqueness of the planted optimal solution, thus\navoiding groundstate degeneracy, and it enables the generation of QUBOs that\nare tailored to a given hardware connectivity structure, provided that the\nconnectivity is not too sparse. Posiform planted QUBOs are a type of 2-SAT\nboolean satisfiability combinatorial optimization problems. Our experiments\ndemonstrate the capability of the D-Wave quantum annealers to sample the\noptimal planted solution of combinatorial optimization problems with up to\n$5627$ qubits.",
            "author": [
                "Georg Hahn",
                "Elijah Pelofske",
                "Hristo N. Djidjev"
            ],
            "link": [
                "http://dx.doi.org/10.3389/fcomp.2023.1275948",
                "http://arxiv.org/abs/2308.05859v2",
                "http://arxiv.org/pdf/2308.05859v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech",
                "cs.ET",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05857v1",
            "title": "Knowledge Propagation over Conditional Independence Graphs",
            "updated": "2023-08-10T21:06:18Z",
            "published": "2023-08-10T21:06:18Z",
            "summary": "Conditional Independence (CI) graph is a special type of a Probabilistic\nGraphical Model (PGM) where the feature connections are modeled using an\nundirected graph and the edge weights show the partial correlation strength\nbetween the features. Since the CI graphs capture direct dependence between\nfeatures, they have been garnering increasing interest within the research\ncommunity for gaining insights into the systems from various domains, in\nparticular discovering the domain topology. In this work, we propose algorithms\nfor performing knowledge propagation over the CI graphs. Our experiments\ndemonstrate that our techniques improve upon the state-of-the-art on the\npublicly available Cora and PubMed datasets.",
            "author": [
                "Urszula Chajewska",
                "Harsh Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05857v1",
                "http://arxiv.org/pdf/2308.05857v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05851v1",
            "title": "SegDA: Maximum Separable Segment Mask with Pseudo Labels for Domain\n  Adaptive Semantic Segmentation",
            "updated": "2023-08-10T20:35:48Z",
            "published": "2023-08-10T20:35:48Z",
            "summary": "Unsupervised Domain Adaptation (UDA) aims to solve the problem of label\nscarcity of the target domain by transferring the knowledge from the label rich\nsource domain. Usually, the source domain consists of synthetic images for\nwhich the annotation is easily obtained using the well known computer graphics\ntechniques. However, obtaining annotation for real world images (target domain)\nrequire lot of manual annotation effort and is very time consuming because it\nrequires per pixel annotation. To address this problem we propose SegDA module\nto enhance transfer performance of UDA methods by learning the maximum\nseparable segment representation. This resolves the problem of identifying\nvisually similar classes like pedestrian/rider, sidewalk/road etc. We leveraged\nEquiangular Tight Frame (ETF) classifier inspired from Neural Collapse for\nmaximal separation between segment classes. This causes the source domain pixel\nrepresentation to collapse to a single vector forming a simplex vertices which\nare aligned to the maximal separable ETF classifier. We use this phenomenon to\npropose the novel architecture for domain adaptation of segment representation\nfor target domain. Additionally, we proposed to estimate the noise in labelling\nthe target domain images and update the decoder for noise correction which\nencourages the discovery of pixels for classes not identified in pseudo labels.\nWe have used four UDA benchmarks simulating synthetic-to-real,\ndaytime-to-nighttime, clear-to-adverse weather scenarios. Our proposed approach\noutperforms +2.2 mIoU on GTA -> Cityscapes, +2.0 mIoU on Synthia -> Cityscapes,\n+5.9 mIoU on Cityscapes -> DarkZurich, +2.6 mIoU on Cityscapes -> ACDC.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05851v1",
                "http://arxiv.org/pdf/2308.05851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05828v2",
            "title": "DiLogics: Creating Web Automation Programs With Diverse Logics",
            "updated": "2023-08-18T15:33:39Z",
            "published": "2023-08-10T19:01:30Z",
            "summary": "Knowledge workers frequently encounter repetitive web data entry tasks, like\nupdating records or placing orders. Web automation increases productivity, but\ntranslating tasks to web actions accurately and extending to new specifications\nis challenging. Existing tools can automate tasks that perform the same logical\ntrace of UI actions (e.g., input text in each field in order), but do not\nsupport tasks requiring different executions based on varied input conditions.\nWe present DiLogics, a programming-by-demonstration system that utilizes NLP to\nassist users in creating web automation programs that handle diverse\nspecifications. DiLogics first semantically segments input data to structured\ntask steps. By recording user demonstrations for each step, DiLogics\ngeneralizes the web macros to novel but semantically similar task requirements.\nOur evaluation showed that non-experts can effectively use DiLogics to create\nautomation programs that fulfill diverse input instructions. DiLogics provides\nan efficient, intuitive, and expressive method for developing web automation\nprograms satisfying diverse specifications.",
            "author": [
                "Kevin Pu",
                "Jim Yang",
                "Angel Yuan",
                "Minyi Ma",
                "Rui Dong",
                "Xinyu Wang",
                "Yan Chen",
                "Tovi Grossman"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3586183.3606822",
                "http://arxiv.org/abs/2308.05828v2",
                "http://arxiv.org/pdf/2308.05828v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05823v1",
            "title": "Vibrational Stabilization of Complex Network Systems",
            "updated": "2023-08-10T18:49:02Z",
            "published": "2023-08-10T18:49:02Z",
            "summary": "Many natural and man-made network systems need to maintain certain patterns,\nsuch as working at equilibria or limit cycles, to function properly. Thus, the\nability to stabilize such patterns is crucial. Most of the existing studies on\nstabilization assume that network systems states can be measured online so that\nfeedback control strategies can be used. However, in many real-world scenarios,\nsystems states, e.g., neuronal activity in the brain, are often difficult to\nmeasure. In this paper, we take this situation into account and study the\nstabilization problem of linear network systems with an open-loop control\nstrategy (vibrational control). We derive a graph-theoretic sufficient\ncondition for structural vibrational stabilizability, under which network\nsystems can always be stabilized. We further provide an approach to select the\nlocations in the network for control placement and design corresponding\nvibrational inputs to stabilize systems that satisfy this condition. Finally,\nwe provide some numerical results that demonstrate the validity of our\ntheoretical findings.",
            "author": [
                "Alberto Maria Nobili",
                "Yuzhen Qin",
                "Carlo Alberto Avizzano",
                "Danielle S. Bassett",
                "Fabio Pasqualetti"
            ],
            "link": [
                "http://dx.doi.org/10.23919/ACC55779.2023.10156032",
                "http://arxiv.org/abs/2308.05823v1",
                "http://arxiv.org/pdf/2308.05823v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05817v2",
            "title": "Comparing Width Parameters on Graph Classes",
            "updated": "2023-11-27T10:12:36Z",
            "published": "2023-08-10T18:34:18Z",
            "summary": "We study how the relationship between non-equivalent width parameters changes\nonce we restrict to some special graph class. As width parameters, we consider\ntreewidth, clique-width, twin-width, mim-width, sim-width and tree-independence\nnumber, whereas as graph classes we consider $K_{t,t}$-subgraph-free graphs,\nline graphs and their common superclass, for $t \\geq 3$, of $K_{t,t}$-free\ngraphs.\n  We first provide a complete comparison when restricted to\n$K_{t,t}$-subgraph-free graphs, showing in particular that treewidth,\nclique-width, mim-width, sim-width and tree-independence number are all\nequivalent. This extends a result of Gurski and Wanke (2000) stating that\ntreewidth and clique-width are equivalent for the class of\n$K_{t,t}$-subgraph-free graphs.\n  Next, we provide a complete comparison when restricted to line graphs,\nshowing in particular that, on any class of line graphs, clique-width,\nmim-width, sim-width and tree-independence number are all equivalent, and\nbounded if and only if the class of root graphs has bounded treewidth. This\nextends a result of Gurski and Wanke (2007) stating that a class of graphs\n${\\cal G}$ has bounded treewidth if and only if the class of line graphs of\ngraphs in ${\\cal G}$ has bounded clique-width.\n  We then provide an almost-complete comparison for $K_{t,t}$-free graphs,\nleaving one missing case. Our main result is that $K_{t,t}$-free graphs of\nbounded mim-width have bounded tree-independence number. This result has\nstructural and algorithmic consequences. In particular, it proves a special\ncase of a conjecture of Dallard, Milani\\v{c} and \\v{S}torgel.\n  Finally, we consider the question of whether boundedness of a certain width\nparameter is preserved under graph powers. We show that the question has a\npositive answer for sim-width precisely in the case of odd powers.",
            "author": [
                "Nick Brettell",
                "Andrea Munaro",
                "Dani\u00ebl Paulusma",
                "Shizhou Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05817v2",
                "http://arxiv.org/pdf/2308.05817v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05707v2",
            "title": "Shadow Datasets, New challenging datasets for Causal Representation\n  Learning",
            "updated": "2023-08-11T19:24:36Z",
            "published": "2023-08-10T17:14:07Z",
            "summary": "Discovering causal relations among semantic factors is an emergent topic in\nrepresentation learning. Most causal representation learning (CRL) methods are\nfully supervised, which is impractical due to costly labeling. To resolve this\nrestriction, weakly supervised CRL methods were introduced. To evaluate CRL\nperformance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and\nCelebA(SMILE), are utilized. However, existing CRL datasets are limited to\nsimple graphs with few generative factors. Thus we propose two new datasets\nwith a larger number of diverse generative factors and more sophisticated\ncausal graphs. In addition, current real datasets, CelebA(BEARD) and\nCelebA(SMILE), the originally proposed causal graphs are not aligned with the\ndataset distributions. Thus, we propose modifications to them.",
            "author": [
                "Jiageng Zhu",
                "Hanchen Xie",
                "Jianhua Wu",
                "Jiazhi Li",
                "Mahyar Khayatkhoei",
                "Mohamed E. Hussein",
                "Wael AbdAlmageed"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05707v2",
                "http://arxiv.org/pdf/2308.05707v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05705v2",
            "title": "Loop Amplitudes in the Coulomb Branch of $\\mathcal{N}=4$\n  Super-Yang-Mills Theory",
            "updated": "2023-10-18T12:40:43Z",
            "published": "2023-08-10T17:08:31Z",
            "summary": "We study four point loop amplitudes at an arbitrary point in the Coulomb\nbranch of $\\mathcal{N}=4$ super-Yang-Mills theory. We study two particle\nunitary cuts up to four loop order. We explicitly verify that bubble and\ntriangle graphs do not contribute at one loop level and show that the results\nhold at higher loop level as well. We also write down an all loop recursion\nrelation for two particle reducible graphs for four point amplitudes.",
            "author": [
                "Md. Abhishek",
                "Subramanya Hegde",
                "Dileep P. Jatkar",
                "Arnab Priya Saha",
                "Amit Suthar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05705v2",
                "http://arxiv.org/pdf/2308.05705v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05697v2",
            "title": "SSLRec: A Self-Supervised Learning Framework for Recommendation",
            "updated": "2023-10-21T09:31:17Z",
            "published": "2023-08-10T16:59:36Z",
            "summary": "Self-supervised learning (SSL) has gained significant interest in recent\nyears as a solution to address the challenges posed by sparse and noisy data in\nrecommender systems. Despite the growing number of SSL algorithms designed to\nprovide state-of-the-art performance in various recommendation scenarios (e.g.,\ngraph collaborative filtering, sequential recommendation, social\nrecommendation, KG-enhanced recommendation), there is still a lack of unified\nframeworks that integrate recommendation algorithms across different domains.\nSuch a framework could serve as the cornerstone for self-supervised\nrecommendation algorithms, unifying the validation of existing methods and\ndriving the design of new ones. To address this gap, we introduce SSLRec, a\nnovel benchmark platform that provides a standardized, flexible, and\ncomprehensive framework for evaluating various SSL-enhanced recommenders. The\nSSLRec framework features a modular architecture that allows users to easily\nevaluate state-of-the-art models and a complete set of data augmentation and\nself-supervised toolkits to help create SSL recommendation models with specific\nneeds. Furthermore, SSLRec simplifies the process of training and evaluating\ndifferent recommendation models with consistent and fair settings. Our SSLRec\nplatform covers a comprehensive set of state-of-the-art SSL-enhanced\nrecommendation models across different scenarios, enabling researchers to\nevaluate these cutting-edge models and drive further innovation in the field.\nOur implemented SSLRec framework is available at the source code repository\nhttps://github.com/HKUDS/SSLRec.",
            "author": [
                "Xubin Ren",
                "Lianghao Xia",
                "Yuhao Yang",
                "Wei Wei",
                "Tianle Wang",
                "Xuheng Cai",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05697v2",
                "http://arxiv.org/pdf/2308.05697v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05693v2",
            "title": "Limitations of Game Comonads via Homomorphism Indistinguishability",
            "updated": "2023-09-13T14:10:35Z",
            "published": "2023-08-10T16:54:12Z",
            "summary": "Abramsky, Dawar, and Wang (2017) introduced the pebbling comonad for\nk-variable counting logic and thereby initiated a line of work that imports\ncategory theoretic machinery to finite model theory. Such game comonads have\nbeen developed for various logics, yielding characterisations of logical\nequivalences in terms of isomorphisms in the associated co-Kleisli category. We\nshow a first limitation of this approach by studying linear-algebraic logic,\nwhich is strictly more expressive than first-order counting logic and whose\nk-variable logical equivalence relations are known as invertible-map\nequivalences (IM). We show that there exists no finite-rank comonad on the\ncategory of graphs whose co-Kleisli isomorphisms characterise IM-equivalence,\nanswering a question of \\'O Conghaile and Dawar (CSL 2021). We obtain this\nresult by ruling out a characterisation of IM-equivalence in terms of\nhomomorphism indistinguishability and employing the Lov\\'asz-type theorems for\ngame comonads established by Dawar, Jakl, and Reggio (2021). Two graphs are\nhomomorphism indistinguishable over a graph class if they admit the same number\nof homomorphisms from every graph in the class. The IM-equivalences cannot be\ncharacterised in this way, neither when counting homomorphisms in the natural\nnumbers, nor in any finite prime field.",
            "author": [
                "Moritz Lichter",
                "Benedikt Pago",
                "Tim Seppelt"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05693v2",
                "http://arxiv.org/pdf/2308.05693v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05688v1",
            "title": "Counting geodesics between surface triangulations",
            "updated": "2023-08-10T16:41:52Z",
            "published": "2023-08-10T16:41:52Z",
            "summary": "Given a surface $\\Sigma$ equipped with a set $P$ of marked points, we\nconsider the triangulations of $\\Sigma$ with vertex set $P$. The flip-graph of\n$\\Sigma$ whose vertices are these triangulations, and whose edges correspond to\nflipping arcs appears in the study of moduli spaces and mapping class groups.\nWe consider the number of geodesics in the flip-graph of $\\Sigma$ between two\ntriangulations as a function of their distance. We show that this number grows\nexponentially provided the surface has enough topology, and that in the\nremaining cases the growth is polynomial.",
            "author": [
                "Hugo Parlier",
                "Lionel Pournin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05688v1",
                "http://arxiv.org/pdf/2308.05688v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "cs.CG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05681v2",
            "title": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action\n  Recognition with Skeleton-Motion-Informed Gradient",
            "updated": "2023-08-18T15:34:40Z",
            "published": "2023-08-10T16:34:20Z",
            "summary": "Recently, methods for skeleton-based human activity recognition have been\nshown to be vulnerable to adversarial attacks. However, these attack methods\nrequire either the full knowledge of the victim (i.e. white-box attacks),\naccess to training data (i.e. transfer-based attacks) or frequent model queries\n(i.e. black-box attacks). All their requirements are highly restrictive,\nraising the question of how detrimental the vulnerability is. In this paper, we\nshow that the vulnerability indeed exists. To this end, we consider a new\nattack task: the attacker has no access to the victim model or the training\ndata or labels, where we coin the term hard no-box attack. Specifically, we\nfirst learn a motion manifold where we define an adversarial loss to compute a\nnew gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our\ngradient contains information of the motion dynamics, which is different from\nexisting gradient-based attack methods that compute the loss gradient assuming\neach dimension in the data is independent. The SMI gradient can augment many\ngradient-based attack methods, leading to a new family of no-box attack\nmethods. Extensive evaluation and comparison show that our method imposes a\nreal threat to existing classifiers. They also show that the SMI gradient\nimproves the transferability and imperceptibility of adversarial samples in\nboth no-box and transfer-based black-box settings.",
            "author": [
                "Zhengzhi Lu",
                "He Wang",
                "Ziyi Chang",
                "Guoan Yang",
                "Hubert P. H. Shum"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05681v2",
                "http://arxiv.org/pdf/2308.05681v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05675v2",
            "title": "Erd\u0151s-Gy\u00e1rf\u00e1s Conjecture for $P_{10}$-free Graphs",
            "updated": "2023-08-12T03:38:34Z",
            "published": "2023-08-10T16:23:39Z",
            "summary": "Let $P_{10}$ be a path on $10$ vertices. A graph is said to be $P_{10}$-free\nif it does not contain $P_{10}$ as an induced subgraph. The well-known\nErd\\H{o}s-Gy\\'{a}rf\\'{a}s Conjecture states that every graph with minimum\ndegree at least three has a cycle whose length is a power of $2$. In this\npaper, we show that every $P_{10}$-free graph with minimum degree at least\nthree contains a cycle of length $4$ or $8$. This implies that the conjecture\nis true for $P_{10}$-free graphs.",
            "author": [
                "Zhiquan Hu",
                "Changlong Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05675v2",
                "http://arxiv.org/pdf/2308.05675v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C38, 05C75"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05648v2",
            "title": "Counterfactual Cross-modality Reasoning for Weakly Supervised Video\n  Moment Localization",
            "updated": "2023-10-14T16:16:31Z",
            "published": "2023-08-10T15:45:45Z",
            "summary": "Video moment localization aims to retrieve the target segment of an untrimmed\nvideo according to the natural language query. Weakly supervised methods gains\nattention recently, as the precise temporal location of the target segment is\nnot always available. However, one of the greatest challenges encountered by\nthe weakly supervised method is implied in the mismatch between the video and\nlanguage induced by the coarse temporal annotations. To refine the\nvision-language alignment, recent works contrast the cross-modality\nsimilarities driven by reconstructing masked queries between positive and\nnegative video proposals. However, the reconstruction may be influenced by the\nlatent spurious correlation between the unmasked and the masked parts, which\ndistorts the restoring process and further degrades the efficacy of contrastive\nlearning since the masked words are not completely reconstructed from the\ncross-modality knowledge. In this paper, we discover and mitigate this spurious\ncorrelation through a novel proposed counterfactual cross-modality reasoning\nmethod. Specifically, we first formulate query reconstruction as an aggregated\ncausal effect of cross-modality and query knowledge. Then by introducing\ncounterfactual cross-modality knowledge into this aggregation, the spurious\nimpact of the unmasked part contributing to the reconstruction is explicitly\nmodeled. Finally, by suppressing the unimodal effect of masked query, we can\nrectify the reconstructions of video proposals to perform reasonable\ncontrastive learning. Extensive experimental evaluations demonstrate the\neffectiveness of our proposed method. The code is available at\n\\href{https://github.com/sLdZ0306/CCR}{https://github.com/sLdZ0306/CCR}.",
            "author": [
                "Zezhong Lv",
                "Bing Su",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05648v2",
                "http://arxiv.org/pdf/2308.05648v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05634v1",
            "title": "Tracing the Influence of Predecessors on Trajectory Prediction",
            "updated": "2023-08-10T15:24:37Z",
            "published": "2023-08-10T15:24:37Z",
            "summary": "In real-world traffic scenarios, agents such as pedestrians and car drivers\noften observe neighboring agents who exhibit similar behavior as examples and\nthen mimic their actions to some extent in their own behavior. This information\ncan serve as prior knowledge for trajectory prediction, which is unfortunately\nlargely overlooked in current trajectory prediction models. This paper\nintroduces a novel Predecessor-and-Successor (PnS) method that incorporates a\npredecessor tracing module to model the influence of predecessors (identified\nfrom concurrent neighboring agents) on the successor (target agent) within the\nsame scene. The method utilizes the moving patterns of these predecessors to\nguide the predictor in trajectory prediction. PnS effectively aligns the motion\nencodings of the successor with multiple potential predecessors in a\nprobabilistic manner, facilitating the decoding process. We demonstrate the\neffectiveness of PnS by integrating it into a graph-based predictor for\npedestrian trajectory prediction on the ETH/UCY datasets, resulting in a new\nstate-of-the-art performance. Furthermore, we replace the HD map-based\nscene-context module with our PnS method in a transformer-based predictor for\nvehicle trajectory prediction on the nuScenes dataset, showing that the\npredictor maintains good prediction performance even without relying on any map\ninformation.",
            "author": [
                "Mengmeng Liu",
                "Hao Cheng",
                "Michael Ying Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05634v1",
                "http://arxiv.org/pdf/2308.05634v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05609v1",
            "title": "LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition",
            "updated": "2023-08-10T14:41:17Z",
            "published": "2023-08-10T14:41:17Z",
            "summary": "Biomedical Natural Language Processing (NLP) tends to become cumbersome for\nmost researchers, frequently due to the amount and heterogeneity of text to be\nprocessed. To address this challenge, the industry is continuously developing\nhighly efficient tools and creating more flexible engineering solutions. This\nwork presents the integration between industry data engineering solutions for\nefficient data processing and academic systems developed for Named Entity\nRecognition (LasigeUnicage\\_NER) and Relation Extraction (BiOnt). Our design\nreflects an integration of those components with external knowledge in the form\nof additional training data from other datasets and biomedical ontologies. We\nused this pipeline in the 2022 LitCoin NLP Challenge, where our team\nLasigeUnicage was awarded the 7th Prize out of approximately 200 participating\nteams, reflecting a successful collaboration between the academia (LASIGE) and\nthe industry (Unicage). The software supporting this work is available at\n\\url{https://github.com/lasigeBioTM/Litcoin-Lasige_Unicage}.",
            "author": [
                "Pedro Ruas",
                "Diana F. Sousa",
                "Andr\u00e9 Neves",
                "Carlos Cruz",
                "Francisco M. Couto"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05609v1",
                "http://arxiv.org/pdf/2308.05609v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05601v1",
            "title": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow\n  Prediction",
            "updated": "2023-08-10T14:20:43Z",
            "published": "2023-08-10T14:20:43Z",
            "summary": "Inter-city highway transportation is significant for urban life. As one of\nthe key functions in intelligent transportation system (ITS), traffic\nevaluation always plays significant role nowadays, and daily traffic flow\nprediction still faces challenges at network-wide toll stations. On the one\nhand, the data imbalance in practice among various locations deteriorates the\nperformance of prediction. On the other hand, complex correlative\nspatio-temporal factors cannot be comprehensively employed in long-term\nduration. In this paper, a prediction method is proposed for daily traffic flow\nin highway domain through spatio-temporal deep learning. In our method, data\nnormalization strategy is used to deal with data imbalance, due to long-tail\ndistribution of traffic flow at network-wide toll stations. And then, based on\ngraph convolutional network, we construct networks in distinct semantics to\ncapture spatio-temporal features. Beside that, meteorology and calendar\nfeatures are used by our model in the full connection stage to extra external\ncharacteristics of traffic flow. By extensive experiments and case studies in\none Chinese provincial highway, our method shows clear improvement in\npredictive accuracy than baselines and practical benefits in business.",
            "author": [
                "Weilong Ding",
                "Tianpu Zhang",
                "Jianwu Wang",
                "Zhuofeng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05601v1",
                "http://arxiv.org/pdf/2308.05601v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05593v1",
            "title": "Robust Lifelong Indoor LiDAR Localization using the Area Graph",
            "updated": "2023-08-10T14:03:48Z",
            "published": "2023-08-10T14:03:48Z",
            "summary": "Lifelong indoor localization in a given map is the basis for navigation of\nautonomous mobile robots. In this letter, we address the problem of robust\nlocalization in cluttered indoor environments like office spaces and corridors\nusing 3D LiDAR point clouds in a given Area Graph, which is a hierarchical,\ntopometric semantic map representation that uses polygons to demark areas such\nas rooms, corridors or buildings. This representation is very compact, can\nrepresent different floors of buildings through its hierarchy and provides\nsemantic information that helps with localization, like poses of doors and\nglass. In contrast to this, commonly used map representations, such as\noccupancy grid maps or point clouds, lack these features and require frequent\nupdates in response to environmental changes (e.g. moved furniture), unlike our\napproach, which matches against lifelong architectural features such as walls\nand doors. For that we apply filtering to remove clutter from the 3D input\npoint cloud and then employ further scoring and weight functions for\nlocalization. Given a broad initial guess from WiFi localization, our\nexperiments show that our global localization and the weighted point to line\nICP pose tracking perform very well, even when compared to localization and\nSLAM algorithms that use the current, feature-rich cluttered map for\nlocalization.",
            "author": [
                "Fujing Xie",
                "S\u00f6ren Schwertfeger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05593v1",
                "http://arxiv.org/pdf/2308.05593v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05575v1",
            "title": "Symmetry Defense Against XGBoost Adversarial Perturbation Attacks",
            "updated": "2023-08-10T13:39:19Z",
            "published": "2023-08-10T13:39:19Z",
            "summary": "We examine whether symmetry can be used to defend tree-based ensemble\nclassifiers such as gradient-boosting decision trees (GBDTs) against\nadversarial perturbation attacks. The idea is based on a recent symmetry\ndefense for convolutional neural network classifiers (CNNs) that utilizes CNNs'\nlack of invariance with respect to symmetries. CNNs lack invariance because\nthey can classify a symmetric sample, such as a horizontally flipped image,\ndifferently from the original sample. CNNs' lack of invariance also means that\nCNNs can classify symmetric adversarial samples differently from the incorrect\nclassification of adversarial samples. Using CNNs' lack of invariance, the\nrecent CNN symmetry defense has shown that the classification of symmetric\nadversarial samples reverts to the correct sample classification. In order to\napply the same symmetry defense to GBDTs, we examine GBDT invariance and are\nthe first to show that GBDTs also lack invariance with respect to symmetries.\nWe apply and evaluate the GBDT symmetry defense for nine datasets against six\nperturbation attacks with a threat model that ranges from zero-knowledge to\nperfect-knowledge adversaries. Using the feature inversion symmetry against\nzero-knowledge adversaries, we achieve up to 100% accuracy on adversarial\nsamples even when default and robust classifiers have 0% accuracy. Using the\nfeature inversion and horizontal flip symmetries against perfect-knowledge\nadversaries, we achieve up to over 95% accuracy on adversarial samples for the\nGBDT classifier of the F-MNIST dataset even when default and robust classifiers\nhave 0% accuracy.",
            "author": [
                "Blerta Lindqvist"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05575v1",
                "http://arxiv.org/pdf/2308.05575v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05571v1",
            "title": "Unleashing the Potential of Reconfigurable Intelligent Surfaces in\n  Martian Communication",
            "updated": "2023-08-10T13:33:37Z",
            "published": "2023-08-10T13:33:37Z",
            "summary": "Space exploration has witnessed a steady increase since the 1960s, with Mars\nplaying a significant role in our quest for further knowledge. As the ambition\nto colonize Mars becomes a reality through the collaboration of private\ncompanies and space agencies, the need for reliable and robust communication\ninfrastructures in the Martian environment becomes paramount. In this context,\nreconfigurable intelligent surface (RIS)-empowered communication emerges as a\npromising technology to enhance the coverage and improve the communication\nquality. By considering various Martian scenarios such as canyons, craters,\nmountains, and plateaus, this article explores of the potential of RISs in\nincreasing the coverage in Martian environments, thereby enabling future Mars\nmissions to be more robust and reliable. The article also investigates the\napplication of RIS-assisted localization in both line-of-sight (LOS) and\nnon-line-of-sight (NLOS) scenarios, presenting a general framework for accurate\nuser angle estimation in challenging Martian conditions. The findings and\npresented framework of this article provide a promising research direction for\nintegrating RISs in deep space communication as well as paving the way for\nfuture improvements in interplanetary communication networks.",
            "author": [
                "Enes Koktas",
                "Recep A. Tasci",
                "Ibrahim Yildirim",
                "Ertugrul Basar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05571v1",
                "http://arxiv.org/pdf/2308.05571v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05568v1",
            "title": "An ALMA Glimpse of Dense Molecular Filaments Associated with High-mass\n  Protostellar Systems in the Large Magellanic Cloud",
            "updated": "2023-08-10T13:30:37Z",
            "published": "2023-08-10T13:30:37Z",
            "summary": "Recent millimeter/sub-millimeter facilities have revealed the physical\nproperties of filamentary molecular clouds in relation to high-mass star\nformation. A uniform survey of the nearest, face-on star-forming galaxy, the\nLarge Magellanic Cloud (LMC), complements the Galactic knowledge. We present\nALMA survey data with a spatial resolution of $\\sim$0.1 pc in the 0.87 mm\ncontinuum and HCO$^{+}$(4-3) emission toward 30 protostellar objects with\nluminosities of 10$^4$-10$^{5.5}$ $L_{\\odot}$ in the LMC. The spatial\ndistributions of the HCO$^{+}$(4-3) line and thermal dust emission are well\ncorrelated, indicating that the line effectively traces dense, filamentary gas\nwith an H$_2$ volume density of $\\gtrsim$10$^5$ cm$^{-3}$ and a line mass of\n$\\sim$10$^3$-10$^{4}$ $M_{\\odot}$ pc$^{-1}$. Furthermore, we obtain an increase\nin the velocity linewidths of filamentary clouds, which follows a power-law\ndependence on their H$_2$ column densities with an exponent of $\\sim$0.5. This\ntrend is consistent with observations toward filamentary clouds in nearby\nstar-forming regions withiin $ \\lesssim$1 kpc from us and suggests enhanced\ninternal turbulence within the filaments owing to surrounding gas accretion.\nAmong the 30 sources, we find that 14 are associated with hub-filamentary\nstructures, and these complex structures predominantly appear in protostellar\nluminosities exceeding $\\sim$5 $\\times$10$^4$ $L_{\\odot}$. The hub-filament\nsystems tend to appear in the latest stages of their natal cloud evolution,\noften linked to prominent H$\\;${\\sc ii} regions and numerous stellar clusters.\nOur preliminary statistics suggest that the massive filaments accompanied by\nhub-type complex features may be a necessary intermediate product in forming\nextremely luminous high-mass stellar systems capable of ultimately dispersing\nthe parent cloud.",
            "author": [
                "Kazuki Tokuda",
                "Naoto Harada",
                "Kei E. I. Tanaka",
                "Tsuyoshi Inoue",
                "Takashi Shimonishi",
                "Yichen Zhang",
                "Marta Sewi\u0142o",
                "Yuri Kunitoshi",
                "Ayu Konishi",
                "Yasuo Fukui",
                "Akiko Kawamura",
                "Toshikazu Onishi",
                "Masahiro N. Machida"
            ],
            "link": [
                "http://dx.doi.org/10.3847/1538-4357/acefb7",
                "http://arxiv.org/abs/2308.05568v1",
                "http://arxiv.org/pdf/2308.05568v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05567v1",
            "title": "C5: Towards Better Conversation Comprehension and Contextual Continuity\n  for ChatGPT",
            "updated": "2023-08-10T13:29:12Z",
            "published": "2023-08-10T13:29:12Z",
            "summary": "Large language models (LLMs), such as ChatGPT, have demonstrated outstanding\nperformance in various fields, particularly in natural language understanding\nand generation tasks. In complex application scenarios, users tend to engage in\nmulti-turn conversations with ChatGPT to keep contextual information and obtain\ncomprehensive responses. However, human forgetting and model contextual\nforgetting remain prominent issues in multi-turn conversation scenarios, which\nchallenge the users' conversation comprehension and contextual continuity for\nChatGPT. To address these challenges, we propose an interactive conversation\nvisualization system called C5, which includes Global View, Topic View, and\nContext-associated Q\\&A View. The Global View uses the GitLog diagram metaphor\nto represent the conversation structure, presenting the trend of conversation\nevolution and supporting the exploration of locally salient features. The Topic\nView is designed to display all the question and answer nodes and their\nrelationships within a topic using the structure of a knowledge graph, thereby\ndisplay the relevance and evolution of conversations. The Context-associated\nQ\\&A View consists of three linked views, which allow users to explore\nindividual conversations deeply while providing specific contextual information\nwhen posing questions. The usefulness and effectiveness of C5 were evaluated\nthrough a case study and a user study.",
            "author": [
                "Pan Liang",
                "Danwei Ye",
                "Zihao Zhu",
                "Yunchao Wang",
                "Wang Xia",
                "Ronghua Liang",
                "Guodao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05567v1",
                "http://arxiv.org/pdf/2308.05567v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05561v1",
            "title": "Sullivant-Talaska ideal of the cyclic Gaussian Graphical Model",
            "updated": "2023-08-10T13:21:59Z",
            "published": "2023-08-10T13:21:59Z",
            "summary": "In this paper, we settle a conjecture due to Sturmfels and Uhler concerning\ngeneration of the prime ideal of the variety associated to the Gaussian\ngraphical model of any cycle graph. Our methods are general and applicable to a\nlarge class of ideals with radical initial ideals.",
            "author": [
                "Austin Conner",
                "Kangjin Han",
                "Mateusz Micha\u0142ek"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05561v1",
                "http://arxiv.org/pdf/2308.05561v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.AC",
                "math.CO",
                "math.ST",
                "stat.TH",
                "primary: 62R01, 13P10, 13P25, secondary: 05A10, 05C30, 14M12, 14M20,\n  14N10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05521v1",
            "title": "Checkpoint Placement for Systematic Fault-Injection Campaigns",
            "updated": "2023-08-10T12:03:54Z",
            "published": "2023-08-10T12:03:54Z",
            "summary": "Shrinking hardware structures and decreasing operating voltages lead to an\nincreasing number of transient hardware faults,which thus become a core problem\nto consider for safety-critical systems. Here, systematic fault injection (FI),\nwhere one program-under-test is systematically stressed with faults, provides\nan in-depth resilience analysis in the presence of faults. However, FI\ncampaigns require many independent injection experiments and, combined, long\nrun times, especially if we aim for a high coverage of the fault space. One\ncost factor is the forwarding phase, which is the time required to bring the\nsystem-under test into the fault-free state at injection time. One common\ntechnique to speed up the forwarding are checkpoints of the fault-free system\nstate at fixed points in time.\n  In this paper, we show that the placement of checkpoints has a significant\ninfluence on the required forwarding cycles, especially if we place faults\nnon-uniformly on the time axis. For this, we discuss the checkpoint-selection\nproblem in general, formalize it as a maximum-weight reward path problem in\ngraphs, propose an ILP formulation and a dynamic programming algorithm that\nfind the optimal solution, and provide a heuristic checkpoint-selection method\nbased on a genetic algorithm. Applied to the MiBench benchmark suite, our\napproach consistently reduces the forward-phase cycles by at least 88 percent\nand up to 99.934 percent when placing 16 checkpoints.",
            "author": [
                "Christian Dietrich",
                "Tim-Marek Thomas",
                "Matthias Mnich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05521v1",
                "http://arxiv.org/pdf/2308.05521v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05515v1",
            "title": "Mono-hydra: Real-time 3D scene graph construction from monocular camera\n  input with IMU",
            "updated": "2023-08-10T11:58:38Z",
            "published": "2023-08-10T11:58:38Z",
            "summary": "The ability of robots to autonomously navigate through 3D environments\ndepends on their comprehension of spatial concepts, ranging from low-level\ngeometry to high-level semantics, such as objects, places, and buildings. To\nenable such comprehension, 3D scene graphs have emerged as a robust tool for\nrepresenting the environment as a layered graph of concepts and their\nrelationships. However, building these representations using monocular vision\nsystems in real-time remains a difficult task that has not been explored in\ndepth. This paper puts forth a real-time spatial perception system Mono-Hydra,\ncombining a monocular camera and an IMU sensor setup, focusing on indoor\nscenarios. However, the proposed approach is adaptable to outdoor applications,\noffering flexibility in its potential uses. The system employs a suite of deep\nlearning algorithms to derive depth and semantics. It uses a robocentric\nvisual-inertial odometry (VIO) algorithm based on square-root information,\nthereby ensuring consistent visual odometry with an IMU and a monocular camera.\nThis system achieves sub-20 cm error in real-time processing at 15 fps,\nenabling real-time 3D scene graph construction using a laptop GPU (NVIDIA\n3080). This enhances decision-making efficiency and effectiveness in simple\ncamera setups, augmenting robotic system agility. We make Mono-Hydra publicly\navailable at: https://github.com/UAV-Centre-ITC/Mono_Hydra",
            "author": [
                "U. V. B. L. Udugama",
                "G. Vosselman",
                "F. Nex"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05515v1",
                "http://arxiv.org/pdf/2308.05515v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05514v1",
            "title": "Advanced-Glycation Endproducts: How cross-linking properties affect the\n  collagen fibril behavior",
            "updated": "2023-08-10T11:55:44Z",
            "published": "2023-08-10T11:55:44Z",
            "summary": "Advanced-Glycation-Endproducts (AGEs) are known to be a major cause of\nimpaired tissue material properties. In collagen fibrils, the main building\ncomponent of human tissue, these AGEs appear as fibrillar cross-links. When\nAGEs accumulate in collagen fibrils, a process often caused by diabetes and\naging, the mechanical properties of the collagen fibril are altered. However,\ncurrent knowledge about the mechanical properties of different types of AGEs,\nand their quantity in collagen fibrils is limited owing to the scarcity of\navailable experimental data. Consequently, the precise relationship between the\nnano-scale cross-link properties, their density in collagen fibrils, and the\nmechanical properties of the collagen fibrils at larger scales remains poorly\nunderstood. In our study, we use coarse-grained molecular dynamics simulations\nand perform destructive tensile tests on collagen fibrils to evaluate the\neffect of different cross-link densities and their mechanical properties on\ncollagen fibril deformation and fracture behavior. We observe that the collagen\nfibril stiffens at high strain levels when either the AGEs density or the\nloading energy capacity of AGEs are increased. We demonstrate that this\nstiffening is caused by a mechanism that favors energy absorption via\nstretching rather than inter-molecular sliding. Hence, in cross-linked collagen\nfibrils, the absorbed energy is stored rather than dissipated through friction,\nresulting in brittle fracture upon fibrillar failure. Further, by varying\nmultiple AGEs nano-scale parameters, we show that the AGEs loading energy\ncapacity is, aside from their density in the fibril, the unique factor\ndetermining the effect of different types of AGEs on the mechanical behavior of\ncollagen fibrils. Our results show that knowing AGEs properties is crucial for\nunderstanding of the origin of impaired tissue behavior.",
            "author": [
                "Julia Kamml",
                "Claire Acevedo",
                "David Kammer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05514v1",
                "http://arxiv.org/pdf/2308.05514v1"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05508v2",
            "title": "Multi-domain Recommendation with Embedding Disentangling and Domain\n  Alignment",
            "updated": "2023-08-14T01:48:12Z",
            "published": "2023-08-10T11:41:34Z",
            "summary": "Multi-domain recommendation (MDR) aims to provide recommendations for\ndifferent domains (e.g., types of products) with overlapping users/items and is\ncommon for platforms such as Amazon, Facebook, and LinkedIn that host multiple\nservices. Existing MDR models face two challenges: First, it is difficult to\ndisentangle knowledge that generalizes across domains (e.g., a user likes cheap\nitems) and knowledge specific to a single domain (e.g., a user likes blue\nclothing but not blue cars). Second, they have limited ability to transfer\nknowledge across domains with small overlaps. We propose a new MDR method named\nEDDA with two key components, i.e., embedding disentangling recommender and\ndomain alignment, to tackle the two challenges respectively. In particular, the\nembedding disentangling recommender separates both the model and embedding for\nthe inter-domain part and the intra-domain part, while most existing MDR\nmethods only focus on model-level disentangling. The domain alignment leverages\nrandom walks from graph processing to identify similar user/item pairs from\ndifferent domains and encourages similar user/item pairs to have similar\nembeddings, enhancing knowledge transfer. We compare EDDA with 12\nstate-of-the-art baselines on 3 real datasets. The results show that EDDA\nconsistently outperforms the baselines on all datasets and domains. All\ndatasets and codes are available at https://github.com/Stevenn9981/EDDA.",
            "author": [
                "Wentao Ning",
                "Xiao Yan",
                "Weiwen Liu",
                "Reynold Cheng",
                "Rui Zhang",
                "Bo Tang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614977",
                "http://arxiv.org/abs/2308.05508v2",
                "http://arxiv.org/pdf/2308.05508v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05498v1",
            "title": "Complex Network Effects on the Robustness of Graph Convolutional\n  Networks",
            "updated": "2023-08-10T11:03:11Z",
            "published": "2023-08-10T11:03:11Z",
            "summary": "Vertex classification -- the problem of identifying the class labels of nodes\nin a graph -- has applicability in a wide variety of domains. Examples include\nclassifying subject areas of papers in citation networks or roles of machines\nin a computer network. Vertex classification using graph convolutional networks\nis susceptible to targeted poisoning attacks, in which both graph structure and\nnode attributes can be changed in an attempt to misclassify a target node. This\nvulnerability decreases users' confidence in the learning method and can\nprevent adoption in high-stakes contexts. Defenses have also been proposed,\nfocused on filtering edges before creating the model or aggregating information\nfrom neighbors more robustly. This paper considers an alternative: we leverage\nnetwork characteristics in the training data selection process to improve\nrobustness of vertex classifiers.\n  We propose two alternative methods of selecting training data: (1) to select\nthe highest-degree nodes and (2) to iteratively select the node with the most\nneighbors minimally connected to the training set. In the datasets on which the\noriginal attack was demonstrated, we show that changing the training set can\nmake the network much harder to attack. To maintain a given probability of\nattack success, the adversary must use far more perturbations; often a factor\nof 2--4 over the random training baseline. These training set selection methods\noften work in conjunction with the best recently published defenses to provide\neven greater robustness. While increasing the amount of randomly selected\ntraining data sometimes results in a more robust classifier, the proposed\nmethods increase robustness substantially more. We also run a simulation study\nin which we demonstrate conditions under which each of the two methods\noutperforms the other, controlling for the graph topology, homophily of the\nlabels, and node attributes.",
            "author": [
                "Benjamin A. Miller",
                "Kevin Chan",
                "Tina Eliassi-Rad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05498v1",
                "http://arxiv.org/pdf/2308.05498v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05493v1",
            "title": "Look at the Neighbor: Distortion-aware Unsupervised Domain Adaptation\n  for Panoramic Semantic Segmentation",
            "updated": "2023-08-10T10:47:12Z",
            "published": "2023-08-10T10:47:12Z",
            "summary": "Endeavors have been recently made to transfer knowledge from the labeled\npinhole image domain to the unlabeled panoramic image domain via Unsupervised\nDomain Adaptation (UDA). The aim is to tackle the domain gaps caused by the\nstyle disparities and distortion problem from the non-uniformly distributed\npixels of equirectangular projection (ERP). Previous works typically focus on\ntransferring knowledge based on geometric priors with specially designed\nmulti-branch network architectures. As a result, considerable computational\ncosts are induced, and meanwhile, their generalization abilities are profoundly\nhindered by the variation of distortion among pixels. In this paper, we find\nthat the pixels' neighborhood regions of the ERP indeed introduce less\ndistortion. Intuitively, we propose a novel UDA framework that can effectively\naddress the distortion problems for panoramic semantic segmentation. In\ncomparison, our method is simpler, easier to implement, and more\ncomputationally efficient. Specifically, we propose distortion-aware attention\n(DA) capturing the neighboring pixel distribution without using any geometric\nconstraints. Moreover, we propose a class-wise feature aggregation (CFA) module\nto iteratively update the feature representations with a memory bank. As such,\nthe feature similarity between two domains can be consistently optimized.\nExtensive experiments show that our method achieves new state-of-the-art\nperformance while remarkably reducing 80% parameters.",
            "author": [
                "Xu Zheng",
                "Tianbo Pan",
                "Yunhao Luo",
                "Lin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05493v1",
                "http://arxiv.org/pdf/2308.05493v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05483v2",
            "title": "Quality Diversity under Sparse Reward and Sparse Interaction:\n  Application to Grasping in Robotics",
            "updated": "2023-10-31T10:15:31Z",
            "published": "2023-08-10T10:19:48Z",
            "summary": "Quality-Diversity (QD) methods are algorithms that aim to generate a set of\ndiverse and high-performing solutions to a given problem. Originally developed\nfor evolutionary robotics, most QD studies are conducted on a limited set of\ndomains - mainly applied to locomotion, where the fitness and the behavior\nsignal are dense. Grasping is a crucial task for manipulation in robotics.\nDespite the efforts of many research communities, this task is yet to be\nsolved. Grasping cumulates unprecedented challenges in QD literature: it\nsuffers from reward sparsity, behavioral sparsity, and behavior space\nmisalignment. The present work studies how QD can address grasping. Experiments\nhave been conducted on 15 different methods on 10 grasping domains,\ncorresponding to 2 different robot-gripper setups and 5 standard objects. An\nevaluation framework that distinguishes the evaluation of an algorithm from its\ninternal components has also been proposed for a fair comparison. The obtained\nresults show that MAP-Elites variants that select successful solutions in\npriority outperform all the compared methods on the studied metrics by a large\nmargin. We also found experimental evidence that sparse interaction can lead to\ndeceptive novelty. To our knowledge, the ability to efficiently produce\nexamples of grasping trajectories demonstrated in this work has no precedent in\nthe literature.",
            "author": [
                "J. Huber",
                "F. H\u00e9l\u00e9non",
                "M. Coninx",
                "F. Ben Amar",
                "S. Doncieux"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05483v2",
                "http://arxiv.org/pdf/2308.05483v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05481v2",
            "title": "LLM As DBA",
            "updated": "2023-08-11T07:55:19Z",
            "published": "2023-08-10T10:12:43Z",
            "summary": "Database administrators (DBAs) play a crucial role in managing, maintaining\nand optimizing a database system to ensure data availability, performance, and\nreliability. However, it is hard and tedious for DBAs to manage a large number\nof database instances (e.g., millions of instances on the cloud databases).\nRecently large language models (LLMs) have shown great potential to understand\nvaluable documents and accordingly generate reasonable answers. Thus, we\npropose D-Bot, a LLM-based database administrator that can continuously acquire\ndatabase maintenance experience from textual sources, and provide reasonable,\nwell-founded, in-time diagnosis and optimization advice for target databases.\nThis paper presents a revolutionary LLM-centric framework for database\nmaintenance, including (i) database maintenance knowledge detection from\ndocuments and tools, (ii) tree of thought reasoning for root cause analysis,\nand (iii) collaborative diagnosis among multiple LLMs. Our preliminary\nexperimental results that D-Bot can efficiently and effectively diagnose the\nroot causes and our code is available at\ngithub.com/TsinghuaDatabaseGroup/DB-GPT.",
            "author": [
                "Xuanhe Zhou",
                "Guoliang Li",
                "Zhiyuan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05481v2",
                "http://arxiv.org/pdf/2308.05481v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05471v1",
            "title": "Provably Efficient Algorithm for Nonstationary Low-Rank MDPs",
            "updated": "2023-08-10T09:52:44Z",
            "published": "2023-08-10T09:52:44Z",
            "summary": "Reinforcement learning (RL) under changing environment models many real-world\napplications via nonstationary Markov Decision Processes (MDPs), and hence\ngains considerable interest. However, theoretical studies on nonstationary MDPs\nin the literature have mainly focused on tabular and linear (mixture) MDPs,\nwhich do not capture the nature of unknown representation in deep RL. In this\npaper, we make the first effort to investigate nonstationary RL under episodic\nlow-rank MDPs, where both transition kernels and rewards may vary over time,\nand the low-rank model contains unknown representation in addition to the\nlinear state embedding function. We first propose a parameter-dependent policy\noptimization algorithm called PORTAL, and further improve PORTAL to its\nparameter-free version of Ada-PORTAL, which is able to tune its\nhyper-parameters adaptively without any prior knowledge of nonstationarity. For\nboth algorithms, we provide upper bounds on the average dynamic suboptimality\ngap, which show that as long as the nonstationarity is not significantly large,\nPORTAL and Ada-PORTAL are sample-efficient and can achieve arbitrarily small\naverage dynamic suboptimality gap with polynomial sample complexity.",
            "author": [
                "Yuan Cheng",
                "Jing Yang",
                "Yingbin Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05471v1",
                "http://arxiv.org/pdf/2308.05471v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05467v1",
            "title": "Arithmetic Dijkgraaf-Witten invariants for real quadratic fields,\n  quadratic residue graphs, and density formulas",
            "updated": "2023-08-10T09:45:32Z",
            "published": "2023-08-10T09:45:32Z",
            "summary": "We compute Hirano's formula for the mod 2 arithmetic Dijkgraaf-Witten\ninvariant ${Z}_k$ for the ring of integers of the quadratic field\n$k=\\mathbb{Q}(\\sqrt{p_1\\cdots p_r})$, where ${p_i}$'s are distinct prime\nnumbers with $p_i \\equiv 1 \\pmod{4}$, and give a simple formula for $Z_k$ in\nterms of the graph obtained from quadratic residues among $p_1,\\cdots, p_r$.\nOur result answers the question posed by Ken Ono. We also give a density\nformula for mod 2 arithmetic Dijkgraaf-Witten invariants.",
            "author": [
                "Yuqi Deng",
                "Riku Kurimaru",
                "Toshiki Matsusaka"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05467v1",
                "http://arxiv.org/pdf/2308.05467v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05463v1",
            "title": "$\\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs\n  with Proxy Unknowns",
            "updated": "2023-08-10T09:42:20Z",
            "published": "2023-08-10T09:42:20Z",
            "summary": "Node classification is the task of predicting the labels of unlabeled nodes\nin a graph. State-of-the-art methods based on graph neural networks achieve\nexcellent performance when all labels are available during training. But in\nreal-life, models are often applied on data with new classes, which can lead to\nmassive misclassification and thus significantly degrade performance. Hence,\ndeveloping open-set classification methods is crucial to determine if a given\nsample belongs to a known class. Existing methods for open-set node\nclassification generally use transductive learning with part or all of the\nfeatures of real unseen class nodes to help with open-set classification. In\nthis paper, we propose a novel generative open-set node classification method,\ni.e. $\\mathcal{G}^2Pxy$, which follows a stricter inductive learning setting\nwhere no information about unknown classes is available during training and\nvalidation. Two kinds of proxy unknown nodes, inter-class unknown proxies and\nexternal unknown proxies are generated via mixup to efficiently anticipate the\ndistribution of novel classes. Using the generated proxies, a closed-set\nclassifier can be transformed into an open-set one, by augmenting it with an\nextra proxy classifier. Under the constraints of both cross entropy loss and\ncomplement entropy loss, $\\mathcal{G}^2Pxy$ achieves superior effectiveness for\nunknown class detection and known class classification, which is validated by\nexperiments on benchmark graph datasets. Moreover, $\\mathcal{G}^2Pxy$ does not\nhave specific requirement on the GNN architecture and shows good\ngeneralizations.",
            "author": [
                "Qin Zhang",
                "Zelin Shi",
                "Xiaolin Zhang",
                "Xiaojun Chen",
                "Philippe Fournier-Viger",
                "Shirui Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05463v1",
                "http://arxiv.org/pdf/2308.05463v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05451v1",
            "title": "A Forecaster's Review of Judea Pearl's Causality: Models, Reasoning and\n  Inference, Second Edition, 2009",
            "updated": "2023-08-10T09:17:07Z",
            "published": "2023-08-10T09:17:07Z",
            "summary": "With the big popularity and success of Judea Pearl's original causality book,\nthis review covers the main topics updated in the second edition in 2009 and\nillustrates an easy-to-follow causal inference strategy in a forecast scenario.\nIt further discusses some potential benefits and challenges for causal\ninference with time series forecasting when modeling the counterfactuals,\nestimating the uncertainty and incorporating prior knowledge to estimate causal\neffects in different forecasting scenarios.",
            "author": [
                "Feng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05451v1",
                "http://arxiv.org/pdf/2308.05451v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05447v1",
            "title": "A Generalized Physical-knowledge-guided Dynamic Model for Underwater\n  Image Enhancement",
            "updated": "2023-08-10T09:09:15Z",
            "published": "2023-08-10T09:09:15Z",
            "summary": "Underwater images often suffer from color distortion and low contrast\nresulting in various image types, due to the scattering and absorption of light\nby water. While it is difficult to obtain high-quality paired training samples\nwith a generalized model. To tackle these challenges, we design a Generalized\nUnderwater image enhancement method via a Physical-knowledge-guided Dynamic\nModel (short for GUPDM), consisting of three parts: Atmosphere-based Dynamic\nStructure (ADS), Transmission-guided Dynamic Structure (TDS), and Prior-based\nMulti-scale Structure (PMS). In particular, to cover complex underwater scenes,\nthis study changes the global atmosphere light and the transmission to simulate\nvarious underwater image types (e.g., the underwater image color ranging from\nyellow to blue) through the formation model. We then design ADS and TDS that\nuse dynamic convolutions to adaptively extract prior information from\nunderwater images and generate parameters for PMS. These two modules enable the\nnetwork to select appropriate parameters for various water types adaptively.\nBesides, the multi-scale feature extraction module in PMS uses convolution\nblocks with different kernel sizes and obtains weights for each feature map via\nchannel attention block and fuses them to boost the receptive field of the\nnetwork. The source code will be available at\n\\href{https://github.com/shiningZZ/GUPDM}{https://github.com/shiningZZ/GUPDM}.",
            "author": [
                "Pan Mu",
                "Hanning Xu",
                "Zheyuan Liu",
                "Zheng Wang",
                "Sixian Chan",
                "Cong Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05447v1",
                "http://arxiv.org/pdf/2308.05447v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05775v1",
            "title": "Application of dense neural networks for manifold-based modeling of\n  flame-wall interactions",
            "updated": "2023-08-10T09:06:32Z",
            "published": "2023-08-10T09:06:32Z",
            "summary": "Artifical neural networks (ANNs) are universal approximators capable of\nlearning any correlation between arbitrary input data with corresponding\noutputs, which can also be exploited to represent a low-dimensional chemistry\nmanifold in the field of combustion. In this work, a procedure is developed to\nsimulate a premixed methane-air flame undergoing side-wall quenching utilizing\nan ANN chemistry manifold. In the investigated case, the flame characteristics\nare governed by two canonical problems: the adiabatic flame propagation in the\ncore flow and the non-adiabatic flame-wall interaction governed by enthalpy\nlosses to the wall. Similar to the tabulation of a Quenching Flamelet-Generated\nManifold (QFM), the neural network is trained on a 1D head-on quenching flame\ndatabase to learn the intrinsic chemistry manifold. The control parameters\n(i.e. the inputs) of the ANN are identified from thermo-chemical state\nvariables by a sparse principal component analysis (PCA) without using prior\nknowledge about the flame physics. These input quantities are then transported\nin the coupled CFD solver and used for manifold access during simulation\nruntime. The chemical source terms are corrected at the manifold boundaries to\nensure boundedness of the thermo-chemical state at all times. Finally, the ANN\nmodel is assessed by comparison to simulation results of the 2D side-wall\nquenching (SWQ) configuration with detailed chemistry and with a flamelet-based\nmanifold (QFM).",
            "author": [
                "Julian Bissantz",
                "Jeremy Karpowski",
                "Matthias Steinhausen",
                "Yujuan Luo",
                "Federica Ferraro",
                "Arne Scholtissek",
                "Christian Hasse",
                "Luc Vervisch"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jaecs.2023.100113",
                "http://arxiv.org/abs/2308.05775v1",
                "http://arxiv.org/pdf/2308.05775v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05444v1",
            "title": "How-to Augmented Lagrangian on Factor Graphs",
            "updated": "2023-08-10T09:01:18Z",
            "published": "2023-08-10T09:01:18Z",
            "summary": "Factor graphs are a very powerful graphical representation, used to model\nmany problems in robotics. They are widely spread in the areas of Simultaneous\nLocalization and Mapping (SLAM), computer vision, and localization. In this\npaper we describe an approach to fill the gap with other areas, such as optimal\ncontrol, by presenting an extension of Factor Graph Solvers to constrained\noptimization. The core idea of our method is to encapsulate the Augmented\nLagrangian (AL) method in factors of the graph that can be integrated\nstraightforwardly in existing factor graph solvers. We show the generality of\nour approach by addressing three applications, arising from different areas:\npose estimation, rotation synchronization and Model Predictive Control (MPC) of\na pseudo-omnidirectional platform. We implemented our approach using C++ and\nROS. Besides the generality of the approach, application results show that we\ncan favorably compare against domain specific approaches.",
            "author": [
                "Barbara Bazzana",
                "Henrik Andreasson",
                "Giorgio Grisetti"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05444v1",
                "http://arxiv.org/pdf/2308.05444v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05443v1",
            "title": "Occupancy Grid Map to Pose Graph-based Map: Robust BIM-based 2D-LiDAR\n  Localization for Lifelong Indoor Navigation in Changing and Dynamic\n  Environments",
            "updated": "2023-08-10T08:59:47Z",
            "published": "2023-08-10T08:59:47Z",
            "summary": "Several studies rely on the de facto standard Adaptive Monte Carlo\nLocalization (AMCL) method to localize a robot in an Occupancy Grid Map (OGM)\nextracted from a building information model (BIM model). However, most of these\nstudies assume that the BIM model precisely represents the real world, which is\nrarely true. Discrepancies between the reference BIM model and the real world\n(Scan-BIM deviations) are not only due to furniture or clutter but also the\nusual as-planned and as-built deviations that exist with any model created in\nthe design phase. These deviations affect the accuracy of AMCL drastically.\nThis paper proposes an open-source method to generate appropriate Pose\nGraph-based maps from BIM models for robust 2D-LiDAR localization in changing\nand dynamic environments. First, 2D OGMs are automatically generated from\ncomplex BIM models. These OGMs only represent structural elements allowing\nindoor autonomous robot navigation. Then, an efficient technique converts these\n2D OGMs into Pose Graph-based maps enabling more accurate robot pose tracking.\nFinally, we leverage the different map representations for accurate, robust\nlocalization with a combination of state-of-the-art algorithms. Moreover, we\nprovide a quantitative comparison of various state-of-the-art localization\nalgorithms in three simulated scenarios with varying levels of Scan-BIM\ndeviations and dynamic agents. More precisely, we compare two Particle Filter\n(PF) algorithms: AMCL and General Monte Carlo Localization (GMCL); and two\nGraph-based Localization (GBL) methods: Google's Cartographer and SLAM Toolbox,\nsolving the global localization and pose tracking problems. The numerous\nexperiments demonstrate that the proposed method contributes to a robust\nlocalization with an as-designed BIM model or a sparse OGM in changing and\ndynamic environments, outperforming the conventional AMCL in accuracy and\nrobustness.",
            "author": [
                "Miguel Arturo Vega Torres",
                "Alexander Braun",
                "Andr\u00e9 Borrmann"
            ],
            "link": [
                "http://dx.doi.org/10.1201/9781003354222-72",
                "http://arxiv.org/abs/2308.05443v1",
                "http://arxiv.org/pdf/2308.05443v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05442v1",
            "title": "Optimal chromatic bound for ($P_3\\cup P_2$, house)-free graphs",
            "updated": "2023-08-10T08:58:12Z",
            "published": "2023-08-10T08:58:12Z",
            "summary": "Let $G$ and $H$ be two vertex disjoint graphs. The {\\em union} $G\\cup H$ is\nthe graph with $V(G\\cup H)=V(G)\\cup V(H)$ and $E(G\\cup H)=E(G)\\cup E(H)$. We\nuse $P_k$ to denote a {\\em path} on $k$ vertices, use {\\em house} to denote the\ncomplement of $P_5$. In this paper, we show that $\\chi(G)\\le2\\omega(G)$ if $G$\nis ($P_3\\cup P_2$, house)-free. Moreover, this bound is optimal when\n$\\omega(G)\\ge2$.",
            "author": [
                "Rui Li",
                "Di Wu",
                "Jinfeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05442v1",
                "http://arxiv.org/pdf/2308.05442v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05422v1",
            "title": "TSLiNGAM: DirectLiNGAM under heavy tails",
            "updated": "2023-08-10T08:34:46Z",
            "published": "2023-08-10T08:34:46Z",
            "summary": "One of the established approaches to causal discovery consists of combining\ndirected acyclic graphs (DAGs) with structural causal models (SCMs) to describe\nthe functional dependencies of effects on their causes. Possible\nidentifiability of SCMs given data depends on assumptions made on the noise\nvariables and the functional classes in the SCM. For instance, in the LiNGAM\nmodel, the functional class is restricted to linear functions and the\ndisturbances have to be non-Gaussian.\n  In this work, we propose TSLiNGAM, a new method for identifying the DAG of a\ncausal model based on observational data. TSLiNGAM builds on DirectLiNGAM, a\npopular algorithm which uses simple OLS regression for identifying causal\ndirections between variables. TSLiNGAM leverages the non-Gaussianity assumption\nof the error terms in the LiNGAM model to obtain more efficient and robust\nestimation of the causal structure. TSLiNGAM is justified theoretically and is\nstudied empirically in an extensive simulation study. It performs significantly\nbetter on heavy-tailed and skewed data and demonstrates a high small-sample\nefficiency. In addition, TSLiNGAM also shows better robustness properties as it\nis more resilient to contamination.",
            "author": [
                "Sarah Leyder",
                "Jakob Raymaekers",
                "Tim Verdonck"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05422v1",
                "http://arxiv.org/pdf/2308.05422v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05418v2",
            "title": "Guided quantum walk",
            "updated": "2023-08-23T14:10:01Z",
            "published": "2023-08-10T08:24:37Z",
            "summary": "We utilize the theory of local amplitude transfers (LAT) to gain insights\ninto quantum walks (QWs) and quantum annealing (QA) beyond the adiabatic\ntheorem. By representing the eigenspace of the problem Hamiltonian as a\nhypercube graph, we demonstrate that probability amplitude traverses the search\nspace through a series of local Rabi oscillations. We argue that the amplitude\nmovement can be systematically guided towards the ground state using a\ntime-dependent hopping rate based solely on the problem's energy spectrum.\nBuilding upon these insights, we extend the concept of multi-stage QW by\nintroducing the guided quantum walk (GQW) as a bridge between QW-like and\nQA-like procedures. We assess the performance of the GQW on exact cover,\ntraveling salesperson and garden optimization problems with 9 to 30 qubits. Our\nresults provide evidence for the existence of optimal annealing schedules,\nbeyond the requirement of adiabatic time evolutions. These schedules might be\ncapable of solving large-scale combinatorial optimization problems within\nevolution times that scale linearly in the problem size.",
            "author": [
                "Sebastian Schulz",
                "Dennis Willsch",
                "Kristel Michielsen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05418v2",
                "http://arxiv.org/pdf/2308.05418v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05410v1",
            "title": "SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated,\n  Noisy, and Decimated Point Cloud Data",
            "updated": "2023-08-10T08:10:01Z",
            "published": "2023-08-10T08:10:01Z",
            "summary": "This paper proposes a new method to infer keypoints from arbitrary object\ncategories in practical scenarios where point cloud data (PCD) are noisy,\ndown-sampled and arbitrarily rotated. Our proposed model adheres to the\nfollowing principles: i) keypoints inference is fully unsupervised (no\nannotation given), ii) keypoints position error should be low and resilient to\nPCD perturbations (robustness), iii) keypoints should not change their indexes\nfor the intra-class objects (semantic coherence), iv) keypoints should be close\nto or proximal to PCD surface (compactness). We achieve these desiderata by\nproposing a new self-supervised training strategy for keypoints estimation that\ndoes not assume any a priori knowledge of the object class, and a model\narchitecture with coupled auxiliary losses that promotes the desired keypoints\nproperties. We compare the keypoints estimated by the proposed approach with\nthose of the state-of-the-art unsupervised approaches. The experiments show\nthat our approach outperforms by estimating keypoints with improved coverage\n(+9.41%) while being semantically consistent (+4.66%) that best characterizes\nthe object's 3D shape for downstream tasks. Code and data are available at:\nhttps://github.com/IITPAVIS/SC3K",
            "author": [
                "Mohammad Zohaib",
                "Alessio Del Bue"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05410v1",
                "http://arxiv.org/pdf/2308.05410v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07332v1",
            "title": "Notation3 as an Existential Rule Language",
            "updated": "2023-08-10T07:41:01Z",
            "published": "2023-08-10T07:41:01Z",
            "summary": "Notation3 Logic (\\nthree) is an extension of RDF that allows the user to\nwrite rules introducing new blank nodes to RDF graphs. Many applications (e.g.,\nontology mapping) rely on this feature as blank nodes -- used directly or in\nauxiliary constructs -- are omnipresent on the Web. However, the number of fast\n\\nthree reasoners covering this very important feature of the logic is rather\nlimited. On the other hand, there are engines like VLog or Nemo which do not\ndirectly support Semantic Web rule formats but which are developed and\noptimized for very similar constructs: existential rules. In this paper, we\ninvestigate the relation between \\nthree rules with blank nodes in their heads\nand existential rules. We identify a subset of \\nthree which can be mapped\ndirectly to existential rules and define such a mapping preserving the\nequivalence of \\nthree formulae. In order to also illustrate that in some cases\n\\nthree reasoning could benefit from our translation, we then employ this\nmapping in an implementation to compare the performance of the \\nthree\nreasoners EYE and cwm to VLog and Nemo on \\nthree rules and their mapped\ncounterparts. Our tests show that the existential rule reasoners perform\nparticularly well for use cases containing many facts while especially the EYE\nreasoner is very fast when dealing with a high number of dependent rules. We\nthus provide a tool enabling the Semantic Web community to directly use\nexisting and future existential rule reasoners and benefit from the findings of\nthis active community.",
            "author": [
                "D\u00f6rthe Arndt",
                "Stephan Mennicke"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07332v1",
                "http://arxiv.org/pdf/2308.07332v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05397v1",
            "title": "Photoelectronic mapping of spin-orbit interaction of intense light\n  fields",
            "updated": "2023-08-10T07:29:47Z",
            "published": "2023-08-10T07:29:47Z",
            "summary": "The interaction between a quantum particle's spin angular momentum and its\norbital angular momentum is ubiquitous in nature. In optics, the spin-orbit\noptical phenomenon is closely related with the light-matter interaction and has\nbeen of great interest. With the development of laser technology, the\nhigh-power and ultrafast light sources now serve as a crucial tool in revealing\nthe behaviour of matters under extreme conditions. The comprehensive knowledge\nof the spin-orbit interaction for the intense light is of utmost importance.\nHere, we achieve the in-situ modulation and visualization of the optical\norbital-to-spin conversion in strong-field regime. We show that, through\nmanipulating the morphology of femtosecond cylindrical vector vortex pulses by\na slit, the photons' orbital angular momentum can be controllably transformed\ninto spin after focusing. By employing strong-field ionization experiment, the\norbital-to-spin conversion can be imaged and measured through the photoelectron\nmomentum distributions. Such detection and consequent control of spin-orbit\ndynamics of intense laser fields have implications on controlling the\nphotoelectron holography and coherent extreme ultraviolet radiation.",
            "author": [
                "Yiqi Fang",
                "Meng Han",
                "Peipei Ge",
                "Zhenning Guo",
                "Xiaoyang Yu",
                "Yongkai Deng",
                "Chengyin Wu",
                "Qihuang Gong",
                "Yunquan Liu"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41566-020-00709-3",
                "http://arxiv.org/abs/2308.05397v1",
                "http://arxiv.org/pdf/2308.05397v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05395v2",
            "title": "Communication-efficient distributed optimization with adaptability to\n  system heterogeneity",
            "updated": "2023-11-25T09:16:21Z",
            "published": "2023-08-10T07:24:24Z",
            "summary": "We consider the setting of agents cooperatively minimizing the sum of local\nobjectives plus a regularizer on a graph. This paper proposes a primal-dual\nmethod in consideration of three distinctive attributes of real-life\nmulti-agent systems, namely: (i)expensive communication, (ii)lack of\nsynchronization, and (iii)system heterogeneity. In specific, we propose a\ndistributed asynchronous algorithm with minimal communication cost, in which\nusers commit variable amounts of local work on their respective sub-problems.\nWe illustrate this both theoretically and experimentally in the machine\nlearning setting, where the agents hold private data and use a stochastic\nNewton method as the local solver. Under standard assumptions on Lipschitz\ncontinuous gradients and strong convexity, our analysis establishes linear\nconvergence in expectation and characterizes the dependency of the rate on the\nnumber of local iterations. We proceed a step further to propose a simple means\nfor tuning agents' hyperparameters locally, so as to adjust to heterogeneity\nand accelerate the overall convergence. Last, we validate our proposed method\non a benchmark machine learning dataset to illustrate the merits in terms of\ncomputation, communication, and run-time saving as well as adaptability to\nheterogeneity.",
            "author": [
                "Ziyi Yu",
                "Nikolaos M. Freris"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05395v2",
                "http://arxiv.org/pdf/2308.05395v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05385v1",
            "title": "Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent\n  Classification",
            "updated": "2023-08-10T07:02:24Z",
            "published": "2023-08-10T07:02:24Z",
            "summary": "Patent classification aims to assign multiple International Patent\nClassification (IPC) codes to a given patent. Recent methods for automatically\nclassifying patents mainly focus on analyzing the text descriptions of patents.\nHowever, apart from the texts, each patent is also associated with some\nassignees, and the knowledge of their applied patents is often valuable for\nclassification. Furthermore, the hierarchical taxonomy formulated by the IPC\nsystem provides important contextual information and enables models to leverage\nthe correlations between IPC codes for more accurate classification. However,\nexisting methods fail to incorporate the above aspects. In this paper, we\npropose an integrated framework that comprehensively considers the information\non patents for patent classification. To be specific, we first present an IPC\ncodes correlations learning module to derive their semantic representations via\nadaptively passing and aggregating messages within the same level and across\ndifferent levels along the hierarchical taxonomy. Moreover, we design a\nhistorical application patterns learning component to incorporate the\ncorresponding assignee's previous patents by a dual channel aggregation\nmechanism. Finally, we combine the contextual information of patent texts that\ncontains the semantics of IPC codes, and assignees' sequential preferences to\nmake predictions. Experiments on real-world datasets demonstrate the\nsuperiority of our approach over the existing methods. Besides, we present the\nmodel's ability to capture the temporal patterns of assignees and the semantic\ndependencies among IPC codes.",
            "author": [
                "Tao Zou",
                "Le Yu",
                "Leilei Sun",
                "Bowen Du",
                "Deqing Wang",
                "Fuzhen Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05385v1",
                "http://arxiv.org/pdf/2308.05385v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05772v2",
            "title": "Note on Hamiltonicity of basis graphs of even delta-matroids",
            "updated": "2023-09-16T10:38:11Z",
            "published": "2023-08-10T07:00:58Z",
            "summary": "We show that the basis graph of an even delta-matroid is Hamiltonian if it\nhas more than two vertices. More strongly, we prove that for two distinct edges\n$e$ and $f$ sharing a common end, it has a Hamiltonian cycle using $e$ and\navoiding $f$ unless it has at most two vertices or it is a cycle of length at\nmost four. We also prove that if the basis graph is not a hypercube graph, then\neach vertex belongs to cycles of every length $\\ell\\ge 3$, and each edge\nbelongs to cycles of every length $\\ell \\ge 4$. For the last theorem, we\nprovide two proofs, one of which uses the result of Naddef (1984) on polytopes\nand the result of Chepoi (2007) on basis graphs of even delta-matroids, and the\nother is a direct proof using various properties of even delta-matroids. Our\ntheorems generalize the analogous results for matroids by Holzmann and Harary\n(1972) and Bondy and Ingleton (1976).",
            "author": [
                "Donggyu Kim",
                "Sang-il Oum"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05772v2",
                "http://arxiv.org/pdf/2308.05772v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05B35, 05C38, 05C45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05383v1",
            "title": "Liquid Metal Molecular Scissors",
            "updated": "2023-08-10T07:00:42Z",
            "published": "2023-08-10T07:00:42Z",
            "summary": "Molecules are the smallest unit in matters that can exist independently,\nrelatively stable, and maintain physical and chemical activities. The atomic\nspecies, alignment commands, and chemical bonds are key factors to dominate\ntheir structures and properties. Here we disclosed a general chemistry effect\nthat the liquid metals can directly cut off oxygen-containing groups in various\nmolecular matters at room temperature, and then recombine the remaining groups\nto form functional materials including nano semiconductors. Based on this\nunique mechanism, we proposed a basic tool and named it as liquid metal\nscissors for molecular directional clipping and functional transformation. As\nproof-of-concept, we demonstrated the capabilities of eGaIn scissors made of Ga\nand In particles, and revealed that the Ga on the surface of eGaIn could\ndirectly snatch oxygen atoms from various targeted substances such as H2O, CO2\nor CH3OH molecules to form gallium oxides. As illustration, after clipping, the\nremaining hydrogen atoms of H2O molecules recombined to form H2, while the\nremaining groups of CH3OH lead to H2, carbon quantum dots, and other related\nsubstances. If needed, more molecules can also be manipulated via such\nscissors. This finding refreshes the basic knowledge of chemistry and suggests\neasygoing ways for molecular weaving, which may break up the limitations and\nsingle features of molecular substances. It also opens up a universal route for\ninnovating future molecular chemical engineering, life science, energy and\nenvironment, and biomedicine.",
            "author": [
                "Liangfei Duan",
                "Tong Zhou",
                "Huiqin Yang",
                "Weihua Mu",
                "Zhongshan Deng",
                "Jing Liu",
                "Qingju Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05383v1",
                "http://arxiv.org/pdf/2308.05383v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05362v1",
            "title": "FINER: Enhancing State-of-the-art Classifiers with Feature Attribution\n  to Facilitate Security Analysis",
            "updated": "2023-08-10T06:10:49Z",
            "published": "2023-08-10T06:10:49Z",
            "summary": "Deep learning classifiers achieve state-of-the-art performance in various\nrisk detection applications. They explore rich semantic representations and are\nsupposed to automatically discover risk behaviors. However, due to the lack of\ntransparency, the behavioral semantics cannot be conveyed to downstream\nsecurity experts to reduce their heavy workload in security analysis. Although\nfeature attribution (FA) methods can be used to explain deep learning, the\nunderlying classifier is still blind to what behavior is suspicious, and the\ngenerated explanation cannot adapt to downstream tasks, incurring poor\nexplanation fidelity and intelligibility. In this paper, we propose FINER, the\nfirst framework for risk detection classifiers to generate high-fidelity and\nhigh-intelligibility explanations. The high-level idea is to gather explanation\nefforts from model developer, FA designer, and security experts. To improve\nfidelity, we fine-tune the classifier with an explanation-guided multi-task\nlearning strategy. To improve intelligibility, we engage task knowledge to\nadjust and ensemble FA methods. Extensive evaluations show that FINER improves\nexplanation quality for risk detection. Moreover, we demonstrate that FINER\noutperforms a state-of-the-art tool in facilitating malware analysis.",
            "author": [
                "Yiling He",
                "Jian Lou",
                "Zhan Qin",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05362v1",
                "http://arxiv.org/pdf/2308.05362v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05361v3",
            "title": "WeaverBird: Empowering Financial Decision-Making with Large Language\n  Model, Knowledge Base, and Search Engine",
            "updated": "2023-12-02T12:24:14Z",
            "published": "2023-08-10T06:08:20Z",
            "summary": "We present WeaverBird, an intelligent dialogue system designed specifically\nfor the finance domain. Our system harnesses a large language model of GPT\narchitecture that has been tuned using extensive corpora of finance-related\ntext. As a result, our system possesses the capability to understand complex\nfinancial queries, such as \"How should I manage my investments during\ninflation?\", and provide informed responses. Furthermore, our system\nincorporates a local knowledge base and a search engine to retrieve relevant\ninformation. The final responses are conditioned on the search results and\ninclude proper citations to the sources, thus enjoying an enhanced credibility.\nThrough a range of finance-related questions, we have demonstrated the superior\nperformance of our system compared to other models. To experience our system\nfirsthand, users can interact with our live demo at\nhttps://weaverbird.ttic.edu, as well as watch our 2-min video illustration at\nhttps://www.youtube.com/watch?v=fyV2qQkX6Tc.",
            "author": [
                "Siqiao Xue",
                "Fan Zhou",
                "Yi Xu",
                "Ming Jin",
                "Qingsong Wen",
                "Hongyan Hao",
                "Qingyang Dai",
                "Caigao Jiang",
                "Hongyu Zhao",
                "Shuo Xie",
                "Jianshan He",
                "James Zhang",
                "Hongyuan Mei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05361v3",
                "http://arxiv.org/pdf/2308.05361v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05346v1",
            "title": "Towards General and Fast Video Derain via Knowledge Distillation",
            "updated": "2023-08-10T05:27:43Z",
            "published": "2023-08-10T05:27:43Z",
            "summary": "As a common natural weather condition, rain can obscure video frames and thus\naffect the performance of the visual system, so video derain receives a lot of\nattention. In natural environments, rain has a wide variety of streak types,\nwhich increases the difficulty of the rain removal task. In this paper, we\npropose a Rain Review-based General video derain Network via knowledge\ndistillation (named RRGNet) that handles different rain streak types with one\npre-training weight. Specifically, we design a frame grouping-based\nencoder-decoder network that makes full use of the temporal information of the\nvideo. Further, we use the old task model to guide the current model in\nlearning new rain streak types while avoiding forgetting. To consolidate the\nnetwork's ability to derain, we design a rain review module to play back data\nfrom old tasks for the current model. The experimental results show that our\ndeveloped general method achieves the best results in terms of running speed\nand derain effect.",
            "author": [
                "Defang Cai",
                "Pan Mu",
                "Sixian Chan",
                "Zhanpeng Shao",
                "Cong Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05346v1",
                "http://arxiv.org/pdf/2308.05346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05342v3",
            "title": "Metacognitive Prompting Improves Understanding in Large Language Models",
            "updated": "2023-08-17T04:53:15Z",
            "published": "2023-08-10T05:10:17Z",
            "summary": "In Large Language Models (LLMs), there have been consistent advancements in\ntask-specific performance, largely influenced by effective prompt design. While\nrecent research on prompting has enhanced the reasoning capabilities of LLMs, a\ngap remains in further improving their understanding abilities. In this study,\nwe introduce Metacognitive Prompting (MP), a strategy inspired by human\nintrospective reasoning processes. Using MP, LLMs undergo a systematic series\nof structured, self-aware evaluations, drawing on both their vast inherent\nknowledge and new insights. Our experiments involve five prevalent LLMs:\nLlama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general\nnatural language understanding (NLU) tasks from the GLUE and SuperGLUE\nbenchmarks. Results indicate that, although GPT-4 consistently excels in most\ntasks, PaLM, when equipped with MP, approaches its performance level.\nFurthermore, across models and datasets, MP consistently outperforms existing\nprompting methods, including standard and chain-of-thought prompting. This\nstudy underscores the potential to amplify the understanding abilities of LLMs\nand highlights the benefits of mirroring human introspective reasoning in NLU\ntasks.",
            "author": [
                "Yuqing Wang",
                "Yun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05342v3",
                "http://arxiv.org/pdf/2308.05342v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05330v1",
            "title": "Refining the IceCube detector geometry using muon and LED calibration\n  data",
            "updated": "2023-08-10T04:18:30Z",
            "published": "2023-08-10T04:18:30Z",
            "summary": "The IceCube Neutrino Observatory deployed 5160 digital optical modules (DOMs)\non 86 cables, called strings, in a cubic kilometer of deep glacial ice below\nthe geographic South Pole. These record the Cherenkov light of passing charged\nparticles. Knowledge of the DOM positions is vital for event reconstruction.\nWhile vertical positions have been calibrated, previous in-situ geometry\ncalibration methods have been unable to measure horizontal deviations from the\nsurface positions, largely due to degeneracies with ice model uncertainties.\nThus the lateral position of the surface position of each hole is to date in\nalmost all cases used as the lateral position of all DOMs on a given string.\nWith the recent advances in ice modeling, two new in-situ measurements have now\nbeen undertaken. Using a large sample of muon tracks, the individual positions\nof all DOMs on a small number of strings around the center of the detector have\nbeen fitted.\n  Verifying the results against LED calibration data shows that the\nstring-average corrections improve detector modeling. Directly fitting\nstring-average geometry corrections for the full array using LED data agrees\nwith the average corrections as derived from muons where available. Analyses\nare now ongoing to obtain per-DOM positions using both methods and in addition,\nmethods are being developed to correct the recorded arrival times for the\nexpected scattering delay, allowing for multilateration of the positions using\nnanosecond-precision propagation delays.",
            "author": [
                "Matti Janson",
                "Saskia Philippen",
                "Martin Rongen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05330v1",
                "http://arxiv.org/pdf/2308.05330v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05322v1",
            "title": "DegUIL: Degree-aware Graph Neural Networks for Long-tailed User Identity\n  Linkage",
            "updated": "2023-08-10T03:48:18Z",
            "published": "2023-08-10T03:48:18Z",
            "summary": "User identity linkage (UIL), matching accounts of a person on different\nsocial networks, is a fundamental task in cross-network data mining. Recent\nworks have achieved promising results by exploiting graph neural networks\n(GNNs) to capture network structure. However, they rarely analyze the realistic\nnode-level bottlenecks that hinder UIL's performance. First, node degrees in a\ngraph vary widely and are long-tailed. A significant fraction of tail nodes\nwith small degrees are underrepresented due to limited structural information,\ndegrading linkage performance seriously. The second bottleneck usually\noverlooked is super head nodes. It is commonly accepted that head nodes perform\nwell. However, we find that some of them with super high degrees also have\ndifficulty aligning counterparts, due to noise introduced by the randomness of\nfollowing friends in real-world social graphs. In pursuit of learning ideal\nrepresentations for these two groups of nodes, this paper proposes a\ndegree-aware model named DegUIL to narrow the degree gap. To this end, our\nmodel complements missing neighborhoods for tail nodes and discards redundant\nstructural information for super head nodes in embeddings respectively.\nSpecifically, the neighboring bias is predicted and corrected locally by two\nmodules, which are trained using the knowledge from structurally adequate head\nnodes. As a result, ideal neighborhoods are obtained for meaningful aggregation\nin GNNs. Extensive experiments demonstrate the superiority of our model. Our\ndata and code can be found at https://github.com/Longmeix/DegUIL.",
            "author": [
                "Meixiu Long",
                "Siyuan Chen",
                "Xin Du",
                "Jiahai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05322v1",
                "http://arxiv.org/pdf/2308.05322v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05318v1",
            "title": "RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End\n  Robust Estimation",
            "updated": "2023-08-10T03:14:19Z",
            "published": "2023-08-10T03:14:19Z",
            "summary": "Robust estimation is a crucial and still challenging task, which involves\nestimating model parameters in noisy environments. Although conventional\nsampling consensus-based algorithms sample several times to achieve robustness,\nthese algorithms cannot use data features and historical information\neffectively. In this paper, we propose RLSAC, a novel Reinforcement Learning\nenhanced SAmple Consensus framework for end-to-end robust estimation. RLSAC\nemploys a graph neural network to utilize both data and memory features to\nguide exploring directions for sampling the next minimum set. The feedback of\ndownstream tasks serves as the reward for unsupervised training. Therefore,\nRLSAC can avoid differentiating to learn the features and the feedback of\ndownstream tasks for end-to-end robust estimation. In addition, RLSAC\nintegrates a state transition module that encodes both data and memory\nfeatures. Our experimental results demonstrate that RLSAC can learn from\nfeatures to gradually explore a better hypothesis. Through analysis, it is\napparent that RLSAC can be easily transferred to other sampling consensus-based\nrobust estimation tasks. To the best of our knowledge, RLSAC is also the first\nmethod that uses reinforcement learning to sample consensus for end-to-end\nrobust estimation. We release our codes at https://github.com/IRMVLab/RLSAC.",
            "author": [
                "Chang Nie",
                "Guangming Wang",
                "Zhe Liu",
                "Luca Cavalli",
                "Marc Pollefeys",
                "Hesheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05318v1",
                "http://arxiv.org/pdf/2308.05318v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05317v1",
            "title": "Few-Shot Data-to-Text Generation via Unified Representation and\n  Multi-Source Learning",
            "updated": "2023-08-10T03:09:12Z",
            "published": "2023-08-10T03:09:12Z",
            "summary": "We present a novel approach for structured data-to-text generation that\naddresses the limitations of existing methods that primarily focus on specific\ntypes of structured data. Our proposed method aims to improve performance in\nmulti-task training, zero-shot and few-shot scenarios by providing a unified\nrepresentation that can handle various forms of structured data such as tables,\nknowledge graph triples, and meaning representations. We demonstrate that our\nproposed approach can effectively adapt to new structured forms, and can\nimprove performance in comparison to current methods. For example, our method\nresulted in a 66% improvement in zero-shot BLEU scores when transferring models\ntrained on table inputs to a knowledge graph dataset. Our proposed method is an\nimportant step towards a more general data-to-text generation framework.",
            "author": [
                "Alexander Hanbo Li",
                "Mingyue Shang",
                "Evangelia Spiliopoulou",
                "Jie Ma",
                "Patrick Ng",
                "Zhiguo Wang",
                "Bonan Min",
                "William Wang",
                "Kathleen McKeown",
                "Vittorio Castelli",
                "Dan Roth",
                "Bing Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05317v1",
                "http://arxiv.org/pdf/2308.05317v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05314v2",
            "title": "Deep Semantic Graph Matching for Large-scale Outdoor Point Clouds\n  Registration",
            "updated": "2023-10-18T01:19:55Z",
            "published": "2023-08-10T03:07:28Z",
            "summary": "Current point cloud registration methods are mainly based on local geometric\ninformation and usually ignore the semantic information contained in the\nscenes. In this paper, we treat the point cloud registration problem as a\nsemantic instance matching and registration task, and propose a deep semantic\ngraph matching method (DeepSGM) for large-scale outdoor point cloud\nregistration. Firstly, the semantic categorical labels of 3D points are\nobtained using a semantic segmentation network. The adjacent points with the\nsame category labels are then clustered together using the Euclidean clustering\nalgorithm to obtain the semantic instances, which are represented by three\nkinds of attributes including spatial location information, semantic\ncategorical information, and global geometric shape information. Secondly, the\nsemantic adjacency graph is constructed based on the spatial adjacency\nrelations of semantic instances. To fully explore the topological structures\nbetween semantic instances in the same scene and across different scenes, the\nspatial distribution features and the semantic categorical features are learned\nwith graph convolutional networks, and the global geometric shape features are\nlearned with a PointNet-like network. These three kinds of features are further\nenhanced with the self-attention and cross-attention mechanisms. Thirdly, the\nsemantic instance matching is formulated as an optimal transport problem, and\nsolved through an optimal matching layer. Finally, the geometric transformation\nmatrix between two point clouds is first estimated by the SVD algorithm and\nthen refined by the ICP algorithm. Experimental results conducted on the KITTI\nOdometry dataset demonstrate that the proposed method improves the registration\nperformance and outperforms various state-of-the-art methods.",
            "author": [
                "Shaocong Liu",
                "Tao Wang",
                "Yan Zhang",
                "Ruqin Zhou",
                "Li Li",
                "Chenguang Dai",
                "Yongsheng Zhang",
                "Longguang Wang",
                "Hanyun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05314v2",
                "http://arxiv.org/pdf/2308.05314v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05311v1",
            "title": "DAOT: Domain-Agnostically Aligned Optimal Transport for Domain-Adaptive\n  Crowd Counting",
            "updated": "2023-08-10T02:59:40Z",
            "published": "2023-08-10T02:59:40Z",
            "summary": "Domain adaptation is commonly employed in crowd counting to bridge the domain\ngaps between different datasets. However, existing domain adaptation methods\ntend to focus on inter-dataset differences while overlooking the\nintra-differences within the same dataset, leading to additional learning\nambiguities. These domain-agnostic factors, e.g., density, surveillance\nperspective, and scale, can cause significant in-domain variations, and the\nmisalignment of these factors across domains can lead to a drop in performance\nin cross-domain crowd counting. To address this issue, we propose a\nDomain-agnostically Aligned Optimal Transport (DAOT) strategy that aligns\ndomain-agnostic factors between domains. The DAOT consists of three steps.\nFirst, individual-level differences in domain-agnostic factors are measured\nusing structural similarity (SSIM). Second, the optimal transfer (OT) strategy\nis employed to smooth out these differences and find the optimal\ndomain-to-domain misalignment, with outlier individuals removed via a virtual\n\"dustbin\" column. Third, knowledge is transferred based on the aligned\ndomain-agnostic factors, and the model is retrained for domain adaptation to\nbridge the gap across domains. We conduct extensive experiments on five\nstandard crowd-counting benchmarks and demonstrate that the proposed method has\nstrong generalizability across diverse datasets. Our code will be available at:\nhttps://github.com/HopooLinZ/DAOT/.",
            "author": [
                "Huilin Zhu",
                "Jingling Yuan",
                "Xian Zhong",
                "Zhengwei Yang",
                "Zheng Wang",
                "Shengfeng He"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611793",
                "http://arxiv.org/abs/2308.05311v1",
                "http://arxiv.org/pdf/2308.05311v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05309v3",
            "title": "Homophily-enhanced Structure Learning for Graph Clustering",
            "updated": "2023-10-30T08:44:32Z",
            "published": "2023-08-10T02:53:30Z",
            "summary": "Graph clustering is a fundamental task in graph analysis, and recent advances\nin utilizing graph neural networks (GNNs) have shown impressive results.\nDespite the success of existing GNN-based graph clustering methods, they often\noverlook the quality of graph structure, which is inherent in real-world graphs\ndue to their sparse and multifarious nature, leading to subpar performance.\nGraph structure learning allows refining the input graph by adding missing\nlinks and removing spurious connections. However, previous endeavors in graph\nstructure learning have predominantly centered around supervised settings, and\ncannot be directly applied to our specific clustering tasks due to the absence\nof ground-truth labels. To bridge the gap, we propose a novel method called\n\\textbf{ho}mophily-enhanced structure \\textbf{le}arning for graph clustering\n(HoLe). Our motivation stems from the observation that subtly enhancing the\ndegree of homophily within the graph structure can significantly improve GNNs\nand clustering outcomes. To realize this objective, we develop two\nclustering-oriented structure learning modules, i.e., hierarchical correlation\nestimation and cluster-aware sparsification. The former module enables a more\naccurate estimation of pairwise node relationships by leveraging guidance from\nlatent and clustering spaces, while the latter one generates a sparsified\nstructure based on the similarity matrix and clustering assignments.\nAdditionally, we devise a joint optimization approach alternating between\ntraining the homophily-enhanced structure learning and GNN-based clustering,\nthereby enforcing their reciprocal effects. Extensive experiments on seven\nbenchmark datasets of various types and scales, across a range of clustering\nmetrics, demonstrate the superiority of HoLe against state-of-the-art\nbaselines.",
            "author": [
                "Ming Gu",
                "Gaoming Yang",
                "Sheng Zhou",
                "Ning Ma",
                "Jiawei Chen",
                "Qiaoyu Tan",
                "Meihan Liu",
                "Jiajun Bu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05309v3",
                "http://arxiv.org/pdf/2308.05309v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05298v1",
            "title": "Double-chain Constraints for 3D Human Pose Estimation in Images and\n  Videos",
            "updated": "2023-08-10T02:41:18Z",
            "published": "2023-08-10T02:41:18Z",
            "summary": "Reconstructing 3D poses from 2D poses lacking depth information is\nparticularly challenging due to the complexity and diversity of human motion.\nThe key is to effectively model the spatial constraints between joints to\nleverage their inherent dependencies. Thus, we propose a novel model, called\nDouble-chain Graph Convolutional Transformer (DC-GCT), to constrain the pose\nthrough a double-chain design consisting of local-to-global and global-to-local\nchains to obtain a complex representation more suitable for the current human\npose. Specifically, we combine the advantages of GCN and Transformer and design\na Local Constraint Module (LCM) based on GCN and a Global Constraint Module\n(GCM) based on self-attention mechanism as well as a Feature Interaction Module\n(FIM). The proposed method fully captures the multi-level dependencies between\nhuman body joints to optimize the modeling capability of the model. Moreover,\nwe propose a method to use temporal information into the single-frame model by\nguiding the video sequence embedding through the joint embedding of the target\nframe, with negligible increase in computational cost. Experimental results\ndemonstrate that DC-GCT achieves state-of-the-art performance on two\nchallenging datasets (Human3.6M and MPI-INF-3DHP). Notably, our model achieves\nstate-of-the-art performance on all action categories in the Human3.6M dataset\nusing detected 2D poses from CPN, and our code is available at:\nhttps://github.com/KHB1698/DC-GCT.",
            "author": [
                "Hongbo Kang",
                "Yong Wang",
                "Mengyuan Liu",
                "Doudou Wu",
                "Peng Liu",
                "Wenming Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05298v1",
                "http://arxiv.org/pdf/2308.05298v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05295v1",
            "title": "Multimodal Pretrained Models for Sequential Decision-Making: Synthesis,\n  Verification, Grounding, and Perception",
            "updated": "2023-08-10T02:29:11Z",
            "published": "2023-08-10T02:29:11Z",
            "summary": "Recently developed pretrained models can encode rich world knowledge\nexpressed in multiple modalities, such as text and images. However, the outputs\nof these models cannot be integrated into algorithms to solve sequential\ndecision-making tasks. We develop an algorithm that utilizes the knowledge from\npretrained models to construct and verify controllers for sequential\ndecision-making tasks, and to ground these controllers to task environments\nthrough visual observations. In particular, the algorithm queries a pretrained\nmodel with a user-provided, text-based task description and uses the model's\noutput to construct an automaton-based controller that encodes the model's\ntask-relevant knowledge. It then verifies whether the knowledge encoded in the\ncontroller is consistent with other independently available knowledge, which\nmay include abstract information on the environment or user-provided\nspecifications. If this verification step discovers any inconsistency, the\nalgorithm automatically refines the controller to resolve the inconsistency.\nNext, the algorithm leverages the vision and language capabilities of\npretrained models to ground the controller to the task environment. It collects\nimage-based observations from the task environment and uses the pretrained\nmodel to link these observations to the text-based control logic encoded in the\ncontroller (e.g., actions and conditions that trigger the actions). We propose\na mechanism to ensure the controller satisfies the user-provided specification\neven when perceptual uncertainties are present. We demonstrate the algorithm's\nability to construct, verify, and ground automaton-based controllers through a\nsuite of real-world tasks, including daily life and robot manipulation tasks.",
            "author": [
                "Yunhao Yang",
                "Cyrus Neary",
                "Ufuk Topcu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05295v1",
                "http://arxiv.org/pdf/2308.05295v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05293v2",
            "title": "Galois points for a finite graph",
            "updated": "2023-08-11T00:40:21Z",
            "published": "2023-08-10T02:14:35Z",
            "summary": "This paper introduces the notion of a Galois point for a finite graph, using\nthe theory of linear systems of divisors for graphs discovered by Baker and\nNorine. We present a new characterization of complete graphs in terms of Galois\npoints.",
            "author": [
                "Satoru Fukasawa",
                "Tsuyoshi Miezaki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05293v2",
                "http://arxiv.org/pdf/2308.05293v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG",
                "math.GR",
                "Primary 05C10, Secondary 05C60, 14H99"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05292v1",
            "title": "Byzantine-Robust Decentralized Stochastic Optimization with Stochastic\n  Gradient Noise-Independent Learning Error",
            "updated": "2023-08-10T02:14:23Z",
            "published": "2023-08-10T02:14:23Z",
            "summary": "This paper studies Byzantine-robust stochastic optimization over a\ndecentralized network, where every agent periodically communicates with its\nneighbors to exchange local models, and then updates its own local model by\nstochastic gradient descent (SGD). The performance of such a method is affected\nby an unknown number of Byzantine agents, which conduct adversarially during\nthe optimization process. To the best of our knowledge, there is no existing\nwork that simultaneously achieves a linear convergence speed and a small\nlearning error. We observe that the learning error is largely dependent on the\nintrinsic stochastic gradient noise. Motivated by this observation, we\nintroduce two variance reduction methods, stochastic average gradient algorithm\n(SAGA) and loopless stochastic variance-reduced gradient (LSVRG), to\nByzantine-robust decentralized stochastic optimization for eliminating the\nnegative effect of the stochastic gradient noise. The two resulting methods,\nBRAVO-SAGA and BRAVO-LSVRG, enjoy both linear convergence speeds and stochastic\ngradient noise-independent learning errors. Such learning errors are optimal\nfor a class of methods based on total variation (TV)-norm regularization and\nstochastic subgradient update. We conduct extensive numerical experiments to\ndemonstrate their effectiveness under various Byzantine attacks.",
            "author": [
                "Jie Peng",
                "Weiyu Li",
                "Qing Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05292v1",
                "http://arxiv.org/pdf/2308.05292v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05286v1",
            "title": "Informative Scene Graph Generation via Debiasing",
            "updated": "2023-08-10T02:04:01Z",
            "published": "2023-08-10T02:04:01Z",
            "summary": "Scene graph generation aims to detect visual relationship triplets, (subject,\npredicate, object). Due to biases in data, current models tend to predict\ncommon predicates, e.g. \"on\" and \"at\", instead of informative ones, e.g.\n\"standing on\" and \"looking at\". This tendency results in the loss of precise\ninformation and overall performance. If a model only uses \"stone on road\"\nrather than \"stone blocking road\" to describe an image, it may be a grave\nmisunderstanding. We argue that this phenomenon is caused by two imbalances:\nsemantic space level imbalance and training sample level imbalance. For this\nproblem, we propose DB-SGG, an effective framework based on debiasing but not\nthe conventional distribution fitting. It integrates two components: Semantic\nDebiasing (SD) and Balanced Predicate Learning (BPL), for these imbalances. SD\nutilizes a confusion matrix and a bipartite graph to construct predicate\nrelationships. BPL adopts a random undersampling strategy and an ambiguity\nremoving strategy to focus on informative predicates. Benefiting from the\nmodel-agnostic process, our method can be easily applied to SGG models and\noutperforms Transformer by 136.3%, 119.5%, and 122.6% on mR@20 at three SGG\nsub-tasks on the SGG-VG dataset. Our method is further verified on another\ncomplex SGG dataset (SGG-GQA) and two downstream tasks (sentence-to-graph\nretrieval and image captioning).",
            "author": [
                "Lianli Gao",
                "Xinyu Lyu",
                "Yuyu Guo",
                "Yuxuan Hu",
                "Yuan-Fang Li",
                "Lu Xu",
                "Heng Tao Shen",
                "Jingkuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05286v1",
                "http://arxiv.org/pdf/2308.05286v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05277v1",
            "title": "A note on Hadwiger's conjecture: Another proof that every 4-chromatic\n  graph has a $K_4$ minor",
            "updated": "2023-08-10T01:35:12Z",
            "published": "2023-08-10T01:35:12Z",
            "summary": "The first non-obvious case of Hadwiger's Conjecture states that every graph\n$G$ with chromatic number at least 4 has a $K_4$ minor. We give a new proof\nthat derives the $K_4$ minor from a proper 3-coloring of a subgraph of $G$.",
            "author": [
                "Daniel Cooper McDonald"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05277v1",
                "http://arxiv.org/pdf/2308.05277v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05275v1",
            "title": "Cross-heterogeneity Graph Few-shot Learning",
            "updated": "2023-08-10T01:25:28Z",
            "published": "2023-08-10T01:25:28Z",
            "summary": "In recent years, heterogeneous graph few-shot learning has been proposed to\naddress the label sparsity issue in heterogeneous graphs (HGs), which contain\nvarious types of nodes and edges. The existing methods have achieved good\nperformance by transferring generalized knowledge extracted from rich-labeled\nclasses in source HG(s) to few-labeled classes in a target HG. However, these\nmethods only consider the single-heterogeneity scenario where the source and\ntarget HGs share a fixed set of node/edge types, ignoring the more general\nscenario of cross-heterogeneity, where each HG can have a different and\nnon-fixed set of node/edge types. To this end, we focus on the unexplored\ncross-heterogeneity scenario and propose a novel model for Cross-heterogeneity\nGraph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns\nto capture heterogeneous information and propose a multi-view heterogeneous\ngraph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose\na score module to measure the informativeness of labeled samples and determine\nthe transferability of each source HG. Finally, by integrating MHGN and the\nscore module into a meta-learning mechanism, CGFL can effectively transfer\ngeneralized knowledge to predict new classes with few-labeled data. Extensive\nexperiments on four real-world datasets have demonstrated the superior\nperformance of CGFL over the state-of-the-art methods.",
            "author": [
                "Pengfei Ding",
                "Yan Wang",
                "Guanfeng Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05275v1",
                "http://arxiv.org/pdf/2308.05275v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05274v2",
            "title": "Local-Global Information Interaction Debiasing for Dynamic Scene Graph\n  Generation",
            "updated": "2023-09-25T02:39:29Z",
            "published": "2023-08-10T01:24:25Z",
            "summary": "The task of dynamic scene graph generation (DynSGG) aims to generate scene\ngraphs for given videos, which involves modeling the spatial-temporal\ninformation in the video. However, due to the long-tailed distribution of\nsamples in the dataset, previous DynSGG models fail to predict the tail\npredicates. We argue that this phenomenon is due to previous methods that only\npay attention to the local spatial-temporal information and neglect the\nconsistency of multiple frames. To solve this problem, we propose a novel\nDynSGG model based on multi-task learning, DynSGG-MTL, which introduces the\nlocal interaction information and global human-action interaction information.\nThe interaction between objects and frame features makes the model more fully\nunderstand the visual context of the single image. Long-temporal human actions\nsupervise the model to generate multiple scene graphs that conform to the\nglobal constraints and avoid the model being unable to learn the tail\npredicates. Extensive experiments on Action Genome dataset demonstrate the\nefficacy of our proposed framework, which not only improves the dynamic scene\ngraph generation but also alleviates the long-tail problem.",
            "author": [
                "Xinyu Lyu",
                "Jingwei Liu",
                "Yuyu Guo",
                "Lianli Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05274v2",
                "http://arxiv.org/pdf/2308.05274v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05265v1",
            "title": "Output-feedback model predictive and model-free control for ramp\n  metering",
            "updated": "2023-08-10T00:28:51Z",
            "published": "2023-08-10T00:28:51Z",
            "summary": "We study the stability of freeway traffic flow under output-feedback ramp\nmetering in cases of incomplete information about the traffic flow state. We\npropose a set-membership estimation method for the cell transmission model with\ncapacity drops and design a model predictive controller accordingly. This\ncontroller has linear running and terminal costs in cell densities, and its\noutput comprises density measurements from a subset of the cells, e.g., through\nloop detectors or connected vehicles. For a line network, we provide sufficient\nconditions under which the traffic system is input-to-state stable, meaning the\nramp queue length remains bounded, on the control horizons, cost coefficients,\nand the inflows at the ramps. To further relax the requirement on exact\nknowledge of model parameters, we design a model-free controller that computes\nmetering rates directly from measurement data. In addition to the proposed\ncontrollers, we provide extensive simulations of other ramp metering algorithms\nin the literature as baselines for evaluating performance. Simulation results\nshow that traffic flow is unstable without ramp metering or with other ramp\nmetering methods under high inflows, congested initial conditions, and\nincomplete state measurements. In contrast, the designed model predictive and\nmodel-free controllers stabilize traffic flow and provide higher throughput\nwith measurements from an arbitrary subset of the cells.",
            "author": [
                "Zhexian Li",
                "Ketan Savla"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05265v1",
                "http://arxiv.org/pdf/2308.05265v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05257v1",
            "title": "Advancing Early Detection of Virus Yellows: Developing a Hybrid\n  Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet\n  Fields",
            "updated": "2023-08-09T23:36:03Z",
            "published": "2023-08-09T23:36:03Z",
            "summary": "Aphids are efficient vectors to transmit virus yellows in sugar beet fields.\nTimely monitoring and control of their populations are thus critical to prevent\nthe large-scale outbreak of virus yellows. However, the manual counting of\naphids, which is the most common practice, is labor-intensive and\ntime-consuming. Additionally, two of the biggest challenges in aphid counting\nare that aphids are small objects and their density distributions are varied in\ndifferent areas of the field. To address these challenges, we proposed a hybrid\nautomatic aphid counting network architecture which integrates the detection\nnetwork and the density map estimation network. When the distribution density\nof aphids is low, it utilizes an improved Yolov5 to count aphids. Conversely,\nwhen the distribution density of aphids is high, its witches to CSRNet to count\naphids. To the best of our knowledge, this is the first framework integrating\nthe detection network and the density map estimation network for counting\ntasks. Through comparison experiments of counting aphids, it verified that our\nproposed approach outperforms all other methods in counting aphids. It achieved\nthe lowest MAE and RMSE values for both the standard and high-density aphid\ndatasets: 2.93 and 4.01 (standard), and 34.19 and 38.66 (high-density),\nrespectively. Moreover, the AP of the improved Yolov5 is 5% higher than that of\nthe original Yolov5. Especially for extremely small aphids and densely\ndistributed aphids, the detection performance of the improved Yolov5 is\nsignificantly better than the original Yolov5. This work provides an effective\nearly warning for the virus yellows risk caused by aphids in sugar beet fields,\noffering protection for sugar beet growth and ensuring sugar beet yield. The\ndatasets and project code are released at:\nhttps://github.com/JunfengGaolab/Counting-Aphids.",
            "author": [
                "Xumin Gao",
                "Wenxin Xue",
                "Callum Lennox",
                "Mark Stevens",
                "Junfeng Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05257v1",
                "http://arxiv.org/pdf/2308.05257v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05256v1",
            "title": "Social Network Analysis and Validation of an Agent-Based Model",
            "updated": "2023-08-09T23:32:06Z",
            "published": "2023-08-09T23:32:06Z",
            "summary": "Agent-based models (ABMs) simulate the formation and evolution of social\nprocesses at a fundamental level by decoupling agent behavior from global\nobservations. In the case where ABM networks evolve over time as a result of\n(or in conjunction with) agent states, there is a need for understanding the\nrelationship between the dynamic processes and network structure. Social\nnetworks provide a natural set of tools for understanding the emergent\nrelationships of these systems. This work examines the utility of a collection\nof network comparison methods for the purpose of tracking network changes in an\nABM over time or between model parameters. Among the techniques examined is a\nnovel graph pseudometric based on heat content asymptotics, which have been\nshown to distinguish many isospectral graphs which are not isomorphic.\nAdditionally, we establish the use of observations about real-world networks\nfrom network science (e.g. fat-tailed degree distribution, small-world\nproperty) for ABM validation in the case where empirical population data is\nunavailable. These methods are all demonstrated on systematic perturbations of\nan original model simulating the formation of friendships in a population of\n20,000 agents in Cincinnati, OH.",
            "author": [
                "Karleigh Pine",
                "Joel Klipfel",
                "Jared Bennett",
                "Nathaniel Bade",
                "Christian Manasseh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05256v1",
                "http://arxiv.org/pdf/2308.05256v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.DM",
                "cs.MA",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05254v1",
            "title": "Data-driven Intra-Autonomous Systems Graph Generator",
            "updated": "2023-08-09T23:18:53Z",
            "published": "2023-08-09T23:18:53Z",
            "summary": "This paper introduces a novel deep-learning based generator of synthetic\ngraphs that represent intra-Autonomous System (AS) in the Internet, named\nDeep-generative graphs for the Internet (DGGI). It also presents a novel\nmassive dataset of real intra-AS graphs extracted from the project Internet\nTopology Data Kit (ITDK), called Internet Graphs (IGraphs). To create IGraphs,\nthe Filtered Recurrent Multi-level (FRM) algorithm for community extraction was\ndeveloped. It is shown that DGGI creates synthetic graphs which accurately\nreproduce the properties of centrality, clustering, assortativity, and node\ndegree. The DGGI generator overperforms existing Internet topology generators.\nOn average, DGGI improves the Maximum Mean Discrepancy (MMD) metric 84.4%,\n95.1%, 97.9%, and 94.7% for assortativity, betweenness, clustering, and node\ndegree, respectively.",
            "author": [
                "Caio Vinicius Dadauto",
                "Nelson Luis Saldanha da Fonseca",
                "Ricardo da Silva Torres"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05254v1",
                "http://arxiv.org/pdf/2308.05254v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05207v1",
            "title": "MNL-Prophet: Sequential Assortment Selection under Uncertainty",
            "updated": "2023-08-09T20:02:59Z",
            "published": "2023-08-09T20:02:59Z",
            "summary": "Due to numerous applications in retail and (online) advertising the problem\nof assortment selection has been widely studied under many combinations of\ndiscrete choice models and feasibility constraints. In many situations,\nhowever, an assortment of products has to be constructed gradually and without\naccurate knowledge of all possible alternatives; in such cases, existing\noffline approaches become inapplicable. We consider a stochastic variant of the\nassortment selection problem, where the parameters that determine the revenue\nand (relative) demand of each item are jointly drawn from some known\nitem-specific distribution. The items are observed sequentially in an arbitrary\nand unknown order; upon observing the realized parameters of each item, the\ndecision-maker decides irrevocably whether to include it in the constructed\nassortment, or forfeit it forever. The objective is to maximize the expected\ntotal revenue of the constructed assortment, relative to that of an offline\nalgorithm which foresees all the parameter realizations and computes the\noptimal assortment. We provide simple threshold-based online policies for the\nunconstrained and cardinality-constrained versions of the problem under a\nnatural class of substitutable choice models; as we show, our policies are\n(worst-case) optimal under the celebrated Multinomial Logit choice model. We\nextend our results to the case of knapsack constraints and discuss interesting\nconnections to the Prophet Inequality problem, which is already subsumed by our\nsetting.",
            "author": [
                "Vineet Goyal",
                "Salal Humair",
                "Orestis Papadigenopoulos",
                "Assaf Zeevi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05207v1",
                "http://arxiv.org/pdf/2308.05207v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05204v2",
            "title": "Optimal design of vaccination policies: A case study for Newfoundland\n  and Labrador",
            "updated": "2023-08-11T01:11:07Z",
            "published": "2023-08-09T19:51:17Z",
            "summary": "This paper proposes pandemic mitigation vaccination policies for Newfoundland\nand Labrador (NL) based on two compact mixed integer programming (MIP) models\nof the distance-based critical node detection problem (DCNDP). Our main focus\nis on two variants of the DCNDP that seek to minimize the number of connections\nwith lengths of at most one (1-DCNDP) and two (2-DCNDP). A polyhedral study for\nthe 1-DCNDP is conducted, and new aggregated inequalities are provided for the\n2-DCNDP. The computational experiments show that the 2-DCNDP with aggregated\ninequalities outperforms the one with disaggregated inequalities for graphs\nwith a density of at least 0.5%. We also study the strategic vaccine allocation\nproblem as a real-world application of the DCNDP and conduct a set of\ncomputational experiments on a simulated contact network of NL. Our\ncomputational results demonstrate that the DCNDP-based strategies can have a\nbetter performance in comparison with the real-world strategies implemented\nduring COVID-19.",
            "author": [
                "Faraz Khoshbakhtian",
                "Hamidreza Validi",
                "Mario Ventresca",
                "Dionne Aleman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05204v2",
                "http://arxiv.org/pdf/2308.05204v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "physics.soc-ph",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05175v1",
            "title": "Cycles in graphs and in hypergraphs",
            "updated": "2023-08-09T18:29:25Z",
            "published": "2023-08-09T18:29:25Z",
            "summary": "This is an expository paper. A $1$-cycle in a graph is a set $C$ of edges\nsuch that every vertex is contained in an even number of edges from $C$. E.g.,\na cycle in the sense of graph theory is a $1$-cycle, but not vice versa. It is\neasy to check that the sum (modulo $2$) of $1$-cycles is a $1$-cycle. In this\ntext we study the following problems: to find\n  $\\bullet$ the number of all 1-cycles in a given graph;\n  $\\bullet$ a small number of 1-cycles in a given graph such that any 1-cycle\nis the sum of some of them.\n  We also consider generalizations (of these problems) to graphs with symmetry,\nand to $2$-cycles in $2$-dimensional hypergraphs.",
            "author": [
                "E. Alkin",
                "S. Dzhenzher",
                "O. Nikitenko",
                "A. Skopenkov",
                "A. Voropaev"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05175v1",
                "http://arxiv.org/pdf/2308.05175v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "cs.DM",
                "math.AT",
                "math.CO",
                "55-01, 05-01, 05C25, 05C65"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05170v1",
            "title": "FPGA Resource-aware Structured Pruning for Real-Time Neural Networks",
            "updated": "2023-08-09T18:14:54Z",
            "published": "2023-08-09T18:14:54Z",
            "summary": "Neural networks achieve state-of-the-art performance in image classification,\nspeech recognition, scientific analysis and many more application areas. With\nthe ever-increasing need for faster computation and lower power consumption,\ndriven by real-time systems and Internet-of-Things (IoT) devices, FPGAs have\nemerged as suitable devices for deep learning inference. Due to the high\ncomputational complexity and memory footprint of neural networks, various\ncompression techniques, such as pruning, quantization and knowledge\ndistillation, have been proposed in literature. Pruning sparsifies a neural\nnetwork, reducing the number of multiplications and memory. However, pruning\noften fails to capture properties of the underlying hardware, causing\nunstructured sparsity and load-balance inefficiency, thus bottlenecking\nresource improvements. We propose a hardware-centric formulation of pruning, by\nformulating it as a knapsack problem with resource-aware tensor structures. The\nprimary emphasis is on real-time inference, with latencies in the order of\n1$\\mu$s, accelerated with hls4ml, an open-source framework for deep learning\ninference on FPGAs. Evaluated on a range of tasks, including real-time particle\nclassification at CERN's Large Hadron Collider and fast image classification,\nthe proposed method achieves a reduction ranging between 55% and 92% in the\nutilization of digital signal processing blocks (DSP) and up to 81% in block\nmemory (BRAM) utilization.",
            "author": [
                "Benjamin Ramhorst",
                "George A. Constantinides",
                "Vladimir Loncar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05170v1",
                "http://arxiv.org/pdf/2308.05170v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05081v2",
            "title": "Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic\n  Role Labeling",
            "updated": "2023-08-12T06:02:02Z",
            "published": "2023-08-09T17:20:14Z",
            "summary": "Video Semantic Role Labeling (VidSRL) aims to detect the salient events from\ngiven videos, by recognizing the predict-argument event structures and the\ninterrelationships between events. While recent endeavors have put forth\nmethods for VidSRL, they can be mostly subject to two key drawbacks, including\nthe lack of fine-grained spatial scene perception and the insufficiently\nmodeling of video temporality. Towards this end, this work explores a novel\nholistic spatio-temporal scene graph (namely HostSG) representation based on\nthe existing dynamic scene graph structures, which well model both the\nfine-grained spatial semantics and temporal dynamics of videos for VidSRL.\nBuilt upon the HostSG, we present a nichetargeting VidSRL framework. A\nscene-event mapping mechanism is first designed to bridge the gap between the\nunderlying scene structure and the high-level event semantic structure,\nresulting in an overall hierarchical scene-event (termed ICE) graph structure.\nWe further perform iterative structure refinement to optimize the ICE graph,\nsuch that the overall structure representation can best coincide with end task\ndemand. Finally, three subtask predictions of VidSRL are jointly decoded, where\nthe end-to-end paradigm effectively avoids error propagation. On the benchmark\ndataset, our framework boosts significantly over the current best-performing\nmodel. Further analyses are shown for a better understanding of the advances of\nour methods.",
            "author": [
                "Yu Zhao",
                "Hao Fei",
                "Yixin Cao",
                "Bobo Li",
                "Meishan Zhang",
                "Jianguo Wei",
                "Min Zhang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05081v2",
                "http://arxiv.org/pdf/2308.05081v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05068v2",
            "title": "Geometric Learning-Based Transformer Network for Estimation of\n  Segmentation Errors",
            "updated": "2023-08-10T04:26:42Z",
            "published": "2023-08-09T16:58:03Z",
            "summary": "Many segmentation networks have been proposed for 3D volumetric segmentation\nof tumors and organs at risk. Hospitals and clinical institutions seek to\naccelerate and minimize the efforts of specialists in image segmentation.\nStill, in case of errors generated by these networks, clinicians would have to\nmanually edit the generated segmentation maps. Given a 3D volume and its\nputative segmentation map, we propose an approach to identify and measure\nerroneous regions in the segmentation map. Our method can estimate error at any\npoint or node in a 3D mesh generated from a possibly erroneous volumetric\nsegmentation map, serving as a Quality Assurance tool. We propose a graph\nneural network-based transformer based on the Nodeformer architecture to\nmeasure and classify the segmentation errors at any point. We have evaluated\nour network on a high-resolution micro-CT dataset of the human inner-ear bony\nlabyrinth structure by simulating erroneous 3D segmentation maps. Our network\nincorporates a convolutional encoder to compute node-centric features from the\ninput micro-CT data, the Nodeformer to learn the latent graph embeddings, and a\nMulti-Layer Perceptron (MLP) to compute and classify the node-wise errors. Our\nnetwork achieves a mean absolute error of ~0.042 over other Graph Neural\nNetworks (GNN) and an accuracy of 79.53% over other GNNs in estimating and\nclassifying the node-wise errors, respectively. We also put forth vertex-normal\nprediction as a custom pretext task for pre-training the CNN encoder to improve\nthe network's overall performance. Qualitative analysis shows the efficiency of\nour network in correctly classifying errors and reducing misclassifications.",
            "author": [
                "Sneha Sree C",
                "Mohammad Al Fahim",
                "Keerthi Ram",
                "Mohanasankar Sivaprakasam"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05068v2",
                "http://arxiv.org/pdf/2308.05068v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05061v3",
            "title": "Fine-Tune Language Models as Multi-Modal Differential Equation Solvers",
            "updated": "2023-11-09T17:10:55Z",
            "published": "2023-08-09T16:44:25Z",
            "summary": "In the growing domain of scientific machine learning, in-context operator\nlearning has shown notable potential in learning operators and solving\ndifferential equations using prompted data, during the inference stage without\nweight updates. However, the current model's overdependence on function data,\nmay inadvertently overlook the invaluable human insight into the operator. To\naddress this, we present a transformation of in-context operator learning into\na multi-modal paradigm. In particular, we take inspiration from the recent\nsuccess of large language models, and propose using \"captions\" to integrate\nhuman knowledge about the operator, expressed through natural language\ndescriptions and equations. Also, we introduce a novel approach to train a\nlanguage-model-like architecture, or directly fine-tune existing language\nmodels, for in-context operator learning. We beat the baseline on single-modal\nlearning tasks, and also demonstrated the effectiveness of multi-modal learning\nin enhancing performance and reducing function data requirements. The proposed\nmethod not only significantly improves in-context operator learning, but also\ncreates a new path for the application of language models.",
            "author": [
                "Liu Yang",
                "Siting Liu",
                "Stanley J. Osher"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05061v3",
                "http://arxiv.org/pdf/2308.05061v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05047v2",
            "title": "Large-Scale Simulation of Shor's Quantum Factoring Algorithm",
            "updated": "2023-10-09T16:10:56Z",
            "published": "2023-08-09T16:19:52Z",
            "summary": "Shor's factoring algorithm is one of the most anticipated applications of\nquantum computing. However, the limited capabilities of today's quantum\ncomputers only permit a study of Shor's algorithm for very small numbers. Here\nwe show how large GPU-based supercomputers can be used to assess the\nperformance of Shor's algorithm for numbers that are out of reach for current\nand near-term quantum hardware. First, we study Shor's original factoring\nalgorithm. While theoretical bounds suggest success probabilities of only 3-4\n%, we find average success probabilities above 50 %, due to a high frequency of\n\"lucky\" cases, defined as successful factorizations despite unmet sufficient\nconditions. Second, we investigate a powerful post-processing procedure, by\nwhich the success probability can be brought arbitrarily close to one, with\nonly a single run of Shor's quantum algorithm. Finally, we study the\neffectiveness of this post-processing procedure in the presence of typical\nerrors in quantum processing hardware. We find that the quantum factoring\nalgorithm exhibits a particular form of universality and resilience against the\ndifferent types of errors. The largest semiprime that we have factored by\nexecuting Shor's algorithm on a GPU-based supercomputer, without exploiting\nprior knowledge of the solution, is 549755813701 = 712321 * 771781. We put\nforward the challenge of factoring, without oversimplification, a non-trivial\nsemiprime larger than this number on any quantum computing device.",
            "author": [
                "Dennis Willsch",
                "Madita Willsch",
                "Fengping Jin",
                "Hans De Raedt",
                "Kristel Michielsen"
            ],
            "link": [
                "http://dx.doi.org/10.3390/math11194222",
                "http://arxiv.org/abs/2308.05047v2",
                "http://arxiv.org/pdf/2308.05047v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05041v1",
            "title": "Critical configurations of the hard-core model on square grid graphs",
            "updated": "2023-08-09T16:16:50Z",
            "published": "2023-08-09T16:16:50Z",
            "summary": "We consider the hard-core model on a finite square grid graph with stochastic\nGlauber dynamics parametrized by the inverse temperature $\\beta$. We\ninvestigate how the transition between its two maximum-occupancy configurations\ntakes place in the low-temperature regime $\\beta\\to\\infty$ in the case of\nperiodic boundary conditions. The hard-core constraints and the grid symmetry\nmake the structure of the critical configurations, also known as essential\nsaddles, for this transition very rich and complex. We provide a comprehensive\ngeometrical characterization of the set of critical configurations that are\nasymptotically visited with probability one. In particular, we develop a novel\nisoperimetric inequality for hard-core configurations with a fixed number of\nparticles and we show how not only their size but also their shape determines\nthe characterization of the saddles.",
            "author": [
                "Simone Baldassarri",
                "Vanessa Jacquier",
                "Alessandro Zocca"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05041v1",
                "http://arxiv.org/pdf/2308.05041v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cond-mat.stat-mech",
                "math-ph",
                "math.MP",
                "82C20, 60J10, 60K35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05034v3",
            "title": "Kairos: Practical Intrusion Detection and Investigation using\n  Whole-system Provenance",
            "updated": "2023-09-28T03:02:57Z",
            "published": "2023-08-09T16:04:55Z",
            "summary": "Provenance graphs are structured audit logs that describe the history of a\nsystem's execution. Recent studies have explored a variety of techniques to\nanalyze provenance graphs for automated host intrusion detection, focusing\nparticularly on advanced persistent threats. Sifting through their design\ndocuments, we identify four common dimensions that drive the development of\nprovenance-based intrusion detection systems (PIDSes): scope (can PIDSes detect\nmodern attacks that infiltrate across application boundaries?), attack\nagnosticity (can PIDSes detect novel attacks without a priori knowledge of\nattack characteristics?), timeliness (can PIDSes efficiently monitor host\nsystems as they run?), and attack reconstruction (can PIDSes distill attack\nactivity from large provenance graphs so that sysadmins can easily understand\nand quickly respond to system intrusion?). We present KAIROS, the first PIDS\nthat simultaneously satisfies the desiderata in all four dimensions, whereas\nexisting approaches sacrifice at least one and struggle to achieve comparable\ndetection performance.\n  Kairos leverages a novel graph neural network-based encoder-decoder\narchitecture that learns the temporal evolution of a provenance graph's\nstructural changes to quantify the degree of anomalousness for each system\nevent. Then, based on this fine-grained information, Kairos reconstructs attack\nfootprints, generating compact summary graphs that accurately describe\nmalicious activity over a stream of system audit logs. Using state-of-the-art\nbenchmark datasets, we demonstrate that Kairos outperforms previous approaches.",
            "author": [
                "Zijun Cheng",
                "Qiujian Lv",
                "Jinyuan Liang",
                "Yan Wang",
                "Degang Sun",
                "Thomas Pasquier",
                "Xueyuan Han"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05034v3",
                "http://arxiv.org/pdf/2308.05034v3"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05020v1",
            "title": "The sequentially Cohen-Macaulay property of edge ideals of edge-weighted\n  graphs",
            "updated": "2023-08-09T15:31:01Z",
            "published": "2023-08-09T15:31:01Z",
            "summary": "Let $I(G_{\\mathbf{w}})$ be the edge ideal of an edge-weighted graph\n$(G,\\mathbf{w})$. We prove that $I(G_{\\mathbf{w}})$ is sequentially\nCohen-Macaulay for all weight functions $w$ if and only if $G$ is a Woodroofe\ngraph.",
            "author": [
                "Ly Thi Kieu Diem",
                "Nguyen Cong Minh",
                "Thanh Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05020v1",
                "http://arxiv.org/pdf/2308.05020v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "05E40, 13F55, 13D02"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05017v1",
            "title": "When and How Does Known Class Help Discover Unknown Ones? Provable\n  Understanding Through Spectral Analysis",
            "updated": "2023-08-09T15:27:21Z",
            "published": "2023-08-09T15:27:21Z",
            "summary": "Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled\nset by leveraging prior knowledge from a labeled set with known classes.\nDespite its importance, there is a lack of theoretical foundations for NCD.\nThis paper bridges the gap by providing an analytical framework to formalize\nand investigate when and how known classes can help discover novel classes.\nTailored to the NCD problem, we introduce a graph-theoretic representation that\ncan be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this\nobjective is equivalent to factorizing the graph's adjacency matrix, which\nallows us to derive a provable error bound and provide the sufficient and\nnecessary condition for NCD. Empirically, NSCL can match or outperform several\nstrong baselines on common benchmark datasets, which is appealing for practical\nusage while enjoying theoretical guarantees.",
            "author": [
                "Yiyou Sun",
                "Zhenmei Shi",
                "Yingyu Liang",
                "Yixuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05017v1",
                "http://arxiv.org/pdf/2308.05017v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05013v2",
            "title": "Dual Intents Graph Modeling for User-centric Group Discovery",
            "updated": "2023-08-10T02:30:44Z",
            "published": "2023-08-09T15:11:46Z",
            "summary": "Online groups have become increasingly prevalent, providing users with space\nto share experiences and explore interests. Therefore, user-centric group\ndiscovery task, i.e., recommending groups to users can help both users' online\nexperiences and platforms' long-term developments. Existing recommender methods\ncan not deal with this task as modeling user-group participation into a\nbipartite graph overlooks their item-side interests. Although there exist a few\nworks attempting to address this task, they still fall short in fully\npreserving the social context and ensuring effective interest representation\nlearning.\n  In this paper, we focus on exploring the intents that motivate users to\nparticipate in groups, which can be categorized into different types, like the\nsocial-intent and the personal interest-intent. The former refers to users\njoining a group affected by their social links, while the latter relates to\nusers joining groups with like-minded people for self-enjoyment. To comprehend\ndifferent intents, we propose a novel model, DiRec, that first models each\nintent separately and then fuses them together for predictions. Specifically,\nfor social-intent, we introduce the hypergraph structure to model the\nrelationship between groups and members, leading to a richer understanding of\nthe social context. As for interest-intent, we employ novel structural\nrefinement on the interactive graph to uncover more intricate user behaviors\nand group interests, realizing better representation learning of interests.\nFurthermore, we also observe the intent overlapping in real-world scenarios and\ndevise a novel self-supervised learning loss that encourages such alignment for\nfinal recommendations. Extensive experiments on three public datasets show the\nsignificant improvement of DiRec over the state-of-the-art methods.",
            "author": [
                "Xixi Wu",
                "Yun Xiong",
                "Yao Zhang",
                "Yizhu Jiao",
                "Jiawei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05013v2",
                "http://arxiv.org/pdf/2308.05013v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05011v2",
            "title": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with\n  Distinct Inlier Categories",
            "updated": "2023-08-10T14:08:26Z",
            "published": "2023-08-09T15:10:53Z",
            "summary": "With the increasing volume of astronomical data generated by modern survey\ntelescopes, automated pipelines and machine learning techniques have become\ncrucial for analyzing and extracting knowledge from these datasets. Anomaly\ndetection, i.e. the task of identifying irregular or unexpected patterns in the\ndata, is a complex challenge in astronomy. In this paper, we propose\nMulti-Class Deep Support Vector Data Description (MCDSVDD), an extension of the\nstate-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically\ndesigned to handle different inlier categories with distinct data\ndistributions. MCDSVDD uses a neural network to map the data into hyperspheres,\nwhere each hypersphere represents a specific inlier category. The distance of\neach sample from the centers of these hyperspheres determines the anomaly\nscore. We evaluate the effectiveness of MCDSVDD by comparing its performance\nwith several anomaly detection algorithms on a large dataset of astronomical\nlight-curves obtained from the Zwicky Transient Facility. Our results\ndemonstrate the efficacy of MCDSVDD in detecting anomalous sources while\nleveraging the presence of different inlier categories. The code and the data\nneeded to reproduce our results are publicly available at\nhttps://github.com/mperezcarrasco/AnomalyALeRCE.",
            "author": [
                "Manuel P\u00e9rez-Carrasco",
                "Guillermo Cabrera-Vives",
                "Lorena Hern\u00e1ndez-Garc\u00eda",
                "Francisco Forster",
                "Paula S\u00e1nchez-S\u00e1ez",
                "Alejandra Mu\u00f1oz Arancibia",
                "Nicol\u00e1s Astorga",
                "Franz Bauer",
                "Amelia Bayo",
                "Martina C\u00e1diz-Leyton",
                "Marcio Catelan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05011v2",
                "http://arxiv.org/pdf/2308.05011v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04996v1",
            "title": "Directed differential equation discovery using modified mutation and\n  cross-over operators",
            "updated": "2023-08-09T14:50:02Z",
            "published": "2023-08-09T14:50:02Z",
            "summary": "The discovery of equations with knowledge of the process origin is a tempting\nprospect. However, most equation discovery tools rely on gradient methods,\nwhich offer limited control over parameters. An alternative approach is the\nevolutionary equation discovery, which allows modification of almost every\noptimization stage. In this paper, we examine the modifications that can be\nintroduced into the evolutionary operators of the equation discovery algorithm,\ntaking inspiration from directed evolution techniques employed in fields such\nas chemistry and biology. The resulting approach, dubbed directed equation\ndiscovery, demonstrates a greater ability to converge towards accurate\nsolutions than the conventional method. To support our findings, we present\nexperiments based on Burgers', wave, and Korteweg--de Vries equations.",
            "author": [
                "Elizaveta Ivanchik",
                "Alexander Hvatov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04996v1",
                "http://arxiv.org/pdf/2308.04996v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04992v2",
            "title": "AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities",
            "updated": "2023-09-18T14:51:20Z",
            "published": "2023-08-09T14:45:13Z",
            "summary": "Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text\nand image) for a comprehensive understanding of entities. Despite the recent\nprogress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature\nof entities, limiting the ability to comprehend entities from various\nperspectives. In this paper, we construct AspectMMKG, the first MMKG with\naspect-related images by matching images to different entity aspects.\nSpecifically, we collect aspect-related images from a knowledge base, and\nfurther extract aspect-related sentences from the knowledge base as queries to\nretrieve a large number of aspect-related images via an online image search\nengine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and\n645,383 aspect-related images. We demonstrate the usability of AspectMMKG in\nentity aspect linking (EAL) downstream task and show that previous EAL models\nachieve a new state-of-the-art performance with the help of AspectMMKG. To\nfacilitate the research on aspect-related MMKG, we further propose an\naspect-related image retrieval (AIR) model, that aims to correct and expand\naspect-related images in AspectMMKG. We train an AIR model to learn the\nrelationship between entity image and entity aspect-related images by\nincorporating entity image, aspect, and aspect image information. Experimental\nresults indicate that the AIR model could retrieve suitable images for a given\nentity w.r.t different aspects.",
            "author": [
                "Jingdan Zhang",
                "Jiaan Wang",
                "Xiaodan Wang",
                "Zhixu Li",
                "Yanghua Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04992v2",
                "http://arxiv.org/pdf/2308.04992v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04981v1",
            "title": "Coupling liquid electrochemical TEM and mass-spectrometry to investigate\n  electrochemical reactions occurring in a Na-ion battery anode",
            "updated": "2023-08-09T14:29:39Z",
            "published": "2023-08-09T14:29:39Z",
            "summary": "In this study, we propose a novel approach for investigating the formation of\nsolid electrolyte interphase (SEI) in Na-ion batteries (NIB) through the\ncoupling of in situ liquid electrochemical transmission electron microscopy\n(ec-TEM) and gas-chromatography mass-spectrometry (GC/MS). To optimize this\ncoupling, we conducted experiments on the sodiation of hard carbon materials\n(HC) using two different setups: in situ ec-TEM holder (operating in an \"anode\nfree\" configuration, referred to as $\\mu$-battery) and ex-situ setup (Swagelok\nbattery configuration). In the in situ TEM experiments, we intentionally\ndegraded the electrolyte (NP30) using cyclic voltammetry (CV) and analyzed the\nrecovered liquid product using GC/MS, while the solid product ($\\mu$-chip) was\nanalyzed using TEM techniques in a post-mortem analysis. The ex-situ\nexperiments served as a reference to observe and detect the insertion of Na+\nions in the HC, SEI size (389 nm), SEI composition (P, Na, F, and O), and Na\nplating. Furthermore, the TEM analysis revealed a cyclability limitation in our\nin situ TEM system. This issue appears to be caused by the deposition of Na in\nthe form of a \"foam\" structure, resulting from the gas release during the\nreaction of Na with DMC/EC electrolyte. The foam structure, subsequently\ntransforms into a second SEI, is electrochemically inactive and reduce the\ncyclability of the battery. Overall, our results demonstrate the powerful\nsynergy achieved by coupling in situ ec-TEM and GC/MS techniques, which\nprovides a deeper understanding of the dynamics and behavior of SEI.\nConsequently, this knowledge contributes to the advancement of the new\ngeneration of NIB.",
            "author": [
                "Kevyn Gallegos Moncayo",
                "Nicolas Folastre",
                "Milan Toledo",
                "H\u00e9l\u00e8ne Tonnoir",
                "Fran\u00e7ois Rabuel",
                "Gr\u00e9gory Gachot",
                "Da Huo",
                "Arnaud Demorti\u00e8re"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04981v1",
                "http://arxiv.org/pdf/2308.04981v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04979v1",
            "title": "A remark on sequentially Cohen-Macaulay monomial ideals",
            "updated": "2023-08-09T14:26:31Z",
            "published": "2023-08-09T14:26:31Z",
            "summary": "Let $R=K[x_1,\\ldots,x_n]$ be the polynomial ring in $n$ variables over a\nfield $K$. We show that if $G$ is a connected graph with a basic $5$-cycle $C$,\nthen $G$ is a sequentially Cohen-Macaulay graph if and only if there exists a\nshedding vertex $x$ of $C$ such that $G\\setminus x$ and $G\\setminus N[x]$ are\nsequentially Cohen-Macaulay graphs. Furthermore, we study the sequentially\nCohen-Macaulay and Castelnuovo-Mumford regularity of square-free monomial\nideals in some special cases.",
            "author": [
                "Mozhgan Koolani",
                "Amir Mafi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04979v1",
                "http://arxiv.org/pdf/2308.04979v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "13C14, 13F55, 05E45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.16694v1",
            "title": "A Direct k-Way Hypergraph Partitioning Algorithm for Optimizing the\n  Steiner Tree Metric",
            "updated": "2023-08-09T13:56:56Z",
            "published": "2023-08-09T13:56:56Z",
            "summary": "Minimizing wire-lengths is one of the most important objectives in circuit\ndesign. The process involves initially placing the logical units (cells) of a\ncircuit onto a physical layout, and subsequently routing the wires to connect\nthe cells. Hypergraph partitioning (HGP) has been long used as a placement\nstrategy in this process. However, it has been replaced by other methods due to\nthe limitation that common HGP objective funtions only optimize wire-lengths\nimplicitly. In this work, we present a novel HGP formulation that maps a\nhypergraph $H$, representing a logical circuit, onto a routing layout\nrepresented by a weighted graph $G$. The objective is to minimize the total\nlength of all wires induced by the hyperedges of $H$ on $G$. To capture\nwire-lengths, we compute minimal Steiner trees - a metric commonly used in\nrouting algorithms. For this formulation, we present the first direct $k$-way\nmultilevel mapping algorithm that incorporates techniques used by the\nhighest-quality partitioning algorithms. We contribute a greedy mapping\nalgorithm to compute an initial solution and three refinement algorithms to\nimprove the initial: Two move-based local search heuristics (based on label\npropagation and the FM algorithm) and a refinement algorithm based on max-flow\nmin-cut computations. Our experiments demonstrate that our new algorithm\nachieves an improvement in the Steiner tree metric by 7% (median) on VLSI\ninstances when compared to the best performing partitioning algorithm that\noptimizes the mapping in a postprocessing step. Although computing Steiner\ntrees is an NP-hard problem, we achieve this improvement with only a 2-3 times\nslowdown in partitioning time compared to optimizing the connectivity metric.",
            "author": [
                "Tobias Heuer"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16694v1",
                "http://arxiv.org/pdf/2309.16694v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04958v1",
            "title": "Improving Autonomous Separation Assurance through Distributed\n  Reinforcement Learning with Attention Networks",
            "updated": "2023-08-09T13:44:35Z",
            "published": "2023-08-09T13:44:35Z",
            "summary": "Advanced Air Mobility (AAM) introduces a new, efficient mode of\ntransportation with the use of vehicle autonomy and electrified aircraft to\nprovide increasingly autonomous transportation between previously underserved\nmarkets. Safe and efficient navigation of low altitude aircraft through highly\ndense environments requires the integration of a multitude of complex\nobservations, such as surveillance, knowledge of vehicle dynamics, and weather.\nThe processing and reasoning on these observations pose challenges due to the\nvarious sources of uncertainty in the information while ensuring cooperation\nwith a variable number of aircraft in the airspace. These challenges coupled\nwith the requirement to make safety-critical decisions in real-time rule out\nthe use of conventional separation assurance techniques. We present a\ndecentralized reinforcement learning framework to provide autonomous\nself-separation capabilities within AAM corridors with the use of speed and\nvertical maneuvers. The problem is formulated as a Markov Decision Process and\nsolved by developing a novel extension to the sample-efficient, off-policy soft\nactor-critic (SAC) algorithm. We introduce the use of attention networks for\nvariable-length observation processing and a distributed computing architecture\nto achieve high training sample throughput as compared to existing approaches.\nA comprehensive numerical study shows that the proposed framework can ensure\nsafe and efficient separation of aircraft in high density, dynamic environments\nwith various sources of uncertainty.",
            "author": [
                "Marc W. Brittain",
                "Luis E. Alvarez",
                "Kara Breeden"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04958v1",
                "http://arxiv.org/pdf/2308.04958v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04952v3",
            "title": "Prototypical Kernel Learning and Open-set Foreground Perception for\n  Generalized Few-shot Semantic Segmentation",
            "updated": "2023-08-19T03:22:52Z",
            "published": "2023-08-09T13:38:52Z",
            "summary": "Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic\nSegmentation (FSS) to simultaneously segment unseen classes and seen classes\nduring evaluation. Previous works leverage additional branch or prototypical\naggregation to eliminate the constrained setting of FSS. However,\nrepresentation division and embedding prejudice, which heavily results in poor\nperformance of GFSS, have not been synthetical considered. We address the\naforementioned problems by jointing the prototypical kernel learning and\nopen-set foreground perception. Specifically, a group of learnable kernels is\nproposed to perform segmentation with each kernel in charge of a stuff class.\nThen, we explore to merge the prototypical learning to the update of base-class\nkernels, which is consistent with the prototype knowledge aggregation of\nfew-shot novel classes. In addition, a foreground contextual perception module\ncooperating with conditional bias based inference is adopted to perform\nclass-agnostic as well as open-set foreground detection, thus to mitigate the\nembedding prejudice and prevent novel targets from being misclassified as\nbackground. Moreover, we also adjust our method to the Class Incremental\nFew-shot Semantic Segmentation (CIFSS) which takes the knowledge of novel\nclasses in a incremental stream. Extensive experiments on PASCAL-5i and\nCOCO-20i datasets demonstrate that our method performs better than previous\nstate-of-the-art.",
            "author": [
                "Kai Huang",
                "Feigege Wang",
                "Ye Xi",
                "Yutao Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04952v3",
                "http://arxiv.org/pdf/2308.04952v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04950v1",
            "title": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
            "updated": "2023-08-09T13:33:27Z",
            "published": "2023-08-09T13:33:27Z",
            "summary": "Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git",
            "author": [
                "Shafna Fitria Nur Azizah",
                "Hasan Dwi Cahyono",
                "Sari Widya Sihwi",
                "Wisnu Widiarto"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04950v1",
                "http://arxiv.org/pdf/2308.04950v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04949v1",
            "title": "Branches Mutual Promotion for End-to-End Weakly Supervised Semantic\n  Segmentation",
            "updated": "2023-08-09T13:32:10Z",
            "published": "2023-08-09T13:32:10Z",
            "summary": "End-to-end weakly supervised semantic segmentation aims at optimizing a\nsegmentation model in a single-stage training process based on only image\nannotations. Existing methods adopt an online-trained classification branch to\nprovide pseudo annotations for supervising the segmentation branch. However,\nthis strategy makes the classification branch dominate the whole concurrent\ntraining process, hindering these two branches from assisting each other. In\nour work, we treat these two branches equally by viewing them as diverse ways\nto generate the segmentation map, and add interactions on both their\nsupervision and operation to achieve mutual promotion. For this purpose, a\nbidirectional supervision mechanism is elaborated to force the consistency\nbetween the outputs of these two branches. Thus, the segmentation branch can\nalso give feedback to the classification branch to enhance the quality of\nlocalization seeds. Moreover, our method also designs interaction operations\nbetween these two branches to exchange their knowledge to assist each other.\nExperiments indicate our work outperforms existing end-to-end weakly supervised\nsegmentation methods.",
            "author": [
                "Lei Zhu",
                "Hangzhou He",
                "Xinliang Zhang",
                "Qian Chen",
                "Shuang Zeng",
                "Qiushi Ren",
                "Yanye Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04949v1",
                "http://arxiv.org/pdf/2308.04949v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04947v1",
            "title": "Methods for Acquiring and Incorporating Knowledge into Stock Price\n  Prediction: A Survey",
            "updated": "2023-08-09T13:28:00Z",
            "published": "2023-08-09T13:28:00Z",
            "summary": "Predicting stock prices presents a challenging research problem due to the\ninherent volatility and non-linear nature of the stock market. In recent years,\nknowledge-enhanced stock price prediction methods have shown groundbreaking\nresults by utilizing external knowledge to understand the stock market. Despite\nthe importance of these methods, there is a scarcity of scholarly works that\nsystematically synthesize previous studies from the perspective of external\nknowledge types. Specifically, the external knowledge can be modeled in\ndifferent data structures, which we group into non-graph-based formats and\ngraph-based formats: 1) non-graph-based knowledge captures contextual\ninformation and multimedia descriptions specifically associated with an\nindividual stock; 2) graph-based knowledge captures interconnected and\ninterdependent information in the stock market. This survey paper aims to\nprovide a systematic and comprehensive description of methods for acquiring\nexternal knowledge from various unstructured data sources and then\nincorporating it into stock price prediction models. We also explore fusion\nmethods for combining external knowledge with historical price features.\nMoreover, this paper includes a compilation of relevant datasets and delves\ninto potential future research directions in this domain.",
            "author": [
                "Liping Wang",
                "Jiawei Li",
                "Lifan Zhao",
                "Zhizhuo Kou",
                "Xiaohan Wang",
                "Xinyi Zhu",
                "Hao Wang",
                "Yanyan Shen",
                "Lei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04947v1",
                "http://arxiv.org/pdf/2308.04947v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04943v1",
            "title": "Differentially Private Graph Neural Network with Importance-Grained\n  Noise Adaption",
            "updated": "2023-08-09T13:18:41Z",
            "published": "2023-08-09T13:18:41Z",
            "summary": "Graph Neural Networks (GNNs) with differential privacy have been proposed to\npreserve graph privacy when nodes represent personal and sensitive information.\nHowever, the existing methods ignore that nodes with different importance may\nyield diverse privacy demands, which may lead to over-protect some nodes and\ndecrease model utility. In this paper, we study the problem of\nimportance-grained privacy, where nodes contain personal data that need to be\nkept private but are critical for training a GNN. We propose NAP-GNN, a\nnode-importance-grained privacy-preserving GNN algorithm with privacy\nguarantees based on adaptive differential privacy to safeguard node\ninformation. First, we propose a Topology-based Node Importance Estimation\n(TNIE) method to infer unknown node importance with neighborhood and centrality\nawareness. Second, an adaptive private aggregation method is proposed to\nperturb neighborhood aggregation from node-importance-grain. Third, we propose\nto privately train a graph learning algorithm on perturbed aggregations in\nadaptive residual connection mode over multi-layers convolution for node-wise\ntasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees.\nEmpirical experiments over real-world graph datasets show that NAP-GNN achieves\na better trade-off between privacy and accuracy.",
            "author": [
                "Yuxin Qi",
                "Xi Lin",
                "Jun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04943v1",
                "http://arxiv.org/pdf/2308.04943v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04934v1",
            "title": "JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset\n  Student-Teacher Scenario for Video Action Recognition",
            "updated": "2023-08-09T13:09:07Z",
            "published": "2023-08-09T13:09:07Z",
            "summary": "We propose JEDI, a multi-dataset semi-supervised learning method, which\nefficiently combines knowledge from multiple experts, learned on different\ndatasets, to train and improve the performance of individual, per dataset,\nstudent models. Our approach achieves this by addressing two important problems\nin current machine learning research: generalization across datasets and\nlimitations of supervised training due to scarcity of labeled data. We start\nwith an arbitrary number of experts, pretrained on their own specific dataset,\nwhich form the initial set of student models. The teachers are immediately\nderived by concatenating the feature representations from the penultimate\nlayers of the students. We then train all models in a student-teacher\nsemi-supervised learning scenario until convergence. In our efficient approach,\nstudent-teacher training is carried out jointly and end-to-end, showing that\nboth students and teachers improve their generalization capacity during\ntraining. We validate our approach on four video action recognition datasets.\nBy simultaneously considering all datasets within a unified semi-supervised\nsetting, we demonstrate significant improvements over the initial experts.",
            "author": [
                "Lucian Bicsi",
                "Bogdan Alexe",
                "Radu Tudor Ionescu",
                "Marius Leordeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04934v1",
                "http://arxiv.org/pdf/2308.04934v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04928v2",
            "title": "GeodesicPSIM: Predicting the Quality of Static Mesh with Texture Map via\n  Geodesic Patch Similarity",
            "updated": "2023-08-24T02:11:15Z",
            "published": "2023-08-09T12:54:27Z",
            "summary": "Static meshes with texture maps have attracted considerable attention in both\nindustrial manufacturing and academic research, leading to an urgent\nrequirement for effective and robust objective quality evaluation. However,\ncurrent model-based static mesh quality metrics have obvious limitations: most\nof them only consider geometry information, while color information is ignored,\nand they have strict constraints for the meshes' geometrical topology. Other\nmetrics, such as image-based and point-based metrics, are easily influenced by\nthe prepossessing algorithms, e.g., projection and sampling, hampering their\nability to perform at their best. In this paper, we propose Geodesic Patch\nSimilarity (GeodesicPSIM), a novel model-based metric to accurately predict\nhuman perception quality for static meshes. After selecting a group keypoints,\n1-hop geodesic patches are constructed based on both the reference and\ndistorted meshes cleaned by an effective mesh cleaning algorithm. A two-step\npatch cropping algorithm and a patch texture mapping module refine the size of\n1-hop geodesic patches and build the relationship between the mesh geometry and\ncolor information, resulting in the generation of 1-hop textured geodesic\npatches. Three types of features are extracted to quantify the distortion:\npatch color smoothness, patch discrete mean curvature, and patch pixel color\naverage and variance. To the best of our knowledge, GeodesicPSIM is the first\nmodel-based metric especially designed for static meshes with texture maps.\nGeodesicPSIM provides state-of-the-art performance in comparison with\nimage-based, point-based, and video-based metrics on a newly created and\nchallenging database. We also prove the robustness of GeodesicPSIM by\nintroducing different settings of hyperparameters. Ablation studies also\nexhibit the effectiveness of three proposed features and the patch cropping\nalgorithm.",
            "author": [
                "Qi Yang",
                "Joel Jung",
                "Xiaozhong Xu",
                "Shan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04928v2",
                "http://arxiv.org/pdf/2308.04928v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04913v1",
            "title": "LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction\n  Following",
            "updated": "2023-08-09T12:26:37Z",
            "published": "2023-08-09T12:26:37Z",
            "summary": "E-commerce authoring involves creating attractive, abundant, and targeted\npromotional content to drive product sales. The emergence of large language\nmodels (LLMs) introduces an innovative paradigm, offering a unified solution to\naddress various authoring tasks within this scenario. However, mainstream LLMs\ntrained on general corpora with common sense knowledge reveal limitations in\nfitting complex and personalized features unique to e-commerce products and\ncustomers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility,\nraising concerns about safeguarding voluminous customer privacy data during\ntransmission. This paper proposes the LLaMA-E, the unified and customized\ninstruction-following language models focusing on diverse e-commerce authoring\ntasks. Specifically, the domain experts create the seed instruction set from\nthe tasks of ads generation, query-enhanced product title rewriting, product\nclassification, purchase intent speculation, and general Q&A. These tasks\nenable the models to comprehensively understand precise e-commerce authoring\nknowledge by interleaving features covering typical service aspects of\ncustomers, sellers, and platforms. The GPT-3.5 is introduced as a teacher\nmodel, which expands the seed instructions to form a training set for the\nLLaMA-E models with various scales. The experimental results show that the\nproposed LLaMA-E models achieve state-of-the-art results in quantitative and\nqualitative evaluations, also exhibiting the advantage in zero-shot scenes. To\nthe best of our knowledge, this study is the first to serve the LLMs to\nspecific e-commerce authoring scenarios.",
            "author": [
                "Kaize Shi",
                "Xueyao Sun",
                "Dingxian Wang",
                "Yinlin Fu",
                "Guandong Xu",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04913v1",
                "http://arxiv.org/pdf/2308.04913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04905v1",
            "title": "GraphCC: A Practical Graph Learning-based Approach to Congestion Control\n  in Datacenters",
            "updated": "2023-08-09T12:04:41Z",
            "published": "2023-08-09T12:04:41Z",
            "summary": "Congestion Control (CC) plays a fundamental role in optimizing traffic in\nData Center Networks (DCN). Currently, DCNs mainly implement two main CC\nprotocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are\nbased on Explicit Congestion Notification (ECN), where intermediate switches\nmark packets when they detect congestion. The ECN configuration is thus a\ncrucial aspect on the performance of CC protocols. Nowadays, network experts\nset static ECN parameters carefully selected to optimize the average network\nperformance. However, today's high-speed DCNs experience quick and abrupt\nchanges that severely change the network state (e.g., dynamic traffic\nworkloads, incast events, failures). This leads to under-utilization and\nsub-optimal performance. This paper presents GraphCC, a novel Machine\nLearning-based framework for in-network CC optimization. Our distributed\nsolution relies on a novel combination of Multi-agent Reinforcement Learning\n(MARL) and Graph Neural Networks (GNN), and it is compatible with widely\ndeployed ECN-based CC protocols. GraphCC deploys distributed agents on switches\nthat communicate with their neighbors to cooperate and optimize the global ECN\nconfiguration. In our evaluation, we test the performance of GraphCC under a\nwide variety of scenarios, focusing on the capability of this solution to adapt\nto new scenarios unseen during training (e.g., new traffic workloads, failures,\nupgrades). We compare GraphCC with a state-of-the-art MARL-based solution for\nECN tuning -- ACC -- and observe that our proposed solution outperforms the\nstate-of-the-art baseline in all of the evaluation scenarios, showing\nimprovements up to $20\\%$ in Flow Completion Time as well as significant\nreductions in buffer occupancy ($38.0-85.7\\%$).",
            "author": [
                "Guillermo Bern\u00e1rdez",
                "Jos\u00e9 Su\u00e1rez-Varela",
                "Xiang Shi",
                "Shihan Xiao",
                "Xiangle Cheng",
                "Pere Barlet-Ros",
                "Albert Cabellos-Aparicio"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04905v1",
                "http://arxiv.org/pdf/2308.04905v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04901v1",
            "title": "Towards true discovery of the differential equations",
            "updated": "2023-08-09T12:03:12Z",
            "published": "2023-08-09T12:03:12Z",
            "summary": "Differential equation discovery, a machine learning subfield, is used to\ndevelop interpretable models, particularly in nature-related applications. By\nexpertly incorporating the general parametric form of the equation of motion\nand appropriate differential terms, algorithms can autonomously uncover\nequations from data. This paper explores the prerequisites and tools for\nindependent equation discovery without expert input, eliminating the need for\nequation form assumptions. We focus on addressing the challenge of assessing\nthe adequacy of discovered equations when the correct equation is unknown, with\nthe aim of providing insights for reliable equation discovery without prior\nknowledge of the equation form.",
            "author": [
                "Alexander Hvatov",
                "Roman Titov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04901v1",
                "http://arxiv.org/pdf/2308.04901v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04892v1",
            "title": "Transmission and Color-guided Network for Underwater Image Enhancement",
            "updated": "2023-08-09T11:43:54Z",
            "published": "2023-08-09T11:43:54Z",
            "summary": "In recent years, with the continuous development of the marine industry,\nunderwater image enhancement has attracted plenty of attention. Unfortunately,\nthe propagation of light in water will be absorbed by water bodies and\nscattered by suspended particles, resulting in color deviation and low\ncontrast. To solve these two problems, we propose an Adaptive Transmission and\nDynamic Color guided network (named ATDCnet) for underwater image enhancement.\nIn particular, to exploit the knowledge of physics, we design an Adaptive\nTransmission-directed Module (ATM) to better guide the network. To deal with\nthe color deviation problem, we design a Dynamic Color-guided Module (DCM) to\npost-process the enhanced image color. Further, we design an\nEncoder-Decoder-based Compensation (EDC) structure with attention and a\nmulti-stage feature fusion mechanism to perform color restoration and contrast\nenhancement simultaneously. Extensive experiments demonstrate the\nstate-of-the-art performance of the ATDCnet on multiple benchmark datasets.",
            "author": [
                "Pan Mu",
                "Jing Fang",
                "Haotian Qian",
                "Cong Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04892v1",
                "http://arxiv.org/pdf/2308.04892v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04882v2",
            "title": "Approximation algorithm for finding multipacking on Cactus",
            "updated": "2023-11-14T11:41:05Z",
            "published": "2023-08-09T11:26:18Z",
            "summary": "For a graph $ G = (V, E) $ with vertex set $ V $ and edge set $ E $, a\nfunction $ f : V \\rightarrow \\{0, 1, 2, . . . , diam(G)\\} $ is called a\n\\emph{broadcast} on $ G $. For each vertex $ u \\in V $, if there exists a\nvertex $ v $ in $ G $ (possibly, $ u = v $) such that $ f (v) > 0 $ and $ d(u,\nv) \\leq f (v) $, then $ f $ is called a \\textit{dominating broadcast} on $ G $.\nThe \\textit{cost} of the dominating broadcast $f$ is the quantity $ \\sum_{v\\in\nV}f(v) $. The minimum cost of a dominating broadcast is the \\textit{broadcast\ndomination number} of $G$, denoted by $ \\gamma_{b}(G) $. A\n\\textit{multipacking} is a set $ S \\subseteq V $ in a graph $ G = (V, E) $ such\nthat for every vertex $ v \\in V $ and for every integer $ r \\geq 1 $, the ball\nof radius $ r $ around $ v $ contains at most $ r $ vertices of $ S $, that is,\nthere are at most $ r $ vertices in $ S $ at a distance at most $ r $ from $ v\n$ in $ G $. The \\textit{multipacking number} of $ G $ is the maximum\ncardinality of a multipacking of $ G $ and is denoted by $ mp(G) $. We show\nthat, for any cactus graph $G$, $\\gamma_b(G)\\leq\n\\frac{3}{2}mp(G)+\\frac{11}{2}$. We also show that $\\gamma_b(G)-mp(G)$ can be\narbitrarily large for cactus graphs by constructing an infinite family of\ncactus graphs such that the ratio $\\gamma_b(G)/mp(G)=4/3$, with $mp(G)$\narbitrarily large. This result shows that, for cactus graphs, we cannot improve\nthe bound $\\gamma_b(G)\\leq \\frac{3}{2}mp(G)+\\frac{11}{2}$ to a bound in the\nform $\\gamma_b(G)\\leq c_1\\cdot mp(G)+c_2$, for any constant $c_1<4/3$ and\n$c_2$. Moreover, we provide an $O(n)$-time algorithm to construct a\nmultipacking of $G$ of size at least $ \\frac{2}{3}mp(G)-\\frac{11}{3} $, where\n$n$ is the number of vertices of the graph $G$.",
            "author": [
                "Sandip Das",
                "Sk Samim Islam"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04882v2",
                "http://arxiv.org/pdf/2308.04882v2"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04880v1",
            "title": "Learning multi-domain feature relation for visible and Long-wave\n  Infrared image patch matching",
            "updated": "2023-08-09T11:23:32Z",
            "published": "2023-08-09T11:23:32Z",
            "summary": "Recently, learning-based algorithms have achieved promising performance on\ncross-spectral image patch matching, which, however, is still far from\nsatisfactory for practical application. On the one hand, a lack of large-scale\ndataset with diverse scenes haunts its further improvement for learning-based\nalgorithms, whose performances and generalization rely heavily on the dataset\nsize and diversity. On the other hand, more emphasis has been put on feature\nrelation in the spatial domain whereas the scale dependency between features\nhas often been ignored, leading to performance degeneration especially when\nencountering significant appearance variations for cross-spectral patches. To\naddress these issues, we publish, to be best of our knowledge, the largest\nvisible and Long-wave Infrared (LWIR) image patch matching dataset, termed\nVL-CMIM, which contains 1300 pairs of strictly aligned visible and LWIR images\nand over 2 million patch pairs covering diverse scenes such as asteroid, field,\ncountry, build, street and water.In addition, a multi-domain feature relation\nlearning network (MD-FRN) is proposed. Input by the features extracted from a\nfour-branch network, both feature relations in spatial and scale domains are\nlearned via a spatial correlation module (SCM) and multi-scale adaptive\naggregation module (MSAG), respectively. To further aggregate the multi-domain\nrelations, a deep domain interactive mechanism (DIM) is applied, where the\nlearnt spatial-relation and scale-relation features are exchanged and further\ninput into MSCRM and SCM. This mechanism allows our model to learn interactive\ncross-domain feature relations, leading to improved robustness to significant\nappearance changes due to different modality.",
            "author": [
                "Xiuwei Zhang",
                "Yanping Li",
                "Zhaoshuai Qi",
                "Yi Sun",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04880v1",
                "http://arxiv.org/pdf/2308.04880v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04851v1",
            "title": "CME Propagation Through the Heliosphere: Status and Future of\n  Observations and Model Development",
            "updated": "2023-08-09T10:26:23Z",
            "published": "2023-08-09T10:26:23Z",
            "summary": "The ISWAT clusters H1+H2 have a focus on interplanetary space and its\ncharacteristics, especially on the large-scale co-rotating and transient\nstructures impacting Earth. SIRs, generated by the interaction between\nhigh-speed solar wind originating in large-scale open coronal magnetic fields\nand slower solar wind from closed magnetic fields, are regions of compressed\nplasma and magnetic field followed by high-speed streams that recur at the ca.\n27 day solar rotation period. Short-term reconfigurations of the lower coronal\nmagnetic field generate flare emissions and provide the energy to accelerate\nenormous amounts of magnetised plasma and particles in the form of CMEs into\ninterplanetary space. The dynamic interplay between these phenomena changes the\nconfiguration of interplanetary space on various temporal and spatial scales\nwhich in turn influences the propagation of individual structures. While\nconsiderable efforts have been made to model the solar wind, we outline the\nlimitations arising from the rather large uncertainties in parameters inferred\nfrom observations that make reliable predictions of the structures impacting\nEarth difficult. Moreover, the increased complexity of interplanetary space as\nsolar activity rises in cycle 25 is likely to pose a challenge to these models.\nCombining observational and modeling expertise will extend our knowledge of the\nrelationship between these different phenomena and the underlying physical\nprocesses, leading to improved models and scientific understanding and\nmore-reliable space-weather forecasting. The current paper summarizes the\nefforts and progress achieved in recent years, identifies open questions, and\ngives an outlook for the next 5-10 years. It acts as basis for updating the\nexisting COSPAR roadmap by Schrijver+ (2015), as well as providing a useful and\npractical guide for peer-users and the next generation of space weather\nscientists.",
            "author": [
                "M. Temmer",
                "C. Scolini",
                "I. G. Richardson",
                "S. G. Heinemann",
                "E. Paouris",
                "A. Vourlidas",
                "M. M. Bisi",
                "writing teams",
                ":",
                "N. Al-Haddad",
                "T. Amerstorfer",
                "L. Barnard",
                "D. Buresova",
                "S. J. Hofmeister",
                "K. Iwai",
                "B. V. Jackson",
                "R. Jarolim",
                "L. K. Jian",
                "J. A. Linker",
                "N. Lugaz",
                "P. K. Manoharan",
                "M. L. Mays",
                "W. Mishra",
                "M. J. Owens",
                "E. Palmerio",
                "B. Perri",
                "J. Pomoell",
                "R. F. Pinto",
                "E. Samara",
                "T. Singh",
                "D. Sur",
                "C. Verbeke",
                "A. M. Veronig",
                "B. Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04851v1",
                "http://arxiv.org/pdf/2308.04851v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04847v2",
            "title": "Vehicle State Estimation through Modular Factor Graph-based Fusion of\n  Multiple Sensors",
            "updated": "2023-10-02T10:18:45Z",
            "published": "2023-08-09T10:21:34Z",
            "summary": "This study focuses on the critical aspect of robust state estimation for the\nsafe navigation of an Autonomous Vehicle (AV). Existing literature primarily\nemploys two prevalent techniques for state estimation, namely filtering-based\nand graph-based approaches. Factor Graph (FG) is a graph-based approach,\nconstructed using Values and Factors for Maximum Aposteriori (MAP) estimation,\nthat offers a modular architecture that facilitates the integration of inputs\nfrom diverse sensors. However, most FG-based architectures in current use\nrequire explicit knowledge of sensor parameters and are designed for single\nsetups. To address these limitations, this research introduces a novel\nplug-and-play FG-based state estimator capable of operating without predefined\nsensor parameters. This estimator is suitable for deployment in multiple sensor\nsetups, offering convenience and providing comprehensive state estimation at a\nhigh frequency, including mean and covariances. The proposed algorithm\nundergoes rigorous validation using various sensor setups on two different\nvehicles: a quadricycle and a shuttle bus. The algorithm provides accurate and\nrobust state estimation across diverse scenarios, even when faced with degraded\nGlobal Navigation Satellite System (GNSS) measurements or complete outages.\nThese findings highlight the efficacy and reliability of the algorithm in\nreal-world AV applications.",
            "author": [
                "Pragyan Dahal",
                "Jai Prakash",
                "Stefano Arrigoni",
                "Francesco Braghin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04847v2",
                "http://arxiv.org/pdf/2308.04847v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05129v1",
            "title": "Are Sex-based Physiological Differences the Cause of Gender Bias for\n  Chest X-ray Diagnosis?",
            "updated": "2023-08-09T10:19:51Z",
            "published": "2023-08-09T10:19:51Z",
            "summary": "While many studies have assessed the fairness of AI algorithms in the medical\nfield, the causes of differences in prediction performance are often unknown.\nThis lack of knowledge about the causes of bias hampers the efficacy of bias\nmitigation, as evidenced by the fact that simple dataset balancing still often\nperforms best in reducing performance gaps but is unable to resolve all\nperformance differences. In this work, we investigate the causes of gender bias\nin machine learning-based chest X-ray diagnosis. In particular, we explore the\nhypothesis that breast tissue leads to underexposure of the lungs and causes\nlower model performance. Methodologically, we propose a new sampling method\nwhich addresses the highly skewed distribution of recordings per patient in two\nwidely used public datasets, while at the same time reducing the impact of\nlabel errors. Our comprehensive analysis of gender differences across diseases,\ndatasets, and gender representations in the training set shows that dataset\nimbalance is not the sole cause of performance differences. Moreover, relative\ngroup performance differs strongly between datasets, indicating important\ndataset-specific factors influencing male/female group performance. Finally, we\ninvestigate the effect of breast tissue more specifically, by cropping out the\nbreasts from recordings, finding that this does not resolve the observed\nperformance gaps. In conclusion, our results indicate that dataset-specific\nfactors, not fundamental physiological differences, are the main drivers of\nmale--female performance gaps in chest X-ray analyses on widely used NIH and\nCheXpert Dataset.",
            "author": [
                "Nina Weng",
                "Siavash Bigdeli",
                "Eike Petersen",
                "Aasa Feragen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05129v1",
                "http://arxiv.org/pdf/2308.05129v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05764v1",
            "title": "Unlocking the Diagnostic Potential of ECG through Knowledge Transfer\n  from Cardiac MRI",
            "updated": "2023-08-09T10:05:11Z",
            "published": "2023-08-09T10:05:11Z",
            "summary": "The electrocardiogram (ECG) is a widely available diagnostic tool that allows\nfor a cost-effective and fast assessment of the cardiovascular health. However,\nmore detailed examination with expensive cardiac magnetic resonance (CMR)\nimaging is often preferred for the diagnosis of cardiovascular diseases. While\nproviding detailed visualization of the cardiac anatomy, CMR imaging is not\nwidely available due to long scan times and high costs. To address this issue,\nwe propose the first self-supervised contrastive approach that transfers\ndomain-specific information from CMR images to ECG embeddings. Our approach\ncombines multimodal contrastive learning with masked data modeling to enable\nholistic cardiac screening solely from ECG data. In extensive experiments using\ndata from 40,044 UK Biobank subjects, we demonstrate the utility and\ngeneralizability of our method. We predict the subject-specific risk of various\ncardiovascular diseases and determine distinct cardiac phenotypes solely from\nECG data. In a qualitative analysis, we demonstrate that our learned ECG\nembeddings incorporate information from CMR image regions of interest. We make\nour entire pipeline publicly available, including the source code and\npre-trained model weights.",
            "author": [
                "\u00d6zg\u00fcn Turgut",
                "Philip M\u00fcller",
                "Paul Hager",
                "Suprosanna Shit",
                "Sophie Starck",
                "Martin J. Menten",
                "Eimo Martens",
                "Daniel Rueckert"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05764v1",
                "http://arxiv.org/pdf/2308.05764v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04842v1",
            "title": "Merging in a Coupled Driving Simulator: How do drivers resolve\n  conflicts?",
            "updated": "2023-08-09T10:04:48Z",
            "published": "2023-08-09T10:04:48Z",
            "summary": "Traffic interactions between merging and highway vehicles are a major topic\nof research, yielding many empirical studies and models of driver behaviour.\nMost of these studies on merging use naturalistic data. Although this provides\ninsight into human gap acceptance and traffic flow effects, it obscures the\noperational inputs of interacting drivers. Besides that, researchers have no\ncontrol over the vehicle kinematics (i.e., positions and velocities) at the\nstart of the interactions. Therefore the relationship between initial\nkinematics and the outcome of the interaction is difficult to investigate. To\naddress these gaps, we conducted an experiment in a coupled driving simulator\nwith a simplified, top-down view, merging scenario with two vehicles. We found\nthat kinematics can explain the outcome (i.e., which driver merges first) and\nthe duration of the merging conflict. Furthermore, our results show that\ndrivers use key decision moments combined with constant acceleration inputs\n(intermittent piecewise-constant control) during merging. This indicates that\nthey do not continuously optimize their expected utility. Therefore, these\nresults advocate the development of interaction models based on intermittent\npiecewise-constant control. We hope our work can contribute to this development\nand to the fundamental knowledge of interactive driver behaviour.",
            "author": [
                "Olger Siebinga",
                "Arkady Zgonnikov",
                "David A. Abbink"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04842v1",
                "http://arxiv.org/pdf/2308.04842v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.13530v1",
            "title": "Quantitative analysis of secondary Bjerkenes forces in various liquids",
            "updated": "2023-08-09T09:49:09Z",
            "published": "2023-08-09T09:49:09Z",
            "summary": "Numerically calculating the interaction forces between two free bubbles under\nthe action of a background of random acoustic radiation, we highlight the\ncontributions of radiative coefficient and absorption damping coefficient to\nthe size of these forces.It is quantitatively demonstrated, for different radii\nof the oscillating bubbles, that the scattering absorption forces and the\nscattering scattering forces are close in magnitude.For superfluid helium, the\nforces change direction, oscillatingly, and the ratio of the forces is much\nless than one.",
            "author": [
                "Ion Simaciu",
                "Zoltan Borsos",
                "Viorel Drafta",
                "Gheorghe Dumitrescu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.13530v1",
                "http://arxiv.org/pdf/2308.13530v1"
            ],
            "primary_category": "physics.gen-ph",
            "category": [
                "physics.gen-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04831v1",
            "title": "Fairness Notions in DAG-based DLTs",
            "updated": "2023-08-09T09:40:14Z",
            "published": "2023-08-09T09:40:14Z",
            "summary": "This paper investigates the issue of fairness in Distributed Ledger\nTechnology (DLT), specifically focusing on the shortcomings observed in current\nblockchain systems due to Miner Extractable Value (MEV) phenomena and systemic\ncentralization. We explore the potential of Directed Acyclic Graphs (DAGs) as a\nsolution to address or mitigate these fairness concerns. Our objective is to\ngain a comprehensive understanding of fairness in DAG-based DLTs by examining\nits different aspects and measurement metrics. We aim to establish a shared\nknowledge base that facilitates accurate fairness assessment and allows for an\nevaluation of whether DAG-based DLTs offer a more equitable design. We describe\nthe various dimensions of fairness and conduct a comparative analysis to\nexamine how they relate to different components of DLTs. This analysis serves\nas a catalyst for further research, encouraging the development of\ncryptographic systems that promote fairness.",
            "author": [
                "Mayank Raikwar",
                "Nikita Polyanskii",
                "Sebastian M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04831v1",
                "http://arxiv.org/pdf/2308.04831v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04821v1",
            "title": "HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task\n  Switching Network for MRI Reconstruction",
            "updated": "2023-08-09T09:22:49Z",
            "published": "2023-08-09T09:22:49Z",
            "summary": "Parallel imaging, a fast MRI technique, involves dynamic adjustments based on\nthe configuration i.e. number, positioning, and sensitivity of the coils with\nrespect to the anatomy under study. Conventional deep learning-based image\nreconstruction models have to be trained or fine-tuned for each configuration,\nposing a barrier to clinical translation, given the lack of computational\nresources and machine learning expertise for clinicians to train models at\ndeployment. Joint training on diverse datasets learns a single weight set that\nmight underfit to deviated configurations. We propose, HyperCoil-Recon, a\nhypernetwork-based coil configuration task-switching network for multi-coil MRI\nreconstruction that encodes varying configurations of the numbers of coils in a\nmulti-tasking perspective, posing each configuration as a task. The\nhypernetworks infer and embed task-specific weights into the reconstruction\nnetwork, 1) effectively utilizing the contextual knowledge of common and\nvarying image features among the various fields-of-view of the coils, and 2)\nenabling generality to unseen configurations at test time. Experiments reveal\nthat our approach 1) adapts on the fly to various unseen configurations up to\n32 coils when trained on lower numbers (i.e. 7 to 11) of randomly varying\ncoils, and to 120 deviated unseen configurations when trained on 18\nconfigurations in a single model, 2) matches the performance of coil\nconfiguration-specific models, and 3) outperforms configuration-invariant\nmodels with improvement margins of around 1 dB / 0.03 and 0.3 dB / 0.02 in PSNR\n/ SSIM for knee and brain data. Our code is available at\nhttps://github.com/sriprabhar/HyperCoil-Recon",
            "author": [
                "Sriprabha Ramanarayanan",
                "Mohammad Al Fahim",
                "Rahul G. S.",
                "Amrit Kumar Jethi",
                "Keerthi Ram",
                "Mohanasankar Sivaprakasam"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04821v1",
                "http://arxiv.org/pdf/2308.04821v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04814v1",
            "title": "Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art\n  and Challenges",
            "updated": "2023-08-09T09:12:35Z",
            "published": "2023-08-09T09:12:35Z",
            "summary": "Ontologies are used in various domains, with RDF and OWL being prominent\nstandards for ontology development. RDF is favored for its simplicity and\nflexibility, while OWL enables detailed domain knowledge representation.\nHowever, as ontologies grow larger and more expressive, reasoning complexity\nincreases, and traditional reasoners struggle to perform efficiently. Despite\noptimization efforts, scalability remains an issue. Additionally, advancements\nin automated knowledge base construction have created large and expressive\nontologies that are often noisy and inconsistent, posing further challenges for\nconventional reasoners. To address these challenges, researchers have explored\nneuro-symbolic approaches that combine neural networks' learning capabilities\nwith symbolic systems' reasoning abilities. In this chapter,we provide an\noverview of the existing literature in the field of neuro-symbolic deductive\nreasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL,\ndiscussing the techniques employed, the tasks they address, and other relevant\nefforts in this area.",
            "author": [
                "Gunjan Singh",
                "Sumit Bhatia",
                "Raghava Mutharaju"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04814v1",
                "http://arxiv.org/pdf/2308.04814v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04811v1",
            "title": "A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with\n  Commonsense Knowledge",
            "updated": "2023-08-09T09:09:17Z",
            "published": "2023-08-09T09:09:17Z",
            "summary": "The context-aware emotional reasoning ability of AI systems, especially in\nconversations, is of vital importance in applications such as online opinion\nmining from social media and empathetic dialogue systems. Due to the implicit\nnature of conveying emotions in many scenarios, commonsense knowledge is widely\nutilized to enrich utterance semantics and enhance conversation modeling.\nHowever, most previous knowledge infusion methods perform empirical knowledge\nfiltering and design highly customized architectures for knowledge interaction\nwith the utterances, which can discard useful knowledge aspects and limit their\ngeneralizability to different knowledge sources. Based on these observations,\nwe propose a Bipartite Heterogeneous Graph (BHG) method for enhancing emotional\nreasoning with commonsense knowledge. In BHG, the extracted context-aware\nutterance representations and knowledge representations are modeled as\nheterogeneous nodes. Two more knowledge aggregation node types are proposed to\nperform automatic knowledge filtering and interaction. BHG-based knowledge\ninfusion can be directly generalized to multi-type and multi-grained knowledge\nsources. In addition, we propose a Multi-dimensional Heterogeneous Graph\nTransformer (MHGT) to perform graph reasoning, which can retain unchanged\nfeature spaces and unequal dimensions for heterogeneous node types during\ninference to prevent unnecessary loss of information. Experiments show that\nBHG-based methods significantly outperform state-of-the-art knowledge infusion\nmethods and show generalized knowledge infusion ability with higher efficiency.\nFurther analysis proves that previous empirical knowledge filtering methods do\nnot guarantee to provide the most useful knowledge information. Our code is\navailable at: https://github.com/SteveKGYang/BHG.",
            "author": [
                "Kailai Yang",
                "Tianlin Zhang",
                "Shaoxiong Ji",
                "Sophia Ananiadou"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614758",
                "http://arxiv.org/abs/2308.04811v1",
                "http://arxiv.org/pdf/2308.04811v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04807v1",
            "title": "Parallel Knowledge Enhancement based Framework for Multi-behavior\n  Recommendation",
            "updated": "2023-08-09T09:01:37Z",
            "published": "2023-08-09T09:01:37Z",
            "summary": "Multi-behavior recommendation algorithms aim to leverage the multiplex\ninteractions between users and items to learn users' latent preferences. Recent\nmulti-behavior recommendation frameworks contain two steps: fusion and\nprediction. In the fusion step, advanced neural networks are used to model the\nhierarchical correlations between user behaviors. In the prediction step,\nmultiple signals are utilized to jointly optimize the model with a multi-task\nlearning (MTL) paradigm. However, recent approaches have not addressed the\nissue caused by imbalanced data distribution in the fusion step, resulting in\nthe learned relationships being dominated by high-frequency behaviors. In the\nprediction step, the existing methods use a gate mechanism to directly\naggregate expert information generated by coupling input, leading to negative\ninformation transfer. To tackle these issues, we propose a Parallel Knowledge\nEnhancement Framework (PKEF) for multi-behavior recommendation. Specifically,\nwe enhance the hierarchical information propagation in the fusion step using\nparallel knowledge (PKF). Meanwhile, in the prediction step, we decouple the\nrepresentations to generate expert information and introduce a projection\nmechanism during aggregation to eliminate gradient conflicts and alleviate\nnegative transfer (PME). We conduct comprehensive experiments on three\nreal-world datasets to validate the effectiveness of our model. The results\nfurther demonstrate the rationality and effectiveness of the designed PKF and\nPME modules. The source code and datasets are available at\nhttps://github.com/MC-CV/PKEF.",
            "author": [
                "Chang Meng",
                "Chenhao Zhai",
                "Yu Yang",
                "Hengyu Zhang",
                "Xiu Li"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615004",
                "http://arxiv.org/abs/2308.04807v1",
                "http://arxiv.org/pdf/2308.04807v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04802v1",
            "title": "Generalized Unbiased Scene Graph Generation",
            "updated": "2023-08-09T08:51:03Z",
            "published": "2023-08-09T08:51:03Z",
            "summary": "Existing Unbiased Scene Graph Generation (USGG) methods only focus on\naddressing the predicate-level imbalance that high-frequency classes dominate\npredictions of rare ones, while overlooking the concept-level imbalance.\nActually, even if predicates themselves are balanced, there is still a\nsignificant concept-imbalance within them due to the long-tailed distribution\nof contexts (i.e., subject-object combinations). This concept-level imbalance\nposes a more pervasive and challenging issue compared to the predicate-level\nimbalance since subject-object pairs are inherently complex in combinations.\nHence, we introduce a novel research problem: Generalized Unbiased Scene Graph\nGeneration (G-USGG), which takes into account both predicate-level and\nconcept-level imbalance. To the end, we propose the Multi-Concept Learning\n(MCL) framework, which ensures a balanced learning process across rare/\nuncommon/ common concepts. MCL first quantifies the concept-level imbalance\nacross predicates in terms of different amounts of concepts, representing as\nmultiple concept-prototypes within the same class. It then effectively learns\nconcept-prototypes by applying the Concept Regularization (CR) technique.\nFurthermore, to achieve balanced learning over different concepts, we introduce\nthe Balanced Prototypical Memory (BPM), which guides SGG models to generate\nbalanced representations for concept-prototypes. Extensive experiments\ndemonstrate the remarkable efficacy of our model-agnostic strategy in enhancing\nthe performance of benchmark models on both VG-SGG and OI-SGG datasets, leading\nto new state-of-the-art achievements in two key aspects: predicate-level\nunbiased relation recognition and concept-level compositional generability.",
            "author": [
                "Xinyu Lyu",
                "Lianli Gao",
                "Junlin Xie",
                "Pengpeng Zeng",
                "Yulu Tian",
                "Jie Shao",
                "Heng Tao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04802v1",
                "http://arxiv.org/pdf/2308.04802v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05128v1",
            "title": "High-Level Features Parallelization for Inference Cost Reduction Through\n  Selective Attention",
            "updated": "2023-08-09T08:49:29Z",
            "published": "2023-08-09T08:49:29Z",
            "summary": "In this work, we parallelize high-level features in deep networks to\nselectively skip or select class-specific features to reduce inference costs.\nThis challenges most deep learning methods due to their limited ability to\nefficiently and effectively focus on selected class-specific features without\nretraining. We propose a serial-parallel hybrid architecture with serial\ngeneric low-level features and parallel high-level features. This accounts for\nthe fact that many high-level features are class-specific rather than generic,\nand has connections to recent neuroscientific findings that observe spatially\nand contextually separated neural activations in the human brain. Our approach\nprovides the unique functionality of cutouts: selecting parts of the network to\nfocus on only relevant subsets of classes without requiring retraining. High\nperformance is maintained, but the cost of inference can be significantly\nreduced. In some of our examples, up to $75\\,\\%$ of parameters are skipped and\n$35\\,\\%$ fewer GMACs (Giga multiply-accumulate) operations are used as the\napproach adapts to a change in task complexity. This is important for mobile,\nindustrial, and robotic applications where reducing the number of parameters,\nthe computational complexity, and thus the power consumption can be paramount.\nAnother unique functionality is that it allows processing to be directly\ninfluenced by enhancing or inhibiting high-level class-specific features,\nsimilar to the mechanism of selective attention in the human brain. This can be\nrelevant for cross-modal applications, the use of semantic prior knowledge,\nand/or context-aware processing.",
            "author": [
                "Andr\u00e9 Peter Kelm",
                "Lucas Schmidt",
                "Tim Rolff",
                "Christian Wilms",
                "Ehsan Yaghoubi",
                "Simone Frintrop"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05128v1",
                "http://arxiv.org/pdf/2308.05128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04800v1",
            "title": "ADMUS: A Progressive Question Answering Framework Adaptable to Multiple\n  Knowledge Sources",
            "updated": "2023-08-09T08:46:39Z",
            "published": "2023-08-09T08:46:39Z",
            "summary": "With the introduction of deep learning models, semantic parsingbased\nknowledge base question answering (KBQA) systems have achieved high performance\nin handling complex questions. However, most existing approaches primarily\nfocus on enhancing the model's effectiveness on individual benchmark datasets,\ndisregarding the high costs of adapting the system to disparate datasets in\nreal-world scenarios (e.g., multi-tenant platform). Therefore, we present\nADMUS, a progressive knowledge base question answering framework designed to\naccommodate a wide variety of datasets, including multiple languages, diverse\nbackbone knowledge bases, and disparate question answering datasets. To\naccomplish the purpose, we decouple the architecture of conventional KBQA\nsystems and propose this dataset-independent framework. Our framework supports\nthe seamless integration of new datasets with minimal effort, only requiring\ncreating a dataset-related micro-service at a negligible cost. To enhance the\nusability of ADUMS, we design a progressive framework consisting of three\nstages, ranges from executing exact queries, generating approximate queries and\nretrieving open-domain knowledge referring from large language models. An\nonline demonstration of ADUMS is available at:\nhttps://answer.gstore.cn/pc/index.html",
            "author": [
                "Yirui Zhan",
                "Yanzeng Li",
                "Minhao Zhang",
                "Lei Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04800v1",
                "http://arxiv.org/pdf/2308.04800v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04795v1",
            "title": "Induced-Minor-Free Graphs: Separator Theorem, Subexponential Algorithms,\n  and Improved Hardness of Recognition",
            "updated": "2023-08-09T08:34:42Z",
            "published": "2023-08-09T08:34:42Z",
            "summary": "A graph $G$ contains a graph $H$ as an induced minor if $H$ can be obtained\nfrom $G$ by vertex deletions and edge contractions. The class of\n$H$-induced-minor-free graphs generalizes the class of $H$-minor-free graphs,\nbut unlike $H$-minor-free graphs, it can contain dense graphs. We show that if\nan $n$-vertex $m$-edge graph $G$ does not contain a graph $H$ as an induced\nminor, then it has a balanced vertex separator of size $O_{H}(\\sqrt{m})$, where\nthe $O_{H}(\\cdot)$-notation hides factors depending on $H$. More precisely, our\nupper bound for the size of the balanced separator is $O(\\min(|V(H)|^2, \\log n)\n\\cdot \\sqrt{|V(H)|+|E(H)|} \\cdot \\sqrt{m})$. We give an algorithm for finding\neither an induced minor model of $H$ in $G$ or such a separator in randomized\npolynomial-time. We apply this to obtain subexponential $2^{O_{H}(n^{2/3} \\log\nn)}$ time algorithms on $H$-induced-minor-free graphs for a large class of\nproblems including maximum independent set, minimum feedback vertex set,\n3-coloring, and planarization.\n  For graphs $H$ where every edge is incident to a vertex of degree at most 2,\nour results imply a $2^{O_{H}(n^{2/3} \\log n)}$ time algorithm for testing if\n$G$ contains $H$ as an induced minor. Our second main result is that there\nexists a fixed tree $T$, so that there is no $2^{o(n/\\log^3 n)}$ time algorithm\nfor testing if a given $n$-vertex graph contains $T$ as an induced minor unless\nthe Exponential Time Hypothesis (ETH) fails. Our reduction also gives\nNP-hardness, which solves an open problem asked by Fellows, Kratochv\\'il,\nMiddendorf, and Pfeiffer [Algorithmica, 1995], who asked if there exists a\nfixed planar graph $H$ so that testing for $H$ as an induced minor is NP-hard.",
            "author": [
                "Tuukka Korhonen",
                "Daniel Lokshtanov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04795v1",
                "http://arxiv.org/pdf/2308.04795v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04788v1",
            "title": "Adaptive Intellect Unleashed: The Feasibility of Knowledge Transfer in\n  Large Language Models",
            "updated": "2023-08-09T08:26:22Z",
            "published": "2023-08-09T08:26:22Z",
            "summary": "We conduct the first empirical study on using knowledge transfer to improve\nthe generalization ability of large language models (LLMs) in software\nengineering tasks, which often require LLMs to generalize beyond their training\ndata. Our proposed general knowledge transfer approach guides the LLM towards a\nsimilar and familiar API or code snippet it has encountered before, improving\nthe model's generalization ability for unseen knowledge. We apply this approach\nto three software engineering tasks: API inference, code example generation,\nand FQN inference, and find transfer span, transfer strategy, and transfer\narchitecture as key factors affecting the method. Our findings demonstrate the\nfeasibility of knowledge transfer and its potential to enhance LLMs'\nperformance in various software engineering tasks. The effectiveness of\nknowledge transfer varies depending on the target domain and task, with the\nhierarchical strategy being more effective than direct transfer, and AI-Chain\noutperforming CoT in prompt design. The implications of these findings extend\nbeyond software engineering tasks and suggest that knowledge transfer can\nenhance LLMs' ability to handle unknowns in any natural language task.",
            "author": [
                "Qing Huang",
                "Yishun Wu",
                "Zhenchang Xing",
                "He Jiang",
                "Yu Cheng",
                "Huan Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04788v1",
                "http://arxiv.org/pdf/2308.04788v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04779v1",
            "title": "Multi-View Fusion and Distillation for Subgrade Distresses Detection\n  based on 3D-GPR",
            "updated": "2023-08-09T08:06:28Z",
            "published": "2023-08-09T08:06:28Z",
            "summary": "The application of 3D ground-penetrating radar (3D-GPR) for subgrade distress\ndetection has gained widespread popularity. To enhance the efficiency and\naccuracy of detection, pioneering studies have attempted to adopt automatic\ndetection techniques, particularly deep learning. However, existing works\ntypically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of the\nGPR, resulting in either insufficient spatial information or high computational\ncomplexity. To address these challenges, we introduce a novel methodology for\nthe subgrade distress detection task by leveraging the multi-view information\nfrom 3D-GPR data. Moreover, we construct a real multi-view image dataset\nderived from the original 3D-GPR data for the detection task, which provides\nricher spatial information compared to A-scan and B-scan data, while reducing\ncomputational complexity compared to C-scan data. Subsequently, we develop a\nnovel \\textbf{M}ulti-\\textbf{V}iew \\textbf{V}usion and \\textbf{D}istillation\nframework, \\textbf{GPR-MVFD}, specifically designed to optimally utilize the\nmulti-view GPR dataset. This framework ingeniously incorporates multi-view\ndistillation and attention-based fusion to facilitate significant feature\nextraction for subgrade distresses. In addition, a self-adaptive learning\nmechanism is adopted to stabilize the model training and prevent performance\ndegeneration in each branch. Extensive experiments conducted on this new GPR\nbenchmark demonstrate the effectiveness and efficiency of our proposed\nframework. Our framework outperforms not only the existing GPR baselines, but\nalso the state-of-the-art methods in the fields of multi-view learning,\nmulti-modal learning, and knowledge distillation. We will release the\nconstructed multi-view GPR dataset with expert-annotated labels and the source\ncodes of the proposed framework.",
            "author": [
                "Chunpeng Zhou",
                "Kangjie Ning",
                "Haishuai Wang",
                "Zhi Yu",
                "Sheng Zhou",
                "Jiajun Bu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04779v1",
                "http://arxiv.org/pdf/2308.04779v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04769v1",
            "title": "Correlation-diversified portfolio construction by finding maximum\n  independent set in large-scale market graph",
            "updated": "2023-08-09T07:57:24Z",
            "published": "2023-08-09T07:57:24Z",
            "summary": "Correlation-diversified portfolios can be constructed by finding the maximum\nindependent sets (MISs) in market graphs with edges corresponding to\ncorrelations between two stocks. The computational complexity to find the MIS\nincreases exponentially as the size of the market graph increases, making the\nMIS selection in a large-scale market graph difficult. Here we construct a\ndiversified portfolio by solving the MIS problem for a large-scale market graph\nwith a combinatorial optimization solver (an Ising machine) based on a\nquantum-inspired algorithm called simulated bifurcation (SB) and investigate\nthe investment performance of the constructed portfolio using long-term\nhistorical market data. Comparisons using stock universes of various sizes\n[TOPIX 100, Nikkei 225, TOPIX 1000, and TOPIX (including approximately 2,000\nconstituents)] show that the SB-based solver outperforms conventional MIS\nsolvers in terms of computation-time and solution-accuracy. By using the\nSB-based solver, we optimized the parameters of a MIS portfolio strategy\nthrough iteration of the backcast simulation that calculates the performance of\nthe MIS portfolio strategy based on a large-scale universe covering more than\n1,700 Japanese stocks for a long period of 10 years. It has been found that the\nbest MIS portfolio strategy (Sharpe ratio = 1.16, annualized return/risk =\n16.3%/14.0%) outperforms the major indices such as TOPIX (0.66, 10.0%/15.2%)\nand MSCI Japan Minimum Volatility Index (0.64, 7.7%/12.1%) for the period from\n2013 to 2023.",
            "author": [
                "Ryo Hidaka",
                "Yohei Hamakawa",
                "Jun Nakayama",
                "Kosuke Tatsumura"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04769v1",
                "http://arxiv.org/pdf/2308.04769v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "cs.CE",
                "q-fin.PM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04766v1",
            "title": "Open Source Software in the Public Sector: 25 years and still in its\n  infancy",
            "updated": "2023-08-09T07:54:28Z",
            "published": "2023-08-09T07:54:28Z",
            "summary": "The proliferation of Open Source Software (OSS) adoption and collaboration\nhas surged within industry, resulting in its ubiquitous presence in commercial\nofferings and shared digital infrastructure. However, in the public sector,\nboth awareness and adoption of OSS is still in its infancy due to a number of\nobstacles including regulatory, cultural, and capacity-related challenges. This\nspecial issue is a call for action, highlighting the necessity for both\nresearch and practice to narrow the gap, selectively transfer and adapt\nexisting knowledge, as well as generate new knowledge to enable the public\nsector to fully harness the potential benefits OSS has to offer.",
            "author": [
                "Johan Lin\u00e5ker",
                "Gregorio Robles",
                "Deborah Bryant",
                "Sachiko Muto"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MS.2023.3266105",
                "http://arxiv.org/abs/2308.04766v1",
                "http://arxiv.org/pdf/2308.04766v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04759v4",
            "title": "A new approach to pancyclicity of Paley graphs I",
            "updated": "2023-09-02T14:26:34Z",
            "published": "2023-08-09T07:49:03Z",
            "summary": "Let $G$ be an undirected graph of order $n$ and let $C_i$ be an $i$-cycle\ngraph. $G$ is called pancyclic if $G$ contains a $C_i$ for any $i\\in\n\\{3,4,\\ldots,n\\}$. We show that the pancyclicity of specific Cayley graphs and\nthe Cartesian product of specific two graphs. As a corollary of these two\ntheorems, we provide a new proof of the pancyclicity of the Paley graph.",
            "author": [
                "Yusaku Nishimura"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04759v4",
                "http://arxiv.org/pdf/2308.04759v4"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04758v2",
            "title": "Bird's-Eye-View Scene Graph for Vision-Language Navigation",
            "updated": "2023-08-12T08:29:16Z",
            "published": "2023-08-09T07:48:20Z",
            "summary": "Vision-language navigation (VLN), which entails an agent to navigate 3D\nenvironments following human instructions, has shown great advances. However,\ncurrent agents are built upon panoramic observations, which hinders their\nability to perceive 3D scene geometry and easily leads to ambiguous selection\nof panoramic view. To address these limitations, we present a BEV Scene Graph\n(BSG), which leverages multi-step BEV representations to encode scene layouts\nand geometric cues of indoor environment under the supervision of 3D detection.\nDuring navigation, BSG builds a local BEV representation at each step and\nmaintains a BEV-based global scene map, which stores and organizes all the\nonline collected local BEV representations according to their topological\nrelations. Based on BSG, the agent predicts a local BEV grid-level decision\nscore and a global graph-level decision score, combined with a sub-view\nselection score on panoramic views, for more accurate action prediction. Our\napproach significantly outperforms state-of-the-art methods on REVERIE, R2R,\nand R4R, showing the potential of BEV perception in VLN.",
            "author": [
                "Rui Liu",
                "Xiaohan Wang",
                "Wenguan Wang",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04758v2",
                "http://arxiv.org/pdf/2308.04758v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04756v1",
            "title": "Building Interpretable and Reliable Open Information Retriever for New\n  Domains Overnight",
            "updated": "2023-08-09T07:47:17Z",
            "published": "2023-08-09T07:47:17Z",
            "summary": "Information retrieval (IR) or knowledge retrieval, is a critical component\nfor many down-stream tasks such as open-domain question answering (QA). It is\nalso very challenging, as it requires succinctness, completeness, and\ncorrectness. In recent works, dense retrieval models have achieved\nstate-of-the-art (SOTA) performance on in-domain IR and QA benchmarks by\nrepresenting queries and knowledge passages with dense vectors and learning the\nlexical and semantic similarity. However, using single dense vectors and\nend-to-end supervision are not always optimal because queries may require\nattention to multiple aspects and event implicit knowledge. In this work, we\npropose an information retrieval pipeline that uses entity/event linking model\nand query decomposition model to focus more accurately on different information\nunits of the query. We show that, while being more interpretable and reliable,\nour proposed pipeline significantly improves passage coverages and denotation\naccuracies across five IR and QA benchmarks. It will be the go-to system to use\nfor applications that need to perform IR on a new domain without much dedicated\neffort, because of its superior interpretability and cross-domain performance.",
            "author": [
                "Xiaodong Yu",
                "Ben Zhou",
                "Dan Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04756v1",
                "http://arxiv.org/pdf/2308.04756v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04749v1",
            "title": "Enhancing Efficient Continual Learning with Dynamic Structure\n  Development of Spiking Neural Networks",
            "updated": "2023-08-09T07:36:40Z",
            "published": "2023-08-09T07:36:40Z",
            "summary": "Children possess the ability to learn multiple cognitive tasks sequentially,\nwhich is a major challenge toward the long-term goal of artificial general\nintelligence. Existing continual learning frameworks are usually applicable to\nDeep Neural Networks (DNNs) and lack the exploration on more brain-inspired,\nenergy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning\nmechanisms during child growth and development, we propose Dynamic Structure\nDevelopment of Spiking Neural Networks (DSD-SNN) for efficient and adaptive\ncontinual learning. When learning a sequence of tasks, the DSD-SNN dynamically\nassigns and grows new neurons to new tasks and prunes redundant neurons,\nthereby increasing memory capacity and reducing computational overhead. In\naddition, the overlapping shared structure helps to quickly leverage all\nacquired knowledge to new tasks, empowering a single network capable of\nsupporting multiple incremental tasks (without the separate sub-network mask\nfor each task). We validate the effectiveness of the proposed model on multiple\nclass incremental learning and task incremental learning benchmarks. Extensive\nexperiments demonstrated that our model could significantly improve\nperformance, learning speed and memory capacity, and reduce computational\noverhead. Besides, our DSD-SNN model achieves comparable performance with the\nDNNs-based methods, and significantly outperforms the state-of-the-art (SOTA)\nperformance for existing SNNs-based continual learning methods.",
            "author": [
                "Bing Han",
                "Feifei Zhao",
                "Yi Zeng",
                "Wenxuan Pan",
                "Guobin Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04749v1",
                "http://arxiv.org/pdf/2308.04749v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04742v2",
            "title": "Note on disjoint faces in simple topological graphs",
            "updated": "2023-09-17T11:17:32Z",
            "published": "2023-08-09T07:23:32Z",
            "summary": "We prove that every $n$-vertex complete simple topological graph generates at\nleast $\\Omega(n)$ pairwise disjoint $4$-faces. This improves upon a recent\nresult by Hubard and Suk. As an immediate corollary, every $n$-vertex complete\nsimple topological graph drawn in the unit square generates a $4$-face with\narea at most $O(1/n)$. This can be seen as a topological variant of Heilbronn's\nproblem for $4$-faces. We construct examples showing that our result is\nasymptotically tight. We also discuss the similar problem for $k$-faces with\narbitrary $k\\geq 3$.",
            "author": [
                "Ji Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04742v2",
                "http://arxiv.org/pdf/2308.04742v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05127v1",
            "title": "Data-Free Model Extraction Attacks in the Context of Object Detection",
            "updated": "2023-08-09T06:23:54Z",
            "published": "2023-08-09T06:23:54Z",
            "summary": "A significant number of machine learning models are vulnerable to model\nextraction attacks, which focus on stealing the models by using specially\ncurated queries against the target model. This task is well accomplished by\nusing part of the training data or a surrogate dataset to train a new model\nthat mimics a target model in a white-box environment. In pragmatic situations,\nhowever, the target models are trained on private datasets that are\ninaccessible to the adversary. The data-free model extraction technique\nreplaces this problem when it comes to using queries artificially curated by a\ngenerator similar to that used in Generative Adversarial Nets. We propose for\nthe first time, to the best of our knowledge, an adversary black box attack\nextending to a regression problem for predicting bounding box coordinates in\nobject detection. As part of our study, we found that defining a loss function\nand using a novel generator setup is one of the key aspects in extracting the\ntarget model. We find that the proposed model extraction method achieves\nsignificant results by using reasonable queries. The discovery of this object\ndetection vulnerability will support future prospects for securing such models.",
            "author": [
                "Harshit Shah",
                "Aravindhan G",
                "Pavan Kulkarni",
                "Yuvaraj Govidarajulu",
                "Manojkumar Parmar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05127v1",
                "http://arxiv.org/pdf/2308.05127v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04714v2",
            "title": "A Computational Design Pipeline to Fabricate Sensing Network\n  Physicalizations",
            "updated": "2023-08-12T22:39:21Z",
            "published": "2023-08-09T05:26:02Z",
            "summary": "Interaction is critical for data analysis and sensemaking. However, designing\ninteractive physicalizations is challenging as it requires cross-disciplinary\nknowledge in visualization, fabrication, and electronics. Interactive\nphysicalizations are typically produced in an unstructured manner, resulting in\nunique solutions for a specific dataset, problem, or interaction that cannot be\neasily extended or adapted to new scenarios or future physicalizations. To\nmitigate these challenges, we introduce a computational design pipeline to 3D\nprint network physicalizations with integrated sensing capabilities. Networks\nare ubiquitous, yet their complex geometry also requires significant\nengineering considerations to provide intuitive, effective interactions for\nexploration. Using our pipeline, designers can readily produce network\nphysicalizations supporting selection-the most critical atomic operation for\ninteraction-by touch through capacitive sensing and computational inference.\nOur computational design pipeline introduces a new design paradigm by\nconcurrently considering the form and interactivity of a physicalization into\none cohesive fabrication workflow. We evaluate our approach using (i)\ncomputational evaluations, (ii) three usage scenarios focusing on general\nvisualization tasks, and (iii) expert interviews. The design paradigm\nintroduced by our pipeline can lower barriers to physicalization research,\ncreation, and adoption.",
            "author": [
                "S. Sandra Bae",
                "Takanori Fujiwara",
                "Anders Ynnerman",
                "Ellen Yi-Luen Do",
                "Michael L. Rivera",
                "Danielle Albers Szafir"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04714v2",
                "http://arxiv.org/pdf/2308.04714v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04712v1",
            "title": "Slot Induction via Pre-trained Language Model Probing and Multi-level\n  Contrastive Learning",
            "updated": "2023-08-09T05:08:57Z",
            "published": "2023-08-09T05:08:57Z",
            "summary": "Recent advanced methods in Natural Language Understanding for Task-oriented\nDialogue (TOD) Systems (e.g., intent detection and slot filling) require a\nlarge amount of annotated data to achieve competitive performance. In reality,\ntoken-level annotations (slot labels) are time-consuming and difficult to\nacquire. In this work, we study the Slot Induction (SI) task whose objective is\nto induce slot boundaries without explicit knowledge of token-level slot\nannotations. We propose leveraging Unsupervised Pre-trained Language Model\n(PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised\nsemantic knowledge extracted from PLM, and (2) additional sentence-level intent\nlabel signals available from TOD. Our approach is shown to be effective in SI\ntask and capable of bridging the gaps with token-level supervised models on two\nNLU benchmark datasets. When generalized to emerging intents, our SI objectives\nalso provide enhanced slot label representations, leading to improved\nperformance on the Slot Filling tasks.",
            "author": [
                "Hoang H. Nguyen",
                "Chenwei Zhang",
                "Ye Liu",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04712v1",
                "http://arxiv.org/pdf/2308.04712v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04711v3",
            "title": "Answering Unseen Questions With Smaller Language Models Using Rationale\n  Generation and Dense Retrieval",
            "updated": "2023-10-12T21:25:15Z",
            "published": "2023-08-09T05:06:39Z",
            "summary": "When provided with sufficient explanatory context, smaller Language Models\nhave been shown to exhibit strong reasoning ability on challenging short-answer\nquestion-answering tasks where the questions are unseen in training. We\nevaluate two methods for further improvement in this setting. Both methods\nfocus on combining rationales generated by a larger Language Model with longer\ncontexts created from a multi-hop dense retrieval system. The first method\n($\\textit{RR}$) involves training a Rationale Ranking model to score both\ngenerated rationales and retrieved contexts with respect to relevance and\ntruthfulness. We then use the scores to derive combined contexts from both\nknowledge sources using a number of combinatory strategies. For the second\nmethod ($\\textit{RATD}$) we utilise retrieval-augmented training datasets\ndeveloped by Hartill et al. 2023 to train a smaller Reasoning model such that\nit becomes proficient at utilising relevant information from longer text\nsequences that may be only partially evidential and frequently contain many\nirrelevant sentences. We find that both methods significantly improve results.\nOur single best Reasoning model materially improves upon strong comparable\nprior baselines for unseen evaluation datasets (StrategyQA 58.9 $\\rightarrow$\n61.7 acc., CommonsenseQA 63.6 $\\rightarrow$ 72.7 acc., ARC-DA 31.6\n$\\rightarrow$ 52.1 F1, IIRC 25.5 $\\rightarrow$ 27.3 F1) and a version utilising\nour prior knowledge of each type of question in selecting a context combination\nstrategy does even better. Our proposed models also generally outperform direct\nprompts against much larger models (BLOOM 175B and StableVicuna 13B) in both\nfew-shot chain-of-thought and standard few-shot settings.",
            "author": [
                "Tim Hartill",
                "Diana Benavides-Prado",
                "Michael Witbrock",
                "Patricia J. Riddle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04711v3",
                "http://arxiv.org/pdf/2308.04711v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04709v1",
            "title": "A Comparative Study of Open-Source Large Language Models, GPT-4 and\n  Claude 2: Multiple-Choice Test Taking in Nephrology",
            "updated": "2023-08-09T05:01:28Z",
            "published": "2023-08-09T05:01:28Z",
            "summary": "In recent years, there have been significant breakthroughs in the field of\nnatural language processing, particularly with the development of large\nlanguage models (LLMs). These LLMs have showcased remarkable capabilities on\nvarious benchmarks. In the healthcare field, the exact role LLMs and other\nfuture AI models will play remains unclear. There is a potential for these\nmodels in the future to be used as part of adaptive physician training, medical\nco-pilot applications, and digital patient interaction scenarios. The ability\nof AI models to participate in medical training and patient care will depend in\npart on their mastery of the knowledge content of specific medical fields. This\nstudy investigated the medical knowledge capability of LLMs, specifically in\nthe context of internal medicine subspecialty multiple-choice test-taking\nability. We compared the performance of several open-source LLMs (Koala 7B,\nFalcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on\nmultiple-choice questions in the field of Nephrology. Nephrology was chosen as\nan example of a particularly conceptually complex subspecialty field within\ninternal medicine. The study was conducted to evaluate the ability of LLM\nmodels to provide correct answers to nephSAP (Nephrology Self-Assessment\nProgram) multiple-choice questions. The overall success of open-sourced LLMs in\nanswering the 858 nephSAP multiple-choice questions correctly was 17.1% -\n25.5%. In contrast, Claude 2 answered 54.4% of the questions correctly, whereas\nGPT-4 achieved a score of 73.3%. We show that current widely used open-sourced\nLLMs do poorly in their ability for zero-shot reasoning when compared to GPT-4\nand Claude 2. The findings of this study potentially have significant\nimplications for the future of subspecialty medical training and patient care.",
            "author": [
                "Sean Wu",
                "Michael Koo",
                "Lesley Blum",
                "Andy Black",
                "Liyo Kao",
                "Fabien Scalzo",
                "Ira Kurtz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04709v1",
                "http://arxiv.org/pdf/2308.04709v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04708v1",
            "title": "Generative Perturbation Analysis for Probabilistic Black-Box Anomaly\n  Attribution",
            "updated": "2023-08-09T04:59:06Z",
            "published": "2023-08-09T04:59:06Z",
            "summary": "We address the task of probabilistic anomaly attribution in the black-box\nregression setting, where the goal is to compute the probability distribution\nof the attribution score of each input variable, given an observed anomaly. The\ntraining dataset is assumed to be unavailable. This task differs from the\nstandard XAI (explainable AI) scenario, since we wish to explain the anomalous\ndeviation from a black-box prediction rather than the black-box model itself.\n  We begin by showing that mainstream model-agnostic explanation methods, such\nas the Shapley values, are not suitable for this task because of their\n``deviation-agnostic property.'' We then propose a novel framework for\nprobabilistic anomaly attribution that allows us to not only compute\nattribution scores as the predictive mean but also quantify the uncertainty of\nthose scores. This is done by considering a generative process for\nperturbations that counter-factually bring the observed anomalous observation\nback to normalcy. We introduce a variational Bayes algorithm for deriving the\ndistributions of per variable attribution scores. To the best of our knowledge,\nthis is the first probabilistic anomaly attribution framework that is free from\nbeing deviation-agnostic.",
            "author": [
                "Tsuyoshi Id\u00e9",
                "Naoki Abe"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3580305.3599365",
                "http://arxiv.org/abs/2308.04708v1",
                "http://arxiv.org/pdf/2308.04708v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07932v1",
            "title": "Balanced Butterfly Counting in Bipartite-Network",
            "updated": "2023-08-09T04:57:32Z",
            "published": "2023-08-09T04:57:32Z",
            "summary": "Bipartite graphs offer a powerful framework for modeling complex\nrelationships between two distinct types of vertices, incorporating\nprobabilistic, temporal, and rating-based information. While the research\ncommunity has extensively explored various types of bipartite relationships,\nthere has been a notable gap in studying Signed Bipartite Graphs, which capture\nliking / disliking interactions in real-world networks such as\ncustomer-rating-product and senator-vote-bill. Balance butterflies,\nrepresenting 2 x 2 bicliques, provide crucial insights into antagonistic\ngroups, balance theory, and fraud detection by leveraging the signed\ninformation. However, such applications require counting balance butterflies\nwhich remains unexplored. In this paper, we propose a new problem: counting\nbalance butterflies in a signed bipartite graph. To address this problem, we\nadopt state-of-the-art algorithms for butterfly counting, establishing a smart\nbaseline that reduces the time complexity for solving our specific problem. We\nfurther introduce a novel bucket approach specifically designed to count\nbalanced butterflies efficiently. We propose a parallelized version of the\nbucketing approach to enhance performance. Extensive experimental studies on\nnine real-world datasets demonstrate that our proposed bucket-based algorithm\nis up to 120x faster over the baseline, and the parallel implementation of the\nbucket-based algorithm is up to 45x faster over the single core execution.\nMoreover, a real-world case study showcases the practical application and\nrelevance of counting balanced butterflies.",
            "author": [
                "Apurba Das",
                "Aman Abidi",
                "Ajinkya Shingane",
                "Mekala Kiran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07932v1",
                "http://arxiv.org/pdf/2308.07932v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.03910v1",
            "title": "Analyzing and Comparing Omicron Lineage Variants Protein-Protein\n  Interaction Network using Centrality Measure",
            "updated": "2023-08-09T04:56:02Z",
            "published": "2023-08-09T04:56:02Z",
            "summary": "The Worldwide spread of the Omicron lineage variants has now been confirmed.\nIt is crucial to understand the process of cellular life and to discover new\ndrugs need to identify the important proteins in a protein interaction network\n(PPIN). PPINs are often represented by graphs in bioinformatics, which describe\ncell processes. There are some proteins that have significant influences on\nthese tissues, and which play a crucial role in regulating them. The discovery\nof new drugs is aided by the study of significant proteins. These significant\nproteins can be found by reducing the graph and using graph analysis. Studies\nexamining protein interactions in the Omicron lineage (B.1.1.529) and its\nvariants (BA.5, BA.4, BA.3, BA.2, BA.1.1, BA.1) are not yet available. Studying\nOmicron has been intended to find a significant protein. 68 nodes represent 68\nproteins and 52 edges represent the relationship among the protein in the\nnetwork. A few entrality measures are computed namely page rank centrality\n(PRC), degree centrality (DC), closeness centrality (CC), and betweenness\ncentrality (BC) together with node degree and Local Clustering Co-efficient\n(LCC). We also discover 18 network clusters using Markov clustering. 8\nsignificant proteins (candidate gene of Omicron lineage variants) were detected\namong the 68 proteins, including AHSG, KCNK1, KCNQ1, MAPT, NR1H4, PSMC2, PTPN11\nand, UBE21 which scored the highest among the Omicron proteins. It is found\nthat in the variant of Omicron protein-protein interaction networks, the MAPT\nprotein's impact is the most significant.",
            "author": [
                "Mamata Das",
                "Selvakumar K.",
                "P. J. A. Alphonse"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s42979-023-01685-5",
                "http://arxiv.org/abs/2309.03910v1",
                "http://arxiv.org/pdf/2309.03910v1"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04705v2",
            "title": "Regularity of symbolic and ordinary powers of weighted oriented graphs\n  and their upper bounds",
            "updated": "2023-10-08T10:49:31Z",
            "published": "2023-08-09T04:51:59Z",
            "summary": "In this paper, we compare the regularities of symbolic and ordinary powers of\nedge ideals of weighted oriented graphs. For a weighted oriented graph $D$, we\ngive a lower bound for $\\reg(I(D)^{(k)})$, if $V^+$ are sinks. If $D$ has an\ninduced directed path $(x_i,x_j),(x_j,x_r) \\in E(D)$ of length $2$ with\n$w(x_j)\\geq 2$, then we show that $\\reg(I(D)^{(k)})\\leq \\reg(I(D)^k)$ for all\n$k\\geq 2$. In particular, if $D$ is bipartite, then the above inequality holds\nfor all $k\\geq 2$. For any weighted oriented graph $D$, if $V^+$ are sink\nvertices, then we show that $\\reg(I(D)^{(k)}) \\leq \\reg(I(D)^k)$ with $k=2,3$.\nWe further study when these regularities are equal. As a consequence, we give\nsharp linear upper bounds for regularity of symbolic powers of certain classes\nof weighted oriented graphs. Furthermore, we compare the regularity of symbolic\npowers of weighted oriented graphs $D$ and $D'$, where $D'$ is obtained from\n$D$ by adding a pendent. We show linear upper bounds for regularity of symbolic\nand ordinary powers of complete graph $K_n$ and $K_n'$.",
            "author": [
                "Manohar Kumar",
                "Ramakrishna Nanduri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04705v2",
                "http://arxiv.org/pdf/2308.04705v2"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "13D02, 05E40, 05E99, 13D45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04704v2",
            "title": "A Feature Set of Small Size for the PDF Malware Detection",
            "updated": "2023-08-10T03:08:03Z",
            "published": "2023-08-09T04:51:28Z",
            "summary": "Machine learning (ML)-based malware detection systems are becoming\nincreasingly important as malware threats increase and get more sophisticated.\nPDF files are often used as vectors for phishing attacks because they are\nwidely regarded as trustworthy data resources, and are accessible across\ndifferent platforms. Therefore, researchers have developed many different PDF\nmalware detection methods. Performance in detecting PDF malware is greatly\ninfluenced by feature selection. In this research, we propose a small features\nset that don't require too much domain knowledge of the PDF file. We evaluate\nproposed features with six different machine learning models. We report the\nbest accuracy of 99.75% when using Random Forest model. Our proposed feature\nset, which consists of just 12 features, is one of the most conciseness in the\nfield of PDF malware detection. Despite its modest size, we obtain comparable\nresults to state-of-the-art that employ a much larger set of features.",
            "author": [
                "Ran Liu",
                "Charles Nicholas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04704v2",
                "http://arxiv.org/pdf/2308.04704v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04703v1",
            "title": "Data Player: Automatic Generation of Data Videos with\n  Narration-Animation Interplay",
            "updated": "2023-08-09T04:49:14Z",
            "published": "2023-08-09T04:49:14Z",
            "summary": "Data visualizations and narratives are often integrated to convey data\nstories effectively. Among various data storytelling formats, data videos have\nbeen garnering increasing attention. These videos provide an intuitive\ninterpretation of data charts while vividly articulating the underlying data\ninsights. However, the production of data videos demands a diverse set of\nprofessional skills and considerable manual labor, including understanding\nnarratives, linking visual elements with narration segments, designing and\ncrafting animations, recording audio narrations, and synchronizing audio with\nvisual animations. To simplify this process, our paper introduces a novel\nmethod, referred to as Data Player, capable of automatically generating dynamic\ndata videos with narration-animation interplay. This approach lowers the\ntechnical barriers associated with creating data videos rich in narration. To\nenable narration-animation interplay, Data Player constructs references between\nvisualizations and text input. Specifically, it first extracts data into tables\nfrom the visualizations. Subsequently, it utilizes large language models to\nform semantic connections between text and visuals. Finally, Data Player\nencodes animation design knowledge as computational low-level constraints,\nallowing for the recommendation of suitable animation presets that align with\nthe audio narration produced by text-to-speech technologies. We assessed Data\nPlayer's efficacy through an example gallery, a user study, and expert\ninterviews. The evaluation results demonstrated that Data Player can generate\nhigh-quality data videos that are comparable to human-composed ones.",
            "author": [
                "Leixian Shen",
                "Yizhi Zhang",
                "Haidong Zhang",
                "Yun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04703v1",
                "http://arxiv.org/pdf/2308.04703v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04701v1",
            "title": "Direct and in situ examination of Li+ transport kinetics in isotope\n  labelled solid electrolyte interphase",
            "updated": "2023-08-09T04:45:31Z",
            "published": "2023-08-09T04:45:31Z",
            "summary": "Here, using unique in-situ liquid secondary ion mass spectroscopy on\nisotope-labelled solid-electrolyte-interphase (SEI), assisted by cryogenic\ntransmission electron microscopy and constrained ab initio molecular dynamics\nsimulation, for the first time we answer the question regarding Li+ transport\nmechanism across SEI, and quantitatively determine the Li+-mobility therein. We\nunequivocally unveil that Li+ transport in SEI follows a mechanism of\nsuccessive displacement, rather than \"direct-hopping\". We further reveal, in\naccordance with spatial-dependence of SEI structure across the thickness, the\napparent Li+ self-diffusivity varies from 6.7*10-19 m2/s to 1.0*10-20 m2/s,\nsetting a quantitative gauging of ionic transport behavior of SEI layer against\nthe underlining electrode as well as the rate limiting step of battery\noperation. This direct study on Li+ kinetics in SEI fills part of the\ndecade-long knowledge gap about the most important component in advanced\nbatteries and provides more precise guidelines to the tailoring of interphasial\nchemistries for future battery chemistries.",
            "author": [
                "Xiaofei Yu",
                "Stefany Angarita-Gomez",
                "Yaobin Xu",
                "Peiyuan Gao",
                "Jun-Gang Wang",
                "Xin Zhang",
                "Hao Jia",
                "Wu Xu",
                "Xiaolin Li",
                "Yingge Du",
                "Zhijie Xu",
                "Janet S. Ho",
                "Kang Xu",
                "Perla B. Balbuena",
                "Chongmin Wang",
                "Zihua Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04701v1",
                "http://arxiv.org/pdf/2308.04701v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "None",
                "I.6.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04700v1",
            "title": "BOPIM: Bayesian Optimization for influence maximization on temporal\n  networks",
            "updated": "2023-08-09T04:35:08Z",
            "published": "2023-08-09T04:35:08Z",
            "summary": "The goal of influence maximization (IM) is to select a small set of seed\nnodes which maximize the spread of influence on a network. In this work, we\npropose BOPIM, a Bayesian Optimization (BO) algorithm for IM on temporal\nnetworks. The IM task is well-suited for a BO solution due to its expensive and\ncomplicated objective function. We propose a simple surrogate function to model\nthe objective function and leverage Gaussian Process regression with shrinkage\npriors to fit the model. An acquisition function based on the median of the\nposterior distribution leads to a straightforward procedure to select the next\nsampling point. In numerical experiments on real-world networks, we find that,\non average, the surrogate function estimates the true influence spread within a\nfew nodes. Additionally, we show that BOPIM yields comparable influence spreads\nto a gold-standard greedy algorithm while being as much as seventeen times\nfaster. We also use these experiments to demonstrate the proposed method's\nability to quantify uncertainty in optimal seed sets. To the knowledge of the\nauthor, this is the first attempt to look at uncertainty in the seed sets for\nIM, as well as the first application of BO to a constrained, combinatorial\noptimization problem.",
            "author": [
                "Eric Yanchenko"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04700v1",
                "http://arxiv.org/pdf/2308.04700v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04699v2",
            "title": "GIFD: A Generative Gradient Inversion Method with Feature Domain\n  Optimization",
            "updated": "2023-09-11T02:00:51Z",
            "published": "2023-08-09T04:34:21Z",
            "summary": "Federated Learning (FL) has recently emerged as a promising distributed\nmachine learning framework to preserve clients' privacy, by allowing multiple\nclients to upload the gradients calculated from their local data to a central\nserver. Recent studies find that the exchanged gradients also take the risk of\nprivacy leakage, e.g., an attacker can invert the shared gradients and recover\nsensitive data against an FL system by leveraging pre-trained generative\nadversarial networks (GAN) as prior knowledge. However, performing gradient\ninversion attacks in the latent space of the GAN model limits their expression\nability and generalizability. To tackle these challenges, we propose\n\\textbf{G}radient \\textbf{I}nversion over \\textbf{F}eature \\textbf{D}omains\n(GIFD), which disassembles the GAN model and searches the feature domains of\nthe intermediate layers. Instead of optimizing only over the initial latent\ncode, we progressively change the optimized layer, from the initial latent\nspace to intermediate layers closer to the output images. In addition, we\ndesign a regularizer to avoid unreal image generation by adding a small ${l_1}$\nball constraint to the searching range. We also extend GIFD to the\nout-of-distribution (OOD) setting, which weakens the assumption that the\ntraining sets of GANs and FL tasks obey the same data distribution. Extensive\nexperiments demonstrate that our method can achieve pixel-level reconstruction\nand is superior to the existing methods. Notably, GIFD also shows great\ngeneralizability under different defense strategy settings and batch sizes.",
            "author": [
                "Hao Fang",
                "Bin Chen",
                "Xuan Wang",
                "Zhi Wang",
                "Shu-Tao Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04699v2",
                "http://arxiv.org/pdf/2308.04699v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04697v1",
            "title": "An Analytical Study of Covid-19 Dataset using Graph-Based Clustering\n  Algorithms",
            "updated": "2023-08-09T04:16:48Z",
            "published": "2023-08-09T04:16:48Z",
            "summary": "Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is\ninitially identified in Wuhan of China in December of 2019 and now this deadly\ndisease has spread all over the world. According to World Health Organization\n(WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case,\nmany methods, AI base techniques, and machine learning algorithms have been\nresearched and are being used to save people from this pandemic. The SARS-CoV\nand the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences\nin the structure of cell proteins. Protein-protein interaction (PPI) is an\nessential process in our cells and plays a very important role in the\ndevelopment of medicines and gives ideas about the disease. In this study, we\nperformed clustering on PPI networks generated from 92 genes of the Covi-19\ndataset. We have used three graph-based clustering algorithms to give intuition\nto the analysis of clusters.",
            "author": [
                "Mamata Das",
                "P. J. A. Alphonse",
                "Selvakumar K"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04697v1",
                "http://arxiv.org/pdf/2308.04697v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04695v1",
            "title": "Deterministic $k$-Vertex Connectivity in $k^2$ Max-flows",
            "updated": "2023-08-09T04:07:27Z",
            "published": "2023-08-09T04:07:27Z",
            "summary": "An $n$-vertex $m$-edge graph is \\emph{$k$-vertex connected} if it cannot be\ndisconnected by deleting less than $k$ vertices. After more than half a century\nof intensive research, the result by [Li et al. STOC'21] finally gave a\n\\emph{randomized} algorithm for checking $k$-connectivity in near-optimal\n$\\widehat{O}(m)$ time. (We use $\\widehat{O}(\\cdot)$ to hide an $n^{o(1)}$\nfactor.) Deterministic algorithms, unfortunately, have remained much slower\neven if we assume a linear-time max-flow algorithm: they either require at\nleast $\\Omega(mn)$ time [Even'75; Henzinger Rao and Gabow, FOCS'96; Gabow,\nFOCS'00] or assume that $k=o(\\sqrt{\\log n})$ [Saranurak and\nYingchareonthawornchai, FOCS'22]. We show a \\emph{deterministic} algorithm for\nchecking $k$-vertex connectivity in time proportional to making\n$\\widehat{O}(k^{2})$ max-flow calls, and, hence, in $\\widehat{O}(mk^{2})$ time\nusing the deterministic max-flow algorithm by [Brand et al. FOCS'23]. Our\nalgorithm gives the first almost-linear-time bound for all $k$ where\n$\\sqrt{\\log n}\\le k\\le n^{o(1)}$ and subsumes up to a sub polynomial factor the\nlong-standing state-of-the-art algorithm by [Even'75] which requires\n$O(n+k^{2})$ max-flow calls. Our key technique is a deterministic algorithm for\nterminal reduction for vertex connectivity: given a terminal set separated by a\nvertex mincut, output either a vertex mincut or a smaller terminal set that\nremains separated by a vertex mincut. We also show a deterministic\n$(1+\\epsilon)$-approximation algorithm for vertex connectivity that makes\n$O(n/\\epsilon^2)$ max-flow calls, improving the bound of $O(n^{1.5})$ max-flow\ncalls in the exact algorithm of [Gabow, FOCS'00]. The technique is based on\nRamanujan graphs.",
            "author": [
                "Chaitanya Nalam",
                "Thatchaphol Saranurak",
                "Sorrachai Yingchareonthawornchai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04695v1",
                "http://arxiv.org/pdf/2308.04695v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04693v1",
            "title": "Evaluating and Optimizing the Effectiveness of Neural Machine\n  Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark",
            "updated": "2023-08-09T04:06:24Z",
            "published": "2023-08-09T04:06:24Z",
            "summary": "Neural Machine Translation (NMT) is widely applied in software engineering\ntasks. The effectiveness of NMT for code retrieval relies on the ability to\nlearn from the sequence of tokens in the source language to the sequence of\ntokens in the target language. While NMT performs well in pseudocode-to-code\ntranslation, it might have challenges in learning to translate from natural\nlanguage query to source code in newly curated real-world code documentation/\nimplementation datasets. In this work, we analyze the performance of NMT in\nnatural language-to-code translation in the newly curated CAT benchmark that\nincludes the optimized versions of three Java datasets TLCodeSum,\nCodeSearchNet, Funcom, and a Python dataset PCSD. Our evaluation shows that NMT\nhas low accuracy, measured by CrystalBLEU and Meteor metrics in this task. To\nalleviate the duty of NMT in learning complex representation of source code, we\npropose ASTTrans Representation, a tailored representation of an Abstract\nSyntax Tree (AST) using a subset of non-terminal nodes. We show that the\nclassical approach NMT performs significantly better in learning ASTTrans\nRepresentation over code tokens with up to 36% improvement on Meteor score.\nMoreover, we leverage ASTTrans Representation to conduct combined code search\nprocesses from the state-of-the-art code search processes using GraphCodeBERT\nand UniXcoder. Our NMT models of learning ASTTrans Representation can boost the\nMean Reciprocal Rank of these state-of-the-art code search processes by up to\n3.08% and improve 23.08% of queries' results over the CAT benchmark.",
            "author": [
                "Hung Phan",
                "Ali Jannesari"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614869",
                "http://arxiv.org/abs/2308.04693v1",
                "http://arxiv.org/pdf/2308.04693v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.05125v1",
            "title": "Two Novel Approaches to Detect Community: A Case Study of Omicron\n  Lineage Variants PPI Network",
            "updated": "2023-08-09T03:51:20Z",
            "published": "2023-08-09T03:51:20Z",
            "summary": "The capacity to identify and analyze protein-protein interactions, along with\ntheir internal modular organization, plays a crucial role in comprehending the\nintricate mechanisms underlying biological processes at the molecular level. We\ncan learn a lot about the structure and dynamics of these interactions by using\nnetwork analysis. We can improve our understanding of the biological roots of\ndisease pathogenesis by recognizing network communities. This knowledge, in\nturn, holds significant potential for driving advancements in drug discovery\nand facilitating personalized medicine approaches for disease treatment. In\nthis study, we aimed to uncover the communities within the variant B.1.1.529\n(Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four\nwidely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label\nPropagation algorithm. Each of these algorithms has established prominence in\nthe field and offers unique perspectives on identifying communities within\ncomplex networks. We also compare the networks by the global properties,\nstatistic summary, subgraph count, graphlet and validate by the modulaity. By\nemploying these approaches, we sought to gain deeper insights into the\nstructural organization and interconnections present within the Omicron virus\nnetwork.",
            "author": [
                "Mamata Das",
                "Selvakumar K.",
                "P. J. A. Alphonse"
            ],
            "link": [
                "http://arxiv.org/abs/2308.05125v1",
                "http://arxiv.org/pdf/2308.05125v1"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04688v1",
            "title": "Generating News-Centric Crossword Puzzles As A Constraint Satisfaction\n  and Optimization Problem",
            "updated": "2023-08-09T03:50:26Z",
            "published": "2023-08-09T03:50:26Z",
            "summary": "Crossword puzzles have traditionally served not only as entertainment but\nalso as an educational tool that can be used to acquire vocabulary and language\nproficiency. One strategy to enhance the educational purpose is\npersonalization, such as including more words on a particular topic. This paper\nfocuses on the case of encouraging people's interest in news and proposes a\nframework for automatically generating news-centric crossword puzzles. We\ndesigned possible scenarios and built a prototype as a constraint satisfaction\nand optimization problem, that is, containing as many news-derived words as\npossible. Our experiments reported the generation probabilities and time\nrequired under several conditions. The results showed that news-centric\ncrossword puzzles can be generated even with few news-derived words. We\nsummarize the current issues and future research directions through a\nqualitative evaluation of the prototype. This is the first proposal that a\nformulation of a constraint satisfaction and optimization problem can be\nbeneficial as an educational application.",
            "author": [
                "Kaito Majima",
                "Shotaro Ishihara"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615151",
                "http://arxiv.org/abs/2308.04688v1",
                "http://arxiv.org/pdf/2308.04688v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04679v1",
            "title": "Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge\n  Distillation in Small Models for Scientific QA",
            "updated": "2023-08-09T03:18:07Z",
            "published": "2023-08-09T03:18:07Z",
            "summary": "Large Language Models (LLMs) have shown outstanding performance across wide\nrange of downstream tasks. This competency is attributed to their substantial\nparameter size and pre-training on extensive corpus. Moreover, LLMs have\nexhibited enhanced reasoning capabilities in tackling complex reasoning tasks,\nowing to the utilization of a method named ``Chain-of-Thought (CoT)\nprompting''. This method is designed to generate intermediate reasoning steps\nthat guide the inference of the final answer. However, it is essential to\nhighlight that these advanced reasoning abilities appear to emerge in models\nwith a minimum of 10 billion parameters, thereby limiting its efficacy in\nsituations where computational resources are constrained. In this paper, we\ninvestigate the possibility of transferring the reasoning capabilities of LLMs\nto smaller models via knowledge distillation. Specifically, we propose Sci-CoT,\na two-stage framework that separates the processes of generating rationales and\ninferring answers. This method enables a more efficient use of rationales\nduring the answer inference stage, leading to improved performance on\nscientific question-answering tasks. Utilizing Sci-CoT, our 80-million\nparameter model is able to exceed the performance of BLOOM-176B in the ARC-Easy\ndataset under the few shot setting.",
            "author": [
                "Yuhan Ma",
                "Haiqi Jiang",
                "Chenyou Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04679v1",
                "http://arxiv.org/pdf/2308.04679v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04666v1",
            "title": "Speaker Recognition Using Isomorphic Graph Attention Network Based\n  Pooling on Self-Supervised Representation",
            "updated": "2023-08-09T02:14:10Z",
            "published": "2023-08-09T02:14:10Z",
            "summary": "The emergence of self-supervised representation (i.e., wav2vec 2.0) allows\nspeaker-recognition approaches to process spoken signals through foundation\nmodels built on speech data. Nevertheless, effective fusion on the\nrepresentation requires further investigating, due to the inclusion of fixed or\nsub-optimal temporal pooling strategies. Despite of improved strategies\nconsidering graph learning and graph attention factors, non-injective\naggregation still exists in the approaches, which may influence the performance\nfor speaker recognition. In this regard, we propose a speaker recognition\napproach using Isomorphic Graph ATtention network (IsoGAT) on self-supervised\nrepresentation. The proposed approach contains three modules of representation\nlearning, graph attention, and aggregation, jointly considering learning on the\nself-supervised representation and the IsoGAT. Then, we perform experiments for\nspeaker recognition tasks on VoxCeleb1\\&2 datasets, with the corresponding\nexperimental results demonstrating the recognition performance for the proposed\napproach, compared with existing pooling approaches on the self-supervised\nrepresentation.",
            "author": [
                "Zirui Ge",
                "Xinzhou Xu",
                "Haiyan Guo",
                "Tingting Wang",
                "Zhen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04666v1",
                "http://arxiv.org/pdf/2308.04666v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04662v1",
            "title": "VulLibGen: Identifying Vulnerable Third-Party Libraries via Generative\n  Pre-Trained Model",
            "updated": "2023-08-09T02:02:46Z",
            "published": "2023-08-09T02:02:46Z",
            "summary": "To avoid potential risks posed by vulnerabilities in third-party libraries,\nsecurity researchers maintain vulnerability databases (e.g., NVD) containing\nvulnerability reports, each of which records the description of a vulnerability\nand the name list of libraries affected by the vulnerability (a.k.a. vulnerable\nlibraries). However, recent studies on about 200,000 vulnerability reports in\nNVD show that 53.3% of these reports do not include the name list of vulnerable\nlibraries, and 59.82% of the included name lists of vulnerable libraries are\nincomplete or incorrect.\n  To address the preceding issue, in this paper, we propose the first\ngenerative approach named VulLibGen to generate the name list of vulnerable\nlibraries (out of all the existing libraries) for the given vulnerability by\nutilizing recent enormous advances in Large Language Models (LLMs), in order to\nachieve high accuracy. VulLibGen takes only the description of a vulnerability\nas input and achieves high identification accuracy based on LLMs' prior\nknowledge of all the existing libraries. VulLibGen also includes the input\naugmentation technique to help identify zero-shot vulnerable libraries (those\nnot occurring during training) and the post-processing technique to help\naddress VulLibGen's hallucinations. We evaluate VulLibGen using three\nstate-of-the-art/practice approaches (LightXML, Chronos, and VulLibMiner) that\nidentify vulnerable libraries on an open-source dataset (VulLib). Our\nevaluation results show that VulLibGen can accurately identify vulnerable\nlibraries with an average F1 score of 0.626 while the state-of-the-art/practice\napproaches achieve only 0.561. The post-processing technique helps VulLibGen\nachieve an average improvement of F1@1 by 9.3%. The input augmentation\ntechnique helps VulLibGen achieve an average improvement of F1@1 by 39% in\nidentifying zero-shot libraries.",
            "author": [
                "Tianyu Chen",
                "Lin Li",
                "Liuchuan Zhu",
                "Zongyang Li",
                "Guangtai Liang",
                "Ding Li",
                "Qianxiang Wang",
                "Tao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04662v1",
                "http://arxiv.org/pdf/2308.04662v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04646v1",
            "title": "Multi-Valued Connected Consensus: A New Perspective on Crusader\n  Agreement and Adopt-Commit",
            "updated": "2023-08-09T01:08:45Z",
            "published": "2023-08-09T01:08:45Z",
            "summary": "Algorithms to solve fault-tolerant consensus in asynchronous systems often\nrely on primitives such as crusader agreement, adopt-commit, and graded\nbroadcast, which provide weaker agreement properties than consensus. Although\nthese primitives have a similar flavor, they have been defined and implemented\nseparately in ad hoc ways. We propose a new problem called connected consensus\nthat has as special cases crusader agreement, adopt-commit, and graded\nbroadcast, and generalizes them to handle multi-valued inputs. The\ngeneralization is accomplished by relating the problem to approximate agreement\non graphs.\n  We present three algorithms for multi-valued connected consensus in\nasynchronous message-passing systems, one tolerating crash failures and two\ntolerating malicious (unauthenticated Byzantine) failures. We extend the\ndefinition of binding, a desirable property recently identified as supporting\nbinary consensus algorithms that are correct against adaptive adversaries, to\nthe multi-valued input case and show that all our algorithms satisfy the\nproperty. Our crash-resilient algorithm has failure-resilience and time\ncomplexity that we show are optimal. When restricted to the case of binary\ninputs, the algorithm has improved time complexity over prior algorithms. Our\ntwo algorithms for malicious failures trade off failure resilience and time\ncomplexity. The first algorithm has time complexity that we prove is optimal\nbut worse failure-resilience, while the second has failure-resilience that we\nprove is optimal but worse time complexity. When restricted to the case of\nbinary inputs, the time complexity (as well as resilience) of the second\nalgorithm matches that of prior algorithms.",
            "author": [
                "Hagit Attiya",
                "Jennifer L. Welch"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04646v1",
                "http://arxiv.org/pdf/2308.04646v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04613v1",
            "title": "Effects of Planetary Approximations on Asteroid Deflection Previsibility\n  for Trajectory Design",
            "updated": "2023-08-08T22:39:36Z",
            "published": "2023-08-08T22:39:36Z",
            "summary": "This research investigates the influence of distant encounters between an\nasteroid and perturbing bodies on the deflection process, aiming to provide\nvaluable guidelines for the trajectory design of a deflecting spacecraft.\nAnalytical approximations are commonly used in the preliminary design phase to\nquickly explore a large design space. However, the dynamics involved in\nasteroid deflection are intricate, and simple models may not capture the full\ncomplexity of the system. We examine the accuracy and limitations of analytical\nmodels compared to more accurate numerical simulations. The study reveals that\nencounters with perturbing bodies, even at considerable distances (of dozens of\nradii of the sphere of influence), can significantly perturb the asteroid's\ntrajectory, leading to discrepancies between analytical and numerical\npredictions. To address this, we propose a heuristic rule to guide trajectory\ndesigners in determining the suitability of analytical models for specific\ndeflection scenarios. By understanding the impact of distant encounters on\ndeflection, our study equips designers with the knowledge to make informed\ndecisions during the trajectory planning process, facilitating efficient and\neffective asteroid deflection missions.",
            "author": [
                "Rodolfo Batista Negri",
                "Ant\u00f4nio Fernando Bertachini de Almeida Prado"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04613v1",
                "http://arxiv.org/pdf/2308.04613v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04606v1",
            "title": "Generalized Power Iteration with Application to Distributed Connectivity\n  Estimation of Asymmetric Networks",
            "updated": "2023-08-08T22:12:07Z",
            "published": "2023-08-08T22:12:07Z",
            "summary": "The problem of connectivity assessment in an asymmetric network represented\nby a weighted directed graph is investigated in this article. A power iteration\nalgorithm in a centralized implementation is developed first to compute the\ngeneralized algebraic connectivity of asymmetric networks. After properly\ntransforming the Laplacian matrix of the network, two sequences of\none-dimensional and two-dimensional subspaces are generated iteratively, one of\nwhich converges to the desired subspace spanned by the eigenvector(s)\nassociated with the eigenvalue(s) representing the network's generalized\nalgebraic connectivity. A distributed implementation of the proposed power\niteration algorithm is then developed to compute the generalized algebraic\nconnectivity from the viewpoint of each node, which is scalable to any\nasymmetric network of any size with a fixed message length per node. The\nconvergence analysis of these algorithms is subsequently provided under some\nweak assumptions. The efficiency of the developed algorithms in computing the\nnetwork connectivity is then demonstrated by simulations.",
            "author": [
                "M. Mehdi Asadi",
                "Mohammad Khosravi",
                "Hesam Mosalli",
                "Stephane Blouin",
                "Amir G. Aghdam"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04606v1",
                "http://arxiv.org/pdf/2308.04606v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04600v2",
            "title": "Model of models -- Part 1",
            "updated": "2023-10-24T10:22:44Z",
            "published": "2023-08-08T21:56:52Z",
            "summary": "This paper proposes a new cognitive model, acting as the main component of an\nAGI agent. The model is introduced in its mature intelligence state, and as an\nextension of previous models, DENN, and especially AKREM, by including\noperational models (frames/classes) and will. This model's core assumption is\nthat cognition is about operating on accumulated knowledge, with the guidance\nof an appropriate will. Also, we assume that the actions, part of knowledge,\nare learning to be aligned with will, during the evolution phase that precedes\nthe mature intelligence state. In addition, this model is mainly based on the\nduality principle in every known intelligent aspect, such as exhibiting both\ntop-down and bottom-up model learning, generalization verse specialization, and\nmore. Furthermore, a holistic approach is advocated for AGI designing, and\ncognition under constraints or efficiency is proposed, in the form of\nreusability and simplicity. Finally, reaching this mature state is described\nvia a cognitive evolution from infancy to adulthood, utilizing a consolidation\nprinciple. The final product of this cognitive model is a dynamic operational\nmemory of models and instances. Lastly, some examples and preliminary ideas for\nthe evolution phase to reach the mature state are presented.",
            "author": [
                "Shimon Komarovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04600v2",
                "http://arxiv.org/pdf/2308.04600v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04586v12",
            "title": "Bootstrapping Developmental AIs: From Simple Competences to Intelligent\n  Human-Compatible AIs",
            "updated": "2023-11-11T15:43:13Z",
            "published": "2023-08-08T21:14:21Z",
            "summary": "The mainstream AI approaches include the generative and deep learning\napproaches with large language models (LLMs) and the manually constructed\nsymbolic approach. These approaches have led to valuable AI systems and\nimpressive feats. However, manually constructed AIs are brittle even in\ncircumscribed domains. Generative AIs make strange mistakes and do not notice\nthem. In these approaches AIs cannot be instructed easily, fail to use common\nsense, and lack curiosity. They have abstract knowledge but lack social\nalignment. Developmental AIs start with innate competences, interact with their\nenvironment, and learn from their interactions. They interact, learn from\npeople, and establish perceptual, cognitive, and common grounding. The\nbootstrapping approach tracks a competence trajectory where the competences of\nintelligence are developed in small steps in parallel by embodied AIs.\nDevelopmental AIs have capabilities for multimodal perception, object\nrecognition, and manipulation. Powerful computational models for hierarchical\nplanning, abstraction discovery, curiosity, and language acquisition exist but\nneed to be adapted to a developmental learning based approach. The promise is\nthat this research will ultimately produce AIs that learn to communicate, read\ncritically, consider the provenance of information, test hypotheses, and\ncollaborate. However, developmental AI projects have not yet passed the\nabilities of young children. The research needs to bridge competence gaps\ninvolving nonverbal communication, speech, reading, and writing. This position\npaper lays out prospects, gaps, and challenges for AI and a developmental\napproach. The goal is to create resilient, intelligent, and human-compatible\nAIs. They would learn, share what they learn, and collaborate to achieve high\nstandards.",
            "author": [
                "Mark Stefik",
                "Robert Price"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04586v12",
                "http://arxiv.org/pdf/2308.04586v12"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04579v1",
            "title": "RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose\n  Recommendation System?",
            "updated": "2023-08-08T20:54:59Z",
            "published": "2023-08-08T20:54:59Z",
            "summary": "Over the past two decades, recommendation systems (RSs) have used machine\nlearning (ML) solutions to recommend items, e.g., movies, books, and\nrestaurants, to clients of a business or an online platform. Recipe\nrecommendation, however, has not yet received much attention compared to those\napplications. We introduce RECipe as a multi-purpose recipe recommendation\nframework with a multi-modal knowledge graph (MMKG) backbone. The motivation\nbehind RECipe is to go beyond (deep) neural collaborative filtering (NCF) by\nrecommending recipes to users when they query in natural language or by\nproviding an image. RECipe consists of 3 subsystems: (1) behavior-based\nrecommender, (2) review-based recommender, and (3) image-based recommender.\nEach subsystem relies on the embedding representations of entities and\nrelations in the graph. We first obtain (pre-trained) embedding representations\nof textual entities, such as reviews or ingredients, from a fine-tuned model of\nMicrosoft's MPNet. We initialize the weights of the entities with these\nembeddings to train our knowledge graph embedding (KGE) model. For the visual\ncomponent, i.e., recipe images, we develop a KGE-Guided variational autoencoder\n(KG-VAE) to learn the distribution of images and their latent representations.\nOnce KGE and KG-VAE models are fully trained, we use them as a multi-purpose\nrecommendation framework. For benchmarking, we created two knowledge graphs\n(KGs) from public datasets on Kaggle for recipe recommendation. Our experiments\nshow that the KGE models have comparable performance to the neural solutions.\nWe also present pre-trained NLP embeddings to address important applications\nsuch as zero-shot inference for new users (or the cold start problem) and\nconditional recommendation with respect to recipe categories. We eventually\ndemonstrate the application of RECipe in a multi-purpose recommendation\nsetting.",
            "author": [
                "Ali Pesaranghader",
                "Touqir Sajed"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04579v1",
                "http://arxiv.org/pdf/2308.04579v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04575v2",
            "title": "On the Complexity of Finding a Sparse Connected Spanning Subgraph in a\n  non-Uniform Failure Model",
            "updated": "2023-08-10T06:45:00Z",
            "published": "2023-08-08T20:50:02Z",
            "summary": "We study a generalization of the classic Spanning Tree problem that allows\nfor a non-uniform failure model. More precisely, edges are either \\emph{safe}\nor \\emph{unsafe} and we assume that failures only affect unsafe edges. In\nUnweighted Flexible Graph Connectivity we are given an undirected graph $G =\n(V,E)$ in which the edge set $E$ is partitioned into a set $S$ of safe edges\nand a set $U$ of unsafe edges and the task is to find a set $T$ of at most $k$\nedges such that $T - \\{u\\}$ is connected and spans $V$ for any unsafe edge $u\n\\in T$. Unweighted Flexible Graph Connectivity generalizes both Spanning Tree\nand Hamiltonian Cycle. We study Unweighted Flexible Graph Connectivity in terms\nof fixed-parameter tractability (FPT). We show an almost complete dichotomy on\nwhich parameters lead to fixed-parameter tractability and which lead to\nhardness. To this end, we obtain FPT-time algorithms with respect to the vertex\ndeletion distance to cluster graphs and with respect to the treewidth. By\nexploiting the close relationship to Hamiltonian Cycle, we show that FPT-time\nalgorithms for many smaller parameters are unlikely under standard\nparameterized complexity assumptions. Regarding problem-specific parameters, we\nobserve that Unweighted Flexible Graph Connectivity} admits an FPT-time\nalgorithm when parameterized by the number of unsafe edges. Furthermore, we\ninvestigate a below-upper-bound parameter for the number of edges of a\nsolution. We show that this parameter also leads to an FPT-time algorithm.",
            "author": [
                "Matthias Bentert",
                "Jannik Schestag",
                "Frank Sommer"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04575v2",
                "http://arxiv.org/pdf/2308.04575v2"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04552v1",
            "title": "WhaleVis: Visualizing the History of Commercial Whaling",
            "updated": "2023-08-08T19:48:51Z",
            "published": "2023-08-08T19:48:51Z",
            "summary": "Whales are an important part of the oceanic ecosystem. Although historic\ncommercial whale hunting a.k.a. whaling has severely threatened whale\npopulations, whale researchers are looking at historical whaling data to inform\ncurrent whale status and future conservation efforts. To facilitate this, we\nworked with experts in aquatic and fishery sciences to create WhaleVis -- an\ninteractive dashboard for the commercial whaling dataset maintained by the\nInternational Whaling Commission (IWC). We characterize key analysis tasks\namong whale researchers for this database, most important of which is inferring\nspatial distribution of whale populations over time. In addition to\nfacilitating analysis of whale catches based on the spatio-temporal attributes,\nwe use whaling expedition details to plot the search routes of expeditions. We\npropose a model of the catch data as a graph, where nodes represent catch\nlocations, and edges represent whaling expedition routes. This model\nfacilitates visual estimation of whale search effort and in turn the spatial\ndistribution of whale populations normalized by the search effort -- a well\nknown problem in fisheries research. It further opens up new avenues for graph\nanalysis on the data, including more rigorous computation of spatial\ndistribution of whales normalized by the search effort, and enabling new\ninsight generation. We demonstrate the use of our dashboard through a real life\nuse case.",
            "author": [
                "Ameya Patil",
                "Zoe Rand",
                "Trevor Branch",
                "Leilani Battle"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04552v1",
                "http://arxiv.org/pdf/2308.04552v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "J.2; J.3; H.5; I.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04548v1",
            "title": "Spartan Bipartite Graphs are Essentially Elementary",
            "updated": "2023-08-08T19:37:23Z",
            "published": "2023-08-08T19:37:23Z",
            "summary": "We study a two-player game on a graph between an attacker and a defender. To\nbegin with, the defender places guards on a subset of vertices. In each move,\nthe attacker attacks an edge. The defender must move at least one guard across\nthe attacked edge to defend the attack. The defender wins if and only if the\ndefender can defend an infinite sequence of attacks. The smallest number of\nguards with which the defender has a winning strategy is called the eternal\nvertex cover number of a graph $G$ and is denoted by $evc(G)$. It is clear that\n$evc(G)$ is at least $mvc(G)$, the size of a minimum vertex cover of $G$. We\nsay that $G$ is Spartan if $evc(G) = mvc(G)$. The characterization of Spartan\ngraphs has been largely open. In the setting of bipartite graphs on $2n$\nvertices where every edge belongs to a perfect matching, an easy strategy is to\nhave $n$ guards that always move along perfect matchings in response to\nattacks. We show that these are essentially the only Spartan bipartite graphs.",
            "author": [
                "Neeldhara Misra",
                "Saraswati Girish Nanoti"
            ],
            "link": [
                "http://dx.doi.org/10.4230/LIPIcs.MFCS.2023.68",
                "http://arxiv.org/abs/2308.04548v1",
                "http://arxiv.org/pdf/2308.04548v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO",
                "F.2; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04544v1",
            "title": "Finding Optimal Pathways in Chemical Reaction Networks Using Ising\n  Machines",
            "updated": "2023-08-08T19:22:54Z",
            "published": "2023-08-08T19:22:54Z",
            "summary": "Finding optimal pathways in chemical reaction networks is essential for\nelucidating and designing chemical processes, with significant applications\nsuch as synthesis planning and metabolic pathway analysis. Such a chemical\npathway-finding problem can be formulated as a constrained combinatorial\noptimization problem, aiming to find an optimal combination of chemical\nreactions connecting starting materials to target materials in a given network.\nDue to combinatorial explosion, the computation time required to find an\noptimal pathway increases exponentially with the network size. Ising machines,\nincluding quantum and simulated annealing devices, are promising novel\ncomputers dedicated to such hard combinatorial optimization. However, to the\nbest of our knowledge, there has yet to be an attempt to apply Ising machines\nto chemical pathway-finding problems. In this article, we present the first\nIsing/quantum computing application for chemical pathway-finding problems. The\nIsing model, translated from a chemical pathway-finding problem, involves\nseveral types of penalty terms for violating constraints. It is not obvious how\nto set appropriate penalty strengths of different types. To address this\nchallenge, we employ Bayesian optimization for parameter tuning. Furthermore,\nwe introduce a novel technique that enhances tuning performance by grouping\npenalty terms according to the underlying problem structure. The performance\nevaluation and analysis of the proposed algorithm were conducted using a D-Wave\nAdvantage system and simulated annealing. The benchmark results reveal\nchallenges in finding exact optimal pathways. Concurrently, the results\nindicate the feasibility of finding approximate optimal pathways, provided that\na certain degree of relative error in cost value is acceptable.",
            "author": [
                "Yuta Mizuno",
                "Tamiki Komatsuzaki"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04544v1",
                "http://arxiv.org/pdf/2308.04544v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04536v1",
            "title": "Facial Prior Based First Order Motion Model for Micro-expression\n  Generation",
            "updated": "2023-08-08T18:57:03Z",
            "published": "2023-08-08T18:57:03Z",
            "summary": "Spotting facial micro-expression from videos finds various potential\napplications in fields including clinical diagnosis and interrogation,\nmeanwhile this task is still difficult due to the limited scale of training\ndata. To solve this problem, this paper tries to formulate a new task called\nmicro-expression generation and then presents a strong baseline which combines\nthe first order motion model with facial prior knowledge. Given a target face,\nwe intend to drive the face to generate micro-expression videos according to\nthe motion patterns of source videos. Specifically, our new model involves\nthree modules. First, we extract facial prior features from a region focusing\nmodule. Second, we estimate facial motion using key points and local affine\ntransformations with a motion prediction module. Third, expression generation\nmodule is used to drive the target face to generate videos. We train our model\non public CASME II, SAMM and SMIC datasets and then use the model to generate\nnew micro-expression videos for evaluation. Our model achieves the first place\nin the Facial Micro-Expression Challenge 2021 (MEGC2021), where our superior\nperformance is verified by three experts with Facial Action Coding System\ncertification. Source code is provided in\nhttps://github.com/Necolizer/Facial-Prior-Based-FOMM.",
            "author": [
                "Yi Zhang",
                "Youjun Zhao",
                "Yuhang Wen",
                "Zixuan Tang",
                "Xinhua Xu",
                "Mengyuan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04536v1",
                "http://arxiv.org/pdf/2308.04536v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04534v1",
            "title": "Ahead of the Text: Leveraging Entity Preposition for Financial Relation\n  Extraction",
            "updated": "2023-08-08T18:56:52Z",
            "published": "2023-08-08T18:56:52Z",
            "summary": "In the context of the ACM KDF-SIGIR 2023 competition, we undertook an entity\nrelation task on a dataset of financial entity relations called REFind. Our\ntop-performing solution involved a multi-step approach. Initially, we inserted\nthe provided entities at their corresponding locations within the text.\nSubsequently, we fine-tuned the transformer-based language model roberta-large\nfor text classification by utilizing a labeled training set to predict the\nentity relations. Lastly, we implemented a post-processing phase to identify\nand handle improbable predictions generated by the model. As a result of our\nmethodology, we achieved the 1st place ranking on the competition's public\nleaderboard.",
            "author": [
                "Stefan Pasch",
                "Dimitrios Petridis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04534v1",
                "http://arxiv.org/pdf/2308.04534v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04522v2",
            "title": "Deep Learning for Diverse Data Types Steganalysis: A Review",
            "updated": "2023-08-11T15:39:03Z",
            "published": "2023-08-08T18:37:24Z",
            "summary": "Steganography and steganalysis are two interrelated aspects of the field of\ninformation security. Steganography seeks to conceal communications, whereas\nsteganalysis is aimed to either find them or even, if possible, recover the\ndata they contain. Steganography and steganalysis have attracted a great deal\nof interest, particularly from law enforcement. Steganography is often used by\ncybercriminals and even terrorists to avoid being captured while in possession\nof incriminating evidence, even encrypted, since cryptography is prohibited or\nrestricted in many countries. Therefore, knowledge of cutting-edge techniques\nto uncover concealed information is crucial in exposing illegal acts. Over the\nlast few years, a number of strong and reliable steganography and steganalysis\ntechniques have been introduced in the literature. This review paper provides a\ncomprehensive overview of deep learning-based steganalysis techniques used to\ndetect hidden information within digital media. The paper covers all types of\ncover in steganalysis, including image, audio, and video, and discusses the\nmost commonly used deep learning techniques. In addition, the paper explores\nthe use of more advanced deep learning techniques, such as deep transfer\nlearning (DTL) and deep reinforcement learning (DRL), to enhance the\nperformance of steganalysis systems. The paper provides a systematic review of\nrecent research in the field, including data sets and evaluation metrics used\nin recent studies. It also presents a detailed analysis of DTL-based\nsteganalysis approaches and their performance on different data sets. The\nreview concludes with a discussion on the current state of deep learning-based\nsteganalysis, challenges, and future research directions.",
            "author": [
                "Hamza Kheddar",
                "Mustapha Hemis",
                "Yassine Himeur",
                "David Meg\u00edas",
                "Abbes Amira"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04522v2",
                "http://arxiv.org/pdf/2308.04522v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04509v1",
            "title": "Acyclic graphs with at least $2\\ell+1$ vertices are $\\ell$-recognizable",
            "updated": "2023-08-08T18:17:49Z",
            "published": "2023-08-08T18:17:49Z",
            "summary": "The $(n-\\ell)$-deck of an $n$-vertex graph is the multiset of subgraphs\nobtained from it by deleting $\\ell$ vertices. A family of $n$-vertex graphs is\n$\\ell$-recognizable if every graph having the same $(n-\\ell)$-deck as a graph\nin the family is also in the family. We prove that the family of $n$-vertex\ngraphs with no cycles is $\\ell$-recognizable when $n\\ge2\\ell+1$ (except for\n$(n,\\ell)=(5,2)$). As a consequence, the family of $n$-vertex trees is\n$\\ell$-recognizable when $n\\ge2\\ell+1$ and $\\ell\\ne2$. It is known that this\nfails when $n=2\\ell$.",
            "author": [
                "Alexandr V. Kostochka",
                "Mina Nahvi",
                "Douglas B. West",
                "Dara Zirlin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04509v1",
                "http://arxiv.org/pdf/2308.04509v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04498v2",
            "title": "DialogRE^C+: An Extension of DialogRE to Investigate How Much\n  Coreference Helps Relation Extraction in Dialogs",
            "updated": "2023-08-12T06:12:36Z",
            "published": "2023-08-08T18:03:29Z",
            "summary": "Dialogue relation extraction (DRE) that identifies the relations between\nargument pairs in dialogue text, suffers much from the frequent occurrence of\npersonal pronouns, or entity and speaker coreference. This work introduces a\nnew benchmark dataset DialogRE^C+, introducing coreference resolution into the\nDRE scenario. With the aid of high-quality coreference knowledge, the reasoning\nof argument relations is expected to be enhanced. In DialogRE^C+ dataset, we\nmanually annotate total 5,068 coreference chains over 36,369 argument mentions\nbased on the existing DialogRE data, where four different coreference chain\ntypes namely speaker chain, person chain, location chain and organization chain\nare explicitly marked. We further develop 4 coreference-enhanced graph-based\nDRE models, which learn effective coreference representations for improving the\nDRE task. We also train a coreference resolution model based on our annotations\nand evaluate the effect of automatically extracted coreference chains\ndemonstrating the practicality of our dataset and its potential to other\ndomains and tasks.",
            "author": [
                "Yiyun Xiong",
                "Mengwei Dai",
                "Fei Li",
                "Hao Fei",
                "Bobo Li",
                "Shengqiong Wu",
                "Donghong Ji",
                "Chong Teng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04498v2",
                "http://arxiv.org/pdf/2308.04498v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04412v2",
            "title": "Probabilistic Invariant Learning with Randomized Linear Classifiers",
            "updated": "2023-09-28T00:00:16Z",
            "published": "2023-08-08T17:18:04Z",
            "summary": "Designing models that are both expressive and preserve known invariances of\ntasks is an increasingly hard problem. Existing solutions tradeoff invariance\nfor computational or memory resources. In this work, we show how to leverage\nrandomness and design models that are both expressive and invariant but use\nless resources. Inspired by randomized algorithms, our key insight is that\naccepting probabilistic notions of universal approximation and invariance can\nreduce our resource requirements. More specifically, we propose a class of\nbinary classification models called Randomized Linear Classifiers (RLCs). We\ngive parameter and sample size conditions in which RLCs can, with high\nprobability, approximate any (smooth) function while preserving invariance to\ncompact group transformations. Leveraging this result, we design three RLCs\nthat are provably probabilistic invariant for classification tasks over sets,\ngraphs, and spherical data. We show how these models can achieve probabilistic\ninvariance and universality using less resources than (deterministic) neural\nnetworks and their invariant counterparts. Finally, we empirically demonstrate\nthe benefits of this new class of models on invariant tasks where deterministic\ninvariant neural networks are known to struggle.",
            "author": [
                "Leonardo Cotta",
                "Gal Yehuda",
                "Assaf Schuster",
                "Chris J. Maddison"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04412v2",
                "http://arxiv.org/pdf/2308.04412v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04407v2",
            "title": "Chrisimos: A useful Proof-of-Work for finding Minimal Dominating Set of\n  a graph",
            "updated": "2023-09-13T12:54:31Z",
            "published": "2023-08-08T17:13:09Z",
            "summary": "Hash-based Proof-of-Work (PoW) used in the Bitcoin Blockchain leads to high\nenergy consumption and resource wastage. In this paper, we aim to re-purpose\nthe energy by replacing the hash function with real-life problems having\ncommercial utility. We propose Chrisimos, a useful Proof-of-Work where miners\nare required to find a minimal dominating set for real-life graph instances. A\nminer who is able to output the smallest dominating set for the given graph\nwithin the block interval time wins the mining game. We also propose a new\nchain selection rule that ensures the security of the scheme. Thus our protocol\nalso realizes a decentralized minimal dominating set solver for any graph\ninstance. We provide formal proof of correctness and show via experimental\nresults that the block interval time is within feasible bounds of hash-based\nPoW.",
            "author": [
                "Diptendu Chatterjee",
                "Prabal Banerjee",
                "Subhra Mazumdar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04407v2",
                "http://arxiv.org/pdf/2308.04407v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04406v1",
            "title": "XGBD: Explanation-Guided Graph Backdoor Detection",
            "updated": "2023-08-08T17:10:23Z",
            "published": "2023-08-08T17:10:23Z",
            "summary": "Backdoor attacks pose a significant security risk to graph learning models.\nBackdoors can be embedded into the target model by inserting backdoor triggers\ninto the training dataset, causing the model to make incorrect predictions when\nthe trigger is present. To counter backdoor attacks, backdoor detection has\nbeen proposed. An emerging detection strategy in the vision and NLP domains is\nbased on an intriguing phenomenon: when training models on a mixture of\nbackdoor and clean samples, the loss on backdoor samples drops significantly\nfaster than on clean samples, allowing backdoor samples to be easily detected\nby selecting samples with the lowest loss values. However, the ignorance of\ntopological feature information on graph data limits its detection\neffectiveness when applied directly to the graph domain. To this end, we\npropose an explanation-guided backdoor detection method to take advantage of\nthe topological information. Specifically, we train a helper model on the graph\ndataset, feed graph samples into the model, and then adopt explanation methods\nto attribute model prediction to an important subgraph. We observe that\nbackdoor samples have distinct attribution distribution than clean samples, so\nthe explanatory subgraph could serve as more discriminative features for\ndetecting backdoor samples. Comprehensive experiments on multiple popular\ndatasets and attack methods demonstrate the effectiveness and explainability of\nour method. Our code is available:\nhttps://github.com/GuanZihan/GNN_backdoor_detection.",
            "author": [
                "Zihan Guan",
                "Mengnan Du",
                "Ninghao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04406v1",
                "http://arxiv.org/pdf/2308.04406v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04390v3",
            "title": "On the approximability of the burning number",
            "updated": "2023-09-06T08:16:42Z",
            "published": "2023-08-08T16:48:39Z",
            "summary": "The burning number of a graph $G$ is the smallest number $b$ such that the\nvertices of $G$ can be covered by balls of radii $0, 1, \\dots, b-1$. As\ncomputing the burning number of a graph is known to be NP-hard, even on trees,\nit is natural to consider polynomial time approximation algorithms for the\nquantity. The best known approximation factor in the literature is $3$ for\ngeneral graphs and $2$ for trees. In this note we give a\n$2/(1-e^{-2})+\\varepsilon=2.313\\dots$-approximation algorithm for the burning\nnumber of general graphs, and a PTAS for the burning number of trees and\nforests. Moreover, we show that computing a\n$(\\frac53-\\varepsilon)$-approximation of the burning number of a general graph\n$G$ is NP-hard.",
            "author": [
                "Anders Martinsson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04390v3",
                "http://arxiv.org/pdf/2308.04390v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04388v1",
            "title": "Gravitational Scattering of Compact Bodies from Worldline Quantum Field\n  Theory",
            "updated": "2023-08-08T16:42:11Z",
            "published": "2023-08-08T16:42:11Z",
            "summary": "In this work the worldline quantum field theory (WQFT) approach to computing\nobservables of the classical general relativistic two-body system is presented.\nCompact bodies such as black holes or neutron stars are described in an\neffective field theory by worldline fields with spin degrees of freedom\nefficiently described by anti-commuting Grassmann variables. Novel results of\nthe WQFT include the gravitational bremsstrahlung at second post-Minkowskian\norder and the impulse and spin kick at third post-Minkowskian order all at\nquadratic order in spins.\n  Next, the WQFT is presented with a comprehensive discussion of its in-in\nSchwinger-Keldysh formulation, its Feynman rules and graph generation and its\non-shell one-point functions which are directly related to the scattering\nobservables of unbound motion. Here, we present the second post-Minkowskian\nquadratic-in-spin contributions to its free energy from which the impulse and\nspin kick may be derived to the corresponding order.\n  The computation of scattering observables requires the evaluation of\nmulti-loop integrals and for the computation of observables at the third\npost-Minkowskian order we analyze the required two-loop integrals. Our\ndiscussion uses retarded propagators which impose causal boundary conditions of\nthe observables.\n  Finally we turn to results of the WQFT starting with the gravitational\nbremsstrahlung of the scattering of two spinning bodies. This waveform is\ndiscussed together with its radiative information of linear and angular\nmomentum fluxes.\n  Lastly we present the conservative and radiative impulse and spin kick at\nthird post-Minkowskian order and quadratic order in spins together with the a\nconservative Hamiltonian at the corresponding perturbative order. The results\nobey a generalized Bini-Damour radiation-reaction relation and their\nconservative parts can be parametrized in terms of a single scalar.",
            "author": [
                "Gustav Uhre Jakobsen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04388v1",
                "http://arxiv.org/pdf/2308.04388v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04372v1",
            "title": "Some Options for Instantiation of Bipolar Argument Graphs with Deductive\n  Arguments",
            "updated": "2023-08-08T16:22:27Z",
            "published": "2023-08-08T16:22:27Z",
            "summary": "Argument graphs provide an abstract representation of an argumentative\nsituation. A bipolar argument graph is a directed graph where each node denotes\nan argument, and each arc denotes the influence of one argument on another.\nHere we assume that the influence is supporting, attacking, or ambiguous. In a\nbipolar argument graph, each argument is atomic and so it has no internal\nstructure. Yet to better understand the nature of the individual arguments, and\nhow they interact, it is important to consider their internal structure. To\naddress this need, this paper presents a framework based on the use of logical\narguments to instantiate bipolar argument graphs, and a set of possible\nconstraints on instantiating arguments that take into account the internal\nstructure of the arguments, and the types of relationship between arguments.",
            "author": [
                "Anthony Hunter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04372v1",
                "http://arxiv.org/pdf/2308.04372v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04369v1",
            "title": "SSTFormer: Bridging Spiking Neural Network and Memory Support\n  Transformer for Frame-Event based Recognition",
            "updated": "2023-08-08T16:15:35Z",
            "published": "2023-08-08T16:15:35Z",
            "summary": "Event camera-based pattern recognition is a newly arising research topic in\nrecent years. Current researchers usually transform the event streams into\nimages, graphs, or voxels, and adopt deep neural networks for event-based\nclassification. Although good performance can be achieved on simple event\nrecognition datasets, however, their results may be still limited due to the\nfollowing two issues. Firstly, they adopt spatial sparse event streams for\nrecognition only, which may fail to capture the color and detailed texture\ninformation well. Secondly, they adopt either Spiking Neural Networks (SNN) for\nenergy-efficient recognition with suboptimal results, or Artificial Neural\nNetworks (ANN) for energy-intensive, high-performance recognition. However,\nseldom of them consider achieving a balance between these two aspects. In this\npaper, we formally propose to recognize patterns by fusing RGB frames and event\nstreams simultaneously and propose a new RGB frame-event recognition framework\nto address the aforementioned issues. The proposed method contains four main\nmodules, i.e., memory support Transformer network for RGB frame encoding,\nspiking neural network for raw event stream encoding, multi-modal bottleneck\nfusion module for RGB-Event feature aggregation, and prediction head. Due to\nthe scarce of RGB-Event based classification dataset, we also propose a\nlarge-scale PokerEvent dataset which contains 114 classes, and 27102\nframe-event pairs recorded using a DVS346 event camera. Extensive experiments\non two RGB-Event based classification datasets fully validated the\neffectiveness of our proposed framework. We hope this work will boost the\ndevelopment of pattern recognition by fusing RGB frames and event streams. Both\nour dataset and source code of this work will be released at\nhttps://github.com/Event-AHU/SSTFormer.",
            "author": [
                "Xiao Wang",
                "Zongzhen Wu",
                "Yao Rong",
                "Lin Zhu",
                "Bo Jiang",
                "Jin Tang",
                "Yonghong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04369v1",
                "http://arxiv.org/pdf/2308.04369v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04365v4",
            "title": "SLEM: Machine Learning for Path Modeling and Causal Inference with Super\n  Learner Equation Modeling",
            "updated": "2023-08-11T16:40:41Z",
            "published": "2023-08-08T16:04:42Z",
            "summary": "Causal inference is a crucial goal of science, enabling researchers to arrive\nat meaningful conclusions regarding the predictions of hypothetical\ninterventions using observational data. Path models, Structural Equation Models\n(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to\nunambiguously specify assumptions regarding the causal structure underlying a\nphenomenon. Unlike DAGs, which make very few assumptions about the functional\nand parametric form, SEM assumes linearity. This can result in functional\nmisspecification which prevents researchers from undertaking reliable effect\nsize estimation. In contrast, we propose Super Learner Equation Modeling, a\npath modeling technique integrating machine learning Super Learner ensembles.\nWe empirically demonstrate its ability to provide consistent and unbiased\nestimates of causal effects, its competitive performance for linear models when\ncompared with SEM, and highlight its superiority over SEM when dealing with\nnon-linear relationships. We provide open-source code, and a tutorial notebook\nwith example usage, accentuating the easy-to-use nature of the method.",
            "author": [
                "Matthew J. Vowels"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04365v4",
                "http://arxiv.org/pdf/2308.04365v4"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04357v1",
            "title": "Ramsey problems for monotone paths in graphs and hypergraphs",
            "updated": "2023-08-08T16:01:39Z",
            "published": "2023-08-08T16:01:39Z",
            "summary": "The study of ordered Ramsey numbers of monotone paths for graphs and\nhypergraphs has a long history, going back to the celebrated work by Erd\\H{o}s\nand Szekeres in the early days of Ramsey theory. In this paper we obtain\nseveral results in this area, establishing two conjectures of Mubayi and Suk\nand improving bounds due to Balko, Cibulka, Kr\\'al and Kyn\\v{c}l. We also\nobtain a color-monotone version of the well-known Canonical Ramsey Theorem of\nErd\\H{o}s and Rado, which could be of independent interest.",
            "author": [
                "Lior Gishboliner",
                "Zhihan Jin",
                "Benny Sudakov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04357v1",
                "http://arxiv.org/pdf/2308.04357v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04339v1",
            "title": "Spectral multiplicity functions of adjacency operators of graphs and\n  cospectral infinite graphs",
            "updated": "2023-08-08T15:36:14Z",
            "published": "2023-08-08T15:36:14Z",
            "summary": "The adjacency operator of a graph has a spectrum and a class of scalar-valued\nspectral measures which have been systematically analyzed; it also has a\nspectral multiplicity function which has been less studied. The first purpose\nof this article is to review a small number of examples of infinite graphs $G =\n(V,E)$ for which the spectral multiplicity function of the adjacency operator\n$A_G$ of $G$ has been determined. The second purpose of this article is to show\nexplicit examples of infinite connected graphs which are cospectral, i.e.,\nwhich have unitarily equivalent adjacency operators.",
            "author": [
                "Pierre de la Harpe"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04339v1",
                "http://arxiv.org/pdf/2308.04339v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 47A10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04336v2",
            "title": "On the concentration of the maximum degree in the duplication-divergence\n  models",
            "updated": "2023-12-06T17:29:17Z",
            "published": "2023-08-08T15:30:07Z",
            "summary": "We present a rigorous and precise analysis of the maximum degree and the\naverage degree in a dynamic duplication-divergence graph model introduced by\nSol\\'e, Pastor-Satorras et al. in which the graph grows according to a\nduplication-divergence mechanism, i.e. by iteratively creating a copy of some\nnode and then randomly alternating the neighborhood of a new node with\nprobability $p$. This model captures the growth of some real-world processes\ne.g. biological or social networks.\n  In this paper, we prove that for some $0 < p < 1$ the maximum degree and the\naverage degree of a duplication-divergence graph on $t$ vertices are\nasymptotically concentrated with high probability around $t^p$ and $\\max\\{t^{2\np - 1}, 1\\}$, respectively, i.e. they are within at most a polylogarithmic\nfactor from these values with probability at least $1 - t^{-A}$ for any\nconstant $A > 0$.",
            "author": [
                "Alan Frieze",
                "Krzysztof Turowski",
                "Wojciech Szpankowski"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04336v2",
                "http://arxiv.org/pdf/2308.04336v2"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "05C07, 05C80, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04307v1",
            "title": "A survey on constructive methods for the Oberwolfach problem and its\n  variants",
            "updated": "2023-08-08T14:52:06Z",
            "published": "2023-08-08T14:52:06Z",
            "summary": "The generalized Oberwolfach problem asks for a decomposition of a graph $G$\ninto specified 2-regular spanning subgraphs $F_1,\\ldots, F_k$, called factors.\nThe classic Oberwolfach problem corresponds to the case when all of the factors\nare pairwise isomorphic, and $G$ is the complete graph of odd order or the\ncomplete graph of even order with the edges of a $1$-factor removed. When there\nare two possible factor types, it is called the Hamilton-Waterloo problem.\n  In this paper we present a survey of constructive methods which have allowed\nrecent progress in this area. Specifically, we consider blow-up type\nconstructions, particularly as applied to the case when each factor consists of\ncycles of the same length. We consider the case when the factors are all\nbipartite (and hence consist of even cycles) and a method for using circulant\ngraphs to find solutions. We also consider constructions which yield solutions\nwith well-behaved automorphisms.",
            "author": [
                "Andrea Burgess",
                "Peter Danziger",
                "Tommaso Traetta"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04307v1",
                "http://arxiv.org/pdf/2308.04307v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05B30, 05C51, 05C70, 05C78, 05E18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04306v3",
            "title": "Deep Learning-Based Knowledge Injection for Metaphor Detection: A\n  Comprehensive Review",
            "updated": "2023-09-19T05:08:39Z",
            "published": "2023-08-08T14:51:16Z",
            "summary": "The history of metaphor research also marks the evolution of knowledge\ninfusion research. With the continued advancement of deep learning techniques\nin recent years, the natural language processing community has shown great\ninterest in applying knowledge to successful results in metaphor recognition\ntasks. Although there has been a gradual increase in the number of approaches\ninvolving knowledge injection in the field of metaphor recognition, there is a\nlack of a complete review article on knowledge injection based approaches.\nTherefore, the goal of this paper is to provide a comprehensive review of\nresearch advances in the application of deep learning for knowledge injection\nin metaphor recognition tasks. In this paper, we systematically summarize and\ngeneralize the mainstream knowledge and knowledge injection principles, as well\nas review the datasets, evaluation metrics, and benchmark models used in\nmetaphor recognition tasks. Finally, we explore the current issues facing\nknowledge injection methods and provide an outlook on future research\ndirections.",
            "author": [
                "Cheng Yang",
                "Wenye Zhao",
                "Zhiyue Liu",
                "Qingbao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04306v3",
                "http://arxiv.org/pdf/2308.04306v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04475v1",
            "title": "Sums of squares of eigenvalues and the vector chromatic number",
            "updated": "2023-08-08T14:37:25Z",
            "published": "2023-08-08T14:37:25Z",
            "summary": "In this short paper we prove that the sum of the squares of negative (or\npositive) eigenvalues of the adjacency matrix of a graph is lower bounded by\nthe sum of the degrees divided by the vector chromatic number, resolving a\nconjecture by Wocjan, Elphick and Anekstein (2018).",
            "author": [
                "Gabriel Coutinho",
                "Thom\u00e1s Jung Spier"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04475v1",
                "http://arxiv.org/pdf/2308.04475v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04284v1",
            "title": "A Littlewood-Offord kind of problem in $\\mathbb{Z}_p$ and\n  $\u0393$-sequenceability",
            "updated": "2023-08-08T14:25:28Z",
            "published": "2023-08-08T14:25:28Z",
            "summary": "The Littlewood-Offord problem is a classical question in probability theory\nand discrete mathematics, proposed, firstly by Littlewood and Offord in the\n1940s. Given a set $A$ of integer, this problem asks for an upper bound on the\nprobability that a randomly chosen subset $X$ of $A$ sums to an integer $x$.\n  This article proposes a variation of the problem, considering a subset $A$ of\na cyclic group of prime order and examining subsets $X\\subseteq A$ of a given\ncardinality $\\ell$. The main focus of this paper is then on bounding the\nprobability distribution of the sum $Y$ of $\\ell$ i.i.d. $Y_1,\\dots, Y_{\\ell}$\nwhose support is contained in $\\mathbb{Z}_p$. The main result here presented is\nthat, if the probability distributions of the variables $Y_i$ are bounded by\n$\\lambda \\leq 9/10$, then, assuming that $p>\n\\frac{2}{\\lambda}\\left(\\frac{\\ell_0}{3}\\right)^{\\nu}$ (for some\n$\\ell_0\\leq\\ell$), the distribution of $Y$ is bounded by\n$\\lambda\\left(\\frac{3}{\\ell_0}\\right)^{\\nu}$ for some positive absolute\nconstant $\\nu$. Then an analogous result is implied for the Littlewood-Offord\nproblem over $\\mathbb{Z}_p$ on subsets $X$ of a given cardinality $\\ell$ in the\nregime where $n$ is large enough.\n  Finally, as an application of our results, we propose a variation of the\nset-sequenceability problem: that of $\\Gamma$-sequenceability. Given a graph\n$\\Gamma$ on the vertex set $\\{1,2,\\dots,n\\}$ and given a subset $A\\subseteq\n\\mathbb{Z}_p$ of size $n$, here we want to find an ordering of $A$ such that\nthe partial sums $s_i$ and $s_j$ are different whenever $\\{i,j\\}\\in E(\\Gamma)$.\nAs a consequence of our results on the Littlewood-Offord problem, we have been\nable to prove that, if the maximum degree of $\\Gamma$ is at most $d$, $n$ is\nlarge enough, and $p>n^2$, any subset $A\\subseteq \\mathbb{Z}_p$ of size $n$ is\n$\\Gamma$-sequenceable.",
            "author": [
                "Simone Costa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04284v1",
                "http://arxiv.org/pdf/2308.04284v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.NT",
                "math.PR",
                "11B75, 60G50, 05C38, 05D40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04268v1",
            "title": "Teacher-Student Architecture for Knowledge Distillation: A Survey",
            "updated": "2023-08-08T14:09:33Z",
            "published": "2023-08-08T14:09:33Z",
            "summary": "Although Deep neural networks (DNNs) have shown a strong capacity to solve\nlarge-scale problems in many areas, such DNNs are hard to be deployed in\nreal-world systems due to their voluminous parameters. To tackle this issue,\nTeacher-Student architectures were proposed, where simple student networks with\na few parameters can achieve comparable performance to deep teacher networks\nwith many parameters. Recently, Teacher-Student architectures have been\neffectively and widely embraced on various knowledge distillation (KD)\nobjectives, including knowledge compression, knowledge expansion, knowledge\nadaptation, and knowledge enhancement. With the help of Teacher-Student\narchitectures, current studies are able to achieve multiple distillation\nobjectives through lightweight and generalized student networks. Different from\nexisting KD surveys that primarily focus on knowledge compression, this survey\nfirst explores Teacher-Student architectures across multiple distillation\nobjectives. This survey presents an introduction to various knowledge\nrepresentations and their corresponding optimization objectives. Additionally,\nwe provide a systematic overview of Teacher-Student architectures with\nrepresentative learning algorithms and effective distillation schemes. This\nsurvey also summarizes recent applications of Teacher-Student architectures\nacross multiple purposes, including classification, recognition, generation,\nranking, and regression. Lastly, potential research directions in KD are\ninvestigated, focusing on architecture design, knowledge quality, and\ntheoretical studies of regression-based learning, respectively. Through this\ncomprehensive survey, industry practitioners and the academic community can\ngain valuable insights and guidelines for effectively designing, learning, and\napplying Teacher-Student architectures on various distillation objectives.",
            "author": [
                "Chengming Hu",
                "Xuan Li",
                "Dan Liu",
                "Haolun Wu",
                "Xi Chen",
                "Ju Wang",
                "Xue Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04268v1",
                "http://arxiv.org/pdf/2308.04268v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04260v1",
            "title": "Nonequilibrium Response for Markov Jump Processes: Exact Results and\n  Tight Bounds",
            "updated": "2023-08-08T13:49:23Z",
            "published": "2023-08-08T13:49:23Z",
            "summary": "Generalizing response theory of open systems far from equilibrium is a\ncentral quest of nonequilibrium statistical physics. Using stochastic\nthermodynamics, we develop an algebraic method to study the response of\nnonequilibrium steady state to arbitrary perturbations. This allows us to\nderive explicit expressions for the response of edge currents as well as\ntraffic to perturbations in kinetic barriers and driving forces. We also show\nthat these responses satisfy very simple bounds. For the response to energy\nperturbations, we straightforwardly recover results obtained using nontrivial\ngraph-theoretical methods.",
            "author": [
                "Timur Aslyamov",
                "Massimiliano Esposito"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04260v1",
                "http://arxiv.org/pdf/2308.04260v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "physics.bio-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04251v1",
            "title": "On the Node-Averaged Complexity of Locally Checkable Problems on Trees",
            "updated": "2023-08-08T13:35:38Z",
            "published": "2023-08-08T13:35:38Z",
            "summary": "Over the past decade, a long line of research has investigated the\ndistributed complexity landscape of locally checkable labeling (LCL) problems\non bounded-degree graphs, culminating in an almost-complete classification on\ngeneral graphs and a complete classification on trees. The latter states that,\non bounded-degree trees, any LCL problem has deterministic \\emph{worst-case}\ntime complexity $O(1)$, $\\Theta(\\log^* n)$, $\\Theta(\\log n)$, or\n$\\Theta(n^{1/k})$ for some positive integer $k$, and all of those complexity\nclasses are nonempty. Moreover, randomness helps only for (some) problems with\ndeterministic worst-case complexity $\\Theta(\\log n)$, and if randomness helps\n(asymptotically), then it helps exponentially.\n  In this work, we study how many distributed rounds are needed \\emph{on\naverage per node} in order to solve an LCL problem on trees. We obtain a\npartial classification of the deterministic \\emph{node-averaged} complexity\nlandscape for LCL problems. As our main result, we show that every problem with\nworst-case round complexity $O(\\log n)$ has deterministic node-averaged\ncomplexity $O(\\log^* n)$. We further establish bounds on the node-averaged\ncomplexity of problems with worst-case complexity $\\Theta(n^{1/k})$: we show\nthat all these problems have node-averaged complexity $\\widetilde{\\Omega}(n^{1\n/ (2^k - 1)})$, and that this lower bound is tight for some problems.",
            "author": [
                "Alkida Balliu",
                "Sebastian Brandt",
                "Fabian Kuhn",
                "Dennis Olivetti",
                "Gustav Schmid"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04251v1",
                "http://arxiv.org/pdf/2308.04251v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC",
                "F.2.2; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04244v1",
            "title": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
            "updated": "2023-08-08T13:17:37Z",
            "published": "2023-08-08T13:17:37Z",
            "summary": "The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.",
            "author": [
                "Xiaoyu Chen",
                "Changde Du",
                "Qiongyi Zhou",
                "Huiguang He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04244v1",
                "http://arxiv.org/pdf/2308.04244v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.HC",
                "eess.AS",
                "q-bio.NC",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04243v1",
            "title": "AICSD: Adaptive Inter-Class Similarity Distillation for Semantic\n  Segmentation",
            "updated": "2023-08-08T13:17:20Z",
            "published": "2023-08-08T13:17:20Z",
            "summary": "In recent years, deep neural networks have achieved remarkable accuracy in\ncomputer vision tasks. With inference time being a crucial factor, particularly\nin dense prediction tasks such as semantic segmentation, knowledge distillation\nhas emerged as a successful technique for improving the accuracy of lightweight\nstudent networks. The existing methods often neglect the information in\nchannels and among different classes. To overcome these limitations, this paper\nproposes a novel method called Inter-Class Similarity Distillation (ICSD) for\nthe purpose of knowledge distillation. The proposed method transfers high-order\nrelations from the teacher network to the student network by independently\ncomputing intra-class distributions for each class from network outputs. This\nis followed by calculating inter-class similarity matrices for distillation\nusing KL divergence between distributions of each pair of classes. To further\nimprove the effectiveness of the proposed method, an Adaptive Loss Weighting\n(ALW) training strategy is proposed. Unlike existing methods, the ALW strategy\ngradually reduces the influence of the teacher network towards the end of\ntraining process to account for errors in teacher's predictions. Extensive\nexperiments conducted on two well-known datasets for semantic segmentation,\nCityscapes and Pascal VOC 2012, validate the effectiveness of the proposed\nmethod in terms of mIoU and pixel accuracy. The proposed method outperforms\nmost of existing knowledge distillation methods as demonstrated by both\nquantitative and qualitative evaluations. Code is available at:\nhttps://github.com/AmirMansurian/AICSD",
            "author": [
                "Amir M. Mansourian",
                "Rozhan Ahmadi",
                "Shohreh Kasaei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04243v1",
                "http://arxiv.org/pdf/2308.04243v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04241v2",
            "title": "AutoPCF: Efficient Product Carbon Footprint Accounting with Large\n  Language Models",
            "updated": "2023-08-11T06:09:37Z",
            "published": "2023-08-08T13:12:03Z",
            "summary": "The product carbon footprint (PCF) is crucial for decarbonizing the supply\nchain, as it measures the direct and indirect greenhouse gas emissions caused\nby all activities during the product's life cycle. However, PCF accounting\noften requires expert knowledge and significant time to construct life cycle\nmodels. In this study, we test and compare the emergent ability of five large\nlanguage models (LLMs) in modeling the 'cradle-to-gate' life cycles of products\nand generating the inventory data of inputs and outputs, revealing their\nlimitations as a generalized PCF knowledge database. By utilizing LLMs, we\npropose an automatic AI-driven PCF accounting framework, called AutoPCF, which\nalso applies deep learning algorithms to automatically match calculation\nparameters, and ultimately calculate the PCF. The results of estimating the\ncarbon footprint for three case products using the AutoPCF framework\ndemonstrate its potential in achieving automatic modeling and estimation of PCF\nwith a large reduction in modeling time from days to minutes.",
            "author": [
                "Zhu Deng",
                "Jinjie Liu",
                "Biao Luo",
                "Can Yuan",
                "Qingrun Yang",
                "Lei Xiao",
                "Wenwen Zhou",
                "Zhu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04241v2",
                "http://arxiv.org/pdf/2308.04241v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04238v1",
            "title": "Interplay of the complete-graph and Gaussian fixed-point asymptotics in\n  finite-size scaling of percolation above the upper critical dimension",
            "updated": "2023-08-08T13:09:41Z",
            "published": "2023-08-08T13:09:41Z",
            "summary": "Percolation has two mean-field theories, the Gaussian fixed point (GFP) and\nthe Landau mean-field theory or the complete graph (CG) asymptotics. By\nlarge-scale Monte Carlo simulations, we systematically study the interplay of\nthe GFP and CG effects to the finite-size scaling of percolation above the\nupper critical dimension $d_c = 6$ with periodic, free, and cylindrical\nboundary conditions. Our results suggest that, with periodic boundaries, the\n\\emph{unwrapped} correlation length scales as $L^{d/6}$ at the critical point,\ndiverging faster than $L$ above $d_c$. As a consequence, the scaling behaviours\nof macroscopic quantities with respect to the linear system size $L$ follow the\nCG asymptotics. The distance-dependent properties, such as the short-distance\nbehaviour of the two-point correlation function and the Fourier transformed\nquantities with non-zero modes, are still controlled by the GFP. With free\nboundaries, since the correlation length is cutoff by $L$, the finite-size\nscaling at the critical point is controlled by the GFP. However, some\nquantities are observed to exhibit the CG aysmptotics at the low-temperature\npseudo-critical point, such as the sizes of the two largest clusters. With\ncylindrical boundaries, due to the interplay of the GFP and CG effects, the\ncorrelation length along the axial direction of the cylinder scales as $\\xi_L\n\\sim L^{(d-1)/5}$ within the critical window of size $O(L^{-2(d-1)/5})$,\ndistinct from both periodic and free boundaries. A field-theoretical\ncalculation for deriving the scaling of $\\xi_L$ is also presented. Moreover,\nthe one-point surface correlation function along the axial direction of the\ncylinder is observed to scale as ${\\tau}^{(1-d)/2}$ for short distance but then\nenter a plateau of order $L^{-3(d-1)/5}$ before it decays significantly fast.",
            "author": [
                "Mingzhong Lu",
                "Sheng Fang",
                "Zongzheng Zhou",
                "Youjin Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04238v1",
                "http://arxiv.org/pdf/2308.04238v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04229v1",
            "title": "Stirling Decomposition of Graph Homology in Genus 1",
            "updated": "2023-08-08T12:52:18Z",
            "published": "2023-08-08T12:52:18Z",
            "summary": "We prove that commutative graph homology in genus $g=1$ with $n\\geq 3$\nmarkings has a direct sum decomposition whose summands have rank given by\nStirling numbers of the first kind. These summands are computed as the homology\nof complexes of certain decorated trees. This paper was written with a\nnon-expert audience in mind, and an emphasis is placed on an elementary\ncombinatorial description of these decorated tree complexes.",
            "author": [
                "Benjamin C. Ward"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04229v1",
                "http://arxiv.org/pdf/2308.04229v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04223v2",
            "title": "Real-Time Progressive Learning: Accumulate Knowledge from Control with\n  Neural-Network-Based Selective Memory",
            "updated": "2023-11-24T05:43:36Z",
            "published": "2023-08-08T12:39:57Z",
            "summary": "Memory, as the basis of learning, determines the storage, update and\nforgetting of knowledge and further determines the efficiency of learning.\nFeatured with the mechanism of memory, a radial basis function neural network\nbased learning control scheme named real-time progressive learning (RTPL) is\nproposed to learn the unknown dynamics of the system with guaranteed stability\nand closed-loop performance. Instead of the Lyapunov-based weight update law of\nconventional neural network learning control (NNLC), which mainly concentrates\non stability and control performance, RTPL employs the selective memory\nrecursive least squares (SMRLS) algorithm to update the weights of the neural\nnetwork and achieves the following merits: 1) improved learning speed without\nfiltering, 2) robustness to hyperparameter setting of neural networks, 3) good\ngeneralization ability, i.e., reuse of learned knowledge in different tasks,\nand 4) guaranteed learning performance under parameter perturbation. Moreover,\nRTPL realizes continuous accumulation of knowledge as a result of its\nreasonably allocated memory while NNLC may gradually forget knowledge that it\nhas learned. Corresponding theoretical analysis and simulation studies\ndemonstrate the effectiveness of RTPL.",
            "author": [
                "Yiming Fei",
                "Jiangang Li",
                "Yanan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04223v2",
                "http://arxiv.org/pdf/2308.04223v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.NE",
                "cs.SY",
                "93-10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04220v2",
            "title": "Semantic Interpretation and Validation of Graph Attention-based\n  Explanations for GNN Models",
            "updated": "2023-10-20T20:13:51Z",
            "published": "2023-08-08T12:34:32Z",
            "summary": "In this work, we propose a methodology for investigating the use of semantic\nattention to enhance the explainability of Graph Neural Network (GNN)-based\nmodels. Graph Deep Learning (GDL) has emerged as a promising field for tasks\nlike scene interpretation, leveraging flexible graph structures to concisely\ndescribe complex features and relationships. As traditional explainability\nmethods used in eXplainable AI (XAI) cannot be directly applied to such\nstructures, graph-specific approaches are introduced. Attention has been\npreviously employed to estimate the importance of input features in GDL,\nhowever, the fidelity of this method in generating accurate and consistent\nexplanations has been questioned. To evaluate the validity of using attention\nweights as feature importance indicators, we introduce semantically-informed\nperturbations and correlate predicted attention weights with the accuracy of\nthe model. Our work extends existing attention-based graph explainability\nmethods by analysing the divergence in the attention distributions in relation\nto semantically sorted feature sets and the behaviour of a GNN model,\nefficiently estimating feature importance. We apply our methodology on a lidar\npointcloud estimation model successfully identifying key semantic classes that\ncontribute to enhanced performance, effectively generating reliable post-hoc\nsemantic explanations.",
            "author": [
                "Efimia Panagiotaki",
                "Daniele De Martini",
                "Lars Kunze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04220v2",
                "http://arxiv.org/pdf/2308.04220v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "cs.RO",
                "G.3; I.2.10; I.2.9; I.4.8; I.5.2; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04187v1",
            "title": "Adding Why to What? Analyses of an Everyday Explanation",
            "updated": "2023-08-08T11:17:22Z",
            "published": "2023-08-08T11:17:22Z",
            "summary": "In XAI it is important to consider that, in contrast to explanations for\nprofessional audiences, one cannot assume common expertise when explaining for\nlaypeople. But such explanations between humans vary greatly, making it\ndifficult to research commonalities across explanations. We used the dual\nnature theory, a techno-philosophical approach, to cope with these challenges.\nAccording to it, one can explain, for example, an XAI's decision by addressing\nits dual nature: by focusing on the Architecture (e.g., the logic of its\nalgorithms) or the Relevance (e.g., the severity of a decision, the\nimplications of a recommendation). We investigated 20 game explanations using\nthe theory as an analytical framework. We elaborate how we used the theory to\nquickly structure and compare explanations of technological artifacts. We\nsupplemented results from analyzing the explanation contents with results from\na video recall to explore how explainers justified their explanation. We found\nthat explainers were focusing on the physical aspects of the game first\n(Architecture) and only later on aspects of the Relevance. Reasoning in the\nvideo recalls indicated that EX regarded the focus on the Architecture as\nimportant for structuring the explanation initially by explaining the basic\ncomponents before focusing on more complex, intangible aspects. Shifting\nbetween addressing the two sides was justified by explanation goals, emerging\nmisunderstandings, and the knowledge needs of the explainee. We discovered\nseveral commonalities that inspire future research questions which, if further\ngeneralizable, provide first ideas for the construction of synthetic\nexplanations.",
            "author": [
                "Lutz Terfloth",
                "Michael Schaffer",
                "Heike M. Buhl",
                "Carsten Schulte"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-44070-0_13",
                "http://arxiv.org/abs/2308.04187v1",
                "http://arxiv.org/pdf/2308.04187v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04186v1",
            "title": "The Emergence of Preprints: Comparing Publishing Behaviour in the Global\n  South and the Global North",
            "updated": "2023-08-08T11:13:58Z",
            "published": "2023-08-08T11:13:58Z",
            "summary": "Purpose: The recent proliferation of preprints could be a way for researchers\nworldwide to increase the availability and visibility of their research\nfindings. Against the background of rising publication costs caused by the\nincreasing prevalence of article processing fees, the search for other ways to\npublish research results besides traditional journal publication may increase.\nThis could be especially true for lower-income countries.\nDesign/methodology/approach: Therefore, we are interested in the experiences\nand attitudes towards posting and using preprints in the Global South as\nopposed to the Global North. To explore whether motivations and concerns about\nposting preprints differ, we adopted a mixed-methods approach, combining a\nquantitative survey of researchers with focus group interviews. Findings: We\nfound that respondents from the Global South were more likely to agree to\nadhere to policies and to emphasise that mandates could change publishing\nbehaviour towards open access. They were also more likely to agree posting\npreprints has a positive impact. Respondents from the Global South and the\nGlobal North emphasised the importance of peer-reviewed research for career\nadvancement. Originality: The study has identified a wide range of experiences\nwith and attitudes towards posting preprints among researchers in the Global\nSouth and the Global North. To our knowledge, this has hardly been studied\nbefore, which is also because preprints only have emerged lately in many\ndisciplines and countries.",
            "author": [
                "Kristin Biesenbender",
                "Nina Smirnova",
                "Philipp Mayr",
                "Isabella Peters"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04186v1",
                "http://arxiv.org/pdf/2308.04186v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04180v1",
            "title": "Studying Socially Unacceptable Discourse Classification (SUD) through\n  different eyes: \"Are we on the same page ?\"",
            "updated": "2023-08-08T10:42:33Z",
            "published": "2023-08-08T10:42:33Z",
            "summary": "We study Socially Unacceptable Discourse (SUD) characterization and detection\nin online text. We first build and present a novel corpus that contains a large\nvariety of manually annotated texts from different online sources used so far\nin state-of-the-art Machine learning (ML) SUD detection solutions. This global\ncontext allows us to test the generalization ability of SUD classifiers that\nacquire knowledge around the same SUD categories, but from different contexts.\nFrom this perspective, we can analyze how (possibly) different annotation\nmodalities influence SUD learning by discussing open challenges and open\nresearch directions. We also provide several data insights which can support\ndomain experts in the annotation task.",
            "author": [
                "Bruno Machado Carneiro",
                "Michele Linardi",
                "Julien Longhi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04180v1",
                "http://arxiv.org/pdf/2308.04180v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04176v1",
            "title": "On Monotonic Aggregation for Open-domain QA",
            "updated": "2023-08-08T10:23:04Z",
            "published": "2023-08-08T10:23:04Z",
            "summary": "Question answering (QA) is a critical task for speech-based retrieval from\nknowledge sources, by sifting only the answers without requiring to read\nsupporting documents. Specifically, open-domain QA aims to answer user\nquestions on unrestricted knowledge sources. Ideally, adding a source should\nnot decrease the accuracy, but we find this property (denoted as\n\"monotonicity\") does not hold for current state-of-the-art methods. We identify\nthe cause, and based on that we propose Judge-Specialist framework. Our\nframework consists of (1) specialist retrievers/readers to cover individual\nsources, and (2) judge, a dedicated language model to select the final answer.\nOur experiments show that our framework not only ensures monotonicity, but also\noutperforms state-of-the-art multi-source QA methods on Natural Questions.\nAdditionally, we show that our models robustly preserve the monotonicity\nagainst noise from speech recognition. We publicly release our code and\nsetting.",
            "author": [
                "Sang-eun Han",
                "Yeonseok Jeong",
                "Seung-won Hwang",
                "Kyungjae Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04176v1",
                "http://arxiv.org/pdf/2308.04176v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04174v1",
            "title": "The parametrix construction of the heat kernel on a graph",
            "updated": "2023-08-08T10:13:23Z",
            "published": "2023-08-08T10:13:23Z",
            "summary": "In this paper we develop the parametrix approach for constructing the heat\nkernel on a graph $G$. In particular, we highlight two specific cases. First,\nwe consider the case when $G$ is embedded in a Eulidean domain or manifold\n$\\Omega$, and we use a heat kernel associated to $\\Omega$ to obtain a formula\nfor the heat kernel on $G$. Second, we consider when $G$ is a subgraph of a\nlarger graph $\\widetilde{G}$, and we obtain a formula for the heat kernel on\n$G$ from the heat kernel on $\\widetilde{G}$ restricted to $G$.",
            "author": [
                "Gautam Chinta",
                "Jay Jorgenson",
                "Anders Karlsson",
                "Lejla Smajlovi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04174v1",
                "http://arxiv.org/pdf/2308.04174v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math.CO",
                "Primary: 35K08, 05C50, Secondary:35K05, 39A12, 33C10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04172v2",
            "title": "Predicting Drug-Drug Interactions Using Knowledge Graphs",
            "updated": "2023-08-11T07:54:24Z",
            "published": "2023-08-08T10:07:22Z",
            "summary": "In the last decades, people have been consuming and combining more drugs than\nbefore, increasing the number of Drug-Drug Interactions (DDIs). To predict\nunknown DDIs, recently, studies started incorporating Knowledge Graphs (KGs)\nsince they are able to capture the relationships among entities providing\nbetter drug representations than using a single drug property. In this paper,\nwe propose the medicX end-to-end framework that integrates several drug\nfeatures from public drug repositories into a KG and embeds the nodes in the\ngraph using various translation, factorisation and Neural Network (NN) based KG\nEmbedding (KGE) methods. Ultimately, we use a Machine Learning (ML) algorithm\nthat predicts unknown DDIs. Among the different translation and\nfactorisation-based KGE models, we found that the best performing combination\nwas the ComplEx embedding method with a Long Short-Term Memory (LSTM) network,\nwhich obtained an F1-score of 95.19% on a dataset based on the DDIs found in\nDrugBank version 5.1.8. This score is 5.61% better than the state-of-the-art\nmodel DeepDDI. Additionally, we also developed a graph auto-encoder model that\nuses a Graph Neural Network (GNN), which achieved an F1-score of 91.94%.\nConsequently, GNNs have demonstrated a stronger ability to mine the underlying\nsemantics of the KG than the ComplEx model, and thus using higher dimension\nembeddings within the GNN can lead to state-of-the-art performance.",
            "author": [
                "Lizzy Farrugia",
                "Lilian M. Azzopardi",
                "Jeremy Debattista",
                "Charlie Abela"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04172v2",
                "http://arxiv.org/pdf/2308.04172v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04170v3",
            "title": "DroidDissector: A Static and Dynamic Analysis Tool for Android Malware\n  Detection",
            "updated": "2023-11-30T19:28:38Z",
            "published": "2023-08-08T09:59:56Z",
            "summary": "DroidDissector is an extraction tool for both static and dynamic features.\nThe aim is to provide Android malware researchers and analysts with an\nintegrated tool that can extract all of the most widely used features in\nAndroid malware detection from one location. The static analysis module\nextracts features from both the manifest file and the source code of the\napplication to obtain a broad array of features that include permissions, API\ncall graphs and opcodes. The dynamic analysis module runs on the latest version\nof Android and analyses the complete behaviour of an application by tracking\nthe system calls used, network traffic generated, API calls used and log files\nproduced by the application.",
            "author": [
                "Ali Muzaffar",
                "Hani Ragab Hassen",
                "Hind Zantout",
                "Michael A Lones"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-40598-3_1",
                "http://arxiv.org/abs/2308.04170v3",
                "http://arxiv.org/pdf/2308.04170v3"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04162v1",
            "title": "EPCFormer: Expression Prompt Collaboration Transformer for Universal\n  Referring Video Object Segmentation",
            "updated": "2023-08-08T09:48:00Z",
            "published": "2023-08-08T09:48:00Z",
            "summary": "Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object\nSegmentation (R-VOS) are two highly-related tasks, which both aim to segment\nspecific objects from video sequences according to user-provided expression\nprompts. However, due to the challenges in modeling representations for\ndifferent modalities, contemporary methods struggle to strike a balance between\ninteraction flexibility and high-precision localization and segmentation. In\nthis paper, we address this problem from two perspectives: the alignment\nrepresentation of audio and text and the deep interaction among audio, text,\nand visual features. First, we propose a universal architecture, the Expression\nPrompt Collaboration Transformer, herein EPCFormer. Next, we propose an\nExpression Alignment (EA) mechanism for audio and text expressions. By\nintroducing contrastive learning for audio and text expressions, the proposed\nEPCFormer realizes comprehension of the semantic equivalence between audio and\ntext expressions denoting the same objects. Then, to facilitate deep\ninteractions among audio, text, and video features, we introduce an\nExpression-Visual Attention (EVA) mechanism. The knowledge of video object\nsegmentation in terms of the expression prompts can seamlessly transfer between\nthe two tasks by deeply exploring complementary cues between text and audio.\nExperiments on well-recognized benchmarks demonstrate that our universal\nEPCFormer attains state-of-the-art results on both tasks. The source code of\nEPCFormer will be made publicly available at\nhttps://github.com/lab206/EPCFormer.",
            "author": [
                "Jiajun Chen",
                "Jiacheng Lin",
                "Zhiqiang Xiao",
                "Haolong Fu",
                "Ke Nai",
                "Kailun Yang",
                "Zhiyong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04162v1",
                "http://arxiv.org/pdf/2308.04162v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.AS",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04161v1",
            "title": "Current and Future Challenges in Knowledge Representation and Reasoning",
            "updated": "2023-08-08T09:47:44Z",
            "published": "2023-08-08T09:47:44Z",
            "summary": "Knowledge Representation and Reasoning is a central, longstanding, and active\narea of Artificial Intelligence. Over the years it has evolved significantly;\nmore recently it has been challenged and complemented by research in areas such\nas machine learning and reasoning under uncertainty. In July 2022 a Dagstuhl\nPerspectives workshop was held on Knowledge Representation and Reasoning. The\ngoal of the workshop was to describe the state of the art in the field,\nincluding its relation with other areas, its shortcomings and strengths,\ntogether with recommendations for future progress. We developed this manifesto\nbased on the presentations, panels, working groups, and discussions that took\nplace at the Dagstuhl Workshop. It is a declaration of our views on Knowledge\nRepresentation: its origins, goals, milestones, and current foci; its relation\nto other disciplines, especially to Artificial Intelligence; and on its\nchallenges, along with key priorities for the next decade.",
            "author": [
                "James P. Delgrande",
                "Birte Glimm",
                "Thomas Meyer",
                "Miroslaw Truszczynski",
                "Frank Wolter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04161v1",
                "http://arxiv.org/pdf/2308.04161v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04155v1",
            "title": "A short note on the order of the double reduced 2-factor transfer\n  digraph for rectangular grid graphs",
            "updated": "2023-08-08T09:36:50Z",
            "published": "2023-08-08T09:36:50Z",
            "summary": "We prove that the order of the double reduced 2-factor transfer digraph\n${\\cal R}^{**}_{m}$ which is needed for the enumeration of the spanning unions\nof cycles in the rectangular grid graph $P_m \\times P_n$ ($m,n \\in N$), when\n$m$ is odd, is equal to $\\displaystyle \\mid V({\\cal R}^{**}_{m}) \\mid =\n\\frac{1}{2} \\left[{m+1 \\choose (m-1)/2 } + {(m+1)/2 \\choose \\lfloor (m+1)/4\n\\rfloor}\\right].$",
            "author": [
                "Jelena \u0110okic"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04155v1",
                "http://arxiv.org/pdf/2308.04155v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04142v1",
            "title": "Class-level Structural Relation Modelling and Smoothing for Visual\n  Representation Learning",
            "updated": "2023-08-08T09:03:46Z",
            "published": "2023-08-08T09:03:46Z",
            "summary": "Representation learning for images has been advanced by recent progress in\nmore complex neural models such as the Vision Transformers and new learning\ntheories such as the structural causal models. However, these models mainly\nrely on the classification loss to implicitly regularize the class-level data\ndistributions, and they may face difficulties when handling classes with\ndiverse visual patterns. We argue that the incorporation of the structural\ninformation between data samples may improve this situation. To achieve this\ngoal, this paper presents a framework termed \\textbf{C}lass-level Structural\nRelation Modeling and Smoothing for Visual Representation Learning (CSRMS),\nwhich includes the Class-level Relation Modelling, Class-aware Graph Sampling,\nand Relational Graph-Guided Representation Learning modules to model a\nrelational graph of the entire dataset and perform class-aware smoothing and\nregularization operations to alleviate the issue of intra-class visual\ndiversity and inter-class similarity. Specifically, the Class-level Relation\nModelling module uses a clustering algorithm to learn the data distributions in\nthe feature space and identify three types of class-level sample relations for\nthe training set; Class-aware Graph Sampling module extends typical training\nbatch construction process with three strategies to sample dataset-level\nsub-graphs; and Relational Graph-Guided Representation Learning module employs\na graph convolution network with knowledge-guided smoothing operations to ease\nthe projection from different visual patterns to the same class. Experiments\ndemonstrate the effectiveness of structured knowledge modelling for enhanced\nrepresentation learning and show that CSRMS can be incorporated with any\nstate-of-the-art visual representation learning models for performance gains.\nThe source codes and demos have been released at\nhttps://github.com/czt117/CSRMS.",
            "author": [
                "Zitan Chen",
                "Zhuang Qi",
                "Xiao Cao",
                "Xiangxian Li",
                "Xiangxu Meng",
                "Lei Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04142v1",
                "http://arxiv.org/pdf/2308.04142v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04127v1",
            "title": "Flexible Distributed Flocking Control for Multi-agent Unicycle Systems",
            "updated": "2023-08-08T08:32:11Z",
            "published": "2023-08-08T08:32:11Z",
            "summary": "Currently, the general aim of flocking and formation control laws for\nmulti-agent systems is to form and maintain a rigid configuration, such as, the\nalpha-lattices in flocking control methods, where the desired distance between\neach pair of connected agents is fixed. This introduces a scalability issue for\nlarge-scale deployment of agents due to unrealizable geometrical constraints\nand the constant need of centralized orchestrator to ensure the formation graph\nrigidity. This paper presents a flexible distributed flocking cohesion\nalgorithm for nonholonomic multi-agent systems. The desired geometry\nconfiguration between each pair of agents is adaptive and flexible. The\ndistributed flocking goal is achieved using limited information exchange (i.e.,\nthe local field gradient) between connected neighbor agents and it does not\nrely on any other motion variables measurements, such as (relative) position,\nvelocity, or acceleration. Additionally, the flexible flocking scheme with\nsafety is considered so that the agents with limited sensing capability are\nable to maintain the connectedness of communication topology at all time and\navoid inter-agent collisions. The stability analysis of the proposed methods is\npresented along with numerical simulation results to show their effectiveness.",
            "author": [
                "Tinghua Li",
                "Bayu Jayawardhana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04127v1",
                "http://arxiv.org/pdf/2308.04127v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04116v1",
            "title": "Phase diagram of muonium hydride: when dimensionality matters",
            "updated": "2023-08-08T08:10:09Z",
            "published": "2023-08-08T08:10:09Z",
            "summary": "We carry out a theoretical investigation of the low-temperature phase diagram\nof muonium hydride in two dimensions, using numerical simulations. It is shown\nthat the phase diagram of this substance is qualitatively different in two and\nthree dimensions. Specifically, while in three dimensions it has been shown to\nbe essentially identical to that of parahydrogen, i.e., only displaying a\nsingle (crystalline) phase, in two dimensions it is very similar to that of\nHe-4, with an equilibrium liquid phase that turns superfluid at a temperature\nas high as ~ 2.2 K, and that crystallizes under applied pressure. To our\nknowledge, this is the first well-described case of a condensed matter system\nwhose phase diagram is drastically altered by dimensional reduction.",
            "author": [
                "Jieru Hu",
                "Massimo Boninsegni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04116v1",
                "http://arxiv.org/pdf/2308.04116v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04468v1",
            "title": "3D Scene Diffusion Guidance using Scene Graphs",
            "updated": "2023-08-08T06:16:37Z",
            "published": "2023-08-08T06:16:37Z",
            "summary": "Guided synthesis of high-quality 3D scenes is a challenging task. Diffusion\nmodels have shown promise in generating diverse data, including 3D scenes.\nHowever, current methods rely directly on text embeddings for controlling the\ngeneration, limiting the incorporation of complex spatial relationships between\nobjects. We propose a novel approach for 3D scene diffusion guidance using\nscene graphs. To leverage the relative spatial information the scene graphs\nprovide, we make use of relational graph convolutional blocks within our\ndenoising network. We show that our approach significantly improves the\nalignment between scene description and generated scene.",
            "author": [
                "Mohammad Naanaa",
                "Katharina Schmid",
                "Yinyu Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04468v1",
                "http://arxiv.org/pdf/2308.04468v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04073v1",
            "title": "Learning Specialized Activation Functions for Physics-informed Neural\n  Networks",
            "updated": "2023-08-08T06:11:52Z",
            "published": "2023-08-08T06:11:52Z",
            "summary": "Physics-informed neural networks (PINNs) are known to suffer from\noptimization difficulty. In this work, we reveal the connection between the\noptimization difficulty of PINNs and activation functions. Specifically, we\nshow that PINNs exhibit high sensitivity to activation functions when solving\nPDEs with distinct properties. Existing works usually choose activation\nfunctions by inefficient trial-and-error. To avoid the inefficient manual\nselection and to alleviate the optimization difficulty of PINNs, we introduce\nadaptive activation functions to search for the optimal function when solving\ndifferent problems. We compare different adaptive activation functions and\ndiscuss their limitations in the context of PINNs. Furthermore, we propose to\ntailor the idea of learning combinations of candidate activation functions to\nthe PINNs optimization, which has a higher requirement for the smoothness and\ndiversity on learned functions. This is achieved by removing activation\nfunctions which cannot provide higher-order derivatives from the candidate set\nand incorporating elementary functions with different properties according to\nour prior knowledge about the PDE at hand. We further enhance the search space\nwith adaptive slopes. The proposed adaptive activation function can be used to\nsolve different PDE systems in an interpretable way. Its effectiveness is\ndemonstrated on a series of benchmarks. Code is available at\nhttps://github.com/LeapLabTHU/AdaAFforPINNs.",
            "author": [
                "Honghui Wang",
                "Lu Lu",
                "Shiji Song",
                "Gao Huang"
            ],
            "link": [
                "http://dx.doi.org/10.4208/cicp.OA-2023-0058",
                "http://arxiv.org/abs/2308.04073v1",
                "http://arxiv.org/pdf/2308.04073v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "cs.NE",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04070v1",
            "title": "ConDistFL: Conditional Distillation for Federated Learning from\n  Partially Annotated Data",
            "updated": "2023-08-08T06:07:49Z",
            "published": "2023-08-08T06:07:49Z",
            "summary": "Developing a generalized segmentation model capable of simultaneously\ndelineating multiple organs and diseases is highly desirable. Federated\nlearning (FL) is a key technology enabling the collaborative development of a\nmodel without exchanging training data. However, the limited access to fully\nannotated training data poses a major challenge to training generalizable\nmodels. We propose \"ConDistFL\", a framework to solve this problem by combining\nFL with knowledge distillation. Local models can extract the knowledge of\nunlabeled organs and tumors from partially annotated data from the global model\nwith an adequately designed conditional probability representation. We validate\nour framework on four distinct partially annotated abdominal CT datasets from\nthe MSD and KiTS19 challenges. The experimental results show that the proposed\nframework significantly outperforms FedAvg and FedOpt baselines. Moreover, the\nperformance on an external test dataset demonstrates superior generalizability\ncompared to models trained on each dataset separately. Our ablation study\nsuggests that ConDistFL can perform well without frequent aggregation, reducing\nthe communication cost of FL. Our implementation will be available at\nhttps://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl.",
            "author": [
                "Pochuan Wang",
                "Chen Shen",
                "Weichung Wang",
                "Masahiro Oda",
                "Chiou-Shann Fuh",
                "Kensaku Mori",
                "Holger R. Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04070v1",
                "http://arxiv.org/pdf/2308.04070v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04061v1",
            "title": "Enhancing Adversarial Robustness in Low-Label Regime via Adaptively\n  Weighted Regularization and Knowledge Distillation",
            "updated": "2023-08-08T05:48:38Z",
            "published": "2023-08-08T05:48:38Z",
            "summary": "Adversarial robustness is a research area that has recently received a lot of\nattention in the quest for trustworthy artificial intelligence. However, recent\nworks on adversarial robustness have focused on supervised learning where it is\nassumed that labeled data is plentiful. In this paper, we investigate\nsemi-supervised adversarial training where labeled data is scarce. We derive\ntwo upper bounds for the robust risk and propose a regularization term for\nunlabeled data motivated by these two upper bounds. Then, we develop a\nsemi-supervised adversarial training algorithm that combines the proposed\nregularization term with knowledge distillation using a semi-supervised teacher\n(i.e., a teacher model trained using a semi-supervised learning algorithm). Our\nexperiments show that our proposed algorithm achieves state-of-the-art\nperformance with significant margins compared to existing algorithms. In\nparticular, compared to supervised learning algorithms, performance of our\nproposed algorithm is not much worse even when the amount of labeled data is\nvery small. For example, our algorithm with only 8\\% labeled data is comparable\nto supervised adversarial training algorithms that use all labeled data, both\nin terms of standard and robust accuracies on CIFAR-10.",
            "author": [
                "Dongyoon Yang",
                "Insung Kong",
                "Yongdai Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04061v1",
                "http://arxiv.org/pdf/2308.04061v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04048v1",
            "title": "Characterization of rings with genus two prime ideal sum graphs",
            "updated": "2023-08-08T04:53:59Z",
            "published": "2023-08-08T04:53:59Z",
            "summary": "Let $R$ be a commutative ring with unity. The prime ideal sum graph of the\nring $R$ is a simple undirected graph whose vertex set is the set of nonzero\nproper ideals of $R$ and two distinct vertices $I$ and $J$ are adjacent if and\nonly if $I + J$ is a prime ideal of $R$. In this paper, we characterize all the\nfinite non-local commutative rings whose prime ideal sum graph is of genus $2$.",
            "author": [
                "Praveen Mathil",
                "Jitender Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04048v1",
                "http://arxiv.org/pdf/2308.04048v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AC",
                "05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04016v1",
            "title": "Hierarchical Visual Primitive Experts for Compositional Zero-Shot\n  Learning",
            "updated": "2023-08-08T03:24:21Z",
            "published": "2023-08-08T03:24:21Z",
            "summary": "Compositional zero-shot learning (CZSL) aims to recognize unseen compositions\nwith prior knowledge of known primitives (attribute and object). Previous works\nfor CZSL often suffer from grasping the contextuality between attribute and\nobject, as well as the discriminability of visual features, and the long-tailed\ndistribution of real-world compositional data. We propose a simple and scalable\nframework called Composition Transformer (CoT) to address these issues. CoT\nemploys object and attribute experts in distinctive manners to generate\nrepresentative embeddings, using the visual network hierarchically. The object\nexpert extracts representative object embeddings from the final layer in a\nbottom-up manner, while the attribute expert makes attribute embeddings in a\ntop-down manner with a proposed object-guided attention module that models\ncontextuality explicitly. To remedy biased prediction caused by imbalanced data\ndistribution, we develop a simple minority attribute augmentation (MAA) that\nsynthesizes virtual samples by mixing two images and oversampling minority\nattribute classes. Our method achieves SoTA performance on several benchmarks,\nincluding MIT-States, C-GQA, and VAW-CZSL. We also demonstrate the\neffectiveness of CoT in improving visual discrimination and addressing the\nmodel bias from the imbalanced data distribution. The code is available at\nhttps://github.com/HanjaeKim98/CoT.",
            "author": [
                "Hanjae Kim",
                "Jiyoung Lee",
                "Seongheon Park",
                "Kwanghoon Sohn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04016v1",
                "http://arxiv.org/pdf/2308.04016v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04464v3",
            "title": "Analysis of Insect-Plant Interactions Affected by Mining Operations, A\n  Graph Mining Approach",
            "updated": "2023-10-08T12:33:38Z",
            "published": "2023-08-08T02:53:16Z",
            "summary": "The decline in ecological connections signifies the potential extinction of\nspecies, which can be attributed to disruptions and alterations. The decrease\nin interconnections among species reflects their susceptibility to changes. For\nexample, certain insects and plants that rely on exclusive interactions with a\nlimited number of species, or even a specific species, face the risk of\nextinction if they lose these crucial connections. Currently, mining activities\npose significant harm to natural ecosystems, resulting in various adverse\nenvironmental impacts. In this study, we utilized network science techniques to\nanalyze the ecosystem in a graph-based structure, aiming to conserve the\necosystem affected by mining operations in the northern region of Scotland. The\nresearch encompasses identifying the most vital members of the network,\nestablishing criteria for identifying communities within the network,\ncomparing, and evaluating them, using models to predict secondary extinctions\nthat occur when a species is removed from the network, and assessing the extent\nof network damage. Our study's novelty is utilizing network science approaches\nto investigate the biological data related to interactions between insects and\nplants.",
            "author": [
                "Ali Bayat",
                "Mohammad Heydari",
                "Amir Albadvi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04464v3",
                "http://arxiv.org/pdf/2308.04464v3"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04463v1",
            "title": "Weakly Semi-Supervised Detection in Lung Ultrasound Videos",
            "updated": "2023-08-08T02:36:41Z",
            "published": "2023-08-08T02:36:41Z",
            "summary": "Frame-by-frame annotation of bounding boxes by clinical experts is often\nrequired to train fully supervised object detection models on medical video\ndata. We propose a method for improving object detection in medical videos\nthrough weak supervision from video-level labels. More concretely, we aggregate\nindividual detection predictions into video-level predictions and extend a\nteacher-student training strategy to provide additional supervision via a\nvideo-level loss. We also introduce improvements to the underlying\nteacher-student framework, including methods to improve the quality of\npseudo-labels based on weak supervision and adaptive schemes to optimize\nknowledge transfer between the student and teacher networks. We apply this\napproach to the clinically important task of detecting lung consolidations\n(seen in respiratory infections such as COVID-19 pneumonia) in medical\nultrasound videos. Experiments reveal that our framework improves detection\naccuracy and robustness compared to baseline semi-supervised models, and\nimproves efficiency in data and annotation usage.",
            "author": [
                "Jiahong Ouyang",
                "Li Chen",
                "Gary Y. Li",
                "Naveen Balaraju",
                "Shubham Patil",
                "Courosh Mehanian",
                "Sourabh Kulhare",
                "Rachel Millin",
                "Kenton W. Gregory",
                "Cynthia R. Gregory",
                "Meihua Zhu",
                "David O. Kessler",
                "Laurie Malia",
                "Almaz Dessie",
                "Joni Rabiner",
                "Di Coneybeare",
                "Bo Shopsin",
                "Andrew Hersh",
                "Cristian Madar",
                "Jeffrey Shupp",
                "Laura S. Johnson",
                "Jacob Avila",
                "Kristin Dwyer",
                "Peter Weimersheimer",
                "Balasundar Raju",
                "Jochen Kruecker",
                "Alvin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04463v1",
                "http://arxiv.org/pdf/2308.04463v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03999v2",
            "title": "Understanding CNN Hidden Neuron Activations Using Structured Background\n  Knowledge and Deductive Reasoning",
            "updated": "2023-08-09T15:59:50Z",
            "published": "2023-08-08T02:28:50Z",
            "summary": "A major challenge in Explainable AI is in correctly interpreting activations\nof hidden neurons: accurate interpretations would provide insights into the\nquestion of what a deep learning system has internally detected as relevant on\nthe input, demystifying the otherwise black-box character of deep learning\nsystems. The state of the art indicates that hidden node activations can, in\nsome cases, be interpretable in a way that makes sense to humans, but\nsystematic automated methods that would be able to hypothesize and verify\ninterpretations of hidden neuron activations are underexplored. In this paper,\nwe provide such a method and demonstrate that it provides meaningful\ninterpretations. Our approach is based on using large-scale background\nknowledge approximately 2 million classes curated from the Wikipedia concept\nhierarchy together with a symbolic reasoning approach called Concept Induction\nbased on description logics, originally developed for applications in the\nSemantic Web field. Our results show that we can automatically attach\nmeaningful labels from the background knowledge to individual neurons in the\ndense layer of a Convolutional Neural Network through a hypothesis and\nverification process.",
            "author": [
                "Abhilekha Dalal",
                "Md Kamruzzaman Sarker",
                "Adrita Barua",
                "Eugene Vasserman",
                "Pascal Hitzler"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03999v2",
                "http://arxiv.org/pdf/2308.03999v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03983v1",
            "title": "SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative\n  AI Tool",
            "updated": "2023-08-08T02:00:43Z",
            "published": "2023-08-08T02:00:43Z",
            "summary": "Large Language Model (LLM) based Generative AI systems have seen significant\nprogress in recent years. Integrating a knowledge retrieval architecture allows\nfor seamless integration of private data into publicly available Generative AI\nsystems using pre-trained LLM without requiring additional model fine-tuning.\nMoreover, Retrieval-Centric Generation (RCG) approach, a promising future\nresearch direction that explicitly separates roles of LLMs and retrievers in\ncontext interpretation and knowledge memorization, potentially leads to more\nefficient implementation. SimplyRetrieve is an open-source tool with the goal\nof providing a localized, lightweight, and user-friendly interface to these\nsophisticated advancements to the machine learning community. SimplyRetrieve\nfeatures a GUI and API based RCG platform, assisted by a Private Knowledge Base\nConstructor and a Retrieval Tuning Module. By leveraging these capabilities,\nusers can explore the potential of RCG for improving generative AI performance\nwhile maintaining privacy standards. The tool is available at\nhttps://github.com/RCGAI/SimplyRetrieve with an MIT license.",
            "author": [
                "Youyang Ng",
                "Daisuke Miyashita",
                "Yasuto Hoshi",
                "Yasuhiro Morioka",
                "Osamu Torii",
                "Tomoya Kodama",
                "Jun Deguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03983v1",
                "http://arxiv.org/pdf/2308.03983v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03980v2",
            "title": "A class of trees determined by their chromatic symmetric functions",
            "updated": "2023-08-09T01:14:06Z",
            "published": "2023-08-08T01:57:25Z",
            "summary": "Stanley introduced the concept of chromatic symmetric functions of graphs\nwhich extends and refines the notion of chromatic polynomials of graphs.\nStanley further conjectured that trees are determined up to isomorphism by\ntheir chromatic symmetric functions. In this paper, we study various\nrepresentations of chromatic symmetric functions. We verify Stanley's\nconjecture for the class of trees with exactly two vertices of degree at least\n3.",
            "author": [
                "Yuzhenni Wang",
                "Xingxing Yu",
                "Xiao-Dong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03980v2",
                "http://arxiv.org/pdf/2308.03980v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03970v2",
            "title": "Dependent Cluster Mapping (DCMAP): Optimal clustering of directed\n  acyclic graphs for statistical inference",
            "updated": "2023-11-16T23:27:21Z",
            "published": "2023-08-08T01:01:37Z",
            "summary": "A Directed Acyclic Graph (DAG) can be partitioned or mapped into clusters to\nsupport and make inference more computationally efficient in Bayesian Network\n(BN), Markov process and other models. However, optimal partitioning with an\narbitrary cost function is challenging, especially in statistical inference as\nthe local cluster cost is dependent on both nodes within a cluster, and the\nmapping of clusters connected via parent and/or child nodes, which we call\ndependent clusters. We propose a novel algorithm called DCMAP for optimal\ncluster mapping with dependent clusters. Given an arbitrarily defined, positive\ncost function based on the DAG, we show that DCMAP converges to find all\noptimal clusters, and returns near-optimal solutions along the way.\nEmpirically, we find that the algorithm is time-efficient for a Dynamic BN\n(DBN) model of a seagrass complex system using a computation cost function. For\na 25 and 50-node DBN, the search space size was $9.91\\times 10^9$ and\n$1.51\\times10^{21}$ possible cluster mappings, and the first optimal solution\nwas found at iteration 934 $(\\text{95\\% CI } 926,971)$, and 2256 $(2150,2271)$\nwith a cost that was 4\\% and 0.2\\% of the naive heuristic cost, respectively.",
            "author": [
                "Paul Pao-Yen Wu",
                "Fabrizio Rggeri",
                "Kerrie Mengersen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03970v2",
                "http://arxiv.org/pdf/2308.03970v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03967v1",
            "title": "The Widths of Strict Outerconfluent Graphs",
            "updated": "2023-08-08T00:34:22Z",
            "published": "2023-08-08T00:34:22Z",
            "summary": "Strict outerconfluent drawing is a style of graph drawing in which vertices\nare drawn on the boundary of a disk, adjacencies are indicated by the existence\nof smooth curves through a system of tracks within the disk, and no two\nadjacent vertices are connected by more than one of these smooth tracks. We\ninvestigate graph width parameters on the graphs that have drawings in this\nstyle. We prove that the clique-width of these graphs is unbounded, but their\ntwin-width is bounded.",
            "author": [
                "David Eppstein"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03967v1",
                "http://arxiv.org/pdf/2308.03967v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03961v1",
            "title": "A Benchmarking Study of Matching Algorithms for Knowledge Graph Entity\n  Alignment",
            "updated": "2023-08-08T00:03:43Z",
            "published": "2023-08-08T00:03:43Z",
            "summary": "How to identify those equivalent entities between knowledge graphs (KGs),\nwhich is called Entity Alignment (EA), is a long-standing challenge. So far,\nmany methods have been proposed, with recent focus on leveraging Deep Learning\nto solve this problem. However, we observe that most of the efforts has been\npaid to having better representation of entities, rather than improving entity\nmatching from the learned representations. In fact, how to efficiently infer\nthe entity pairs from this similarity matrix, which is essentially a matching\nproblem, has been largely ignored by the community. Motivated by this\nobservation, we conduct an in-depth analysis on existing algorithms that are\nparticularly designed for solving this matching problem, and propose a novel\nmatching method, named Bidirectional Matching (BMat). Our extensive\nexperimental results on public datasets indicate that there is currently no\nsingle silver bullet solution for EA. In other words, different classes of\nentity similarity estimation may require different matching algorithms to reach\nthe best EA results for each class. We finally conclude that using PARIS, the\nstate-of-the-art EA approach, with BMat gives the best combination in terms of\nEA performance and the algorithm's time and space complexity.",
            "author": [
                "Nhat-Minh Dao",
                "Thai V. Hoang",
                "Zonghua Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03961v1",
                "http://arxiv.org/pdf/2308.03961v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03944v2",
            "title": "GraPhSyM: Graph Physical Synthesis Model",
            "updated": "2023-09-07T15:59:20Z",
            "published": "2023-08-07T23:19:34Z",
            "summary": "In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model\nfor fast and accurate estimation of post-physical synthesis circuit delay and\narea metrics from pre-physical synthesis circuit netlists. Once trained,\nGraPhSyM provides accurate visibility of final design metrics to early EDA\nstages, such as logic synthesis, without running the slow physical synthesis\nflow, enabling global co-optimization across stages. Additionally, the swift\nand precise feedback provided by GraPhSyM is instrumental for\nmachine-learning-based EDA optimization frameworks. Given a gate-level netlist\nof a circuit represented as a graph, GraPhSyM utilizes graph structure,\nconnectivity, and electrical property features to predict the impact of\nphysical synthesis transformations such as buffer insertion and gate sizing.\nWhen trained on a dataset of 6000 prefix adder designs synthesized at an\naggressive delay target, GraPhSyM can accurately predict the post-synthesis\ndelay (98.3%) and area (96.1%) metrics of unseen adders with a fast 0.22s\ninference time. Furthermore, we illustrate the compositionality of GraPhSyM by\nemploying the model trained on a fixed delay target to accurately anticipate\npost-synthesis metrics at a variety of unseen delay targets. Lastly, we report\npromising generalization capabilities of the GraPhSyM model when it is\nevaluated on circuits different from the adders it was exclusively trained on.\nThe results show the potential for GraPhSyM to serve as a powerful tool for\nadvanced optimization techniques and as an oracle for EDA machine learning\nframeworks.",
            "author": [
                "Ahmed Agiza",
                "Rajarshi Roy",
                "Teodor Dumitru Ene",
                "Saad Godil",
                "Sherief Reda",
                "Bryan Catanzaro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03944v2",
                "http://arxiv.org/pdf/2308.03944v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03933v1",
            "title": "A Reinforcement Learning-Based Approach to Graph Discovery in\n  D2D-Enabled Federated Learning",
            "updated": "2023-08-07T22:28:15Z",
            "published": "2023-08-07T22:28:15Z",
            "summary": "Augmenting federated learning (FL) with direct device-to-device (D2D)\ncommunications can help improve convergence speed and reduce model bias through\nrapid local information exchange. However, data privacy concerns, device trust\nissues, and unreliable wireless channels each pose challenges to determining an\neffective yet resource efficient D2D structure. In this paper, we develop a\ndecentralized reinforcement learning (RL) methodology for D2D graph discovery\nthat promotes communication of non-sensitive yet impactful data-points over\ntrusted yet reliable links. Each device functions as an RL agent, training a\npolicy to predict the impact of incoming links. Local (device-level) and global\nrewards are coupled through message passing within and between device clusters.\nNumerical experiments confirm the advantages offered by our method in terms of\nconvergence speed and straggler resilience across several datasets and FL\nschemes.",
            "author": [
                "Satyavrat Wagle",
                "Anindya Bijoy Das",
                "David J. Love",
                "Christopher G. Brinton"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03933v1",
                "http://arxiv.org/pdf/2308.03933v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03929v3",
            "title": "Challenging the Machinery of Generative AI with Fact-Checking:\n  Ontology-Driven Biological Graphs for Verifying Human Disease-Gene Links",
            "updated": "2023-09-23T21:39:25Z",
            "published": "2023-08-07T22:13:30Z",
            "summary": "Background: Since the launch of various generative AI tools, scientists have\nbeen striving to evaluate their capabilities and contents, in the hope of\nestablishing trust in their generative abilities. Regulations and guidelines\nare emerging to verify generated contents and identify novel uses. Objective:\nwe aspire to demonstrate how ChatGPT claims are checked computationally using\nthe rigor of network models. We aim to achieve fact-checking of the knowledge\nembedded in biological graphs that were contrived from ChatGPT contents at the\naggregate level. Methods: We adopted a biological networks approach that\nenables the systematic interrogation of ChatGPT's linked entities. We designed\nan ontology-driven fact-checking algorithm that compares biological graphs\nconstructed from approximately 200,000 PubMed abstracts with counterparts\nconstructed from a dataset generated using the ChatGPT-3.5 Turbo model.\nResults: in 10-samples of 250 randomly selected records a ChatGPT dataset of\n1000 \"simulated\" articles, the fact-checking link accuracy ranged from 70% to\n86%. The computational process was followed by a manual process using IntAct\nInteraction database and the Gene regulatory network database (GRNdb) to\nconfirm the validity of the links identified computationally. We also found\nthat the proximity of the edges of ChatGPT graphs were significantly shorter\n(90 -- 153) while literature distances were (236 -- 765). This pattern held\ntrue in all 10-samples. Conclusion: This study demonstrated high accuracy of\naggregate disease-gene links relationships found in ChatGPT-generated texts.\nThe strikingly consistent pattern offers an illuminate new biological pathways\nthat may open the door for new research opportunities.",
            "author": [
                "Ahmed Abdeen Hamed",
                "Byung Suk Lee",
                "Alessandro Crimi",
                "Magdalena M. Misiak"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03929v3",
                "http://arxiv.org/pdf/2308.03929v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03908v1",
            "title": "ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings\n  for Video Action Recognition",
            "updated": "2023-08-07T20:50:54Z",
            "published": "2023-08-07T20:50:54Z",
            "summary": "Video Action Recognition (VAR) is a challenging task due to its inherent\ncomplexities. Though different approaches have been explored in the literature,\ndesigning a unified framework to recognize a large number of human actions is\nstill a challenging problem. Recently, Multi-Modal Learning (MML) has\ndemonstrated promising results in this domain. In literature, 2D skeleton or\npose modality has often been used for this task, either independently or in\nconjunction with the visual information (RGB modality) present in videos.\nHowever, the combination of pose, visual information, and text attributes has\nnot been explored yet, though text and pose attributes independently have been\nproven to be effective in numerous computer vision tasks. In this paper, we\npresent the first pose augmented Vision-language model (VLM) for VAR. Notably,\nour scheme achieves an accuracy of 92.81% and 73.02% on two popular human video\naction recognition benchmark datasets, UCF-101 and HMDB-51, respectively, even\nwithout any video data pre-training, and an accuracy of 96.11% and 75.75% after\nkinetics pre-training.",
            "author": [
                "Soumyabrata Chaudhuri",
                "Saumik Bhattacharya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03908v1",
                "http://arxiv.org/pdf/2308.03908v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03903v1",
            "title": "Average Estimates in Line Graphs Are Biased Toward Areas of Higher\n  Variability",
            "updated": "2023-08-07T20:35:30Z",
            "published": "2023-08-07T20:35:30Z",
            "summary": "We investigate variability overweighting, a previously undocumented bias in\nline graphs, where estimates of average value are biased toward areas of higher\nvariability in that line. We found this effect across two preregistered\nexperiments with 140 and 420 participants. These experiments also show that the\nbias is reduced when using a dot encoding of the same series. We can model the\nbias with the average of the data series and the average of the points drawn\nalong the line. This bias might arise because higher variability leads to\nstronger weighting in the average calculation, either due to the longer line\nsegments (even though those segments contain the same number of data values) or\nline segments with higher variability being otherwise more visually salient.\nUnderstanding and predicting this bias is important for visualization design\nguidelines, recommendation systems, and tool builders, as the bias can\nadversely affect estimates of averages and trends.",
            "author": [
                "Dominik Moritz",
                "Lace M. Padilla",
                "Francis Nguyen",
                "Steven L. Franconeri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03903v1",
                "http://arxiv.org/pdf/2308.03903v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03891v1",
            "title": "A Cross-Domain Evaluation of Approaches for Causal Knowledge Extraction",
            "updated": "2023-08-07T19:50:59Z",
            "published": "2023-08-07T19:50:59Z",
            "summary": "Causal knowledge extraction is the task of extracting relevant causes and\neffects from text by detecting the causal relation. Although this task is\nimportant for language understanding and knowledge discovery, recent works in\nthis domain have largely focused on binary classification of a text segment as\ncausal or non-causal. In this regard, we perform a thorough analysis of three\nsequence tagging models for causal knowledge extraction and compare it with a\nspan based approach to causality extraction. Our experiments show that\nembeddings from pre-trained language models (e.g. BERT) provide a significant\nperformance boost on this task compared to previous state-of-the-art models\nwith complex architectures. We observe that span based models perform better\nthan simple sequence tagging models based on BERT across all 4 data sets from\ndiverse domains with different types of cause-effect phrases.",
            "author": [
                "Anik Saha",
                "Oktie Hassanzadeh",
                "Alex Gittens",
                "Jian Ni",
                "Kavitha Srinivas",
                "Bulent Yener"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03891v1",
                "http://arxiv.org/pdf/2308.03891v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03890v2",
            "title": "On the Perception of Small Sub-graphs",
            "updated": "2023-08-09T21:54:18Z",
            "published": "2023-08-07T19:47:20Z",
            "summary": "Interpreting a node-link graph is enhanced if similar subgraphs (or motifs)\nare depicted in a similar manner; that is, they have the same visual form.\nSmall motifs within graphs may be perceived to be identical when they are\nstructurally dissimilar, or may be perceived to be dissimilar when they are\nidentical. This issue primarily relates to the Gestalt principle of similarity,\nbut may also include an element of quick, low-level pattern-matching. We\nbelieve that if motifs are identical, they should be depicted identically; if\nthey are nearly-identical, they should be depicted nearly-identically. This\nprinciple is particularly important in domains where motifs hold meaning and\nwhere their identification is important. We identified five small motifs:\nbi-cliques, cliques, cycles, double-cycles, and stars. For each, we defined\nvisual variations on two dimensions: same or different structure, same or\ndifferent shape. We conducted a crowd-sourced empirical study to test the\nperception of similarity of these varied motifs, and found that determining\nwhether motifs are identical or similar is affected by both shape and\nstructure.",
            "author": [
                "Jacob Miller",
                "Mohammad Ghoniem",
                "Hsiang-Yun Wu",
                "Helen C. Purchase"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03890v2",
                "http://arxiv.org/pdf/2308.03890v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03889v1",
            "title": "Borsuk and V\u00e1zsonyi problems through Reuleaux polyhedra",
            "updated": "2023-08-07T19:40:16Z",
            "published": "2023-08-07T19:40:16Z",
            "summary": "The Borsuk conjecture and the V\\'azsonyi problem are two attractive and\nfamous questions in discrete and combinatorial geometry, both based on the\nnotion of diameter of a bounded sets. In this paper, we present an equivalence\nbetween the critical sets with Borsuk number 4 in $\\mathbb{R}^3$ and the\nminimal structures for the V\\'azsonyi problem by using the well-known Reuleaux\npolyhedra. The latter lead to a full characterization of all finite sets in\n$\\mathbb{R}^3$ with Borsuk number 4.\n  The proof of such equivalence needs various ingredients, in particular, we\nproved a conjecture dealing with strongly critical configuration for the\nV\\'azsonyi problem and showed that the diameter graph arising from involutive\npolyhedra is vertex (and edge) 4-critical.",
            "author": [
                "Gyivan Lopez-Campos",
                "Deborah Oliveros",
                "Jorge L. Ram\u00edrez Alfons\u00edn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03889v1",
                "http://arxiv.org/pdf/2308.03889v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.MG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03865v1",
            "title": "DefCor-Net: Physics-Aware Ultrasound Deformation Correction",
            "updated": "2023-08-07T18:27:04Z",
            "published": "2023-08-07T18:27:04Z",
            "summary": "The recovery of morphologically accurate anatomical images from deformed ones\nis challenging in ultrasound (US) image acquisition, but crucial to accurate\nand consistent diagnosis, particularly in the emerging field of\ncomputer-assisted diagnosis. This article presents a novel anatomy-aware\ndeformation correction approach based on a coarse-to-fine, multi-scale deep\nneural network (DefCor-Net). To achieve pixel-wise performance, DefCor-Net\nincorporates biomedical knowledge by estimating pixel-wise stiffness online\nusing a U-shaped feature extractor. The deformation field is then computed\nusing polynomial regression by integrating the measured force applied by the US\nprobe. Based on real-time estimation of pixel-by-pixel tissue properties, the\nlearning-based approach enables the potential for anatomy-aware deformation\ncorrection. To demonstrate the effectiveness of the proposed DefCor-Net, images\nrecorded at multiple locations on forearms and upper arms of six volunteers are\nused to train and validate DefCor-Net. The results demonstrate that DefCor-Net\ncan significantly improve the accuracy of deformation correction to recover the\noriginal geometry (Dice Coefficient: from $14.3\\pm20.9$ to $82.6\\pm12.1$ when\nthe force is $6N$).",
            "author": [
                "Zhongliang Jiang",
                "Yue Zhou",
                "Dongliang Cao",
                "Nassir Navab"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03865v1",
                "http://arxiv.org/pdf/2308.03865v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03859v1",
            "title": "Counting two-forests and random cut size via potential theory",
            "updated": "2023-08-07T18:10:52Z",
            "published": "2023-08-07T18:10:52Z",
            "summary": "We prove a lower bound on the number of spanning two-forests in a graph, in\nterms of the number of vertices, edges, and spanning trees. This implies an\nupper bound on the average cut size of a random two-forest. The main tool is an\nidentity relating the number of spanning trees and two-forests to pairwise\neffective resistances in a graph. Along the way, we make connections to\npotential theoretic invariants on metric graphs.",
            "author": [
                "Harry Richman",
                "Farbod Shokrieh",
                "Chenxi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03859v1",
                "http://arxiv.org/pdf/2308.03859v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.DG",
                "math.PR",
                "05C30, 31C20, 82B20, 05B35, 14T15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03857v1",
            "title": "Degrees in random $m$-ary hooking networks",
            "updated": "2023-08-07T18:09:52Z",
            "published": "2023-08-07T18:09:52Z",
            "summary": "The theme in this paper is a composition of random graphs and P\\'olya urns.\nThe random graphs are generated through a small structure called the seed. Via\nP\\'olya urns, we study the asymptotic degree structure in a random $m$-ary\nhooking network and identify strong laws. We further upgrade the result to\nsecond-order asymptotics in the form of multivariate Gaussian limit laws. We\ngive a few concrete examples and explore some properties with a full\nrepresentation of the Gaussian limit in each case. The asymptotic covariance\nmatrix associated with the P\\'olya urn is obtained by a new method that\noriginated in this paper and is reported in [25].",
            "author": [
                "Kiran R. Bhutani",
                "Ravi Kalpathy",
                "Hosam Mahmoud"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03857v1",
                "http://arxiv.org/pdf/2308.03857v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "05C82, 90B15 (Primary) 60C05, 60F05 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03841v1",
            "title": "Ruling out Strongly Interacting Dark Matter-Dark Radiation Models from\n  Joint Cosmic Microwave Background-Quasar Observations",
            "updated": "2023-08-07T18:00:04Z",
            "published": "2023-08-07T18:00:04Z",
            "summary": "The cold dark matter (CDM) paradigm provides a remarkably good description of\nthe Universe's large-scale structure. However, some discrepancies exist between\nits predictions and observations at very small sub-galactic scales. To address\nthese issues, the consideration of a strong interaction between dark matter\nparticles and dark radiation emerges as an intriguing alternative. In this\nstudy, we explore the constraints on those models using joint observations of\nCosmic Microwave Background (CMB) and Quasars with our previously built\nparameter estimation package CosmoReionMC. At 2-$\\sigma$ confidence limits,\nthis analysis rules out all strongly interacting Dark Matter - Dark Radiation\nmodels proposed to date, representing the most stringent constraint on those\nmodels to the best of our knowledge. Future research using a 21-cm experiment\nholds the potential to reveal stronger constraints or uncover hidden\ninteractions within the dark sector.",
            "author": [
                "Atrideb Chatterjee",
                "Sourav Mitra",
                "Amrita Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03841v1",
                "http://arxiv.org/pdf/2308.03841v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03734v1",
            "title": "Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity\n  Resolution",
            "updated": "2023-08-07T17:32:33Z",
            "published": "2023-08-07T17:32:33Z",
            "summary": "The entity resolution problem requires finding pairs across datasets that\nbelong to different owners but refer to the same entity in the real world. To\ntrain and evaluate solutions (either rule-based or machine-learning-based) to\nthe entity resolution problem, generating a ground truth dataset with entity\npairs or clusters is needed. However, such a data annotation process involves\nhumans as domain oracles to review the plaintext data for all candidate record\npairs from different parties, which inevitably infringes the privacy of data\nowners, especially in privacy-sensitive cases like medical records. To the best\nof our knowledge, there is no prior work on privacy-preserving ground truth\ndataset generation, especially in the domain of entity resolution. We propose a\nnovel blind annotation protocol based on homomorphic encryption that allows\ndomain oracles to collaboratively label ground truths without sharing data in\nplaintext with other parties. In addition, we design a domain-specific\neasy-to-use language that hides the sophisticated underlying homomorphic\nencryption layer. Rigorous proof of the privacy guarantee is provided and our\nempirical experiments via an annotation simulator indicate the feasibility of\nour privacy-preserving protocol (f-measure on average achieves more than 90\\%\ncompared with the real ground truths).",
            "author": [
                "Yixiang Yao",
                "Weizhao Jin",
                "Srivatsan Ravi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03734v1",
                "http://arxiv.org/pdf/2308.03734v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03729v1",
            "title": "Tiny LVLM-eHub: Early Multimodal Experiments with Bard",
            "updated": "2023-08-07T17:17:05Z",
            "published": "2023-08-07T17:17:05Z",
            "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated\nsignificant progress in tackling complex multimodal tasks. Among these\ncutting-edge developments, Google's Bard stands out for its remarkable\nmultimodal capabilities, promoting comprehensive comprehension and reasoning\nacross various domains. This work presents an early and holistic evaluation of\nLVLMs' multimodal abilities, with a particular focus on Bard, by proposing a\nlightweight variant of LVLM-eHub, named Tiny LVLM-eHub. In comparison to the\nvanilla version, Tiny LVLM-eHub possesses several appealing properties.\nFirstly, it provides a systematic assessment of six categories of multimodal\ncapabilities, including visual perception, visual knowledge acquisition, visual\nreasoning, visual commonsense, object hallucination, and embodied intelligence,\nthrough quantitative evaluation of $42$ standard text-related visual\nbenchmarks. Secondly, it conducts an in-depth analysis of LVLMs' predictions\nusing the ChatGPT Ensemble Evaluation (CEE), which leads to a robust and\naccurate evaluation and exhibits improved alignment with human evaluation\ncompared to the word matching approach. Thirdly, it comprises a mere $2.1$K\nimage-text pairs, facilitating ease of use for practitioners to evaluate their\nown offline LVLMs. Through extensive experimental analysis, this study\ndemonstrates that Bard outperforms previous LVLMs in most multimodal\ncapabilities except object hallucination, to which Bard is still susceptible.\nTiny LVLM-eHub serves as a baseline evaluation for various LVLMs and encourages\ninnovative strategies aimed at advancing multimodal techniques. Our project is\npublicly available at \\url{https://github.com/OpenGVLab/Multi-Modality-Arena}.",
            "author": [
                "Wenqi Shao",
                "Yutao Hu",
                "Peng Gao",
                "Meng Lei",
                "Kaipeng Zhang",
                "Fanqing Meng",
                "Peng Xu",
                "Siyuan Huang",
                "Hongsheng Li",
                "Yu Qiao",
                "Ping Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03729v1",
                "http://arxiv.org/pdf/2308.03729v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03725v1",
            "title": "Efficient Temporal Sentence Grounding in Videos with Multi-Teacher\n  Knowledge Distillation",
            "updated": "2023-08-07T17:07:48Z",
            "published": "2023-08-07T17:07:48Z",
            "summary": "Temporal Sentence Grounding in Videos (TSGV) aims to detect the event\ntimestamps described by the natural language query from untrimmed videos. This\npaper discusses the challenge of achieving efficient computation in TSGV models\nwhile maintaining high performance. Most existing approaches exquisitely design\ncomplex architectures to improve accuracy with extra layers and loss, suffering\nfrom inefficiency and heaviness. Although some works have noticed that, they\nonly make an issue of feature fusion layers, which can hardly enjoy the\nhighspeed merit in the whole clunky network. To tackle this problem, we propose\na novel efficient multi-teacher model (EMTM) based on knowledge distillation to\ntransfer diverse knowledge from both heterogeneous and isomorphic networks.\nSpecifically, We first unify different outputs of the heterogeneous models into\none single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire\nhigh-quality integrated soft labels from multiple teachers. After that, the KAU\nmodule leverages the multi-scale video and global query information to\nadaptively determine the weights of different teachers. A Shared Encoder\nstrategy is then proposed to solve the problem that the student shallow layers\nhardly benefit from teachers, in which an isomorphic teacher is collaboratively\ntrained with the student to align their hidden states. Extensive experimental\nresults on three popular TSGV benchmarks demonstrate that our method is both\neffective and efficient without bells and whistles.",
            "author": [
                "Renjie Liang",
                "Yiming Yang",
                "Hui Lu",
                "Li Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03725v1",
                "http://arxiv.org/pdf/2308.03725v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03825v1",
            "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak\n  Prompts on Large Language Models",
            "updated": "2023-08-07T16:55:20Z",
            "published": "2023-08-07T16:55:20Z",
            "summary": "The misuse of large language models (LLMs) has garnered significant attention\nfrom the general public and LLM vendors. In response, efforts have been made to\nalign LLMs with human values and intent use. However, a particular type of\nadversarial prompts, known as jailbreak prompt, has emerged and continuously\nevolved to bypass the safeguards and elicit harmful content from LLMs. In this\npaper, we conduct the first measurement study on jailbreak prompts in the wild,\nwith 6,387 prompts collected from four platforms over six months. Leveraging\nnatural language processing technologies and graph-based community detection\nmethods, we discover unique characteristics of jailbreak prompts and their\nmajor attack strategies, such as prompt injection and privilege escalation. We\nalso observe that jailbreak prompts increasingly shift from public platforms to\nprivate ones, posing new challenges for LLM vendors in proactive detection. To\nassess the potential harm caused by jailbreak prompts, we create a question set\ncomprising 46,800 samples across 13 forbidden scenarios. Our experiments show\nthat current LLMs and safeguards cannot adequately defend jailbreak prompts in\nall scenarios. Particularly, we identify two highly effective jailbreak prompts\nwhich achieve 0.99 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and\nthey have persisted online for over 100 days. Our work sheds light on the\nsevere and evolving threat landscape of jailbreak prompts. We hope our study\ncan facilitate the research community and LLM vendors in promoting safer and\nregulated LLMs.",
            "author": [
                "Xinyue Shen",
                "Zeyuan Chen",
                "Michael Backes",
                "Yun Shen",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03825v1",
                "http://arxiv.org/pdf/2308.03825v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03719v1",
            "title": "Laplacian Eigen values of character degree graphs of solvable groups",
            "updated": "2023-08-07T16:45:21Z",
            "published": "2023-08-07T16:45:21Z",
            "summary": "Let $G$ be a finite solvable group, let $Irr(G)$ be the set of all complex\nirreducible characters of $G$ and let $cd(G)$ be the set of all degrees of\ncharacters in $Irr(G).$ Let $\\rho(G)$ be the set of primes that divide degrees\nin $cd(G).$ The character degree graph $\\Delta(G)$ of $G$ is the simple\nundirected graph with vertex set $\\rho(G)$ and in which two distinct vertices\n$p$ and $q$ are adjacent if there exists a character degree $r \\in cd(G)$ such\nthat $r$ is divisible by the product $pq.$ In this paper, we obtain Laplacian\neigen values and distance Laplacian eigen values of regular character degree\ngraph, super graphs of regular character degree graph and character degree\ngraph with diameter $2$ has two blocks.",
            "author": [
                "G. Sivanesan",
                "C. Selvaraj"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03719v1",
                "http://arxiv.org/pdf/2308.03719v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "20C15, 05C50, 05C25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03718v2",
            "title": "SEM-GAT: Explainable Semantic Pose Estimation using Learned Graph\n  Attention",
            "updated": "2023-10-22T18:46:34Z",
            "published": "2023-08-07T16:43:46Z",
            "summary": "This paper proposes a Graph Neural Network(GNN)-based method for exploiting\nsemantics and local geometry to guide the identification of reliable pointcloud\nregistration candidates. Semantic and morphological features of the environment\nserve as key reference points for registration, enabling accurate lidar-based\npose estimation. Our novel lightweight static graph structure informs our\nattention-based node aggregation network by identifying semantic-instance\nrelationships, acting as an inductive bias to significantly reduce the\ncomputational burden of pointcloud registration. By connecting candidate nodes\nand exploiting cross-graph attention, we identify confidence scores for all\npotential registration correspondences and estimate the displacement between\npointcloud scans. Our pipeline enables introspective analysis of the model's\nperformance by correlating it with the individual contributions of local\nstructures in the environment, providing valuable insights into the system's\nbehaviour. We test our method on the KITTI odometry dataset, achieving\ncompetitive accuracy compared to benchmark methods and a higher track\nsmoothness while relying on significantly fewer network parameters.",
            "author": [
                "Efimia Panagiotaki",
                "Daniele De Martini",
                "Georgi Pramatarov",
                "Matthew Gadd",
                "Lars Kunze"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03718v2",
                "http://arxiv.org/pdf/2308.03718v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "I.2.9; I.2.10; I.2.4; I.4.8; I.5.1; I.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03711v3",
            "title": "Martin boundaries and asymptotic behavior of branching random walks",
            "updated": "2023-10-26T15:14:07Z",
            "published": "2023-08-07T16:30:50Z",
            "summary": "Let $G$ be an infinite, locally finite graph. We investigate the relation\nbetween supercritical, transient branching random walk and the Martin boundary\nof its underlying random walk. We show results regarding the typical asymptotic\ndirections taken by the particles, and as a consequence we find a new\nconnection between $t$-Martin boundaries and standard Martin boundaries.\nMoreover, given a subgraph $U$ we study two aspects of branching random walks\non $U$: when the trajectories visit $U$ infinitely often (survival) and when\nthey stay inside $U$ forever (persistence). We show that there are cases, when\n$U$ is not connected, where the branching random walk does not survive in $U$,\nbut the random walk on $G$ converges to the boundary of $U$ with positive\nprobability. In contrast, the branching random walk can survive in $U$ even\nthough the random walk eventually exits $U$ almost surely. We provide several\nexamples and counterexamples.",
            "author": [
                "Daniela Bertacchi",
                "Elisabetta Candellero",
                "Fabio Zucca"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03711v3",
                "http://arxiv.org/pdf/2308.03711v3"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60J80, 60J10, 60J45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03692v1",
            "title": "Collective ion dynamics in Coulomb one-component plasmas within the\n  self-consistent relaxation theory",
            "updated": "2023-08-07T16:10:55Z",
            "published": "2023-08-07T16:10:55Z",
            "summary": "In this paper, we present the theoretical formalism describing the collective\nion dynamics of the nonideal Coulomb classical one-component plasmas on the\nbasis of the self-consistent relaxation theory. The theory is adapted to\naccount for correlations between the frequency relaxation parameters that\ncharacterize the three- and four-particle dynamics and the parameters\nassociated with the two-particle dynamics. The dynamic structure factor spectra\nand dispersion characteristics calculated for a wide range of wave numbers are\nin agreement with the molecular dynamics simulation data and the results\nobtained with the theory of the frequency moments. The proposed formalism\nreproduces all the features inherent to the Coulomb one-component plasmas and\nrequires only knowledge of the coupling parameter and the information about the\nstructure.",
            "author": [
                "Ilnaz I. Fairushin",
                "Anatolii V. Mokshin"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevE.108.015206",
                "http://arxiv.org/abs/2308.03692v1",
                "http://arxiv.org/pdf/2308.03692v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "physics.class-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03685v1",
            "title": "Learning Concise and Descriptive Attributes for Visual Recognition",
            "updated": "2023-08-07T16:00:22Z",
            "published": "2023-08-07T16:00:22Z",
            "summary": "Recent advances in foundation models present new opportunities for\ninterpretable visual recognition -- one can first query Large Language Models\n(LLMs) to obtain a set of attributes that describe each class, then apply\nvision-language models to classify images via these attributes. Pioneering work\nshows that querying thousands of attributes can achieve performance competitive\nwith image features. However, our further investigation on 8 datasets reveals\nthat LLM-generated attributes in a large quantity perform almost the same as\nrandom words. This surprising finding suggests that significant noise may be\npresent in these attributes. We hypothesize that there exist subsets of\nattributes that can maintain the classification performance with much smaller\nsizes, and propose a novel learning-to-search method to discover those concise\nsets of attributes. As a result, on the CUB dataset, our method achieves\nperformance close to that of massive LLM-generated attributes (e.g., 10k\nattributes for CUB), yet using only 32 attributes in total to distinguish 200\nbird species. Furthermore, our new paradigm demonstrates several additional\nbenefits: higher interpretability and interactivity for humans, and the ability\nto summarize knowledge for a recognition task.",
            "author": [
                "An Yan",
                "Yu Wang",
                "Yiwu Zhong",
                "Chengyu Dong",
                "Zexue He",
                "Yujie Lu",
                "William Wang",
                "Jingbo Shang",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03685v1",
                "http://arxiv.org/pdf/2308.03685v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03671v1",
            "title": "SemOpenAlex: The Scientific Landscape in 26 Billion RDF Triples",
            "updated": "2023-08-07T15:46:39Z",
            "published": "2023-08-07T15:46:39Z",
            "summary": "We present SemOpenAlex, an extensive RDF knowledge graph that contains over\n26 billion triples about scientific publications and their associated entities,\nsuch as authors, institutions, journals, and concepts. SemOpenAlex is licensed\nunder CC0, providing free and open access to the data. We offer the data\nthrough multiple channels, including RDF dump files, a SPARQL endpoint, and as\na data source in the Linked Open Data cloud, complete with resolvable URIs and\nlinks to other data sources. Moreover, we provide embeddings for knowledge\ngraph entities using high-performance computing. SemOpenAlex enables a broad\nrange of use-case scenarios, such as exploratory semantic search via our\nwebsite, large-scale scientific impact quantification, and other forms of\nscholarly big data analytics within and across scientific disciplines.\nAdditionally, it enables academic recommender systems, such as recommending\ncollaborators, publications, and venues, including explainability capabilities.\nFinally, SemOpenAlex can serve for RDF query optimization benchmarks, creating\nscholarly knowledge-guided language models, and as a hub for semantic\nscientific publishing.",
            "author": [
                "Michael F\u00e4rber",
                "David Lamprecht",
                "Johan Krause",
                "Linn Aung",
                "Peter Haase"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03671v1",
                "http://arxiv.org/pdf/2308.03671v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03669v3",
            "title": "Diffusion Model in Causal Inference with Unmeasured Confounders",
            "updated": "2023-08-15T04:21:36Z",
            "published": "2023-08-07T15:40:34Z",
            "summary": "We study how to extend the use of the diffusion model to answer the causal\nquestion from the observational data under the existence of unmeasured\nconfounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to\ncapture the causal intervention, a Diffusion-based Causal Model (DCM) was\nproposed incorporating the diffusion model to answer the causal questions more\naccurately, assuming that all of the confounders are observed. However,\nunmeasured confounders in practice exist, which hinders DCM from being\napplicable. To alleviate this limitation of DCM, we propose an extended model\ncalled Backdoor Criterion based DCM (BDCM), whose idea is rooted in the\nBackdoor criterion to find the variables in DAG to be included in the decoding\nprocess of the diffusion model so that we can extend DCM to the case with\nunmeasured confounders. Synthetic data experiment demonstrates that our\nproposed model captures the counterfactual distribution more precisely than DCM\nunder the unmeasured confounders.",
            "author": [
                "Tatsuhiro Shimizu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03669v3",
                "http://arxiv.org/pdf/2308.03669v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03821v1",
            "title": "Distributionally Robust Classification on a Data Budget",
            "updated": "2023-08-07T15:30:02Z",
            "published": "2023-08-07T15:30:02Z",
            "summary": "Real world uses of deep learning require predictable model behavior under\ndistribution shifts. Models such as CLIP show emergent natural distributional\nrobustness comparable to humans, but may require hundreds of millions of\ntraining samples. Can we train robust learners in a domain where data is\nlimited? To rigorously address this question, we introduce JANuS (Joint\nAnnotations and Names Set), a collection of four new training datasets with\nimages, labels, and corresponding captions, and perform a series of carefully\ncontrolled investigations of factors contributing to robustness in image\nclassification, then compare those results to findings derived from a\nlarge-scale meta-analysis. Using this approach, we show that standard ResNet-50\ntrained with the cross-entropy loss on 2.4 million image samples can attain\ncomparable robustness to a CLIP ResNet-50 trained on 400 million samples. To\nour knowledge, this is the first result showing (near) state-of-the-art\ndistributional robustness on limited data budgets. Our dataset is available at\n\\url{https://huggingface.co/datasets/penfever/JANuS_dataset}, and the code used\nto reproduce our experiments can be found at\n\\url{https://github.com/penfever/vlhub/}.",
            "author": [
                "Benjamin Feuer",
                "Ameya Joshi",
                "Minh Pham",
                "Chinmay Hegde"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03821v1",
                "http://arxiv.org/pdf/2308.03821v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03819v1",
            "title": "XFlow: Benchmarking Flow Behaviors over Graphs",
            "updated": "2023-08-07T14:49:22Z",
            "published": "2023-08-07T14:49:22Z",
            "summary": "The occurrence of diffusion on a graph is a prevalent and significant\nphenomenon, as evidenced by the spread of rumors, influenza-like viruses, smart\ngrid failures, and similar events. Comprehending the behaviors of flow is a\nformidable task, due to the intricate interplay between the distribution of\nseeds that initiate flow propagation, the propagation model, and the topology\nof the graph. The study of networks encompasses a diverse range of academic\ndisciplines, including mathematics, physics, social science, and computer\nscience. This interdisciplinary nature of network research is characterized by\na high degree of specialization and compartmentalization, and the cooperation\nfacilitated by them is inadequate. From a machine learning standpoint, there is\na deficiency in a cohesive platform for assessing algorithms across various\ndomains. One of the primary obstacles to current research in this field is the\nabsence of a comprehensive curated benchmark suite to study the flow behaviors\nunder network scenarios.\n  To address this disparity, we propose the implementation of a novel benchmark\nsuite that encompasses a variety of tasks, baseline models, graph datasets, and\nevaluation tools. In addition, we present a comprehensive analytical framework\nthat offers a generalized approach to numerous flow-related tasks across\ndiverse domains, serving as a blueprint and roadmap. Drawing upon the outcomes\nof our empirical investigation, we analyze the advantages and disadvantages of\ncurrent foundational models, and we underscore potential avenues for further\nstudy. The datasets, code, and baseline models have been made available for the\npublic at: https://github.com/XGraphing/XFlow",
            "author": [
                "Zijian Zhang",
                "Zonghan Zhang",
                "Zhiqian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03819v1",
                "http://arxiv.org/pdf/2308.03819v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03642v1",
            "title": "RIP-based Performance Guarantee for Low Rank Matrix Recovery via\n  $L_{*-F}$ Minimization",
            "updated": "2023-08-07T14:47:30Z",
            "published": "2023-08-07T14:47:30Z",
            "summary": "In the undetermined linear system $\\bm{b}=\\mathcal{A}(\\bm{X})+\\bm{s}$, vector\n$\\bm{b}$ and operator $\\mathcal{A}$ are the known measurements and $\\bm{s}$ is\nthe unknown noise. In this paper, we investigate sufficient conditions for\nexactly reconstructing desired matrix $\\bm{X}$ being low-rank or approximately\nlow-rank. We use the difference of nuclear norm and Frobenius norm ($L_{*-F}$)\nas a surrogate for rank function and establish a new nonconvex relaxation of\nsuch low rank matrix recovery, called the $L_{*-F}$ minimization, in order to\napproximate the rank function closer. For such nonconvex and nonsmooth\nconstrained $L_{*-F}$ minimization problems, based on whether the noise level\nis $0$, we give the upper bound estimation of the recovery error respectively.\nParticularly, in the noise-free case, one sufficient condition for exact\nrecovery is presented. If linear operator $\\mathcal{A}$ satisfies the\nrestricted isometry property with\n$\\delta_{4r}<\\frac{\\sqrt{2r}-1}{\\sqrt{2r}-1+\\sqrt{2}(\\sqrt{2r}+1)}$, then\n$r$-\\textbf{rank} matrix $\\bm{X}$ can be exactly recovered without other\nassumptions. In addition, we also take insights into the regularized $L_{*-F}$\nminimization model since such regularized model is more widely used in\nalgorithm design. We provide the recovery error estimation of this regularized\n$L_{*-F}$ minimization model via RIP tool. To our knowledge, this is the first\nresult on exact reconstruction of low rank matrix via regularized $L_{*-F}$\nminimization.",
            "author": [
                "Yan Li",
                "Liping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03642v1",
                "http://arxiv.org/pdf/2308.03642v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03638v1",
            "title": "KITLM: Domain-Specific Knowledge InTegration into Language Models for\n  Question Answering",
            "updated": "2023-08-07T14:42:49Z",
            "published": "2023-08-07T14:42:49Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable performance in a\nwide range of natural language tasks. However, as these models continue to grow\nin size, they face significant challenges in terms of computational costs.\nAdditionally, LLMs often lack efficient domain-specific understanding, which is\nparticularly crucial in specialized fields such as aviation and healthcare. To\nboost the domain-specific understanding, we propose, KITLM, a novel knowledge\nbase integration approach into language model through relevant information\ninfusion. By integrating pertinent knowledge, not only the performance of the\nlanguage model is greatly enhanced, but the model size requirement is also\nsignificantly reduced while achieving comparable performance. Our proposed\nknowledge-infused model surpasses the performance of both GPT-3.5-turbo and the\nstate-of-the-art knowledge infusion method, SKILL, achieving over 1.5 times\nimprovement in exact match scores on the MetaQA. KITLM showed a similar\nperformance boost in the aviation domain with AeroQA. The drastic performance\nimprovement of KITLM over the existing methods can be attributed to the\ninfusion of relevant knowledge while mitigating noise. In addition, we release\ntwo curated datasets to accelerate knowledge infusion research in specialized\nfields: a) AeroQA, a new benchmark dataset designed for multi-hop\nquestion-answering within the aviation domain, and b) Aviation Corpus, a\ndataset constructed from unstructured text extracted from the National\nTransportation Safety Board reports. Our research contributes to advancing the\nfield of domain-specific language understanding and showcases the potential of\nknowledge infusion techniques in improving the performance of language models\non question-answering.",
            "author": [
                "Ankush Agarwal",
                "Sakharam Gawade",
                "Amar Prakash Azad",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03638v1",
                "http://arxiv.org/pdf/2308.03638v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03636v1",
            "title": "Comparing biased random walks in graph embedding and link prediction",
            "updated": "2023-08-07T14:41:28Z",
            "published": "2023-08-07T14:41:28Z",
            "summary": "Random walks find extensive application across various complex network\ndomains, including embedding generation and link prediction. Despite the\nwidespread utilization of random walks, the precise impact of distinct biases\non embedding generation from sequence data and their subsequent effects on link\nprediction remain elusive. In this study, we conduct a comparative analysis of\nseveral random walk strategies, each rooted in different biases: true\nself-avoidance, unbiased randomness, bias towards node degree, and inverse node\ndegree bias. Furthermore, we explore diverse adaptations of the node2vec\nalgorithm to induce distinct exploratory behaviors. Our empirical findings\ndemonstrate that despite the varied behaviors inherent in these embeddings,\nonly slight performance differences manifest in the context of link prediction.\nThis implies the resilient recovery of network structure, regardless of the\nspecific walk heuristic employed to traverse the network. Consequently, the\nresults suggest that data generated from sequences governed by unknown\nmechanisms can be successfully reconstructed.",
            "author": [
                "Adilson Vital Jr.",
                "Filipi N. Silva",
                "Diego R. Amancio"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03636v1",
                "http://arxiv.org/pdf/2308.03636v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03593v1",
            "title": "Towards a Generalized Assessment of Computational Thinking for\n  Introductory Physics Students",
            "updated": "2023-08-07T13:51:05Z",
            "published": "2023-08-07T13:51:05Z",
            "summary": "Computational thinking in physics has many different forms, definitions, and\nimplementations depending on the level of physics, or the institution it is\npresented in. In order to better integrate computational thinking in\nintroductory physics, we need to understand what physicists find important\nabout computational thinking in introductory physics. We present a qualitative\nanalysis of twenty-six interviews asking academic (N=18) and industrial (N=8)\nphysicists about the teaching and learning of computational thinking in\nintroductory physics courses. These interviews are part of a longer-term\nproject towards developing an assessment protocol for computational thinking in\nintroductory physics. We find that academic and industrial physicists value\nstudents' ability to read code and that Python (or VPython) and spreadsheets\nwere the preferred computational language or environment used. Additionally,\nthe interviewees mentioned that identifying the core physics concepts within a\nprogram, explaining code to others, and good program hygiene (i.e., commenting\nand using meaningful variable names) are important skills for introductory\nstudents to acquire. We also find that while a handful of interviewees note\nthat the experience and skills gained from computation are quite useful for\nstudent's future careers, they also describe multiple limiting factors of\nteaching computation in introductory physics, such as curricular overhaul, not\nhaving \"space\" for computation, and student rejection. The interviews show that\nwhile adding computational thinking to physics students repertoire is\nimportant, the importance really comes from using computational thinking to\nlearn and understand physics better. This informs us that the assessment we\ndevelop should only include the basics of computational thinking needed to\nassess introductory physics knowledge.",
            "author": [
                "Justin Gambrell",
                "Eric Brewe"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03593v1",
                "http://arxiv.org/pdf/2308.03593v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03588v1",
            "title": "Multi-View Graph Convolutional Network for Multimedia Recommendation",
            "updated": "2023-08-07T13:45:48Z",
            "published": "2023-08-07T13:45:48Z",
            "summary": "Multimedia recommendation has received much attention in recent years. It\nmodels user preferences based on both behavior information and item multimodal\ninformation. Though current GCN-based methods achieve notable success, they\nsuffer from two limitations: (1) Modality noise contamination to the item\nrepresentations. Existing methods often mix modality features and behavior\nfeatures in a single view (e.g., user-item view) for propagation, the noise in\nthe modality features may be amplified and coupled with behavior features. In\nthe end, it leads to poor feature discriminability; (2) Incomplete user\npreference modeling caused by equal treatment of modality features. Users often\nexhibit distinct modality preferences when purchasing different items. Equally\nfusing each modality feature ignores the relative importance among different\nmodalities, leading to the suboptimal user preference modeling. To tackle the\nabove issues, we propose a novel Multi-View Graph Convolutional Network for the\nmultimedia recommendation. Specifically, to avoid modality noise contamination,\nthe modality features are first purified with the aid of item behavior\ninformation. Then, the purified modality features of items and behavior\nfeatures are enriched in separate views, including the user-item view and the\nitem-item view. In this way, the distinguishability of features is enhanced.\nMeanwhile, a behavior-aware fuser is designed to comprehensively model user\npreferences by adaptively learning the relative importance of different\nmodality features. Furthermore, we equip the fuser with a self-supervised\nauxiliary task. This task is expected to maximize the mutual information\nbetween the fused multimodal features and behavior features, so as to capture\ncomplementary and supplementary preference information simultaneously.\nExtensive experiments on three public datasets demonstrate the effectiveness of\nour methods.",
            "author": [
                "Penghang Yu",
                "Zhiyi Tan",
                "Guanming Lu",
                "Bing-Kun Bao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3613915",
                "http://arxiv.org/abs/2308.03588v1",
                "http://arxiv.org/pdf/2308.03588v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03584v1",
            "title": "A Polystore Architecture Using Knowledge Graphs to Support Queries on\n  Heterogeneous Data Stores",
            "updated": "2023-08-07T13:42:38Z",
            "published": "2023-08-07T13:42:38Z",
            "summary": "Modern applications commonly need to manage dataset types composed of\nheterogeneous data and schemas, making it difficult to access them in an\nintegrated way. A single data store to manage heterogeneous data using a common\ndata model is not effective in such a scenario, which results in the domain\ndata being fragmented in the data stores that best fit their storage and access\nrequirements (e.g., NoSQL, relational DBMS, or HDFS). Besides, organization\nworkflows independently consume these fragments, and usually, there is no\nexplicit link among the fragments that would be useful to support an integrated\nview. The research challenge tackled by this work is to provide the means to\nquery heterogeneous data residing on distinct data repositories that are not\nexplicitly connected. We propose a federated database architecture by providing\na single abstract global conceptual schema to users, allowing them to write\ntheir queries, encapsulating data heterogeneity, location, and linkage by\nemploying: (i) meta-models to represent the global conceptual schema, the\nremote data local conceptual schemas, and mappings among them; (ii) provenance\nto create explicit links among the consumed and generated data residing in\nseparate datasets. We evaluated the architecture through its implementation as\na polystore service, following a microservice architecture approach, in a\nscenario that simulates a real case in Oil \\& Gas industry. Also, we compared\nthe proposed architecture to a relational multidatabase system based on foreign\ndata wrappers, measuring the user's cognitive load to write a query (or query\ncomplexity) and the query processing time. The results demonstrated that the\nproposed architecture allows query writing two times less complex than the one\nwritten for the relational multidatabase system, adding an excess of no more\nthan 30% in query processing time.",
            "author": [
                "Leonardo Guerreiro Azevedo",
                "Renan Francisco Santos Souza",
                "Elton F. de S. Soares",
                "Raphael M. Thiago",
                "Julio Cesar Cardoso Tesolin",
                "Ann C. Oliveira",
                "Marcio Ferreira Moreno"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03584v1",
                "http://arxiv.org/pdf/2308.03584v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03582v2",
            "title": "WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset",
            "updated": "2023-08-18T12:31:52Z",
            "published": "2023-08-07T13:38:54Z",
            "summary": "A fundamental challenge in the current NLP context, dominated by language\nmodels, comes from the inflexibility of current architectures to 'learn' new\ninformation. While model-centric solutions like continual learning or\nparameter-efficient fine tuning are available, the question still remains of\nhow to reliably identify changes in language or in the world. In this paper, we\npropose WikiTiDe, a dataset derived from pairs of timestamped definitions\nextracted from Wikipedia. We argue that such resource can be helpful for\naccelerating diachronic NLP, specifically, for training models able to scan\nknowledge resources for core updates concerning a concept, an event, or a named\nentity. Our proposed end-to-end method is fully automatic, and leverages a\nbootstrapping algorithm for gradually creating a high-quality dataset. Our\nresults suggest that bootstrapping the seed version of WikiTiDe leads to better\nfine-tuned models. We also leverage fine-tuned models in a number of downstream\ntasks, showing promising results with respect to competitive baselines.",
            "author": [
                "Hsuvas Borkakoty",
                "Luis Espinosa-Anke"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03582v2",
                "http://arxiv.org/pdf/2308.03582v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03581v1",
            "title": "Towards Controllable Natural Language Inference through Lexical\n  Inference Types",
            "updated": "2023-08-07T13:37:05Z",
            "published": "2023-08-07T13:37:05Z",
            "summary": "Explainable natural language inference aims to provide a mechanism to produce\nexplanatory (abductive) inference chains which ground claims to their\nsupporting premises. A recent corpus called EntailmentBank strives to advance\nthis task by explaining the answer to a question using an entailment tree\n\\cite{dalvi2021explaining}. They employ the T5 model to directly generate the\ntree, which can explain how the answer is inferred. However, it lacks the\nability to explain and control the generation of intermediate steps, which is\ncrucial for the multi-hop inference process. % One recent corpus,\nEntailmentBank, aims to push this task forward by explaining an answer to a\nquestion according to an entailment tree \\cite{dalvi2021explaining}. They\nemploy T5 to generate the tree directly, which can explain how the answer is\ninferred but cannot explain how the intermediate is generated, which is\nessential to the multi-hop inference process. In this work, we focus on\nproposing a controlled natural language inference architecture for\nmulti-premise explanatory inference. To improve control and enable explanatory\nanalysis over the generation, we define lexical inference types based on\nAbstract Meaning Representation (AMR) graph and modify the architecture of T5\nto learn a latent sentence representation (T5 bottleneck) conditioned on said\ntype information. We also deliver a dataset of approximately 5000 annotated\nexplanatory inference steps, with well-grounded lexical-symbolic operations.\nExperimental results indicate that the inference typing induced at the T5\nbottleneck can help T5 to generate a conclusion under explicit control.",
            "author": [
                "Yingji Zhang",
                "Danilo S. Carvalho",
                "Ian Pratt-Hartmann",
                "Andre Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03581v1",
                "http://arxiv.org/pdf/2308.03581v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03578v1",
            "title": "TeraHAC: Hierarchical Agglomerative Clustering of Trillion-Edge Graphs",
            "updated": "2023-08-07T13:35:02Z",
            "published": "2023-08-07T13:35:02Z",
            "summary": "We introduce TeraHAC, a $(1+\\epsilon)$-approximate hierarchical agglomerative\nclustering (HAC) algorithm which scales to trillion-edge graphs. Our algorithm\nis based on a new approach to computing $(1+\\epsilon)$-approximate HAC, which\nis a novel combination of the nearest-neighbor chain algorithm and the notion\nof $(1+\\epsilon)$-approximate HAC. Our approach allows us to partition the\ngraph among multiple machines and make significant progress in computing the\nclustering within each partition before any communication with other partitions\nis needed.\n  We evaluate TeraHAC on a number of real-world and synthetic graphs of up to 8\ntrillion edges. We show that TeraHAC requires over 100x fewer rounds compared\nto previously known approaches for computing HAC. It is up to 8.3x faster than\nSCC, the state-of-the-art distributed algorithm for hierarchical clustering,\nwhile achieving 1.16x higher quality. In fact, TeraHAC essentially retains the\nquality of the celebrated HAC algorithm while significantly improving the\nrunning time.",
            "author": [
                "Laxman Dhulipala",
                "Jason Lee",
                "Jakub \u0141\u0105cki",
                "Vahab Mirrokni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03578v1",
                "http://arxiv.org/pdf/2308.03578v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DB",
                "cs.DC",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03574v1",
            "title": "Generalized Early Stopping in Evolutionary Direct Policy Search",
            "updated": "2023-08-07T13:25:48Z",
            "published": "2023-08-07T13:25:48Z",
            "summary": "Lengthy evaluation times are common in many optimization problems such as\ndirect policy search tasks, especially when they involve conducting evaluations\nin the physical world, e.g. in robotics applications. Often, when evaluating a\nsolution over a fixed time period, it becomes clear that the objective value\nwill not increase with additional computation time (for example, when a\ntwo-wheeled robot continuously spins on the spot). In such cases, it makes\nsense to stop the evaluation early to save computation time. However, most\napproaches to stop the evaluation are problem-specific and need to be\nspecifically designed for the task at hand. Therefore, we propose an early\nstopping method for direct policy search. The proposed method only looks at the\nobjective value at each time step and requires no problem-specific knowledge.\n  We test the introduced stopping criterion in five direct policy search\nenvironments drawn from games, robotics, and classic control domains, and show\nthat it can save up to 75% of the computation time. We also compare it with\nproblem-specific stopping criteria and demonstrate that it performs comparably\nwhile being more generally applicable.",
            "author": [
                "Etor Arza",
                "Leni K. Le Goff",
                "Emma Hart"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03574v1",
                "http://arxiv.org/pdf/2308.03574v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NE",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03572v2",
            "title": "Provably Efficient Learning in Partially Observable Contextual Bandit",
            "updated": "2023-09-04T11:41:54Z",
            "published": "2023-08-07T13:24:50Z",
            "summary": "In this paper, we investigate transfer learning in partially observable\ncontextual bandits, where agents have limited knowledge from other agents and\npartial information about hidden confounders. We first convert the problem to\nidentifying or partially identifying causal effects between actions and rewards\nthrough optimization problems. To solve these optimization problems, we\ndiscretize the original functional constraints of unknown distributions into\nlinear constraints, and sample compatible causal models via sequentially\nsolving linear programmings to obtain causal bounds with the consideration of\nestimation error. Our sampling algorithms provide desirable convergence results\nfor suitable sampling distributions. We then show how causal bounds can be\napplied to improving classical bandit algorithms and affect the regrets with\nrespect to the size of action sets and function spaces. Notably, in the task\nwith function approximation which allows us to handle general context\ndistributions, our method improves the order dependence on function space size\ncompared with previous literatures. We formally prove that our causally\nenhanced algorithms outperform classical bandit algorithms and achieve orders\nof magnitude faster convergence rates. Finally, we perform simulations that\ndemonstrate the efficiency of our strategy compared to the current\nstate-of-the-art methods. This research has the potential to enhance the\nperformance of contextual bandit agents in real-world applications where data\nis scarce and costly to obtain.",
            "author": [
                "Xueping Gong",
                "Jiheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03572v2",
                "http://arxiv.org/pdf/2308.03572v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03567v2",
            "title": "Understanding random-walk dynamical phase coexistence through waiting\n  times",
            "updated": "2023-08-13T16:34:17Z",
            "published": "2023-08-07T13:17:54Z",
            "summary": "We study the appearance of first-order dynamical phase transitions (DPTs) as\n`intermittent' co-existing phases in the fluctuations of random walks on\ngraphs. We show that the diverging time scale leading to critical behaviour is\nthe waiting time to jump from one phase to another. This time scale is crucial\nfor observing the system's relaxation to stationarity and demonstrates\nergodicity of the system at criticality. We illustrate these results through\nthree analytical examples which provide insights into random walks exploring\nrandom graphs.",
            "author": [
                "David C. Stuhrmann",
                "Francesco Coghi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03567v2",
                "http://arxiv.org/pdf/2308.03567v2"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03563v1",
            "title": "Global cognitive graph properties dynamics of hippocampal formation",
            "updated": "2023-08-07T13:15:33Z",
            "published": "2023-08-07T13:15:33Z",
            "summary": "In the present study we have used a set of methods and metrics to build a\ngraph of relative neural connections in a hippocampus of a rodent. A set of\ngraphs was built on top of time-sequenced data and analyzed in terms of\ndynamics of a connection genesis. The analysis has shown that during the\nprocess of a rodent exploring a novel environment, the relations between\nneurons constantly change which indicates that globally memory is constantly\nupdated even for known areas of space. Even if some neurons gain cognitive\nspecialization, the global network though remains relatively stable.\nAdditionally we suggest a set of methods for building a graph of cognitive\nneural network.",
            "author": [
                "Konstantin Sorokin",
                "Andrey Zaitsew",
                "Aleksandr Levin",
                "German Magai",
                "Maxim Beketov",
                "Vladimir Sotskov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03563v1",
                "http://arxiv.org/pdf/2308.03563v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07325v1",
            "title": "MSLE: An ontology for Materials Science Laboratory Equipment.\n  Large-Scale Devices for Materials Characterization",
            "updated": "2023-08-07T12:39:42Z",
            "published": "2023-08-07T12:39:42Z",
            "summary": "This paper introduces a new ontology for Materials Science Laboratory\nEquipment, termed MSLE. A fundamental issue with materials science laboratory\n(hereafter lab) equipment in the real world is that scientists work with\nvarious types of equipment with multiple specifications. For example, there are\nmany electron microscopes with different parameters in chemical and physical\nlabs. A critical development to unify the description is to build an equipment\ndomain ontology as basic semantic knowledge and to guide the user to work with\nthe equipment appropriately. Here, we propose to develop a consistent ontology\nfor equipment, the MSLE ontology. In the MSLE, two main existing ontologies,\nthe Semantic Sensor Network (SSN) and the Material Vocabulary (MatVoc), have\nbeen integrated into the MSLE core to build a coherent ontology. Since various\nacronyms and terms have been used for equipment, this paper proposes an\napproach to use a Simple Knowledge Organization System (SKOS) to represent the\nhierarchical structure of equipment terms. Equipment terms were collected in\nvarious languages and abbreviations and coded into the MSLE using the SKOS\nmodel. The ontology development was conducted in close collaboration with\ndomain experts and focused on the large-scale devices for materials\ncharacterization available in our research group. Competency questions are\nexpected to be addressed through the MSLE ontology. Constraints are modeled in\nthe Shapes Query Language (SHACL); a prototype is shown and validated to show\nthe value of the modeling constraints.",
            "author": [
                "Mehrdad Jalali",
                "Matthias Mail",
                "Rossella Aversa",
                "Christian K\u00fcbel"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.mtcomm.2023.105532",
                "http://arxiv.org/abs/2308.07325v1",
                "http://arxiv.org/pdf/2308.07325v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03814v1",
            "title": "Sex differences in attitudes towards online privacy and anonymity among\n  Israeli students with different technical backgrounds",
            "updated": "2023-08-07T12:36:37Z",
            "published": "2023-08-07T12:36:37Z",
            "summary": "Introduction. In this exploratory study, we proposed an experimental\nframework to investigate and model male/female differences in attitudes towards\nonline privacy and anonymity among Israeli students. Our aim was to\ncomparatively model men and women's online privacy attitudes, and to assess the\nonline privacy gender gap. Method. Various factors related to the user's online\nprivacy and anonymity were considered, such as awareness of anonymous threats\nmade online, concern for protecting personal information on the Internet,\nonline privacy self-efficacy, online privacy literacy and users' tendency to\nengage in privacy paradox behaviour, i.e., personal data disclosure despite the\nawareness of anonymity and privacy threats. Analysis. A user study was carried\nout among 169 Israeli academic students through a quantitative method using\nclosed-ended questionnaires. The subjects' responses were analysed using\nstandard statistical measures. We then proposed a summarized comparative model\nfor the two sexes' online privacy behaviour. Results. We found that a digital\ngap still exists between men and women regarding technological knowledge and\nskills used to protect their identity and personal information on the Web.\nInterestingly, users' tendency to engage in privacy paradox behaviour was not\nhigher among men despite their higher level of technological online privacy\nliteracy compared to women. Conclusions. Women's relatively high online privacy\nself-efficacy level and their low awareness of technological threat do not\nmatch their relatively low technological online privacy literacy level. This\nleads to a lower ability to protect their identity and personal information as\ncompared to men. We conclude that further steps should be taken to eliminate\nthe inter-gender technological gap in online privacy and anonymity awareness\nand literacy.",
            "author": [
                "Maor Weinberger",
                "Maayan Zhitomirsky-Geffet",
                "Dan Bouhnik"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03814v1",
                "http://arxiv.org/pdf/2308.03814v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03532v1",
            "title": "Quantum algorithm for de novo DNA sequence assembly based on quantum\n  walks on graphs",
            "updated": "2023-08-07T12:30:25Z",
            "published": "2023-08-07T12:30:25Z",
            "summary": "De novo DNA sequence assembly is based on finding paths in overlap graphs,\nwhich is a NP-hard problem. We developed a quantum algorithm for de novo\nassembly based on quantum walks in graphs. The overlap graph is partitioned\nrepeatedly to smaller graphs that form a hierarchical structure. We use quantum\nwalks to find paths in low rank graphs and a quantum algorithm that finds\nHamiltonian paths in high hierarchical rank. We tested the partitioning quantum\nalgorithm, as well as the quantum algorithm that finds Hamiltonian paths in\nhigh hierarchical rank and confirmed its correct operation using Qiskit. We\ndeveloped a custom simulation for quantum walks to search for paths in low rank\ngraphs. The approach described in this paper may serve as a basis for the\ndevelopment of efficient quantum algorithms that solve the de novo DNA assembly\nproblem.",
            "author": [
                "G. D. Varsamis",
                "I. G. Karafyllidis",
                "K. M. Gilkes",
                "U. Arranz",
                "R. Martin-Cuevas",
                "G. Calleja",
                "J. Wong",
                "H. C. Jessen",
                "P. Dimitrakis",
                "P. Kolovos",
                "R. Sandaltzopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03532v1",
                "http://arxiv.org/pdf/2308.03532v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03528v1",
            "title": "A note on monotonicity in Maker-Breaker graph colouring games",
            "updated": "2023-08-07T12:24:59Z",
            "published": "2023-08-07T12:24:59Z",
            "summary": "In the Maker-Breaker vertex colouring game, first publicised by Gardner in\n1981, Maker and Breaker alternately colour vertices of a graph using a fixed\npalette, maintaining a proper colouring at all times. Maker aims to colour the\nwhole graph, and Breaker aims to make some vertex impossible to colour. We are\ninterested in the following question, first asked by Zhu in 1999: if Maker wins\nwith $k$ colours available, must they also win with $k+1$? This question has\nremained open, attracting significant attention and being reposed for many\nsimilar games. While we cannot resolve this problem for the vertex colouring\ngame, we can answer it in the affirmative for the game of arboricity, resolving\na question of Bartnicki, Grytczuk, and Kierstead from 2008.\n  We then consider how one might approach the question of monotonicity for the\nvertex colouring game, and work with a related game in which the vertices must\nbe coloured in a prescribed order. We demonstrate that this `ordered vertex\ncolouring game' does not have the above monotonicity property, and discuss the\nimplications of this fact to the unordered game.\n  Finally, we provide counterexamples to two open problems concerning a\nconnected version of the graph colouring game.",
            "author": [
                "Lawrence Hollom"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03528v1",
                "http://arxiv.org/pdf/2308.03528v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C57 (Primary) 05C15 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03519v1",
            "title": "Vocab-Expander: A System for Creating Domain-Specific Vocabularies Based\n  on Word Embeddings",
            "updated": "2023-08-07T12:13:25Z",
            "published": "2023-08-07T12:13:25Z",
            "summary": "In this paper, we propose Vocab-Expander at https://vocab-expander.com, an\nonline tool that enables end-users (e.g., technology scouts) to create and\nexpand a vocabulary of their domain of interest. It utilizes an ensemble of\nstate-of-the-art word embedding techniques based on web text and ConceptNet, a\ncommon-sense knowledge base, to suggest related terms for already given terms.\nThe system has an easy-to-use interface that allows users to quickly confirm or\nreject term suggestions. Vocab-Expander offers a variety of potential use\ncases, such as improving concept-based information retrieval in technology and\ninnovation management, enhancing communication and collaboration within\norganizations or interdisciplinary projects, and creating vocabularies for\nspecific courses in education.",
            "author": [
                "Michael F\u00e4rber",
                "Nicholas Popovic"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03519v1",
                "http://arxiv.org/pdf/2308.03519v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03518v1",
            "title": "Off-the-grid Blind Deconvolution and Demixing",
            "updated": "2023-08-07T12:11:53Z",
            "published": "2023-08-07T12:11:53Z",
            "summary": "We consider the problem of gridless blind deconvolution and demixing (GB2D)\nin scenarios where multiple users communicate messages through multiple unknown\nchannels, and a single base station (BS) collects their contributions. This\nscenario arises in various communication fields, including wireless\ncommunications, the Internet of Things, over-the-air computation, and\nintegrated sensing and communications. In this setup, each user's message is\nconvolved with a multi-path channel formed by several scaled and delayed copies\nof Dirac spikes. The BS receives a linear combination of the convolved signals,\nand the goal is to recover the unknown amplitudes, continuous-indexed delays,\nand transmitted waveforms from a compressed vector of measurements at the BS.\nHowever, in the absence of any prior knowledge of the transmitted messages and\nchannels, GB2D is highly challenging and intractable in general. To address\nthis issue, we assume that each user's message follows a distinct modulation\nscheme living in a known low-dimensional subspace. By exploiting these subspace\nassumptions and the sparsity of the multipath channels for different users, we\ntransform the nonlinear GB2D problem into a matrix tuple recovery problem from\na few linear measurements. To achieve this, we propose a semidefinite\nprogramming optimization that exploits the specific low-dimensional structure\nof the matrix tuple to recover the messages and continuous delays of different\ncommunication paths from a single received signal at the BS. Finally, our\nnumerical experiments show that our proposed method effectively recovers all\ntransmitted messages and the continuous delay parameters of the channels with a\nsufficient number of samples.",
            "author": [
                "Saeed Razavikia",
                "Sajad Daei",
                "Mikael Skoglund",
                "Gabor Fodor",
                "Carlo Fischione"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03518v1",
                "http://arxiv.org/pdf/2308.03518v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03516v1",
            "title": "An Improved Approximation Algorithm for the Max-$3$-Section Problem",
            "updated": "2023-08-07T12:11:26Z",
            "published": "2023-08-07T12:11:26Z",
            "summary": "We consider the Max-$3$-Section problem, where we are given an undirected\ngraph $ G=(V,E)$ equipped with non-negative edge weights $w :E\\rightarrow\n\\mathbb{R}_+$ and the goal is to find a partition of $V$ into three equisized\nparts while maximizing the total weight of edges crossing between different\nparts. Max-$3$-Section is closely related to other well-studied graph\npartitioning problems, e.g., Max-$k$-Cut, Max-$3$-Cut, and Max-Bisection. We\npresent a polynomial time algorithm achieving an approximation of $ 0.795$,\nthat improves upon the previous best known approximation of $ 0.673$. The\nrequirement of multiple parts that have equal sizes renders Max-$3$-Section\nmuch harder to cope with compared to, e.g., Max-Bisection. We show a new\nalgorithm that combines the existing approach of Lassere hierarchy along with a\nrandom cut strategy that suffices to give our result.",
            "author": [
                "Dor Katzelnick",
                "Aditya Pillai",
                "Roy Schwartz",
                "Mohit Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03516v1",
                "http://arxiv.org/pdf/2308.03516v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03503v1",
            "title": "1-Konig-Egervary Graphs",
            "updated": "2023-08-07T11:58:28Z",
            "published": "2023-08-07T11:58:28Z",
            "summary": "Let $\\alpha(G)$ denote the cardinality of a maximum independent set, while\n$\\mu(G)$ be the size of a maximum matching in $G=\\left( V,E\\right) $. It is\nknown that if $\\alpha(G)+\\mu(G)=\\left\\vert V\\right\\vert $, then $G$ is a\n\\textit{K\\\"{o}nig-Egerv\\'{a}ry graph. If $\\alpha (G)+\\mu(G)=\\left\\vert\nV\\right\\vert -1$, then $G$ is an $1$-K\\\"{o}nig-Egerv\\'{a}ry graph. If $G$ is\nnot a K\\\"{o}nig-Egerv\\'{a}ry graph, and there exists a vertex $v\\in V$ (an edge\n$e\\in E$) such that $G-v$ ($G-e$) is K\\\"{o}nig-Egerv\\'{a}ry, then $G$ is called\na vertex (an edge) almost K\\\"{o}nig-Egerv\\'{a}ry graph (respectively). In this\npaper, we characterize all these types of almost K\\\"{o}nig-Egerv\\'{a}ry graphs\nand present interrelationships between them.",
            "author": [
                "Vadim E. Levit",
                "Eugen Mandrescu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03503v1",
                "http://arxiv.org/pdf/2308.03503v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C69 (Primary) 05C70 (Secondary)",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03488v1",
            "title": "No Length Left Behind: Enhancing Knowledge Tracing for Modeling\n  Sequences of Excessive or Insufficient Lengths",
            "updated": "2023-08-07T11:30:58Z",
            "published": "2023-08-07T11:30:58Z",
            "summary": "Knowledge tracing (KT) aims to predict students' responses to practices based\non their historical question-answering behaviors. However, most current KT\nmethods focus on improving overall AUC, leaving ample room for optimization in\nmodeling sequences of excessive or insufficient lengths. As sequences get\nlonger, computational costs will increase exponentially. Therefore, KT methods\nusually truncate sequences to an acceptable length, which makes it difficult\nfor models on online service systems to capture complete historical practice\nbehaviors of students with too long sequences. Conversely, modeling students\nwith short practice sequences using most KT methods may result in overfitting\ndue to limited observation samples. To address the above limitations, we\npropose a model called Sequence-Flexible Knowledge Tracing (SFKT).",
            "author": [
                "Moyu Zhang",
                "Xinning Zhu",
                "Chunhong Zhang",
                "Feng Pan",
                "Wenchen Qian",
                "Hui Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614988",
                "http://arxiv.org/abs/2308.03488v1",
                "http://arxiv.org/pdf/2308.03488v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03480v1",
            "title": "Enhancing iteration performance on distributed task-based workflows",
            "updated": "2023-08-07T11:22:43Z",
            "published": "2023-08-07T11:22:43Z",
            "summary": "Task-based programming models have proven to be a robust and versatile way to\napproach development of applications for distributed environments. They provide\nnatural programming patterns with high performance. However, execution on this\nparadigm can be very sensitive to granularity --i.e., the quantity and\nexecution length of tasks. Granularity is often linked with the block size of\nthe data, and finding the optimal block size has several challenges, as it\nrequires inner knowledge of the computing environment.\n  Our proposal is to supplement the task-based programming model with a new\nmechanism --our SplIter proposal. At its core, the SplIter provides a\ntransparent way to split a collection into partitions (logical groups of\nblocks, obtained without any transfers nor data rearrangement), which can then\nbe iterated. Tasks are linked to those partitions, which means that SplIter\nbreaks the dependency between block size and task granularity.\n  The evaluation shows that the SplIter is able to achieve performance\nimprovements of over one order of magnitude when compared to the baseline, and\nit is either competitive or strictly better (depending on application\ncharacteristics) to the competitor alternative. We have chosen different\napplications covering a wide variety of scenarios; those applications are\nrepresentatives of a broader set of applications and domains. The changes\nrequired in the source code of a task-based application are minimal, preserving\nthe high programmability of the programming model. Two different\nstate-of-the-art task-based frameworks have been evaluated for all the\napplications: COMPSs and Dask, showing that the SplIter can be effectively used\nwithin different frameworks.",
            "author": [
                "Alex Barcelo",
                "Anna Queralt",
                "Toni Cortes"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.future.2023.07.032",
                "http://arxiv.org/abs/2308.03480v1",
                "http://arxiv.org/pdf/2308.03480v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09719v1",
            "title": "CIRO: COVID-19 infection risk ontology",
            "updated": "2023-08-07T11:12:09Z",
            "published": "2023-08-07T11:12:09Z",
            "summary": "Public health authorities perform contact tracing for highly contagious\nagents to identify close contacts with the infected cases. However, during the\npandemic caused by coronavirus disease 2019 (COVID-19), this operation was not\nemployed in countries with high patient volumes. Meanwhile, the Japanese\ngovernment conducted this operation, thereby contributing to the control of\ninfections, at the cost of arduous manual labor by public health officials. To\nease the burden of the officials, this study attempted to automate the\nassessment of each person's infection risk through an ontology, called COVID-19\nInfection Risk Ontology (CIRO). This ontology expresses infection risks of\nCOVID-19 formulated by the Japanese government, toward automated assessment of\ninfection risks of individuals, using Resource Description Framework (RDF) and\nSPARQL (SPARQL Protocol and RDF Query Language) queries. For evaluation, we\ndemonstrated that the knowledge graph built could infer the risks, formulated\nby the government. Moreover, we conducted reasoning experiments to analyze the\ncomputational efficiency. The experiments demonstrated usefulness of the\nknowledge processing, and identified issues left for deployment.",
            "author": [
                "Shusaku Egami",
                "Yasunori Yamamoto",
                "Ikki Ohmukai",
                "Takashi Okumura"
            ],
            "link": [
                "http://dx.doi.org/10.1371/journal.pone.0282291",
                "http://arxiv.org/abs/2308.09719v1",
                "http://arxiv.org/pdf/2308.09719v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "I.2.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03475v1",
            "title": "COPA: Efficient Vision-Language Pre-training Through Collaborative\n  Object- and Patch-Text Alignment",
            "updated": "2023-08-07T11:05:59Z",
            "published": "2023-08-07T11:05:59Z",
            "summary": "Vision-Language Pre-training (VLP) methods based on object detection enjoy\nthe rich knowledge of fine-grained object-text alignment but at the cost of\ncomputationally expensive inference. Recent Visual-Transformer (ViT)-based\napproaches circumvent this issue while struggling with long visual sequences\nwithout detailed cross-modal alignment information. This paper introduces a\nViT-based VLP technique that efficiently incorporates object information\nthrough a novel patch-text alignment mechanism. Specifically, we convert\nobject-level signals into patch-level ones and devise a Patch-Text Alignment\npre-training task (PTA) to learn a text-aware patch detector. By using\noff-the-shelf delicate object annotations in 5\\% training images, we jointly\ntrain PTA with other conventional VLP objectives in an end-to-end manner,\nbypassing the high computational cost of object detection and yielding an\neffective patch detector that accurately detects text-relevant patches, thus\nconsiderably reducing patch sequences and accelerating computation within the\nViT backbone. Our experiments on a variety of widely-used benchmarks reveal\nthat our method achieves a speedup of nearly 88\\% compared to prior VLP models\nwhile maintaining competitive or superior performance on downstream tasks with\nsimilar model size and data scale.",
            "author": [
                "Chaoya Jiang",
                "Haiyang Xu",
                "Wei Ye",
                "Qinghao Ye",
                "Chenliang Li",
                "Ming Yan",
                "Bin Bi",
                "Shikun Zhang",
                "Ji Zhang",
                "Fei Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03475v1",
                "http://arxiv.org/pdf/2308.03475v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03470v1",
            "title": "Uncertainty-aware Consistency Learning for Cold-Start Item\n  Recommendation",
            "updated": "2023-08-07T10:56:57Z",
            "published": "2023-08-07T10:56:57Z",
            "summary": "Graph Neural Network (GNN)-based models have become the mainstream approach\nfor recommender systems. Despite the effectiveness, they are still suffering\nfrom the cold-start problem, i.e., recommend for few-interaction items.\nExisting GNN-based recommendation models to address the cold-start problem\nmainly focus on utilizing auxiliary features of users and items, leaving the\nuser-item interactions under-utilized. However, embeddings distributions of\ncold and warm items are still largely different, since cold items' embeddings\nare learned from lower-popularity interactions, while warm items' embeddings\nare from higher-popularity interactions. Thus, there is a seesaw phenomenon,\nwhere the recommendation performance for the cold and warm items cannot be\nimproved simultaneously. To this end, we proposed a Uncertainty-aware\nConsistency learning framework for Cold-start item recommendation (shorten as\nUCC) solely based on user-item interactions. Under this framework, we train the\nteacher model (generator) and student model (recommender) with consistency\nlearning, to ensure the cold items with additionally generated low-uncertainty\ninteractions can have similar distribution with the warm items. Therefore, the\nproposed framework improves the recommendation of cold and warm items at the\nsame time, without hurting any one of them. Extensive experiments on benchmark\ndatasets demonstrate that our proposed method significantly outperforms\nstate-of-the-art methods on both warm and cold items, with an average\nperformance improvement of 27.6%.",
            "author": [
                "Taichi Liu",
                "Chen Gao",
                "Zhenyu Wang",
                "Dong Li",
                "Jianye Hao",
                "Depeng Jin",
                "Yong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03470v1",
                "http://arxiv.org/pdf/2308.03470v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03449v1",
            "title": "Knowledge-preserving Pruning for Pre-trained Language Models without\n  Retraining",
            "updated": "2023-08-07T10:11:42Z",
            "published": "2023-08-07T10:11:42Z",
            "summary": "Given a pre-trained language model, how can we efficiently compress it\nwithout retraining? Retraining-free structured pruning algorithms are crucial\nin pre-trained language model compression due to their significantly reduced\npruning cost and capability to prune large language models. However, existing\nretraining-free algorithms encounter severe accuracy degradation, as they fail\nto preserve the useful knowledge of pre-trained models. In this paper, we\npropose K-pruning (Knowledge-preserving pruning), an accurate retraining-free\nstructured pruning algorithm for pre-trained language models. K-pruning\nidentifies and prunes attention heads and neurons deemed to be superfluous,\nbased on the amount of their inherent knowledge. K-pruning applies an iterative\nprocess of pruning followed by knowledge reconstruction for each sub-layer to\npreserve the knowledge of the pre-trained models. Consequently, K-pruning shows\nup to 58.02%p higher F1 score than existing retraining-free pruning algorithms\nunder a high compression rate of 80% on the SQuAD benchmark.",
            "author": [
                "Seungcheol Park",
                "Hojun Choi",
                "U Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03449v1",
                "http://arxiv.org/pdf/2308.03449v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03447v1",
            "title": "Biomedical Knowledge Graph Embeddings with Negative Statements",
            "updated": "2023-08-07T10:08:25Z",
            "published": "2023-08-07T10:08:25Z",
            "summary": "A knowledge graph is a powerful representation of real-world entities and\ntheir relations. The vast majority of these relations are defined as positive\nstatements, but the importance of negative statements is increasingly\nrecognized, especially under an Open World Assumption. Explicitly considering\nnegative statements has been shown to improve performance on tasks such as\nentity summarization and question answering or domain-specific tasks such as\nprotein function prediction. However, no attention has been given to the\nexploration of negative statements by knowledge graph embedding approaches\ndespite the potential of negative statements to produce more accurate\nrepresentations of entities in a knowledge graph.\n  We propose a novel approach, TrueWalks, to incorporate negative statements\ninto the knowledge graph representation learning process. In particular, we\npresent a novel walk-generation method that is able to not only differentiate\nbetween positive and negative statements but also take into account the\nsemantic implications of negation in ontology-rich knowledge graphs. This is of\nparticular importance for applications in the biomedical domain, where the\ninadequacy of embedding approaches regarding negative statements at the\nontology level has been identified as a crucial limitation.\n  We evaluate TrueWalks in ontology-rich biomedical knowledge graphs in two\ndifferent predictive tasks based on KG embeddings: protein-protein interaction\nprediction and gene-disease association prediction. We conduct an extensive\nanalysis over established benchmarks and demonstrate that our method is able to\nimprove the performance of knowledge graph embeddings on all tasks.",
            "author": [
                "Rita T. Sousa",
                "Sara Silva",
                "Heiko Paulheim",
                "Catia Pesquita"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03447v1",
                "http://arxiv.org/pdf/2308.03447v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03445v1",
            "title": "Height probabilities for Abelian sandpiles and the looping constant on\n  Sierpinski graphs",
            "updated": "2023-08-07T10:02:13Z",
            "published": "2023-08-07T10:02:13Z",
            "summary": "We investigate the Abelian sandpile model and related quantities such as\nheight probabilities and looping constant on fractal graphs. In particular, we\ngive an algorithmic approach for calculating the height probabilities of\nrecurrent sandpiles under stationarity on finite iterations of the Sierpinski\ngraphs by using the connection between recurrent configurations of the Abelian\nsandpile Markov chain and uniform spanning trees. We also calculate the\nexpected fraction of vertices of height i for $i\\in\\{0,1,2,3\\}$ and expected\nbulk average height of sandpiles under stationarity and relate it to the\nlooping constant on the Sierpinski gasket.",
            "author": [
                "Nico Heizmann",
                "Robin Kaiser",
                "Ecaterina Sava-Huss"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03445v1",
                "http://arxiv.org/pdf/2308.03445v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CO",
                "60J10, 60J45, 05C81, 31E05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03434v2",
            "title": "Tyshkevich's Graph Decomposition and the Distinguishing Numbers of\n  Unigraphs",
            "updated": "2023-08-26T18:42:15Z",
            "published": "2023-08-07T09:32:12Z",
            "summary": "A $c$-labeling $\\phi: V(G) \\rightarrow \\{1, 2, \\hdots, c \\}$ of graph $G$ is\ndistinguishing if, for every non-trivial automorphism $\\pi$ of $G$, there is\nsome vertex $v$ so that $\\phi(v) \\neq \\phi(\\pi(v))$. The distinguishing number\nof $G$, $D(G)$, is the smallest $c$ such that $G$ has a distinguishing\n$c$-labeling.\n  We consider a compact version of Tyshkevich's graph decomposition theorem\nwhere trivial components are maximally combined to form a complete graph or a\ngraph of isolated vertices. Suppose the compact canonical decomposition of $G$\nis $G_{k} \\circ G_{k-1} \\circ \\cdots \\circ G_1 \\circ G_0$. We prove that $\\phi$\nis a distinguishing labeling of $G$ if and only if $\\phi$ is a distinguishing\nlabeling of $G_i$ when restricted to $V(G_i)$ for $i = 0, \\hdots, k$. Thus,\n$D(G) = \\max \\{D(G_i), i = 0, \\hdots, k \\}$. We then present an algorithm that\ncomputes the distinguishing number of a unigraph in linear time.",
            "author": [
                "Christine T. Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03434v2",
                "http://arxiv.org/pdf/2308.03434v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03433v1",
            "title": "Numerical Reconstruction of Diffusion and Potential Coefficients from\n  Two Observations: Decoupled Recovery and Error Estimates",
            "updated": "2023-08-07T09:28:59Z",
            "published": "2023-08-07T09:28:59Z",
            "summary": "The focus of this paper is on the concurrent reconstruction of both the\ndiffusion and potential coefficients present in an elliptic/parabolic equation,\nutilizing two internal measurements of the solutions. A decoupled algorithm is\nconstructed to sequentially recover these two parameters. In the first step, we\nimplement a straightforward reformulation that results in a standard problem of\nidentifying the diffusion coefficient. This coefficient is then numerically\nrecovered, with no requirement for knowledge of the potential, by utilizing an\noutput least-square method coupled with finite element discretization. In the\nsecond step, the previously recovered diffusion coefficient is employed to\nreconstruct the potential coefficient, applying a method similar to the first\nstep. Our approach is stimulated by a constructive conditional stability, and\nwe provide rigorous a priori error estimates in $L^2(\\Omega)$ for the recovered\ndiffusion and potential coefficients. Our approach is stimulated by a\nconstructive conditional stability, and we provide rigorous a priori error\nestimates in $L^2(\\Omega)$ for the recovered diffusion and potential\ncoefficients. To derive these estimates, we develop a weighted energy argument\nand suitable positivity conditions. These estimates offer a beneficial guide\nfor choosing regularization parameters and discretization mesh sizes, in\naccordance with the noise level. Some numerical experiments are presented to\ndemonstrate the accuracy of the numerical scheme and support our theoretical\nresults.",
            "author": [
                "Siyu Cen",
                "Zhi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03433v1",
                "http://arxiv.org/pdf/2308.03433v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03432v1",
            "title": "Cuing Without Sharing: A Federated Cued Speech Recognition Framework via\n  Mutual Knowledge Distillation",
            "updated": "2023-08-07T09:26:36Z",
            "published": "2023-08-07T09:26:36Z",
            "summary": "Cued Speech (CS) is a visual coding tool to encode spoken languages at the\nphonetic level, which combines lip-reading and hand gestures to effectively\nassist communication among people with hearing impairments. The Automatic CS\nRecognition (ACSR) task aims to recognize CS videos into linguistic texts,\nwhich involves both lips and hands as two distinct modalities conveying\ncomplementary information. However, the traditional centralized training\napproach poses potential privacy risks due to the use of facial and gesture\nvideos in CS data. To address this issue, we propose a new Federated Cued\nSpeech Recognition (FedCSR) framework to train an ACSR model over the\ndecentralized CS data without sharing private information. In particular, a\nmutual knowledge distillation method is proposed to maintain cross-modal\nsemantic consistency of the Non-IID CS data, which ensures learning a unified\nfeature space for both linguistic and visual information. On the server side, a\nglobally shared linguistic model is trained to capture the long-term\ndependencies in the text sentences, which is aligned with the visual\ninformation from the local clients via visual-to-linguistic distillation. On\nthe client side, the visual model of each client is trained with its own local\ndata, assisted by linguistic-to-visual distillation treating the linguistic\nmodel as the teacher. To the best of our knowledge, this is the first approach\nto consider the federated ACSR task for privacy protection. Experimental\nresults on the Chinese CS dataset with multiple cuers demonstrate that our\napproach outperforms both mainstream federated learning baselines and existing\ncentralized state-of-the-art ACSR methods, achieving 9.7% performance\nimprovement for character error rate (CER) and 15.0% for word error rate (WER).",
            "author": [
                "Yuxuan Zhang",
                "Lei Liu",
                "Li Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03432v1",
                "http://arxiv.org/pdf/2308.03432v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03419v1",
            "title": "Mitigating Persistence of Open-Source Vulnerabilities in Maven Ecosystem",
            "updated": "2023-08-07T09:11:26Z",
            "published": "2023-08-07T09:11:26Z",
            "summary": "Vulnerabilities from third-party libraries (TPLs) have been unveiled to\nthreaten the Maven ecosystem. Despite patches being released promptly after\nvulnerabilities are disclosed, the libraries and applications in the community\nstill use the vulnerable versions, which makes the vulnerabilities persistent\nin the Maven ecosystem (e.g., the notorious Log4Shell still greatly influences\nthe Maven ecosystem nowadays from 2021). Both academic and industrial\nresearchers have proposed user-oriented standards and solutions to address\nvulnerabilities, while such solutions fail to tackle the ecosystem-wide\npersistent vulnerabilities because it requires a collective effort from the\ncommunity to timely adopt patches without introducing breaking issues.\n  To seek an ecosystem-wide solution, we first carried out an empirical study\nto examine the prevalence of persistent vulnerabilities in the Maven ecosystem.\nThen, we identified affected libraries for alerts by implementing an algorithm\nmonitoring downstream dependents of vulnerabilities based on an up-to-date\ndependency graph. Based on them, we further quantitatively revealed that\npatches blocked by upstream libraries caused the persistence of\nvulnerabilities. After reviewing the drawbacks of existing countermeasures, to\naddress them, we proposed a solution for range restoration (Ranger) to\nautomatically restore the compatible and secure version ranges of dependencies\nfor downstream dependents. The automatic restoration requires no manual effort\nfrom the community, and the code-centric compatibility assurance ensures smooth\nupgrades to patched versions. Moreover, Ranger along with the ecosystem\nmonitoring can timely alert developers of blocking libraries and suggest\nflexible version ranges to rapidly unblock patch versions. By evaluation,\nRanger could restore 75.64% of ranges which automatically remediated 90.32% of\nvulnerable downstream projects.",
            "author": [
                "Lyuye Zhang",
                "Chengwei Liu",
                "Sen Chen",
                "Zhengzi Xu",
                "Lingling Fan",
                "Lida Zhao",
                "Yiran Zhang",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03419v1",
                "http://arxiv.org/pdf/2308.03419v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CR",
                "68-06",
                "D.2.13; D.2.9"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03417v1",
            "title": "PURL: Safe and Effective Sanitization of Link Decoration",
            "updated": "2023-08-07T09:08:39Z",
            "published": "2023-08-07T09:08:39Z",
            "summary": "While privacy-focused browsers have taken steps to block third-party cookies\nand browser fingerprinting, novel tracking methods that bypass existing\ndefenses continue to emerge. Since trackers need to exfiltrate information from\nthe client- to server-side through link decoration regardless of the tracking\ntechnique they employ, a promising orthogonal approach is to detect and\nsanitize tracking information in decorated links. We present PURL, a\nmachine-learning approach that leverages a cross-layer graph representation of\nwebpage execution to safely and effectively sanitize link decoration. Our\nevaluation shows that PURL significantly outperforms existing countermeasures\nin terms of accuracy and reducing website breakage while being robust to common\nevasion techniques. We use PURL to perform a measurement study on top-million\nwebsites. We find that link decorations are widely abused by well-known\nadvertisers and trackers to exfiltrate user information collected from browser\nstorage, email addresses, and scripts involved in fingerprinting.",
            "author": [
                "Shaoor Munir",
                "Patrick Lee",
                "Umar Iqbal",
                "Zubair Shafiq",
                "Sandra Siby"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03417v1",
                "http://arxiv.org/pdf/2308.03417v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03414v3",
            "title": "Critical $(P_5,dart)$-Free Graphs",
            "updated": "2023-10-11T14:03:57Z",
            "published": "2023-08-07T09:05:20Z",
            "summary": "Given two graphs $H_1$ and $H_2$, a graph is $(H_1,H_2)$-free if it contains\nno induced subgraph isomorphic to $H_1$ nor $H_2$. Let $P_t$ be the path on $t$\nvertices. A dart is the graph obtained from a diamond by adding a new vertex\nand making it adjacent to exactly one vertex with degree 3 in the diamond.\n  In this paper, we show that there are finitely many $k$-vertex-critical\n$(P_5,dart)$-free graphs for $k \\ge 1$ To prove these results, we use induction\non $k$ and perform a careful structural analysis via Strong Perfect Graph\nTheorem combined with the pigeonhole principle based on the properties of\nvertex-critical graphs. Moreover, for $k \\in \\{5, 6, 7\\}$ we characterize all\n$k$-vertex-critical $(P_5,dart)$-free graphs using a computer generation\nalgorithm. Our results imply the existence of a polynomial-time certifying\nalgorithm to decide the $k$-colorability of $(P_5,dart)$-free graphs for $k \\ge\n1$ where the certificate is either a $k$-coloring or a $(k+1)$-vertex-critical\ninduced subgraph.",
            "author": [
                "Wen Xia",
                "Jorik Jooken",
                "Jan Goedgebeur",
                "Shenwei Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03414v3",
                "http://arxiv.org/pdf/2308.03414v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03378v1",
            "title": "Friedrichs' systems discretized with the Discontinuous Galerkin method:\n  domain decomposable model order reduction and Graph Neural Networks\n  approximating vanishing viscosity solutions",
            "updated": "2023-08-07T07:57:31Z",
            "published": "2023-08-07T07:57:31Z",
            "summary": "Friedrichs' systems (FS) are symmetric positive linear systems of first-order\npartial differential equations (PDEs), which provide a unified framework for\ndescribing various elliptic, parabolic and hyperbolic semi-linear PDEs such as\nthe linearized Euler equations of gas dynamics, the equations of compressible\nlinear elasticity and the Dirac-Klein-Gordon system. FS were studied to\napproximate PDEs of mixed elliptic and hyperbolic type in the same domain. For\nthis and other reasons, the versatility of the discontinuous Galerkin method\n(DGM) represents the best approximation space for FS. We implement a\ndistributed memory solver for stationary FS in deal.II. Our focus is model\norder reduction. Since FS model hyperbolic PDEs, they often suffer from a slow\nKolmogorov n-width decay. We develop two approaches to tackle this problem. The\nfirst is domain decomposable reduced-order models (DD-ROMs). We will show that\nthe DGM offers a natural formulation of DD-ROMs, in particular regarding\ninterface penalties, compared to the continuous finite element method. We also\ndevelop new repartitioning strategies to obtain more efficient local\napproximations of the solution manifold. The second approach involves graph\nneural networks used to infer the limit of a succession of projection-based\nlinear ROMs corresponding to lower viscosity constants: the heuristic behind is\nto develop a multi-fidelity super-resolution paradigm to mimic the mathematical\nconvergence to vanishing viscosity solutions while exploiting to the most\ninterpretable and certified projection-based ROMs.",
            "author": [
                "Francesco Romor",
                "Davide Torlo",
                "Gianluigi Rozza"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03378v1",
                "http://arxiv.org/pdf/2308.03378v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03377v1",
            "title": "Counterfactual Monotonic Knowledge Tracing for Assessing Students'\n  Dynamic Mastery of Knowledge Concepts",
            "updated": "2023-08-07T07:57:26Z",
            "published": "2023-08-07T07:57:26Z",
            "summary": "As the core of the Knowledge Tracking (KT) task, assessing students' dynamic\nmastery of knowledge concepts is crucial for both offline teaching and online\neducational applications. Since students' mastery of knowledge concepts is\noften unlabeled, existing KT methods rely on the implicit paradigm of\nhistorical practice to mastery of knowledge concepts to students' responses to\npractices to address the challenge of unlabeled concept mastery. However,\npurely predicting student responses without imposing specific constraints on\nhidden concept mastery values does not guarantee the accuracy of these\nintermediate values as concept mastery values. To address this issue, we\npropose a principled approach called Counterfactual Monotonic Knowledge Tracing\n(CMKT), which builds on the implicit paradigm described above by using a\ncounterfactual assumption to constrain the evolution of students' mastery of\nknowledge concepts.",
            "author": [
                "Moyu Zhang",
                "Xinning Zhu",
                "Chunhong Zhang",
                "Wenchen Qian",
                "Feng Pan",
                "Hui Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614827",
                "http://arxiv.org/abs/2308.03377v1",
                "http://arxiv.org/pdf/2308.03377v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03349v1",
            "title": "SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering\n  Dataset for Scientific Graphs",
            "updated": "2023-08-07T07:03:49Z",
            "published": "2023-08-07T07:03:49Z",
            "summary": "In this work, we present SciGraphQA, a synthetic multi-turn question-answer\ndataset related to academic graphs. SciGraphQA is 13 times larger than\nChartVQA, the previously largest chart-visual question-answering dataset. It is\nalso the largest open-sourced chart VQA dataset with non-synthetic charts. To\nbuild our dataset, we selected 290,000 Computer Science or Machine Learning\nArXiv papers published between 2010 and 2020, and then used Palm-2 to generate\n295K samples of open-vocabulary multi-turn question-answering dialogues about\nthe graphs. As context, we provided the text-only Palm-2 with paper title,\nabstract, paragraph mentioning the graph, and rich text contextual data from\nthe graph itself, obtaining dialogues with an average 2.23 question-answer\nturns for each graph. We asked GPT-4 to assess the matching quality of our\nquestion-answer turns given the paper's context, obtaining an average rating of\n8.7/10 on our 3K test set. We evaluated the 0-shot capability of the most\npopular MLLM models such as LLaVa, mPLUGowl, BLIP-2, and openFlamingo's on our\ndataset, finding LLaVA-13B being the most performant with a CIDEr score of\n0.08. We further enriched the question prompts for LLAVA by including the\nserialized data tables extracted from the graphs using the DePlot model,\nboosting LLaVA's 0-shot CIDEr to 0.15. To verify the validity of our dataset,\nwe also fine-tuned LLaVa using our dataset, reaching a substantially higher\nCIDEr score of 0.26. We anticipate further accuracy improvement by including\nsegmentation mask tokens and leveraging larger LLM backbones coupled with\nemergent prompting techniques. Our code and data are open-sourced.",
            "author": [
                "Shengzhi Li",
                "Nima Tajbakhsh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03349v1",
                "http://arxiv.org/pdf/2308.03349v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03348v1",
            "title": "Cooperative Colorization: Exploring Latent Cross-Domain Priors for NIR\n  Image Spectrum Translation",
            "updated": "2023-08-07T07:02:42Z",
            "published": "2023-08-07T07:02:42Z",
            "summary": "Near-infrared (NIR) image spectrum translation is a challenging problem with\nmany promising applications. Existing methods struggle with the mapping\nambiguity between the NIR and the RGB domains, and generalize poorly due to the\nlimitations of models' learning capabilities and the unavailability of\nsufficient NIR-RGB image pairs for training. To address these challenges, we\npropose a cooperative learning paradigm that colorizes NIR images in parallel\nwith another proxy grayscale colorization task by exploring latent cross-domain\npriors (i.e., latent spectrum context priors and task domain priors), dubbed\nCoColor. The complementary statistical and semantic spectrum information from\nthese two task domains -- in the forms of pre-trained colorization networks --\nare brought in as task domain priors. A bilateral domain translation module is\nsubsequently designed, in which intermittent NIR images are generated from\ngrayscale and colorized in parallel with authentic NIR images; and vice versa\nfor the grayscale images. These intermittent transformations act as latent\nspectrum context priors for efficient domain knowledge exchange. We\nprogressively fine-tune and fuse these modules with a series of pixel-level and\nfeature-level consistency constraints. Experiments show that our proposed\ncooperative learning framework produces satisfactory spectrum translation\noutputs with diverse colors and rich textures, and outperforms state-of-the-art\ncounterparts by 3.95dB and 4.66dB in terms of PNSR for the NIR and grayscale\ncolorization tasks, respectively.",
            "author": [
                "Xingxing Yang",
                "Jie Chen",
                "Zaifeng Yang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612008",
                "http://arxiv.org/abs/2308.03348v1",
                "http://arxiv.org/pdf/2308.03348v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03333v2",
            "title": "Heterogeneous Knowledge Fusion: A Novel Approach for Personalized\n  Recommendation via LLM",
            "updated": "2023-08-18T07:05:10Z",
            "published": "2023-08-07T06:29:20Z",
            "summary": "The analysis and mining of user heterogeneous behavior are of paramount\nimportance in recommendation systems. However, the conventional approach of\nincorporating various types of heterogeneous behavior into recommendation\nmodels leads to feature sparsity and knowledge fragmentation issues. To address\nthis challenge, we propose a novel approach for personalized recommendation via\nLarge Language Model (LLM), by extracting and fusing heterogeneous knowledge\nfrom user heterogeneous behavior information. In addition, by combining\nheterogeneous knowledge and recommendation tasks, instruction tuning is\nperformed on LLM for personalized recommendations. The experimental results\ndemonstrate that our method can effectively integrate user heterogeneous\nbehavior and significantly improve recommendation performance.",
            "author": [
                "Bin Yin",
                "Junjie Xie",
                "Yu Qin",
                "Zixiang Ding",
                "Zhichao Feng",
                "Xiang Li",
                "Wei Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03333v2",
                "http://arxiv.org/pdf/2308.03333v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03324v2",
            "title": "Grid homology for spatial graphs and a K\u00fcnneth formula of connected\n  sum",
            "updated": "2023-08-21T06:44:07Z",
            "published": "2023-08-07T06:16:50Z",
            "summary": "In this paper, we research the grid homology for spatial graphs with cut\nedges. We show that the grid homology for spatial graph $f$ is trivial if $f$\nhas sinks, sources, or cut edges. As an application, we give a purely\ncombinatorial proof of a K\\\"{u}nneth formula for the knot Floer homology of\nconnected sums in the framework of the grid homology.",
            "author": [
                "Hajime Kubota"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03324v2",
                "http://arxiv.org/pdf/2308.03324v2"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.AT",
                "57K18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03314v1",
            "title": "When GPT Meets Program Analysis: Towards Intelligent Detection of Smart\n  Contract Logic Vulnerabilities in GPTScan",
            "updated": "2023-08-07T05:48:53Z",
            "published": "2023-08-07T05:48:53Z",
            "summary": "Smart contracts are prone to various vulnerabilities, leading to substantial\nfinancial losses over time. Current analysis tools mainly target\nvulnerabilities with fixed control or dataflow patterns, such as re-entrancy\nand integer overflow. However, a recent study on Web3 security bugs revealed\nthat about 80% of these bugs cannot be audited by existing tools due to the\nlack of domain-specific property description and checking. Given recent\nadvances in Generative Pretraining Transformer (GPT), it is worth exploring how\nGPT could aid in detecting logic vulnerabilities in smart contracts. In this\npaper, we propose GPTScan, the first tool combining GPT with static analysis\nfor smart contract logic vulnerability detection. Instead of relying solely on\nGPT to identify vulnerabilities, which can lead to high false positives and is\nlimited by GPT's pre-trained knowledge, we utilize GPT as a versatile code\nunderstanding tool. By breaking down each logic vulnerability type into\nscenarios and properties, GPTScan matches candidate vulnerabilities with GPT.\nTo enhance accuracy, GPTScan further instructs GPT to intelligently recognize\nkey variables and statements, which are then validated by static confirmation.\nEvaluation on diverse datasets with around 400 contract projects and 3K\nSolidity files shows that GPTScan achieves high precision (over 90%) for token\ncontracts and acceptable precision (57.14%) for large projects like Web3Bugs.\nIt effectively detects groundtruth logic vulnerabilities with a recall of over\n80%, including 9 new vulnerabilities missed by human auditors. GPTScan is fast\nand cost-effective, taking an average of 14.39 seconds and 0.01 USD to scan per\nthousand lines of Solidity code. Moreover, static confirmation helps GPTScan\nreduce two-thirds of false positives.",
            "author": [
                "Yuqiang Sun",
                "Daoyuan Wu",
                "Yue Xue",
                "Han Liu",
                "Haijun Wang",
                "Zhengzi Xu",
                "Xiaofei Xie",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03314v1",
                "http://arxiv.org/pdf/2308.03314v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03313v2",
            "title": "Quantifying the Impact of Large Language Models on Collective Opinion\n  Dynamics",
            "updated": "2023-08-26T01:53:37Z",
            "published": "2023-08-07T05:45:17Z",
            "summary": "The process of opinion expression and exchange is a critical component of\ndemocratic societies. As people interact with large language models (LLMs) in\nthe opinion shaping process different from traditional media, the impacts of\nLLMs are increasingly recognized and being concerned. However, the knowledge\nabout how LLMs affect the process of opinion expression and exchange of social\nopinion networks is very limited. Here, we create an opinion network dynamics\nmodel to encode the opinions of LLMs, cognitive acceptability and usage\nstrategies of individuals, and simulate the impact of LLMs on opinion dynamics\nin a variety of scenarios. The outcomes of the simulations inform about\neffective demand-oriented opinion network interventions. The results from this\nstudy suggested that the output opinion of LLMs has a unique and positive\neffect on the collective opinion difference. The marginal effect of cognitive\nacceptability on collective opinion formation is nonlinear and shows a\ndecreasing trend. When people partially rely on LLMs, the exchange process of\nopinion becomes more intense and the diversity of opinion becomes more\nfavorable. In fact, there is 38.6% more opinion diversity when people all\npartially rely on LLMs, compared to prohibiting the use of LLMs entirely. The\noptimal diversity of opinion was found when the fractions of people who do not\nuse, partially rely on, and fully rely on LLMs reached roughly 4:12:1. Our\nexperiments also find that introducing extra agents with\nopposite/neutral/random opinions, we can effectively mitigate the impact of\nbiased/toxic output from LLMs. Our findings provide valuable insights into\nopinion dynamics in the age of LLMs, highlighting the need for customized\ninterventions tailored to specific scenarios to address the drawbacks of\nimproper output and use of LLMs.",
            "author": [
                "Chao Li",
                "Xing Su",
                "Haoying Han",
                "Cong Xue",
                "Chunmo Zheng",
                "Chao Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03313v2",
                "http://arxiv.org/pdf/2308.03313v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03312v5",
            "title": "Symmetry-Preserving Program Representations for Learning Code Semantics",
            "updated": "2023-08-31T02:29:36Z",
            "published": "2023-08-07T05:40:58Z",
            "summary": "Large Language Models (LLMs) have shown promise in automated program\nreasoning, a crucial aspect of many security tasks. However, existing LLM\narchitectures for code are often borrowed from other domains like natural\nlanguage processing, raising concerns about their generalization and robustness\nto unseen code. A key generalization challenge is to incorporate the knowledge\nof code semantics, including control and data flow, into the LLM architectures.\n  Drawing inspiration from examples of convolution layers exploiting\ntranslation symmetry, we explore how code symmetries can enhance LLM\narchitectures for program analysis and modeling. We present a rigorous\ngroup-theoretic framework that formally defines code symmetries as\nsemantics-preserving transformations and provides techniques for precisely\nreasoning about symmetry preservation within LLM architectures. Using this\nframework, we introduce a novel variant of self-attention that preserves\nprogram symmetries, demonstrating its effectiveness in generalization and\nrobustness through detailed experimental evaluations across different binary\nand source code analysis tasks. Overall, our code symmetry framework offers\nrigorous and powerful reasoning techniques that can guide the future\ndevelopment of specialized LLMs for code and advance LLM-guided program\nreasoning tasks.",
            "author": [
                "Kexin Pei",
                "Weichen Li",
                "Qirui Jin",
                "Shuyang Liu",
                "Scott Geng",
                "Lorenzo Cavallaro",
                "Junfeng Yang",
                "Suman Jana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03312v5",
                "http://arxiv.org/pdf/2308.03312v5"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03306v1",
            "title": "Implicit Graph Neural Diffusion Based on Constrained Dirichlet Energy\n  Minimization",
            "updated": "2023-08-07T05:22:33Z",
            "published": "2023-08-07T05:22:33Z",
            "summary": "Implicit graph neural networks (GNNs) have emerged as a potential approach to\nenable GNNs to capture long-range dependencies effectively. However, poorly\ndesigned implicit GNN layers can experience over-smoothing or may have limited\nadaptability to learn data geometry, potentially hindering their performance in\ngraph learning problems. To address these issues, we introduce a geometric\nframework to design implicit graph diffusion layers based on a parameterized\ngraph Laplacian operator. Our framework allows learning the geometry of vertex\nand edge spaces, as well as the graph gradient operator from data. We further\nshow how implicit GNN layers can be viewed as the fixed-point solution of a\nDirichlet energy minimization problem and give conditions under which it may\nsuffer from over-smoothing. To overcome the over-smoothing problem, we design\nour implicit graph diffusion layer as the solution of a Dirichlet energy\nminimization problem with constraints on vertex features, enabling it to trade\noff smoothing with the preservation of node feature information. With an\nappropriate hyperparameter set to be larger than the largest eigenvalue of the\nparameterized graph Laplacian, our framework guarantees a unique equilibrium\nand quick convergence. Our models demonstrate better performance than leading\nimplicit and explicit GNNs on benchmark datasets for node and graph\nclassification tasks, with substantial accuracy improvements observed for some\ndatasets.",
            "author": [
                "Guoji Fu",
                "Mohammed Haroon Dupty",
                "Yanfei Dong",
                "Lee Wee Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03306v1",
                "http://arxiv.org/pdf/2308.03306v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03300v1",
            "title": "Do You Remember? Overcoming Catastrophic Forgetting for Fake Audio\n  Detection",
            "updated": "2023-08-07T05:05:49Z",
            "published": "2023-08-07T05:05:49Z",
            "summary": "Current fake audio detection algorithms have achieved promising performances\non most datasets. However, their performance may be significantly degraded when\ndealing with audio of a different dataset. The orthogonal weight modification\nto overcome catastrophic forgetting does not consider the similarity of genuine\naudio across different datasets. To overcome this limitation, we propose a\ncontinual learning algorithm for fake audio detection to overcome catastrophic\nforgetting, called Regularized Adaptive Weight Modification (RAWM). When\nfine-tuning a detection network, our approach adaptively computes the direction\nof weight modification according to the ratio of genuine utterances and fake\nutterances. The adaptive modification direction ensures the network can\neffectively detect fake audio on the new dataset while preserving its knowledge\nof old model, thus mitigating catastrophic forgetting. In addition, genuine\naudio collected from quite different acoustic conditions may skew their feature\ndistribution, so we introduce a regularization constraint to force the network\nto remember the old distribution in this regard. Our method can easily be\ngeneralized to related fields, like speech emotion recognition. We also\nevaluate our approach across multiple datasets and obtain a significant\nperformance improvement on cross-dataset experiments.",
            "author": [
                "Xiaohui Zhang",
                "Jiangyan Yi",
                "Jianhua Tao",
                "Chenglong Wang",
                "Chuyuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03300v1",
                "http://arxiv.org/pdf/2308.03300v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03289v1",
            "title": "Testing Graph Properties with the Container Method",
            "updated": "2023-08-07T04:15:16Z",
            "published": "2023-08-07T04:15:16Z",
            "summary": "We establish nearly optimal sample complexity bounds for testing the\n$\\rho$-clique property in the dense graph model. Specifically, we show that it\nis possible to distinguish graphs on $n$ vertices that have a $\\rho n$-clique\nfrom graphs for which at least $\\epsilon n^2$ edges must be added to form a\n$\\rho n$-clique by sampling and inspecting a random subgraph on only\n$\\tilde{O}(\\rho^3/\\epsilon^2)$ vertices.\n  We also establish new sample complexity bounds for $\\epsilon$-testing\n$k$-colorability. In this case, we show that a sampled subgraph on\n$\\tilde{O}(k/\\epsilon)$ vertices suffices to distinguish $k$-colorable graphs\nfrom those for which any $k$-coloring of the vertices causes at least $\\epsilon\nn^2$ edges to be monochromatic.\n  The new bounds for testing the $\\rho$-clique and $k$-colorability properties\nare both obtained via new extensions of the graph container method. This method\nhas been an effective tool for tackling various problems in graph theory and\ncombinatorics. Our results demonstrate that it is also a powerful tool for the\nanalysis of property testing algorithms.",
            "author": [
                "Eric Blais",
                "Cameron Seth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03289v1",
                "http://arxiv.org/pdf/2308.03289v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03282v2",
            "title": "Environment-Invariant Curriculum Relation Learning for Fine-Grained\n  Scene Graph Generation",
            "updated": "2023-08-21T01:19:33Z",
            "published": "2023-08-07T03:56:15Z",
            "summary": "The scene graph generation (SGG) task is designed to identify the predicates\nbased on the subject-object pairs.However,existing datasets generally include\ntwo imbalance cases: one is the class imbalance from the predicted predicates\nand another is the context imbalance from the given subject-object pairs, which\npresents significant challenges for SGG. Most existing methods focus on the\nimbalance of the predicted predicate while ignoring the imbalance of the\nsubject-object pairs, which could not achieve satisfactory results. To address\nthe two imbalance cases, we propose a novel Environment Invariant Curriculum\nRelation learning (EICR) method, which can be applied in a plug-and-play\nfashion to existing SGG methods. Concretely, to remove the imbalance of the\nsubject-object pairs, we first construct different distribution environments\nfor the subject-object pairs and learn a model invariant to the environment\nchanges. Then, we construct a class-balanced curriculum learning strategy to\nbalance the different environments to remove the predicate imbalance.\nComprehensive experiments conducted on VG and GQA datasets demonstrate that our\nEICR framework can be taken as a general strategy for various SGG models, and\nachieve significant improvements.",
            "author": [
                "Yukuan Min",
                "Aming Wu",
                "Cheng Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03282v2",
                "http://arxiv.org/pdf/2308.03282v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "68Txx",
                "I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06533v1",
            "title": "Knowledge Distilled Ensemble Model for sEMG-based Silent Speech\n  Interface",
            "updated": "2023-08-07T03:52:37Z",
            "published": "2023-08-07T03:52:37Z",
            "summary": "Voice disorders affect millions of people worldwide. Surface\nelectromyography-based Silent Speech Interfaces (sEMG-based SSIs) have been\nexplored as a potential solution for decades. However, previous works were\nlimited by small vocabularies and manually extracted features from raw data. To\naddress these limitations, we propose a lightweight deep learning\nknowledge-distilled ensemble model for sEMG-based SSI (KDE-SSI). Our model can\nclassify a 26 NATO phonetic alphabets dataset with 3900 data samples, enabling\nthe unambiguous generation of any English word through spelling. Extensive\nexperiments validate the effectiveness of KDE-SSI, achieving a test accuracy of\n85.9\\%. Our findings also shed light on an end-to-end system for portable,\npractical equipment.",
            "author": [
                "Wenqiang Lai",
                "Qihan Yang",
                "Ye Mao",
                "Endong Sun",
                "Jiangnan Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06533v1",
                "http://arxiv.org/pdf/2308.06533v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03275v1",
            "title": "Adapter-based Selective Knowledge Distillation for Federated\n  Multi-domain Meeting Summarization",
            "updated": "2023-08-07T03:34:01Z",
            "published": "2023-08-07T03:34:01Z",
            "summary": "Meeting summarization has emerged as a promising technique for providing\nusers with condensed summaries. However, existing work has focused on training\nmodels on centralized data, neglecting real-world scenarios where meeting data\nare infeasible to collect centrally, due to their sensitive nature. This gap\nmotivates us to explore federated learning for meeting summarization. Two\ncritical challenges impede progress. First, state-of-the-art summarizers are\nbased on parameter-heavy pre-trained models. Exchanging such a model's\nparameters across clients imposes large bandwidth costs. Second, as real-world\nmeeting data belong to various domains and are distributed across clients, they\nare instances of non-identically and independently distributed (non-IID). IID\nassumptions do not hold, which changes which forms of learning algorithms best\napply. To address this, we propose Adapter-based Federated Selective Knowledge\nDistillation (AdaFedSelecKD) for training performant client models.\nSpecifically, we develop an adapter-based summarization model where two\nadapters cooperatively facilitate learning using fewer parameters to reduce\ncommunication costs. Then, we devise a selective knowledge distillation\nstrategy, assisting clients in robustly handling domain-focused modelling on\ntheir own data, while leveraging global parameters based on non-IID data.\nExtensive experiments on the QMSum benchmark demonstrate AdaFedSelecKD can\nachieve comparable performance with powerful centralized training methods, and\nshows its generalizability and robustness.",
            "author": [
                "Xiachong Feng",
                "Xiaocheng Feng",
                "Xiyuan Du",
                "Min-Yen Kan",
                "Bing Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03275v1",
                "http://arxiv.org/pdf/2308.03275v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03271v1",
            "title": "Local Structure-aware Graph Contrastive Representation Learning",
            "updated": "2023-08-07T03:23:46Z",
            "published": "2023-08-07T03:23:46Z",
            "summary": "Traditional Graph Neural Network (GNN), as a graph representation learning\nmethod, is constrained by label information. However, Graph Contrastive\nLearning (GCL) methods, which tackle the label problem effectively, mainly\nfocus on the feature information of the global graph or small subgraph\nstructure (e.g., the first-order neighborhood). In the paper, we propose a\nLocal Structure-aware Graph Contrastive representation Learning method (LS-GCL)\nto model the structural information of nodes from multiple views. Specifically,\nwe construct the semantic subgraphs that are not limited to the first-order\nneighbors. For the local view, the semantic subgraph of each target node is\ninput into a shared GNN encoder to obtain the target node embeddings at the\nsubgraph-level. Then, we use a pooling function to generate the subgraph-level\ngraph embeddings. For the global view, considering the original graph preserves\nindispensable semantic information of nodes, we leverage the shared GNN encoder\nto learn the target node embeddings at the global graph-level. The proposed\nLS-GCL model is optimized to maximize the common information among similar\ninstances at three various perspectives through a multi-level contrastive loss\nfunction. Experimental results on five datasets illustrate that our method\noutperforms state-of-the-art graph representation learning approaches for both\nnode classification and link prediction tasks.",
            "author": [
                "Kai Yang",
                "Yuan Liu",
                "Zijuan Zhao",
                "Peijin Ding",
                "Wenqian Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03271v1",
                "http://arxiv.org/pdf/2308.03271v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03269v1",
            "title": "Simple Rule Injection for ComplEx Embeddings",
            "updated": "2023-08-07T03:19:59Z",
            "published": "2023-08-07T03:19:59Z",
            "summary": "Recent works in neural knowledge graph inference attempt to combine logic\nrules with knowledge graph embeddings to benefit from prior knowledge. However,\nthey usually cannot avoid rule grounding, and injecting a diverse set of rules\nhas still not been thoroughly explored. In this work, we propose InjEx, a\nmechanism to inject multiple types of rules through simple constraints, which\ncapture definite Horn rules. To start, we theoretically prove that InjEx can\ninject such rules. Next, to demonstrate that InjEx infuses interpretable prior\nknowledge into the embedding space, we evaluate InjEx on both the knowledge\ngraph completion (KGC) and few-shot knowledge graph completion (FKGC) settings.\nOur experimental results reveal that InjEx outperforms both baseline KGC models\nas well as specialized few-shot models while maintaining its scalability and\nefficiency.",
            "author": [
                "Haodi Ma",
                "Anthony Colas",
                "Yuejie Wang",
                "Ali Sadeghian",
                "Daisy Zhe Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03269v1",
                "http://arxiv.org/pdf/2308.03269v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03257v2",
            "title": "TempFuser: Learning Tactical and Agile Flight Maneuvers in Aerial\n  Dogfights using a Long Short-Term Temporal Fusion Transformer",
            "updated": "2023-09-16T17:18:03Z",
            "published": "2023-08-07T02:28:31Z",
            "summary": "In aerial combat, dogfighting poses intricate challenges that demand an\nunderstanding of both strategic maneuvers and the aerodynamics of agile fighter\naircraft. In this paper, we introduce TempFuser, a novel long short-term\ntemporal fusion transformer designed to learn tactical and agile flight\nmaneuvers in aerial dogfights. Our approach employs two distinct LSTM-based\ninput embeddings to encode long-term sparse and short-term dense state\nrepresentations. By integrating these embeddings through a transformer encoder,\nour model captures the tactics and agility of fighter jets, enabling it to\ngenerate end-to-end flight commands that secure dominant positions and\noutmaneuver the opponent. After extensive training against various types of\nopponent aircraft in a high-fidelity flight simulator, our model successfully\nlearns to perform complex fighter maneuvers, consistently outperforming several\nbaseline models. Notably, our model exhibits human-like strategic maneuvers\neven when facing adversaries with superior specifications, all without relying\non explicit prior knowledge. Moreover, it demonstrates robust pursuit\nperformance in challenging supersonic and low-altitude environments. Demo\nvideos are available at https://sites.google.com/view/tempfuser.",
            "author": [
                "Hyunki Seong",
                "David Hyunchul Shim"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03257v2",
                "http://arxiv.org/pdf/2308.03257v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03256v1",
            "title": "Learning a Graph Neural Network with Cross Modality Interaction for\n  Image Fusion",
            "updated": "2023-08-07T02:25:06Z",
            "published": "2023-08-07T02:25:06Z",
            "summary": "Infrared and visible image fusion has gradually proved to be a vital fork in\nthe field of multi-modality imaging technologies. In recent developments,\nresearchers not only focus on the quality of fused images but also evaluate\ntheir performance in downstream tasks. Nevertheless, the majority of methods\nseldom put their eyes on the mutual learning from different modalities,\nresulting in fused images lacking significant details and textures. To overcome\nthis issue, we propose an interactive graph neural network (GNN)-based\narchitecture between cross modality for fusion, called IGNet. Specifically, we\nfirst apply a multi-scale extractor to achieve shallow features, which are\nemployed as the necessary input to build graph structures. Then, the graph\ninteraction module can construct the extracted intermediate features of the\ninfrared/visible branch into graph structures. Meanwhile, the graph structures\nof two branches interact for cross-modality and semantic learning, so that\nfused images can maintain the important feature expressions and enhance the\nperformance of downstream tasks. Besides, the proposed leader nodes can improve\ninformation propagation in the same modality. Finally, we merge all graph\nfeatures to get the fusion result. Extensive experiments on different datasets\n(TNO, MFNet and M3FD) demonstrate that our IGNet can generate visually\nappealing fused images while scoring averagely 2.59% mAP@.5 and 7.77% mIoU\nhigher in detection and segmentation than the compared state-of-the-art\nmethods. The source code of the proposed IGNet can be available at\nhttps://github.com/lok-18/IGNet.",
            "author": [
                "Jiawei Li",
                "Jiansheng Chen",
                "Jinyuan Liu",
                "Huimin Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03256v1",
                "http://arxiv.org/pdf/2308.03256v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03243v1",
            "title": "Unsupervised Adversarial Detection without Extra Model: Training Loss\n  Should Change",
            "updated": "2023-08-07T01:41:21Z",
            "published": "2023-08-07T01:41:21Z",
            "summary": "Adversarial robustness poses a critical challenge in the deployment of deep\nlearning models for real-world applications. Traditional approaches to\nadversarial training and supervised detection rely on prior knowledge of attack\ntypes and access to labeled training data, which is often impractical. Existing\nunsupervised adversarial detection methods identify whether the target model\nworks properly, but they suffer from bad accuracies owing to the use of common\ncross-entropy training loss, which relies on unnecessary features and\nstrengthens adversarial attacks. We propose new training losses to reduce\nuseless features and the corresponding detection method without prior knowledge\nof adversarial attacks. The detection rate (true positive rate) against all\ngiven white-box attacks is above 93.9% except for attacks without limits\n(DF($\\infty$)), while the false positive rate is barely 2.5%. The proposed\nmethod works well in all tested attack types and the false positive rates are\neven better than the methods good at certain types.",
            "author": [
                "Chien Cheng Chyou",
                "Hung-Ting Su",
                "Winston H. Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03243v1",
                "http://arxiv.org/pdf/2308.03243v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03810v2",
            "title": "AdaER: An Adaptive Experience Replay Approach for Continual Lifelong\n  Learning",
            "updated": "2023-08-19T16:23:09Z",
            "published": "2023-08-07T01:25:45Z",
            "summary": "Continual lifelong learning is an machine learning framework inspired by\nhuman learning, where learners are trained to continuously acquire new\nknowledge in a sequential manner. However, the non-stationary nature of\nstreaming training data poses a significant challenge known as catastrophic\nforgetting, which refers to the rapid forgetting of previously learned\nknowledge when new tasks are introduced. While some approaches, such as\nexperience replay (ER), have been proposed to mitigate this issue, their\nperformance remains limited, particularly in the class-incremental scenario\nwhich is considered natural and highly challenging. In this paper, we present a\nnovel algorithm, called adaptive-experience replay (AdaER), to address the\nchallenge of continual lifelong learning. AdaER consists of two stages: memory\nreplay and memory update. In the memory replay stage, AdaER introduces a\ncontextually-cued memory recall (C-CMR) strategy, which selectively replays\nmemories that are most conflicting with the current input data in terms of both\ndata and task. Additionally, AdaER incorporates an entropy-balanced reservoir\nsampling (E-BRS) strategy to enhance the performance of the memory buffer by\nmaximizing information entropy. To evaluate the effectiveness of AdaER, we\nconduct experiments on established supervised continual lifelong learning\nbenchmarks, specifically focusing on class-incremental learning scenarios. The\nresults demonstrate that AdaER outperforms existing continual lifelong learning\nbaselines, highlighting its efficacy in mitigating catastrophic forgetting and\nimproving learning performance.",
            "author": [
                "Xingyu Li",
                "Bo Tang",
                "Haifeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03810v2",
                "http://arxiv.org/pdf/2308.03810v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03234v1",
            "title": "Exploring Automated Distractor and Feedback Generation for Math\n  Multiple-choice Questions via In-context Learning",
            "updated": "2023-08-07T01:03:04Z",
            "published": "2023-08-07T01:03:04Z",
            "summary": "Multiple-choice questions (MCQs) are ubiquitous in almost all levels of\neducation since they are easy to administer, grade, and are a reliable format\nin both assessments and practices. An important aspect of MCQs is the\ndistractors, i.e., incorrect options that are designed to target specific\nmisconceptions or insufficient knowledge among students. To date, the task of\ncrafting high-quality distractors has largely remained a labor-intensive\nprocess for teachers and learning content designers, which has limited\nscalability. In this work, we explore the task of automated distractor and\ncorresponding feedback message generation in math MCQs using large language\nmodels. We establish a formulation of these two tasks and propose a simple,\nin-context learning-based solution. Moreover, we explore using two non-standard\nmetrics to evaluate the quality of the generated distractors and feedback\nmessages. We conduct extensive experiments on these tasks using a real-world\nMCQ dataset that contains student response information. Our findings suggest\nthat there is a lot of room for improvement in automated distractor and\nfeedback generation. We also outline several directions for future work",
            "author": [
                "Hunter McNichols",
                "Wanyong Feng",
                "Jaewook Lee",
                "Alexander Scarlatos",
                "Digory Smith",
                "Simon Woodhead",
                "Andrew Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03234v1",
                "http://arxiv.org/pdf/2308.03234v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03231v1",
            "title": "Imbalanced Large Graph Learning Framework for FPGA Logic Elements\n  Packing Prediction",
            "updated": "2023-08-07T00:30:29Z",
            "published": "2023-08-07T00:30:29Z",
            "summary": "Packing is a required step in a typical FPGA CAD flow. It has high impacts to\nthe performance of FPGA placement and routing. Early prediction of packing\nresults can guide design optimization and expedite design closure. In this\nwork, we propose an imbalanced large graph learning framework, ImLG, for\nprediction of whether logic elements will be packed after placement.\nSpecifically, we propose dedicated feature extraction and feature aggregation\nmethods to enhance the node representation learning of circuit graphs. With\nimbalanced distribution of packed and unpacked logic elements, we further\npropose techniques such as graph oversampling and mini-batch training for this\nimbalanced learning task in large circuit graphs. Experimental results\ndemonstrate that our framework can improve the F1 score by 42.82% compared to\nthe most recent Gaussian-based prediction method. Physical design results show\nthat the proposed method can assist the placer in improving routed wirelength\nby 0.93% and SLICE occupation by 0.89%.",
            "author": [
                "Zhixiong Di",
                "Runzhe Tao",
                "Lin Chen",
                "Qiang Wu",
                "Yibo Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03231v1",
                "http://arxiv.org/pdf/2308.03231v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.08552v1",
            "title": "Logic and Paradox",
            "updated": "2023-08-06T22:32:22Z",
            "published": "2023-08-06T22:32:22Z",
            "summary": "This article discusses the logical errors in the liar paradox, G\\\"odel's\nincompleteness theorems, Russell's paradox, and the halting problem. In order\nto avoid these errors, a redefinition of logic has been presented, which is\nconcluded as four principles in set-theoretic language, including 1. Don't talk\nabout empty; 2. Elements of set should have identity; 3. Sets should have\ndefinitions; and 4. A total set should be defined. The new definition of logic\ncan eliminate all paradoxes and invalid statements, thus becoming a solid\nfoundation for human language and knowledge.",
            "author": [
                "Xuezhi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.08552v1",
                "http://arxiv.org/pdf/2308.08552v1"
            ],
            "primary_category": "math.GM",
            "category": [
                "math.GM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03209v1",
            "title": "Communication-Free Distributed GNN Training with Vertex Cut",
            "updated": "2023-08-06T21:04:58Z",
            "published": "2023-08-06T21:04:58Z",
            "summary": "Training Graph Neural Networks (GNNs) on real-world graphs consisting of\nbillions of nodes and edges is quite challenging, primarily due to the\nsubstantial memory needed to store the graph and its intermediate node and edge\nfeatures, and there is a pressing need to speed up the training process. A\ncommon approach to achieve speed up is to divide the graph into many smaller\nsubgraphs, which are then distributed across multiple GPUs in one or more\nmachines and processed in parallel. However, existing distributed methods\nrequire frequent and substantial cross-GPU communication, leading to\nsignificant time overhead and progressively diminishing scalability. Here, we\nintroduce CoFree-GNN, a novel distributed GNN training framework that\nsignificantly speeds up the training process by implementing communication-free\ntraining. The framework utilizes a Vertex Cut partitioning, i.e., rather than\npartitioning the graph by cutting the edges between partitions, the Vertex Cut\npartitions the edges and duplicates the node information to preserve the graph\nstructure. Furthermore, the framework maintains high model accuracy by\nincorporating a reweighting mechanism to handle a distorted graph distribution\nthat arises from the duplicated nodes. We also propose a modified DropEdge\ntechnique to further speed up the training process. Using an extensive set of\nexperiments on real-world networks, we demonstrate that CoFree-GNN speeds up\nthe GNN training process by up to 10 times over the existing state-of-the-art\nGNN training approaches.",
            "author": [
                "Kaidi Cao",
                "Rui Deng",
                "Shirley Wu",
                "Edward W Huang",
                "Karthik Subbian",
                "Jure Leskovec"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03209v1",
                "http://arxiv.org/pdf/2308.03209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03198v1",
            "title": "Re-imagining the Future of Forest Management -- An Age-Dependent\n  Approach towards Harvesting",
            "updated": "2023-08-06T19:52:41Z",
            "published": "2023-08-06T19:52:41Z",
            "summary": "Facing the drastic climate changes, current strategies for enhancing carbon\ndioxide stocks need to be thoroughly honed. To address the problem, we first\nbuilt a carbon sequestration growth model driven by growth rate dependency\n(GRDM). We abstracted the carbon cycling system into the process of\nphotosynthesis, the humidity fluctuation, and the original storage of carbon in\nthe trees. In the photosynthesis model, we considered various factors,\nincluding transition rate of absorption and organic matter production. We also\ndesigned an Economic Return Evaluation Model (EREM) to estimate the optimal\ndistribution of trees in the forest based on the utility function. Maximizing\nthe utility brought by the amount of carbon storage, we derived the equation\nfor profit optimization with the constraints of total economic expenses\nallowed. To assess its performance, we took an object-oriented approach,\nsimulated an ideal forest by placing instances of trees and plotted a\ntime-dependent forest composition graph. After proper normalization of climate\nand economic data, we also make predictions for 169 worldwide forest-covered\ncountries. Our model further suggests high sensitivity and robustness with a\nsimilar trend of overall utility when environmental aridity or proportion of\nharvested woods are varied. Finally, we apply the model to Georgia temperate\ndeciduous forest, and we evaluate the carbon storage ability to adjust the Red\nSpruce based on available biological literature research. We recognize that\nwhile the model is preliminary in its failure to identify a diverse array of\nvariables, it has encapsulated key features of idealized forests.",
            "author": [
                "Shuyang Bian",
                "Yuanyuan Xie",
                "Flora Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03198v1",
                "http://arxiv.org/pdf/2308.03198v1"
            ],
            "primary_category": "q-bio.OT",
            "category": [
                "q-bio.OT",
                "92-10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03185v1",
            "title": "VN-Solver: Vision-based Neural Solver for Combinatorial Optimization\n  over Graphs",
            "updated": "2023-08-06T18:33:11Z",
            "published": "2023-08-06T18:33:11Z",
            "summary": "Data-driven approaches have been proven effective in solving combinatorial\noptimization problems over graphs such as the traveling salesman problems and\nthe vehicle routing problem. The rationale behind such methods is that the\ninput instances may follow distributions with salient patterns that can be\nleveraged to overcome the worst-case computational hardness. For optimization\nproblems over graphs, the common practice of neural combinatorial solvers\nconsumes the inputs in the form of adjacency matrices. In this paper, we\nexplore a vision-based method that is conceptually novel: can neural models\nsolve graph optimization problems by \\textit{taking a look at the graph\npattern}? Our results suggest that the performance of such vision-based methods\nis not only non-trivial but also comparable to the state-of-the-art\nmatrix-based methods, which opens a new avenue for developing data-driven\noptimization solvers.",
            "author": [
                "Mina Samizadeh",
                "Guangmo Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03185v1",
                "http://arxiv.org/pdf/2308.03185v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04457v1",
            "title": "A Critical Review of Physics-Informed Machine Learning Applications in\n  Subsurface Energy Systems",
            "updated": "2023-08-06T18:20:24Z",
            "published": "2023-08-06T18:20:24Z",
            "summary": "Machine learning has emerged as a powerful tool in various fields, including\ncomputer vision, natural language processing, and speech recognition. It can\nunravel hidden patterns within large data sets and reveal unparalleled\ninsights, revolutionizing many industries and disciplines. However, machine and\ndeep learning models lack interpretability and limited domain-specific\nknowledge, especially in applications such as physics and engineering.\nAlternatively, physics-informed machine learning (PIML) techniques integrate\nphysics principles into data-driven models. By combining deep learning with\ndomain knowledge, PIML improves the generalization of the model, abidance by\nthe governing physical laws, and interpretability. This paper comprehensively\nreviews PIML applications related to subsurface energy systems, mainly in the\noil and gas industry. The review highlights the successful utilization of PIML\nfor tasks such as seismic applications, reservoir simulation, hydrocarbons\nproduction forecasting, and intelligent decision-making in the exploration and\nproduction stages. Additionally, it demonstrates PIML's capabilities to\nrevolutionize the oil and gas industry and other emerging areas of interest,\nsuch as carbon and hydrogen storage; and geothermal systems by providing more\naccurate and reliable predictions for resource management and operational\nefficiency.",
            "author": [
                "Abdeldjalil Latrach",
                "Mohamed Lamine Malki",
                "Misael Morales",
                "Mohamed Mehana",
                "Minou Rabiei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04457v1",
                "http://arxiv.org/pdf/2308.04457v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03159v3",
            "title": "Semilinear elliptic eigenvalue problem: Parametric analyticity and the\n  uncertainty quantification",
            "updated": "2023-08-30T22:01:40Z",
            "published": "2023-08-06T16:57:18Z",
            "summary": "In this paper, to the best of our knowledge, we make the first attempt at\nstudying the parametric semilinear elliptic eigenvalue problems with the\nparametric coefficient and some power-type nonlinearities. The parametric\ncoefficient is assumed to have an affine dependence on the countably many\nparameters with an appropriate class of sequences of functions. In this paper,\nwe obtain the upper bound estimation for the mixed derivatives of the ground\neigenpairs that has the same form obtained recently for the linear eigenvalue\nproblem. The three most essential ingredients for this estimation are the\nparametric analyticity of the ground eigenpairs, the uniform boundedness of the\nground eigenpairs, and the uniform positive differences between ground\neigenvalues of linear operators. All these three ingredients need new\ntechniques and a careful investigation of the nonlinear eigenvalue problem that\nwill be presented in this paper. As an application, considering each parameter\nas a uniformly distributed random variable, we estimate the expectation of the\neigenpairs using a randomly shifted quasi-Monte Carlo lattice rule and show the\ndimension-independent error bound.",
            "author": [
                "Byeong-Ho Bahn"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03159v3",
                "http://arxiv.org/pdf/2308.03159v3"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N35 (Primary) 65D30, 35A23 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03146v1",
            "title": "Towards socially-competent and culturally-adaptive artificial agents\n  Expressive order, interactional disruptions and recovery strategies",
            "updated": "2023-08-06T15:47:56Z",
            "published": "2023-08-06T15:47:56Z",
            "summary": "The development of artificial agents for social interaction pushes to enrich\nrobots with social skills and knowledge about (local) social norms. One\npossibility is to distinguish the expressive and the functional orders during a\nhuman-robot interaction. The overarching aim of this work is to set a framework\nto make the artificial agent socially-competent beyond dyadic\ninteraction-interaction in varying multi-party social situations-and beyond\nindividual-based user personalization, thereby enlarging the current conception\nof \"culturally-adaptive\". The core idea is to provide the artificial agent with\nthe capability to handle different kinds of interactional disruptions, and\nassociated recovery strategies, in microsociology. The result is obtained by\nclassifying functional and social disruptions, and by investigating the\nrequirements a robot's architecture should satisfy to exploit such knowledge.\nThe paper also highlights how this level of competence is achieved by focusing\non just three dimensions: (i) social capability, (ii) relational role, and\n(iii) proximity, leaving aside the further complexity of full-fledged\nhuman-human interactions. Without going into technical aspects, End-to-end\nData-driven Architectures and Modular Architectures are discussed to evaluate\nthe degree to which they can exploit this new set of social and cultural\nknowledge. Finally, a list of general requirements for such agents is proposed.",
            "author": [
                "Chiara Bassetti",
                "Enrico Blanzieri",
                "Stefano Borgo",
                "Sofia Marangon"
            ],
            "link": [
                "http://dx.doi.org/10.1075/is.22021.bas",
                "http://arxiv.org/abs/2308.03146v1",
                "http://arxiv.org/pdf/2308.03146v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.MA",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03135v2",
            "title": "E-CLIP: Towards Label-efficient Event-based Open-world Understanding by\n  CLIP",
            "updated": "2023-09-10T14:19:49Z",
            "published": "2023-08-06T15:05:42Z",
            "summary": "Contrasting Language-image pertaining (CLIP) has recently shown promising\nopen-world and few-shot performance on 2D image-based recognition tasks.\nHowever, the transferred capability of CLIP to the novel event camera data\nstill remains under-explored. In particular, due to the modality gap with the\nimage-text data and the lack of large-scale datasets, achieving this goal is\nnon-trivial and thus requires significant research innovation. In this paper,\nwe propose E-CLIP, a novel and effective framework that unleashes the potential\nof CLIP for event-based recognition to compensate for the lack of large-scale\nevent-based datasets. Our work addresses two crucial challenges: 1) how to\ngeneralize CLIP's visual encoder to event data while fully leveraging events'\nunique properties, e.g., sparsity and high temporal resolution; 2) how to\neffectively align the multi-modal embeddings, i.e., image, text, and events. To\nthis end, we first introduce a novel event encoder that subtly models the\ntemporal information from events and meanwhile generates event prompts to\npromote the modality bridging. We then design a text encoder that generates\ncontent prompts and utilizes hybrid text prompts to enhance the E-CLIP's\ngeneralization ability across diverse datasets. With the proposed event\nencoder, text encoder, and original image encoder, a novel Hierarchical Triple\nContrastive Alignment (HTCA) module is introduced to jointly optimize the\ncorrelation and enable efficient knowledge transfer among the three modalities.\nWe conduct extensive experiments on two recognition benchmarks, and the results\ndemonstrate that our E-CLIP outperforms existing methods by a large margin of\n+3.94% and +4.62% on the N-Caltech dataset, respectively, in both fine-tuning\nand few-shot settings. Moreover, our E-CLIP can be flexibly extended to the\nevent retrieval task using both text or image queries, showing plausible\nperformance.",
            "author": [
                "Jiazhou Zhou",
                "Xu Zheng",
                "Yuanhuiyi Lyu",
                "Lin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03135v2",
                "http://arxiv.org/pdf/2308.03135v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03118v1",
            "title": "Level of Awareness of PSU Bayambang Campus Students towards E learning\n  Technologies",
            "updated": "2023-08-06T13:54:39Z",
            "published": "2023-08-06T13:54:39Z",
            "summary": "The study assesses the awareness of PSU Bayambang Campus students regarding\ne-learning technologies. A Quantitative Research Approach was used, gathering\ndata through a demographic questionnaire and ICT Resources assessment. The\nsurvey measured students' familiarity and knowledge of existing e-learning\ntechnologies. Around 52.50% of respondents were familiar with e learning\nconcepts, but their exposure and utilization levels need consideration.\nTechnology, Support, and Users were identified as key factors influencing\nstudent awareness. Implementation can be improved through policies and resource\nprovision. The researchers recommend integrating e learning policies, providing\nICT Resources and Infrastructure, and offering training for students and\nteachers. This research serves as a guide for policy design, enhancing the\nUniversity's learning process and facilitating better learning and interaction.",
            "author": [
                "Matthew John F. Sino Cruz",
                "Kim Eric B. Nanlabi",
                "Michael Ryan C. Peoro"
            ],
            "link": [
                "http://dx.doi.org/10.25147/ijcsr.2017.001.1.33",
                "http://arxiv.org/abs/2308.03118v1",
                "http://arxiv.org/pdf/2308.03118v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03113v1",
            "title": "Semantic-Guided Feature Distillation for Multimodal Recommendation",
            "updated": "2023-08-06T13:39:23Z",
            "published": "2023-08-06T13:39:23Z",
            "summary": "Multimodal recommendation exploits the rich multimodal information associated\nwith users or items to enhance the representation learning for better\nperformance. In these methods, end-to-end feature extractors (e.g.,\nshallow/deep neural networks) are often adopted to tailor the generic\nmultimodal features that are extracted from raw data by pre-trained models for\nrecommendation. However, compact extractors, such as shallow neural networks,\nmay find it challenging to extract effective information from complex and\nhigh-dimensional generic modality features. Conversely, DNN-based extractors\nmay encounter the data sparsity problem in recommendation. To address this\nproblem, we propose a novel model-agnostic approach called Semantic-guided\nFeature Distillation (SGFD), which employs a teacher-student framework to\nextract feature for multimodal recommendation. The teacher model first extracts\nrich modality features from the generic modality feature by considering both\nthe semantic information of items and the complementary information of multiple\nmodalities. SGFD then utilizes response-based and feature-based distillation\nloss to effectively transfer the knowledge encoded in the teacher model to the\nstudent model. To evaluate the effectiveness of our SGFD, we integrate SGFD\ninto three backbone multimodal recommendation models. Extensive experiments on\nthree public real-world datasets demonstrate that SGFD-enhanced models can\nachieve substantial improvement over their counterparts.",
            "author": [
                "Fan Liu",
                "Huilin Chen",
                "Zhiyong Cheng",
                "Liqiang Nie",
                "Mohan Kankanhalli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03113v1",
                "http://arxiv.org/pdf/2308.03113v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03099v2",
            "title": "LARCH: Large Language Model-based Automatic Readme Creation with\n  Heuristics",
            "updated": "2023-08-22T09:48:20Z",
            "published": "2023-08-06T12:28:24Z",
            "summary": "Writing a readme is a crucial aspect of software development as it plays a\nvital role in managing and reusing program code. Though it is a pain point for\nmany developers, automatically creating one remains a challenge even with the\nrecent advancements in large language models (LLMs), because it requires\ngenerating an abstract description from thousands of lines of code. In this\ndemo paper, we show that LLMs are capable of generating a coherent and\nfactually correct readmes if we can identify a code fragment that is\nrepresentative of the repository. Building upon this finding, we developed\nLARCH (LLM-based Automatic Readme Creation with Heuristics) which leverages\nrepresentative code identification with heuristics and weak supervision.\nThrough human and automated evaluations, we illustrate that LARCH can generate\ncoherent and factually correct readmes in the majority of cases, outperforming\na baseline that does not rely on representative code identification. We have\nmade LARCH open-source and provided a cross-platform Visual Studio Code\ninterface and command-line interface, accessible at\nhttps://github.com/hitachi-nlp/larch. A demo video showcasing LARCH's\ncapabilities is available at https://youtu.be/ZUKkh5ED-O4.",
            "author": [
                "Yuta Koreeda",
                "Terufumi Morishita",
                "Osamu Imaichi",
                "Yasuhiro Sogawa"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614744",
                "http://arxiv.org/abs/2308.03099v2",
                "http://arxiv.org/pdf/2308.03099v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03092v1",
            "title": "ECT: Fine-grained Edge Detection with Learned Cause Tokens",
            "updated": "2023-08-06T11:37:55Z",
            "published": "2023-08-06T11:37:55Z",
            "summary": "In this study, we tackle the challenging fine-grained edge detection task,\nwhich refers to predicting specific edges caused by reflectance, illumination,\nnormal, and depth changes, respectively. Prior methods exploit multi-scale\nconvolutional networks, which are limited in three aspects: (1) Convolutions\nare local operators while identifying the cause of edge formation requires\nlooking at far away pixels. (2) Priors specific to edge cause are fixed in\nprediction heads. (3) Using separate networks for generic and fine-grained edge\ndetection, and the constraint between them may be violated. To address these\nthree issues, we propose a two-stage transformer-based network sequentially\npredicting generic edges and fine-grained edges, which has a global receptive\nfield thanks to the attention mechanism. The prior knowledge of edge causes is\nformulated as four learnable cause tokens in a cause-aware decoder design.\nFurthermore, to encourage the consistency between generic edges and\nfine-grained edges, an edge aggregation and alignment loss is exploited. We\nevaluate our method on the public benchmark BSDS-RIND and several newly derived\nbenchmarks, and achieve new state-of-the-art results. Our code, data, and\nmodels are publicly available at https://github.com/Daniellli/ECT.git.",
            "author": [
                "Shaocong Xu",
                "Xiaoxue Chen",
                "Yuhang Zheng",
                "Guyue Zhou",
                "Yurong Chen",
                "Hongbin Zha",
                "Hao Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03092v1",
                "http://arxiv.org/pdf/2308.03092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03081v1",
            "title": "Using Overlapping Methods to Counter Adversaries in Community Detection",
            "updated": "2023-08-06T10:23:32Z",
            "published": "2023-08-06T10:23:32Z",
            "summary": "When dealing with large graphs, community detection is a useful data triage\ntool that can identify subsets of the network that a data analyst should\ninvestigate. In an adversarial scenario, the graph may be manipulated to avoid\nscrutiny of certain nodes by the analyst. Robustness to such behavior is an\nimportant consideration for data analysts in high-stakes scenarios such as\ncyber defense and counterterrorism. In this paper, we evaluate the use of\noverlapping community detection methods in the presence of adversarial attacks\naimed at lowering the priority of a specific vertex. We formulate the data\nanalyst's choice as a Stackelberg game in which the analyst chooses a community\ndetection method and the attacker chooses an attack strategy in response.\nApplying various attacks from the literature to seven real network datasets, we\nfind that, when the attacker has a sufficient budget, overlapping community\ndetection methods outperform non-overlapping methods, often overwhelmingly so.\nThis is the case when the attacker can only add edges that connect to the\ntarget and when the capability is added to add edges between neighbors of the\ntarget. We also analyze the tradeoff between robustness in the presence of an\nattack and performance when there is no attack. Our extensible analytic\nframework enables network data analysts to take these considerations into\naccount and incorporate new attacks and community detection methods as they are\ndeveloped.",
            "author": [
                "Benjamin A. Miller",
                "Kevin Chan",
                "Tina Eliassi-Rad"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03081v1",
                "http://arxiv.org/pdf/2308.03081v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03066v1",
            "title": "Algebraic degrees of quasi-abelian semi-Cayley digraphs",
            "updated": "2023-08-06T09:25:35Z",
            "published": "2023-08-06T09:25:35Z",
            "summary": "For a digraph $\\Gamma$, if $F$ is the smallest field that contains all roots\nof the characteristic polynomial of the adjacency matrix of $\\Gamma$, then $F$\nis called the splitting field of $\\Gamma$. The extension degree of $F$ over the\nfield of rational numbers $\\mathbb{Q}$ is said to be the algebraic degree of\n$\\Gamma$. A digraph is a semi-Cayley digraph over a group $G$ if it admits $G$\nas a semiregular automorphism group with two orbits of equal size. A\nsemi-Cayley digraph $\\mathrm{SC}(G,T_{11},T_{22},T_{12},T_{21})$ is called\nquasi-abelian if each of $T_{11},T_{22},T_{12}$ and $T_{21}$ is a union of some\nconjugacy classes of $G$. This paper determines the splitting field and the\nalgebraic degree of a quasi-abelian semi-Cayley digraph over any finite group\nin terms of irreducible characters of groups. This work generalizes the\nprevious works on algebraic degrees of Cayley graphs over abelian groups and\nany group having a subgroup of index 2, and semi-Cayley digraphs over abelian\ngroups.",
            "author": [
                "Shixin Wang",
                "Majid Arezoomand",
                "Tao Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03066v1",
                "http://arxiv.org/pdf/2308.03066v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03061v2",
            "title": "InterTracker: Discovering and Tracking General Objects Interacting with\n  Hands in the Wild",
            "updated": "2023-08-14T12:44:57Z",
            "published": "2023-08-06T09:09:17Z",
            "summary": "Understanding human interaction with objects is an important research topic\nfor embodied Artificial Intelligence and identifying the objects that humans\nare interacting with is a primary problem for interaction understanding.\nExisting methods rely on frame-based detectors to locate interacting objects.\nHowever, this approach is subjected to heavy occlusions, background clutter,\nand distracting objects. To address the limitations, in this paper, we propose\nto leverage spatio-temporal information of hand-object interaction to track\ninteractive objects under these challenging cases. Without prior knowledge of\nthe general objects to be tracked like object tracking problems, we first\nutilize the spatial relation between hands and objects to adaptively discover\nthe interacting objects from the scene. Second, the consistency and continuity\nof the appearance of objects between successive frames are exploited to track\nthe objects. With this tracking formulation, our method also benefits from\ntraining on large-scale general object-tracking datasets. We further curate a\nvideo-level hand-object interaction dataset for testing and evaluation from\n100DOH. The quantitative results demonstrate that our proposed method\noutperforms the state-of-the-art methods. Specifically, in scenes with\ncontinuous interaction with different objects, we achieve an impressive\nimprovement of about 10% as evaluated using the Average Precision (AP) metric.\nOur qualitative findings also illustrate that our method can produce more\ncontinuous trajectories for interacting objects.",
            "author": [
                "Yanyan Shao",
                "Qi Ye",
                "Wenhan Luo",
                "Kaihao Zhang",
                "Jiming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03061v2",
                "http://arxiv.org/pdf/2308.03061v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03043v2",
            "title": "3D-EX : A Unified Dataset of Definitions and Dictionary Examples",
            "updated": "2023-08-11T12:07:52Z",
            "published": "2023-08-06T07:59:12Z",
            "summary": "Definitions are a fundamental building block in lexicography, linguistics and\ncomputational semantics. In NLP, they have been used for retrofitting word\nembeddings or augmenting contextual representations in language models.\nHowever, lexical resources containing definitions exhibit a wide range of\nproperties, which has implications in the behaviour of models trained and\nevaluated on them. In this paper, we introduce 3D- EX , a dataset that aims to\nfill this gap by combining well-known English resources into one centralized\nknowledge repository in the form of <term, definition, example> triples. 3D- EX\nis a unified evaluation framework with carefully pre-computed\ntrain/validation/test splits to prevent memorization. We report experimental\nresults that suggest that this dataset could be effectively leveraged in\ndownstream NLP tasks. Code and data are available at\nhttps://github.com/F-Almeman/3D-EX .",
            "author": [
                "Fatemah Almeman",
                "Hadi Sheikhi",
                "Luis Espinosa-Anke"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03043v2",
                "http://arxiv.org/pdf/2308.03043v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03042v1",
            "title": "Achievable Information Rate Analysis in Diffusive Channels with Memory\n  and Markov Source",
            "updated": "2023-08-06T07:52:58Z",
            "published": "2023-08-06T07:52:58Z",
            "summary": "This paper explores the Achievable Information Rate (AIR) of a diffusive\nMolecular Communication (MC) channel featuring a fully absorbing receiver that\ncounts the absorbed particles during symbol time intervals (STIs) and resets\nthe counter at the start of each interval. The MC channel, influenced by memory\neffect, experiences inter-symbol interference (ISI) arising from the molecules'\ndelayed arrival. The channel's memory is quantified as an integer multiple of\nthe STI and a single-sample memoryless detector is employed to mitigate\ncomplexity in computing the mutual information (MI). To maximize MI, the\ndetector threshold is optimized under Gaussian approximation of its input. The\nchannel's MI is calculated, considering the influence of ISI, in the context of\nbinary concentration shift keying modulation. Two distinct scenarios were\nconsidered; independent and correlated source-generated symbols, the latter\nmodeled as a first-order Markov process. For each communication scenario, two\ndegrees of knowledge: ISI-Aware and ISI-Unaware were considered. Remarkably, it\nis demonstrated that employing a correlated source enables the attainment of\nhigher capacity. The results indicate that the capacity-achieving input\ndistribution is not necessarily uniform. Notably, when the STI is small,\ncorresponding to the case of strong ISI, the maximum AIR is not achieved\nthrough equiprobable symbol transmission.",
            "author": [
                "Fardad Vakilipoor",
                "Luca Barletta",
                "Stefano Bregni",
                "Maurizio Magarini"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03042v1",
                "http://arxiv.org/pdf/2308.03042v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.05928v1",
            "title": "Network Ecology of Marriage",
            "updated": "2023-08-06T07:07:51Z",
            "published": "2023-08-06T07:07:51Z",
            "summary": "The practice of marriage is an understudied phenomenon in behavioural\nsciences despite being ubiquitous across human cultures. This modelling paper\nshows that replacing distant direct kin with in-laws increases the\ninterconnectedness of the family social network graph, which allows more\ncooperative and larger groups. In this framing, marriage can be seen as a\nsocial technology that reduces free-riding within collaborative group. This\napproach offers a solution to the puzzle of why our species has this particular\nform of regulating mating behaviour, uniquely among pair-bonded animals.",
            "author": [
                "Tamas David-Barrett"
            ],
            "link": [
                "http://arxiv.org/abs/2310.05928v1",
                "http://arxiv.org/pdf/2310.05928v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.SI",
                "econ.TH",
                "q-bio.PE",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03035v1",
            "title": "Serverless Federated AUPRC Optimization for Multi-Party Collaborative\n  Imbalanced Data Mining",
            "updated": "2023-08-06T06:51:32Z",
            "published": "2023-08-06T06:51:32Z",
            "summary": "Multi-party collaborative training, such as distributed learning and\nfederated learning, is used to address the big data challenges. However,\ntraditional multi-party collaborative training algorithms were mainly designed\nfor balanced data mining tasks and are intended to optimize accuracy\n(\\emph{e.g.}, cross-entropy). The data distribution in many real-world\napplications is skewed and classifiers, which are trained to improve accuracy,\nperform poorly when applied to imbalanced data tasks since models could be\nsignificantly biased toward the primary class. Therefore, the Area Under\nPrecision-Recall Curve (AUPRC) was introduced as an effective metric. Although\nsingle-machine AUPRC maximization methods have been designed, multi-party\ncollaborative algorithm has never been studied. The change from the\nsingle-machine to the multi-party setting poses critical challenges.\n  To address the above challenge, we study the serverless multi-party\ncollaborative AUPRC maximization problem since serverless multi-party\ncollaborative training can cut down the communications cost by avoiding the\nserver node bottleneck, and reformulate it as a conditional stochastic\noptimization problem in a serverless multi-party collaborative learning setting\nand propose a new ServerLess biAsed sTochastic gradiEnt (SLATE) algorithm to\ndirectly optimize the AUPRC. After that, we use the variance reduction\ntechnique and propose ServerLess biAsed sTochastic gradiEnt with Momentum-based\nvariance reduction (SLATE-M) algorithm to improve the convergence rate, which\nmatches the best theoretical convergence result reached by the single-machine\nonline method. To the best of our knowledge, this is the first work to solve\nthe multi-party collaborative AUPRC maximization problem.",
            "author": [
                "Xidong Wu",
                "Zhengmian Hu",
                "Jian Pei",
                "Heng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03035v1",
                "http://arxiv.org/pdf/2308.03035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03028v1",
            "title": "Pre-Trained Large Language Models for Industrial Control",
            "updated": "2023-08-06T06:01:18Z",
            "published": "2023-08-06T06:01:18Z",
            "summary": "For industrial control, developing high-performance controllers with few\nsamples and low technical debt is appealing. Foundation models, possessing rich\nprior knowledge obtained from pre-training with Internet-scale corpus, have the\npotential to be a good controller with proper prompts. In this paper, we take\nHVAC (Heating, Ventilation, and Air Conditioning) building control as an\nexample to examine the ability of GPT-4 (one of the first-tier foundation\nmodels) as the controller. To control HVAC, we wrap the task as a language game\nby providing text including a short description for the task, several selected\ndemonstrations, and the current observation to GPT-4 on each step and execute\nthe actions responded by GPT-4. We conduct series of experiments to answer the\nfollowing questions: 1)~How well can GPT-4 control HVAC? 2)~How well can GPT-4\ngeneralize to different scenarios for HVAC control? 3) How different parts of\nthe text context affect the performance? In general, we found GPT-4 achieves\nthe performance comparable to RL methods with few samples and low technical\ndebt, indicating the potential of directly applying foundation models to\nindustrial control tasks.",
            "author": [
                "Lei Song",
                "Chuheng Zhang",
                "Li Zhao",
                "Jiang Bian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03028v1",
                "http://arxiv.org/pdf/2308.03028v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03026v1",
            "title": "CDT-Dijkstra: Fast Planning of Globally Optimal Paths for All Points in\n  2D Continuous Space",
            "updated": "2023-08-06T05:56:14Z",
            "published": "2023-08-06T05:56:14Z",
            "summary": "The Dijkstra algorithm is a classic path planning method, which in a discrete\ngraph space, can start from a specified source node and find the shortest path\nbetween the source node and all other nodes in the graph. However, to the best\nof our knowledge, there is no effective method that achieves a function similar\nto that of the Dijkstra's algorithm in a continuous space. In this study, an\noptimal path planning algorithm called convex dissection topology\n(CDT)-Dijkstra is developed, which can quickly compute the global optimal path\nfrom one point to all other points in a 2D continuous space. CDT-Dijkstra is\nmainly divided into two stages: SetInit and GetGoal. In SetInit, the algorithm\ncan quickly obtain the optimal CDT encoding set of all the cut lines based on\nthe initial point x_{init}. In GetGoal, the algorithm can return the global\noptimal path of any goal point at an extremely high speed. In this study, we\npropose and prove the planning principle of considering only the points on the\ncutlines, thus reducing the state space of the distance optimal path planning\ntask from 2D to 1D. In addition, we propose a fast method to find the optimal\npath in a homogeneous class and theoretically prove the correctness of the\nmethod. Finally, by testing in a series of environments, the experimental\nresults demonstrate that CDT-Dijkstra not only plans the optimal path from all\npoints at once, but also has a significant advantage over advanced algorithms\nconsidering certain complex tasks.",
            "author": [
                "Jinyuan Liu",
                "Minglei Fu",
                "Wenan Zhang",
                "Bo Chen",
                "Ryhor Prakapovich",
                "Uladzislau Sychou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03026v1",
                "http://arxiv.org/pdf/2308.03026v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.07403v1",
            "title": "A fast algorithm for All-Pairs-Shortest-Paths suitable for neural\n  networks",
            "updated": "2023-08-06T05:43:24Z",
            "published": "2023-08-06T05:43:24Z",
            "summary": "Given a directed graph of nodes and edges connecting them, a common problem\nis to find the shortest path between any two nodes. Here I show that the\nshortest path distances can be found by a simple matrix inversion: If the edges\nare given by the adjacency matrix $A_{ij}$ then with a suitably small value of\n$\\gamma$ the shortest path distances are $$ D_{ij} = \\operatorname{ceil} \\left(\n{\\frac{\\log {\\left[ {\\left({\\mathbf{1}}-\\gamma {\\mathbf{A}}\\right)^{-1}}\n\\right]}_{ij}}{\\log \\gamma}} \\right)$$ I derive some bounds on $\\gamma$ useful\nfor a practical application. Even when the distance function is not globally\naccurate across the entire graph, it still works locally to instruct pursuit of\nthe shortest path. In this mode, it also extends to weighted graphs with\npositive edge weights. For a wide range of dense graphs this distance function\nis computationally faster than the best available alternative. Finally I show\nthat this method leads naturally to a neural network solution of the\nall-pairs-shortest-path problem.",
            "author": [
                "Markus Meister"
            ],
            "link": [
                "http://arxiv.org/abs/2308.07403v1",
                "http://arxiv.org/pdf/2308.07403v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03021v1",
            "title": "All-in-one Multi-degradation Image Restoration Network via Hierarchical\n  Degradation Representation",
            "updated": "2023-08-06T04:51:41Z",
            "published": "2023-08-06T04:51:41Z",
            "summary": "The aim of image restoration is to recover high-quality images from distorted\nones. However, current methods usually focus on a single task (\\emph{e.g.},\ndenoising, deblurring or super-resolution) which cannot address the needs of\nreal-world multi-task processing, especially on mobile devices. Thus,\ndeveloping an all-in-one method that can restore images from various unknown\ndistortions is a significant challenge. Previous works have employed\ncontrastive learning to learn the degradation representation from observed\nimages, but this often leads to representation drift caused by deficient\npositive and negative pairs. To address this issue, we propose a novel\nAll-in-one Multi-degradation Image Restoration Network (AMIRNet) that can\neffectively capture and utilize accurate degradation representation for image\nrestoration. AMIRNet learns a degradation representation for unknown degraded\nimages by progressively constructing a tree structure through clustering,\nwithout any prior knowledge of degradation information. This tree-structured\nrepresentation explicitly reflects the consistency and discrepancy of various\ndistortions, providing a specific clue for image restoration. To further\nenhance the performance of the image restoration network and overcome domain\ngaps caused by unknown distortions, we design a feature transform block (FTB)\nthat aligns domains and refines features with the guidance of the degradation\nrepresentation. We conduct extensive experiments on multiple distorted\ndatasets, demonstrating the effectiveness of our method and its advantages over\nstate-of-the-art restoration methods both qualitatively and quantitatively.",
            "author": [
                "Cheng Zhang",
                "Yu Zhu",
                "Qingsen Yan",
                "Jinqiu Sun",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03021v1",
                "http://arxiv.org/pdf/2308.03021v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03000v1",
            "title": "StyleEDL: Style-Guided High-order Attention Network for Image Emotion\n  Distribution Learning",
            "updated": "2023-08-06T03:22:46Z",
            "published": "2023-08-06T03:22:46Z",
            "summary": "Emotion distribution learning has gained increasing attention with the\ntendency to express emotions through images. As for emotion ambiguity arising\nfrom humans' subjectivity, substantial previous methods generally focused on\nlearning appropriate representations from the holistic or significant part of\nimages. However, they rarely consider establishing connections with the\nstylistic information although it can lead to a better understanding of images.\nIn this paper, we propose a style-guided high-order attention network for image\nemotion distribution learning termed StyleEDL, which interactively learns\nstylistic-aware representations of images by exploring the hierarchical\nstylistic information of visual contents. Specifically, we consider exploring\nthe intra- and inter-layer correlations among GRAM-based stylistic\nrepresentations, and meanwhile exploit an adversary-constrained high-order\nattention mechanism to capture potential interactions between subtle visual\nparts. In addition, we introduce a stylistic graph convolutional network to\ndynamically generate the content-dependent emotion representations to benefit\nthe final emotion distribution learning. Extensive experiments conducted on\nseveral benchmark datasets demonstrate the effectiveness of our proposed\nStyleEDL compared to state-of-the-art methods. The implementation is released\nat: https://github.com/liuxianyi/StyleEDL.",
            "author": [
                "Peiguang Jing",
                "Xianyi Liu",
                "Ji Wang",
                "Yinwei Wei",
                "Liqiang Nie",
                "Yuting Su"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03000v1",
                "http://arxiv.org/pdf/2308.03000v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02992v1",
            "title": "Binary Code Similarity Detection",
            "updated": "2023-08-06T02:24:42Z",
            "published": "2023-08-06T02:24:42Z",
            "summary": "Binary code similarity detection is to detect the similarity of code at\nbinary (assembly) level without source code. Existing works have their\nlimitations when dealing with mutated binary code generated by different\ncompiling options. In this paper, we propose a novel approach to addressing\nthis problem. By inspecting the binary code, we found that generally, within a\nfunction, some instructions aim to calculate (prepare) values for other\ninstructions. The latter instructions are defined by us as key instructions.\nCurrently, we define four categories of key instructions: calling subfunctions,\ncomparing instruction, returning instruction, and memory-store instruction.\nThus if we symbolically execute similar binary codes, symbolic values at these\nkey instructions are expected to be similar. As such, we implement a prototype\ntool, which has three steps. First, it symbolically executes binary code;\nSecond, it extracts symbolic values at defined key instructions into a graph;\nLast, it compares the symbolic graph similarity. In our implementation, we also\naddress some problems, including path explosion and loop handling.",
            "author": [
                "Zian Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02992v1",
                "http://arxiv.org/pdf/2308.02992v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02984v1",
            "title": "Decision Knowledge Graphs: Construction of and Usage in Question\n  Answering for Clinical Practice Guidelines",
            "updated": "2023-08-06T01:38:40Z",
            "published": "2023-08-06T01:38:40Z",
            "summary": "In the medical domain, several disease treatment procedures have been\ndocumented properly as a set of instructions known as Clinical Practice\nGuidelines (CPGs). CPGs have been developed over the years on the basis of past\ntreatments, and are updated frequently. A doctor treating a particular patient\ncan use these CPGs to know how past patients with similar conditions were\ntreated successfully and can find the recommended treatment procedure. In this\npaper, we present a Decision Knowledge Graph (DKG) representation to store CPGs\nand to perform question-answering on CPGs. CPGs are very complex and no\nexisting representation is suitable to perform question-answering and searching\ntasks on CPGs. As a result, doctors and practitioners have to manually wade\nthrough the guidelines, which is inefficient. Representation of CPGs is\nchallenging mainly due to frequent updates on CPGs and decision-based\nstructure. Our proposed DKG has a decision dimension added to a Knowledge Graph\n(KG) structure, purported to take care of decision based behavior of CPGs.\nUsing this DKG has shown 40\\% increase in accuracy compared to fine-tuned\nBioBert model in performing question-answering on CPGs. To the best of our\nknowledge, ours is the first attempt at creating DKGs and using them for\nrepresenting CPGs.",
            "author": [
                "Vasudhan Varma Kandula",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02984v1",
                "http://arxiv.org/pdf/2308.02984v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02982v1",
            "title": "Beyond First Impressions: Integrating Joint Multi-modal Cues for\n  Comprehensive 3D Representation",
            "updated": "2023-08-06T01:11:40Z",
            "published": "2023-08-06T01:11:40Z",
            "summary": "In recent years, 3D representation learning has turned to 2D vision-language\npre-trained models to overcome data scarcity challenges. However, existing\nmethods simply transfer 2D alignment strategies, aligning 3D representations\nwith single-view 2D images and coarse-grained parent category text. These\napproaches introduce information degradation and insufficient synergy issues,\nleading to performance loss. Information degradation arises from overlooking\nthe fact that a 3D representation should be equivalent to a series of\nmulti-view images and more fine-grained subcategory text. Insufficient synergy\nneglects the idea that a robust 3D representation should align with the joint\nvision-language space, rather than independently aligning with each modality.\nIn this paper, we propose a multi-view joint modality modeling approach, termed\nJM3D, to obtain a unified representation for point cloud, text, and image.\nSpecifically, a novel Structured Multimodal Organizer (SMO) is proposed to\naddress the information degradation issue, which introduces contiguous\nmulti-view images and hierarchical text to enrich the representation of vision\nand language modalities. A Joint Multi-modal Alignment (JMA) is designed to\ntackle the insufficient synergy problem, which models the joint modality by\nincorporating language knowledge into the visual modality. Extensive\nexperiments on ModelNet40 and ScanObjectNN demonstrate the effectiveness of our\nproposed method, JM3D, which achieves state-of-the-art performance in zero-shot\n3D classification. JM3D outperforms ULIP by approximately 4.3% on PointMLP and\nachieves an improvement of up to 6.5% accuracy on PointNet++ in top-1 accuracy\nfor zero-shot 3D classification on ModelNet40. The source code and trained\nmodels for all our experiments are publicly available at\nhttps://github.com/Mr-Neko/JM3D.",
            "author": [
                "Haowei Wang",
                "Jiji Tang",
                "Jiayi Ji",
                "Xiaoshuai Sun",
                "Rongsheng Zhang",
                "Yiwei Ma",
                "Minda Zhao",
                "Lincheng Li",
                "zeng zhao",
                "Tangjie Lv",
                "Rongrong Ji"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611767",
                "http://arxiv.org/abs/2308.02982v1",
                "http://arxiv.org/pdf/2308.02982v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02981v1",
            "title": "Factoring Pattern-Free Permutations into Separable ones",
            "updated": "2023-08-06T01:09:16Z",
            "published": "2023-08-06T01:09:16Z",
            "summary": "We show that for any permutation $\\pi$ there exists an integer $k_{\\pi}$ such\nthat every permutation avoiding $\\pi$ as a pattern is a product of at most\n$k_{\\pi}$ separable permutations. In other words, every strict class $\\mathcal\nC$ of permutations is contained in a bounded power of the class of separable\npermutations. This factorisation can be computed in linear time, for any fixed\n$\\pi$. The central tool for our result is a notion of width of permutations,\nintroduced by Guillemot and Marx [SODA '14] to efficiently detect patterns, and\nlater generalised to graphs and matrices under the name of twin-width.\nSpecifically, our factorisation is inspired by the decomposition used in the\nrecent result that graphs with bounded twin-width are polynomially\n$\\chi$-bounded. As an application, we show that there is a fixed class\n$\\mathcal C$ of graphs of bounded twin-width such that every class of bounded\ntwin-width is a first-order transduction of $\\mathcal C$.",
            "author": [
                "\u00c9douard Bonnet",
                "Romain Bourneuf",
                "Colin Geniet",
                "St\u00e9phan Thomass\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02981v1",
                "http://arxiv.org/pdf/2308.02981v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "cs.DS",
                "cs.LO",
                "05A05",
                "G.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02978v1",
            "title": "On the automorphism group of a putative Conway 99-graph",
            "updated": "2023-08-06T00:31:47Z",
            "published": "2023-08-06T00:31:47Z",
            "summary": "Let $\\Gamma$ be a {Conway 99-graph}, that is, a strongly regular graph with\nparameters $(99,14,1,2)$. In Makhnev and Minakova (On automorphisms of strongly\nregular graphs with parameters $\\lambda =1$, $\\mu= 2$, Discrete Math.\\ Appl.\\\n14 (2) (2004) 201-210), the authors prove that the automorphism group $G$ of\n$\\Gamma$ must have order dividing $2\\cdot 3^3\\cdot 7\\cdot 11$. They further\nshow that if $|G|$ is divisible by $2$ then $|G|$ must divide $42$. In the\npresent paper, we refine these results by proving that divisibility by $7$\nimplies $G \\cong\\mathbb Z_7$. As a consequence, divisibility by $2$ implies\n$|G|$ divides $6$, \\ie $G$ is isomorphic to one of $\\mathbb Z_2, \\mathbb Z_6,\nS_3$.",
            "author": [
                "Patrick G. Cesarz",
                "Andrew J. Woldar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02978v1",
                "http://arxiv.org/pdf/2308.02978v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05E18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02975v1",
            "title": "On the spectral radius of clique trees with a given zero forcing number",
            "updated": "2023-08-06T00:13:27Z",
            "published": "2023-08-06T00:13:27Z",
            "summary": "Let $G(n,k)$ be the class of clique trees on $n$ vertices and zero forcing\nnumber $k$, where $\\left \\lfloor \\frac{n}{2} \\right \\rfloor + 1 \\le k \\le n-1$\nand each block is a clique of size at least $3$. In this article, we proved the\nexistence and uniqueness of a clique tree in $G(n,k)$ that attains maximal\nspectral radius among all graphs in $G(n,k)$. We also provide an upper bound\nfor the spectral radius of the extremal graph.",
            "author": [
                "Joyentanuj Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02975v1",
                "http://arxiv.org/pdf/2308.02975v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C50, 05C15, 15A18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02968v2",
            "title": "Robust estimation of exposure ratios in multi-exposure image stacks",
            "updated": "2023-08-12T10:36:52Z",
            "published": "2023-08-05T23:42:59Z",
            "summary": "Merging multi-exposure image stacks into a high dynamic range (HDR) image\nrequires knowledge of accurate exposure times. When exposure times are\ninaccurate, for example, when they are extracted from a camera's EXIF metadata,\nthe reconstructed HDR images reveal banding artifacts at smooth gradients. To\nremedy this, we propose to estimate exposure ratios directly from the input\nimages. We derive the exposure time estimation as an optimization problem, in\nwhich pixels are selected from pairs of exposures to minimize estimation error\ncaused by camera noise. When pixel values are represented in the logarithmic\ndomain, the problem can be solved efficiently using a linear solver. We\ndemonstrate that the estimation can be easily made robust to pixel misalignment\ncaused by camera or object motion by collecting pixels from multiple spatial\ntiles. The proposed automatic exposure estimation and alignment eliminates\nbanding artifacts in popular datasets and is essential for applications that\nrequire physically accurate reconstructions, such as measuring the modulation\ntransfer function of a display. The code for the method is available.",
            "author": [
                "Param Hanji",
                "Rafa\u0142 K. Mantiuk"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TCI.2023.3301338",
                "http://arxiv.org/abs/2308.02968v2",
                "http://arxiv.org/pdf/2308.02968v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02944v1",
            "title": "dPASP: A Comprehensive Differentiable Probabilistic Answer Set\n  Programming Environment For Neurosymbolic Learning and Reasoning",
            "updated": "2023-08-05T19:36:58Z",
            "published": "2023-08-05T19:36:58Z",
            "summary": "We present dPASP, a novel declarative probabilistic logic programming\nframework for differentiable neuro-symbolic reasoning. The framework allows for\nthe specification of discrete probabilistic models with neural predicates,\nlogic constraints and interval-valued probabilistic choices, thus supporting\nmodels that combine low-level perception (images, texts, etc), common-sense\nreasoning, and (vague) statistical knowledge. To support all such features, we\ndiscuss the several semantics for probabilistic logic programs that can express\nnondeterministic, contradictory, incomplete and/or statistical knowledge. We\nalso discuss how gradient-based learning can be performed with neural\npredicates and probabilistic choices under selected semantics. We then describe\nan implemented package that supports inference and learning in the language,\nalong with several example programs. The package requires minimal user\nknowledge of deep learning system's inner workings, while allowing end-to-end\ntraining of rather sophisticated models and loss functions.",
            "author": [
                "Renato Lui Geh",
                "Jonas Gon\u00e7alves",
                "Igor Cataneo Silveira",
                "Denis Deratani Mau\u00e1",
                "Fabio Gagliardi Cozman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02944v1",
                "http://arxiv.org/pdf/2308.02944v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.LO",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02938v1",
            "title": "Fundamental Groups of Hamming Graphs",
            "updated": "2023-08-05T18:46:57Z",
            "published": "2023-08-05T18:46:57Z",
            "summary": "Recently there has been growing interest in discrete homotopies and\nhomotopies of graphs beyond treating graphs as 1-dimensional simplicial spaces.\nOne such type of homotopy is $\\times$-homotopy. Recent work by Chih-Scull has\ndeveloped a homotopy category, a fundamental group for graphs under this\nhomotopy, and a way of computing covers of graphs that lift homotopy via this\nfundamental group. In this paper, we compute the fundamental groups of all\nHamming graphs, show that they are direct products of cyclic groups, and use\nthis result to describe some $\\times$-homotopy covers of Hamming graphs.",
            "author": [
                "Keira Behal",
                "Tien Chih"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02938v1",
                "http://arxiv.org/pdf/2308.02938v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C25 05C25 05C25 05C25, 05C76, 05E18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02933v2",
            "title": "InnovationInsights: A Visual Analytics Approach for Understanding the\n  Dual Frontiers of Science and Technology",
            "updated": "2023-08-08T18:00:44Z",
            "published": "2023-08-05T18:23:06Z",
            "summary": "Science has long been viewed as a key driver of economic growth and rising\nstandards of living. Knowledge about how scientific advances support\nmarketplace inventions is therefore essential for understanding the role of\nscience in propelling real-world applications and technological progress. The\nincreasing availability of large-scale datasets tracing scientific publications\nand patented inventions and the complex interactions among them offers us new\nopportunities to explore the evolving dual frontiers of science and technology\nat an unprecedented level of scale and detail. However, we lack suitable visual\nanalytics approaches to analyze such complex interactions effectively. Here we\nintroduce InnovationInsights, an interactive visual analysis system for\nresearchers, research institutions, and policymakers to explore the complex\nlinkages between science and technology, and to identify critical innovations,\ninventors, and potential partners. The system first identifies important\nassociations between scientific papers and patented inventions through a set of\nstatistical measures introduced by our experts from the field of the Science of\nScience. A series of visualization views are then used to present these\nassociations in the data context. In particular, we introduce the Interplay\nGraph to visualize patterns and insights derived from the data, helping users\neffectively navigate citation relationships between papers and patents. This\nvisualization thereby helps them identify the origins of technical inventions\nand the impact of scientific research. We evaluate the system through two case\nstudies with experts followed by expert interviews. We further engage a premier\nresearch institution to test-run the system, helping its institution leaders to\nextract new insights for innovation.",
            "author": [
                "Yifang Wang",
                "Yifan Qian",
                "Xiaoyu Qi",
                "Nan Cao",
                "Dashun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02933v2",
                "http://arxiv.org/pdf/2308.02933v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02927v1",
            "title": "Subquadratic Multivalued Asynchronous Byzantine Agreement WHP",
            "updated": "2023-08-05T17:36:42Z",
            "published": "2023-08-05T17:36:42Z",
            "summary": "There have been several reductions from multivalued consensus to binary\nconsensus over the past 20 years. To the best of our knowledge, none of them\nsolved it for Byzantine asynchronous settings. In this paper, we close this\ngap. Moreover, we do so in subquadratic communication, using newly developed\nsubquadratic binary Byzantine Agreement techniques.",
            "author": [
                "Shir Cohen",
                "Idit Keidar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02927v1",
                "http://arxiv.org/pdf/2308.02927v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02918v2",
            "title": "Spectral Ranking Inferences based on General Multiway Comparisons",
            "updated": "2023-08-13T13:00:00Z",
            "published": "2023-08-05T16:31:32Z",
            "summary": "This paper studies the performance of the spectral method in the estimation\nand uncertainty quantification of the unobserved preference scores of compared\nentities in a very general and more realistic setup in which the comparison\ngraph consists of hyper-edges of possible heterogeneous sizes and the number of\ncomparisons can be as low as one for a given hyper-edge. Such a setting is\npervasive in real applications, circumventing the need to specify the graph\nrandomness and the restrictive homogeneous sampling assumption imposed in the\ncommonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models.\nFurthermore, in the scenarios when the BTL or PL models are appropriate, we\nunravel the relationship between the spectral estimator and the Maximum\nLikelihood Estimator (MLE). We discover that a two-step spectral method, where\nwe apply the optimal weighting estimated from the equal weighting vanilla\nspectral method, can achieve the same asymptotic efficiency as the MLE. Given\nthe asymptotic distributions of the estimated preference scores, we also\nintroduce a comprehensive framework to carry out both one-sample and two-sample\nranking inferences, applicable to both fixed and random graph settings. It is\nnoteworthy that it is the first time effective two-sample rank testing methods\nare proposed. Finally, we substantiate our findings via comprehensive numerical\nsimulations and subsequently apply our developed methodologies to perform\nstatistical inferences on statistics journals and movie rankings.",
            "author": [
                "Jianqing Fan",
                "Zhipeng Lou",
                "Weichen Wang",
                "Mengxin Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02918v2",
                "http://arxiv.org/pdf/2308.02918v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02916v2",
            "title": "Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery\n  Ticket",
            "updated": "2023-08-10T18:10:13Z",
            "published": "2023-08-05T16:21:12Z",
            "summary": "Graph Lottery Ticket (GLT), a combination of core subgraph and sparse\nsubnetwork, has been proposed to mitigate the computational cost of deep Graph\nNeural Networks (GNNs) on large input graphs while preserving original\nperformance. However, the winning GLTs in exisiting studies are obtained by\napplying iterative magnitude-based pruning (IMP) without re-evaluating and\nre-considering the pruned information, which disregards the dynamic changes in\nthe significance of edges/weights during graph/model structure pruning, and\nthus limits the appeal of the winning tickets. In this paper, we formulate a\nconjecture, i.e., existing overlooked valuable information in the pruned graph\nconnections and model parameters which can be re-grouped into GLT to enhance\nthe final performance. Specifically, we propose an adversarial complementary\nerasing (ACE) framework to explore the valuable information from the pruned\ncomponents, thereby developing a more powerful GLT, referred to as the ACE-GLT.\nThe main idea is to mine valuable information from pruned edges/weights after\neach round of IMP, and employ the ACE technique to refine the GLT processing.\nFinally, experimental results demonstrate that our ACE-GLT outperforms existing\nmethods for searching GLT in diverse tasks. Our code will be made publicly\navailable.",
            "author": [
                "Yuwen Wang",
                "Shunyu Liu",
                "Kaixuan Chen",
                "Tongtian Zhu",
                "Ji Qiao",
                "Mengjie Shi",
                "Yuanyu Wan",
                "Mingli Song"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02916v2",
                "http://arxiv.org/pdf/2308.02916v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02914v2",
            "title": "Anomaly Detection in Global Financial Markets with Graph Neural Networks\n  and Nonextensive Entropy",
            "updated": "2023-08-09T02:47:17Z",
            "published": "2023-08-05T16:12:26Z",
            "summary": "Anomaly detection is a challenging task, particularly in systems with many\nvariables. Anomalies are outliers that statistically differ from the analyzed\ndata and can arise from rare events, malfunctions, or system misuse. This study\ninvestigated the ability to detect anomalies in global financial markets\nthrough Graph Neural Networks (GNN) considering an uncertainty scenario\nmeasured by a nonextensive entropy. The main findings show that the complex\nstructure of highly correlated assets decreases in a crisis, and the number of\nanomalies is statistically different for nonextensive entropy parameters\nconsidering before, during, and after crisis.",
            "author": [
                "Kleyton da Costa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02914v2",
                "http://arxiv.org/pdf/2308.02914v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "q-fin.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02903v1",
            "title": "LaDA: Latent Dialogue Action For Zero-shot Cross-lingual Neural Network\n  Language Modeling",
            "updated": "2023-08-05T15:51:45Z",
            "published": "2023-08-05T15:51:45Z",
            "summary": "Cross-lingual adaptation has proven effective in spoken language\nunderstanding (SLU) systems with limited resources. Existing methods are\nfrequently unsatisfactory for intent detection and slot filling, particularly\nfor distant languages that differ significantly from the source language in\nscripts, morphology, and syntax. Latent Dialogue Action (LaDA) layer is\nproposed to optimize decoding strategy in order to address the aforementioned\nissues. The model consists of an additional layer of latent dialogue action. It\nenables our model to improve a system's capability of handling conversations\nwith complex multilingual intent and slot values of distant languages. To the\nbest of our knowledge, this is the first exhaustive investigation of the use of\nlatent variables for optimizing cross-lingual SLU policy during the decode\nstage. LaDA obtains state-of-the-art results on public datasets for both\nzero-shot and few-shot adaptation.",
            "author": [
                "Zhanyu Ma",
                "Jian Ye",
                "Shuang Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02903v1",
                "http://arxiv.org/pdf/2308.02903v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02901v2",
            "title": "A logarithmic approximation algorithm for the activation edge multicover\n  problem",
            "updated": "2023-09-14T14:22:01Z",
            "published": "2023-08-05T15:38:30Z",
            "summary": "In the Activation Edge-Multicover problem we are given a multigraph $G=(V,E)$\nwith activation costs $\\{c_{e}^u,c_{e}^v\\}$ for every edge $e=uv \\in E$, and\ndegree requirements $r=\\{r_v:v \\in V\\}$. The goal is to find an edge subset $J\n\\subseteq E$ of minimum activation cost $\\sum_{v \\in V}\\max\\{c_{uv}^v:uv \\in\nJ\\}$,such that every $v \\in V$ has at least $r_v$ neighbors in the graph\n$(V,J)$. Let $k= \\max_{v \\in V} r_v$ be the maximum requirement and let\n$\\theta=\\max_{e=uv \\in E} \\frac{\\max\\{c_e^u,c_e^v\\}}{\\min\\{c_e^u,c_e^v\\}}$ be\nthe maximum quotient between the two costs of an edge. For $\\theta=1$ the\nproblem admits approximation ratio $O(\\log k)$. For $k=1$ it generalizes the\nSet Cover problem (when $\\theta=\\infty$), and admits a tight approximation\nratio $O(\\log n)$. This implies approximation ratio $O(k \\log n)$ for general\n$k$ and $\\theta$, and no better approximation ratio was known. We obtain the\nfirst logarithmic approximation ratio $O(\\log k +\\log\\min\\{\\theta,n\\})$, that\nbridges between the two known ratios -- $O(\\log k)$ for $\\theta=1$ and $O(\\log\nn)$ for $k=1$. This implies approximation ratio $O\\left(\\log k\n+\\log\\min\\{\\theta,n\\}\\right) +\\beta \\cdot (\\theta+1)$ for the Activation\n$k$-Connected Subgraph problem, where $\\beta$ is the best known approximation\nratio for the ordinary min-cost version of the problem.",
            "author": [
                "Zeev Nutov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02901v2",
                "http://arxiv.org/pdf/2308.02901v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02900v1",
            "title": "Disentangled Counterfactual Reasoning for Unbiased Sequential\n  Recommendation",
            "updated": "2023-08-05T15:23:26Z",
            "published": "2023-08-05T15:23:26Z",
            "summary": "Sequential recommender systems have achieved state-of-the-art recommendation\nperformance by modeling the sequential dynamics of user activities. However, in\nmost recommendation scenarios, the popular items comprise the major part of the\nprevious user actions. Therefore, the learned models are biased towards the\npopular items irrespective of the user's real interests. In this paper, we\npropose a structural causal model-based method to address the popularity bias\nissue for sequential recommendation model learning. For more generalizable\nmodeling, we disentangle the popularity and interest representations at both\nthe item side and user context side. Based on the disentangled representation,\nwe identify a more effective structural causal graph for general recommendation\napplications. Then, we design delicate sequential models to apply the\naforementioned causal graph to the sequential recommendation scenario for\nunbiased prediction with counterfactual reasoning. Furthermore, we conduct\nextensive offline experiments and online A/B tests to verify the proposed\n\\textbf{DCR} (Disentangled Counterfactual Reasoning) method's superior overall\nperformance and understand the effectiveness of the various introduced\ncomponents. Based on our knowledge, this is the first structural causal model\nspecifically designed for the popularity bias correction of sequential\nrecommendation models, which achieves significant performance gains over the\nexisting methods.",
            "author": [
                "Yi Ren",
                "Xu Zhao",
                "Hongyan Tang",
                "Shuai Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02900v1",
                "http://arxiv.org/pdf/2308.02900v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02898v1",
            "title": "Elucidate Gender Fairness in Singing Voice Transcription",
            "updated": "2023-08-05T15:15:01Z",
            "published": "2023-08-05T15:15:01Z",
            "summary": "It is widely known that males and females typically possess different sound\ncharacteristics when singing, such as timbre and pitch, but it has never been\nexplored whether these gender-based characteristics lead to a performance\ndisparity in singing voice transcription (SVT), whose target includes pitch.\nSuch a disparity could cause fairness issues and severely affect the user\nexperience of downstream SVT applications. Motivated by this, we first\ndemonstrate the female superiority of SVT systems, which is observed across\ndifferent models and datasets. We find that different pitch distributions,\nrather than gender data imbalance, contribute to this disparity. To address\nthis issue, we propose using an attribute predictor to predict gender labels\nand adversarially training the SVT system to enforce the gender-invariance of\nacoustic representations. Leveraging the prior knowledge that pitch\ndistributions may contribute to the gender bias, we propose conditionally\naligning acoustic representations between demographic groups by feeding note\nevents to the attribute predictor. Empirical experiments on multiple benchmark\nSVT datasets show that our method significantly reduces gender bias (up to more\nthan 50%) with negligible degradation of overall SVT performance, on both\nin-domain and out-of-domain singing data, thus offering a better\nfairness-utility trade-off.",
            "author": [
                "Xiangming Gu",
                "Wei Zeng",
                "Ye Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02898v1",
                "http://arxiv.org/pdf/2308.02898v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02897v1",
            "title": "An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial\n  Transferability",
            "updated": "2023-08-05T15:12:36Z",
            "published": "2023-08-05T15:12:36Z",
            "summary": "While the transferability property of adversarial examples allows the\nadversary to perform black-box attacks (i.e., the attacker has no knowledge\nabout the target model), the transfer-based adversarial attacks have gained\ngreat attention. Previous works mostly study gradient variation or image\ntransformations to amplify the distortion on critical parts of inputs. These\nmethods can work on transferring across models with limited differences, i.e.,\nfrom CNNs to CNNs, but always fail in transferring across models with wide\ndifferences, such as from CNNs to ViTs. Alternatively, model ensemble\nadversarial attacks are proposed to fuse outputs from surrogate models with\ndiverse architectures to get an ensemble loss, making the generated adversarial\nexample more likely to transfer to other models as it can fool multiple models\nconcurrently. However, existing ensemble attacks simply fuse the outputs of the\nsurrogate models evenly, thus are not efficacious to capture and amplify the\nintrinsic transfer information of adversarial examples. In this paper, we\npropose an adaptive ensemble attack, dubbed AdaEA, to adaptively control the\nfusion of the outputs from each model, via monitoring the discrepancy ratio of\ntheir contributions towards the adversarial objective. Furthermore, an extra\ndisparity-reduced filter is introduced to further synchronize the update\ndirection. As a result, we achieve considerable improvement over the existing\nensemble attacks on various datasets, and the proposed AdaEA can also boost\nexisting transfer-based attacks, which further demonstrates its efficacy and\nversatility.",
            "author": [
                "Bin Chen",
                "Jia-Li Yin",
                "Shukai Chen",
                "Bo-Hao Chen",
                "Ximeng Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02897v1",
                "http://arxiv.org/pdf/2308.02897v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02877v1",
            "title": "Meta-learning in healthcare: A survey",
            "updated": "2023-08-05T13:11:35Z",
            "published": "2023-08-05T13:11:35Z",
            "summary": "As a subset of machine learning, meta-learning, or learning to learn, aims at\nimproving the model's capabilities by employing prior knowledge and experience.\nA meta-learning paradigm can appropriately tackle the conventional challenges\nof traditional learning approaches, such as insufficient number of samples,\ndomain shifts, and generalization. These unique characteristics position\nmeta-learning as a suitable choice for developing influential solutions in\nvarious healthcare contexts, where the available data is often insufficient,\nand the data collection methodologies are different. This survey discusses\nmeta-learning broad applications in the healthcare domain to provide insight\ninto how and where it can address critical healthcare challenges. We first\ndescribe the theoretical foundations and pivotal methods of meta-learning. We\nthen divide the employed meta-learning approaches in the healthcare domain into\ntwo main categories of multi/single-task learning and many/few-shot learning\nand survey the studies. Finally, we highlight the current challenges in\nmeta-learning research, discuss the potential solutions and provide future\nperspectives on meta-learning in healthcare.",
            "author": [
                "Alireza Rafiei",
                "Ronald Moore",
                "Sina Jahromi",
                "Farshid Hajati",
                "Rishikesan Kamaleswaran"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02877v1",
                "http://arxiv.org/pdf/2308.02877v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02875v1",
            "title": "An Overview of Analysis Methods and Evaluation Results for Caching\n  Strategies",
            "updated": "2023-08-05T13:11:08Z",
            "published": "2023-08-05T13:11:08Z",
            "summary": "We survey analytical methods and evaluation results for the performance\nassessment of caching strategies. Knapsack solutions are derived, which provide\nstatic caching bounds for independent requests and general bounds for dynamic\ncaching under arbitrary request pattern. We summarize Markov- and\ntime-to-live-based solutions, which assume specific stochastic processes for\ncapturing web request streams and timing. We compare the performance of caching\nstrategies with different knowledge about the properties of data objects\nregarding a broad set of caching demands. The efficiency of web caching must\nregard benefits for network wide traffic load, energy consumption and\nquality-of-service aspects in a tradeoff with costs for updating and storage\noverheads.",
            "author": [
                "Gerhard Hasslinger",
                "Mahshid Okhovatzadeh",
                "Konstantinos Ntougias",
                "Frank Hasslinger",
                "Oliver Hohlfeld"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.comnet.2023.109583",
                "http://arxiv.org/abs/2308.02875v1",
                "http://arxiv.org/pdf/2308.02875v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02862v1",
            "title": "Improving Generalization of Image Captioning with Unsupervised Prompt\n  Learning",
            "updated": "2023-08-05T12:27:01Z",
            "published": "2023-08-05T12:27:01Z",
            "summary": "Pretrained visual-language models have demonstrated impressive zero-shot\nabilities in image captioning, when accompanied by hand-crafted prompts.\nMeanwhile, hand-crafted prompts utilize human prior knowledge to guide the\nmodel. However, due to the diversity between different domains, such\nhand-crafted prompt that provide invariant prior knowledge may result in mode\ncollapse for some domains. Some researches attempted to incorporate expert\nknowledge and instruction datasets, but the results were costly and led to\nhallucinations. In this paper, we propose an unsupervised prompt learning\nmethod to improve Generalization of Image Captioning (GeneIC), which learns a\ndomain-specific prompt vector for the target domain without requiring annotated\ndata. GeneIC aligns visual and language modalities with a pre-trained\nContrastive Language-Image Pre-Training (CLIP) model, thus optimizing the\ndomain-specific prompt vector from two aspects: attribute and semantic\nconsistency. Specifically, GeneIC first generates attribute-transferred images\nwith differing attributes, while retaining semantic similarity with original\nimages. Then, GeneIC uses CLIP to measure the similarity between the images and\nthe generated sentences. By exploring the variable and invariant features in\nthe original images and attribute-transferred images, attribute consistency\nconstrains the attribute change direction of both images and sentences to learn\ndomain-specific knowledge. The semantic consistency directly measures the\nsimilarity between the generated sentences and images to ensure the accuracy\nand comprehensiveness of the generated sentences. Consequently, GeneIC only\noptimizes the prompt vectors, which effectively retains the knowledge in the\nlarge model and introduces domain-specific knowledge.",
            "author": [
                "Hongchen Wei",
                "Zhenzhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02862v1",
                "http://arxiv.org/pdf/2308.02862v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02849v1",
            "title": "Brightness and mass accretion rate evolution during the 2022 burst of\n  EX~Lupi",
            "updated": "2023-08-05T11:34:18Z",
            "published": "2023-08-05T11:34:18Z",
            "summary": "EX Lupi is the prototype by which EXor-type outbursts were defined. It has\nexperienced multiple accretion-related bursts and outbursts throughout the last\ndecades, whose study have greatly extended our knowledge about the effects of\nthese types of events. This star experienced a new burst in 2022. We used\nmulti-band photometry to create color-color and color-magnitude diagrams to\nexclude the possibility that the brightening could be explained by a decrease\nin extinction. We obtained VLT/X-shooter spectra to determine the Lacc and Macc\nduring the peak of the burst and after its return to quiescence using 2\nmethods: empirical relationships between line luminosity and Lacc, and a slab\nmodel of the whole spectrum. We examined the 130 year light curve of EX Lupi to\nprovide statistics on the number of outbursts experienced during this period of\ntime. Our analysis of the data taken during the 2022 burst confirmed that a\nchange in extinction is not responsible for the brightening. Our two approaches\nin calculating the Macc were in agreement, and resulted in values that are 2\norders of magnitude above what had previously been estimated, thus suggesting\nthat EX Lupi is a strong accretor even when in quiescence. We determined that\nin 2022 March the Macc increased by a factor of 7 with respect to the quiescent\nlevel. We also found hints that even though the Macc had returned to almost its\npre-outburst levels, certain physical properties of the gas had not returned to\nthe quiescent values. We found that the mass accreted during this three month\nevent was 0.8 lunar masses, which is approximately half of what is accreted\nduring a year of quiescence. We calculated that if EX Lupi remains as active as\nit has been for the past 130 years, during which it has experienced at least 3\noutbursts and 10 bursts, then it will deplete the mass of its circumstellar\nmaterial in less than 160000 yr.",
            "author": [
                "F. Cruz-S\u00e1enz de Miera",
                "\u00c1. K\u00f3sp\u00e1l",
                "P. \u00c1brah\u00e1m",
                "R. A. B. Claes",
                "C. F. Manara",
                "J. Wendeborn",
                "E. Fiorellino",
                "T. Giannini",
                "B. Nisini",
                "A. Sicilia-Aguilar",
                "J. Campbell-White",
                "J. M. Alcal\u00e1",
                "A. Banzatti",
                "Zs. M. Szab\u00f3",
                "F. Lykou",
                "S. Antoniucci",
                "J. Varga",
                "M. Siwak",
                "S. Park",
                "Zs. Nagy",
                "M. Kun"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202347063",
                "http://arxiv.org/abs/2308.02849v1",
                "http://arxiv.org/pdf/2308.02849v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04454v3",
            "title": "Sustainable development-oriented campus bike-sharing site evaluation\n  model: A case study of Henan Polytechnic University",
            "updated": "2023-09-22T03:14:04Z",
            "published": "2023-08-05T11:31:28Z",
            "summary": "Promoting sustainable transportation options is increasingly crucial in the\npursuit of environmentally friendly and efficient campus mobility systems.\nAmong these options, bike-sharing programs have garnered substantial attention\nfor their capacity to mitigate traffic congestion, decrease carbon emissions,\nand enhance overall campus sustainability. However, improper selection of\nbike-sharing sites has led to the growing problems of unsustainable practices\nin campus, including the disorderly parking and indiscriminate placement of\nbike-sharing. To this end, this paper proposes a novel sustainable\ndevelopment-oriented campus bike-sharing site evaluation model integrating the\nimproved Delphi and fuzzy comprehensive evaluation approaches. Fourteen\nevaluation metrics are firstly selected from four dimensions: the user\nfeatures, implementation and usage characteristics of parking spots,\nenvironmental sustainability, and social sustainability, through the\ncombination of expert experience and the improved Delphi method. Then, the\nanalytic hierarchy process and the entropy weight method are employed to\ndetermine the weights of the evaluation indices, ensuring a robust and\nobjective assessment framework. The fuzzy comprehensive evaluation method is\nfinally implemented to evaluate the quality of location selection. South Campus\nof Henan Polytechnic University is selected as a case study using the proposed\nevaluation system. This work contributes to the existing body of knowledge by\npresenting a comprehensive location selection evaluation system for campus\nbike-sharing, informed by the principles of sustainable development.",
            "author": [
                "Huimin Qi",
                "Xianghong Li",
                "Kai Yin",
                "Xiangnan Song",
                "Xufei Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04454v3",
                "http://arxiv.org/pdf/2308.04454v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02829v1",
            "title": "Multi-Agent Verification and Control with Probabilistic Model Checking",
            "updated": "2023-08-05T09:31:32Z",
            "published": "2023-08-05T09:31:32Z",
            "summary": "Probabilistic model checking is a technique for formal automated reasoning\nabout software or hardware systems that operate in the context of uncertainty\nor stochasticity. It builds upon ideas and techniques from a diverse range of\nfields, from logic, automata and graph theory, to optimisation, numerical\nmethods and control. In recent years, probabilistic model checking has also\nbeen extended to integrate ideas from game theory, notably using models such as\nstochastic games and solution concepts such as equilibria, to formally verify\nthe interaction of multiple rational agents with distinct objectives. This\nprovides a means to reason flexibly about agents acting in either an\nadversarial or a collaborative fashion, and opens up opportunities to tackle\nnew problems within, for example, artificial intelligence, robotics and\nautonomous systems. In this paper, we summarise some of the advances in this\narea, and highlight applications for which they have already been used. We\ndiscuss how the strengths of probabilistic model checking apply, or have the\npotential to apply, to the multi-agent setting and outline some of the key\nchallenges required to make further progress in this field.",
            "author": [
                "David Parker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02829v1",
                "http://arxiv.org/pdf/2308.02829v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02825v2",
            "title": "Burning a binary tree and its generalization",
            "updated": "2023-11-14T17:11:07Z",
            "published": "2023-08-05T09:05:10Z",
            "summary": "Graph burning is a graph process that models the spread of social contagion.\nInitially, all the vertices of a graph $G$ are unburnt. At each step, an\nunburnt vertex is put on fire and the fire from burnt vertices of the previous\nstep spreads to their adjacent unburnt vertices. This process continues till\nall the vertices are burnt. The burning number $b(G)$ of the graph $G$ is the\nminimum number of steps required to burn all the vertices in the graph. The\nburning number conjecture by Bonato et al. states that for a connected graph\n$G$ of order $n$, its burning number $b(G) \\leq \\lceil \\sqrt{n} \\rceil$. It is\neasy to observe that in order to burn a graph it is enough to burn its spanning\ntree. Hence it suffices to prove that for any tree $T$ of order $n$, its\nburning number $b(T) \\leq \\lceil \\sqrt{n} \\rceil$ where $T$ is the spanning\ntree of $G$. It was proved in 2018 that $b(T) \\leq \\lceil \\sqrt{n + n_2 + 1/4}\n+1/2 \\rceil$ for a tree $T$ where $n_2$ is the number of degree $2$ vertices in\n$T$. In this paper, we provide an algorithm to burn a tree and we improve the\nexisting bound using this algorithm. We prove that $b(T)\\leq \\lceil \\sqrt{n +\nn_2 + 8}\\rceil -1$ which is an improved bound for $n\\geq 50$. We also provide\nan algorithm to burn some subclasses of the binary tree and prove the burning\nnumber conjecture for the same.",
            "author": [
                "Sandip Das",
                "Sk Samim Islam",
                "Ritam M Mitra",
                "Sanchita Paul"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02825v2",
                "http://arxiv.org/pdf/2308.02825v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02793v1",
            "title": "Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph",
            "updated": "2023-08-05T05:35:40Z",
            "published": "2023-08-05T05:35:40Z",
            "summary": "The rise of the click farm business using Multi-purpose Messaging Mobile Apps\n(MMMAs) tempts cybercriminals to perpetrate crowdsourcing frauds that cause\nfinancial losses to click farm workers. In this paper, we propose a novel\ncontrastive multi-view learning method named CMT for crowdsourcing fraud\ndetection over the heterogeneous temporal graph (HTG) of MMMA. CMT captures\nboth heterogeneity and dynamics of HTG and generates high-quality\nrepresentations for crowdsourcing fraud detection in a self-supervised manner.\nWe deploy CMT to detect crowdsourcing frauds on an industry-size HTG of a\nrepresentative MMMA WeChat and it significantly outperforms other methods. CMT\nalso shows promising results for fraud detection on a large-scale public\nfinancial HTG, indicating that it can be applied in other graph anomaly\ndetection tasks.",
            "author": [
                "Zequan Xu",
                "Qihang Sun",
                "Shaofeng Hu",
                "Jieming Shi",
                "Hui Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02793v1",
                "http://arxiv.org/pdf/2308.02793v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02790v1",
            "title": "Few-shot Class-Incremental Semantic Segmentation via Pseudo-Labeling and\n  Knowledge Distillation",
            "updated": "2023-08-05T05:05:37Z",
            "published": "2023-08-05T05:05:37Z",
            "summary": "We address the problem of learning new classes for semantic segmentation\nmodels from few examples, which is challenging because of the following two\nreasons. Firstly, it is difficult to learn from limited novel data to capture\nthe underlying class distribution. Secondly, it is challenging to retain\nknowledge for existing classes and to avoid catastrophic forgetting. For\nlearning from limited data, we propose a pseudo-labeling strategy to augment\nthe few-shot training annotations in order to learn novel classes more\neffectively. Given only one or a few images labeled with the novel classes and\na much larger set of unlabeled images, we transfer the knowledge from labeled\nimages to unlabeled images with a coarse-to-fine pseudo-labeling approach in\ntwo steps. Specifically, we first match each labeled image to its nearest\nneighbors in the unlabeled image set at the scene level, in order to obtain\nimages with a similar scene layout. This is followed by obtaining pseudo-labels\nwithin this neighborhood by applying classifiers learned on the few-shot\nannotations. In addition, we use knowledge distillation on both labeled and\nunlabeled data to retain knowledge on existing classes. We integrate the above\nsteps into a single convolutional neural network with a unified learning\nobjective. Extensive experiments on the Cityscapes and KITTI datasets validate\nthe efficacy of the proposed approach in the self-driving domain. Code is\navailable from https://github.com/ChasonJiang/FSCILSS.",
            "author": [
                "Chengjia Jiang",
                "Tao Wang",
                "Sien Li",
                "Jinyang Wang",
                "Shirui Wang",
                "Antonios Antoniou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02790v1",
                "http://arxiv.org/pdf/2308.02790v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02785v1",
            "title": "Understanding the RSA algorithm",
            "updated": "2023-08-05T04:20:18Z",
            "published": "2023-08-05T04:20:18Z",
            "summary": "With the emerging importance of cybersecurity, it will be beneficial for a\nwide community to understand some of the fundamental security mechanisms. The\nRSA algorithm is one of the essential algorithms used in public-key\ncryptosystems. Understanding the RSA algorithm requires knowledge regarding\nnumber theory, modular arithmetic, etc., which is often beyond the knowledge\npool of many beginners in cybersecurity. In this work, we provide an intuitive\nand onion-peeling style introduction to the RSA algorithm, in which we assume\nthat readers will only have a basic background in mathematics and\ncybersecurity. Started from three essential goals of public-key cryptosystems,\nwe explained step-by-step how the RSA algorithm achieved these goals. We also\nused a toy example to further help readers to understand the algorithm from a\npractical perspective.",
            "author": [
                "Zhengping Jay Luo",
                "Ruowen Liu",
                "Aarav Mehta"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02785v1",
                "http://arxiv.org/pdf/2308.02785v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04453v1",
            "title": "Towards Immutability: A Secure and Efficient Auditing Framework for\n  Cloud Supporting Data Integrity and File Version Control",
            "updated": "2023-08-05T03:41:37Z",
            "published": "2023-08-05T03:41:37Z",
            "summary": "Although wide-scale integration of cloud services with myriad applications\nincreases quality of services (QoS) for enterprise users, verifying the\nexistence and manipulation of stored cloud information remains an open research\nproblem. Decentralized blockchain-based solutions are becoming more appealing\nfor cloud auditing environments because of the immutable nature of blockchain.\nHowever, the decentralized structure of blockchain results in considerable\nsynchronization and communication overhead, which increases maintenance costs\nfor cloud service providers (CSP). This paper proposes a Merkle Hash Tree based\narchitecture named Entangled Merkle Forest to support version control and\ndynamic auditing of information in centralized cloud environments. We utilized\na semi-trusted third-party auditor to conduct the auditing tasks with minimal\nprivacy-preserving file metadata. To the best of our knowledge, we are the\nfirst to design a node sharing Merkle Forest to offer a cost-effective auditing\nframework for centralized cloud infrastructures while achieving the immutable\nfeature of blockchain, mitigating the synchronization and performance\nchallenges of the decentralized architectures. Our proposed scheme outperforms\nit's equivalent Blockchain-based schemes by ensuring time and storage\nefficiency with minimum overhead as evidenced by performance analysis.",
            "author": [
                "Faisal Haque Bappy",
                "Saklain Zaman",
                "Tariqul Islam",
                "Redwan Ahmed Rizvee",
                "Joon S. Park",
                "Kamrul Hasan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04453v1",
                "http://arxiv.org/pdf/2308.04453v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02782v1",
            "title": "Non-line-of-sight reconstruction via structure sparsity regularization",
            "updated": "2023-08-05T03:32:44Z",
            "published": "2023-08-05T03:32:44Z",
            "summary": "Non-line-of-sight (NLOS) imaging allows for the imaging of objects around a\ncorner, which enables potential applications in various fields such as\nautonomous driving, robotic vision, medical imaging, security monitoring, etc.\nHowever, the quality of reconstruction is challenged by low signal-noise-ratio\n(SNR) measurements. In this study, we present a regularization method, referred\nto as structure sparsity (SS) regularization, for denoising in NLOS\nreconstruction. By exploiting the prior knowledge of structure sparseness, we\nincorporate nuclear norm penalization into the cost function of directional\nlight-cone transform (DLCT) model for NLOS imaging system. This incorporation\neffectively integrates the neighborhood information associated with the\ndirectional albedo, thereby facilitating the denoising process. Subsequently,\nthe reconstruction is achieved by optimizing a directional albedo model with SS\nregularization using fast iterative shrinkage-thresholding algorithm. Notably,\nthe robust reconstruction of occluded objects is observed. Through\ncomprehensive evaluations conducted on both synthetic and experimental\ndatasets, we demonstrate that the proposed approach yields high-quality\nreconstructions, surpassing the state-of-the-art reconstruction algorithms,\nespecially in scenarios involving short exposure and low SNR measurements.",
            "author": [
                "Duolan Huang",
                "Quan Chen",
                "Zhun Wei",
                "Rui Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1364/OL.501622",
                "http://arxiv.org/abs/2308.02782v1",
                "http://arxiv.org/pdf/2308.02782v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02774v3",
            "title": "Self-Distillation Network with Ensemble Prototypes: Learning Robust\n  Speaker Representations without Supervision",
            "updated": "2023-09-12T06:03:23Z",
            "published": "2023-08-05T02:59:40Z",
            "summary": "Training speaker-discriminative and robust speaker verification systems\nwithout explicit speaker labels remains a persisting challenge that demands\nfurther investigation. Previous studies have noted a substantial performance\ndisparity between self-supervised and fully supervised approaches. In this\npaper, we propose an effective Self-Distillation network with Ensemble\nPrototypes (SDEP) to facilitate self-supervised speaker representation\nlearning. It assigns representation of augmented views of utterances to the\nsame prototypes as the representation of the original view, thereby enabling\neffective knowledge transfer between the views. A range of experiments\nconducted on the VoxCeleb datasets demonstrate the superiority of the SDEP\nframework in self-supervised speaker verification. SDEP achieves a new\nstate-of-the-art on Voxceleb1 speaker verification evaluation benchmark ( i.e.,\nequal error rate 1.94%, 1.99%, and 3.77% for trial Vox1-O, Vox1-E and Vox1-H ,\nrespectively), without using any speaker labels in the training phase.",
            "author": [
                "Yafeng Chen",
                "Siqi Zheng",
                "Hui Wang",
                "Luyao Cheng",
                "Qian Chen",
                "Shiliang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02774v3",
                "http://arxiv.org/pdf/2308.02774v3"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02773v1",
            "title": "EduChat: A Large-Scale Language Model-based Chatbot System for\n  Intelligent Education",
            "updated": "2023-08-05T02:55:35Z",
            "published": "2023-08-05T02:55:35Z",
            "summary": "EduChat (https://www.educhat.top/) is a large-scale language model\n(LLM)-based chatbot system in the education domain. Its goal is to support\npersonalized, fair, and compassionate intelligent education, serving teachers,\nstudents, and parents. Guided by theories from psychology and education, it\nfurther strengthens educational functions such as open question answering,\nessay assessment, Socratic teaching, and emotional support based on the\nexisting basic LLMs. Particularly, we learn domain-specific knowledge by\npre-training on the educational corpus and stimulate various skills with tool\nuse by fine-tuning on designed system prompts and instructions. Currently,\nEduChat is available online as an open-source project, with its code, data, and\nmodel parameters available on platforms (e.g., GitHub\nhttps://github.com/icalk-nlp/EduChat, Hugging Face\nhttps://huggingface.co/ecnu-icalk ). We also prepare a demonstration of its\ncapabilities online (https://vimeo.com/851004454). This initiative aims to\npromote research and applications of LLMs for intelligent education.",
            "author": [
                "Yuhao Dan",
                "Zhikai Lei",
                "Yiyang Gu",
                "Yong Li",
                "Jianghao Yin",
                "Jiaju Lin",
                "Linhao Ye",
                "Zhiyan Tie",
                "Yougen Zhou",
                "Yilei Wang",
                "Aimin Zhou",
                "Ze Zhou",
                "Qin Chen",
                "Jie Zhou",
                "Liang He",
                "Xipeng Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02773v1",
                "http://arxiv.org/pdf/2308.02773v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.15484v1",
            "title": "Dynamic Dual-Graph Fusion Convolutional Network For Alzheimer's Disease\n  Diagnosis",
            "updated": "2023-08-05T02:44:02Z",
            "published": "2023-08-05T02:44:02Z",
            "summary": "In this paper, a dynamic dual-graph fusion convolutional network is proposed\nto improve Alzheimer's disease (AD) diagnosis performance. The following are\nthe paper's main contributions: (a) propose a novel dynamic GCN architecture,\nwhich is an end-to-end pipeline for diagnosis of the AD task; (b) the proposed\narchitecture can dynamically adjust the graph structure for GCN to produce\nbetter diagnosis outcomes by learning the optimal underlying latent graph; (c)\nincorporate feature graph learning and dynamic graph learning, giving those\nuseful features of subjects more weight while decreasing the weights of other\nnoise features. Experiments indicate that our model provides flexibility and\nstability while achieving excellent classification results in AD diagnosis.",
            "author": [
                "Fanshi Li",
                "Zhihui Wang",
                "Yifan Guo",
                "Congcong Liu",
                "Yanjie Zhu",
                "Yihang Zhou",
                "Jun Li",
                "Dong Liang",
                "Haifeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15484v1",
                "http://arxiv.org/pdf/2308.15484v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02770v1",
            "title": "One-stage Low-resolution Text Recognition with High-resolution Knowledge\n  Transfer",
            "updated": "2023-08-05T02:33:45Z",
            "published": "2023-08-05T02:33:45Z",
            "summary": "Recognizing characters from low-resolution (LR) text images poses a\nsignificant challenge due to the information deficiency as well as the noise\nand blur in low-quality images. Current solutions for low-resolution text\nrecognition (LTR) typically rely on a two-stage pipeline that involves\nsuper-resolution as the first stage followed by the second-stage recognition.\nAlthough this pipeline is straightforward and intuitive, it has to use an\nadditional super-resolution network, which causes inefficiencies during\ntraining and testing. Moreover, the recognition accuracy of the second stage\nheavily depends on the reconstruction quality of the first stage, causing\nineffectiveness. In this work, we attempt to address these challenges from a\nnovel perspective: adapting the recognizer to low-resolution inputs by\ntransferring the knowledge from the high-resolution. Guided by this idea, we\npropose an efficient and effective knowledge distillation framework to achieve\nmulti-level knowledge transfer. Specifically, the visual focus loss is proposed\nto extract the character position knowledge with resolution gap reduction and\ncharacter region focus, the semantic contrastive loss is employed to exploit\nthe contextual semantic knowledge with contrastive learning, and the soft\nlogits loss facilitates both local word-level and global sequence-level\nlearning from the soft teacher label. Extensive experiments show that the\nproposed one-stage pipeline significantly outperforms super-resolution based\ntwo-stage frameworks in terms of effectiveness and efficiency, accompanied by\nfavorable robustness. Code is available at https://github.com/csguoh/KD-LTR.",
            "author": [
                "Hang Guo",
                "Tao Dai",
                "Mingyan Zhu",
                "Guanghao Meng",
                "Bin Chen",
                "Zhi Wang",
                "Shu-Tao Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02770v1",
                "http://arxiv.org/pdf/2308.02770v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02768v1",
            "title": "FGLQR: Factor Graph Accelerator of LQR Control for Autonomous Machines",
            "updated": "2023-08-05T02:19:04Z",
            "published": "2023-08-05T02:19:04Z",
            "summary": "Factor graph represents the factorization of a probability distribution\nfunction and serves as an effective abstraction in various autonomous machine\ncomputing tasks. Control is one of the core applications in autonomous machine\ncomputing stacks. Among all control algorithms, Linear Quadratic Regulator\n(LQR) offers one of the best trade-offs between efficiency and accuracy.\nHowever, due to the inherent iterative process and extensive computation, it is\na challenging task for the autonomous systems with real-time limits and energy\nconstrained.\n  In this paper, we present FGLQR, an accelerator of LQR control for autonomous\nmachines using the abstraction of a factor graph. By transforming the dynamic\nequation constraints into least squares constraints, the factor graph solving\nprocess is more hardware friendly and accelerated with almost no loss in\naccuracy. With a domain specific parallel solving pattern, FGLQR achieves 10.2x\nspeed up and 32.9x energy reduction compared to the software implementation on\nan advanced Intel CPU.",
            "author": [
                "Yuhui Hao",
                "Bo Yu",
                "Qiang Liu",
                "Shao-Shan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02768v1",
                "http://arxiv.org/pdf/2308.02768v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02766v1",
            "title": "Sizing the double pole resonant enhancement in $e^{+}e^{-} \\to \u03c0^{0}\n  \u03c0^{0} \u03b3$ cross section and $\u03c4^{-} \\to \u03c0^{-}\u03c0^{0}\n  \u03bd_\u03c4\u03b3$ decay",
            "updated": "2023-08-05T02:00:17Z",
            "published": "2023-08-05T02:00:17Z",
            "summary": "The enhancement mechanism due to the resonant properties of the $\\rho$ and\n$\\omega$ mesons, which are close in mass, are analysed when such resonances\ncarry different momenta. Considerations from the particular process where they\nappear to the individual resonant features are at play for the appearance of\nthe global resonant manifestation. In this work, we first consider the $e^+e^-\n\\to \\pi^0 \\pi^0 \\gamma$ process. We use the differential cross section at a\ngiven angle of emission of one of the pions, to tune the individual features of\nthe two resonances and exhibit how both resonances combine to produce the\nenhancement. Then, we incorporate the $\\rho^\\prime$ using the information\nobtained from the $ e^+e^- \\to \\pi^0 \\pi^0 \\gamma$ total scattering process and\nshow that, it becomes important thanks to the same enhancement mechanism\nbetween the $\\rho$ and the $\\omega$. In a second step, we use a similar\napproach to describe a model dependent contribution to the $\\tau^- \\to\n\\pi^-\\pi^0\\nu_\\tau\\gamma$ decay, the so-called $\\omega$ channel. We show that\nthe dipion invariant mass distribution at particular angles is sensitive to the\nindividual resonant states. We compute the interference of this channel with\nthe known dominant model independent contribution, and show how a better\nknowledge of the $e^+e^- \\to \\pi^0 \\pi^0 \\gamma$ process can help to properly\naccount for such model dependent effects. The implication on the isospin\nsymmetry breaking correction to tau-based estimates of the muon magnetic dipole\nmoment is assessed.",
            "author": [
                "Leonardo Esparza-Arellano",
                "Antonio Rojas",
                "Genaro Toledo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02766v1",
                "http://arxiv.org/pdf/2308.02766v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02762v1",
            "title": "Fixation times on directed graphs",
            "updated": "2023-08-05T01:44:03Z",
            "published": "2023-08-05T01:44:03Z",
            "summary": "Computing the rate of evolution in spatially structured populations can be\ndifficult. A key quantity that describes evolutionary dynamics is the fixation\ntime of a single mutant with relative reproduction rate $r\\ge 1$ who invades a\npopulation of residents. We say that the fixation time is \"fast\" if it is at\nmost polynomial in terms of the population size $N$. In this work, we study\nfixation times of advantageous mutants ($r>1$) and neutral mutants ($r=1$) on\ndirected graphs, which are defined as those graphs that have at least some\none-way connections. We obtain three main results. First, we prove that for any\ndirected graph the fixation time is fast, provided that $r$ is sufficiently\nlarge. Second, we devise an efficient algorithm that gives an upper bound for\nthe fixation time for any graph and any $r\\ge 1$. Third, we identify a broad\nclass of directed graphs with fast fixation times for any $r\\ge 1$. This class\nincludes previously studied amplifiers of selection, such as Superstars and\nMetafunnels. We also show that on some graphs fixation time is not a\nmonotonically declining function of $r$; in particular, neutral fixation can\noccur faster than fixation for small selective advantages. Our results have\nimportant algorithmic consequences and enable efficient computational\nexploration of various properties of directed graphs.",
            "author": [
                "David A. Brewster",
                "Martin A. Nowak",
                "Josef Tkadlec"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02762v1",
                "http://arxiv.org/pdf/2308.02762v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02755v1",
            "title": "Multi-topic belief formation through bifurcations over signed social\n  networks",
            "updated": "2023-08-05T00:42:39Z",
            "published": "2023-08-05T00:42:39Z",
            "summary": "We propose and analyze a nonlinear dynamic model of continuous-time\nmulti-dimensional belief formation over signed social networks. Our model\naccounts for the effects of a structured belief system, self-appraisal,\ninternal biases, and various sources of cognitive dissonance posited by recent\ntheories in social psychology. We prove that strong beliefs emerge on the\nnetwork as a consequence of a bifurcation. We analyze how the balance of social\nnetwork effects in the model controls the nature of the bifurcation and,\ntherefore, the belief-forming limit-set solutions. Our analysis provides\nconstructive conditions on how multi-stable network belief equilibria and\nbelief oscillations emerging at a belief-forming bifurcation depend on the\ncommunication network graph and belief system network graph. Our model and\nanalysis provide new theoretical insights on the dynamics of social systems and\na new principled framework for designing decentralized decision-making on\nengineered networks in the presence of structured relationships among\nalternatives.",
            "author": [
                "Anastasia Bizyaeva",
                "Alessio Franci",
                "Naomi Ehrich Leonard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02755v1",
                "http://arxiv.org/pdf/2308.02755v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.MA",
                "cs.SI",
                "math.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02749v1",
            "title": "Exploiting On-chip Heterogeneity of Versal Architecture for GNN\n  Inference Acceleration",
            "updated": "2023-08-04T23:57:55Z",
            "published": "2023-08-04T23:57:55Z",
            "summary": "Graph Neural Networks (GNNs) have revolutionized many Machine Learning (ML)\napplications, such as social network analysis, bioinformatics, etc. GNN\ninference can be accelerated by exploiting data sparsity in the input graph,\nvertex features, and intermediate data in GNN computations. For dynamic\nsparsity exploitation, we leverage the heterogeneous computing capabilities of\nAMD Versal ACAP architecture to accelerate GNN inference. We develop a custom\nhardware module that executes the sparse primitives of the computation kernel\non the Programmable Logic (PL) and efficiently computes the dense primitives\nusing the AI Engine (AIE). To exploit data sparsity during inference, we devise\na runtime kernel mapping strategy that dynamically assigns computation tasks to\nthe PL and AIE based on data sparsity. Our implementation on the VCK5000 ACAP\nplatform leads to superior performance compared with the state-of-the-art\nimplementations on CPU, GPU, ACAP, and other custom GNN accelerators. Compared\nwith these implementations, we achieve significant average runtime speedup\nacross various models and datasets of 162.42x, 17.01x, 9.90x, and 27.23x,\nrespectively. Furthermore, for Graph Convolutional Network (GCN) inference, our\napproach leads to a speedup of 3.9-96.7x compared to designs using PL only on\nthe same ACAP device.",
            "author": [
                "Paul Chen",
                "Pavan Manjunath",
                "Sasindu Wijeratne",
                "Bingyi Zhang",
                "Viktor Prasanna"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02749v1",
                "http://arxiv.org/pdf/2308.02749v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.06280v1",
            "title": "Incorporation of Eye-Tracking and Gaze Feedback to Characterize and\n  Improve Radiologist Search Patterns of Chest X-rays: A Randomized Controlled\n  Clinical Trial",
            "updated": "2023-08-04T23:41:16Z",
            "published": "2023-08-04T23:41:16Z",
            "summary": "Diagnostic errors in radiology often occur due to incomplete visual\nassessments by radiologists, despite their knowledge of predicting disease\nclasses. This insufficiency is possibly linked to the absence of required\ntraining in search patterns. Additionally, radiologists lack consistent\nfeedback on their visual search patterns, relying on ad-hoc strategies and peer\ninput to minimize errors and enhance efficiency, leading to suboptimal patterns\nand potential false negatives. This study aimed to use eye-tracking technology\nto analyze radiologist search patterns, quantify performance using established\nmetrics, and assess the impact of an automated feedback-driven educational\nframework on detection accuracy. Ten residents participated in a controlled\ntrial focused on detecting suspicious pulmonary nodules. They were divided into\nan intervention group (received automated feedback) and a control group.\nResults showed that the intervention group exhibited a 38.89% absolute\nimprovement in detecting suspicious-for-cancer nodules, surpassing the control\ngroup's improvement (5.56%, p-value=0.006). Improvement was more rapid over the\nfour training sessions (p-value=0.0001). However, other metrics such as speed,\nsearch pattern heterogeneity, distractions, and coverage did not show\nsignificant changes. In conclusion, implementing an automated feedback-driven\neducational framework improved radiologist accuracy in detecting suspicious\nnodules. The study underscores the potential of such systems in enhancing\ndiagnostic performance and reducing errors. Further research and broader\nimplementation are needed to consolidate these promising results and develop\neffective training strategies for radiologists, ultimately benefiting patient\noutcomes.",
            "author": [
                "Carolina Ramirez-Tamayo",
                "Syed Hasib Akhter Faruqui",
                "Stanford Martinez",
                "Angel Brisco",
                "Nicholas Czarnek",
                "Adel Alaeddini",
                "Jeffrey R. Mock",
                "Edward J. Golob",
                "Kal L. Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2308.06280v1",
                "http://arxiv.org/pdf/2308.06280v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02734v1",
            "title": "Learning to Schedule in Non-Stationary Wireless Networks With Unknown\n  Statistics",
            "updated": "2023-08-04T22:51:15Z",
            "published": "2023-08-04T22:51:15Z",
            "summary": "The emergence of large-scale wireless networks with partially-observable and\ntime-varying dynamics has imposed new challenges on the design of optimal\ncontrol policies. This paper studies efficient scheduling algorithms for\nwireless networks subject to generalized interference constraint, where mean\narrival and mean service rates are unknown and non-stationary. This model\nexemplifies realistic edge devices' characteristics of wireless communication\nin modern networks. We propose a novel algorithm termed MW-UCB for generalized\nwireless network scheduling, which is based on the Max-Weight policy and\nleverages the Sliding-Window Upper-Confidence Bound to learn the channels'\nstatistics under non-stationarity. MW-UCB is provably throughput-optimal under\nmild assumptions on the variability of mean service rates. Specifically, as\nlong as the total variation in mean service rates over any time period grows\nsub-linearly in time, we show that MW-UCB can achieve the stability region\narbitrarily close to the stability region of the class of policies with full\nknowledge of the channel statistics. Extensive simulations validate our\ntheoretical results and demonstrate the favorable performance of MW-UCB.",
            "author": [
                "Quang Minh Nguyen",
                "Eytan Modiano"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02734v1",
                "http://arxiv.org/pdf/2308.02734v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02732v1",
            "title": "A state sum for the total face color polynomial",
            "updated": "2023-08-04T22:35:27Z",
            "published": "2023-08-04T22:35:27Z",
            "summary": "The total face color polynomial is based upon the Poincar\\'{e} polynomials of\na family of filtered $n$-color homologies. It counts the number of $n$-face\ncolorings of ribbon graphs for each positive integer $n$. As such, it may be\nseen as a successor of the Penrose polynomial, which at $n=3$ counts $3$-edge\ncolorings (and consequently $4$-face colorings) of planar trivalent graphs. In\nthis paper we describe a state sum formula for the polynomial. This formula\nunites two different perspectives about graph coloring: one based upon\ntopological quantum field theory and the other on diagrammatic tensors.",
            "author": [
                "Scott Baldridge",
                "Louis H. Kauffman",
                "Ben McCarty"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02732v1",
                "http://arxiv.org/pdf/2308.02732v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.CO",
                "57R56, 05C10, 05C15, 05C31, 05C70, 57M15, 57K16,"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02681v2",
            "title": "MARTA Reach: Piloting an On-Demand Multimodal Transit System in Atlanta",
            "updated": "2023-09-23T18:41:49Z",
            "published": "2023-08-04T22:08:56Z",
            "summary": "This paper reports on the results of the six-month pilot MARTA Reach, which\naimed to demonstrate the potential value of On-Demand Multimodal Transit\nSystems (ODMTS) in the city of Atlanta, Georgia. ODMTS take a transit-centric\nview by integrating on-demand services and traditional fixed routes in order to\naddress the first/last mile problem. ODMTS combine fixed routes and on-demand\nshuttle services by design (not as an after-thought) into a transit system that\noffers a door-to-door multimodal service with fully integrated operations and\nfare structure. The paper fills a knowledge gap, i.e., the understanding of the\nimpact, benefits, and challenges of deploying ODMTS in a city as complex as\nAtlanta, Georgia. The pilot was deployed in four different zones with limited\ntransit options, and used on-demand shuttles integrated with the overall\ntransit system to address the first/last mile problem. The paper describes the\ndesign and operations of the pilot, and presents the results in terms of\nridership, quality of service, trip purposes, alternative modes of\ntransportation, multimodal nature of trips, challenges encountered, and cost\nestimates. The main findings of the pilot are that Reach offered a highly\nvalued service that performed a large number of trips that would have otherwise\nbeen served by ride-hailing companies, taxis, or personal cars. Moreover, the\nwide majority of Reach trips were multimodal, with connections to rail being\nmost prominent.",
            "author": [
                "Pascal Van Hentenryck",
                "Connor Riley",
                "Anthony Trasatti",
                "Hongzhao Guan",
                "Tejas Santanam",
                "Jorge A. Huertas",
                "Kevin Dalmeijer",
                "Kari Watkins",
                "Juwon Drake",
                "Samson Baskin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02681v2",
                "http://arxiv.org/pdf/2308.02681v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02713v1",
            "title": "Fast Bayesian High-Dimensional Gaussian Graphical Model Estimation",
            "updated": "2023-08-04T21:17:23Z",
            "published": "2023-08-04T21:17:23Z",
            "summary": "Graphical models describe associations between variables through the notion\nof conditional independence. Gaussian graphical models are a widely used class\nof such models where the relationships are formalized by non-null entries of\nthe precision matrix. However, in high dimensional cases, standard covariance\nestimates are typically unstable. Moreover, it is natural to expect only a few\nsignificant associations to be present in many realistic applications. This\nnecessitates the injection of sparsity techniques into the estimation.\nClassical frequentist methods use penalization for this purpose; in contrast,\nfully Bayesian methods are computationally slow, typically requiring iterative\nsampling over a quadratic number of parameters in a space constrained by\npositive definiteness. We propose a Bayesian graph estimation method based on\nan ensemble of Bayesian neighborhood regressions. An attractive feature of our\nmethods is the ability for easy parallelization across separate graphical\nneighborhoods, invoking computational efficiency greater than most existing\nmethods. Our strategy induces sparsity with a Horseshoe shrinkage prior and\nincludes a novel variable selection step based on the marginal likelihood from\nthe predictors ranks. Our method appropriately combines the estimated\nregression coefficients to produce a graph estimate and a matrix of partial\ncorrelation estimates for inference. Performance of various methods are\nassessed using measures like FDR and TPR. Competitive performance across a\nvariety of cases is demonstrated through extensive simulations. Lastly, we\napply these methods to investigate the dependence structure across genetic\nexpressions for women with triple negative breast cancer.",
            "author": [
                "Sagnik Bhadury",
                "Riten Mitra",
                "Jeremy T. Gaskins"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02713v1",
                "http://arxiv.org/pdf/2308.02713v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02710v1",
            "title": "Evolutionary Multi-objective Optimisation in Neurotrajectory Prediction",
            "updated": "2023-08-04T21:06:26Z",
            "published": "2023-08-04T21:06:26Z",
            "summary": "Machine learning has rapidly evolved during the last decade, achieving expert\nhuman performance on notoriously challenging problems such as image\nclassification. This success is partly due to the re-emergence of bio-inspired\nmodern artificial neural networks (ANNs) along with the availability of\ncomputation power, vast labelled data and ingenious human-based expert\nknowledge as well as optimisation approaches that can find the correct\nconfiguration (and weights) for these networks. Neuroevolution is a term used\nfor the latter when employing evolutionary algorithms. Most of the works in\nneuroevolution have focused their attention in a single type of ANNs, named\nConvolutional Neural Networks (CNNs). Moreover, most of these works have used a\nsingle optimisation approach. This work makes a progressive step forward in\nneuroevolution for vehicle trajectory prediction, referred to as\nneurotrajectory prediction, where multiple objectives must be considered. To\nthis end, rich ANNs composed of CNNs and Long-short Term Memory Network are\nadopted. Two well-known and robust Evolutionary Multi-objective Optimisation\n(EMO) algorithms, NSGA-II and MOEA/D are also adopted. The completely different\nunderlying mechanism of each of these algorithms sheds light on the\nimplications of using one over the other EMO approach in neurotrajectory\nprediction. In particular, the importance of considering objective scaling is\nhighlighted, finding that MOEA/D can be more adept at focusing on specific\nobjectives whereas, NSGA-II tends to be more invariant to objective scaling.\nAdditionally, certain objectives are shown to be either beneficial or\ndetrimental to finding valid models, for instance, inclusion of a distance\nfeedback objective was considerably detrimental to finding valid models, while\na lateral velocity objective was more beneficial.",
            "author": [
                "Edgar Galv\u00e1n",
                "Fergal Stapleton"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.asoc.2023.110693",
                "http://arxiv.org/abs/2308.02710v1",
                "http://arxiv.org/pdf/2308.02710v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02709v1",
            "title": "Scalable Computation of Causal Bounds",
            "updated": "2023-08-04T21:00:46Z",
            "published": "2023-08-04T21:00:46Z",
            "summary": "We consider the problem of computing bounds for causal queries on causal\ngraphs with unobserved confounders and discrete valued observed variables,\nwhere identifiability does not hold. Existing non-parametric approaches for\ncomputing such bounds use linear programming (LP) formulations that quickly\nbecome intractable for existing solvers because the size of the LP grows\nexponentially in the number of edges in the causal graph. We show that this LP\ncan be significantly pruned, allowing us to compute bounds for significantly\nlarger causal inference problems compared to existing techniques. This pruning\nprocedure allows us to compute bounds in closed form for a special class of\nproblems, including a well-studied family of problems where multiple confounded\ntreatments influence an outcome. We extend our pruning methodology to\nfractional LPs which compute bounds for causal queries which incorporate\nadditional observations about the unit. We show that our methods provide\nsignificant runtime improvement compared to benchmarks in experiments and\nextend our results to the finite data setting. For causal inference without\nadditional observations, we propose an efficient greedy heuristic that produces\nhigh quality bounds, and scales to problems that are several orders of\nmagnitude larger than those for which the pruned LP can be solved.",
            "author": [
                "Madhumitha Shridharan",
                "Garud Iyengar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02709v1",
                "http://arxiv.org/pdf/2308.02709v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02674v1",
            "title": "Group-$k$ consistent measurement set maximization via maximum clique\n  over k-Uniform hypergraphs for robust multi-robot map merging",
            "updated": "2023-08-04T19:15:27Z",
            "published": "2023-08-04T19:15:27Z",
            "summary": "This paper unifies the theory of consistent-set maximization for robust\noutlier detection in a simultaneous localization and mapping framework. We\nfirst describe the notion of pairwise consistency before discussing how a\nconsistency graph can be formed by evaluating pairs of measurements for\nconsistency. Finding the largest set of consistent measurements is transformed\ninto an instance of the maximum clique problem and can be solved relatively\nquickly using existing maximum-clique solvers. We then generalize our algorithm\nto check consistency on a group-$k$ basis by using a generalized notion of\nconsistency and using generalized graphs. We also present modified maximum\nclique algorithms that function on generalized graphs to find the set of\nmeasurements that is internally group-$k$ consistent. We address the\nexponential nature of group-$k$ consistency and present methods that can\nsubstantially decrease the number of necessary checks performed when evaluating\nconsistency. We extend our prior work to multi-agent systems in both simulation\nand hardware and provide a comparison with other state-of-the-art methods.",
            "author": [
                "Brendon Forsgren",
                "Ram Vasudevan",
                "Michael Kaess",
                "Timothy W. McLain",
                "Joshua G. Mangelson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02674v1",
                "http://arxiv.org/pdf/2308.02674v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02663v2",
            "title": "On RAC Drawings of Graphs with Two Bends per Edge",
            "updated": "2023-09-17T09:40:21Z",
            "published": "2023-08-04T18:50:30Z",
            "summary": "It is shown that every $n$-vertex graph that admits a 2-bend RAC drawing in\nthe plane, where the edges are polylines with two bends per edge and any pair\nof edges can only cross at a right angle, has at most $20n-24$ edges for $n\\geq\n3$. This improves upon the previous upper bound of $74.2n$; this is the first\nimprovement in more than 12 years. A crucial ingredient of the proof is an\nupper bound on the size of plane multigraphs with polyline edges in which the\nfirst and last segments are either parallel or orthogonal.",
            "author": [
                "Csaba D. T\u00f3th"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02663v2",
                "http://arxiv.org/pdf/2308.02663v2"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02651v1",
            "title": "Single-Source Unsplittable Flows in Planar Graphs",
            "updated": "2023-08-04T18:11:50Z",
            "published": "2023-08-04T18:11:50Z",
            "summary": "The single-source unsplittable flow (SSUF) problem asks to send flow from a\ncommon source to different terminals with unrelated demands, each terminal\nbeing served through a single path. One of the most heavily studied SSUF\nobjectives is to minimize the violation of some given arc capacities. A seminal\nresult of Dinitz, Garg, and Goemans showed that, whenever a fractional flow\nexists respecting the capacities, then there is an unsplittable one violating\nthe capacities by at most the maximum demand. Goemans conjectured a very\nnatural cost version of the same result, where the unsplittable flow is\nrequired to be no more expensive than the fractional one. This intriguing\nconjecture remains open. More so, there are arguably no non-trivial graph\nclasses for which it is known to hold.\n  We show that a slight weakening of it (with at most twice as large\nviolations) holds for planar graphs. Our result is based on a connection to a\nhighly structured discrepancy problem, whose repeated resolution allows us to\nsuccessively reduce the number of paths used for each terminal, until we obtain\nan unsplittable flow. Moreover, our techniques also extend to simultaneous\nupper and lower bounds on the flow values. This also affirmatively answers a\nconjecture of Morell and Skutella for planar SSUF.",
            "author": [
                "Vera Traub",
                "Laura Vargas Koch",
                "Rico Zenklusen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02651v1",
                "http://arxiv.org/pdf/2308.02651v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02643v1",
            "title": "Variational quantum algorithm for experimental photonic multiparameter\n  estimation",
            "updated": "2023-08-04T18:01:14Z",
            "published": "2023-08-04T18:01:14Z",
            "summary": "Variational quantum metrology represents a powerful tool for optimizing\ngeneric estimation strategies, combining the principles of variational\noptimization with the techniques of quantum metrology. Such optimization\nprocedures result particularly effective for multiparameter estimation\nproblems, where traditional approaches, requiring prior knowledge of the system\nbehavior, often suffer from limitations due to the curse of dimensionality and\ncomputational complexity. To overcome these challenges, we develop a\nvariational approach able to efficiently optimize a multiparameter quantum\nphase sensor operating in a noisy environment. By exploiting the high\nreconfigurability of an integrated photonic device, we implement a hybrid\nquantum-classical feedback loop able to enhance the estimation performances,\ncombining classical optimization techniques with quantum circuit evaluations.\nThe latter allows us to compute the system partial derivatives with respect to\nthe variational parameters by applying the parameter-shift rule, and thus\nreconstruct experimentally the Fisher information matrix. This in turn is\nadopted as the cost function of a derivative-free classical learning algorithm\nrun to optimize the measurement settings. Our experimental results reveal\nsignificant improvements in terms of estimation accuracy and noise robustness,\nhighlighting the potential of the implementation of variational techniques for\npractical applications in quantum sensing and more generally for quantum\ninformation processing with photonic circuits.",
            "author": [
                "Valeria Cimini",
                "Mauro Valeri",
                "Simone Piacentini",
                "Francesco Ceccarelli",
                "Giacomo Corrielli",
                "Roberto Osellame",
                "Nicol\u00f2 Spagnolo",
                "Fabio Sciarrino"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02643v1",
                "http://arxiv.org/pdf/2308.02643v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02640v1",
            "title": "Creating Android Malware Knowledge Graph Based on a Malware Ontology",
            "updated": "2023-08-04T18:00:44Z",
            "published": "2023-08-04T18:00:44Z",
            "summary": "As mobile and smart connectivity continue to grow, malware presents a\npermanently evolving threat to different types of critical domains such as\nhealth, logistics, banking, and community segments. Different types of malware\nhave dynamic behaviors and complicated characteristics that are shared among\nmembers of the same malware family. Malware threat intelligence reports play a\ncrucial role in describing and documenting the detected malware, providing a\nwealth of information regarding its attributes, patterns, and behaviors. There\nis a large amount of intelligent threat information regarding malware. The\nontology allows the systematic organization and categorization of this\ninformation to ensure consistency in representing concepts and entities across\nvarious sources. In this study, we reviewed and extended an existing malware\nontology to cover Android malware. Our extended ontology is called AndMalOnt.\nIt consisted of 13 new classes, 16 object properties, and 31 data properties.\nSecond, we created an Android malware knowledge graph by extracting reports\nfrom the MalwareBazaar repository and representing them in AndMalOnt. This\ninvolved generating a knowledge graph that encompasses over 2600 malware\nsamples. Our ontology, knowledge graph, and source code are all open-source and\naccessible via GitHub",
            "author": [
                "Ahmed Sabbah",
                "Mohammed Kharma",
                "Mustafa Jarrar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02640v1",
                "http://arxiv.org/pdf/2308.02640v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02483v1",
            "title": "Prime and polynomial distances in colourings of the plane",
            "updated": "2023-08-04T17:55:08Z",
            "published": "2023-08-04T17:55:08Z",
            "summary": "We give two extensions of the recent theorem of the first author that the odd\ndistance graph has unbounded chromatic number. The first is that for any\nnon-constant polynomial $f$ with integer coefficients and positive leading\ncoefficient, every finite colouring of the plane contains a monochromatic pair\nof distinct points whose distance is equal to $f(n)$ for some integer $n$. The\nsecond is that for every finite colouring of the plane, there is a\nmonochromatic pair of points whose distance is a prime number.",
            "author": [
                "James Davies",
                "Rose McCarty",
                "Micha\u0142 Pilipczuk"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02483v1",
                "http://arxiv.org/pdf/2308.02483v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.MG",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02477v1",
            "title": "On the Inherent Anonymity of Gossiping",
            "updated": "2023-08-04T17:39:42Z",
            "published": "2023-08-04T17:39:42Z",
            "summary": "Detecting the source of a gossip is a critical issue, related to identifying\npatient zero in an epidemic, or the origin of a rumor in a social network.\nAlthough it is widely acknowledged that random and local gossip communications\nmake source identification difficult, there exists no general quantification of\nthe level of anonymity provided to the source. This paper presents a principled\nmethod based on $\\varepsilon$-differential privacy to analyze the inherent\nsource anonymity of gossiping for a large class of graphs. First, we quantify\nthe fundamental limit of source anonymity any gossip protocol can guarantee in\nan arbitrary communication graph. In particular, our result indicates that when\nthe graph has poor connectivity, no gossip protocol can guarantee any\nmeaningful level of differential privacy. This prompted us to further analyze\ngraphs with controlled connectivity. We prove on these graphs that a large\nclass of gossip protocols, namely cobra walks, offers tangible differential\nprivacy guarantees to the source. In doing so, we introduce an original proof\ntechnique based on the reduction of a gossip protocol to what we call a random\nwalk with probabilistic die out. This proof technique is of independent\ninterest to the gossip community and readily extends to other protocols\ninherited from the security community, such as the Dandelion protocol.\nInterestingly, our tight analysis precisely captures the trade-off between\ndissemination time of a gossip protocol and its source anonymity.",
            "author": [
                "Rachid Guerraoui",
                "Anne-Marie Kermarrec",
                "Anastasiia Kucherenko",
                "Rafael Pinot",
                "Sasha Voitovych"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02477v1",
                "http://arxiv.org/pdf/2308.02477v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02473v1",
            "title": "Scalabale Path Level Thermal History Simulation of PBF process validated\n  by Melt Pool Images",
            "updated": "2023-08-04T17:23:06Z",
            "published": "2023-08-04T17:23:06Z",
            "summary": "In this paper we outline the development of a scalable PBF thermal history\nsimulation built on CAPL and based on melt pool physics and dynamics. The new\napproach inherits linear scalability from CAPL and has three novel ingredients.\nFirstly, to simulate the laser scanning on a solid surface, we discretize the\nentire simulation domain instead of only the manufacturing toolpath by\nappending fictitious paths to the manufacturing toolpath. Secondly, to simulate\nthe scanning on overlapping toolpaths, the path-scale simulations are\ninitialized by a Voronoi diagram for line segments discretized from the\nmanufacturing toolpath. Lastly, we propose a modified conduction model that\nconsiders the high thermal gradient around the melt pool. We validate the\nsimulation against melt pool images captured with the co-axial melt pool\nmonitoring (MPM) system on the NIST Additive Manufacturing Metrology Testbed\n(AMMT). Excellent agreements in the length and width of melt pools are found\nbetween simulations and experiments conducted on a custom-controlled laser\npowder bed fusion (LPBF) testbed on a nickel-alloy (IN625) solid surface. To\nthe authors' best knowledge, this paper is the first to validate a full\npath-scale thermal history with experimentally acquired melt pool images.\nComparing the simulation results and the experimental data, we discuss the\ninfluence of laser power on the melt pool length on the path-scale level. We\nalso identify the possible ways to further improve the accuracy of the CAPL\nsimulation without sacrificing efficiency.",
            "author": [
                "Xin Liu",
                "Xingchen Liu",
                "Goldy Kumar",
                "Paul Witherell"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02473v1",
                "http://arxiv.org/pdf/2308.02473v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02472v1",
            "title": "Randomized and quantum query complexities of finding a king in a\n  tournament",
            "updated": "2023-08-04T17:21:11Z",
            "published": "2023-08-04T17:21:11Z",
            "summary": "A tournament is a complete directed graph. It is well known that every\ntournament contains at least one vertex v such that every other vertex is\nreachable from v by a path of length at most 2. All such vertices v are called\n*kings* of the underlying tournament. Despite active recent research in the\narea, the best-known upper and lower bounds on the deterministic query\ncomplexity (with query access to directions of edges) of finding a king in a\ntournament on n vertices are from over 20 years ago, and the bounds do not\nmatch: the best-known lower bound is Omega(n^{4/3}) and the best-known upper\nbound is O(n^{3/2}) [Shen, Sheng, Wu, SICOMP'03]. Our contribution is to show\nessentially *tight* bounds (up to logarithmic factors) of Theta(n) and\nTheta(sqrt{n}) in the *randomized* and *quantum* query models, respectively. We\nalso study the randomized and quantum query complexities of finding a maximum\nout-degree vertex in a tournament.",
            "author": [
                "Nikhil S. Mande",
                "Manaswi Paraashar",
                "Nitin Saurabh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02472v1",
                "http://arxiv.org/pdf/2308.02472v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DS",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02465v1",
            "title": "BlindSage: Label Inference Attacks against Node-level Vertical Federated\n  Graph Neural Networks",
            "updated": "2023-08-04T17:04:58Z",
            "published": "2023-08-04T17:04:58Z",
            "summary": "Federated learning enables collaborative training of machine learning models\nby keeping the raw data of the involved workers private. One of its main\nobjectives is to improve the models' privacy, security, and scalability.\nVertical Federated Learning (VFL) offers an efficient cross-silo setting where\na few parties collaboratively train a model without sharing the same features.\nIn such a scenario, classification labels are commonly considered sensitive\ninformation held exclusively by one (active) party, while other (passive)\nparties use only their local information. Recent works have uncovered important\nflaws of VFL, leading to possible label inference attacks under the assumption\nthat the attacker has some, even limited, background knowledge on the relation\nbetween labels and data. In this work, we are the first (to the best of our\nknowledge) to investigate label inference attacks on VFL using a\nzero-background knowledge strategy. To concretely formulate our proposal, we\nfocus on Graph Neural Networks (GNNs) as a target model for the underlying VFL.\nIn particular, we refer to node classification tasks, which are widely studied,\nand GNNs have shown promising results. Our proposed attack, BlindSage, provides\nimpressive results in the experiments, achieving nearly 100% accuracy in most\ncases. Even when the attacker has no information about the used architecture or\nthe number of classes, the accuracy remained above 85% in most instances.\nFinally, we observe that well-known defenses cannot mitigate our attack without\naffecting the model's performance on the main classification task.",
            "author": [
                "Marco Arazzi",
                "Mauro Conti",
                "Stefanos Koffas",
                "Marina Krcek",
                "Antonino Nocera",
                "Stjepan Picek",
                "Jing Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02465v1",
                "http://arxiv.org/pdf/2308.02465v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02463v5",
            "title": "Towards Generalist Foundation Model for Radiology by Leveraging\n  Web-scale 2D&3D Medical Data",
            "updated": "2023-11-16T12:38:46Z",
            "published": "2023-08-04T17:00:38Z",
            "summary": "In this study, we aim to initiate the development of Radiology Foundation\nModel, termed as RadFM. We consider the construction of foundational models\nfrom three perspectives, namely, dataset construction, model design, and\nthorough evaluation. Our contribution can be concluded as follows: (i), we\nconstruct a large-scale Medical Multi-modal Dataset, MedMD, which consists of\n16M 2D and 3D medical scans with high-quality text descriptions or reports\nacross various data formats, modalities, and tasks, covering over 5000 distinct\ndiseases. To the best of our knowledge, this is the first large-scale,\nhigh-quality, medical visual-language dataset, with both 2D and 3D scans; (ii),\nwe propose an architecture that enables visually conditioned generative\npre-training, i.e., allowing for integration of text input with 2D or 3D\nmedical scans, and generate responses for diverse radiologic tasks. The model\nwas initially pre-trained on MedMD and subsequently fine-tuned on the\ndomain-specific dataset, which is a radiologic cleaned version of MedMD,\ncontaining 3M radiologic visual-language pairs, termed as RadMD; (iii), we\npropose a new evaluation benchmark, RadBench, that comprises five tasks,\nincluding modality recognition, disease diagnosis, visual question answering,\nreport generation and rationale diagnosis, aiming to comprehensively assess the\ncapability of foundation models in handling practical clinical problems. We\nconduct both automatic and human evaluation on RadBench, in both cases, RadFM\noutperforms existing multi-modal foundation models, that are publicaly\naccessible, including Openflamingo, MedFlamingo, MedVInT and GPT-4V.\nAdditionally, we also adapt RadFM for different public benchmarks, surpassing\nexisting SOTAs on diverse datasets. All codes, data, and model checkpoint will\nall be made publicly available to promote further research and development in\nthe field.",
            "author": [
                "Chaoyi Wu",
                "Xiaoman Zhang",
                "Ya Zhang",
                "Yanfeng Wang",
                "Weidi Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02463v5",
                "http://arxiv.org/pdf/2308.02463v5"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02457v1",
            "title": "A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and\n  Prospects",
            "updated": "2023-08-04T16:49:54Z",
            "published": "2023-08-04T16:49:54Z",
            "summary": "Temporal characteristics are prominently evident in a substantial volume of\nknowledge, which underscores the pivotal role of Temporal Knowledge Graphs\n(TKGs) in both academia and industry. However, TKGs often suffer from\nincompleteness for three main reasons: the continuous emergence of new\nknowledge, the weakness of the algorithm for extracting structured information\nfrom unstructured data, and the lack of information in the source dataset.\nThus, the task of Temporal Knowledge Graph Completion (TKGC) has attracted\nincreasing attention, aiming to predict missing items based on the available\ninformation. In this paper, we provide a comprehensive review of TKGC methods\nand their details. Specifically, this paper mainly consists of three\ncomponents, namely, 1)Background, which covers the preliminaries of TKGC\nmethods, loss functions required for training, as well as the dataset and\nevaluation protocol; 2)Interpolation, that estimates and predicts the missing\nelements or set of elements through the relevant available information. It\nfurther categorizes related TKGC methods based on how to process temporal\ninformation; 3)Extrapolation, which typically focuses on continuous TKGs and\npredicts future events, and then classifies all extrapolation methods based on\nthe algorithms they utilize. We further pinpoint the challenges and discuss\nfuture research directions of TKGC.",
            "author": [
                "Jiapu Wang",
                "Boyue Wang",
                "Meikang Qiu",
                "Shirui Pan",
                "Bo Xiong",
                "Heng Liu",
                "Linhao Luo",
                "Tengfei Liu",
                "Yongli Hu",
                "Baocai Yin",
                "Wen Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02457v1",
                "http://arxiv.org/pdf/2308.02457v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02442v3",
            "title": "Distribution-Informed Adaptation for kNN Graph Construction",
            "updated": "2023-11-10T05:07:51Z",
            "published": "2023-08-04T16:14:43Z",
            "summary": "Graph-based kNN algorithms have garnered widespread popularity for machine\nlearning tasks due to their simplicity and effectiveness. However, as factual\ndata often inherit complex distributions, the conventional kNN graph's reliance\non a unified k-value can hinder its performance. A crucial factor behind this\nchallenge is the presence of ambiguous samples along decision boundaries that\nare inevitably more prone to incorrect classifications. To address the\nsituation, we propose the Distribution-Informed adaptive kNN Graph (DaNNG),\nwhich combines adaptive kNN with distribution-aware graph construction. By\nincorporating an approximation of the distribution with customized k-adaption\ncriteria, DaNNG can significantly improve performance on ambiguous samples, and\nhence enhance overall accuracy and generalization capability. Through rigorous\nevaluations on diverse benchmark datasets, DaNNG outperforms state-of-the-art\nalgorithms, showcasing its adaptability and efficacy across various real-world\nscenarios.",
            "author": [
                "Shaojie Min",
                "Ji Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02442v3",
                "http://arxiv.org/pdf/2308.02442v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02622v1",
            "title": "Harnessing the Web and Knowledge Graphs for Automated Impact Investing\n  Scoring",
            "updated": "2023-08-04T15:14:16Z",
            "published": "2023-08-04T15:14:16Z",
            "summary": "The Sustainable Development Goals (SDGs) were introduced by the United\nNations in order to encourage policies and activities that help guarantee human\nprosperity and sustainability. SDG frameworks produced in the finance industry\nare designed to provide scores that indicate how well a company aligns with\neach of the 17 SDGs. This scoring enables a consistent assessment of\ninvestments that have the potential of building an inclusive and sustainable\neconomy. As a result of the high quality and reliability required by such\nframeworks, the process of creating and maintaining them is time-consuming and\nrequires extensive domain expertise. In this work, we describe a data-driven\nsystem that seeks to automate the process of creating an SDG framework. First,\nwe propose a novel method for collecting and filtering a dataset of texts from\ndifferent web sources and a knowledge graph relevant to a set of companies. We\nthen implement and deploy classifiers trained with this data for predicting\nscores of alignment with SDGs for a given company. Our results indicate that\nour best performing model can accurately predict SDG scores with a micro\naverage F1 score of 0.89, demonstrating the effectiveness of the proposed\nsolution. We further describe how the integration of the models for its use by\nhumans can be facilitated by providing explanations in the form of data\nrelevant to a predicted score. We find that our proposed solution enables\naccess to a large amount of information that analysts would normally not be\nable to process, resulting in an accurate prediction of SDG scores at a\nfraction of the cost.",
            "author": [
                "Qingzhi Hu",
                "Daniel Daza",
                "Laurens Swinkels",
                "Kristina \u016asait\u0117",
                "Robbert-Jan 't Hoen",
                "Paul Groth"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02622v1",
                "http://arxiv.org/pdf/2308.02622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02371v1",
            "title": "Fractional revival on semi-Cayley graphs over abelian groups",
            "updated": "2023-08-04T15:10:09Z",
            "published": "2023-08-04T15:10:09Z",
            "summary": "In this paper, we investigate the existence of fractional revival on\nsemi-Cayley graphs over finite abelian groups. We give some necessary and\nsufficient conditions for semi-Cayley graphs over finite abelian groups\nadmitting fractional revival. We also show that integrality is necessary for\nsome semi-Cayley graphs admitting fractional revival. Moreover, we characterize\nthe minimum time when semi-Cayley graphs admit fractional revival. As\napplications, we give examples of certain Cayley graphs over the generalized\ndihedral groups and generalized dicyclic groups admitting fractional revival.",
            "author": [
                "Jing Wang",
                "Ligong Wang",
                "Xiaogang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02371v1",
                "http://arxiv.org/pdf/2308.02371v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02370v1",
            "title": "A Machine Learning Method for Predicting Traffic Signal Timing from\n  Probe Vehicle Data",
            "updated": "2023-08-04T15:10:07Z",
            "published": "2023-08-04T15:10:07Z",
            "summary": "Traffic signals play an important role in transportation by enabling traffic\nflow management, and ensuring safety at intersections. In addition, knowing the\ntraffic signal phase and timing data can allow optimal vehicle routing for time\nand energy efficiency, eco-driving, and the accurate simulation of signalized\nroad networks. In this paper, we present a machine learning (ML) method for\nestimating traffic signal timing information from vehicle probe data. To the\nauthors best knowledge, very few works have presented ML techniques for\ndetermining traffic signal timing parameters from vehicle probe data. In this\nwork, we develop an Extreme Gradient Boosting (XGBoost) model to estimate\nsignal cycle lengths and a neural network model to determine the corresponding\nred times per phase from probe data. The green times are then be derived from\nthe cycle length and red times. Our results show an error of less than 0.56 sec\nfor cycle length, and red times predictions within 7.2 sec error on average.",
            "author": [
                "Juliette Ugirumurera",
                "Joseph Severino",
                "Erik A. Bensen",
                "Qichao Wang",
                "Jane Macfarlane"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02370v1",
                "http://arxiv.org/pdf/2308.02370v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02357v1",
            "title": "Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation\n  from Text",
            "updated": "2023-08-04T14:47:15Z",
            "published": "2023-08-04T14:47:15Z",
            "summary": "The recent advances in large language models (LLM) and foundation models with\nemergent capabilities have been shown to improve the performance of many NLP\ntasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs\ncan be used for KG construction or completion while existing KGs can be used\nfor different tasks such as making LLM outputs explainable or fact-checking in\nNeuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to\nevaluate the capabilities of language models to generate KGs from natural\nlanguage text guided by an ontology. Given an input ontology and a set of\nsentences, the task is to extract facts from the text while complying with the\ngiven ontology (concepts, relations, domain/range constraints) and being\nfaithful to the input sentences. We provide two datasets (i) Wikidata-TekGen\nwith 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19\nontologies and 4,860 sentences. We define seven evaluation metrics to measure\nfact extraction performance, ontology conformance, and hallucinations by LLMs.\nFurthermore, we provide results for two baseline models, Vicuna-13B and\nAlpaca-LoRA-13B using automatic prompt generation from test cases. The baseline\nresults show that there is room for improvement using both Semantic Web and\nNatural Language Processing techniques.",
            "author": [
                "Nandana Mihindukulasooriya",
                "Sanju Tiwari",
                "Carlos F. Enguix",
                "Kusum Lata"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02357v1",
                "http://arxiv.org/pdf/2308.02357v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68",
                "I.2.4; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02353v1",
            "title": "Adapting to Change: Robust Counterfactual Explanations in Dynamic Data\n  Landscapes",
            "updated": "2023-08-04T14:41:03Z",
            "published": "2023-08-04T14:41:03Z",
            "summary": "We introduce a novel semi-supervised Graph Counterfactual Explainer (GCE)\nmethodology, Dynamic GRAph Counterfactual Explainer (DyGRACE). It leverages\ninitial knowledge about the data distribution to search for valid\ncounterfactuals while avoiding using information from potentially outdated\ndecision functions in subsequent time steps. Employing two graph autoencoders\n(GAEs), DyGRACE learns the representation of each class in a binary\nclassification scenario. The GAEs minimise the reconstruction error between the\noriginal graph and its learned representation during training. The method\ninvolves (i) optimising a parametric density function (implemented as a\nlogistic regression function) to identify counterfactuals by maximising the\nfactual autoencoder's reconstruction error, (ii) minimising the counterfactual\nautoencoder's error, and (iii) maximising the similarity between the factual\nand counterfactual graphs. This semi-supervised approach is independent of an\nunderlying black-box oracle. A logistic regression model is trained on a set of\ngraph pairs to learn weights that aid in finding counterfactuals. At inference,\nfor each unseen graph, the logistic regressor identifies the best\ncounterfactual candidate using these learned weights, while the GAEs can be\niteratively updated to represent the continual adaptation of the learned graph\nrepresentation over iterations. DyGRACE is quite effective and can act as a\ndrift detector, identifying distributional drift based on differences in\nreconstruction errors between iterations. It avoids reliance on the oracle's\npredictions in successive iterations, thereby increasing the efficiency of\ncounterfactual discovery. DyGRACE, with its capacity for contrastive learning\nand drift detection, will offer new avenues for semi-supervised learning and\nexplanation generation.",
            "author": [
                "Bardh Prenkaj",
                "Mario Villaizan-Vallelado",
                "Tobias Leemann",
                "Gjergji Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02353v1",
                "http://arxiv.org/pdf/2308.02353v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02347v1",
            "title": "Stability and Generalization of Hypergraph Collaborative Networks",
            "updated": "2023-08-04T14:21:02Z",
            "published": "2023-08-04T14:21:02Z",
            "summary": "Graph neural networks have been shown to be very effective in utilizing\npairwise relationships across samples. Recently, there have been several\nsuccessful proposals to generalize graph neural networks to hypergraph neural\nnetworks to exploit more complex relationships. In particular, the hypergraph\ncollaborative networks yield superior results compared to other hypergraph\nneural networks for various semi-supervised learning tasks. The collaborative\nnetwork can provide high quality vertex embeddings and hyperedge embeddings\ntogether by formulating them as a joint optimization problem and by using their\nconsistency in reconstructing the given hypergraph. In this paper, we aim to\nestablish the algorithmic stability of the core layer of the collaborative\nnetwork and provide generalization guarantees. The analysis sheds light on the\ndesign of hypergraph filters in collaborative networks, for instance, how the\ndata and hypergraph filters should be scaled to achieve uniform stability of\nthe learning process. Some experimental results on real-world datasets are\npresented to illustrate the theory.",
            "author": [
                "Michael Ng",
                "Hanrui Wu",
                "Andy Yip"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02347v1",
                "http://arxiv.org/pdf/2308.02347v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02346v1",
            "title": "Class Incremental Learning with Self-Supervised Pre-Training and\n  Prototype Learning",
            "updated": "2023-08-04T14:20:42Z",
            "published": "2023-08-04T14:20:42Z",
            "summary": "Deep Neural Network (DNN) has achieved great success on datasets of closed\nclass set. However, new classes, like new categories of social media topics,\nare continuously added to the real world, making it necessary to incrementally\nlearn. This is hard for DNN because it tends to focus on fitting to new classes\nwhile ignoring old classes, a phenomenon known as catastrophic forgetting.\nState-of-the-art methods rely on knowledge distillation and data replay\ntechniques but still have limitations. In this work, we analyze the causes of\ncatastrophic forgetting in class incremental learning, which owes to three\nfactors: representation drift, representation confusion, and classifier\ndistortion. Based on this view, we propose a two-stage learning framework with\na fixed encoder and an incrementally updated prototype classifier. The encoder\nis trained with self-supervised learning to generate a feature space with high\nintrinsic dimensionality, thus improving its transferability and generality.\nThe classifier incrementally learns new prototypes while retaining the\nprototypes of previously learned data, which is crucial in preserving the\ndecision boundary.Our method does not rely on preserved samples of old classes,\nis thus a non-exemplar based CIL method. Experiments on public datasets show\nthat our method can significantly outperform state-of-the-art exemplar-based\nmethods when they reserved 5 examplers per class, under the incremental setting\nof 10 phases, by 18.24% on CIFAR-100 and 9.37% on ImageNet100.",
            "author": [
                "Wenzhuo Liu",
                "Xinjian Wu",
                "Fei Zhu",
                "Mingming Yu",
                "Chuang Wang",
                "Cheng-Lin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02346v1",
                "http://arxiv.org/pdf/2308.02346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02344v1",
            "title": "Learning Networks from Gaussian Graphical Models and Gaussian Free\n  Fields",
            "updated": "2023-08-04T14:18:39Z",
            "published": "2023-08-04T14:18:39Z",
            "summary": "We investigate the problem of estimating the structure of a weighted network\nfrom repeated measurements of a Gaussian Graphical Model (GGM) on the network.\nIn this vein, we consider GGMs whose covariance structures align with the\ngeometry of the weighted network on which they are based. Such GGMs have been\nof longstanding interest in statistical physics, and are referred to as the\nGaussian Free Field (GFF). In recent years, they have attracted considerable\ninterest in the machine learning and theoretical computer science. In this\nwork, we propose a novel estimator for the weighted network (equivalently, its\nLaplacian) from repeated measurements of a GFF on the network, based on the\nFourier analytic properties of the Gaussian distribution. In this pursuit, our\napproach exploits complex-valued statistics constructed from observed data,\nthat are of interest on their own right. We demonstrate the effectiveness of\nour estimator with concrete recovery guarantees and bounds on the required\nsample complexity. In particular, we show that the proposed statistic achieves\nthe parametric rate of estimation for fixed network size. In the setting of\nnetworks growing with sample size, our results show that for Erdos-Renyi random\ngraphs $G(d,p)$ above the connectivity threshold, we demonstrate that network\nrecovery takes place with high probability as soon as the sample size $n$\nsatisfies $n \\gg d^4 \\log d \\cdot p^{-2}$.",
            "author": [
                "Subhro Ghosh",
                "Soumendu Sundar Mukherjee",
                "Hoang-Son Tran",
                "Ujan Gangopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02344v1",
                "http://arxiv.org/pdf/2308.02344v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.CO",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02339v1",
            "title": "Improving Scene Graph Generation with Superpixel-Based Interaction\n  Learning",
            "updated": "2023-08-04T14:12:32Z",
            "published": "2023-08-04T14:12:32Z",
            "summary": "Recent advances in Scene Graph Generation (SGG) typically model the\nrelationships among entities utilizing box-level features from pre-defined\ndetectors. We argue that an overlooked problem in SGG is the coarse-grained\ninteractions between boxes, which inadequately capture contextual semantics for\nrelationship modeling, practically limiting the development of the field. In\nthis paper, we take the initiative to explore and propose a generic paradigm\ntermed Superpixel-based Interaction Learning (SIL) to remedy coarse-grained\ninteractions at the box level. It allows us to model fine-grained interactions\nat the superpixel level in SGG. Specifically, (i) we treat a scene as a set of\npoints and cluster them into superpixels representing sub-regions of the scene.\n(ii) We explore intra-entity and cross-entity interactions among the\nsuperpixels to enrich fine-grained interactions between entities at an earlier\nstage. Extensive experiments on two challenging benchmarks (Visual Genome and\nOpen Image V6) prove that our SIL enables fine-grained interaction at the\nsuperpixel level above previous box-level methods, and significantly\noutperforms previous state-of-the-art methods across all metrics. More\nencouragingly, the proposed method can be applied to boost the performance of\nexisting box-level approaches in a plug-and-play fashion. In particular, SIL\nbrings an average improvement of 2.0% mR (even up to 3.4%) of baselines for the\nPredCls task on Visual Genome, which facilitates its integration into any\nexisting box-level method.",
            "author": [
                "Jingyi Wang",
                "Can Zhang",
                "Jinfa Huang",
                "Botao Ren",
                "Zhidong Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02339v1",
                "http://arxiv.org/pdf/2308.02339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02335v2",
            "title": "RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph\n  Classification",
            "updated": "2023-09-07T07:46:16Z",
            "published": "2023-08-04T14:06:44Z",
            "summary": "Graph classification is a crucial task in many real-world multimedia\napplications, where graphs can represent various multimedia data types such as\nimages, videos, and social networks. Previous efforts have applied graph neural\nnetworks (GNNs) in balanced situations where the class distribution is\nbalanced. However, real-world data typically exhibit long-tailed class\ndistributions, resulting in a bias towards the head classes when using GNNs and\nlimited generalization ability over the tail classes. Recent approaches mainly\nfocus on re-balancing different classes during model training, which fails to\nexplicitly introduce new knowledge and sacrifices the performance of the head\nclasses. To address these drawbacks, we propose a novel framework called\nRetrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature\nextractor and an unbiased classifier in a decoupled manner. In the feature\nextractor training stage, we develop a graph retrieval module to search for\nrelevant graphs that directly enrich the intra-class diversity for the tail\nclasses. Moreover, we innovatively optimize a category-centered supervised\ncontrastive loss to obtain discriminative representations, which is more\nsuitable for long-tailed scenarios. In the classifier fine-tuning stage, we\nbalance the classifier weights with two weight regularization techniques, i.e.,\nMax-norm and weight decay. Experiments on various popular benchmarks verify the\nsuperiority of the proposed method against state-of-the-art approaches.",
            "author": [
                "Zhengyang Mao",
                "Wei Ju",
                "Yifang Qin",
                "Xiao Luo",
                "Ming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02335v2",
                "http://arxiv.org/pdf/2308.02335v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02611v3",
            "title": "Path Counting on Tree-like Graphs with a Single Entropic Trap: Critical\n  Behavior and Finite Size Effects",
            "updated": "2023-09-21T06:51:09Z",
            "published": "2023-08-04T13:54:01Z",
            "summary": "It is known that maximal entropy random walks and partition functions that\ncount long paths on graphs tend to become localized near nodes with a high\ndegree. Here, we revisit the simplest toy model of such a localization: a\nregular tree of degree $p$ with one special node (\"root\") that has a degree\ndifferent from all the others. We present an in-depth study of the\npath-counting problem precisely at the localization transition. We study paths\nthat start from the root in both infinite trees and finite, locally tree-like\nregular random graphs (RRGs). For the infinite tree, we prove that the\nprobability distribution function of the endpoints of the path is a step\nfunction. The position of the step moves away from the root at a constant\nvelocity $v=(p-2)/p$. We find the width and asymptotic shape of the\ndistribution in the vicinity of the shock. For a finite RRG, we show that a\ncritical slowdown takes place, and the trajectory length needed to reach the\nequilibrium distribution is on the order of $\\sqrt{N}$ instead of $\\log_{p-1}N$\naway from the transition. We calculate the exact values of the equilibrium\ndistribution and relaxation length, as well as the shapes of slowly relaxing\nmodes.",
            "author": [
                "Alexey V. Gulyaev",
                "Mikhail V. Tamm"
            ],
            "link": [
                "http://dx.doi.org/10.3390/e25091318",
                "http://arxiv.org/abs/2308.02611v3",
                "http://arxiv.org/pdf/2308.02611v3"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02286v1",
            "title": "Minimum-Latency Scheduling For Partial-Information Multiple Access\n  Schemes",
            "updated": "2023-08-04T12:42:27Z",
            "published": "2023-08-04T12:42:27Z",
            "summary": "Partial-information multiple access (PIMA) is an orthogonal multiple access\n(OMA) uplink scheme where time is divided into frames, each composed of two\nparts. The first part is used to count the number of users with packets to\ntransmit, while the second has a variable number of allocated slots, each\nassigned to multiple users to uplink data transmission. We investigate the case\nof correlated user activations, wherein the correlation is due to the\nretransmissions of the collided packets, modeling PIMA as a partially\nobservable-Markov decision process. The assignment of users to slots is\noptimized based on the knowledge of both the number of active users and past\nsuccessful transmissions and collisions. The scheduling turns out to be a mixed\ninteger nonlinear programming problem, with a complexity exponentially growing\nwith the number of users. Thus, sub-optimal greedy solutions are proposed and\nevaluated. Our solutions show substantial performance improvements with respect\nto both traditional OMA schemes and conventional PIMA.",
            "author": [
                "Alberto Rech",
                "Stefano Tomasin",
                "Lorenzo Vangelista",
                "Cristina Costa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02286v1",
                "http://arxiv.org/pdf/2308.02286v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02282v1",
            "title": "DIVERSIFY: A General Framework for Time Series Out-of-distribution\n  Detection and Generalization",
            "updated": "2023-08-04T12:27:11Z",
            "published": "2023-08-04T12:27:11Z",
            "summary": "Time series remains one of the most challenging modalities in machine\nlearning research. The out-of-distribution (OOD) detection and generalization\non time series tend to suffer due to its non-stationary property, i.e., the\ndistribution changes over time. The dynamic distributions inside time series\npose great challenges to existing algorithms to identify invariant\ndistributions since they mainly focus on the scenario where the domain\ninformation is given as prior knowledge. In this paper, we attempt to exploit\nsubdomains within a whole dataset to counteract issues induced by\nnon-stationary for generalized representation learning. We propose DIVERSIFY, a\ngeneral framework, for OOD detection and generalization on dynamic\ndistributions of time series. DIVERSIFY takes an iterative process: it first\nobtains the \"worst-case\" latent distribution scenario via adversarial training,\nthen reduces the gap between these latent distributions. We implement DIVERSIFY\nvia combining existing OOD detection methods according to either extracted\nfeatures or outputs of models for detection while we also directly utilize\noutputs for classification. In addition, theoretical insights illustrate that\nDIVERSIFY is theoretically supported. Extensive experiments are conducted on\nseven datasets with different OOD settings across gesture recognition, speech\ncommands recognition, wearable stress and affect detection, and sensor-based\nhuman activity recognition. Qualitative and quantitative results demonstrate\nthat DIVERSIFY learns more generalized features and significantly outperforms\nother baselines.",
            "author": [
                "Wang Lu",
                "Jindong Wang",
                "Xinwei Sun",
                "Yiqiang Chen",
                "Xiangyang Ji",
                "Qiang Yang",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02282v1",
                "http://arxiv.org/pdf/2308.02282v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03789v1",
            "title": "Semantic Channel Equalizer: Modelling Language Mismatch in Multi-User\n  Semantic Communications",
            "updated": "2023-08-04T12:08:19Z",
            "published": "2023-08-04T12:08:19Z",
            "summary": "We consider a multi-user semantic communications system in which agents\n(transmitters and receivers) interact through the exchange of semantic messages\nto convey meanings. In this context, languages are instrumental in structuring\nthe construction and consolidation of knowledge, influencing conceptual\nrepresentation and semantic extraction and interpretation. Yet, the crucial\nrole of languages in semantic communications is often overlooked. When this is\nnot the case, agent languages are assumed compatible and unambiguously\ninteroperable, ignoring practical limitations that may arise due to language\nmismatching. This is the focus of this work. When agents use distinct\nlanguages, message interpretation is prone to semantic noise resulting from\ncritical distortion introduced by semantic channels. To address this problem,\nthis paper proposes a new semantic channel equalizer to counteract and limit\nthe critical ambiguity in message interpretation. Our proposed solution models\nthe mismatch of languages with measurable transformations over semantic\nrepresentation spaces. We achieve this using optimal transport theory, where we\nmodel such transformations as transportation maps. Then, to recover at the\nreceiver the meaning intended by the teacher we operate semantic equalization\nto compensate for the transformation introduced by the semantic channel, either\nbefore transmission and/or after the reception of semantic messages. We\nimplement the proposed approach as an operation over a codebook of\ntransformations specifically designed for successful communication. Numerical\nresults show that the proposed semantic channel equalizer outperforms\ntraditional approaches in terms of operational complexity and transmission\naccuracy.",
            "author": [
                "Mohamed Sana",
                "Emilio Calvanese Strinati"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03789v1",
                "http://arxiv.org/pdf/2308.03789v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02269v1",
            "title": "Optimally Computing Compressed Indexing Arrays Based on the Compact\n  Directed Acyclic Word Graph",
            "updated": "2023-08-04T11:46:12Z",
            "published": "2023-08-04T11:46:12Z",
            "summary": "In this paper, we present the first study of the computational complexity of\nconverting an automata-based text index structure, called the Compact Directed\nAcyclic Word Graph (CDAWG), of size $e$ for a text $T$ of length $n$ into other\ntext indexing structures for the same text, suitable for highly repetitive\ntexts: the run-length BWT of size $r$, the irreducible PLCP array of size $r$,\nand the quasi-irreducible LPF array of size $e$, as well as the lex-parse of\nsize $O(r)$ and the LZ77-parse of size $z$, where $r, z \\le e$. As main\nresults, we showed that the above structures can be optimally computed from\neither the CDAWG for $T$ stored in read-only memory or its self-index version\nof size $e$ without a text in $O(e)$ worst-case time and words of working\nspace. To obtain the above results, we devised techniques for enumerating a\nparticular subset of suffixes in the lexicographic and text orders using the\nforward and backward search on the CDAWG by extending the results by\nBelazzougui et al. in 2015.",
            "author": [
                "Hiroki Arimura",
                "Shunsuke Inenaga",
                "Yasuaki Kobayashi",
                "Yuto Nakashima",
                "Mizuki Sue"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02269v1",
                "http://arxiv.org/pdf/2308.02269v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.FL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02242v1",
            "title": "Countering Eavesdroppers with Meta-learning-based Cooperative Ambient\n  Backscatter Communications",
            "updated": "2023-08-04T10:43:17Z",
            "published": "2023-08-04T10:43:17Z",
            "summary": "This article introduces a novel lightweight framework using ambient\nbackscattering communications to counter eavesdroppers. In particular, our\nframework divides an original message into two parts: (i) the active-transmit\nmessage transmitted by the transmitter using conventional RF signals and (ii)\nthe backscatter message transmitted by an ambient backscatter tag that\nbackscatters upon the active signals emitted by the transmitter. Notably, the\nbackscatter tag does not generate its own signal, making it difficult for an\neavesdropper to detect the backscattered signals unless they have prior\nknowledge of the system. Here, we assume that without decoding/knowing the\nbackscatter message, the eavesdropper is unable to decode the original message.\nEven in scenarios where the eavesdropper can capture both messages,\nreconstructing the original message is a complex task without understanding the\nintricacies of the message-splitting mechanism. A challenge in our proposed\nframework is to effectively decode the backscattered signals at the receiver,\noften accomplished using the maximum likelihood (MLK) approach. However, such a\nmethod may require a complex mathematical model together with perfect channel\nstate information (CSI). To address this issue, we develop a novel deep\nmeta-learning-based signal detector that can not only effectively decode the\nweak backscattered signals without requiring perfect CSI but also quickly adapt\nto a new wireless environment with very little knowledge. Simulation results\nshow that our proposed learning approach, without requiring perfect CSI and\ncomplex mathematical model, can achieve a bit error ratio close to that of the\nMLK-based approach. They also clearly show the efficiency of the proposed\napproach in dealing with eavesdropping attacks and the lack of training data\nfor deep learning models in practical scenarios.",
            "author": [
                "Nam H. Chu",
                "Nguyen Van Huynh",
                "Diep N. Nguyen",
                "Dinh Thai Hoang",
                "Shimin Gong",
                "Tao Shu",
                "Eryk Dutkiewicz",
                "Khoa T. Phan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02242v1",
                "http://arxiv.org/pdf/2308.02242v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02603v2",
            "title": "Knowledge-Driven Multi-Agent Reinforcement Learning for Computation\n  Offloading in Cybertwin-Enabled Internet of Vehicles",
            "updated": "2023-09-08T13:14:16Z",
            "published": "2023-08-04T09:11:37Z",
            "summary": "By offloading computation-intensive tasks of vehicles to roadside units\n(RSUs), mobile edge computing (MEC) in the Internet of Vehicles (IoV) can\nrelieve the onboard computation burden. However, existing model-based task\noffloading methods suffer from heavy computational complexity with the increase\nof vehicles and data-driven methods lack interpretability. To address these\nchallenges, in this paper, we propose a knowledge-driven multi-agent\nreinforcement learning (KMARL) approach to reduce the latency of task\noffloading in cybertwin-enabled IoV. Specifically, in the considered scenario,\nthe cybertwin serves as a communication agent for each vehicle to exchange\ninformation and make offloading decisions in the virtual space. To reduce the\nlatency of task offloading, a KMARL approach is proposed to select the optimal\noffloading option for each vehicle, where graph neural networks are employed by\nleveraging domain knowledge concerning graph-structure communication topology\nand permutation invariance into neural networks. Numerical results show that\nour proposed KMARL yields higher rewards and demonstrates improved scalability\ncompared with other methods, benefitting from the integration of domain\nknowledge.",
            "author": [
                "Ruijin Sun",
                "Xiao Yang",
                "Nan Cheng",
                "Xiucheng Wang",
                "Changle Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02603v2",
                "http://arxiv.org/pdf/2308.02603v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02202v2",
            "title": "SoK: The Ghost Trilemma",
            "updated": "2023-08-07T21:56:58Z",
            "published": "2023-08-04T08:36:43Z",
            "summary": "Trolls, bots, and sybils distort online discourse and compromise the security\nof networked platforms. User identity is central to the vectors of attack and\nmanipulation employed in these contexts. However it has long seemed that, try\nas it might, the security community has been unable to stem the rising tide of\nsuch problems. We posit the Ghost Trilemma, that there are three key properties\nof identity -- sentience, location, and uniqueness -- that cannot be\nsimultaneously verified in a fully-decentralized setting. Many\nfully-decentralized systems -- whether for communication or social coordination\n-- grapple with this trilemma in some way, perhaps unknowingly. In this\nSystematization of Knowledge (SoK) paper, we examine the design space, use\ncases, problems with prior approaches, and possible paths forward. We sketch a\nproof of this trilemma and outline options for practical, incrementally\ndeployable schemes to achieve an acceptable tradeoff of trust in centralized\ntrust anchors, decentralized operation, and an ability to withstand a range of\nattacks, while protecting user privacy.",
            "author": [
                "S. Mukherjee",
                "S. Ravi",
                "P. Schmitt",
                "B. Raghavan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02202v2",
                "http://arxiv.org/pdf/2308.02202v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY",
                "D.4.6; H.5; K.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02200v1",
            "title": "Online Obstacle evasion with Space-Filling Curves",
            "updated": "2023-08-04T08:34:15Z",
            "published": "2023-08-04T08:34:15Z",
            "summary": "The paper presents a strategy for robotic exploration problems using\nSpace-Filling curves (SFC). The region of interest is first tessellated, and\nthe tiles/cells are connected using some SFC. A robot follows the SFC to\nexplore the entire area. However, there could be obstacles that block the\nsystematic movement of the robot. We overcome this problem by providing an\nevading technique that avoids the blocked tiles while ensuring all the free\nones are visited at least once. The proposed strategy is online, implying that\nprior knowledge of the obstacles is not mandatory. It works for all SFCs, but\nfor the sake of demonstration, we use Hilbert curve. We present the\ncompleteness of the algorithm and discuss its desirable properties with\nexamples. We also address the non-uniform coverage problem using our strategy.",
            "author": [
                "Ashay Wakode",
                "Arpita Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02200v1",
                "http://arxiv.org/pdf/2308.02200v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02185v1",
            "title": "From Fake to Hyperpartisan News Detection Using Domain Adaptation",
            "updated": "2023-08-04T07:58:48Z",
            "published": "2023-08-04T07:58:48Z",
            "summary": "Unsupervised Domain Adaptation (UDA) is a popular technique that aims to\nreduce the domain shift between two data distributions. It was successfully\napplied in computer vision and natural language processing. In the current\nwork, we explore the effects of various unsupervised domain adaptation\ntechniques between two text classification tasks: fake and hyperpartisan news\ndetection. We investigate the knowledge transfer from fake to hyperpartisan\nnews detection without involving target labels during training. Thus, we\nevaluate UDA, cluster alignment with a teacher, and cross-domain contrastive\nlearning. Extensive experiments show that these techniques improve performance,\nwhile including data augmentation further enhances the results. In addition, we\ncombine clustering and topic modeling algorithms with UDA, resulting in\nimproved performances compared to the initial UDA setup.",
            "author": [
                "R\u0103zvan-Alexandru Sm\u0103du",
                "Sebastian-Vasile Echim",
                "Dumitru-Clementin Cercel",
                "Iuliana Marin",
                "Florin Pop"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02185v1",
                "http://arxiv.org/pdf/2308.02185v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02177v1",
            "title": "Scene-aware Human Pose Generation using Transformer",
            "updated": "2023-08-04T07:39:09Z",
            "published": "2023-08-04T07:39:09Z",
            "summary": "Affordance learning considers the interaction opportunities for an actor in\nthe scene and thus has wide application in scene understanding and intelligent\nrobotics. In this paper, we focus on contextual affordance learning, i.e.,\nusing affordance as context to generate a reasonable human pose in a scene.\nExisting scene-aware human pose generation methods could be divided into two\ncategories depending on whether using pose templates. Our proposed method\nbelongs to the template-based category, which benefits from the representative\npose templates. Moreover, inspired by recent transformer-based methods, we\nassociate each query embedding with a pose template, and use the interaction\nbetween query embeddings and scene feature map to effectively predict the scale\nand offsets for each pose template. In addition, we employ knowledge\ndistillation to facilitate the offset learning given the predicted scale.\nComprehensive experiments on Sitcom dataset demonstrate the effectiveness of\nour method.",
            "author": [
                "Jieteng Yao",
                "Junjie Chen",
                "Li Niu",
                "Bin Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02177v1",
                "http://arxiv.org/pdf/2308.02177v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02172v1",
            "title": "Delete: Deep Lead Optimization Enveloped in Protein Pocket through\n  Unified Deleting Strategies and a Structure-aware Network",
            "updated": "2023-08-04T07:18:08Z",
            "published": "2023-08-04T07:18:08Z",
            "summary": "Drug discovery is a highly complicated process, and it is unfeasible to fully\ncommit it to the recently developed molecular generation methods. Deep\nlearning-based lead optimization takes expert knowledge as a starting point,\nlearning from numerous historical cases about how to modify the structure for\nbetter drug-forming properties. However, compared with the more established de\nnovo generation schemes, lead optimization is still an area that requires\nfurther exploration. Previously developed models are often limited to resolving\none (or few) certain subtask(s) of lead optimization, and most of them can only\ngenerate the two-dimensional structures of molecules while disregarding the\nvital protein-ligand interactions based on the three-dimensional binding poses.\nTo address these challenges, we present a novel tool for lead optimization,\nnamed Delete (Deep lead optimization enveloped in protein pocket). Our model\ncan handle all subtasks of lead optimization involving fragment growing,\nlinking, and replacement through a unified deleting (masking) strategy, and is\naware of the intricate pocket-ligand interactions through the geometric design\nof networks. Statistical evaluations and case studies conducted on individual\nsubtasks demonstrate that Delete has a significant ability to produce molecules\nwith superior binding affinities to protein targets and reasonable\ndrug-likeness from given fragments or atoms. This feature may assist medicinal\nchemists in developing not only me-too/me-better products from existing drugs\nbut also hit-to-lead for first-in-class drugs in a highly efficient manner.",
            "author": [
                "Haotian Zhang",
                "Huifeng Zhao",
                "Xujun Zhang",
                "Qun Su",
                "Hongyan Du",
                "Chao Shen",
                "Zhe Wang",
                "Dan Li",
                "Peichen Pan",
                "Guangyong Chen",
                "Yu Kang",
                "Chang-yu Hsieh",
                "Tingjun Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02172v1",
                "http://arxiv.org/pdf/2308.02172v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02167v1",
            "title": "IntLearner: AI-enabled Interference Mitigation for Wireless Networks",
            "updated": "2023-08-04T07:01:35Z",
            "published": "2023-08-04T07:01:35Z",
            "summary": "The future Six-Generation (6G) envisions massive access of wireless devices\nin the network, leading to more serious interference from concurrent\ntransmissions between wireless devices in the same frequency band. Existing\ninterference mitigation approaches takes the interference signals as Gaussian\nwhite noise, which cannot precisely estimate the non-Gaussian interference\nsignals from other devices. In this paper, we present IntLearner, a new\ninterference mitigation technique that estimates and mitigates the impact of\ninterference signals with only physical-layer (PHY) information available in\nbase-station (BS) and user-equipment (UE), including channel estimator and\nconstellations. More specifically, IntLearner utilizes the power of AI to\nestimate the features in interference signals, and removes the interference\nfrom the interfered received signal with neural network (NN). IntLearner's NN\nadopts a modular NN design, which takes the domain knowledge of BS and UE PHY\nas the guidance to NN design for minimizing training confusion and NN\ncomplexity. Simulation results show IntLearner increases Uplink (UL) channel\nestimation accuracy up to 7.4x, and reduces the Downlink (DL) Signal to\nInterference Ratio plus Noise Ratio (SINR) requirement to achieve the same\nBlock Error Rate (BLER) by 1.5dB in a conventional multi-cell scenario.",
            "author": [
                "Ruirong Chen",
                "Gaoning He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02167v1",
                "http://arxiv.org/pdf/2308.02167v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04517v1",
            "title": "Capturing Spectral and Long-term Contextual Information for Speech\n  Emotion Recognition Using Deep Learning Techniques",
            "updated": "2023-08-04T06:20:42Z",
            "published": "2023-08-04T06:20:42Z",
            "summary": "Traditional approaches in speech emotion recognition, such as LSTM, CNN, RNN,\nSVM, and MLP, have limitations such as difficulty capturing long-term\ndependencies in sequential data, capturing the temporal dynamics, and\nstruggling to capture complex patterns and relationships in multimodal data.\nThis research addresses these shortcomings by proposing an ensemble model that\ncombines Graph Convolutional Networks (GCN) for processing textual data and the\nHuBERT transformer for analyzing audio signals. We found that GCNs excel at\ncapturing Long-term contextual dependencies and relationships within textual\ndata by leveraging graph-based representations of text and thus detecting the\ncontextual meaning and semantic relationships between words. On the other hand,\nHuBERT utilizes self-attention mechanisms to capture long-range dependencies,\nenabling the modeling of temporal dynamics present in speech and capturing\nsubtle nuances and variations that contribute to emotion recognition. By\ncombining GCN and HuBERT, our ensemble model can leverage the strengths of both\napproaches. This allows for the simultaneous analysis of multimodal data, and\nthe fusion of these modalities enables the extraction of complementary\ninformation, enhancing the discriminative power of the emotion recognition\nsystem. The results indicate that the combined model can overcome the\nlimitations of traditional methods, leading to enhanced accuracy in recognizing\nemotions from speech.",
            "author": [
                "Samiul Islam",
                "Md. Maksudul Haque",
                "Abu Jobayer Md. Sadat"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04517v1",
                "http://arxiv.org/pdf/2308.04517v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.09780v2",
            "title": "Event-based Dynamic Graph Representation Learning for Patent Application\n  Trend Prediction",
            "updated": "2023-09-05T03:32:19Z",
            "published": "2023-08-04T05:43:32Z",
            "summary": "Accurate prediction of what types of patents that companies will apply for in\nthe next period of time can figure out their development strategies and help\nthem discover potential partners or competitors in advance. Although important,\nthis problem has been rarely studied in previous research due to the challenges\nin modelling companies' continuously evolving preferences and capturing the\nsemantic correlations of classification codes. To fill in this gap, we propose\nan event-based dynamic graph learning framework for patent application trend\nprediction. In particular, our method is founded on the memorable\nrepresentations of both companies and patent classification codes. When a new\npatent is observed, the representations of the related companies and\nclassification codes are updated according to the historical memories and the\ncurrently encoded messages. Moreover, a hierarchical message passing mechanism\nis provided to capture the semantic proximities of patent classification codes\nby updating their representations along the hierarchical taxonomy. Finally, the\npatent application trend is predicted by aggregating the representations of the\ntarget company and classification codes from static, dynamic, and hierarchical\nperspectives. Experiments on real-world data demonstrate the effectiveness of\nour approach under various experimental conditions, and also reveal the\nabilities of our method in learning semantics of classification codes and\ntracking technology developing trajectories of companies.",
            "author": [
                "Tao Zou",
                "Le Yu",
                "Leilei Sun",
                "Bowen Du",
                "Deqing Wang",
                "Fuzhen Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.09780v2",
                "http://arxiv.org/pdf/2308.09780v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02131v1",
            "title": "Graph Convolutional Network Enabled Power-Constrained HARQ Strategy for\n  URLLC",
            "updated": "2023-08-04T04:18:50Z",
            "published": "2023-08-04T04:18:50Z",
            "summary": "In this paper, a power-constrained hybrid automatic repeat request (HARQ)\ntransmission strategy is developed to support ultra-reliable low-latency\ncommunications (URLLC). In particular, we aim to minimize the delivery latency\nof HARQ schemes over time-correlated fading channels, meanwhile ensuring the\nhigh reliability and limited power consumption. To ease the optimization, the\nsimple asymptotic outage expressions of HARQ schemes are adopted. Furthermore,\nby noticing the non-convexity of the latency minimization problem and the\nintricate connection between different HARQ rounds, the graph convolutional\nnetwork (GCN) is invoked for the optimal power solution owing to its powerful\nability of handling the graph data. The primal-dual learning method is then\nleveraged to train the GCN weights. Consequently, the numerical results are\npresented for verification together with the comparisons among three HARQ\nschemes in terms of the latency and the reliability, where the three HARQ\nschemes include Type-I HARQ, HARQ with chase combining (HARQ-CC), and HARQ with\nincremental redundancy (HARQ-IR). To recapitulate, it is revealed that HARQ-IR\noffers the lowest latency while guaranteeing the demanded reliability target\nunder a stringent power constraint, albeit at the price of high coding\ncomplexity.",
            "author": [
                "Yi Chen",
                "Zheng Shi",
                "Hong Wang",
                "Yaru Fu",
                "Guanghua Yang",
                "Shaodan Ma",
                "Haichuan Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02131v1",
                "http://arxiv.org/pdf/2308.02131v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02127v1",
            "title": "Total outer-connected domination number of middle graphs",
            "updated": "2023-08-04T03:59:51Z",
            "published": "2023-08-04T03:59:51Z",
            "summary": "In this paper, we study the total outer-connected domination number of the\nmiddle graph of a simple graph and we obtain tight bounds for this number in\nterms of the order of the middle graph. We also compute the total\nouter-connected domination number of some families of graphs, explicitly.\nMoreover, some Nordhaus-Gaddum-like relations are presented for the total\nouter-connected domination number of middle graphs.",
            "author": [
                "Farshad Kazemnejad",
                "Behnaz Pahlavsay",
                "Elisa Palezzato",
                "Michele Torielli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02127v1",
                "http://arxiv.org/pdf/2308.02127v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02119v1",
            "title": "Attention-Driven Lightweight Model for Pigmented Skin Lesion Detection",
            "updated": "2023-08-04T03:18:18Z",
            "published": "2023-08-04T03:18:18Z",
            "summary": "This study presents a lightweight pipeline for skin lesion detection,\naddressing the challenges posed by imbalanced class distribution and subtle or\natypical appearances of some lesions. The pipeline is built around a\nlightweight model that leverages ghosted features and the DFC attention\nmechanism to reduce computational complexity while maintaining high\nperformance. The model was trained on the HAM10000 dataset, which includes\nvarious types of skin lesions. To address the class imbalance in the dataset,\nthe synthetic minority over-sampling technique and various image augmentation\ntechniques were used. The model also incorporates a knowledge-based loss\nweighting technique, which assigns different weights to the loss function at\nthe class level and the instance level, helping the model focus on minority\nclasses and challenging samples. This technique involves assigning different\nweights to the loss function on two levels - the class level and the instance\nlevel. By applying appropriate loss weights, the model pays more attention to\nthe minority classes and challenging samples, thus improving its ability to\ncorrectly detect and classify different skin lesions. The model achieved an\naccuracy of 92.4%, a precision of 84.2%, a recall of 86.9%, a f1-score of 85.4%\nwith particularly strong performance in identifying Benign Keratosis-like\nlesions (BKL) and Nevus (NV). Despite its superior performance, the model's\ncomputational cost is considerably lower than some models with less accuracy,\nmaking it an optimal solution for real-world applications where both accuracy\nand efficiency are essential.",
            "author": [
                "Mingzhe Hu",
                "Xiaofeng Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02119v1",
                "http://arxiv.org/pdf/2308.02119v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02117v2",
            "title": "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and\n  MLPs",
            "updated": "2023-09-19T02:57:16Z",
            "published": "2023-08-04T02:58:08Z",
            "summary": "GNN-to-MLP distillation aims to utilize knowledge distillation (KD) to learn\ncomputationally-efficient multi-layer perceptron (student MLP) on graph data by\nmimicking the output representations of teacher GNN. Existing methods mainly\nmake the MLP to mimic the GNN predictions over a few class labels. However, the\nclass space may not be expressive enough for covering numerous diverse local\ngraph structures, thus limiting the performance of knowledge transfer from GNN\nto MLP. To address this issue, we propose to learn a new powerful graph\nrepresentation space by directly labeling nodes' diverse local structures for\nGNN-to-MLP distillation. Specifically, we propose a variant of VQ-VAE to learn\na structure-aware tokenizer on graph data that can encode each node's local\nsubstructure as a discrete code. The discrete codes constitute a codebook as a\nnew graph representation space that is able to identify different local graph\nstructures of nodes with the corresponding code indices. Then, based on the\nlearned codebook, we propose a new distillation target, namely soft code\nassignments, to directly transfer the structural knowledge of each node from\nGNN to MLP. The resulting framework VQGraph achieves new state-of-the-art\nperformance on GNN-to-MLP distillation in both transductive and inductive\nsettings across seven graph datasets. We show that VQGraph with better\nperformance infers faster than GNNs by 828x, and also achieves accuracy\nimprovement over GNNs and stand-alone MLPs by 3.90% and 28.05% on average,\nrespectively. Code: https://github.com/YangLing0818/VQGraph.",
            "author": [
                "Ling Yang",
                "Ye Tian",
                "Minkai Xu",
                "Zhongyi Liu",
                "Shenda Hong",
                "Wei Qu",
                "Wentao Zhang",
                "Bin Cui",
                "Muhan Zhang",
                "Jure Leskovec"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02117v2",
                "http://arxiv.org/pdf/2308.02117v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02113v1",
            "title": "Chinese Financial Text Emotion Mining: GCGTS -- A Character\n  Relationship-based Approach for Simultaneous Aspect-Opinion Pair Extraction",
            "updated": "2023-08-04T02:20:56Z",
            "published": "2023-08-04T02:20:56Z",
            "summary": "Aspect-Opinion Pair Extraction (AOPE) from Chinese financial texts is a\nspecialized task in fine-grained text sentiment analysis. The main objective is\nto extract aspect terms and opinion terms simultaneously from a diverse range\nof financial texts. Previous studies have mainly focused on developing grid\nannotation schemes within grid-based models to facilitate this extraction\nprocess. However, these methods often rely on character-level (token-level)\nfeature encoding, which may overlook the logical relationships between Chinese\ncharacters within words. To address this limitation, we propose a novel method\ncalled Graph-based Character-level Grid Tagging Scheme (GCGTS). The GCGTS\nmethod explicitly incorporates syntactic structure using Graph Convolutional\nNetworks (GCN) and unifies the encoding of characters within the same syntactic\nsemantic unit (Chinese word level). Additionally, we introduce an image\nconvolutional structure into the grid model to better capture the local\nrelationships between characters within evaluation units. This innovative\nstructure reduces the excessive reliance on pre-trained language models and\nemphasizes the modeling of structure and local relationships, thereby improving\nthe performance of the model on Chinese financial texts. Through comparative\nexperiments with advanced models such as Synchronous Double-channel Recurrent\nNetwork (SDRN) and Grid Tagging Scheme (GTS), the proposed GCGTS model\ndemonstrates significant improvements in performance.",
            "author": [
                "Qi Chen",
                "Dexi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02113v1",
                "http://arxiv.org/pdf/2308.02113v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02103v1",
            "title": "Prompt2Gaussia: Uncertain Prompt-learning for Script Event Prediction",
            "updated": "2023-08-04T01:34:46Z",
            "published": "2023-08-04T01:34:46Z",
            "summary": "Script Event Prediction (SEP) aims to predict the subsequent event for a\ngiven event chain from a candidate list. Prior research has achieved great\nsuccess by integrating external knowledge to enhance the semantics, but it is\nlaborious to acquisite the appropriate knowledge resources and retrieve the\nscript-related knowledge. In this paper, we regard public pre-trained language\nmodels as knowledge bases and automatically mine the script-related knowledge\nvia prompt-learning. Still, the scenario-diversity and label-ambiguity in\nscripts make it uncertain to construct the most functional prompt and label\ntoken in prompt learning, i.e., prompt-uncertainty and verbalizer-uncertainty.\nConsidering the innate ability of Gaussian distribution to express uncertainty,\nwe deploy the prompt tokens and label tokens as random variables following\nGaussian distributions, where a prompt estimator and a verbalizer estimator are\nproposed to estimate their probabilistic representations instead of\ndeterministic representations. We take the lead to explore prompt-learning in\nSEP and provide a fresh perspective to enrich the script semantics. Our method\nis evaluated on the most widely used benchmark and a newly proposed large-scale\none. Experiments show that our method, which benefits from knowledge evoked\nfrom pre-trained language models, outperforms prior baselines by 1.46\\% and\n1.05\\% on two benchmarks, respectively.",
            "author": [
                "Shiyao Cui",
                "Xin Cong",
                "Jiawei Sheng",
                "Xuebin Wang",
                "Tingwen Liu",
                "Jinqiao Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02103v1",
                "http://arxiv.org/pdf/2308.02103v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02596v2",
            "title": "Revisiting small-world network models: Exploring technical realizations\n  and the equivalence of the Newman-Watts and Harary models",
            "updated": "2023-08-22T02:58:57Z",
            "published": "2023-08-04T01:08:55Z",
            "summary": "We address the relatively less known facts on the equivalence and technical\nrealizations surrounding two network models showing the \"small-world\" property,\nnamely the Newman-Watts and the Harary models. We provide the most accurate (in\nterms of faithfulness to the original literature) versions of these models to\nclarify the deviation from them existing in their variants adopted in one of\nthe most popular network analysis packages. The difference in technical\nrealizations of those models could be conceived as minor details, but we\ndiscover significantly notable changes caused by the possibly inadvertent\nmodification. For the Harary model, the stochasticity in the original\nformulation allows a much wider range of the clustering coefficient and the\naverage shortest path length. For the Newman-Watts model, due to the\ndrastically different degree distributions, the clustering coefficient can also\nbe affected, which is verified by our higher-order analytic derivation. During\nthe process, we discover the equivalence of the Newman-Watts (better known in\nthe network science or physics community) and the Harary (better known in the\ngraph theory or mathematics community) models under a specific condition of\nrestricted parity in variables, which would bridge the two relatively\nindependently developed models in different fields. Our result highlights the\nimportance of each detailed step in constructing network models and the\npossibility of deeply related models, even if they might initially appear\ndistinct in terms of the time period or the academic disciplines from which\nthey emerged.",
            "author": [
                "Seora Son",
                "Eun Ji Choi",
                "Sang Hoon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02596v2",
                "http://arxiv.org/pdf/2308.02596v2"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cond-mat.dis-nn",
                "cs.DM",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02097v1",
            "title": "Multi-interactive Feature Learning and a Full-time Multi-modality\n  Benchmark for Image Fusion and Segmentation",
            "updated": "2023-08-04T01:03:58Z",
            "published": "2023-08-04T01:03:58Z",
            "summary": "Multi-modality image fusion and segmentation play a vital role in autonomous\ndriving and robotic operation. Early efforts focus on boosting the performance\nfor only one task, \\emph{e.g.,} fusion or segmentation, making it hard to\nreach~`Best of Both Worlds'. To overcome this issue, in this paper, we propose\na \\textbf{M}ulti-\\textbf{i}nteractive \\textbf{F}eature learning architecture\nfor image fusion and \\textbf{Seg}mentation, namely SegMiF, and exploit\ndual-task correlation to promote the performance of both tasks. The SegMiF is\nof a cascade structure, containing a fusion sub-network and a commonly used\nsegmentation sub-network. By slickly bridging intermediate features between two\ncomponents, the knowledge learned from the segmentation task can effectively\nassist the fusion task. Also, the benefited fusion network supports the\nsegmentation one to perform more pretentiously. Besides, a hierarchical\ninteractive attention block is established to ensure fine-grained mapping of\nall the vital information between two tasks, so that the modality/semantic\nfeatures can be fully mutual-interactive. In addition, a dynamic weight factor\nis introduced to automatically adjust the corresponding weights of each task,\nwhich can balance the interactive feature correspondence and break through the\nlimitation of laborious tuning. Furthermore, we construct a smart multi-wave\nbinocular imaging system and collect a full-time multi-modality benchmark with\n15 annotated pixel-level categories for image fusion and segmentation.\nExtensive experiments on several public datasets and our benchmark demonstrate\nthat the proposed method outputs visually appealing fused images and perform\naveragely $7.66\\%$ higher segmentation mIoU in the real-world scene than the\nstate-of-the-art approaches. The source code and benchmark are available at\n\\url{https://github.com/JinyuanLiu-CV/SegMiF}.",
            "author": [
                "Jinyuan Liu",
                "Zhu Liu",
                "Guanyao Wu",
                "Long Ma",
                "Risheng Liu",
                "Wei Zhong",
                "Zhongxuan Luo",
                "Xin Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02097v1",
                "http://arxiv.org/pdf/2308.02097v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02059v1",
            "title": "Some Connections Between Restricted Dyck Paths, Polyominoes, and\n  Non-Crossing Partitions",
            "updated": "2023-08-03T21:46:23Z",
            "published": "2023-08-03T21:46:23Z",
            "summary": "A \\emph{Dyck path} is a lattice path in the first quadrant of the $xy$-plane\nthat starts at the origin, ends on the $x$-axis, and consists of the same\nnumber of North-East steps $U$ and South-East steps $D$. A \\emph{valley} is a\nsubpath of the form $DU$. A Dyck path is called \\emph{restricted $d$-Dyck} if\nthe difference between any two consecutive valleys is at least $d$ (right-hand\nside minus left-hand side) or if it has at most one valley. In this paper we\ngive some connections between restricted $d$-Dyck paths and both, the\nnon-crossing partitions of $[n]$ and some subfamilies of polyominoes. We also\ngive generating functions to count several aspects of these combinatorial\nobjects.",
            "author": [
                "Rigoberto Fl\u00f3rez",
                "Jos\u00e9 L. Ram\u00edrez",
                "Fabio A. Velandia",
                "Diego Villamizar"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02059v1",
                "http://arxiv.org/pdf/2308.02059v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02051v1",
            "title": "A Graphical Approach to Document Layout Analysis",
            "updated": "2023-08-03T21:09:59Z",
            "published": "2023-08-03T21:09:59Z",
            "summary": "Document layout analysis (DLA) is the task of detecting the distinct,\nsemantic content within a document and correctly classifying these items into\nan appropriate category (e.g., text, title, figure). DLA pipelines enable users\nto convert documents into structured machine-readable formats that can then be\nused for many useful downstream tasks. Most existing state-of-the-art (SOTA)\nDLA models represent documents as images, discarding the rich metadata\navailable in electronically generated PDFs. Directly leveraging this metadata,\nwe represent each PDF page as a structured graph and frame the DLA problem as a\ngraph segmentation and classification problem. We introduce the Graph-based\nLayout Analysis Model (GLAM), a lightweight graph neural network competitive\nwith SOTA models on two challenging DLA datasets - while being an order of\nmagnitude smaller than existing models. In particular, the 4-million parameter\nGLAM model outperforms the leading 140M+ parameter computer vision-based model\non 5 of the 11 classes on the DocLayNet dataset. A simple ensemble of these two\nmodels achieves a new state-of-the-art on DocLayNet, increasing mAP from 76.8\nto 80.8. Overall, GLAM is over 5 times more efficient than SOTA models, making\nGLAM a favorable engineering choice for DLA tasks.",
            "author": [
                "Jilin Wang",
                "Michael Krumdick",
                "Baojia Tong",
                "Hamima Halim",
                "Maxim Sokolov",
                "Vadym Barda",
                "Delphine Vendryes",
                "Chris Tanner"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02051v1",
                "http://arxiv.org/pdf/2308.02051v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02019v2",
            "title": "Baby Llama: knowledge distillation from an ensemble of teachers trained\n  on a small dataset with no performance penalty",
            "updated": "2023-10-24T17:58:42Z",
            "published": "2023-08-03T20:20:01Z",
            "summary": "We present our submission to the BabyLM challenge, whose goal was to improve\nthe sample efficiency of language models. We trained an ensemble consisting of\na GPT-2 and small LLaMA models on the developmentally-plausible, 10M-word\nBabyLM dataset, then distilled it into a small, 58M-parameter LLaMA model,\nwhich exceeds in performance both of its teachers as well as a similar model\ntrained without distillation. This suggests that distillation can not only\nretain the full performance of the teacher model when the latter is trained on\na sufficiently small dataset; it can exceed it, and lead to significantly\nbetter performance than direct training.",
            "author": [
                "Inar Timiryasov",
                "Jean-Loup Tastet"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02019v2",
                "http://arxiv.org/pdf/2308.02019v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03784v1",
            "title": "Improving Requirements Completeness: Automated Assistance through Large\n  Language Models",
            "updated": "2023-08-03T19:49:18Z",
            "published": "2023-08-03T19:49:18Z",
            "summary": "Natural language (NL) is arguably the most prevalent medium for expressing\nsystems and software requirements. Detecting incompleteness in NL requirements\nis a major challenge. One approach to identify incompleteness is to compare\nrequirements with external sources. Given the rise of large language models\n(LLMs), an interesting question arises: Are LLMs useful external sources of\nknowledge for detecting potential incompleteness in NL requirements? This\narticle explores this question by utilizing BERT. Specifically, we employ\nBERT's masked language model (MLM) to generate contextualized predictions for\nfilling masked slots in requirements. To simulate incompleteness, we withhold\ncontent from the requirements and assess BERT's ability to predict terminology\nthat is present in the withheld content but absent in the disclosed content.\nBERT can produce multiple predictions per mask. Our first contribution is\ndetermining the optimal number of predictions per mask, striking a balance\nbetween effectively identifying omissions in requirements and mitigating noise\npresent in the predictions. Our second contribution involves designing a\nmachine learning-based filter to post-process BERT's predictions and further\nreduce noise. We conduct an empirical evaluation using 40 requirements\nspecifications from the PURE dataset. Our findings indicate that: (1) BERT's\npredictions effectively highlight terminology that is missing from\nrequirements, (2) BERT outperforms simpler baselines in identifying relevant\nyet missing terminology, and (3) our filter significantly reduces noise in the\npredictions, enhancing BERT's effectiveness as a tool for completeness checking\nof requirements.",
            "author": [
                "Dipeeka Luitel",
                "Shabnam Hassani",
                "Mehrdad Sabetzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03784v1",
                "http://arxiv.org/pdf/2308.03784v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.15483v1",
            "title": "Generative AI for Semantic Communication: Architecture, Challenges, and\n  Outlook",
            "updated": "2023-08-03T19:33:43Z",
            "published": "2023-08-03T19:33:43Z",
            "summary": "Semantic communication (SemCom) is expected to be a core paradigm in future\ncommunication networks, yielding significant benefits in terms of spectrum\nresource saving and information interaction efficiency. However, the existing\nSemCom structure is limited by the lack of context-reasoning ability and\nbackground knowledge provisioning, which, therefore, motivates us to seek the\npotential of incorporating generative artificial intelligence (GAI)\ntechnologies with SemCom. Recognizing GAI's powerful capability in automating\nand creating valuable, diverse, and personalized multimodal content, this\narticle first highlights the principal characteristics of the combination of\nGAI and SemCom along with their pertinent benefits and challenges. To tackle\nthese challenges, we further propose a novel GAI-assisted SemCom network\n(GAI-SCN) framework in a cloud-edge-mobile design. Specifically, by employing\nglobal and local GAI models, our GAI-SCN enables multimodal semantic content\nprovisioning, semantic-level joint-source-channel coding, and AIGC acquisition\nto maximize the efficiency and reliability of semantic reasoning and resource\nutilization. Afterward, we present a detailed implementation workflow of\nGAI-SCN, followed by corresponding initial simulations for performance\nevaluation in comparison with two benchmarks. Finally, we discuss several open\nissues and offer feasible solutions to unlock the full potential of GAI-SCN.",
            "author": [
                "Le Xia",
                "Yao Sun",
                "Chengsi Liang",
                "Lei Zhang",
                "Muhammad Ali Imran",
                "Dusit Niyato"
            ],
            "link": [
                "http://arxiv.org/abs/2308.15483v1",
                "http://arxiv.org/pdf/2308.15483v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02000v1",
            "title": "On the Transition from Neural Representation to Symbolic Knowledge",
            "updated": "2023-08-03T19:29:35Z",
            "published": "2023-08-03T19:29:35Z",
            "summary": "Bridging the huge disparity between neural and symbolic representation can\npotentially enable the incorporation of symbolic thinking into neural networks\nfrom essence. Motivated by how human gradually builds complex symbolic\nrepresentation from the prototype symbols that are learned through perception\nand environmental interactions. We propose a Neural-Symbolic Transitional\nDictionary Learning (TDL) framework that employs an EM algorithm to learn a\ntransitional representation of data that compresses high-dimension information\nof visual parts of an input into a set of tensors as neural variables and\ndiscover the implicit predicate structure in a self-supervised way. We\nimplement the framework with a diffusion model by regarding the decomposition\nof input as a cooperative game, then learn predicates by prototype clustering.\nWe additionally use RL enabled by the Markovian of diffusion models to further\ntune the learned prototypes by incorporating subjective factors. Extensive\nexperiments on 3 abstract compositional visual objects datasets that require\nthe model to segment parts without any visual features like texture, color, or\nshadows apart from shape and 3 neural/symbolic downstream tasks demonstrate the\nlearned representation enables interpretable decomposition of visual input and\nsmooth adaption to downstream tasks which are not available by existing\nmethods.",
            "author": [
                "Junyan Cheng",
                "Peter Chin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02000v1",
                "http://arxiv.org/pdf/2308.02000v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01887v1",
            "title": "Athena 2.0: Discourse and User Modeling in Open Domain Dialogue",
            "updated": "2023-08-03T17:30:39Z",
            "published": "2023-08-03T17:30:39Z",
            "summary": "Conversational agents are consistently growing in popularity and many people\ninteract with them every day. While many conversational agents act as personal\nassistants, they can have many different goals. Some are task-oriented, such as\nproviding customer support for a bank or making a reservation. Others are\ndesigned to be empathetic and to form emotional connections with the user. The\nAlexa Prize Challenge aims to create a socialbot, which allows the user to\nengage in coherent conversations, on a range of popular topics that will\ninterest the user. Here we describe Athena 2.0, UCSC's conversational agent for\nAmazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel\nknowledge-grounded discourse model that tracks the entity links that Athena\nintroduces into the dialogue, and uses them to constrain named-entity\nrecognition and linking, and coreference resolution. Athena 2.0 also relies on\na user model to personalize topic selection and other aspects of the\nconversation to individual users.",
            "author": [
                "Omkar Patil",
                "Lena Reed",
                "Kevin K. Bowden",
                "Juraj Juraska",
                "Wen Cui",
                "Vrindavan Harrison",
                "Rishi Rajasekaran",
                "Angela Ramirez",
                "Cecilia Li",
                "Eduardo Zamora",
                "Phillip Lee",
                "Jeshwanth Bheemanpally",
                "Rohan Pandey",
                "Adwait Ratnaparkhi",
                "Marilyn Walker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01887v1",
                "http://arxiv.org/pdf/2308.01887v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01877v1",
            "title": "Genericity of contracting geodesics in groups",
            "updated": "2023-08-03T17:09:41Z",
            "published": "2023-08-03T17:09:41Z",
            "summary": "Let G be a finitely generated group and Cay(G, S) be the Cayley graph of G\nwith respect to a finite generating set S. We characterize the Gromov\nhyperbolicity of G in terms of the genericity of contracting elements in Cay(G,\nS).",
            "author": [
                "Kunal Chawla",
                "Inhyeok Choi",
                "Giulio Tiozzo"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01877v1",
                "http://arxiv.org/pdf/2308.01877v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.DS",
                "math.GR",
                "20F67, 20F69"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01863v1",
            "title": "Tag Prediction of Competitive Programming Problems using Deep Learning\n  Techniques",
            "updated": "2023-08-03T16:39:02Z",
            "published": "2023-08-03T16:39:02Z",
            "summary": "In the past decade, the amount of research being done in the fields of\nmachine learning and deep learning, predominantly in the area of natural\nlanguage processing (NLP), has risen dramatically. A well-liked method for\ndeveloping programming abilities like logic building and problem solving is\ncompetitive programming. It can be tough for novices and even veteran\nprogrammers to traverse the wide collection of questions due to the massive\nnumber of accessible questions and the variety of themes, levels of difficulty,\nand questions offered. In order to help programmers find questions that are\nappropriate for their knowledge and interests, there is a need for an automated\nmethod. This can be done using automated tagging of the questions using Text\nClassification. Text classification is one of the important tasks widely\nresearched in the field of Natural Language Processing. In this paper, we\npresent a way to use text classification techniques to determine the domain of\na competitive programming problem. A variety of models, including are\nimplemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a\nmajor competitive programming website. A total of 2400 problems were scraped\nand preprocessed, which we used as a dataset for our training and testing of\nmodels. The maximum accuracy reached using our model is 78.0% by MLP(Multi\nLayer Perceptron).",
            "author": [
                "Taha Lokat",
                "Divyam Prajapati",
                "Shubhada Labde"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01863v1",
                "http://arxiv.org/pdf/2308.01863v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01860v1",
            "title": "Dissipative Dynamics of Graph-State Stabilizers with Superconducting\n  Qubits",
            "updated": "2023-08-03T16:30:35Z",
            "published": "2023-08-03T16:30:35Z",
            "summary": "We study the noisy evolution of multipartite entangled states, focusing on\nsuperconducting-qubit devices accessible via the cloud. We experimentally\ncharacterize the single-qubit coherent and incoherent error parameters together\nwith the effective two-qubit interactions, whose combined action dominates the\ndecoherence of quantum memory states. We find that a valid modeling of the\ndynamics of superconducting qubits requires one to properly account for\ncoherent frequency shifts, caused by stochastic charge-parity fluctuations. We\npresent a numerical approach that is scalable to tens of qubits, allowing us to\nsimulate efficiently the dissipative dynamics of some large multiqubit states.\nComparing our simulations to measurements of stabilizers dynamics of graph\nstates realized experimentally with up to 12 qubits on a ring, we find that a\nvery good agreement is achievable. Our approach allows us to probe nonlocal\nstate characteristics that are inaccessible in the experiment. We show evidence\nfor a significant improvement of the many-body state fidelity using dynamical\ndecoupling sequences, mitigating the effect of charge-parity oscillations and\ntwo-qubit crosstalk.",
            "author": [
                "Liran Shirizly",
                "Gr\u00e9goire Misguich",
                "Haggai Landa"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01860v1",
                "http://arxiv.org/pdf/2308.01860v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01855v1",
            "title": "Time-optimal geodesic mutual visibility of robots on grids within\n  minimum area",
            "updated": "2023-08-03T16:20:36Z",
            "published": "2023-08-03T16:20:36Z",
            "summary": "The \\textsc{Mutual Visibility} is a well-known problem in the context of\nmobile robots. For a set of $n$ robots disposed in the Euclidean plane, it asks\nfor moving the robots without collisions so as to achieve a placement ensuring\nthat no three robots are collinear. For robots moving on graphs, we consider\nthe \\textsc{Geodesic Mutual Visibility} ($\\GMV$) problem. Robots move along the\nedges of the graph, without collisions, so as to occupy some vertices that\nguarantee they become pairwise geodesic mutually visible. This means that there\nis a shortest path (i.e., a \"geodesic\") between each pair of robots along which\nno other robots reside. We study this problem in the context of finite and\ninfinite square grids, for robots operating under the standard\nLook-Compute-Move model. In both scenarios, we provide resolution algorithms\nalong with formal correctness proofs, highlighting the most relevant\npeculiarities arising within the different contexts, while optimizing the time\ncomplexity.",
            "author": [
                "Serafino Cicerone",
                "Alessia Di Fonso",
                "Gabriele Di Stefano",
                "Alfredo Navarra"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01855v1",
                "http://arxiv.org/pdf/2308.01855v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "math.CO",
                "68Q85, 68R10",
                "F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01851v1",
            "title": "User-friendly confidence regions for quantum state tomography",
            "updated": "2023-08-03T16:18:44Z",
            "published": "2023-08-03T16:18:44Z",
            "summary": "Quantum state tomography is the standard technique for reconstructing a\nquantum state from experimental data. Given finite statistics, experimental\ndata cannot give perfect information about the quantum state. A common way to\nexpress this limited knowledge is by providing confidence regions in state\nspace. Though plenty of confidence regions have been previously proposed, they\nare often too loose to use for large systems or difficult to apply to\nnonstandard measurement schemes. Starting from a vector Bernstein inequality,\nwe consider concentration bounds for random vectors following multinomial\ndistributions and analyse optimal strategies to distribute a fixed budget of\nsamples across them. Interpreting this as a tomography experiment leads to two\nconfidence regions, one of which performs comparably well to the best regions\nin the literature. The regions describe an ellipsoid in the state space and\nhave the appeal of being efficient in the required number of samples as well as\nbeing easily applicable to any measurement scheme.",
            "author": [
                "Carlos de Gois",
                "Matthias Kleinmann"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01851v1",
                "http://arxiv.org/pdf/2308.01851v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01834v1",
            "title": "The Capability of Large Language Models to Measure Psychiatric\n  Functioning",
            "updated": "2023-08-03T15:52:27Z",
            "published": "2023-08-03T15:52:27Z",
            "summary": "The current work investigates the capability of Large language models (LLMs)\nthat are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2)\nto predict psychiatric functioning from patient interviews and clinical\ndescriptions without being trained to do so. To assess this, n = 145 depression\nand n =115 PTSD assessments and n = 46 clinical case studies across high\nprevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma\nand stress, Addictive disorders) were analyzed using prompts to extract\nestimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is\ncapable of assessing psychiatric functioning across a range of psychiatric\nconditions with the strongest performance being the prediction of depression\nscores based on standardized assessments (Accuracy range= 0.80 - 0.84) which\nwere statistically indistinguishable from human clinical raters t(1,144) =\n1.20; p = 0.23. Results show the potential for general clinical language models\nto flexibly predict psychiatric risk based on free descriptions of functioning\nfrom both patients and clinicians.",
            "author": [
                "Isaac R. Galatzer-Levy",
                "Daniel McDuff",
                "Vivek Natarajan",
                "Alan Karthikesalingam",
                "Matteo Malgaroli"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01834v1",
                "http://arxiv.org/pdf/2308.01834v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01832v1",
            "title": "Meeting, coalescence and consensus time on random directed graphs",
            "updated": "2023-08-03T15:47:43Z",
            "published": "2023-08-03T15:47:43Z",
            "summary": "We consider Markovian dynamics on a typical realization of the so-called\nDirected Configuration Model (DCM), that is, a random directed graph with\nprescribed in- and out-degrees. In this random geometry, we study the meeting\ntime of two random walks on a typical realization of the graph starting at\nstationarity, the coalescence time for a system of coalescent random walks, and\nthe consensus time of the voter model. Indeed, it is known that the latter\nthree quantities are related to each other when the underlying sequence of\ngraphs satisfies certain mean field conditions. Such conditions can be\nsummarized by requiring a fast mixing time of the random walk and some\nanti-concentration of its stationary distribution: properties that a typical\nrandom directed graph is known to have under natural assumptions on the degree\nsequence. In this paper we show that, for a typical large graph from the DCM\nensemble, the distribution of the meeting time is well-approximated by an\nexponential random variable and we provide the first-order approximation of its\nexpectation, showing that the latter is linear in the size of the graph, and\nthe preconstant depends on some easy statistics of the degree sequence. As a\nbyproduct, we are able to analyze the effect of the degree sequence in changing\nthe meeting, coalescence and consensus time. Our approach follows the classical\nidea of converting meeting into hitting times of a proper collapsed chain,\nwhich we control by the so-called First Visit Time Lemma.",
            "author": [
                "Luca Avena",
                "Federico Capannoli",
                "Rajat Subhra Hazra",
                "Matteo Quattropani"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01832v1",
                "http://arxiv.org/pdf/2308.01832v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01831v1",
            "title": "Many-to-Many Spoken Language Translation via Unified Speech and Text\n  Representation Learning with Unit-to-Unit Translation",
            "updated": "2023-08-03T15:47:04Z",
            "published": "2023-08-03T15:47:04Z",
            "summary": "In this paper, we propose a method to learn unified representations of\nmultilingual speech and text with a single model, especially focusing on the\npurpose of speech synthesis. We represent multilingual speech audio with speech\nunits, the quantized representations of speech features encoded from a\nself-supervised speech model. Therefore, we can focus on their linguistic\ncontent by treating the audio as pseudo text and can build a unified\nrepresentation of speech and text. Then, we propose to train an encoder-decoder\nstructured model with a Unit-to-Unit Translation (UTUT) objective on\nmultilingual data. Specifically, by conditioning the encoder with the source\nlanguage token and the decoder with the target language token, the model is\noptimized to translate the spoken language into that of the target language, in\na many-to-many language translation setting. Therefore, the model can build the\nknowledge of how spoken languages are comprehended and how to relate them to\ndifferent languages. A single pre-trained model with UTUT can be employed for\ndiverse multilingual speech- and text-related tasks, such as Speech-to-Speech\nTranslation (STS), multilingual Text-to-Speech Synthesis (TTS), and\nText-to-Speech Translation (TTST). By conducting comprehensive experiments\nencompassing various languages, we validate the efficacy of the proposed method\nacross diverse multilingual tasks. Moreover, we show UTUT can perform\nmany-to-many language STS, which has not been previously explored in the\nliterature. Samples are available on https://choijeongsoo.github.io/utut.",
            "author": [
                "Minsu Kim",
                "Jeongsoo Choi",
                "Dahun Kim",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01831v1",
                "http://arxiv.org/pdf/2308.01831v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01828v1",
            "title": "Local and extensive fluctuations in sparsely-interacting ecological\n  communities",
            "updated": "2023-08-03T15:39:26Z",
            "published": "2023-08-03T15:39:26Z",
            "summary": "Ecological communities with many species can be classified into dynamical\nphases. In systems with all-to-all interactions, a phase where a fixed point is\nalways reached and a dynamically-fluctuating phase have been found. The\ndynamics when interactions are sparse, with each species interacting with only\nseveral others, has remained largely unexplored. Here we show that a new type\nof phase appears in the phase diagram, where for the same control parameters\ndifferent communities may reach either a fixed point or a state where the\nabundances of a finite subset of species fluctuate, and calculate the\nprobability for each outcome. These fluctuating species are organized around\nshort cycles in the interaction graph, and their abundances undergo large\nnon-linear fluctuations. We characterize the approach from this phase to a\nphase with extensively many fluctuating species, and show that the probability\nof fluctuations grows continuously to one as the transition is approached, and\nthat the number of fluctuating species diverges. This is qualitatively distinct\nfrom the transition to extensive fluctuations coming from a fixed point phase,\nwhich is marked by a loss of linear stability. The differences are traced back\nto the emergent binary character of the dynamics when far away from short\ncycles in the local fluctuations phase.",
            "author": [
                "Stav Marcus",
                "Ari M Turner",
                "Guy Bunin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01828v1",
                "http://arxiv.org/pdf/2308.01828v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01824v2",
            "title": "Square Coloring of Planar Graphs with Maximum Degree at Most Five",
            "updated": "2023-08-13T10:02:49Z",
            "published": "2023-08-03T15:33:53Z",
            "summary": "The \\textit{square} of a graph $G$, denoted by $G^2$, is obtained from $G$ by\nadding an edge to connect every pair of vertices with a common neighbor in $G$.\nIn this paper we prove that for every planar graph $G$ with maximum degree at\nmost $5$, $G^2$ admits a proper vertex coloring using at most $17$ colors,\nwhich improves the upper bound $18$ recently obtained by Hou, Jin, Miao, and\nZhao.",
            "author": [
                "Jiani Zou",
                "Miaomiao Han",
                "Hong-Jian Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01824v2",
                "http://arxiv.org/pdf/2308.01824v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01821v1",
            "title": "Identifiability of Homoscedastic Linear Structural Equation Models using\n  Algebraic Matroids",
            "updated": "2023-08-03T15:32:54Z",
            "published": "2023-08-03T15:32:54Z",
            "summary": "We consider structural equation models (SEMs), in which every variable is a\nfunction of a subset of the other variables and a stochastic error. Each such\nSEM is naturally associated with a directed graph describing the relationships\nbetween variables. When the errors are homoscedastic, recent work has proposed\nmethods for inferring the graph from observational data under the assumption\nthat the graph is acyclic (i.e., the SEM is recursive). In this work, we study\nthe setting of homoscedastic errors but allow the graph to be cyclic (i.e., the\nSEM to be non-recursive). Using an algebraic approach that compares matroids\nderived from the parameterizations of the models, we derive sufficient\nconditions for when two simple directed graphs generate different distributions\ngenerically. Based on these conditions, we exhibit subclasses of graphs that\nallow for directed cycles, yet are generically identifiable. We also conjecture\na strengthening of our graphical criterion which can be used to distinguish\nmany more non-complete graphs.",
            "author": [
                "Mathias Drton",
                "Benjamin Hollering",
                "Jun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01821v1",
                "http://arxiv.org/pdf/2308.01821v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.ST",
                "stat.TH",
                "62R01, 62H22, 62A09, 05B35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01811v1",
            "title": "Intersection graph and writhe polynomial",
            "updated": "2023-08-03T15:17:26Z",
            "published": "2023-08-03T15:17:26Z",
            "summary": "We prove that two virtual knots have equivalent intersection graphs if and\nonly if they have the same writhe polynomial.",
            "author": [
                "Zhiyun Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01811v1",
                "http://arxiv.org/pdf/2308.01811v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "57K12, 57M15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01807v4",
            "title": "Entropic property of randomized QAOA circuits",
            "updated": "2023-11-28T16:57:10Z",
            "published": "2023-08-03T15:13:23Z",
            "summary": "Quantum approximate optimization algorithm (QAOA) aims to solve discrete\noptimization problems by sampling bitstrings using a parameterized quantum\ncircuit. The circuit parameters (angles) are optimized in the way that\nminimizes the cost Hamiltonian expectation value. Recently, general statistical\nproperties of QAOA output probability distributions have begun to be studied.\nIn contrast to the conventional approach, we analyse QAOA circuits with random\nangles. We provide analytical equations for probabilities and the numerical\nevidence that for unweighted Max-Cut problems on connected graphs such sampling\nalways gives higher entropy of energy distribution than uniform random sampling\nof bitstrings. We also analyse the probability to obtain the global optima,\nwhich appears to be higher on average than for random sampling.",
            "author": [
                "A. Yu. Chernyavskiy",
                "B. I. Bantysh",
                "Yu. I. Bogdanov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01807v4",
                "http://arxiv.org/pdf/2308.01807v4"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01797v1",
            "title": "Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to\n  Sequence approach",
            "updated": "2023-08-03T14:52:17Z",
            "published": "2023-08-03T14:52:17Z",
            "summary": "Job scheduling is a well-known Combinatorial Optimization problem with\nendless applications. Well planned schedules bring many benefits in the context\nof automated systems: among others, they limit production costs and waste.\nNevertheless, the NP-hardness of this problem makes it essential to use\nheuristics whose design is difficult, requires specialized knowledge and often\nproduces methods tailored to the specific task. This paper presents an original\nend-to-end Deep Reinforcement Learning approach to scheduling that\nautomatically learns dispatching rules. Our technique is inspired by natural\nlanguage encoder-decoder models for sequence processing and has never been\nused, to the best of our knowledge, for scheduling purposes. We applied and\ntested our method in particular to some benchmark instances of Job Shop\nProblem, but this technique is general enough to be potentially used to tackle\nother different optimal job scheduling tasks with minimal intervention. Results\ndemonstrate that we outperform many classical approaches exploiting priority\ndispatching rules and show competitive results on state-of-the-art Deep\nReinforcement Learning ones.",
            "author": [
                "Giovanni Bonetta",
                "Davide Zago",
                "Rossella Cancelliere",
                "Andrea Grosso"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01797v1",
                "http://arxiv.org/pdf/2308.01797v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.NE",
                "math.CO",
                "I.2.0; I.2.8; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01769v1",
            "title": "Focus on Content not Noise: Improving Image Generation for Nuclei\n  Segmentation by Suppressing Steganography in CycleGAN",
            "updated": "2023-08-03T13:58:37Z",
            "published": "2023-08-03T13:58:37Z",
            "summary": "Annotating nuclei in microscopy images for the training of neural networks is\na laborious task that requires expert knowledge and suffers from inter- and\nintra-rater variability, especially in fluorescence microscopy. Generative\nnetworks such as CycleGAN can inverse the process and generate synthetic\nmicroscopy images for a given mask, thereby building a synthetic dataset.\nHowever, past works report content inconsistencies between the mask and\ngenerated image, partially due to CycleGAN minimizing its loss by hiding\nshortcut information for the image reconstruction in high frequencies rather\nthan encoding the desired image content and learning the target task. In this\nwork, we propose to remove the hidden shortcut information, called\nsteganography, from generated images by employing a low pass filtering based on\nthe DCT. We show that this increases coherence between generated images and\ncycled masks and evaluate synthetic datasets on a downstream nuclei\nsegmentation task. Here we achieve an improvement of 5.4 percentage points in\nthe F1-score compared to a vanilla CycleGAN. Integrating advanced\nregularization techniques into the CycleGAN architecture may help mitigate\nsteganography-related issues and produce more accurate synthetic datasets for\nnuclei segmentation.",
            "author": [
                "Jonas Utz",
                "Tobias Weise",
                "Maja Schlereth",
                "Fabian Wagner",
                "Mareike Thies",
                "Mingxuan Gu",
                "Stefan Uderhardt",
                "Katharina Breininger"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01769v1",
                "http://arxiv.org/pdf/2308.01769v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01761v1",
            "title": "LOUC: Leave-One-Out-Calibration Measure for Analyzing Human Matcher\n  Performance",
            "updated": "2023-08-03T13:49:17Z",
            "published": "2023-08-03T13:49:17Z",
            "summary": "Schema matching is a core data integration task, focusing on identifying\ncorrespondences among attributes of multiple schemata. Numerous algorithmic\napproaches were suggested for schema matching over the years, aiming at solving\nthe task with as little human involvement as possible. Yet, humans are still\nrequired in the loop -- to validate algorithms and to produce ground truth data\nfor algorithms to be trained against. In recent years, a new research direction\ninvestigates the capabilities and behavior of humans while performing matching\ntasks. Previous works utilized this knowledge to predict, and even improve, the\nperformance of human matchers. In this work, we continue this line of research\nby suggesting a novel measure to evaluate the performance of human matchers,\nbased on calibration, a common meta-cognition measure. The proposed measure\nenables detailed analysis of various factors of the behavior of human matchers\nand their relation to human performance. Such analysis can be further utilized\nto develop heuristics and methods to better asses and improve the annotation\nquality.",
            "author": [
                "Matan Solomon",
                "Bar Genossar",
                "Roee Shraga",
                "Avigdor Gal"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01761v1",
                "http://arxiv.org/pdf/2308.01761v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01732v1",
            "title": "Towards Self-organizing Personal Knowledge Assistants in Evolving\n  Corporate Memories",
            "updated": "2023-08-03T12:48:32Z",
            "published": "2023-08-03T12:48:32Z",
            "summary": "This paper presents a retrospective overview of a decade of research in our\ndepartment towards self-organizing personal knowledge assistants in evolving\ncorporate memories. Our research is typically inspired by real-world problems\nand often conducted in interdisciplinary collaborations with research and\nindustry partners. We summarize past experiments and results comprising topics\nlike various ways of knowledge graph construction in corporate and personal\nsettings, Managed Forgetting and (Self-organizing) Context Spaces as a novel\napproach to Personal Information Management (PIM) and knowledge work support.\nPast results are complemented by an overview of related work and some of our\nlatest findings not published so far. Last, we give an overview of our related\nindustry use cases including a detailed look into CoMem, a Corporate Memory\nbased on our presented research already in productive use and providing\nchallenges for further research. Many contributions are only first steps in new\ndirections with still a lot of untapped potential, especially with regard to\nfurther increasing the automation in PIM and knowledge work support.",
            "author": [
                "Christian Jilek",
                "Markus Schr\u00f6der",
                "Heiko Maus",
                "Sven Schwarz",
                "Andreas Dengel"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01732v1",
                "http://arxiv.org/pdf/2308.01732v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01698v1",
            "title": "Balanced Destruction-Reconstruction Dynamics for Memory-replay Class\n  Incremental Learning",
            "updated": "2023-08-03T11:33:50Z",
            "published": "2023-08-03T11:33:50Z",
            "summary": "Class incremental learning (CIL) aims to incrementally update a trained model\nwith the new classes of samples (plasticity) while retaining previously learned\nability (stability). To address the most challenging issue in this goal, i.e.,\ncatastrophic forgetting, the mainstream paradigm is memory-replay CIL, which\nconsolidates old knowledge by replaying a small number of old classes of\nsamples saved in the memory. Despite effectiveness, the inherent\ndestruction-reconstruction dynamics in memory-replay CIL are an intrinsic\nlimitation: if the old knowledge is severely destructed, it will be quite hard\nto reconstruct the lossless counterpart. Our theoretical analysis shows that\nthe destruction of old knowledge can be effectively alleviated by balancing the\ncontribution of samples from the current phase and those saved in the memory.\nMotivated by this theoretical finding, we propose a novel Balanced\nDestruction-Reconstruction module (BDR) for memory-replay CIL, which can\nachieve better knowledge reconstruction by reducing the degree of maximal\ndestruction of old knowledge. Specifically, to achieve a better balance between\nold knowledge and new classes, the proposed BDR module takes into account two\nfactors: the variance in training status across different classes and the\nquantity imbalance of samples from the current phase and memory. By dynamically\nmanipulating the gradient during training based on these factors, BDR can\neffectively alleviate knowledge destruction and improve knowledge\nreconstruction. Extensive experiments on a range of CIL benchmarks have shown\nthat as a lightweight plug-and-play module, BDR can significantly improve the\nperformance of existing state-of-the-art methods with good generalization.",
            "author": [
                "Yuhang Zhou",
                "Jiangchao Yao",
                "Feng Hong",
                "Ya Zhang",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01698v1",
                "http://arxiv.org/pdf/2308.01698v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02571v1",
            "title": "ADRNet: A Generalized Collaborative Filtering Framework Combining\n  Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction",
            "updated": "2023-08-03T11:28:12Z",
            "published": "2023-08-03T11:28:12Z",
            "summary": "Adverse drug reaction (ADR) prediction plays a crucial role in both health\ncare and drug discovery for reducing patient mortality and enhancing drug\nsafety. Recently, many studies have been devoted to effectively predict the\ndrug-ADRs incidence rates. However, these methods either did not effectively\nutilize non-clinical data, i.e., physical, chemical, and biological information\nabout the drug, or did little to establish a link between content-based and\npure collaborative filtering during the training phase. In this paper, we first\nformulate the prediction of multi-label ADRs as a drug-ADR collaborative\nfiltering problem, and to the best of our knowledge, this is the first work to\nprovide extensive benchmark results of previous collaborative filtering methods\non two large publicly available clinical datasets. Then, by exploiting the easy\naccessible drug characteristics from non-clinical data, we propose ADRNet, a\ngeneralized collaborative filtering framework combining clinical and\nnon-clinical data for drug-ADR prediction. Specifically, ADRNet has a shallow\ncollaborative filtering module and a deep drug representation module, which can\nexploit the high-dimensional drug descriptors to further guide the learning of\nlow-dimensional ADR latent embeddings, which incorporates both the benefits of\ncollaborative filtering and representation learning. Extensive experiments are\nconducted on two publicly available real-world drug-ADR clinical datasets and\ntwo non-clinical datasets to demonstrate the accuracy and efficiency of the\nproposed ADRNet. The code is available at\nhttps://github.com/haoxuanli-pku/ADRnet.",
            "author": [
                "Haoxuan Li",
                "Taojun Hu",
                "Zetong Xiong",
                "Chunyuan Zheng",
                "Fuli Feng",
                "Xiangnan He",
                "Xiao-Hua Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02571v1",
                "http://arxiv.org/pdf/2308.02571v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01685v1",
            "title": "Inequalities Connecting the Annihilation and Independence Numbers",
            "updated": "2023-08-03T10:53:30Z",
            "published": "2023-08-03T10:53:30Z",
            "summary": "Given a graph $G$, the number of its vertices is represented by $n(G)$, while\nthe number of its edges is denoted as $m(G)$.\n  An independent set in a graph is a set of vertices where no two vertices are\nadjacent to each other and the size of the maximum independent set is denoted\nby $\\alpha(G)$. A matching in a graph refers to a set of edges where no two\nedges share a common vertex and the maximum matching size is denoted by\n$\\mu(G)$. If $\\alpha(G) + \\mu(G) = n(G)$, then the graph $G$ is called a\nK\\\"{o}nig-Egerv\\'{a}ry graph.\n  Considering a graph $G$ with a degree sequence $d_1 \\leq d_2 \\leq \\cdots \\leq\nd_n$, the annihilation number $a(G)$ is defined as the largest integer $k$ such\nthat the sum of the first $k$ degrees in the sequence is less than or equal to\n$m(G)$ (Pepper, 2004).\n  It is a known fact that $\\alpha(G)$ is less than or equal to $a(G)$ for any\ngraph $G$. Our goal is to estimate the difference between these two parameters.\nSpecifically, we prove a series of inequalities, including\n  $a(G) - \\alpha(G) \\leq \\frac{\\mu(G) - 1}{2}$ for trees, $a(G) - \\alpha(G)\n\\leq 2 + \\mu(G) - 2\\sqrt{1 + \\mu(G)}$ for bipartite graphs and $a(G) -\n\\alpha(G) \\leq \\mu(G) - 2$ for K\\\"{o}nig-Egerv\\'{a}ry graphs. Furthermore, we\ndemonstrate that these inequalities serve as tight upper bounds for the\ndifference between the annihilation and independence numbers, regardless of the\nassigned value for $\\mu(G)$.",
            "author": [
                "Ohr Kadrawi",
                "Vadim E. Levit"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01685v1",
                "http://arxiv.org/pdf/2308.01685v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "05C69, 05C07 (Primary) 05C05 (Secondary)",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01682v1",
            "title": "Evaluating Link Prediction Explanations for Graph Neural Networks",
            "updated": "2023-08-03T10:48:37Z",
            "published": "2023-08-03T10:48:37Z",
            "summary": "Graph Machine Learning (GML) has numerous applications, such as node/graph\nclassification and link prediction, in real-world domains. Providing\nhuman-understandable explanations for GML models is a challenging yet\nfundamental task to foster their adoption, but validating explanations for link\nprediction models has received little attention. In this paper, we provide\nquantitative metrics to assess the quality of link prediction explanations,\nwith or without ground-truth. State-of-the-art explainability methods for Graph\nNeural Networks are evaluated using these metrics. We discuss how underlying\nassumptions and technical details specific to the link prediction task, such as\nthe choice of distance between node embeddings, can influence the quality of\nthe explanations.",
            "author": [
                "Claudio Borile",
                "Alan Perotti",
                "Andr\u00e9 Panisson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01682v1",
                "http://arxiv.org/pdf/2308.01682v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01671v3",
            "title": "Reconstruction of graph colourings",
            "updated": "2023-11-12T19:46:29Z",
            "published": "2023-08-03T10:18:36Z",
            "summary": "A $k$-deck of a (coloured) graph is a multiset of its induced $k$-vertex\nsubgraphs. Given a graph $G$, when is it possible to reconstruct with high\nprobability a uniformly random colouring of its vertices in $r$ colours from\nits $k$-deck? In this paper, we study this question for grids and random\ngraphs. Reconstruction of random colourings of $d$-dimensional $n$-grids from\nthe deck of their $k$-subgrids is one of the most studied colour reconstruction\nquestions. The 1-dimensional case is motivated by the problem of reconstructing\nDNA sequences from their `shotgunned' stretches. It was comprehensively studied\nand the above reconstruction question was completely answered in the '90s. In\nthis paper, we get a very precise answer for higher $d$. For every $d\\geq 2$\nand every $r\\geq 2$, we present an almost linear algorithm that reconstructs\nwith high probability a random $r$-colouring of vertices of a $d$-dimensional\n$n$-grid from the deck of all its $k$-subgrids for every $k\\geq(d\\log_r\nn)^{1/d}+1/d+\\varepsilon$ and prove that the random $r$-colouring is not\nreconstructible with high probability if $k\\leq (d\\log_r n)^{1/d}-\\varepsilon$.\nThis answers the question of Narayanan and Yap (that was asked for $d\\geq 3$)\non \"two-point concentration\" of the minimum $k$ so that $k$-subgrids determine\nthe entire colouring. Next, we prove that with high probability a uniformly\nrandom $r$-colouring of vertices of a uniformly random graph $G(n,1/2)$ is\nreconstructible from its full $k$-deck if $k\\geq 2\\log_2 n+8$ and is not\nreconstructible with high probability if $k\\leq\\sqrt{2\\log_2 n}$. We further\nshow that the colour reconstruction algorithm for random graphs can be modified\nand used for graph reconstruction: we prove that with high probability\n$G(n,1/2)$ is reconstructible from its full $k$-deck if $k\\geq 2\\log_2 n+11$\nwhile it is not reconstructible with high probability if $k\\leq 2\\sqrt{\\log_2\nn}$.",
            "author": [
                "Yury Demidovich",
                "Yaroslav Panichkin",
                "Maksim Zhukovskii"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01671v3",
                "http://arxiv.org/pdf/2308.01671v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01659v2",
            "title": "Momentum spectrum of Schwinger pair production in four-dimensional\n  e-dipole fields",
            "updated": "2023-08-28T13:45:20Z",
            "published": "2023-08-03T09:49:37Z",
            "summary": "We calculate the momentum spectrum of electron-positron pairs created via the\nSchwinger mechanism by a class of four-dimensional electromagnetic fields\ncalled e-dipole fields. To the best of our knowledge, this is the first time\nthe momentum spectrum has been calculated for 4D, exact solutions to Maxwell's\nequations. Moreover, these solutions give fields that are optimally focused,\nand are hence particularly relevant for future experiments. To achieve this we\nhave developed a worldline instanton formalism where we separate the process\ninto a formation and an acceleration region.",
            "author": [
                "Gianluca Degli Esposti",
                "Greger Torgrimsson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01659v2",
                "http://arxiv.org/pdf/2308.01659v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01650v1",
            "title": "UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node\n  Classification",
            "updated": "2023-08-03T09:32:50Z",
            "published": "2023-08-03T09:32:50Z",
            "summary": "Graph and hypergraph representation learning has attracted increasing\nattention from various research fields. Despite the decent performance and\nfruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural\nNetworks (HGNNs), and their well-designed variants, on some commonly used\nbenchmark graphs and hypergraphs, they are outperformed by even a simple\nMulti-Layer Perceptron. This observation motivates a reexamination of the\ndesign paradigm of the current GNNs and HGNNs and poses challenges of\nextracting graph features effectively. In this work, a universal feature\nencoder for both graph and hypergraph representation learning is designed,\ncalled UniG-Encoder. The architecture starts with a forward transformation of\nthe topological relationships of connected nodes into edge or hyperedge\nfeatures via a normalized projection matrix. The resulting edge/hyperedge\nfeatures, together with the original node features, are fed into a neural\nnetwork. The encoded node embeddings are then derived from the reversed\ntransformation, described by the transpose of the projection matrix, of the\nnetwork's output, which can be further used for tasks such as node\nclassification. The proposed architecture, in contrast to the traditional\nspectral-based and/or message passing approaches, simultaneously and\ncomprehensively exploits the node features and graph/hypergraph topologies in\nan efficient and unified manner, covering both heterophilic and homophilic\ngraphs. The designed projection matrix, encoding the graph features, is\nintuitive and interpretable. Extensive experiments are conducted and\ndemonstrate the superior performance of the proposed framework on twelve\nrepresentative hypergraph datasets and six real-world graph datasets, compared\nto the state-of-the-art methods. Our implementation is available online at\nhttps://github.com/MinhZou/UniG-Encoder.",
            "author": [
                "Minhao Zou",
                "Zhongxue Gan",
                "Yutong Wang",
                "Junheng Zhang",
                "Dongyan Sui",
                "Chun Guan",
                "Siyang Leng"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.patcog.2023.110115",
                "http://arxiv.org/abs/2308.01650v1",
                "http://arxiv.org/pdf/2308.01650v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01643v1",
            "title": "I am a global citizen. Or am I not? International Business Schools\n  students and Global Citizenship unified framework & a scoping literature\n  review of the last decade (2013-2022)",
            "updated": "2023-08-03T09:20:21Z",
            "published": "2023-08-03T09:20:21Z",
            "summary": "This review examines the scientific articles of the last decade, approaching\nthe subject through the methodology of the scoping literature review. Starting\nwith the Boolean search global citizens AND education AND (international\nbusiness OR international business school) in the ScienceDirect, Emerald, and\nScopus databases, the review resulted in only scientific journal articles,\nstrictly targeted at tertiary education ONLY of international business schools\nand ONLY in those articles that study global citizenship. For reasons of\nup-to-date knowledge, the present literature was content with the final decade.\nA total of 13 articles are recorded as a result of the aforementioned Boolean\nsearch from a total of 216 articles identified in the first phase of the\nsearch. The results will help the researchers to acquire the required knowledge\nbase for their research, the academics to incorporate new methods in their\nteaching and the approach of their students, and the policymakers to adapt the\nschools curricula according to the data from the articles present in the\nliterature review.",
            "author": [
                "Nikolaos Misirlis"
            ],
            "link": [
                "http://dx.doi.org/10.26352/H629_2384-9509",
                "http://arxiv.org/abs/2308.01643v1",
                "http://arxiv.org/pdf/2308.01643v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01626v1",
            "title": "Interleaving GANs with knowledge graphs to support design creativity for\n  book covers",
            "updated": "2023-08-03T08:56:56Z",
            "published": "2023-08-03T08:56:56Z",
            "summary": "An attractive book cover is important for the success of a book. In this\npaper, we apply Generative Adversarial Networks (GANs) to the book covers\ndomain, using different methods for training in order to obtain better\ngenerated images. We interleave GANs with knowledge graphs to alter the input\ntitle to obtain multiple possible options for any given title, which are then\nused as an augmented input to the generator. Finally, we use the discriminator\nobtained during the training phase to select the best images generated with new\ntitles. Our method performed better at generating book covers than previous\nattempts, and the knowledge graph gives better options to the book author or\neditor compared to using GANs alone.",
            "author": [
                "Alexandru Motogna",
                "Adrian Groza"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01626v1",
                "http://arxiv.org/pdf/2308.01626v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02419v1",
            "title": "Multimodal Indoor Localisation in Parkinson's Disease for Detecting\n  Medication Use: Observational Pilot Study in a Free-Living Setting",
            "updated": "2023-08-03T08:55:21Z",
            "published": "2023-08-03T08:55:21Z",
            "summary": "Parkinson's disease (PD) is a slowly progressive, debilitating\nneurodegenerative disease which causes motor symptoms including gait\ndysfunction. Motor fluctuations are alterations between periods with a positive\nresponse to levodopa therapy (\"on\") and periods marked by re-emergency of PD\nsymptoms (\"off\") as the response to medication wears off. These fluctuations\noften affect gait speed and they increase in their disabling impact as PD\nprogresses. To improve the effectiveness of current indoor localisation\nmethods, a transformer-based approach utilising dual modalities which provide\ncomplementary views of movement, Received Signal Strength Indicator (RSSI) and\naccelerometer data from wearable devices, is proposed. A sub-objective aims to\nevaluate whether indoor localisation, including its in-home gait speed features\n(i.e. the time taken to walk between rooms), could be used to evaluate motor\nfluctuations by detecting whether the person with PD is taking levodopa\nmedications or withholding them. To properly evaluate our proposed method, we\nuse a free-living dataset where the movements and mobility are greatly varied\nand unstructured as expected in real-world conditions. 24 participants lived in\npairs (consisting of one person with PD, one control) for five days in a smart\nhome with various sensors. Our evaluation on the resulting dataset demonstrates\nthat our proposed network outperforms other methods for indoor localisation.\nThe sub-objective evaluation shows that precise room-level localisation\npredictions, transformed into in-home gait speed features, produce accurate\npredictions on whether the PD participant is taking or withholding their\nmedications.",
            "author": [
                "Ferdian Jovan",
                "Catherine Morgan",
                "Ryan McConville",
                "Emma L. Tonkin",
                "Ian Craddock",
                "Alan Whone"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3580305.3599872",
                "http://arxiv.org/abs/2308.02419v1",
                "http://arxiv.org/pdf/2308.02419v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG",
                "I.2.6; I.2.1; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01947v1",
            "title": "Discriminative Graph-level Anomaly Detection via Dual-students-teacher\n  Model",
            "updated": "2023-08-03T08:29:26Z",
            "published": "2023-08-03T08:29:26Z",
            "summary": "Different from the current node-level anomaly detection task, the goal of\ngraph-level anomaly detection is to find abnormal graphs that significantly\ndiffer from others in a graph set. Due to the scarcity of research on the work\nof graph-level anomaly detection, the detailed description of graph-level\nanomaly is insufficient. Furthermore, existing works focus on capturing\nanomalous graph information to learn better graph representations, but they\nignore the importance of an effective anomaly score function for evaluating\nabnormal graphs. Thus, in this work, we first define anomalous graph\ninformation including node and graph property anomalies in a graph set and\nadopt node-level and graph-level information differences to identify them,\nrespectively. Then, we introduce a discriminative graph-level anomaly detection\nframework with dual-students-teacher model, where the teacher model with a\nheuristic loss are trained to make graph representations more divergent. Then,\ntwo competing student models trained by normal and abnormal graphs respectively\nfit graph representations of the teacher model in terms of node-level and\ngraph-level representation perspectives. Finally, we combine representation\nerrors between two student models to discriminatively distinguish anomalous\ngraphs. Extensive experiment analysis demonstrates that our method is effective\nfor the graph-level anomaly detection task on graph datasets in the real world.",
            "author": [
                "Fu Lin",
                "Xuexiong Luo",
                "Jia Wu",
                "Jian Yang",
                "Shan Xue",
                "Zitong Wang",
                "Haonan Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01947v1",
                "http://arxiv.org/pdf/2308.01947v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01606v1",
            "title": "Unsupervised Multiplex Graph Learning with Complementary and Consistent\n  Information",
            "updated": "2023-08-03T08:24:08Z",
            "published": "2023-08-03T08:24:08Z",
            "summary": "Unsupervised multiplex graph learning (UMGL) has been shown to achieve\nsignificant effectiveness for different downstream tasks by exploring both\ncomplementary information and consistent information among multiple graphs.\nHowever, previous methods usually overlook the issues in practical\napplications, i.e., the out-of-sample issue and the noise issue. To address the\nabove issues, in this paper, we propose an effective and efficient UMGL method\nto explore both complementary and consistent information. To do this, our\nmethod employs multiple MLP encoders rather than graph convolutional network\n(GCN) to conduct representation learning with two constraints, i.e., preserving\nthe local graph structure among nodes to handle the out-of-sample issue, and\nmaximizing the correlation of multiple node representations to handle the noise\nissue. Comprehensive experiments demonstrate that our proposed method achieves\nsuperior effectiveness and efficiency over the comparison methods and\neffectively tackles those two issues. Code is available at\nhttps://github.com/LarryUESTC/CoCoMG.",
            "author": [
                "Liang Peng",
                "Xin Wang",
                "Xiaofeng Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611971",
                "http://arxiv.org/abs/2308.01606v1",
                "http://arxiv.org/pdf/2308.01606v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01604v1",
            "title": "IndoHerb: Indonesia Medicinal Plants Recognition using Transfer Learning\n  and Deep Learning",
            "updated": "2023-08-03T08:16:55Z",
            "published": "2023-08-03T08:16:55Z",
            "summary": "Herbal plants are nutritious plants that can be used as an alternative to\ntraditional disease healing. In Indonesia there are various types of herbal\nplants. But with the development of the times, the existence of herbal plants\nas traditional medicines began to be forgotten so that not everyone could\nrecognize them. Having the ability to identify herbal plants can have many\npositive impacts. However, there is a problem where identifying plants can take\na long time because it requires in-depth knowledge and careful examination of\nplant criteria. So that the application of computer vision can help identify\nherbal plants. Previously, research had been conducted on the introduction of\nherbal plants from Vietnam using several algorithms, but from these research\nthe accuracy was not high enough. Therefore, this study intends to implement\ntransfer learning from the Convolutional Neural Network (CNN) algorithm to\nclassify types of herbal plants from Indonesia. This research was conducted by\ncollecting image data of herbal plants from Indonesia independently through the\nGoogle Images search engine. After that, it will go through the data\npreprocessing, classification using the transfer learning method from CNN, and\nanalysis will be carried out. The CNN transfer learning models used are\nResNet34, DenseNet121, and VGG11_bn. Based on the test results of the three\nmodels, it was found that DenseNet121 was the model with the highest accuracy,\nwhich was 87.4%. In addition, testing was also carried out using the scratch\nmodel and obtained an accuracy of 43.53%. The Hyperparameter configuration used\nin this test is the ExponentialLR scheduler with a gamma value of 0.9; learning\nrate 0.001; Cross Entropy Loss function; Adam optimizer; and the number of\nepochs is 50. Indonesia Medicinal Plant Dataset can be accessed at the\nfollowing link https://github.com/Salmanim20/indo_medicinal_plant",
            "author": [
                "Muhammad Salman Ikrar Musyaffa",
                "Novanto Yudistira",
                "Muhammad Arif Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01604v1",
                "http://arxiv.org/pdf/2308.01604v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01602v1",
            "title": "Deep Learning-based surrogate models for parametrized PDEs: handling\n  geometric variability through graph neural networks",
            "updated": "2023-08-03T08:14:28Z",
            "published": "2023-08-03T08:14:28Z",
            "summary": "Mesh-based simulations play a key role when modeling complex physical systems\nthat, in many disciplines across science and engineering, require the solution\nof parametrized time-dependent nonlinear partial differential equations (PDEs).\nIn this context, full order models (FOMs), such as those relying on the finite\nelement method, can reach high levels of accuracy, however often yielding\nintensive simulations to run. For this reason, surrogate models are developed\nto replace computationally expensive solvers with more efficient ones, which\ncan strike favorable trade-offs between accuracy and efficiency. This work\nexplores the potential usage of graph neural networks (GNNs) for the simulation\nof time-dependent PDEs in the presence of geometrical variability. In\nparticular, we propose a systematic strategy to build surrogate models based on\na data-driven time-stepping scheme where a GNN architecture is used to\nefficiently evolve the system. With respect to the majority of surrogate\nmodels, the proposed approach stands out for its ability of tackling problems\nwith parameter dependent spatial domains, while simultaneously generalizing to\ndifferent geometries and mesh resolutions. We assess the effectiveness of the\nproposed approach through a series of numerical experiments, involving both\ntwo- and three-dimensional problems, showing that GNNs can provide a valid\nalternative to traditional surrogate models in terms of computational\nefficiency and generalization to new scenarios. We also assess, from a\nnumerical standpoint, the importance of using GNNs, rather than classical dense\ndeep neural networks, for the proposed framework.",
            "author": [
                "Nicola Rares Franco",
                "Stefania Fresca",
                "Filippo Tombari",
                "Andrea Manzoni"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01602v1",
                "http://arxiv.org/pdf/2308.01602v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01598v1",
            "title": "Meta-theorems for Parameterized Streaming Algorithms",
            "updated": "2023-08-03T08:05:23Z",
            "published": "2023-08-03T08:05:23Z",
            "summary": "The streaming model was introduced to parameterized complexity independently\nby Fafianie and Kratsch [MFCS14] and by Chitnis, Cormode, Hajiaghayi and\nMonemizadeh [SODA15]. Subsequently, it was broadened by Chitnis, Cormode,\nEsfandiari, Hajiaghayi and Monemizadeh [SPAA15] and by Chitnis, Cormode,\nEsfandiari, Hajiaghayi, McGregor, Monemizadeh and Vorotnikova [SODA16]. Despite\nits strong motivation, the applicability of the streaming model to central\nproblems in parameterized complexity has remained, for almost a decade, quite\nlimited. Indeed, due to simple $\\Omega(n)$-space lower bounds for many of these\nproblems, the $k^{O(1)}\\cdot {\\rm polylog}(n)$-space requirement in the model\nis too strict.\n  Thus, we explore {\\em semi-streaming} algorithms for parameterized graph\nproblems, and present the first systematic study of this topic. Crucially, we\naim to construct succinct representations of the input on which optimal\npost-processing time complexity can be achieved.\n  - We devise meta-theorems specifically designed for parameterized streaming\nand demonstrate their applicability by obtaining the first $k^{O(1)}\\cdot\nn\\cdot {\\rm polylog}(n)$-space streaming algorithms for well-studied problems\nsuch as Feedback Vertex Set on Tournaments, Cluster Vertex Deletion, Proper\nInterval Vertex Deletion and Block Vertex Deletion. In the process, we\ndemonstrate a fundamental connection between semi-streaming algorithms for\nrecognizing graphs in a graph class H and semi-streaming algorithms for the\nproblem of vertex deletion into H.\n  - We present an algorithmic machinery for obtaining streaming algorithms for\ncut problems and exemplify this by giving the first $k^{O(1)}\\cdot n\\cdot {\\rm\npolylog}(n)$-space streaming algorithms for Graph Bipartitization, Multiway Cut\nand Subset Feedback Vertex Set.",
            "author": [
                "Daniel Lokshtanov",
                "Pranabendu Misra",
                "Fahad Panolan",
                "M. S. Ramanujan",
                "Saket Saurabh",
                "Meirav Zehavi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01598v1",
                "http://arxiv.org/pdf/2308.01598v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01597v1",
            "title": "DOLCE: A Descriptive Ontology for Linguistic and Cognitive Engineering",
            "updated": "2023-08-03T08:03:19Z",
            "published": "2023-08-03T08:03:19Z",
            "summary": "DOLCE, the first top-level (foundational) ontology to be axiomatized, has\nremained stable for twenty years and today is broadly used in a variety of\ndomains. DOLCE is inspired by cognitive and linguistic considerations and aims\nto model a commonsense view of reality, like the one human beings exploit in\neveryday life in areas as diverse as socio-technical systems, manufacturing,\nfinancial transactions and cultural heritage. DOLCE clearly lists the\nontological choices it is based upon, relies on philosophical principles, is\nrichly formalized, and is built according to well-established ontological\nmethodologies, e.g. OntoClean. Because of these features, it has inspired most\nof the existing top-level ontologies and has been used to develop or improve\nstandards and public domain resources (e.g. CIDOC CRM, DBpedia and WordNet).\nBeing a foundational ontology, DOLCE is not directly concerned with domain\nknowledge. Its purpose is to provide the general categories and relations\nneeded to give a coherent view of reality, to integrate domain knowledge, and\nto mediate across domains. In these 20 years DOLCE has shown that applied\nontologies can be stable and that interoperability across reference and domain\nontologies is a reality. This paper briefly introduces the ontology and shows\nhow to use it on a few modeling cases.",
            "author": [
                "Stefano Borgo",
                "Roberta Ferrario",
                "Aldo Gangemi",
                "Nicola Guarino",
                "Claudio Masolo",
                "Daniele Porello",
                "Emilio M. Sanfilippo",
                "Laure Vieu"
            ],
            "link": [
                "http://dx.doi.org/10.3233/AO-210259",
                "http://arxiv.org/abs/2308.01597v1",
                "http://arxiv.org/pdf/2308.01597v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01594v1",
            "title": "Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models",
            "updated": "2023-08-03T07:57:02Z",
            "published": "2023-08-03T07:57:02Z",
            "summary": "Electron microscopy (EM) images exhibit anisotropic axial resolution due to\nthe characteristics inherent to the imaging modality, presenting challenges in\nanalysis and downstream tasks.In this paper, we propose a diffusion-model-based\nframework that overcomes the limitations of requiring reference data or prior\nknowledge about the degradation process. Our approach utilizes 2D diffusion\nmodels to consistently reconstruct 3D volumes and is well-suited for highly\ndownsampled data. Extensive experiments conducted on two public datasets\ndemonstrate the robustness and superiority of leveraging the generative prior\ncompared to supervised learning methods. Additionally, we demonstrate our\nmethod's feasibility for self-supervised reconstruction, which can restore a\nsingle anisotropic volume without any training data.",
            "author": [
                "Kyungryun Lee",
                "Won-Ki Jeong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01594v1",
                "http://arxiv.org/pdf/2308.01594v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01585v1",
            "title": "A footnote to a paper of Deodhar",
            "updated": "2023-08-03T07:41:47Z",
            "published": "2023-08-03T07:41:47Z",
            "summary": "Let $X\\subseteq G\\slash B$ be a Schubert variety in a flag manifold and let\n$\\pi: \\tilde X \\rightarrow X$ be a Bott-Samelson resolution of $X$. In this\npaper we prove an effective version of the decomposition theorem for the\nderived pushforward $R \\pi_{*} \\mathbb{Q}_{\\tilde{X}}$. As a by-product, we\nobtain recursive procedure to extract Kazhdan-Lusztig polynomials from the\npolynomials introduced by V. Deodhar in \\cite{Deo}, which does not require\nprior knowledge of a minimal set. We also observe that any family of\nequivariant resolutions of Schubert varieties allows to define a new basis in\nthe Hecke algebra and we show a way to compute the transition matrix, from the\nKazhdan-Lusztig basis to the new one.",
            "author": [
                "Davide Franco"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01585v1",
                "http://arxiv.org/pdf/2308.01585v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.RT",
                "Primary 14B05, 14M15, Secondary 14E15, 14F45, 32S20, 32S60, 58K15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01574v1",
            "title": "Another Hamiltonian Cycle in Bipartite Pfaffian Graphs",
            "updated": "2023-08-03T07:22:12Z",
            "published": "2023-08-03T07:22:12Z",
            "summary": "We present a linear-time algorithm that, given as input (i) a bipartite\nPfaffian graph $G$ of minimum degree three, (ii) a Hamiltonian cycle $H$ in\n$G$, and (iii) an edge $e$ in $H$, outputs at least three other Hamiltonian\ncycles through the edge $e$ in $G$. This linear-time complexity of finding\nanother Hamiltonian cycle given one is in sharp contrast to the problem of\ndeciding the existence of a Hamiltonian cycle, which is NP-complete already for\ncubic bipartite planar graphs; such graphs are Pfaffian. Also, without the\ndegree requirement, we show that it is NP-hard to find another Hamiltonian\ncycle in a bipartite Pfaffian graph. We present further improved algorithms for\nfinding optimal traveling salesperson tours and counting Hamiltonian cycles in\nbipartite planar graphs with running times that are not known to hold in\ngeneral planar graphs.\n  We prove our results by a new structural technique that efficiently witnesses\neach Hamiltonian cycle $H$ through an arbitrary fixed anchor edge $e$ in a\nbipartite Pfaffian graph using a two-coloring of the vertices as advice that is\nunique to $H$. Previous techniques -- the Cut&Count technique of Cygan et al.\n[FOCS'11, TALG'22] in particular -- were able to reduce the Hamiltonian cycle\nproblem only to essentially counting problems; our results show that counting\ncan be avoided by leveraging properties of bipartite Pfaffian graphs. Our\ntechnique also has purely graph-theoretical consequences; for example, we show\nthat every cubic bipartite Pfaffian graph has either zero or at least six\ndistinct Hamiltonian cycles; the latter case is tight for the cube graph.",
            "author": [
                "Andreas Bj\u00f6rklund",
                "Petteri Kaski",
                "Jesper Nederlof"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01574v1",
                "http://arxiv.org/pdf/2308.01574v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01564v1",
            "title": "Sparse pancyclic subgraphs of random graphs",
            "updated": "2023-08-03T07:10:41Z",
            "published": "2023-08-03T07:10:41Z",
            "summary": "It is known that the complete graph $K_n$ contains a pancyclic subgraph with\n$n+(1+o(1))\\cdot \\log _2 n$ edges, and that there is no pancyclic graph on $n$\nvertices with fewer than $n+\\log _2 (n-1) -1$ edges. We show that, with high\nprobability, $G(n,p)$ contains a pancyclic subgraph with $n+(1+o(1))\\log_2 n$\nedges for $p \\ge p^*$, where $p^*=(1+o(1))\\ln n/n$, right above the threshold\nfor pancyclicity.",
            "author": [
                "Yahav Alon",
                "Michael Krivelevich"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01564v1",
                "http://arxiv.org/pdf/2308.01564v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01561v1",
            "title": "Algorithmic study of $d_2$-transitivity of graphs",
            "updated": "2023-08-03T07:00:52Z",
            "published": "2023-08-03T07:00:52Z",
            "summary": "Let $G=(V, E)$ be a graph where $V$ and $E$ are the vertex and edge sets,\nrespectively. For two disjoint subsets $A$ and $B$ of $V$, we say $A$\n\\emph{dominates} $B$ if every vertex of $B$ is adjacent to at least one vertex\nof $A$. A vertex partition $\\pi = \\{V_1, V_2, \\ldots, V_k\\}$ of $G$ is called a\n\\emph{transitive partition} of size $k$ if $V_i$ dominates $V_j$ for all $1\\leq\ni<j\\leq k$. In this article, we initiate the study of a generalization of\ntransitive partition, namely \\emph{$d_2$-transitive partition}. For two\ndisjoint subsets $A$ and $B$ of $V$, we say $A$ \\emph{$d_2$-dominates} $B$ if,\nfor every vertex of $B$, there exists a vertex in $A$, such that the distance\nbetween them is at most two. A vertex partition $\\pi = \\{V_1, V_2, \\ldots,\nV_k\\}$ of $G$ is called a \\emph{$d_2$-transitive partition} of size $k$ if\n$V_i$ $d_2$-dominates $V_j$ for all $1\\leq i<j\\leq k$. The maximum integer $k$\nfor which the above partition exists is called \\emph{$d_2$-transitivity} of\n$G$, and it is denoted by $Tr_{d_2}(G)$. The \\textsc{Maximum $d_2$-Transitivity\nProblem} is to find a $d_2$-transitive partition of a given graph with the\nmaximum number of parts. We show that this problem can be solved in linear time\nfor the complement of bipartite graphs and bipartite chain graphs. On the\nnegative side, we prove that the decision version of the \\textsc{Maximum\n$d_2$-Transitivity Problem} is NP-complete for split graphs, bipartite graphs,\nand star-convex bipartite graphs.",
            "author": [
                "Subhabrata Paul",
                "Kamal Santra"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01561v1",
                "http://arxiv.org/pdf/2308.01561v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02565v1",
            "title": "SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning",
            "updated": "2023-08-03T07:00:04Z",
            "published": "2023-08-03T07:00:04Z",
            "summary": "Textual graphs (TGs) are graphs whose nodes correspond to text (sentences or\ndocuments), which are widely prevalent. The representation learning of TGs\ninvolves two stages: (i) unsupervised feature extraction and (ii) supervised\ngraph representation learning. In recent years, extensive efforts have been\ndevoted to the latter stage, where Graph Neural Networks (GNNs) have dominated.\nHowever, the former stage for most existing graph benchmarks still relies on\ntraditional feature engineering techniques. More recently, with the rapid\ndevelopment of language models (LMs), researchers have focused on leveraging\nLMs to facilitate the learning of TGs, either by jointly training them in a\ncomputationally intensive framework (merging the two stages), or designing\ncomplex self-supervised training tasks for feature extraction (enhancing the\nfirst stage). In this work, we present SimTeG, a frustratingly Simple approach\nfor Textual Graph learning that does not innovate in frameworks, models, and\ntasks. Instead, we first perform supervised parameter-efficient fine-tuning\n(PEFT) on a pre-trained LM on the downstream task, such as node classification.\nWe then generate node embeddings using the last hidden states of finetuned LM.\nThese derived features can be further utilized by any GNN for training on the\nsame task. We evaluate our approach on two fundamental graph representation\nlearning tasks: node classification and link prediction. Through extensive\nexperiments, we show that our approach significantly improves the performance\nof various GNNs on multiple graph benchmarks.",
            "author": [
                "Keyu Duan",
                "Qian Liu",
                "Tat-Seng Chua",
                "Shuicheng Yan",
                "Wei Tsang Ooi",
                "Qizhe Xie",
                "Junxian He"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02565v1",
                "http://arxiv.org/pdf/2308.02565v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02564v1",
            "title": "The differential on Graph Operator R(G)",
            "updated": "2023-08-03T06:39:15Z",
            "published": "2023-08-03T06:39:15Z",
            "summary": "Let $G=(V(G), E(G))$ be a simple graph with vertex set $V(G)$ and edge set\n$E(G)$. Let $S$ be a subset of $V(G)$, and let $B(S)$ be the set of neighbours\nof $S$ in $V(G) \\setminus S$. The differential $\\partial(S)$ of $S$ is the\nnumber $|B(S)|-|S|$. The maximum value of $\\partial(S)$ taken over all subsets\n$S\\subseteq V(G)$ is the differential $\\partial(G)$ of $G$. The graph $R{G}$ is\ndefined as the graph obtained from $G$ by adding a new vertex $v_e$ for each\n$e\\in E(G)$, and by joining $v_e$ to the end vertices of $e$. In this paper we\nstudy the relationship between $\\partial(G)$ and $\\partial(R(G))$, and give\ntight asymptotic bounds for $\\partial(R(G))$. We also exhibit some\nrelationships between certain vertex sets of $G$ and $R(G)$ which involve well\nknown graph theoretical parameters.",
            "author": [
                "Ludwin A. Hern\u00e1ndez",
                "Jes\u00fas Lea\u00f1os",
                "Omar Rosario",
                "Jos\u00e9 M. Sigarreta"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02564v1",
                "http://arxiv.org/pdf/2308.02564v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C69, 05C76"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01534v2",
            "title": "One Partition Approximating All $\\ell_p$-norm Objectives in Correlation\n  Clustering",
            "updated": "2023-10-17T18:30:20Z",
            "published": "2023-08-03T04:26:22Z",
            "summary": "This paper considers correlation clustering on unweighted complete graphs. We\ngive a combinatorial algorithm that returns a single clustering solution that\nis simultaneously $O(1)$-approximate for all $\\ell_p$-norms of the disagreement\nvector. This proves that minimal sacrifice is needed in order to optimize\ndifferent norms of the disagreement vector. Our algorithm is the first\ncombinatorial approximation algorithm for the $\\ell_2$-norm objective, and more\ngenerally the first combinatorial algorithm for the $\\ell_p$-norm objective\nwhen $2 \\leq p < \\infty$. It is also faster than all previous algorithms that\nminimize the $\\ell_p$-norm of the disagreement vector, with run-time\n$O(n^\\omega)$, where $O(n^\\omega)$ is the time for matrix multiplication on $n\n\\times n$ matrices. When the maximum positive degree in the graph is at most\n$\\Delta$, this can be improved to a run-time of $O(n\\Delta^2 \\log n)$.",
            "author": [
                "Sami Davies",
                "Benjamin Moseley",
                "Heather Newman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01534v2",
                "http://arxiv.org/pdf/2308.01534v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01524v1",
            "title": "Unsupervised Learning of Part Similarity for Goal-Guided Accelerated\n  Experiment Design in Metal Additive Manufacturing",
            "updated": "2023-08-03T04:03:01Z",
            "published": "2023-08-03T04:03:01Z",
            "summary": "Metal additive manufacturing is gaining broad interest and increased use in\nthe industrial and academic fields. However, the quantification and\ncommercialization of standard parts usually require extensive experiments and\nexpensive post-characterization, which impedes the rapid development and\nadaptation of metal AM technologies. In this work, a similarity-based\nacceleration (S-acceleration) method for design of experiments is developed to\nreduce the time and costs associated with unveiling process-property (porosity\ndefects) relationships during manufacturing. With S-acceleration, part semantic\nfeatures from machine-setting parameters and physics-effects informed\ncharacteristics are explored for measuring mutual part similarities. A\nuser-defined simplification rate of experiments is proposed to purposely remove\nredundant parts before conducting experiments printing without sacrificing\ninformation gain as original full factorial experiment design. This\nS-acceleration design of experiments is demonstrated on a Concept Laser M2\nmachine for the experimental plan of modeling relationships between process\nparameters and part porosity defects. The printed part has 2 mm diameter by 4\nmm tall pin geometry considering variations in build location and orientation,\nlaser settings and powder feedstock are held constant. In total, 242 parts are\nmeasured to create a ground truth data set of porosity levels by using X-ray\ntomography microscopy. The S-acceleration method is assessed for performance\nconsidering 40%, 50%, and 60% of user-defined experiment simplification rates.\nThe repeated experiments are removed without ignoring the minority experiments\noutlier, assuring a similar process-property relation in the original\nexperiment plan. The experiment number is significantly reduced based on part\nsimilarity with minimal compromise of model accuracy and obtained knowledge.",
            "author": [
                "Rui Liu",
                "Sen Liu",
                "Xiaoli Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01524v1",
                "http://arxiv.org/pdf/2308.01524v1"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an",
                "cond-mat.mtrl-sci",
                "J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01512v1",
            "title": "Erase and Repair: An Efficient Box-Free Removal Attack on High-Capacity\n  Deep Hiding",
            "updated": "2023-08-03T02:51:46Z",
            "published": "2023-08-03T02:51:46Z",
            "summary": "Deep hiding, embedding images with others using deep neural networks, has\ndemonstrated impressive efficacy in increasing the message capacity and\nrobustness of secret sharing. In this paper, we challenge the robustness of\nexisting deep hiding schemes by preventing the recovery of secret images,\nbuilding on our in-depth study of state-of-the-art deep hiding schemes and\ntheir vulnerabilities. Leveraging our analysis, we first propose a simple\nbox-free removal attack on deep hiding that does not require any prior\nknowledge of the deep hiding schemes.\n  To improve the removal performance on the deep hiding schemes that may be\nenhanced by adversarial training, we further design a more powerful removal\nattack, efficient box-free removal attack (EBRA), which employs image\ninpainting techniques to remove secret images from container images. In\naddition, to ensure the effectiveness of our attack and preserve the fidelity\nof the processed container images, we design an erasing phase based on the\nlocality of deep hiding to remove secret information and then make full use of\nthe visual information of container images to repair the erased visual content.\nExtensive evaluations show our method can completely remove secret images from\ncontainer images with negligible impact on the quality of container images.",
            "author": [
                "Hangcheng Liu",
                "Tao Xiang",
                "Shangwei Guo",
                "Han Li",
                "Tianwei Zhang",
                "Xiaofeng Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01512v1",
                "http://arxiv.org/pdf/2308.01512v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01502v2",
            "title": "Induced subdivisions with pinned branch vertices",
            "updated": "2023-08-04T01:49:39Z",
            "published": "2023-08-03T01:52:47Z",
            "summary": "We prove that for all integers $r\\geq 0$ and $s,t\\geq 1$, there exists an\ninteger $\\Omega=\\Omega(r,s,t)\\geq 1$ with the following property. Let $G$ be a\ngraph and let $H$ be a subgraph of $G$ isomorphic to a $(\\leq r)$-subdivision\nof $K_{\\Omega}$. Then either $G$ contains $K_t$ or $K_{t,t}$ as an induced\nsubgraph, or there is an induced subgraph $J$ of $G$ isomorphic to a proper\n$(\\leq r)$-subdivision of $K_s$ such that every branch vertex of $J$ is a\nbranch vertex of $H$. This answers in the affirmative a question of Lozin and\nRazgon. In fact, we show that both the branch vertices and the paths\ncorresponding to the subdivided edges between them can be preserved.",
            "author": [
                "Sepehr Hajebi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01502v2",
                "http://arxiv.org/pdf/2308.01502v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01499v1",
            "title": "TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality\n  Explorations",
            "updated": "2023-08-03T01:50:48Z",
            "published": "2023-08-03T01:50:48Z",
            "summary": "Dynamic colored meshes (DCM) are widely used in various applications;\nhowever, these meshes may undergo different processes, such as compression or\ntransmission, which can distort them and degrade their quality. To facilitate\nthe development of objective metrics for DCMs and study the influence of\ntypical distortions on their perception, we create the Tencent - dynamic\ncolored mesh database (TDMD) containing eight reference DCM objects with six\ntypical distortions. Using processed video sequences (PVS) derived from the\nDCM, we have conducted a large-scale subjective experiment that resulted in 303\ndistorted DCM samples with mean opinion scores, making the TDMD the largest\navailable DCM database to our knowledge. This database enabled us to study the\nimpact of different types of distortion on human perception and offer\nrecommendations for DCM compression and related tasks. Additionally, we have\nevaluated three types of state-of-the-art objective metrics on the TDMD,\nincluding image-based, point-based, and video-based metrics, on the TDMD. Our\nexperimental results highlight the strengths and weaknesses of each metric, and\nwe provide suggestions about the selection of metrics in practical DCM\napplications. The TDMD will be made publicly available at the following\nlocation: https://multimedia.tencent.com/resources/tdmd.",
            "author": [
                "Qi Yang",
                "Joel Jung",
                "Timon Deschamps",
                "Xiaozhong Xu",
                "Shan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01499v1",
                "http://arxiv.org/pdf/2308.01499v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01938v1",
            "title": "Online Multi-Task Learning with Recursive Least Squares and Recursive\n  Kernel Methods",
            "updated": "2023-08-03T01:41:34Z",
            "published": "2023-08-03T01:41:34Z",
            "summary": "This paper introduces two novel approaches for Online Multi-Task Learning\n(MTL) Regression Problems. We employ a high performance graph-based MTL\nformulation and develop its recursive versions based on the Weighted Recursive\nLeast Squares (WRLS) and the Online Sparse Least Squares Support Vector\nRegression (OSLSSVR). Adopting task-stacking transformations, we demonstrate\nthe existence of a single matrix incorporating the relationship of multiple\ntasks and providing structural information to be embodied by the MT-WRLS method\nin its initialization procedure and by the MT-OSLSSVR in its multi-task kernel\nfunction. Contrasting the existing literature, which is mostly based on Online\nGradient Descent (OGD) or cubic inexact approaches, we achieve exact and\napproximate recursions with quadratic per-instance cost on the dimension of the\ninput space (MT-WRLS) or on the size of the dictionary of instances\n(MT-OSLSSVR). We compare our online MTL methods to other contenders in a\nreal-world wind speed forecasting case study, evidencing the significant gain\nin performance of both proposed approaches.",
            "author": [
                "Gabriel R. Lencione",
                "Fernando J. Von Zuben"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01938v1",
                "http://arxiv.org/pdf/2308.01938v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01475v1",
            "title": "Interpretable Machine Learning for Discovery: Statistical Challenges \\&\n  Opportunities",
            "updated": "2023-08-02T23:57:31Z",
            "published": "2023-08-02T23:57:31Z",
            "summary": "New technologies have led to vast troves of large and complex datasets across\nmany scientific domains and industries. People routinely use machine learning\ntechniques to not only process, visualize, and make predictions from this big\ndata, but also to make data-driven discoveries. These discoveries are often\nmade using Interpretable Machine Learning, or machine learning models and\ntechniques that yield human understandable insights. In this paper, we discuss\nand review the field of interpretable machine learning, focusing especially on\nthe techniques as they are often employed to generate new knowledge or make\ndiscoveries from large data sets. We outline the types of discoveries that can\nbe made using Interpretable Machine Learning in both supervised and\nunsupervised settings. Additionally, we focus on the grand challenge of how to\nvalidate these discoveries in a data-driven manner, which promotes trust in\nmachine learning systems and reproducibility in science. We discuss validation\nfrom both a practical perspective, reviewing approaches based on data-splitting\nand stability, as well as from a theoretical perspective, reviewing statistical\nresults on model selection consistency and uncertainty quantification via\nstatistical inference. Finally, we conclude by highlighting open challenges in\nusing interpretable machine learning techniques to make discoveries, including\ngaps between theory and practice for validating data-driven-discoveries.",
            "author": [
                "Genevera I. Allen",
                "Luqin Gan",
                "Lili Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01475v1",
                "http://arxiv.org/pdf/2308.01475v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04512v1",
            "title": "An introduction to graph theory",
            "updated": "2023-08-02T23:24:26Z",
            "published": "2023-08-02T23:24:26Z",
            "summary": "This is a graduate-level introduction to graph theory, corresponding to a\nquarter-long course. It covers simple graphs, multigraphs as well as their\ndirected analogues, and more restrictive classes such as tournaments, trees and\narborescences. Among the features discussed are Eulerian circuits, Hamiltonian\ncycles, spanning trees, the matrix-tree and BEST theorems, proper colorings,\nTuran's theorem, bipartite matching and the Menger and Gallai--Milgram\ntheorems. The basics of network flows are introduced in order to prove Hall's\nmarriage theorem.\n  Around a hundred exercises are included (without solutions).",
            "author": [
                "Darij Grinberg"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04512v1",
                "http://arxiv.org/pdf/2308.04512v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "math.CO",
                "05Cxx"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01469v1",
            "title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference",
            "updated": "2023-08-02T23:13:49Z",
            "published": "2023-08-02T23:13:49Z",
            "summary": "Graph neural networks (GNNs) have brought superb performance to various\napplications utilizing graph structural data, such as social analysis and fraud\ndetection. The graph links, e.g., social relationships and transaction history,\nare sensitive and valuable information, which raises privacy concerns when\nusing GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel\ngraph poisoning attack that increases the effectiveness of graph link stealing\nby amplifying the link connectivity leakage. To infer node adjacency more\naccurately, we propose an attention mechanism that can be embedded into the\nlink detection network. Our experiments demonstrate that VertexSerum\nsignificantly outperforms the SOTA link inference attack, improving the AUC\nscores by an average of $9.8\\%$ across four real-world datasets and three\ndifferent GNN structures. Furthermore, our experiments reveal the effectiveness\nof VertexSerum in both black-box and online learning settings, further\nvalidating its applicability in real-world scenarios.",
            "author": [
                "Ruyi Ding",
                "Shijin Duan",
                "Xiaolin Xu",
                "Yunsi Fei"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01469v1",
                "http://arxiv.org/pdf/2308.01469v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01465v1",
            "title": "Empirical evidence of the inseparability of mathematics and physics in\n  expert reasoning about novel graphing tasks",
            "updated": "2023-08-02T22:53:48Z",
            "published": "2023-08-02T22:53:48Z",
            "summary": "Pre-college mathematics modeling instruction often frames mathematics as\nbeing separated from reasoning about the real world -- and commonly treats\nreasoning mathematically and reasoning about the real-world context as separate\nstages of a modeling cycle. In this paper, we present evidence that helps\ncharacterize how experts use mathematics in physics contexts while developing\ngraphical models. An important finding is that there was essentially no\nevidence of experts reasoning in a context-free way with these tasks, but\ninstead they used physical reasoning -- either grounded in the context of the\ntask or from abstract physical models -- to guide their mathematics. The\ndifference in approach of physics instructors and students may lead to a\nmismatch in expectations, and frustration, for both parties. This work\ncontributes to the body of knowledge about how mathematical reasoning appears\nin physics, and can help researchers and instructors recognize the connections\nto the physical world in expert mathematical reasoning. This can help\ninstructors and researchers be better equipped to develop materials and methods\nthat can help students start building those connections as well.",
            "author": [
                "Charlotte Zimmerman",
                "Alexis Olsho",
                "Michael Loverude",
                "Suzanne White Brahmia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01465v1",
                "http://arxiv.org/pdf/2308.01465v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01463v1",
            "title": "SemDiff: Binary Similarity Detection by Diffing Key-Semantics Graphs",
            "updated": "2023-08-02T22:48:48Z",
            "published": "2023-08-02T22:48:48Z",
            "summary": "Binary similarity detection is a critical technique that has been applied in\nmany real-world scenarios where source code is not available, e.g., bug search,\nmalware analysis, and code plagiarism detection. Existing works are ineffective\nin detecting similar binaries in cases where different compiling optimizations,\ncompilers, source code versions, or obfuscation are deployed.\n  We observe that all the cases do not change a binary's key code behaviors\nalthough they significantly modify its syntax and structure. With this key\nobservation, we extract a set of key instructions from a binary to capture its\nkey code behaviors. By detecting the similarity between two binaries' key\ninstructions, we can address well the ineffectiveness limitation of existing\nworks. Specifically, we translate each extracted key instruction into a\nself-defined key expression, generating a key-semantics graph based on the\nbinary's control flow. Each node in the key-semantics graph denotes a key\ninstruction, and the node attribute is the key expression. To quantify the\nsimilarity between two given key-semantics graphs, we first serialize each\ngraph into a sequence of key expressions by topological sort. Then, we tokenize\nand concatenate key expressions to generate token lists. We calculate the\nlocality-sensitive hash value for all token lists and quantify their\nsimilarity. %We implement a prototype, called SemDiff, consisting of two\nmodules: graph generation and graph diffing. The first module generates a pair\nof key-semantics graphs and the second module diffs the graphs. Our evaluation\nresults show that overall, SemDiff outperforms state-of-the-art tools when\ndetecting the similarity of binaries generated from different optimization\nlevels, compilers, and obfuscations. SemDiff is also effective for library\nversion search and finding similar vulnerabilities in firmware.",
            "author": [
                "Zian Liu",
                "Zhi Zhang",
                "Siqi Ma",
                "Dongxi Liu",
                "Jun Zhang",
                "Chao Chen",
                "Shigang Liu",
                "Muhammad Ejaz Ahmed",
                "Yang Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01463v1",
                "http://arxiv.org/pdf/2308.01463v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01461v2",
            "title": "Directed graphs without rainbow triangles",
            "updated": "2023-08-05T19:48:53Z",
            "published": "2023-08-02T22:29:02Z",
            "summary": "One of the most fundamental results in graph theory is Mantel's theorem which\ndetermines the maximum number of edges in a triangle-free graph of order $n$.\nRecently a colorful variant of this problem has been solved. In such a variant\nwe consider $c$ graphs on a common vertex set, thinking of each graph as edges\nin a distinct color, and want to determine the smallest number of edges in each\ncolor which guarantees existence of a rainbow triangle. Here, we solve the\nanalogous problem for directed graphs without rainbow triangles, either\ndirected or transitive, for any number of colors. The constructions and proofs\nessentially differ for $c=3$ and $c \\geq 4$ and the type of the forbidden\ntriangle. Additionally, we also solve the analogous problem in the setting of\noriented graphs.",
            "author": [
                "Sebastian Babi\u0144ski",
                "Andrzej Grzesik",
                "Magdalena Prorok"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01461v2",
                "http://arxiv.org/pdf/2308.01461v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C20, 05C35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.12354v1",
            "title": "Machine Learning Small Molecule Properties in Drug Discovery",
            "updated": "2023-08-02T22:18:41Z",
            "published": "2023-08-02T22:18:41Z",
            "summary": "Machine learning (ML) is a promising approach for predicting small molecule\nproperties in drug discovery. Here, we provide a comprehensive overview of\nvarious ML methods introduced for this purpose in recent years. We review a\nwide range of properties, including binding affinities, solubility, and ADMET\n(Absorption, Distribution, Metabolism, Excretion, and Toxicity). We discuss\nexisting popular datasets and molecular descriptors and embeddings, such as\nchemical fingerprints and graph-based neural networks. We highlight also\nchallenges of predicting and optimizing multiple properties during hit-to-lead\nand lead optimization stages of drug discovery and explore briefly possible\nmulti-objective optimization techniques that can be used to balance diverse\nproperties while optimizing lead candidates. Finally, techniques to provide an\nunderstanding of model predictions, especially for critical decision-making in\ndrug discovery are assessed. Overall, this review provides insights into the\nlandscape of ML models for small molecule property predictions in drug\ndiscovery. So far, there are multiple diverse approaches, but their\nperformances are often comparable. Neural networks, while more flexible, do not\nalways outperform simpler models. This shows that the availability of\nhigh-quality training data remains crucial for training accurate models and\nthere is a need for standardized benchmarks, additional performance metrics,\nand best practices to enable richer comparisons between the different\ntechniques and models that can shed a better light on the differences between\nthe many techniques.",
            "author": [
                "Nikolai Schapin",
                "Maciej Majewski",
                "Alejandro Varela",
                "Carlos Arroniz",
                "Gianni De Fabritiis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.12354v1",
                "http://arxiv.org/pdf/2308.12354v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01456v1",
            "title": "Decomposing a signed graph into rooted circuits",
            "updated": "2023-08-02T22:12:36Z",
            "published": "2023-08-02T22:12:36Z",
            "summary": "We prove a precise min-max theorem for the following problem. Let $G$ be an\nEulerian graph with a specified set of edges $S \\subseteq E(G)$, and let $b$ be\na vertex of $G$. Then what is the maximum integer $k$ so that the edge-set of\n$G$ can be partitioned into $k$ non-zero $b$-trails? That is, each trail must\nbegin and end at $b$ and contain an odd number of edges from $S$. This theorem\nis motivated by a connection to vertex-minors and yields two conjectures of\nM\\'{a}\\v{c}ajov\\'{a} and \\v{S}koviera as corollaries.",
            "author": [
                "Rose McCarty"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01456v1",
                "http://arxiv.org/pdf/2308.01456v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02559v2",
            "title": "DLSIA: Deep Learning for Scientific Image Analysis",
            "updated": "2023-08-26T18:03:39Z",
            "published": "2023-08-02T21:32:41Z",
            "summary": "We introduce DLSIA (Deep Learning for Scientific Image Analysis), a\nPython-based machine learning library that empowers scientists and researchers\nacross diverse scientific domains with a range of customizable convolutional\nneural network (CNN) architectures for a wide variety of tasks in image\nanalysis to be used in downstream data processing, or for\nexperiment-in-the-loop computing scenarios. DLSIA features easy-to-use\narchitectures such as autoencoders, tunable U-Nets, and parameter-lean\nmixed-scale dense networks (MSDNets). Additionally, we introduce sparse\nmixed-scale networks (SMSNets), generated using random graphs and sparse\nconnections. As experimental data continues to grow in scale and complexity,\nDLSIA provides accessible CNN construction and abstracts CNN complexities,\nallowing scientists to tailor their machine learning approaches, accelerate\ndiscoveries, foster interdisciplinary collaboration, and advance research in\nscientific image analysis.",
            "author": [
                "Eric J Roberts",
                "Tanny Chavez",
                "Alexander Hexemer",
                "Petrus H. Zwart"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02559v2",
                "http://arxiv.org/pdf/2308.02559v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01438v1",
            "title": "Novel Physics-Based Machine-Learning Models for Indoor Air Quality\n  Approximations",
            "updated": "2023-08-02T21:22:17Z",
            "published": "2023-08-02T21:22:17Z",
            "summary": "Cost-effective sensors are capable of real-time capturing a variety of air\nquality-related modalities from different pollutant concentrations to\nindoor/outdoor humidity and temperature. Machine learning (ML) models are\ncapable of performing air-quality \"ahead-of-time\" approximations. Undoubtedly,\naccurate indoor air quality approximation significantly helps provide a healthy\nindoor environment, optimize associated energy consumption, and offer human\ncomfort. However, it is crucial to design an ML architecture to capture the\ndomain knowledge, so-called problem physics. In this study, we propose six\nnovel physics-based ML models for accurate indoor pollutant concentration\napproximations. The proposed models include an adroit combination of\nstate-space concepts in physics, Gated Recurrent Units, and Decomposition\ntechniques. The proposed models were illustrated using data collected from five\noffices in a commercial building in California. The proposed models are shown\nto be less complex, computationally more efficient, and more accurate than\nsimilar state-of-the-art transformer-based models. The superiority of the\nproposed models is due to their relatively light architecture (computational\nefficiency) and, more importantly, their ability to capture the underlying\nhighly nonlinear patterns embedded in the often contaminated sensor-collected\nindoor air quality temporal data.",
            "author": [
                "Ahmad Mohammadshirazi",
                "Aida Nadafian",
                "Amin Karimi Monsefi",
                "Mohammad H. Rafiei",
                "Rajiv Ramnath"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01438v1",
                "http://arxiv.org/pdf/2308.01438v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.data-an",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01936v2",
            "title": "Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?",
            "updated": "2023-09-12T16:33:15Z",
            "published": "2023-08-02T21:13:38Z",
            "summary": "A hallmark of intelligence is the ability to use a familiar domain to make\ninferences about a less familiar domain, known as analogical reasoning. In this\narticle, we delve into the performance of Large Language Models (LLMs) in\ndealing with progressively complex analogies expressed in unstructured text. We\ndiscuss analogies at four distinct levels of complexity: lexical analogies,\nsyntactic analogies, semantic analogies, and pragmatic analogies. As the\nanalogies become more complex, they require increasingly extensive, diverse\nknowledge beyond the textual content, unlikely to be found in the lexical\nco-occurrence statistics that power LLMs. To address this, we discuss the\nnecessity of employing Neuro-symbolic AI techniques that combine statistical\nand symbolic AI, informing the representation of unstructured text to highlight\nand augment relevant content, provide abstraction and guide the mapping\nprocess. Our knowledge-informed approach maintains the efficiency of LLMs while\npreserving the ability to explain analogies for pedagogical applications.",
            "author": [
                "Thilini Wijesiriwardene",
                "Amit Sheth",
                "Valerie L. Shalin",
                "Amitava Das"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01936v2",
                "http://arxiv.org/pdf/2308.01936v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01379v1",
            "title": "Computational Long Exposure Mobile Photography",
            "updated": "2023-08-02T18:36:54Z",
            "published": "2023-08-02T18:36:54Z",
            "summary": "Long exposure photography produces stunning imagery, representing moving\nelements in a scene with motion-blur. It is generally employed in two\nmodalities, producing either a foreground or a background blur effect.\nForeground blur images are traditionally captured on a tripod-mounted camera\nand portray blurred moving foreground elements, such as silky water or light\ntrails, over a perfectly sharp background landscape. Background blur images,\nalso called panning photography, are captured while the camera is tracking a\nmoving subject, to produce an image of a sharp subject over a background\nblurred by relative motion. Both techniques are notoriously challenging and\nrequire additional equipment and advanced skills. In this paper, we describe a\ncomputational burst photography system that operates in a hand-held smartphone\ncamera app, and achieves these effects fully automatically, at the tap of the\nshutter button. Our approach first detects and segments the salient subject. We\ntrack the scene motion over multiple frames and align the images in order to\npreserve desired sharpness and to produce aesthetically pleasing motion\nstreaks. We capture an under-exposed burst and select the subset of input\nframes that will produce blur trails of controlled length, regardless of scene\nor camera motion velocity. We predict inter-frame motion and synthesize\nmotion-blur to fill the temporal gaps between the input frames. Finally, we\ncomposite the blurred image with the sharp regular exposure to protect the\nsharpness of faces or areas of the scene that are barely moving, and produce a\nfinal high resolution and high dynamic range (HDR) photograph. Our system\ndemocratizes a capability previously reserved to professionals, and makes this\ncreative style accessible to most casual photographers.\n  More information and supplementary material can be found on our project\nwebpage: https://motion-mode.github.io/",
            "author": [
                "Eric Tabellion",
                "Nikhil Karnad",
                "Noa Glaser",
                "Ben Weiss",
                "David E. Jacobs",
                "Yael Pritch"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3592124",
                "http://arxiv.org/abs/2308.01379v1",
                "http://arxiv.org/pdf/2308.01379v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG",
                "I.4; I.3.3; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01375v2",
            "title": "CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic\n  Graphical Models",
            "updated": "2023-09-05T13:47:26Z",
            "published": "2023-08-02T18:26:43Z",
            "summary": "Causal probabilistic graph-based models have gained widespread utility,\nenabling the modeling of cause-and-effect relationships across diverse domains.\nWith their rising adoption in new areas, such as automotive system safety and\nmachine learning, the need for an integrated lifecycle framework akin to DevOps\nand MLOps has emerged. Currently, a process reference for organizations\ninterested in employing causal engineering is missing. To address this gap and\nfoster widespread industrial adoption, we propose CausalOps, a novel lifecycle\nframework for causal model development and application. By defining key\nentities, dependencies, and intermediate artifacts generated during causal\nengineering, we establish a consistent vocabulary and workflow model. This work\ncontextualizes causal model usage across different stages and stakeholders,\noutlining a holistic view of creating and maintaining them. CausalOps' aim is\nto drive the adoption of causal methods in practical applications within\ninterested organizations and the causality community.",
            "author": [
                "Robert Maier",
                "Andreas Schlattl",
                "Thomas Guess",
                "J\u00fcrgen Mottok"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01375v2",
                "http://arxiv.org/pdf/2308.01375v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "H.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01371v2",
            "title": "Reconstruction of the quasinormal spectrum from pole-skipping",
            "updated": "2023-11-06T19:25:13Z",
            "published": "2023-08-02T18:24:55Z",
            "summary": "The holographic gauge/gravity duality provides an explicit reduction of\nquantum field theory (QFT) calculations in the semi-classical large-$N$ limit\nto sets of `gravitational' differential equations whose analysis can reveal all\ndetails of the spectra of thermal QFT correlators. We argue that in certain\ncases, a complete reconstruction of the spectrum and of the corresponding\ncorrelator is possible from only the knowledge of an infinite, discrete set of\npole-skipping points traversed by a single (hydrodynamic) mode computed in a\nseries expansion in an inverse number of spacetime dimensions. Conceptually,\nthis reduces the computation of a QFT correlator spectrum to performing a set\nof purely algebraic manipulations. With the help of the pole-skipping analysis,\nwe also uncover a novel structure underpinning the coefficients that enter the\nhydrodynamic dispersion relations.",
            "author": [
                "Sa\u0161o Grozdanov",
                "Timotej Lemut",
                "Juan F. Pedraza"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevD.108.L101901",
                "http://arxiv.org/abs/2308.01371v2",
                "http://arxiv.org/pdf/2308.01371v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01359v1",
            "title": "Fast Coloring Despite Congested Relays",
            "updated": "2023-08-02T18:04:52Z",
            "published": "2023-08-02T18:04:52Z",
            "summary": "We provide a $O(\\log^6 \\log n)$-round randomized algorithm for distance-2\ncoloring in CONGEST with $\\Delta^2+1$ colors. For\n$\\Delta\\gg\\operatorname{poly}\\log n$, this improves exponentially on the\n$O(\\log\\Delta+\\operatorname{poly}\\log\\log n)$ algorithm of [Halld\\'orsson,\nKuhn, Maus, Nolin, DISC'20].\n  Our study is motivated by the ubiquity and hardness of local reductions in\nCONGEST. For instance, algorithms for the Local Lov\\'asz Lemma [Moser, Tardos,\nJACM'10; Fischer, Ghaffari, DISC'17; Davies, SODA'23] usually assume\ncommunication on the conflict graph, which can be simulated in LOCAL with only\nconstant overhead, while this may be prohibitively expensive in CONGEST. We\nhope our techniques help tackle in CONGEST other coloring problems defined by\nlocal relations.",
            "author": [
                "Maxime Flin",
                "Magn\u00fas M. Halld\u00f3rsson",
                "Alexandre Nolin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01359v1",
                "http://arxiv.org/pdf/2308.01359v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01933v1",
            "title": "Summary of 2nd International Workshop on Requirements Engineering and\n  Testing (RET)",
            "updated": "2023-08-02T17:25:03Z",
            "published": "2023-08-02T17:25:03Z",
            "summary": "The RET (Requirements Engineering and Testing) workshop series provides a\nmeeting point for researchers and practitioners from the two separate fields of\nRequirements Engineering (RE) and Testing. The goal is to improve the\nconnection and alignment of these two areas through an exchange of ideas,\nchallenges, practices, experiences and results. The long term aim is to build a\ncommunity and a body of knowledge within the intersection of RE and Testing,\ni.e. RET. The 2nd workshop was held in co-location with ICSE 2015 in Florence,\nItaly. The workshop continued in the same interactive vein as the 1st one and\nincluded a keynote, paper presentations with ample time for discussions, and a\ngroup exercise. For true impact and relevance this cross-cutting area requires\ncontribution from both RE and Testing, and from both researchers and\npractitioners. A range of papers were presented from short experience papers to\nfull research papers that cover connections between the two fields. One of the\nmain outputs of the 2nd workshop was a categorization of the presented workshop\npapers according to an initial definition of the area of RET which identifies\nthe aspects RE, Testing and coordination effect.",
            "author": [
                "Elizabeth Bjarnason",
                "Mirko Morandini",
                "Markus Borg",
                "Michael Unterkalmsteiner",
                "Michael Felderer",
                "Matthew Staats"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICSE.2015.351",
                "http://arxiv.org/abs/2308.01933v1",
                "http://arxiv.org/pdf/2308.01933v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01286v3",
            "title": "Polynomial-delay Enumeration Kernelizations for Cuts of Bounded Degree",
            "updated": "2023-12-01T07:32:28Z",
            "published": "2023-08-02T17:18:19Z",
            "summary": "Enumeration kernelization was first proposed by Creignou et al. [TOCS 2017]\nand was later refined by Golovach et al. [JCSS 2022] into two different\nvariants: fully-polynomial enumeration kernelization and polynomial-delay\nenumeration kernelization. In this paper, we consider the DEGREE-d-CUT problem\nfrom the perspective of (polynomial-delay) enumeration kenrelization. Given an\nundirected graph G = (V, E), a cut F = E(A, B) is a degree-d-cut of G if every\n$u \\in A$ has at most d neighbors in B and every $v \\in B$ has at most d\nneighbors in A. Checking the existence of a degree-d-cut in a graph is a\nwell-known NP-hard problem and is well-studied in parameterized complexity\n[Algorithmica 2021, IWOCA 2021]. This problem also generalizes a well-studied\nproblem MATCHING CUT (set d = 1) that has been a central problem in the\nliterature of polynomial-delay enumeration kernelization. In this paper, we\nstudy three different enumeration variants of this problem, ENUM DEGREE-d-CUT,\nENUM MIN-DEGREE-d-CUT and ENUM MAX-DEGREE-d-CUT that intends to enumerate all\nthe d-cuts, all the minimal d-cuts and all the maximal degree-d-cuts\nrespectively. We consider various structural parameters of the input and\nprovide polynomial-delay enumeration kernels for ENUM DEGREE-d-CUT and ENUM\nMAX-DEGREE-d-CUT and fully-polynomial enumeration kernels of polynomial size\nfor ENUM MIN-DEGREE-d-CUT.",
            "author": [
                "Diptapriyo Majumdar",
                "M. S. Ramanujan"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01286v3",
                "http://arxiv.org/pdf/2308.01286v3"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "F.2.2; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01328v2",
            "title": "A vision transformer-based framework for knowledge transfer from\n  multi-modal to mono-modal lymphoma subtyping models",
            "updated": "2023-10-30T11:17:48Z",
            "published": "2023-08-02T17:05:36Z",
            "summary": "Determining lymphoma subtypes is a crucial step for better patients treatment\ntargeting to potentially increase their survival chances. In this context, the\nexisting gold standard diagnosis method, which is based on gene expression\ntechnology, is highly expensive and time-consuming making difficult its\naccessibility. Although alternative diagnosis methods based on IHC\n(immunohistochemistry) technologies exist (recommended by the WHO), they still\nsuffer from similar limitations and are less accurate. WSI (Whole Slide Image)\nanalysis by deep learning models showed promising new directions for cancer\ndiagnosis that would be cheaper and faster than existing alternative methods.\nIn this work, we propose a vision transformer-based framework for\ndistinguishing DLBCL (Diffuse Large B-Cell Lymphoma) cancer subtypes from\nhigh-resolution WSIs. To this end, we propose a multi-modal architecture to\ntrain a classifier model from various WSI modalities. We then exploit this\nmodel through a knowledge distillation mechanism for efficiently driving the\nlearning of a mono-modal classifier. Our experimental study conducted on a\ndataset of 157 patients shows the promising performance of our mono-modal\nclassification model, outperforming six recent methods from the\nstate-of-the-art dedicated for cancer classification. Moreover, the power-law\ncurve, estimated on our experimental data, suggest that with more training data\nfrom a reasonable number of additional patients, our model has the potential to\nachieve diagnostic accuracy comparable to that of IHC technologies.",
            "author": [
                "Bilel Guetarni",
                "Feryal Windal",
                "Halim Benhabiles",
                "Marianne Petit",
                "Romain Dubois",
                "Emmanuelle Leteurtre",
                "Dominique Collard"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01328v2",
                "http://arxiv.org/pdf/2308.01328v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01252v2",
            "title": "Stochastic smoothing accelerated gradient method for nonsmooth convex\n  composite optimization",
            "updated": "2023-08-09T18:16:09Z",
            "published": "2023-08-02T16:13:23Z",
            "summary": "We propose a novel stochastic smoothing accelerated gradient (SSAG) method\nfor general constrained nonsmooth convex composite optimization, and analyze\nthe convergence rates. The SSAG method allows various smoothing techniques, and\ncan deal with the nonsmooth term that is not easy to compute its proximal term,\nor that does not own the linear max structure. To the best of our knowledge, it\nis the first stochastic approximation type method with solid convergence result\nto solve the convex composite optimization problem whose nonsmooth term is the\nmaximization of numerous nonlinear convex functions. We prove that the SSAG\nmethod achieves the best-known complexity bounds in terms of the stochastic\nfirst-order oracle ($\\mathcal{SFO}$), using either diminishing smoothing\nparameters or a fixed smoothing parameter. We give two applications of our\nresults to distributionally robust optimization problems. Numerical results on\nthe two applications demonstrate the effectiveness and efficiency of the\nproposed SSAG method.",
            "author": [
                "Ruyu Wang",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01252v2",
                "http://arxiv.org/pdf/2308.01252v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01245v3",
            "title": "VisualPDE: rapid interactive simulations of partial differential\n  equations",
            "updated": "2023-10-16T19:18:18Z",
            "published": "2023-08-02T16:00:35Z",
            "summary": "Computing has revolutionised the study of complex nonlinear systems, both by\nallowing us to solve previously intractable models and through the ability to\nvisualise solutions in different ways. Using ubiquitous computing\ninfrastructure, we provide a means to go one step further in using computers to\nunderstand complex models through instantaneous and interactive exploration.\nThis ubiquitous infrastructure has enormous potential in education, outreach\nand research. Here, we present VisualPDE, an online, interactive solver for a\nbroad class of 1D and 2D partial differential equation (PDE) systems. Abstract\ndynamical systems concepts such as symmetry-breaking instabilities, subcritical\nbifurcations and the role of initial data in multistable nonlinear models\nbecome much more intuitive when you can play with these models yourself, and\nimmediately answer questions about how the system responds to changes in\nparameters, initial conditions, boundary conditions or even spatiotemporal\nforcing. Importantly, VisualPDE is freely available, open source and highly\ncustomisable. We give several examples in teaching, research and knowledge\nexchange, providing high-level discussions of how it may be employed in\ndifferent settings. This includes designing web-based course materials\nstructured around interactive simulations, or easily crafting specific\nsimulations that can be shared with students or collaborators via a simple URL.\nWe envisage VisualPDE becoming an invaluable resource for teaching and research\nin mathematical biology and beyond. We also hope that it inspires other efforts\nto make mathematics more interactive and accessible.",
            "author": [
                "Benjamin J. Walker",
                "Adam K. Townsend",
                "Alexander K. Chudasama",
                "Andrew L. Krause"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s11538-023-01218-4",
                "http://arxiv.org/abs/2308.01245v3",
                "http://arxiv.org/pdf/2308.01245v3"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph",
                "nlin.PS",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01242v1",
            "title": "Balanced-chromatic number and Hadwiger-like conjectures",
            "updated": "2023-08-02T15:57:18Z",
            "published": "2023-08-02T15:57:18Z",
            "summary": "Motivated by different characterizations of planar graphs and the 4-Color\nTheorem, several structural results concerning graphs of high chromatic number\nhave been obtained. Toward strengthening some of these results, we consider the\n\\emph{balanced chromatic number}, $\\chi_b(\\hat{G})$, of a signed graph\n$\\hat{G}$. This is the minimum number of parts into which the vertices of a\nsigned graph can be partitioned so that none of the parts induces a negative\ncycle. This extends the notion of the chromatic number of a graph since\n$\\chi(G)=\\chi_b(\\tilde{G})$, where $\\tilde{G}$ denotes the signed graph\nobtained from~$G$ by replacing each edge with a pair of (parallel) positive and\nnegative edges. We introduce a signed version of Hadwiger's conjecture as\nfollows.\n  Conjecture: If a signed graph $\\hat{G}$ has no negative loop and no\n$\\tilde{K_t}$-minor, then its balanced chromatic number is at most $t-1$.\n  We prove that this conjecture is, in fact, equivalent to Hadwiger's\nconjecture and show its relation to the Odd Hadwiger Conjecture.\n  Motivated by these results, we also consider the relation between\nsubdivisions and balanced chromatic number. We prove that if $(G, \\sigma)$ has\nno negative loop and no $\\tilde{K_t}$-subdivision, then it admits a balanced\n$\\frac{79}{2}t^2$-coloring. This qualitatively generalizes a result of\nKawarabayashi (2013) on totally odd subdivisions.",
            "author": [
                "Andrea Jim\u00e9nez",
                "Jessica Mcdonald",
                "Reza Naserasr",
                "Kathryn Nurse",
                "Daniel A. Quiroz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01242v1",
                "http://arxiv.org/pdf/2308.01242v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01237v3",
            "title": "LSF-IDM: Automotive Intrusion Detection Model with Lightweight\n  Attribution and Semantic Fusion",
            "updated": "2023-09-26T04:06:05Z",
            "published": "2023-08-02T15:48:33Z",
            "summary": "Autonomous vehicles (AVs) are more vulnerable to network attacks due to the\nhigh connectivity and diverse communication modes between vehicles and external\nnetworks. Deep learning-based Intrusion detection, an effective method for\ndetecting network attacks, can provide functional safety as well as a real-time\ncommunication guarantee for vehicles, thereby being widely used for AVs.\nExisting works well for cyber-attacks such as simple-mode but become a higher\nfalse alarm with a resource-limited environment required when the attack is\nconcealed within a contextual feature. In this paper, we present a novel\nautomotive intrusion detection model with lightweight attribution and semantic\nfusion, named LSF-IDM. Our motivation is based on the observation that, when\ninjected the malicious packets to the in-vehicle networks (IVNs), the packet\nlog presents a strict order of context feature because of the periodicity and\nbroadcast nature of the CAN bus. Therefore, this model first captures the\ncontext as the semantic feature of messages by the BERT language framework.\nThereafter, the lightweight model (e.g., BiLSTM) learns the fused feature from\nan input packet's classification and its output distribution in BERT based on\nknowledge distillation. Experiment results demonstrate the effectiveness of our\nmethods in defending against several representative attacks from IVNs. We also\nperform the difference analysis of the proposed method with lightweight models\nand Bert to attain a deeper understanding of how the model balance detection\nperformance and model complexity.",
            "author": [
                "Pengzhou Cheng",
                "Lei Hua",
                "Haobin Jiang",
                "Gongshen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01237v3",
                "http://arxiv.org/pdf/2308.01237v3"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01220v1",
            "title": "Using ScrutinAI for Visual Inspection of DNN Performance in a Medical\n  Use Case",
            "updated": "2023-08-02T15:26:08Z",
            "published": "2023-08-02T15:26:08Z",
            "summary": "Our Visual Analytics (VA) tool ScrutinAI supports human analysts to\ninvestigate interactively model performanceand data sets. Model performance\ndepends on labeling quality to a large extent. In particular in medical\nsettings, generation of high quality labels requires in depth expert knowledge\nand is very costly. Often, data sets are labeled by collecting opinions of\ngroups of experts. We use our VA tool to analyse the influence of label\nvariations between different experts on the model performance. ScrutinAI\nfacilitates to perform a root cause analysis that distinguishes weaknesses of\ndeep neural network (DNN) models caused by varying or missing labeling quality\nfrom true weaknesses. We scrutinize the overall detection of intracranial\nhemorrhages and the more subtle differentiation between subtypes in a publicly\navailable data set.",
            "author": [
                "Rebekka G\u00f6rge",
                "Elena Haedecke",
                "Michael Mock"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01220v1",
                "http://arxiv.org/pdf/2308.01220v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01216v1",
            "title": "Classifying character degree graphs with seven vertices",
            "updated": "2023-08-02T15:21:20Z",
            "published": "2023-08-02T15:21:20Z",
            "summary": "We study here the graphs with seven vertices in an effort to classify which\nof them appear as the prime character degree graphs of finite solvable groups.\nThis classification is complete for the disconnected graphs. Of the 853\nnon-isomorphic connected graphs, we were able to demonstrate that twenty-two\noccur as prime character degree graphs. Two are of diameter three, while the\nremaining are constructed as direct products. Forty-four graphs remain\nunclassified.",
            "author": [
                "Jacob Laubacher",
                "Mark Medwid",
                "Dylan Schuster"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01216v1",
                "http://arxiv.org/pdf/2308.01216v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "math.CO",
                "Primary 20C15, Secondary 05C25, 20D10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01199v1",
            "title": "One Tree to Rule Them All: Poly-Logarithmic Universal Steiner Tree",
            "updated": "2023-08-02T15:07:41Z",
            "published": "2023-08-02T15:07:41Z",
            "summary": "A spanning tree $T$ of graph $G$ is a $\\rho$-approximate universal Steiner\ntree (UST) for root vertex $r$ if, for any subset of vertices $S$ containing\n$r$, the cost of the minimal subgraph of $T$ connecting $S$ is within a $\\rho$\nfactor of the minimum cost tree connecting $S$ in $G$. Busch et al. (FOCS 2012)\nshowed that every graph admits $2^{O(\\sqrt{\\log n})}$-approximate USTs by\nshowing that USTs are equivalent to strong sparse partition hierarchies (up to\npoly-logs). Further, they posed poly-logarithmic USTs and strong sparse\npartition hierarchies as open questions.\n  We settle these open questions by giving polynomial-time algorithms for\ncomputing both $O(\\log ^ 7 n)$-approximate USTs and poly-logarithmic strong\nsparse partition hierarchies. For graphs with constant doubling dimension or\nconstant pathwidth we improve this to $O(\\log n)$-approximate USTs and $O(1)$\nstrong sparse partition hierarchies. Our doubling dimension result is tight up\nto second order terms. We reduce the existence of these objects to the\npreviously studied cluster aggregation problem and what we call dangling nets.",
            "author": [
                "Costas Busch",
                "Da Qi Chen",
                "Arnold Filtser",
                "Daniel Hathcock",
                "D Ellis Hershkowitz",
                "Rajmohan Rajaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01199v1",
                "http://arxiv.org/pdf/2308.01199v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01193v1",
            "title": "Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning\n  Accelerator",
            "updated": "2023-08-02T15:02:35Z",
            "published": "2023-08-02T15:02:35Z",
            "summary": "DNN accelerators have been widely deployed in many scenarios to speed up the\ninference process and reduce the energy consumption. One big concern about the\nusage of the accelerators is the confidentiality of the deployed models: model\ninference execution on the accelerators could leak side-channel information,\nwhich enables an adversary to preciously recover the model details. Such model\nextraction attacks can not only compromise the intellectual property of DNN\nmodels, but also facilitate some adversarial attacks.\n  Although previous works have demonstrated a number of side-channel techniques\nto extract models from DNN accelerators, they are not practical for two\nreasons. (1) They only target simplified accelerator implementations, which\nhave limited practicality in the real world. (2) They require heavy human\nanalysis and domain knowledge. To overcome these limitations, this paper\npresents Mercury, the first automated remote side-channel attack against the\noff-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to model\nthe side-channel extraction process as a sequence-to-sequence problem. The\nadversary can leverage a time-to-digital converter (TDC) to remotely collect\nthe power trace of the target model's inference. Then he uses a learning model\nto automatically recover the architecture details of the victim model from the\npower trace without any prior knowledge. The adversary can further use the\nattention mechanism to localize the leakage points that contribute most to the\nattack. Evaluation results indicate that Mercury can keep the error rate of\nmodel extraction below 1%.",
            "author": [
                "Xiaobei Yan",
                "Xiaoxuan Lou",
                "Guowen Xu",
                "Han Qiu",
                "Shangwei Guo",
                "Chip Hong Chang",
                "Tianwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01193v1",
                "http://arxiv.org/pdf/2308.01193v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01191v3",
            "title": "Towards Understanding the Capability of Large Language Models on Code\n  Clone Detection: A Survey",
            "updated": "2023-08-06T01:40:59Z",
            "published": "2023-08-02T14:56:01Z",
            "summary": "Code cloning, the duplication of code fragments, is common in software\ndevelopment. While some reuse aids productivity, excessive cloning hurts\nmaintainability and introduces bugs. Hence, automatic code clone detection is\nvital. Meanwhile, large language models (LLMs) possess diverse code-related\nknowledge, making them versatile for various software engineering challenges.\nHowever, LLMs' performance in code clone detection is unclear and needs more\nstudy for accurate assessment. In this paper, we provide the first\ncomprehensive evaluation of LLMs for clone detection, covering different clone\ntypes, languages, and prompts. We find advanced LLMs excel in detecting complex\nsemantic clones, surpassing existing methods. Adding intermediate reasoning\nsteps via chain-of-thought prompts noticeably enhances performance.\nAdditionally, representing code as vector embeddings, especially with text\nencoders, effectively aids clone detection.Lastly, the ability of LLMs to\ndetect code clones differs among various programming languages. Our study\nsuggests that LLMs have potential for clone detection due to their language\ncapabilities, offering insights for developing robust LLM-based methods to\nenhance software engineering.",
            "author": [
                "Shihan Dou",
                "Junjie Shan",
                "Haoxiang Jia",
                "Wenhao Deng",
                "Zhiheng Xi",
                "Wei He",
                "Yueming Wu",
                "Tao Gui",
                "Yang Liu",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01191v3",
                "http://arxiv.org/pdf/2308.01191v3"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01189v1",
            "title": "Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical\n  Image Segmentation",
            "updated": "2023-08-02T14:53:43Z",
            "published": "2023-08-02T14:53:43Z",
            "summary": "This paper seeks to address the dense labeling problems where a significant\nfraction of the dataset can be pruned without sacrificing much accuracy. We\nobserve that, on standard medical image segmentation benchmarks, the loss\ngradient norm-based metrics of individual training examples applied in image\nclassification fail to identify the important samples. To address this issue,\nwe propose a data pruning method by taking into consideration the training\ndynamics on target regions using Dynamic Average Dice (DAD) score. To the best\nof our knowledge, we are among the first to address the data importance in\ndense labeling tasks in the field of medical image analysis, making the\nfollowing contributions: (1) investigating the underlying causes with rigorous\nempirical analysis, and (2) determining effective data pruning approach in\ndense labeling problems. Our solution can be used as a strong yet simple\nbaseline to select important examples for medical image segmentation with\ncombined data sources.",
            "author": [
                "Yongkang He",
                "Mingjin Chen",
                "Zhijing Yang",
                "Yongyi Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01189v1",
                "http://arxiv.org/pdf/2308.01189v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01182v1",
            "title": "Stability of Cayley graphs and Schur rings",
            "updated": "2023-08-02T14:47:57Z",
            "published": "2023-08-02T14:47:57Z",
            "summary": "A graph $\\Gamma$ is said to be unstable if for the direct product $\\Gamma\n\\times K_2$, $Aut(\\Gamma \\times K_2)$ is not isomorphic to $Aut(\\Gamma) \\times\n\\mathbb{Z}_2$. In this paper we show that a connected and non-bipartite Cayley\ngraph $Cay(H,S)$ is unstable if and only if the set $S \\times \\{1\\}$ belongs to\na Schur ring over the group $H \\times \\mathbb{Z}_2$ having certain properties.\nThe Schur rings with these properties are characterized if $H$ is an abelian\ngroup of odd order or a cyclic group of twice odd order. As an application, a\nshort proof is given for the result of Witte Morris stating that every\nconnected unstable Cayley graph on an abelian group of odd order has twins\n(Electron.~J.~Combin, 2021). As another application, sufficient and necessary\nconditions are given for a connected and non-bipartite circulant graph of order\n$2p^e$ to be unstable, where $p$ is an odd prime and $e \\ge 1$.",
            "author": [
                "Ademir Hujdurovi\u0107",
                "Istv\u00e1n Kov\u00e1cs"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01182v1",
                "http://arxiv.org/pdf/2308.01182v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C25, 20B25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01180v1",
            "title": "Interpretable End-to-End Driving Model for Implicit Scene Understanding",
            "updated": "2023-08-02T14:43:08Z",
            "published": "2023-08-02T14:43:08Z",
            "summary": "Driving scene understanding is to obtain comprehensive scene information\nthrough the sensor data and provide a basis for downstream tasks, which is\nindispensable for the safety of self-driving vehicles. Specific perception\ntasks, such as object detection and scene graph generation, are commonly used.\nHowever, the results of these tasks are only equivalent to the characterization\nof sampling from high-dimensional scene features, which are not sufficient to\nrepresent the scenario. In addition, the goal of perception tasks is\ninconsistent with human driving that just focuses on what may affect the\nego-trajectory. Therefore, we propose an end-to-end Interpretable Implicit\nDriving Scene Understanding (II-DSU) model to extract implicit high-dimensional\nscene features as scene understanding results guided by a planning module and\nto validate the plausibility of scene understanding using auxiliary perception\ntasks for visualization. Experimental results on CARLA benchmarks show that our\napproach achieves the new state-of-the-art and is able to obtain scene features\nthat embody richer scene information relevant to driving, enabling superior\nperformance of the downstream planning.",
            "author": [
                "Yiyang Sun",
                "Xiaonian Wang",
                "Yangyang Zhang",
                "Jiagui Tang",
                "Xiaqiang Tang",
                "Jing Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01180v1",
                "http://arxiv.org/pdf/2308.01180v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01178v1",
            "title": "Model Selection for Exposure-Mediator Interaction",
            "updated": "2023-08-02T14:39:49Z",
            "published": "2023-08-02T14:39:49Z",
            "summary": "In mediation analysis, the exposure often influences the mediating effect,\ni.e., there is an interaction between exposure and mediator on the dependent\nvariable. When the mediator is high-dimensional, it is necessary to identify\nnon-zero mediators (M) and exposure-by-mediator (X-by-M) interactions. Although\nseveral high-dimensional mediation methods can naturally handle X-by-M\ninteractions, research is scarce in preserving the underlying hierarchical\nstructure between the main effects and the interactions. To fill the knowledge\ngap, we develop the XMInt procedure to select M and X-by-M interactions in the\nhigh-dimensional mediators setting while preserving the hierarchical structure.\nOur proposed method employs a sequential regularization-based forward-selection\napproach to identify the mediators and their hierarchically preserved\ninteraction with exposure. Our numerical experiments showed promising selection\nresults. Further, we applied our method to ADNI morphological data and examined\nthe role of cortical thickness and subcortical volumes on the effect of\namyloid-beta accumulation on cognitive performance, which could be helpful in\nunderstanding the brain compensation mechanism.",
            "author": [
                "Ruiyang Li",
                "Xi Zhu",
                "Seonjoo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01178v1",
                "http://arxiv.org/pdf/2308.01178v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01157v2",
            "title": "LLMs Understand Glass-Box Models, Discover Surprises, and Suggest\n  Repairs",
            "updated": "2023-08-07T17:06:56Z",
            "published": "2023-08-02T13:59:35Z",
            "summary": "We show that large language models (LLMs) are remarkably good at working with\ninterpretable models that decompose complex outcomes into univariate\ngraph-represented components. By adopting a hierarchical approach to reasoning,\nLLMs can provide comprehensive model-level summaries without ever requiring the\nentire model to fit in context. This approach enables LLMs to apply their\nextensive background knowledge to automate common tasks in data science such as\ndetecting anomalies that contradict prior knowledge, describing potential\nreasons for the anomalies, and suggesting repairs that would remove the\nanomalies. We use multiple examples in healthcare to demonstrate the utility of\nthese new capabilities of LLMs, with particular emphasis on Generalized\nAdditive Models (GAMs). Finally, we present the package $\\texttt{TalkToEBM}$ as\nan open-source LLM-GAM interface.",
            "author": [
                "Benjamin J. Lengerich",
                "Sebastian Bordt",
                "Harsha Nori",
                "Mark E. Nunnally",
                "Yin Aphinyanaphongs",
                "Manolis Kellis",
                "Rich Caruana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01157v2",
                "http://arxiv.org/pdf/2308.01157v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01137v1",
            "title": "Multi-task learning for classification, segmentation, reconstruction,\n  and detection on chest CT scans",
            "updated": "2023-08-02T13:28:44Z",
            "published": "2023-08-02T13:28:44Z",
            "summary": "Lung cancer and covid-19 have one of the highest morbidity and mortality\nrates in the world. For physicians, the identification of lesions is difficult\nin the early stages of the disease and time-consuming. Therefore, multi-task\nlearning is an approach to extracting important features, such as lesions, from\nsmall amounts of medical data because it learns to generalize better. We\npropose a novel multi-task framework for classification, segmentation,\nreconstruction, and detection. To the best of our knowledge, we are the first\nones who added detection to the multi-task solution. Additionally, we checked\nthe possibility of using two different backbones and different loss functions\nin the segmentation task.",
            "author": [
                "Weronika Hryniewska-Guzik",
                "Maria K\u0119dzierska",
                "Przemys\u0142aw Biecek"
            ],
            "link": [
                "http://dx.doi.org/10.34658/9788366741928.40",
                "http://arxiv.org/abs/2308.01137v1",
                "http://arxiv.org/pdf/2308.01137v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01136v1",
            "title": "Leveraging Expert Models for Training Deep Neural Networks in Scarce\n  Data Domains: Application to Offline Handwritten Signature Verification",
            "updated": "2023-08-02T13:28:12Z",
            "published": "2023-08-02T13:28:12Z",
            "summary": "This paper introduces a novel approach to leverage the knowledge of existing\nexpert models for training new Convolutional Neural Networks, on domains where\ntask-specific data are limited or unavailable. The presented scheme is applied\nin offline handwritten signature verification (OffSV) which, akin to other\nbiometric applications, suffers from inherent data limitations due to\nregulatory restrictions. The proposed Student-Teacher (S-T) configuration\nutilizes feature-based knowledge distillation (FKD), combining graph-based\nsimilarity for local activations with global similarity measures to supervise\nstudent's training, using only handwritten text data. Remarkably, the models\ntrained using this technique exhibit comparable, if not superior, performance\nto the teacher model across three popular signature datasets. More importantly,\nthese results are attained without employing any signatures during the feature\nextraction training process. This study demonstrates the efficacy of leveraging\nexisting expert models to overcome data scarcity challenges in OffSV and\npotentially other related domains.",
            "author": [
                "Dimitrios Tsourounis",
                "Ilias Theodorakopoulos",
                "Elias N. Zois",
                "George Economou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01136v1",
                "http://arxiv.org/pdf/2308.01136v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01127v1",
            "title": "DiffusePast: Diffusion-based Generative Replay for Class Incremental\n  Semantic Segmentation",
            "updated": "2023-08-02T13:13:18Z",
            "published": "2023-08-02T13:13:18Z",
            "summary": "The Class Incremental Semantic Segmentation (CISS) extends the traditional\nsegmentation task by incrementally learning newly added classes. Previous work\nhas introduced generative replay, which involves replaying old class samples\ngenerated from a pre-trained GAN, to address the issues of catastrophic\nforgetting and privacy concerns. However, the generated images lack semantic\nprecision and exhibit out-of-distribution characteristics, resulting in\ninaccurate masks that further degrade the segmentation performance. To tackle\nthese challenges, we propose DiffusePast, a novel framework featuring a\ndiffusion-based generative replay module that generates semantically accurate\nimages with more reliable masks guided by different instructions (e.g., text\nprompts or edge maps). Specifically, DiffusePast introduces a dual-generator\nparadigm, which focuses on generating old class images that align with the\ndistribution of downstream datasets while preserving the structure and layout\nof the original images, enabling more precise masks. To adapt to the novel\nvisual concepts of newly added classes continuously, we incorporate class-wise\ntoken embedding when updating the dual-generator. Moreover, we assign adequate\npseudo-labels of old classes to the background pixels in the new step images,\nfurther mitigating the forgetting of previously learned knowledge. Through\ncomprehensive experiments, our method demonstrates competitive performance\nacross mainstream benchmarks, striking a better balance between the performance\nof old and novel classes.",
            "author": [
                "Jingfan Chen",
                "Yuxi Wang",
                "Pengfei Wang",
                "Xiao Chen",
                "Zhaoxiang Zhang",
                "Zhen Lei",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01127v1",
                "http://arxiv.org/pdf/2308.01127v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03780v1",
            "title": "Exploring IoT for real-time CO2 monitoring and analysis",
            "updated": "2023-08-02T13:10:34Z",
            "published": "2023-08-02T13:10:34Z",
            "summary": "As a part of this project, we have developed an IoT-based instrument\nutilizing the NODE MCU-ESP8266 module, MQ135 gas sensor, and DHT-11 sensor for\nmeasuring CO$_2$ levels in parts per million (ppm), temperature, and humidity.\nThe escalating CO$_2$ levels worldwide necessitate constant monitoring and\nanalysis to comprehend the implications for human health, safety, energy\nefficiency, and environmental well-being. Thus, an efficient and cost-effective\nsolution is imperative to measure and transmit data for statistical analysis\nand storage. The instrument offers real-time monitoring, enabling a\ncomprehensive understanding of indoor environmental conditions. By providing\nvaluable insights, it facilitates the implementation of measures to ensure\nhealth and safety, optimize energy efficiency, and promote effective\nenvironmental monitoring. This scientific endeavor aims to contribute to the\ngrowing body of knowledge surrounding CO$_2$ levels, temperature, and humidity,\nfostering sustainable practices and informed decision-making",
            "author": [
                "Abhiroop Sarkar",
                "Debayan Ghosh",
                "Kinshuk Ganguly",
                "Snehal Ghosh",
                "Subhajit Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03780v1",
                "http://arxiv.org/pdf/2308.03780v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.CY",
                "eess.SP",
                "C.2.6; J.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01126v1",
            "title": "Beyond Generic: Enhancing Image Captioning with Real-World Knowledge\n  using Vision-Language Pre-Training Model",
            "updated": "2023-08-02T13:09:57Z",
            "published": "2023-08-02T13:09:57Z",
            "summary": "Current captioning approaches tend to generate correct but \"generic\"\ndescriptions that lack real-world knowledge, e.g., named entities and\ncontextual information. Considering that Vision-Language Pre-Training (VLP)\nmodels master massive such knowledge from large-scale web-harvested data, it is\npromising to utilize the generalizability of VLP models to incorporate\nknowledge into image descriptions. However, using VLP models faces challenges:\nzero-shot inference suffers from knowledge hallucination that leads to\nlow-quality descriptions, but the generic bias in downstream task fine-tuning\nhinders the VLP model from expressing knowledge. To address these concerns, we\npropose a simple yet effective method called Knowledge-guided Replay\n(K-Replay), which enables the retention of pre-training knowledge during\nfine-tuning. Our approach consists of two parts: (1) a knowledge prediction\ntask on automatically collected replay exemplars to continuously awaken the VLP\nmodel's memory about knowledge, thus preventing the model from collapsing into\nthe generic pattern; (2) a knowledge distillation constraint to improve the\nfaithfulness of generated descriptions hence alleviating the knowledge\nhallucination. To evaluate knowledge-enhanced descriptions, we construct a\nnovel captioning benchmark KnowCap, containing knowledge of landmarks, famous\nbrands, special foods and movie characters. Experimental results show that our\napproach effectively incorporates knowledge into descriptions, outperforming\nstrong VLP baseline by 20.9 points (78.7->99.6) in CIDEr score and 20.5\npercentage points (34.0%->54.5%) in knowledge recognition accuracy. Our code\nand data is available at https://github.com/njucckevin/KnowCap.",
            "author": [
                "Kanzhi Cheng",
                "Wenpo Song",
                "Zheng Ma",
                "Wenhao Zhu",
                "Zixuan Zhu",
                "Jianbing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01126v1",
                "http://arxiv.org/pdf/2308.01126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01125v1",
            "title": "Stereo Visual Odometry with Deep Learning-Based Point and Line Feature\n  Matching using an Attention Graph Neural Network",
            "updated": "2023-08-02T13:09:12Z",
            "published": "2023-08-02T13:09:12Z",
            "summary": "Robust feature matching forms the backbone for most Visual Simultaneous\nLocalization and Mapping (vSLAM), visual odometry, 3D reconstruction, and\nStructure from Motion (SfM) algorithms. However, recovering feature matches\nfrom texture-poor scenes is a major challenge and still remains an open area of\nresearch. In this paper, we present a Stereo Visual Odometry (StereoVO)\ntechnique based on point and line features which uses a novel feature-matching\nmechanism based on an Attention Graph Neural Network that is designed to\nperform well even under adverse weather conditions such as fog, haze, rain, and\nsnow, and dynamic lighting conditions such as nighttime illumination and glare\nscenarios. We perform experiments on multiple real and synthetic datasets to\nvalidate the ability of our method to perform StereoVO under low visibility\nweather and lighting conditions through robust point and line matches. The\nresults demonstrate that our method achieves more line feature matches than\nstate-of-the-art line matching algorithms, which when complemented with point\nfeature matches perform consistently well in adverse weather and dynamic\nlighting conditions.",
            "author": [
                "Shenbagaraj Kannapiran",
                "Nalin Bendapudi",
                "Ming-Yuan Yu",
                "Devarth Parikh",
                "Spring Berman",
                "Ankit Vora",
                "Gaurav Pandey"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01125v1",
                "http://arxiv.org/pdf/2308.01125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01124v1",
            "title": "Some notes on the trapezoidal rule for Fourier type integrals",
            "updated": "2023-08-02T13:06:56Z",
            "published": "2023-08-02T13:06:56Z",
            "summary": "This paper deals with the error analysis of the trapezoidal rule for the\ncomputation of Fourier type integrals, based on two double exponential\ntransformations. The theory allows to construct algorithms in which the\nsteplength and the number of nodes can be a priori selected. The analysis is\nalso used to design an automatic integrator that can be employed without any\nknowledge of the function involved in the problem. Several numerical examples,\nwhich confirm the reliability of this strategy, are reported.",
            "author": [
                "Eleonora Denich",
                "Paolo Novati"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01124v1",
                "http://arxiv.org/pdf/2308.01124v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01122v1",
            "title": "Measure Data for a General Class of Nonlinear Elliptic Problems",
            "updated": "2023-08-02T13:05:55Z",
            "published": "2023-08-02T13:05:55Z",
            "summary": "We consider nonlinear elliptic inclusion having a measure in the right-hand\nside of the type $\\beta(u)-div a(x,Du)\\ni \\mu$ in $\\Omega$ a bounded domain in\n$\\mathbb{R}^{N},$ with $\\beta$ is a maximal monotone graph in $\\mathbb{R}^2$\nand $a(x,Du)$ is a Leray-Lions type operator. We study a suitable notion of\nsolution for this kind of problem. The functional setting involves anisotropic\nSobolev spaces.",
            "author": [
                "Mohammed El Ansari",
                "Youssef Akdim",
                "Soumia Lalaoui Rhali"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01122v1",
                "http://arxiv.org/pdf/2308.01122v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35J60, 35A01"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01120v1",
            "title": "A continuous random operator associated with the Vertex Reinforced Jump\n  Process on the circle and the real line",
            "updated": "2023-08-02T12:59:44Z",
            "published": "2023-08-02T12:59:44Z",
            "summary": "In this paper, we focus on the scaling-limit of the random potential $\\beta$\nassociated with the Vertex Reinforced Jump Process (VRJP) on one-dimensional\ngraphs. Moreover, we give a few applications of this scaling-limit. By\nconsidering a relevant scaling of $\\beta$, we contruct a continuous-space\nversion of the random Schr{\\\"o}dinger operator $H_\\beta$ which is associated\nwith the VRJP on circles and on R. We also compute the integrated density of\nstates of this operator on R which has a remarkably simple form. Moreover, by\nmeans of the same scaling, we obtain a new proof of the Matsumoto-Yor\nproperties concerning the geometric Brownian motion which were proved in\n[MY01]. This new proof is based on some fundamental properties of the random\npotential $\\beta$. We use also the scaling-limit of $\\beta$ in order to prove\nnew identities in law involving exponential functionals of the Brownian motion\nwhich generalize the Dufresne identity.",
            "author": [
                "V Rapenne",
                "C Sabot"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01120v1",
                "http://arxiv.org/pdf/2308.01120v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01109v1",
            "title": "Signed double Roman domination on cubic graphs",
            "updated": "2023-08-02T12:37:23Z",
            "published": "2023-08-02T12:37:23Z",
            "summary": "The signed double Roman domination problem is a combinatorial optimization\nproblem on a graph asking to assign a label from $\\{\\pm{}1,2,3\\}$ to each\nvertex feasibly, such that the total sum of assigned labels is minimized. Here\nfeasibility is given whenever (i) vertices labeled $\\pm{}1$ have at least one\nneighbor with label in $\\{2,3\\}$; (ii) each vertex labeled $-1$ has one\n$3$-labeled neighbor or at least two $2$-labeled neighbors; and (iii) the sum\nof labels over the closed neighborhood of any vertex is positive. The\ncumulative weight of an optimal labeling is called signed double Roman\ndomination number (SDRDN). In this work, we first consider the problem on\ngeneral cubic graphs of order $n$ for which we present a sharp $n/2+\\Theta(1)$\nlower bound for the SDRDN by means of the discharging method. Moreover, we\nderive a new best upper bound. Observing that we are often able to minimize the\nSDRDN over the class of cubic graphs of a fixed order, we then study in this\ncontext generalized Petersen graphs for independent interest, for which we\npropose a constraint programming guided proof. We then use these insights to\ndetermine the SDRDNs of subcubic $2\\times m$ grid graphs, among other results.",
            "author": [
                "Enrico Iurlano",
                "Tatjana Zec",
                "Marko Djukanovic",
                "G\u00fcnther R. Raidl"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01109v1",
                "http://arxiv.org/pdf/2308.01109v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO",
                "05C78, 05C35, 90C27"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01105v1",
            "title": "Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring:\n  A Bosch Case",
            "updated": "2023-08-02T12:22:35Z",
            "published": "2023-08-02T12:22:35Z",
            "summary": "Recently there has been a series of studies in knowledge graph embedding\n(KGE), which attempts to learn the embeddings of the entities and relations as\nnumerical vectors and mathematical mappings via machine learning (ML). However,\nthere has been limited research that applies KGE for industrial problems in\nmanufacturing. This paper investigates whether and to what extent KGE can be\nused for an important problem: quality monitoring for welding in manufacturing\nindustry, which is an impactful process accounting for production of millions\nof cars annually. The work is in line with Bosch research of data-driven\nsolutions that intends to replace the traditional way of destroying cars, which\nis extremely costly and produces waste. The paper tackles two very challenging\nquestions simultaneously: how large the welding spot diameter is; and to which\ncar body the welded spot belongs to. The problem setting is difficult for\ntraditional ML because there exist a high number of car bodies that should be\nassigned as class labels. We formulate the problem as link prediction, and\nexperimented popular KGE methods on real industry data, with consideration of\nliterals. Our results reveal both limitations and promising aspects of adapted\nKGE methods.",
            "author": [
                "Zhipeng Tan",
                "Baifan Zhou",
                "Zhuoxun Zheng",
                "Ognjen Savkovic",
                "Ziqi Huang",
                "Irlan-Grangel Gonzalez",
                "Ahmet Soylu",
                "Evgeny Kharlamov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01105v1",
                "http://arxiv.org/pdf/2308.01105v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2309.16685v1",
            "title": "Target-aware Variational Auto-encoders for Ligand Generation with\n  Multimodal Protein Representation Learning",
            "updated": "2023-08-02T12:08:17Z",
            "published": "2023-08-02T12:08:17Z",
            "summary": "Without knowledge of specific pockets, generating ligands based on the global\nstructure of a protein target plays a crucial role in drug discovery as it\nhelps reduce the search space for potential drug-like candidates in the\npipeline. However, contemporary methods require optimizing tailored networks\nfor each protein, which is arduous and costly. To address this issue, we\nintroduce TargetVAE, a target-aware variational auto-encoder that generates\nligands with high binding affinities to arbitrary protein targets, guided by a\nnovel multimodal deep neural network built based on graph Transformers as the\nprior for the generative model. This is the first effort to unify different\nrepresentations of proteins (e.g., sequence of amino-acids, 3D structure) into\na single model that we name as Protein Multimodal Network (PMN). Our multimodal\narchitecture learns from the entire protein structures and is able to capture\ntheir sequential, topological and geometrical information. We showcase the\nsuperiority of our approach by conducting extensive experiments and\nevaluations, including the assessment of generative model quality, ligand\ngeneration for unseen targets, docking score computation, and binding affinity\nprediction. Empirical results demonstrate the promising performance of our\nproposed approach. Our software package is publicly available at\nhttps://github.com/HySonLab/Ligand_Generation",
            "author": [
                "Nhat Khang Ngo",
                "Truong Son Hy"
            ],
            "link": [
                "http://arxiv.org/abs/2309.16685v1",
                "http://arxiv.org/pdf/2309.16685v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01098v3",
            "title": "Towards Better Query Classification with Multi-Expert Knowledge\n  Condensation in JD Ads Search",
            "updated": "2023-11-19T14:42:39Z",
            "published": "2023-08-02T12:05:01Z",
            "summary": "Search query classification, as an effective way to understand user intents,\nis of great importance in real-world online ads systems. To ensure a lower\nlatency, a shallow model (e.g. FastText) is widely used for efficient online\ninference. However, the representation ability of the FastText model is\ninsufficient, resulting in poor classification performance, especially on some\nlow-frequency queries and tailed categories. Using a deeper and more complex\nmodel (e.g. BERT) is an effective solution, but it will cause a higher online\ninference latency and more expensive computing costs. Thus, how to juggle both\ninference efficiency and classification performance is obviously of great\npractical importance. To overcome this challenge, in this paper, we propose\nknowledge condensation (KC), a simple yet effective knowledge distillation\nframework to boost the classification performance of the online FastText model\nunder strict low latency constraints. Specifically, we propose to train an\noffline BERT model to retrieve more potentially relevant data. Benefiting from\nits powerful semantic representation, more relevant labels not exposed in the\nhistorical data will be added into the training set for better FastText model\ntraining. Moreover, a novel distribution-diverse multi-expert learning strategy\nis proposed to further improve the mining ability of relevant data. By training\nmultiple BERT models from different data distributions, it can respectively\nperform better at high, middle, and low-frequency search queries. The model\nensemble from multi-distribution makes its retrieval ability more powerful. We\nhave deployed two versions of this framework in JD search, and both offline\nexperiments and online A/B testing from multiple datasets have validated the\neffectiveness of the proposed approach.",
            "author": [
                "Kun-Peng Ning",
                "Ming Pang",
                "Zheng Fang",
                "Xue Jiang",
                "Xi-Wei Zhao",
                "Chang-Ping Peng",
                "Zhan-Gang Lin",
                "Jing-He Hu",
                "Jing-Ping Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01098v3",
                "http://arxiv.org/pdf/2308.01098v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01097v3",
            "title": "Spatio-Temporal Branching for Motion Prediction using Motion Increments",
            "updated": "2023-08-11T05:30:10Z",
            "published": "2023-08-02T12:04:28Z",
            "summary": "Human motion prediction (HMP) has emerged as a popular research topic due to\nits diverse applications, but it remains a challenging task due to the\nstochastic and aperiodic nature of future poses. Traditional methods rely on\nhand-crafted features and machine learning techniques, which often struggle to\nmodel the complex dynamics of human motion. Recent deep learning-based methods\nhave achieved success by learning spatio-temporal representations of motion,\nbut these models often overlook the reliability of motion data. Additionally,\nthe temporal and spatial dependencies of skeleton nodes are distinct. The\ntemporal relationship captures motion information over time, while the spatial\nrelationship describes body structure and the relationships between different\nnodes. In this paper, we propose a novel spatio-temporal branching network\nusing incremental information for HMP, which decouples the learning of\ntemporal-domain and spatial-domain features, extracts more motion information,\nand achieves complementary cross-domain knowledge learning through knowledge\ndistillation. Our approach effectively reduces noise interference and provides\nmore expressive information for characterizing motion by separately extracting\ntemporal and spatial features. We evaluate our approach on standard HMP\nbenchmarks and outperform state-of-the-art methods in terms of prediction\naccuracy.",
            "author": [
                "Jiexin Wang",
                "Yujie Zhou",
                "Wenwen Qiang",
                "Ying Ba",
                "Bing Su",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612330",
                "http://arxiv.org/abs/2308.01097v3",
                "http://arxiv.org/pdf/2308.01097v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01095v2",
            "title": "AutoPoster: A Highly Automatic and Content-aware Design System for\n  Advertising Poster Generation",
            "updated": "2023-08-23T06:26:56Z",
            "published": "2023-08-02T11:58:43Z",
            "summary": "Advertising posters, a form of information presentation, combine visual and\nlinguistic modalities. Creating a poster involves multiple steps and\nnecessitates design experience and creativity. This paper introduces\nAutoPoster, a highly automatic and content-aware system for generating\nadvertising posters. With only product images and titles as inputs, AutoPoster\ncan automatically produce posters of varying sizes through four key stages:\nimage cleaning and retargeting, layout generation, tagline generation, and\nstyle attribute prediction. To ensure visual harmony of posters, two\ncontent-aware models are incorporated for layout and tagline generation.\nMoreover, we propose a novel multi-task Style Attribute Predictor (SAP) to\njointly predict visual style attributes. Meanwhile, to our knowledge, we\npropose the first poster generation dataset that includes visual attribute\nannotations for over 76k posters. Qualitative and quantitative outcomes from\nuser studies and experiments substantiate the efficacy of our system and the\naesthetic superiority of the generated posters compared to other poster\ngeneration methods.",
            "author": [
                "Jinpeng Lin",
                "Min Zhou",
                "Ye Ma",
                "Yifan Gao",
                "Chenxi Fei",
                "Yangjian Chen",
                "Zhang Yu",
                "Tiezheng Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01095v2",
                "http://arxiv.org/pdf/2308.01095v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01086v1",
            "title": "Homography Estimation in Complex Topological Scenes",
            "updated": "2023-08-02T11:31:43Z",
            "published": "2023-08-02T11:31:43Z",
            "summary": "Surveillance videos and images are used for a broad set of applications,\nranging from traffic analysis to crime detection. Extrinsic camera calibration\ndata is important for most analysis applications. However, security cameras are\nsusceptible to environmental conditions and small camera movements, resulting\nin a need for an automated re-calibration method that can account for these\nvarying conditions. In this paper, we present an automated camera-calibration\nprocess leveraging a dictionary-based approach that does not require prior\nknowledge on any camera settings. The method consists of a custom\nimplementation of a Spatial Transformer Network (STN) and a novel topological\nloss function. Experiments reveal that the proposed method improves the IoU\nmetric by up to 12% w.r.t. a state-of-the-art model across five synthetic\ndatasets and the World Cup 2014 dataset.",
            "author": [
                "Giacomo D'Amicantonio",
                "Egor Bondarau",
                "Peter H. N. De With"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01086v1",
                "http://arxiv.org/pdf/2308.01086v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01080v1",
            "title": "Leveraging Few-Shot Data Augmentation and Waterfall Prompting for\n  Response Generation",
            "updated": "2023-08-02T11:04:27Z",
            "published": "2023-08-02T11:04:27Z",
            "summary": "This paper discusses our approaches for task-oriented conversational\nmodelling using subjective knowledge, with a particular emphasis on response\ngeneration. Our methodology was shaped by an extensive data analysis that\nevaluated key factors such as response length, sentiment, and dialogue acts\npresent in the provided dataset. We used few-shot learning to augment the data\nwith newly generated subjective knowledge items and present three approaches\nfor DSTC11: (1) task-specific model exploration, (2) incorporation of the most\nfrequent question into all generated responses, and (3) a waterfall prompting\ntechnique using a combination of both GPT-3 and ChatGPT.",
            "author": [
                "Lea Krause",
                "Selene B\u00e1ez Santamar\u00eda",
                "Michiel van der Meer",
                "Urja Khurana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01080v1",
                "http://arxiv.org/pdf/2308.01080v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01071v1",
            "title": "Automatic Feature Engineering for Time Series Classification: Evaluation\n  and Discussion",
            "updated": "2023-08-02T10:46:42Z",
            "published": "2023-08-02T10:46:42Z",
            "summary": "Time Series Classification (TSC) has received much attention in the past two\ndecades and is still a crucial and challenging problem in data science and\nknowledge engineering. Indeed, along with the increasing availability of time\nseries data, many TSC algorithms have been suggested by the research community\nin the literature. Besides state-of-the-art methods based on similarity\nmeasures, intervals, shapelets, dictionaries, deep learning methods or hybrid\nensemble methods, several tools for extracting unsupervised informative summary\nstatistics, aka features, from time series have been designed in the recent\nyears. Originally designed for descriptive analysis and visualization of time\nseries with informative and interpretable features, very few of these feature\nengineering tools have been benchmarked for TSC problems and compared with\nstate-of-the-art TSC algorithms in terms of predictive performance. In this\narticle, we aim at filling this gap and propose a simple TSC process to\nevaluate the potential predictive performance of the feature sets obtained with\nexisting feature engineering tools. Thus, we present an empirical study of 11\nfeature engineering tools branched with 9 supervised classifiers over 112 time\nseries data sets. The analysis of the results of more than 10000 learning\nexperiments indicate that feature-based methods perform as accurately as\ncurrent state-of-the-art TSC algorithms, and thus should rightfully be\nconsidered further in the TSC literature.",
            "author": [
                "Aur\u00e9lien Renault",
                "Alexis Bondu",
                "Vincent Lemaire",
                "Dominique Gay"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN54540.2023.10191074",
                "http://arxiv.org/abs/2308.01071v1",
                "http://arxiv.org/pdf/2308.01071v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02556v1",
            "title": "Industrial Memories: Exploring the Findings of Government Inquiries with\n  Neural Word Embedding and Machine Learning",
            "updated": "2023-08-02T10:39:11Z",
            "published": "2023-08-02T10:39:11Z",
            "summary": "We present a text mining system to support the exploration of large volumes\nof text detailing the findings of government inquiries. Despite their\nhistorical significance and potential societal impact, key findings of\ninquiries are often hidden within lengthy documents and remain inaccessible to\nthe general public. We transform the findings of the Irish government's inquiry\ninto industrial schools and through the use of word embedding, text\nclassification and visualisation, present an interactive web-based platform\nthat enables the exploration of the text to uncover new historical insights.",
            "author": [
                "Susan Leavy",
                "Emilie Pine",
                "Mark T Keane"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-030-10997-4_52",
                "http://arxiv.org/abs/2308.02556v1",
                "http://arxiv.org/pdf/2308.02556v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01063v1",
            "title": "Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced\n  Unsupervised Approach",
            "updated": "2023-08-02T10:22:04Z",
            "published": "2023-08-02T10:22:04Z",
            "summary": "Graph anomaly detection (GAD) has achieved success and has been widely\napplied in various domains, such as fraud detection, cybersecurity, finance\nsecurity, and biochemistry. However, existing graph anomaly detection\nalgorithms focus on distinguishing individual entities (nodes or graphs) and\noverlook the possibility of anomalous groups within the graph. To address this\nlimitation, this paper introduces a novel unsupervised framework for a new task\ncalled Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework\nfirst employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that\nbelong to potential anomaly groups by capturing long-range inconsistencies.\nSubsequently, group sampling is employed to sample candidate groups, which are\nthen fed into the proposed Topology Pattern-based Graph Contrastive Learning\n(TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to\ngenerate embeddings for each candidate group and thus distinct anomaly groups.\nThe experimental results on both real-world and synthetic datasets demonstrate\nthat the proposed framework shows superior performance in identifying and\nlocalizing anomaly groups, highlighting it as a promising solution for Gr-GAD.\nDatasets and codes of the proposed framework are at the github repository\nhttps://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.",
            "author": [
                "Xing Ai",
                "Jialong Zhou",
                "Yulin Zhu",
                "Gaolei Li",
                "Tomasz P. Michalak",
                "Xiapu Luo",
                "Kai Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01063v1",
                "http://arxiv.org/pdf/2308.01063v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01056v1",
            "title": "Impact of the noise knowledge uncertainty for the science exploitation\n  of cosmological and astrophysical stochastic gravitational wave background\n  with LISA",
            "updated": "2023-08-02T10:07:16Z",
            "published": "2023-08-02T10:07:16Z",
            "summary": "This paper investigates the impact of a lack of knowledge of the instrumental\nnoise on the characterisation of stochastic gravitational wave backgrounds with\nthe Laser Interferometer Space Antenna (LISA). We focus on constraints on\nmodelled backgrounds that represent the possible backgrounds from the mergers\nof binary black holes of stellar origin, from primordial black hole generation,\nfrom non-standard inflation, and from sound wave production during cosmic fluid\nphase transitions. We use splines to model generic, slowly varying,\nuncertainties in the auto and cross-spectral densities of the LISA time delay\ninterferometry channels. We find that allowing for noise knowledge uncertainty\nin this way leads to one to two orders of magnitude degradation in our ability\nto constrain stochastic backgrounds, and a corresponding increase in the\nbackground energy density required for a confident detection. We also find that\nto avoid this degradation, the LISA noise would have to be known at the\nsub-percent level, which is unlikely to be achievable in practice.",
            "author": [
                "Martina Muratore",
                "Jonathan Gair",
                "Lorenzo Speri"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01056v1",
                "http://arxiv.org/pdf/2308.01056v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01030v1",
            "title": "Three Factors to Improve Out-of-Distribution Detection",
            "updated": "2023-08-02T09:27:11Z",
            "published": "2023-08-02T09:27:11Z",
            "summary": "In the problem of out-of-distribution (OOD) detection, the usage of auxiliary\ndata as outlier data for fine-tuning has demonstrated encouraging performance.\nHowever, previous methods have suffered from a trade-off between classification\naccuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve\nthis trade-off, we make three contributions: (i) Incorporating a self-knowledge\ndistillation loss can enhance the accuracy of the network; (ii) Sampling\nsemi-hard outlier data for training can improve OOD detection performance with\nminimal impact on accuracy; (iii) The introduction of our novel supervised\ncontrastive learning can simultaneously improve OOD detection performance and\nthe accuracy of the network. By incorporating all three factors, our approach\nenhances both accuracy and OOD detection performance by addressing the\ntrade-off between classification and OOD detection. Our method achieves\nimprovements over previous approaches in both performance metrics.",
            "author": [
                "Hyunjun Choi",
                "JaeHo Chung",
                "Hawook Jeong",
                "Jin Young Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01030v1",
                "http://arxiv.org/pdf/2308.01030v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01006v4",
            "title": "FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of\n  Autonomous Driving",
            "updated": "2023-08-14T08:28:32Z",
            "published": "2023-08-02T08:29:44Z",
            "summary": "Building a multi-modality multi-task neural network toward accurate and\nrobust performance is a de-facto standard in perception task of autonomous\ndriving. However, leveraging such data from multiple sensors to jointly\noptimize the prediction and planning tasks remains largely unexplored. In this\npaper, we present FusionAD, to the best of our knowledge, the first unified\nframework that fuse the information from two most critical sensors, camera and\nLiDAR, goes beyond perception task. Concretely, we first build a transformer\nbased multi-modality fusion network to effectively produce fusion based\nfeatures. In constrast to camera-based end-to-end method UniAD, we then\nestablish a fusion aided modality-aware prediction and status-aware planning\nmodules, dubbed FMSPnP that take advantages of multi-modality features. We\nconduct extensive experiments on commonly used benchmark nuScenes dataset, our\nFusionAD achieves state-of-the-art performance and surpassing baselines on\naverage 15% on perception tasks like detection and tracking, 10% on occupancy\nprediction accuracy, reducing prediction error from 0.708 to 0.389 in ADE score\nand reduces the collision rate from 0.31% to only 0.12%.",
            "author": [
                "Tengju Ye",
                "Wei Jing",
                "Chunyong Hu",
                "Shikun Huang",
                "Lingping Gao",
                "Fangzhen Li",
                "Jingke Wang",
                "Ke Guo",
                "Wencong Xiao",
                "Weibo Mao",
                "Hang Zheng",
                "Kun Li",
                "Junbo Chen",
                "Kaicheng Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01006v4",
                "http://arxiv.org/pdf/2308.01006v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00989v1",
            "title": "Wasserstein Diversity-Enriched Regularizer for Hierarchical\n  Reinforcement Learning",
            "updated": "2023-08-02T07:45:24Z",
            "published": "2023-08-02T07:45:24Z",
            "summary": "Hierarchical reinforcement learning composites subpolicies in different\nhierarchies to accomplish complex tasks.Automated subpolicies discovery, which\ndoes not depend on domain knowledge, is a promising approach to generating\nsubpolicies.However, the degradation problem is a challenge that existing\nmethods can hardly deal with due to the lack of consideration of diversity or\nthe employment of weak regularizers. In this paper, we propose a novel\ntask-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer\n(WDER), which enlarges the diversity of subpolicies by maximizing the\nWasserstein distances among action distributions. The proposed WDER can be\neasily incorporated into the loss function of existing methods to boost their\nperformance further.Experimental results demonstrate that our WDER improves\nperformance and sample efficiency in comparison with prior work without\nmodifying hyperparameters, which indicates the applicability and robustness of\nthe WDER.",
            "author": [
                "Haorui Li",
                "Jiaqi Liang",
                "Linjing Li",
                "Daniel Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00989v1",
                "http://arxiv.org/pdf/2308.00989v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00985v1",
            "title": "Evaluate and Guard the Wisdom of Crowds: Zero Knowledge Proofs for\n  Crowdsourcing Truth Inference",
            "updated": "2023-08-02T07:36:40Z",
            "published": "2023-08-02T07:36:40Z",
            "summary": "Due to the risks of correctness and security in outsourced cloud computing,\nwe consider a new paradigm called crowdsourcing: distribute tasks, receive\nanswers and aggregate the results from multiple entities. Through this\napproach, we can aggregate the wisdom of the crowd to complete tasks, ensuring\nthe accuracy of task completion while reducing the risks posed by the malicious\nacts of a single entity. However, the ensuing question is, how can we ensure\nthat the aggregator has done its work honestly and each contributor's work has\nbeen evaluated fairly?\n  In this paper, we propose a new scheme called $\\mathsf{zkTI}$. This scheme\nensures that the aggregator has honestly completed the aggregation and each\ndata source is fairly evaluated. We combine a cryptographic primitive called\n\\textit{zero-knowledge proof} with a class of \\textit{truth inference\nalgorithms} which is widely studied in AI/ML scenarios. Under this scheme,\nvarious complex outsourced tasks can be solved with efficiency and accuracy. To\nbuild our scheme, a novel method to prove the precise computation of\nfloating-point numbers is proposed, which is nearly optimal and well-compatible\nwith existing argument systems. This may become an independent point of\ninterest. Thus our work can prove the process of aggregation and inference\nwithout loss of precision. We fully implement and evaluate our ideas. Compared\nwith recent works, our scheme achieves $2-4 \\times$ efficiency improvement and\nis robust to be widely applied.",
            "author": [
                "Xuanming Liu",
                "Xinpeng Yang",
                "Xun Zhang",
                "Xiaohu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00985v1",
                "http://arxiv.org/pdf/2308.00985v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02555v1",
            "title": "Knowledge-aware Collaborative Filtering with Pre-trained Language Model\n  for Personalized Review-based Rating Prediction",
            "updated": "2023-08-02T07:28:08Z",
            "published": "2023-08-02T07:28:08Z",
            "summary": "Personalized review-based rating prediction aims at leveraging existing\nreviews to model user interests and item characteristics for rating prediction.\nMost of the existing studies mainly encounter two issues. First, the rich\nknowledge contained in the fine-grained aspects of each review and the\nknowledge graph is rarely considered to complement the pure text for better\nmodeling user-item interactions. Second, the power of pre-trained language\nmodels is not carefully studied for personalized review-based rating\nprediction. To address these issues, we propose an approach named\nKnowledge-aware Collaborative Filtering with Pre-trained Language Model\n(KCF-PLM). For the first issue, to utilize rich knowledge, KCF-PLM develops a\ntransformer network to model the interactions of the extracted aspects w.r.t. a\nuser-item pair. For the second issue, to better represent users and items,\nKCF-PLM takes all the historical reviews of a user or an item as input to\npre-trained language models. Moreover, KCF-PLM integrates the transformer\nnetwork and the pre-trained language models through representation propagation\non the knowledge graph and user-item guided attention of the aspect\nrepresentations. Thus KCF-PLM combines review text, aspect, knowledge graph,\nand pre-trained language models together for review-based rating prediction. We\nconduct comprehensive experiments on several public datasets, demonstrating the\neffectiveness of KCF-PLM.",
            "author": [
                "Quanxiu Wang",
                "Xinlei Cao",
                "Jianyong Wang",
                "Wei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02555v1",
                "http://arxiv.org/pdf/2308.02555v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00972v2",
            "title": "Homological algebra and poset versions of the Garland method",
            "updated": "2023-08-23T09:15:10Z",
            "published": "2023-08-02T07:04:14Z",
            "summary": "Garland introduced a vanishing criterion for a characteristic zero cohomology\ngroup of a locally finite and locally connected simplicial complex. The\ncriterion is based on the spectral gaps of the graph Laplacians of the links of\nfaces and has turned out to be effective in a wide range of examples. In this\nnote we extend the approach to include a range of non-simplicial (co)chain\ncomplexes associated to combinatorial structures we call Garland posets and\nelaborate further on the case of cubical complexes.",
            "author": [
                "Eric Babson",
                "Volkmar Welker"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00972v2",
                "http://arxiv.org/pdf/2308.00972v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AT",
                "math.GR",
                "05E45, 20F32"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00958v2",
            "title": "Isolation and Induction: Training Robust Deep Neural Networks against\n  Model Stealing Attacks",
            "updated": "2023-08-03T06:27:08Z",
            "published": "2023-08-02T05:54:01Z",
            "summary": "Despite the broad application of Machine Learning models as a Service\n(MLaaS), they are vulnerable to model stealing attacks. These attacks can\nreplicate the model functionality by using the black-box query process without\nany prior knowledge of the target victim model. Existing stealing defenses add\ndeceptive perturbations to the victim's posterior probabilities to mislead the\nattackers. However, these defenses are now suffering problems of high inference\ncomputational overheads and unfavorable trade-offs between benign accuracy and\nstealing robustness, which challenges the feasibility of deployed models in\npractice. To address the problems, this paper proposes Isolation and Induction\n(InI), a novel and effective training framework for model stealing defenses.\nInstead of deploying auxiliary defense modules that introduce redundant\ninference time, InI directly trains a defensive model by isolating the\nadversary's training gradient from the expected gradient, which can effectively\nreduce the inference computational cost. In contrast to adding perturbations\nover model predictions that harm the benign accuracy, we train models to\nproduce uninformative outputs against stealing queries, which can induce the\nadversary to extract little useful knowledge from victim models with minimal\nimpact on the benign performance. Extensive experiments on several visual\nclassification datasets (e.g., MNIST and CIFAR10) demonstrate the superior\nrobustness (up to 48% reduction on stealing accuracy) and speed (up to 25.4x\nfaster) of our InI over other state-of-the-art methods. Our codes can be found\nin https://github.com/DIG-Beihang/InI-Model-Stealing-Defense.",
            "author": [
                "Jun Guo",
                "Aishan Liu",
                "Xingyu Zheng",
                "Siyuan Liang",
                "Yisong Xiao",
                "Yichao Wu",
                "Xianglong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00958v2",
                "http://arxiv.org/pdf/2308.00958v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00929v2",
            "title": "Towards Discriminative Representation with Meta-learning for\n  Colonoscopic Polyp Re-Identification",
            "updated": "2023-11-28T08:57:12Z",
            "published": "2023-08-02T04:10:14Z",
            "summary": "Colonoscopic Polyp Re-Identification aims to match the same polyp from a\nlarge gallery with images from different views taken using different cameras\nand plays an important role in the prevention and treatment of colorectal\ncancer in computer-aided diagnosis. However, traditional methods for object\nReID directly adopting CNN models trained on the ImageNet dataset usually\nproduce unsatisfactory retrieval performance on colonoscopic datasets due to\nthe large domain gap. Additionally, these methods neglect to explore the\npotential of self-discrepancy among intra-class relations in the colonoscopic\npolyp dataset, which remains an open research problem in the medical community.\nTo solve this dilemma, we propose a simple but effective training method named\nColo-ReID, which can help our model learn more general and discriminative\nknowledge based on the meta-learning strategy in scenarios with fewer samples.\nBased on this, a dynamic Meta-Learning Regulation mechanism called MLR is\nintroduced to further boost the performance of polyp re-identification. To the\nbest of our knowledge, this is the first attempt to leverage the meta-learning\nparadigm instead of traditional machine learning algorithm to effectively train\ndeep models in the task of colonoscopic polyp re-identification. Empirical\nresults show that our method significantly outperforms current state-of-the-art\nmethods by a clear margin.",
            "author": [
                "Suncheng Xiang",
                "Qingzhong Chen",
                "Shilun Cai",
                "Chengfeng Zhou",
                "Crystal Cai",
                "Sijia Du",
                "Zhengjie Zhang",
                "Yunshi Zhong",
                "Dahong Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00929v2",
                "http://arxiv.org/pdf/2308.00929v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02553v1",
            "title": "Survey on Computer Vision Techniques for Internet-of-Things Devices",
            "updated": "2023-08-02T03:41:24Z",
            "published": "2023-08-02T03:41:24Z",
            "summary": "Deep neural networks (DNNs) are state-of-the-art techniques for solving most\ncomputer vision problems. DNNs require billions of parameters and operations to\nachieve state-of-the-art results. This requirement makes DNNs extremely\ncompute, memory, and energy-hungry, and consequently difficult to deploy on\nsmall battery-powered Internet-of-Things (IoT) devices with limited computing\nresources. Deployment of DNNs on Internet-of-Things devices, such as traffic\ncameras, can improve public safety by enabling applications such as automatic\naccident detection and emergency response.Through this paper, we survey the\nrecent advances in low-power and energy-efficient DNN implementations that\nimprove the deployability of DNNs without significantly sacrificing accuracy.\nIn general, these techniques either reduce the memory requirements, the number\nof arithmetic operations, or both. The techniques can be divided into three\nmajor categories: neural network compression, network architecture search and\ndesign, and compiler and graph optimizations. In this paper, we survey both\nlow-power techniques for both convolutional and transformer DNNs, and summarize\nthe advantages, disadvantages, and open research problems.",
            "author": [
                "Ishmeet Kaur",
                "Adwaita Janardhan Jadhav"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02553v1",
                "http://arxiv.org/pdf/2308.02553v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01816v1",
            "title": "Fixed point results for set-contractions on semi-metric space with a\n  directed graph",
            "updated": "2023-08-02T02:20:16Z",
            "published": "2023-08-02T02:20:16Z",
            "summary": "Fixed point results with respect to generalized rational contractive mappings\nin semi-metric spaces endowed with a directed graph are proved. Some examples\nare provided to illustrate the results. The obtained results extend, improve\nand generalize many results in the existing literature.",
            "author": [
                "Talat Nazir",
                "Zakaria Ali",
                "Shahin Nosrat Jogan",
                "Sergei Silvestrov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01816v1",
                "http://arxiv.org/pdf/2308.01816v1"
            ],
            "primary_category": "math.GN",
            "category": [
                "math.GN",
                "47H09, 47H10, 54C60, 54H25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00900v1",
            "title": "Metric and Path-Connectedness Properties of the Frechet Distance for\n  Paths and Graphs",
            "updated": "2023-08-02T01:29:51Z",
            "published": "2023-08-02T01:29:51Z",
            "summary": "The Frechet distance is often used to measure distances between paths, with\napplications in areas ranging from map matching to GPS trajectory analysis to\nhandwriting recognition. More recently, the Frechet distance has been\ngeneralized to a distance between two copies of the same graph embedded or\nimmersed in a metric space; this more general setting opens up a wide range of\nmore complex applications in graph analysis. In this paper, we initiate a study\nof some of the fundamental topological properties of spaces of paths and of\ngraphs mapped to R^n under the Frechet distance, in an effort to lay the\ntheoretical groundwork for understanding how these distances can be used in\npractice. In particular, we prove whether or not these spaces, and the metric\nballs therein, are path-connected.",
            "author": [
                "Erin Chambers",
                "Brittany Fasy",
                "Benjamin Holmgren",
                "Sushovan Majhi",
                "Carola Wenk"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00900v1",
                "http://arxiv.org/pdf/2308.00900v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00890v2",
            "title": "Tango: rethinking quantization for graph neural network training on GPUs",
            "updated": "2023-09-01T03:30:05Z",
            "published": "2023-08-02T00:51:37Z",
            "summary": "Graph Neural Networks (GNNs) are becoming increasingly popular due to their\nsuperior performance in critical graph-related tasks. While quantization is\nwidely used to accelerate GNN computation, quantized training faces\nunprecedented challenges. Current quantized GNN training systems often have\nlonger training times than their full-precision counterparts for two reasons:\n(i) addressing the accuracy challenge leads to excessive overhead, and (ii) the\noptimization potential exposed by quantization is not adequately leveraged.\nThis paper introduces Tango which re-thinks quantization challenges and\nopportunities for graph neural network training on GPUs with three\ncontributions: Firstly, we introduce efficient rules to maintain accuracy\nduring quantized GNN training. Secondly, we design and implement\nquantization-aware primitives and inter-primitive optimizations that can speed\nup GNN training. Finally, we integrate Tango with the popular Deep Graph\nLibrary (DGL) system and demonstrate its superior performance over\nstate-of-the-art approaches on various GNN models and datasets.",
            "author": [
                "Shiyang Chen",
                "Da Zheng",
                "Caiwen Ding",
                "Chengying Huan",
                "Yuede Ji",
                "Hang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00890v2",
                "http://arxiv.org/pdf/2308.00890v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00887v1",
            "title": "Factor Graph Neural Networks",
            "updated": "2023-08-02T00:32:02Z",
            "published": "2023-08-02T00:32:02Z",
            "summary": "In recent years, we have witnessed a surge of Graph Neural Networks (GNNs),\nmost of which can learn powerful representations in an end-to-end fashion with\ngreat success in many real-world applications. They have resemblance to\nProbabilistic Graphical Models (PGMs), but break free from some limitations of\nPGMs. By aiming to provide expressive methods for representation learning\ninstead of computing marginals or most likely configurations, GNNs provide\nflexibility in the choice of information flowing rules while maintaining good\nperformance. Despite their success and inspirations, they lack efficient ways\nto represent and learn higher-order relations among variables/nodes. More\nexpressive higher-order GNNs which operate on k-tuples of nodes need increased\ncomputational resources in order to process higher-order tensors. We propose\nFactor Graph Neural Networks (FGNNs) to effectively capture higher-order\nrelations for inference and learning. To do so, we first derive an efficient\napproximate Sum-Product loopy belief propagation inference algorithm for\ndiscrete higher-order PGMs. We then neuralize the novel message passing scheme\ninto a Factor Graph Neural Network (FGNN) module by allowing richer\nrepresentations of the message update rules; this facilitates both efficient\ninference and powerful end-to-end learning. We further show that with a\nsuitable choice of message aggregation operators, our FGNN is also able to\nrepresent Max-Product belief propagation, providing a single family of\narchitecture that can represent both Max and Sum-Product loopy belief\npropagation. Our extensive experimental evaluation on synthetic as well as real\ndatasets demonstrates the potential of the proposed model.",
            "author": [
                "Zhen Zhang",
                "Mohammed Haroon Dupty",
                "Fan Wu",
                "Javen Qinfeng Shi",
                "Wee Sun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00887v1",
                "http://arxiv.org/pdf/2308.00887v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02550v1",
            "title": "Sampled Together: Assessing the Value of Simultaneous Co-located\n  Measurements",
            "updated": "2023-08-01T23:43:35Z",
            "published": "2023-08-01T23:43:35Z",
            "summary": "This work applies a quantitative metric well-known to the data assimilation\ncommunity to a new context in order to capture the relative representativeness\nof non-simultaneous or non-co-located observations and quantify how these\nobservations decorrelate in both space and time. This methodology allows for\nthe effective determination of thresholding decisions for representative\nmatchup conditions, and is especially useful for informing future network\ndesigns and architectures. Future weather and climate satellite missions must\nconsider a range of architectural trades to meet observing requirements.\nFrequently, fundamental decisions such as the number of observatories, the\ninstruments manifested, and orbit parameters are determined based upon\nassumptions about the characteristic temporal and spatial scales of variability\nof the target observation. With the introduced methodology, representativity\nerrors due to separations in space and time can be quantified without prior\nknowledge of instrument performance, and errors driven by constellation design\ncan be estimated without model ingest or analysis.",
            "author": [
                "C. E. Powell",
                "Christopher S. Ruf",
                "Scott Gleason",
                "Scot C. R. Rafkin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02550v1",
                "http://arxiv.org/pdf/2308.02550v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.geo-ph",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00852v1",
            "title": "CASSINI: Network-Aware Job Scheduling in Machine Learning Clusters",
            "updated": "2023-08-01T21:34:45Z",
            "published": "2023-08-01T21:34:45Z",
            "summary": "We present CASSINI, a network-aware job scheduler for machine learning (ML)\nclusters. CASSINI introduces a novel geometric abstraction to consider the\ncommunication pattern of different jobs while placing them on network links. To\ndo so, CASSINI uses an affinity graph that finds a series of time-shift values\nto adjust the communication phases of a subset of jobs, such that the\ncommunication patterns of jobs sharing the same network link are interleaved\nwith each other. Experiments with 13 common ML models on a 24-server testbed\ndemonstrate that compared to the state-of-the-art ML schedulers, CASSINI\nimproves the average and tail completion time of jobs by up to 1.6x and 2.5x,\nrespectively. Moreover, we show that CASSINI reduces the number of ECN marked\npackets in the cluster by up to 33x.",
            "author": [
                "Sudarsanan Rajasekaran",
                "Manya Ghobadi",
                "Aditya Akella"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00852v1",
                "http://arxiv.org/pdf/2308.00852v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC",
                "cs.LG",
                "C.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00845v3",
            "title": "Component order edge connectivity, vertex degrees, and integer\n  partitions",
            "updated": "2023-10-07T18:42:20Z",
            "published": "2023-08-01T21:19:01Z",
            "summary": "Given a finite, simple graph $G$, the $k$-component order edge connectivity\nof $G$ is the minimum number of edges whose removal results in a subgraph for\nwhich every component has order at most $k-1$. In general, determining the\n$k$-component order edge connectivity of a graph is NP-hard. We determine\nconditions on the vertex degrees of $G$ that can be used to imply a lower bound\non the $k$-component order edge connectivity of $G$. We will discuss the\nprocess for generating such conditions for a lower bound of 1 or 2, and we\nexplore how the complexity increases when the desired lower bound is 3 or more.\nIn the process, we prove some related results about integer partitions.",
            "author": [
                "Michael Yatauro"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00845v3",
                "http://arxiv.org/pdf/2308.00845v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00840v2",
            "title": "Approximately: Independence Implies Vertex Cover",
            "updated": "2023-08-03T16:04:05Z",
            "published": "2023-08-01T21:07:51Z",
            "summary": "$\\newcommand{\\eps}{\\varepsilon}$\n  We observe that a $(1-\\eps)$-approximation algorithm to Independent Set, that\nworks for any induced subgraph of the input graph, can be used, via a\npolynomial time reduction, to provide a $(1+\\eps)$-approximation to Vertex\nCover. This basic observation was made before, see [BHR11].\n  As a consequence, we get a PTAS for VC for unweighted pseudo-disks, QQPTAS\nfor VC for unweighted axis-aligned rectangles in the plane, and QPTAS for MWVC\nfor weighted polygons in the plane. To the best of our knowledge all these\nresults are new.",
            "author": [
                "Sariel Har-Peled"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00840v2",
                "http://arxiv.org/pdf/2308.00840v2"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00837v1",
            "title": "An Old-Fashioned Framework for Machine Learning in Turbulence Modeling",
            "updated": "2023-08-01T21:02:26Z",
            "published": "2023-08-01T21:02:26Z",
            "summary": "The objective is to provide clear and well-motivated guidance to Machine\nLearning (ML) teams, founded on our experience in empirical turbulence\nmodeling. Guidance is also needed for modeling outside ML. ML is not yet\nsuccessful in turbulence modeling, and many papers have produced unusable\nproposals either due to errors in math or physics, or to severe overfitting. We\nbelieve that \"Turbulence Culture\" (TC) takes years to learn and is difficult to\nconvey especially considering the modern lack of time for careful study;\nimportant facts which are self-evident after a career in turbulence research\nand modeling and extensive reading are easy to miss. In addition, many of them\nare not absolute facts, a consequence of the gaps in our understanding of\nturbulence and the weak connection of models to first principles. Some of the\nmathematical facts are rigorous, but the physical aspects often are not.\nTurbulence models are surprisingly arbitrary. Disagreement between experts\nconfuses the new entrants. In addition, several key properties of the models\nare ascertained through non-trivial analytical properties of the differential\nequations, which puts them out of reach of purely data-driven ML-type\napproaches. The best example is the crucial behavior of the model at the edge\nof the turbulent region (ETR). The knowledge we wish to put out here may be\ndivided into \"Mission\" and \"Requirements,\" each combining physics and\nmathematics. Clear lists of \"Hard\" and \"Soft\" constraints are presented. A\nconcrete example of how DNS data could be used, possibly allied with ML, is\nfirst carried through and illustrates the large number of decisions needed. Our\nfocus is on creating effective products which will empower CFD, rather than on\npublications.",
            "author": [
                "Philippe Spalart"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00837v1",
                "http://arxiv.org/pdf/2308.00837v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00799v1",
            "title": "Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body\n  Reconstruction",
            "updated": "2023-08-01T19:29:10Z",
            "published": "2023-08-01T19:29:10Z",
            "summary": "While 3D body reconstruction methods have made remarkable progress recently,\nit remains difficult to acquire the sufficiently accurate and numerous 3D\nsupervisions required for training. In this paper, we propose \\textbf{KNOWN}, a\nframework that effectively utilizes body \\textbf{KNOW}ledge and\nu\\textbf{N}certainty modeling to compensate for insufficient 3D supervisions.\nKNOWN exploits a comprehensive set of generic body constraints derived from\nwell-established body knowledge. These generic constraints precisely and\nexplicitly characterize the reconstruction plausibility and enable 3D\nreconstruction models to be trained without any 3D data. Moreover, existing\nmethods typically use images from multiple datasets during training, which can\nresult in data noise (\\textit{e.g.}, inconsistent joint annotation) and data\nimbalance (\\textit{e.g.}, minority images representing unusual poses or\ncaptured from challenging camera views). KNOWN solves these problems through a\nnovel probabilistic framework that models both aleatoric and epistemic\nuncertainty. Aleatoric uncertainty is encoded in a robust Negative\nLog-Likelihood (NLL) training loss, while epistemic uncertainty is used to\nguide model refinement. Experiments demonstrate that KNOWN's body\nreconstruction outperforms prior weakly-supervised approaches, particularly on\nthe challenging minority images.",
            "author": [
                "Yufei Zhang",
                "Hanjing Wang",
                "Jeffrey O. Kephart",
                "Qiang Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00799v1",
                "http://arxiv.org/pdf/2308.00799v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00796v1",
            "title": "On determining number and metric dimension of zero-divisor graphs",
            "updated": "2023-08-01T19:13:47Z",
            "published": "2023-08-01T19:13:47Z",
            "summary": "In this article, explicit formulas for finding the determining number and the\nmetric dimension of the zero-divisor graph of Z_n and non-Boolean semisimple\nrings are given. In the case of Boolean rings, an upper bound of the\ndetermining number and the metric dimension of zero-divisor graph is\ndetermined. Further, the determining number and the metric dimension of some\nimportant graphs other than zero-divisor graphs, are proved and the open\nproblem by Boutin, regarding the determining number of graphs is settled.",
            "author": [
                "Muhammed Sabeel K",
                "Krishnan Paramasivam"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00796v1",
                "http://arxiv.org/pdf/2308.00796v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA",
                "05C25, 05C75, 05E40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.04447v1",
            "title": "Assessment of POS Owners Awareness of Cybersecurity and Insider Threats\n  in POS Kiosks Related Financial Crimes",
            "updated": "2023-08-01T18:43:59Z",
            "published": "2023-08-01T18:43:59Z",
            "summary": "The introduction of point of sales POS technologies as a payment system was\nwelcoming and constitutes one of the major breakthroughs in the efforts made to\nrejuvenate the global financial systems. However, like other information\ntechnology IT based financial systems, the POS also poses some cybersecurity\nsecurity threats. The unique thing about the POS is that the main cybersecurity\nthreats it poses to most users are not IT based which refers to unauthorized\naccess and gaining information without the knowledge of the user. The threats\nare rather connected to the mode of operation of POS kiosks, particularly as\nexperienced in most parts of Nigeria. The mode of operation exposes users cards\nto possible cloning.",
            "author": [
                "Rawlings Fiberesima"
            ],
            "link": [
                "http://arxiv.org/abs/2308.04447v1",
                "http://arxiv.org/pdf/2308.04447v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00770v1",
            "title": "DYMOND: DYnamic MOtif-NoDes Network Generative Model",
            "updated": "2023-08-01T18:20:05Z",
            "published": "2023-08-01T18:20:05Z",
            "summary": "Motifs, which have been established as building blocks for network structure,\nmove beyond pair-wise connections to capture longer-range correlations in\nconnections and activity. In spite of this, there are few generative graph\nmodels that consider higher-order network structures and even fewer that focus\non using motifs in models of dynamic graphs. Most existing generative models\nfor temporal graphs strictly grow the networks via edge addition, and the\nmodels are evaluated using static graph structure metrics -- which do not\nadequately capture the temporal behavior of the network. To address these\nissues, in this work we propose DYnamic MOtif-NoDes (DYMOND) -- a generative\nmodel that considers (i) the dynamic changes in overall graph structure using\ntemporal motif activity and (ii) the roles nodes play in motifs (e.g., one node\nplays the hub role in a wedge, while the remaining two act as spokes). We\ncompare DYMOND to three dynamic graph generative model baselines on real-world\nnetworks and show that DYMOND performs better at generating graph structure and\nnode behavior similar to the observed network. We also propose a new\nmethodology to adapt graph structure metrics to better evaluate the temporal\naspect of the network. These metrics take into account the changes in overall\ngraph structure and the individual nodes' behavior over time.",
            "author": [
                "Giselle Zeno",
                "Timothy La Fond",
                "Jennifer Neville"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3442381.3450102",
                "http://arxiv.org/abs/2308.00770v1",
                "http://arxiv.org/pdf/2308.00770v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00753v1",
            "title": "Bounding the joint numerical range of Pauli strings by graph parameters",
            "updated": "2023-08-01T18:00:07Z",
            "published": "2023-08-01T18:00:07Z",
            "summary": "The interplay between the quantum state space and a specific set of\nmeasurements can be effectively captured by examining the set of jointly\nattainable expectation values. This set is commonly referred to as the (convex)\njoint numerical range. In this work, we explore geometric properties of this\nconstruct for measurements represented by tensor products of Pauli observables,\nalso known as Pauli strings. The structure of pairwise commutation and\nanticommutation relations among a set of Pauli strings determines a graph $G$,\nsometimes also called the frustration graph. We investigate the connection\nbetween the parameters of this graph and the structure of minimal ellipsoids\nencompassing the joint numerical range. Such an outer approximation can be very\npractical since ellipsoids can be handled analytically even in high dimensions.\n  We find counterexamples to a conjecture from [C. de Gois, K. Hansenne and O.\nG\\\"uhne, arXiv:2207.02197], and answer an open question in [M. B. Hastings and\nR. O'Donnell, Proc. STOC 2022, pp. 776-789], which implies a new graph\nparameter that we call $\\beta(G)$. Besides, we develop this approach in\ndifferent directions, such as comparison with graph-theoretic approaches in\nother fields, applications in quantum information theory, numerical methods,\nproperties of the new graph parameter, etc. Our approach suggests many open\nquestions that we discuss briefly at the end.",
            "author": [
                "Zhen-Peng Xu",
                "Ren\u00e9 Schwonnek",
                "Andreas Winter"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00753v1",
                "http://arxiv.org/pdf/2308.00753v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00744v2",
            "title": "The El Gordo galaxy cluster challenges \u039bCDM for any plausible\n  collision velocity",
            "updated": "2023-09-05T12:51:22Z",
            "published": "2023-08-01T18:00:01Z",
            "summary": "El Gordo (ACT-CL J0102-4915) is an extraordinarily large and bright galaxy\ncluster collision. In a previous study, we found that El Gordo is in\n$6.2\\sigma$ tension with the $\\Lambda$CDM standard model when assuming the\nnominal mass and infall velocity values from the hydrodynamical simulations of\nZhang et al. ($M_{200} = 3.2 \\times 10^{15} M_{\\odot}$ and $V_{\\textrm{infall}}\n= 2500~\\textrm{km~s}^{-1}$, respectively). The recent weak lensing study of Kim\net al. showed that the mass of El Gordo is actually $2.13^{+0.25}_{-0.23}\n\\times 10^{15} M_{\\odot}$. Here we explore the level of tension between El\nGordo and $\\Lambda$CDM for the new mass estimate, assuming several\n$V_{\\textrm{infall}}$ values. We find that in order to reduce the tension below\nthe $5\\sigma$ level, the El Gordo subclusters should have $V_{\\textrm{infall}}\n< 2300~\\textrm{km~s}^{-1}$ ($V_{\\textrm{infall}} < 1800~\\textrm{km~s}^{-1}$\nwhen considering the combined tension with the Bullet Cluster). To the best of\nour knowledge, the El Gordo hydrodynamical simulations conducted so far require\n$V_{\\textrm{infall}} \\geq 2500~\\textrm{km~s}^{-1}$ to simultaneously reproduce\nits morphology and its high X-ray luminosity and temperature. We therefore\nconclude that El Gordo still poses a significant challenge to $\\Lambda$CDM\ncosmology. Whether the properties of El Gordo can be reconciled with a lower\n$V_{\\textrm{infall}}$ should be tested with new hydrodynamical simulations that\nexplore different configurations of the interaction.",
            "author": [
                "E. Asencio",
                "I. Banik",
                "P. Kroupa"
            ],
            "link": [
                "http://dx.doi.org/10.3847/1538-4357/ace62a",
                "http://arxiv.org/abs/2308.00744v2",
                "http://arxiv.org/pdf/2308.00744v2"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00692v2",
            "title": "LISA: Reasoning Segmentation via Large Language Model",
            "updated": "2023-08-03T17:38:21Z",
            "published": "2023-08-01T17:50:17Z",
            "summary": "Although perception systems have made remarkable advancements in recent\nyears, they still rely on explicit human instruction to identify the target\nobjects or categories before executing visual recognition tasks. Such systems\nlack the ability to actively reason and comprehend implicit user intentions. In\nthis work, we propose a new segmentation task -- reasoning segmentation. The\ntask is designed to output a segmentation mask given a complex and implicit\nquery text. Furthermore, we establish a benchmark comprising over one thousand\nimage-instruction pairs, incorporating intricate reasoning and world knowledge\nfor evaluation purposes. Finally, we present LISA: large Language Instructed\nSegmentation Assistant, which inherits the language generation capabilities of\nthe multi-modal Large Language Model (LLM) while also possessing the ability to\nproduce segmentation masks. We expand the original vocabulary with a <SEG>\ntoken and propose the embedding-as-mask paradigm to unlock the segmentation\ncapability. Remarkably, LISA can handle cases involving: 1) complex reasoning;\n2) world knowledge; 3) explanatory answers; 4) multi-turn conversation. Also,\nit demonstrates robust zero-shot capability when trained exclusively on\nreasoning-free datasets. In addition, fine-tuning the model with merely 239\nreasoning segmentation image-instruction pairs results in further performance\nenhancement. Experiments show our method not only unlocks new reasoning\nsegmentation capabilities but also proves effective in both complex reasoning\nsegmentation and standard referring segmentation tasks. Code, models, and demo\nare at https://github.com/dvlab-research/LISA.",
            "author": [
                "Xin Lai",
                "Zhuotao Tian",
                "Yukang Chen",
                "Yanwei Li",
                "Yuhui Yuan",
                "Shu Liu",
                "Jiaya Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00692v2",
                "http://arxiv.org/pdf/2308.00692v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00690v1",
            "title": "Solving Linear Equations Over Maxmin-$\u03c9$ Systems",
            "updated": "2023-08-01T17:50:04Z",
            "published": "2023-08-01T17:50:04Z",
            "summary": "Maxmin-$\\omega$ dynamical systems were previously introduced as an\n``all-in-one package'' that can yield a solely min-plus, a solely max-plus, or\na max-min-plus dynamical system by varying a parameter $\\omega\\in(0,1]$. With\nsuch systems in mind, it is natural to introduce and consider maxmin-$\\omega$\nlinear systems of equations of the type $A\\otimes_{\\omega} x=b$. However, to\nour knowledge, such maxmin-$\\omega$ linear systems have not been studied before\nand in this paper we present an approach to solve them. We show that the\nproblem can be simplified by performing normalization and then generating a\n``canonical'' matrix which we call the principal order matrix. Instead of\ndirectly trying to find the solutions, we search the possible solution indices\nwhich can be identified using the principal order matrix and the parameter\n$\\omega$. The fully active solutions are then immediately obtained from these\nsolution indices. With the fully active solutions at hand, we then present the\nmethod to find other solutions by applying a relaxation, i.e., increasing or\ndecreasing some components of fully active solutions. This approach can be seen\nas a generalization of an approach that could be applied to solve max-plus or\nmin-plus linear systems. Our results also shed more light on an unusual feature\nof maxmin-$\\omega$ linear systems, which, unlike in the usual linear algebra,\ncan have a finite number of solutions in the case where their solution is\nnon-unique.",
            "author": [
                "Muhammad Syifa'ul Mufid",
                "Ebrahim Patel",
                "Sergei Sergeev"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00690v1",
                "http://arxiv.org/pdf/2308.00690v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00735v1",
            "title": "A Knowledge-Oriented Approach to Enhance Integration and Communicability\n  in the Polkadot Ecosystem",
            "updated": "2023-08-01T17:34:30Z",
            "published": "2023-08-01T17:34:30Z",
            "summary": "The Polkadot ecosystem is a disruptive and highly complex multi-chain\narchitecture that poses challenges in terms of data analysis and\ncommunicability. Currently, there is a lack of standardized and holistic\napproaches to retrieve and analyze data across parachains and applications,\nmaking it difficult for general users and developers to access ecosystem data\nconsistently. This paper proposes a conceptual framework that includes a domain\nontology called POnto (a Polkadot Ontology) to address these challenges. POnto\nprovides a structured representation of the ecosystem's concepts and\nrelationships, enabling a formal understanding of the platform. The proposed\nknowledge-oriented approach enhances integration and communicability, enabling\na wider range of users to participate in the ecosystem and facilitating the\ndevelopment of AI-based applications. The paper presents a case study\nmethodology to validate the proposed framework, which includes expert feedback\nand insights from the Polkadot community. The POnto ontology and the roadmap\nfor a query engine based on a Controlled Natural Language using the ontology,\nprovide valuable contributions to the growth and adoption of the Polkadot\necosystem in heterogeneous socio-technical environments.",
            "author": [
                "Marcio Ferreira Moreno",
                "Rafael Rossi de Mello Brand\u00e3o"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00735v1",
                "http://arxiv.org/pdf/2308.00735v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DC",
                "cs.IR",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00674v2",
            "title": "Minimizing the number of edges in $(C_4, K_{1,k})$-co-critical graphs",
            "updated": "2023-08-09T15:16:46Z",
            "published": "2023-08-01T17:21:31Z",
            "summary": "Given graphs $H_1, H_2$, a {red, blue}-coloring of the edges of a graph $G$\nis a critical coloring if $G$ has neither a red $H_1$ nor a blue $ H_2$. A\nnon-complete graph $G$ is $(H_1, H_2)$-co-critical if $G$ admits a critical\ncoloring, but $G+e$ has no critical coloring for every edge $e$ in the\ncomplement of $G$. Motivated by a conjecture of Hanson and Toft from 1987, we\nstudy the minimum number of edges over all $(C_4, K_{1,k})$-co-critical graphs\non $n$ vertices. We show that for all $k \\ge 2 $ and $ n \\ge k +\\lfloor \\sqrt\n{k-1} \\rfloor +2$, if $G$ is a $(C_4,K_{1,k})$-co-critical graph on $n$\nvertices, then \\[e(G) \\ge \\frac{(k+2)n}2-3- \\frac{(k-1)(k+ \\lfloor \\sqrt\n{k-2}\\rfloor)}2.\\] Moreover, this linear bound is asymptotically best possible\nfor all $k\\ge3$ and $n\\ge3k+4$. It is worth noting that our constructions for\nthe case when $ k$ is even have at least three different critical colorings.\nFor $k=2$, we obtain the sharp bound for the minimum number of edges of $(C_4,\nK_{1,2})$-co-critical graphs on $n\\ge5 $ vertices by showing that all such\ngraphs have at least $2n-3$ edges. Our proofs rely on the structural properties\nof $(C_4,K_{1,k})$-co-critical graphs and a result of Ollmann on the minimum\nnumber of edges of $C_4$-saturated graphs.",
            "author": [
                "Gang Chen",
                "Chenchen Ren",
                "Zi-Xia Song"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00674v2",
                "http://arxiv.org/pdf/2308.00674v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02544v1",
            "title": "The extraordinary story of Sinann -- the inspirational figure who gave\n  her name to Ireland longest river -- and how she arose Ireland's resilient\n  female icons",
            "updated": "2023-08-01T16:15:08Z",
            "published": "2023-08-01T16:15:08Z",
            "summary": "When local authorities recently selected a neoclassical male \"river god head\"\nof colonial origin to represent Ireland's longest river, it was welcomed as\n\"harking back to Irish mythology\". The council, local historians and townsfolk\nwere unaware that in Irish mythology the figure associated with the river is a\nwoman -- not a man. Her name is Sinann, and she had been written out of\nIreland's national iconography after centuries of colonial destruction of\nGaelic heritage. When mathematical investigation into Irish mythology brought\nSinann's story to the people via local media, reaction was immediate. Street\nperformances in support of Sinann were backed by letters in newspapers and a\npetition signed by hundreds of people demanding education about their heritage\n- and respect for women. How did this happen and what is the story behind\nSinann, her diminution, and her rising? Here we recount how modern-day\nmathematics exposed the colonial imposter as stemming from the Ossianic\ncontroversy 250 years ago. We also discuss how a Victorian-era translation of\nher story from the original Irish turned what was an inspirational creation\nmyth into a tale of a disobedient girl seeking knowledge to which she had no\nentitlement. This flawed narrative entered the public domain -- in\nencyclopaedias, on websites, and even in academic literature. Here we cast off\ncolonial baggage to present a new, more accurate translation of Sinann's story\nalongside a new interpretation -- more amenable to a receptive public seeking\nenlightenment. Inspired by Sinann's rising, we also use artistic measures to\ninvoke other Irish resilient female icons to rise up and take their rightful\nplace in Irish iconography.",
            "author": [
                "Ralph Kenna",
                "Chris Thompson",
                "Isolde \u00d3 Brolch\u00e1in Carmody",
                "Benjamin Dwyer",
                "Daniel Curley",
                "Mike McCarthy",
                "Nicola Bowes",
                "P\u00e1draig MacCarron",
                "Thierry Platini",
                "Joseph Yose"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02544v1",
                "http://arxiv.org/pdf/2308.02544v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00729v1",
            "title": "Ada-DQA: Adaptive Diverse Quality-aware Feature Acquisition for Video\n  Quality Assessment",
            "updated": "2023-08-01T16:04:42Z",
            "published": "2023-08-01T16:04:42Z",
            "summary": "Video quality assessment (VQA) has attracted growing attention in recent\nyears. While the great expense of annotating large-scale VQA datasets has\nbecome the main obstacle for current deep-learning methods. To surmount the\nconstraint of insufficient training data, in this paper, we first consider the\ncomplete range of video distribution diversity (\\ie content, distortion,\nmotion) and employ diverse pretrained models (\\eg architecture, pretext task,\npre-training dataset) to benefit quality representation. An Adaptive Diverse\nQuality-aware feature Acquisition (Ada-DQA) framework is proposed to capture\ndesired quality-related features generated by these frozen pretrained models.\nBy leveraging the Quality-aware Acquisition Module (QAM), the framework is able\nto extract more essential and relevant features to represent quality. Finally,\nthe learned quality representation is utilized as supplementary supervisory\ninformation, along with the supervision of the labeled quality score, to guide\nthe training of a relatively lightweight VQA model in a knowledge distillation\nmanner, which largely reduces the computational cost during inference.\nExperimental results on three mainstream no-reference VQA benchmarks clearly\nshow the superior performance of Ada-DQA in comparison with current\nstate-of-the-art approaches without using extra training data of VQA.",
            "author": [
                "Hongbo Liu",
                "Mingda Wu",
                "Kun Yuan",
                "Ming Sun",
                "Yansong Tang",
                "Chuanchuan Zheng",
                "Xing Wen",
                "Xiu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00729v1",
                "http://arxiv.org/pdf/2308.00729v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.03777v1",
            "title": "Lab-in-a-Tube: A portable imaging spectrophotometer for cost-effective,\n  high-throughput, and label-free analysis of centrifugation processes",
            "updated": "2023-08-01T15:58:10Z",
            "published": "2023-08-01T15:58:10Z",
            "summary": "Centrifuges serve as essential instruments in modern experimental sciences,\nfacilitating a wide range of routine sample processing tasks that necessitate\nmaterial sedimentation. However, the study for real time observation of the\ndynamical process during centrifugation has remained elusive. In this study, we\ndeveloped an innovative Lab_in_a_Tube imaging spectrophotometer that\nincorporates capabilities of real time image analysis and programmable\ninterruption. This portable LIAT device costs less than 30 US dollars. Based on\nour knowledge, it is the first Wi Fi camera built_in in common lab centrifuges\nwith active closed_loop control. We tested our LIAT imaging spectrophotometer\nwith solute solvent interaction investigation obtained from lab centrifuges\nwith quantitative data plotting in a real time manner. Single re circulating\nflow was real time observed, forming the ring shaped pattern during\ncentrifugation. To the best of our knowledge, this is the very first\nobservation of similar phenomena. We developed theoretical simulations for the\nsingle particle in a rotating reference frame, which correlated well with\nexperimental results. We also demonstrated the first demonstration to visualize\nthe blood sedimentation process in clinical lab centrifuges. This remarkable\ncost effectiveness opens up exciting opportunities for centrifugation\nmicrobiology research and paves the way for the creation of a network of\ncomputational imaging spectrometers at an affordable price for large scale and\ncontinuous monitoring of centrifugal processes in general.",
            "author": [
                "Yuanyuan Wei",
                "Dehua Hu",
                "Bijie Bai",
                "Chenqi Meng",
                "Tsz Kin Chan",
                "Xing Zhao",
                "Yuye Wang",
                "Yi-Ping Ho",
                "Wu Yuan",
                "Ho-Pui Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2308.03777v1",
                "http://arxiv.org/pdf/2308.03777v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00728v1",
            "title": "ELFNet: Evidential Local-global Fusion for Stereo Matching",
            "updated": "2023-08-01T15:51:04Z",
            "published": "2023-08-01T15:51:04Z",
            "summary": "Although existing stereo matching models have achieved continuous\nimprovement, they often face issues related to trustworthiness due to the\nabsence of uncertainty estimation. Additionally, effectively leveraging\nmulti-scale and multi-view knowledge of stereo pairs remains unexplored. In\nthis paper, we introduce the \\textbf{E}vidential \\textbf{L}ocal-global\n\\textbf{F}usion (ELF) framework for stereo matching, which endows both\nuncertainty estimation and confidence-aware fusion with trustworthy heads.\nInstead of predicting the disparity map alone, our model estimates an\nevidential-based disparity considering both aleatoric and epistemic\nuncertainties. With the normal inverse-Gamma distribution as a bridge, the\nproposed framework realizes intra evidential fusion of multi-level predictions\nand inter evidential fusion between cost-volume-based and transformer-based\nstereo matching. Extensive experimental results show that the proposed\nframework exploits multi-view information effectively and achieves\nstate-of-the-art overall performance both on accuracy and cross-domain\ngeneralization.\n  The codes are available at https://github.com/jimmy19991222/ELFNet.",
            "author": [
                "Jieming Lou",
                "Weide Liu",
                "Zhuo Chen",
                "Fayao Liu",
                "Jun Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00728v1",
                "http://arxiv.org/pdf/2308.00728v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00727v1",
            "title": "Adaptive Semantic Consistency for Cross-domain Few-shot Classification",
            "updated": "2023-08-01T15:37:19Z",
            "published": "2023-08-01T15:37:19Z",
            "summary": "Cross-domain few-shot classification (CD-FSC) aims to identify novel target\nclasses with a few samples, assuming that there exists a domain shift between\nsource and target domains. Existing state-of-the-art practices typically\npre-train on source domain and then finetune on the few-shot target data to\nyield task-adaptive representations. Despite promising progress, these methods\nare prone to overfitting the limited target distribution since data-scarcity\nand ignore the transferable knowledge learned in the source domain. To\nalleviate this problem, we propose a simple plug-and-play Adaptive Semantic\nConsistency (ASC) framework, which improves cross-domain robustness by\npreserving source transfer capability during the finetuning stage. Concretely,\nwe reuse the source images in the pretraining phase and design an adaptive\nweight assignment strategy to highlight the samples similar to target domain,\naiming to aggregate informative target-related knowledge from source domain.\nSubsequently, a semantic consistency regularization is applied to constrain the\nconsistency between the semantic features of the source images output by the\nsource model and target model. In this way, the proposed ASC enables explicit\ntransfer of source domain knowledge to prevent the model from overfitting the\ntarget domain. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of the proposed ASC, and ASC provides consistent improvements\nover the baselines. The source code will be released.",
            "author": [
                "Hengchu Lu",
                "Yuanjie Shao",
                "Xiang Wang",
                "Changxin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00727v1",
                "http://arxiv.org/pdf/2308.00727v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00607v1",
            "title": "Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers",
            "updated": "2023-08-01T15:34:02Z",
            "published": "2023-08-01T15:34:02Z",
            "summary": "Images are loaded with semantic information that pertains to real-world\nontologies: dog breeds share mammalian similarities, food pictures are often\ndepicted in domestic environments, and so on. However, when training machine\nlearning models for image classification, the relative similarities amongst\nobject classes are commonly paired with one-hot-encoded labels. According to\nthis logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark'\nare equally wrong in terms of training loss. To overcome this limitation, we\nexplore the integration of additional goals that reflect ontological and\nsemantic knowledge, improving model interpretability and trustworthiness. We\nsuggest a generic approach that allows to derive an additional loss term\nstarting from any kind of semantic information about the classification label.\nFirst, we show how to apply our approach to ontologies and word embeddings, and\ndiscuss how the resulting information can drive a supervised learning process.\nSecond, we use our semantically enriched loss to train image classifiers, and\nanalyse the trade-offs between accuracy, mistake severity, and learned internal\nrepresentations. Finally, we discuss how this approach can be further exploited\nin terms of explainability and adversarial robustness. Code repository:\nhttps://github.com/S1M0N38/semantic-encodings",
            "author": [
                "Alan Perotti",
                "Simone Bertolotto",
                "Eliana Pastor",
                "Andr\u00e9 Panisson"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00607v1",
                "http://arxiv.org/pdf/2308.00607v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02542v2",
            "title": "Collaborative filtering to capture AI user's preferences as norms",
            "updated": "2023-08-10T20:55:47Z",
            "published": "2023-08-01T15:14:23Z",
            "summary": "Customising AI technologies to each user's preferences is fundamental to them\nfunctioning well. Unfortunately, current methods require too much user\ninvolvement and fail to capture their true preferences. In fact, to avoid the\nnuisance of manually setting preferences, users usually accept the default\nsettings even if these do not conform to their true preferences. Norms can be\nuseful to regulate behaviour and ensure it adheres to user preferences but,\nwhile the literature has thoroughly studied norms, most proposals take a formal\nperspective. Indeed, while there has been some research on constructing norms\nto capture a user's privacy preferences, these methods rely on domain knowledge\nwhich, in the case of AI technologies, is difficult to obtain and maintain. We\nargue that a new perspective is required when constructing norms, which is to\nexploit the large amount of preference information readily available from whole\nsystems of users. Inspired by recommender systems, we believe that\ncollaborative filtering can offer a suitable approach to identifying a user's\nnorm preferences without excessive user involvement.",
            "author": [
                "Marc Serramia",
                "Natalia Criado",
                "Michael Luck"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-21203-1_45",
                "http://arxiv.org/abs/2308.02542v2",
                "http://arxiv.org/pdf/2308.02542v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00593v1",
            "title": "On R\u00f6dl's Theorem for Cographs",
            "updated": "2023-08-01T15:08:22Z",
            "published": "2023-08-01T15:08:22Z",
            "summary": "A theorem of R\\\"odl states that for every fixed $F$ and $\\varepsilon>0$ there\nis $\\delta=\\delta_F(\\varepsilon)$ so that every induced $F$-free graph contains\na vertex set of size $\\delta n$ whose edge density is either at most\n$\\varepsilon$ or at least $1-\\varepsilon$. R\\\"odl's proof relied on the\nregularity lemma, hence it supplied only a tower-type bound for $\\delta$. Fox\nand Sudakov conjectured that $\\delta$ can be made polynomial in $\\varepsilon$,\nand a recent result of Fox, Nguyen, Scott and Seymour shows that this\nconjecture holds when $F=P_4$. In fact, they show that the same conclusion\nholds even if $G$ contains few copies of $P_4$. In this note we give a short\nproof of a more general statement.",
            "author": [
                "Lior Gishboliner",
                "Asaf Shapira"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00593v1",
                "http://arxiv.org/pdf/2308.00593v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00588v1",
            "title": "Relation-Aware Distribution Representation Network for Person Clustering\n  with Multiple Modalities",
            "updated": "2023-08-01T15:04:56Z",
            "published": "2023-08-01T15:04:56Z",
            "summary": "Person clustering with multi-modal clues, including faces, bodies, and\nvoices, is critical for various tasks, such as movie parsing and identity-based\nmovie editing. Related methods such as multi-view clustering mainly project\nmulti-modal features into a joint feature space. However, multi-modal clue\nfeatures are usually rather weakly correlated due to the semantic gap from the\nmodality-specific uniqueness. As a result, these methods are not suitable for\nperson clustering. In this paper, we propose a Relation-Aware Distribution\nrepresentation Network (RAD-Net) to generate a distribution representation for\nmulti-modal clues. The distribution representation of a clue is a vector\nconsisting of the relation between this clue and all other clues from all\nmodalities, thus being modality agnostic and good for person clustering.\nAccordingly, we introduce a graph-based method to construct distribution\nrepresentation and employ a cyclic update policy to refine distribution\nrepresentation progressively. Our method achieves substantial improvements of\n+6% and +8.2% in F-score on the Video Person-Clustering Dataset (VPCD) and\nVoxCeleb2 multi-view clustering dataset, respectively. Codes will be released\npublicly upon acceptance.",
            "author": [
                "Kaijian Liu",
                "Shixiang Tang",
                "Ziyue Li",
                "Zhishuai Li",
                "Lei Bai",
                "Feng Zhu",
                "Rui Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00588v1",
                "http://arxiv.org/pdf/2308.00588v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00587v2",
            "title": "Observation of the decays $B_{(s)}^{0}\\to D_{s1}(2536)^{\\mp}K^{\\pm}$",
            "updated": "2023-10-24T08:12:54Z",
            "published": "2023-08-01T15:03:25Z",
            "summary": "This paper reports the observation of the decays $B_{(s)}^{0}\\to\nD_{s1}(2536)^{\\mp}K^{\\pm}$ using proton-proton collision data collected by the\nLHCb experiment, corresponding to an integrated luminosity of\n$9\\,\\mathrm{fb}^{-1}$. The branching fractions of these decays are measured\nrelative to the normalisation channel $B^{0}\\to \\overline{D}^{0}K^{+}K^{-}$.\nThe $D_{s1}(2536)^{-}$ meson is reconstructed in the\n$\\overline{D}^{*}(2007)^{0}K^{-}$ decay channel and the products of branching\nfractions are measured to be $$\\mathcal{B}(B_{s}^{0}\\to\nD_{s1}(2536)^{\\mp}K^{\\pm})\\times\\mathcal{B}(D_{s1}(2536)^{-}\\to\\overline{D}^{*}(2007)^{0}K^{-})=(2.49\\pm0.11\\pm0.12\\pm0.25\\pm0.06)\\times\n10^{-5}, $$ $$\\mathcal{B}(B^{0}\\to\nD_{s1}(2536)^{\\mp}K^{\\pm})\\times\\mathcal{B}(D_{s1}(2536)^{-}\\to\\overline{D}^{*}(2007)^{0}K^{-})\n= (0.510\\pm0.021\\pm0.036\\pm0.050)\\times 10^{-5}.$$ The first uncertainty is\nstatistical, the second systematic, and the third arises from the uncertainty\nof the branching fraction of the $B^{0}\\to \\overline{D}^{0}K^{+}K^{-}$\nnormalisation channel. The last uncertainty in the $B_{s}^{0}$ result is due to\nthe limited knowledge of the fragmentation fraction ratio, $f_{s}/f_{d}$. The\nsignificance for the $B_{s}^{0}$ and $B^{0}$ signals is larger than\n$10\\,\\sigma$. The ratio of the helicity amplitudes which governs the angular\ndistribution of the $D_{s1}(2536)^{-}\\to\\overline{D}^{*}(2007)^{0}K^{-}$ decay\nis determined from the data. The ratio of the $S$- and $D$-wave amplitudes is\nfound to be $1.11\\pm0.15\\pm 0.06$ and its phase $0.70\\pm0.09\\pm 0.04$ rad,\nwhere the first uncertainty is statistical and the second systematic.",
            "author": [
                "LHCb collaboration",
                "R. Aaij",
                "A. S. W. Abdelmotteleb",
                "C. Abellan Beteta",
                "F. Abudin\u00e9n",
                "T. Ackernley",
                "B. Adeva",
                "M. Adinolfi",
                "P. Adlarson",
                "H. Afsharnia",
                "C. Agapopoulou",
                "C. A. Aidala",
                "Z. Ajaltouni",
                "S. Akar",
                "K. Akiba",
                "P. Albicocco",
                "J. Albrecht",
                "F. Alessio",
                "M. Alexander",
                "A. Alfonso Albero",
                "Z. Aliouche",
                "P. Alvarez Cartelle",
                "R. Amalric",
                "S. Amato",
                "J. L. Amey",
                "Y. Amhis",
                "L. An",
                "L. Anderlini",
                "M. Andersson",
                "A. Andreianov",
                "P. Andreola",
                "M. Andreotti",
                "D. Andreou",
                "D. Ao",
                "F. Archilli",
                "A. Artamonov",
                "M. Artuso",
                "E. Aslanides",
                "M. Atzeni",
                "B. Audurier",
                "D. Bacher",
                "I. Bachiller Perea",
                "S. Bachmann",
                "M. Bachmayer",
                "J. J. Back",
                "A. Bailly-reyre",
                "P. Baladron Rodriguez",
                "V. Balagura",
                "W. Baldini",
                "J. Baptista de Souza Leite",
                "M. Barbetti",
                "I. R. Barbosa",
                "R. J. Barlow",
                "S. Barsuk",
                "W. Barter",
                "M. Bartolini",
                "F. Baryshnikov",
                "J. M. Basels",
                "G. Bassi",
                "B. Batsukh",
                "A. Battig",
                "A. Bay",
                "A. Beck",
                "M. Becker",
                "F. Bedeschi",
                "I. B. Bediaga",
                "A. Beiter",
                "S. Belin",
                "V. Bellee",
                "K. Belous",
                "I. Belov",
                "I. Belyaev",
                "G. Benane",
                "G. Bencivenni",
                "E. Ben-Haim",
                "A. Berezhnoy",
                "R. Bernet",
                "S. Bernet Andres",
                "D. Berninghoff",
                "H. C. Bernstein",
                "C. Bertella",
                "A. Bertolin",
                "C. Betancourt",
                "F. Betti",
                "J. Bex",
                "Ia. Bezshyiko",
                "J. Bhom",
                "L. Bian",
                "M. S. Bieker",
                "N. V. Biesuz",
                "P. Billoir",
                "A. Biolchini",
                "M. Birch",
                "F. C. R. Bishop",
                "A. Bitadze",
                "A. Bizzeti",
                "M. P. Blago",
                "T. Blake",
                "F. Blanc",
                "J. E. Blank",
                "S. Blusk",
                "D. Bobulska",
                "V. Bocharnikov",
                "J. A. Boelhauve",
                "O. Boente Garcia",
                "T. Boettcher",
                "A. Bohare",
                "A. Boldyrev",
                "C. S. Bolognani",
                "R. Bolzonella",
                "N. Bondar",
                "F. Borgato",
                "S. Borghi",
                "M. Borsato",
                "J. T. Borsuk",
                "S. A. Bouchiba",
                "T. J. V. Bowcock",
                "A. Boyer",
                "C. Bozzi",
                "M. J. Bradley",
                "S. Braun",
                "A. Brea Rodriguez",
                "N. Breer",
                "J. Brodzicka",
                "A. Brossa Gonzalo",
                "J. Brown",
                "D. Brundu",
                "A. Buonaura",
                "L. Buonincontri",
                "A. T. Burke",
                "C. Burr",
                "A. Bursche",
                "A. Butkevich",
                "J. S. Butter",
                "J. Buytaert",
                "W. Byczynski",
                "S. Cadeddu",
                "H. Cai",
                "R. Calabrese",
                "L. Calefice",
                "S. Cali",
                "M. Calvi",
                "M. Calvo Gomez",
                "J. Cambon Bouzas",
                "P. Campana",
                "D. H. Campora Perez",
                "A. F. Campoverde Quezada",
                "S. Capelli",
                "L. Capriotti",
                "A. Carbone",
                "L. Carcedo Salgado",
                "R. Cardinale",
                "A. Cardini",
                "P. Carniti",
                "L. Carus",
                "A. Casais Vidal",
                "R. Caspary",
                "G. Casse",
                "M. Cattaneo",
                "G. Cavallero",
                "V. Cavallini",
                "S. Celani",
                "J. Cerasoli",
                "D. Cervenkov",
                "A. J. Chadwick",
                "I. Chahrour",
                "M. G. Chapman",
                "M. Charles",
                "Ph. Charpentier",
                "C. A. Chavez Barajas",
                "M. Chefdeville",
                "C. Chen",
                "S. Chen",
                "A. Chernov",
                "S. Chernyshenko",
                "V. Chobanova",
                "S. Cholak",
                "M. Chrzaszcz",
                "A. Chubykin",
                "V. Chulikov",
                "P. Ciambrone",
                "M. F. Cicala",
                "X. Cid Vidal",
                "G. Ciezarek",
                "P. Cifra",
                "G. Ciullo",
                "P. E. L. Clarke",
                "M. Clemencic",
                "H. V. Cliff",
                "J. Closier",
                "J. L. Cobbledick",
                "C. Cocha Toapaxi",
                "V. Coco",
                "J. Cogan",
                "E. Cogneras",
                "L. Cojocariu",
                "P. Collins",
                "T. Colombo",
                "A. Comerma-Montells",
                "L. Congedo",
                "A. Contu",
                "N. Cooke",
                "I. Corredoira",
                "A. Correia",
                "G. Corti",
                "J. J. Cottee Meldrum",
                "B. Couturier",
                "D. C. Craik",
                "M. Cruz Torres",
                "R. Currie",
                "C. L. Da Silva",
                "S. Dadabaev",
                "L. Dai",
                "X. Dai",
                "E. Dall'Occo",
                "J. Dalseno",
                "C. D'Ambrosio",
                "J. Daniel",
                "A. Danilina",
                "P. d'Argent",
                "A. Davidson",
                "J. E. Davies",
                "A. Davis",
                "O. De Aguiar Francisco",
                "J. de Boer",
                "K. De Bruyn",
                "S. De Capua",
                "M. De Cian",
                "U. De Freitas Carneiro Da Graca",
                "E. De Lucia",
                "J. M. De Miranda",
                "L. De Paula",
                "M. De Serio",
                "D. De Simone",
                "P. De Simone",
                "F. De Vellis",
                "J. A. de Vries",
                "C. T. Dean",
                "F. Debernardis",
                "D. Decamp",
                "V. Dedu",
                "L. Del Buono",
                "B. Delaney",
                "H. -P. Dembinski",
                "V. Denysenko",
                "O. Deschamps",
                "F. Dettori",
                "B. Dey",
                "P. Di Nezza",
                "I. Diachkov",
                "S. Didenko",
                "S. Ding",
                "V. Dobishuk",
                "A. D. Docheva",
                "A. Dolmatov",
                "C. Dong",
                "A. M. Donohoe",
                "F. Dordei",
                "A. C. dos Reis",
                "L. Douglas",
                "A. G. Downes",
                "W. Duan",
                "P. Duda",
                "M. W. Dudek",
                "L. Dufour",
                "V. Duk",
                "P. Durante",
                "M. M. Duras",
                "J. M. Durham",
                "D. Dutta",
                "A. Dziurda",
                "A. Dzyuba",
                "S. Easo",
                "E. Eckstein",
                "U. Egede",
                "A. Egorychev",
                "V. Egorychev",
                "C. Eirea Orro",
                "S. Eisenhardt",
                "E. Ejopu",
                "S. Ek-In",
                "L. Eklund",
                "M. Elashri",
                "J. Ellbracht",
                "S. Ely",
                "A. Ene",
                "E. Epple",
                "S. Escher",
                "J. Eschle",
                "S. Esen",
                "T. Evans",
                "F. Fabiano",
                "L. N. Falcao",
                "Y. Fan",
                "B. Fang",
                "L. Fantini",
                "M. Faria",
                "K. Farmer",
                "S. Farry",
                "D. Fazzini",
                "L. Felkowski",
                "M. Feng",
                "M. Feo",
                "M. Fernandez Gomez",
                "A. D. Fernez",
                "F. Ferrari",
                "L. Ferreira Lopes",
                "F. Ferreira Rodrigues",
                "S. Ferreres Sole",
                "M. Ferrillo",
                "M. Ferro-Luzzi",
                "S. Filippov",
                "R. A. Fini",
                "M. Fiorini",
                "M. Firlej",
                "K. M. Fischer",
                "D. S. Fitzgerald",
                "C. Fitzpatrick",
                "T. Fiutowski",
                "F. Fleuret",
                "M. Fontana",
                "F. Fontanelli",
                "L. F. Foreman",
                "R. Forty",
                "D. Foulds-Holt",
                "M. Franco Sevilla",
                "M. Frank",
                "E. Franzoso",
                "G. Frau",
                "C. Frei",
                "D. A. Friday",
                "L. Frontini",
                "J. Fu",
                "Q. Fuehring",
                "Y. Fujii",
                "T. Fulghesu",
                "E. Gabriel",
                "G. Galati",
                "M. D. Galati",
                "A. Gallas Torreira",
                "D. Galli",
                "S. Gambetta",
                "M. Gandelman",
                "P. Gandini",
                "H. Gao",
                "R. Gao",
                "Y. Gao",
                "Y. Gao",
                "M. Garau",
                "L. M. Garcia Martin",
                "P. Garcia Moreno",
                "J. Garc\u00eda Pardi\u00f1as",
                "B. Garcia Plana",
                "F. A. Garcia Rosales",
                "L. Garrido",
                "C. Gaspar",
                "R. E. Geertsema",
                "L. L. Gerken",
                "E. Gersabeck",
                "M. Gersabeck",
                "T. Gershon",
                "L. Giambastiani",
                "F. I. Giasemis",
                "V. Gibson",
                "H. K. Giemza",
                "A. L. Gilman",
                "M. Giovannetti",
                "A. Giovent\u00f9",
                "P. Gironella Gironell",
                "C. Giugliano",
                "M. A. Giza",
                "K. Gizdov",
                "E. L. Gkougkousis",
                "F. C. Glaser",
                "V. V. Gligorov",
                "C. G\u00f6bel",
                "E. Golobardes",
                "D. Golubkov",
                "A. Golutvin",
                "A. Gomes",
                "S. Gomez Fernandez",
                "F. Goncalves Abrantes",
                "M. Goncerz",
                "G. Gong",
                "J. A. Gooding",
                "I. V. Gorelov",
                "C. Gotti",
                "J. P. Grabowski",
                "L. A. Granado Cardoso",
                "E. Graug\u00e9s",
                "E. Graverini",
                "L. Grazette",
                "G. Graziani",
                "A. T. Grecu",
                "L. M. Greeven",
                "N. A. Grieser",
                "L. Grillo",
                "S. Gromov",
                "C. Gu",
                "M. Guarise",
                "M. Guittiere",
                "V. Guliaeva",
                "P. A. G\u00fcnther",
                "A. K. Guseinov",
                "E. Gushchin",
                "Y. Guz",
                "T. Gys",
                "T. Hadavizadeh",
                "C. Hadjivasiliou",
                "G. Haefeli",
                "C. Haen",
                "J. Haimberger",
                "S. C. Haines",
                "M. Hajheidari",
                "T. Halewood-leagas",
                "M. M. Halvorsen",
                "P. M. Hamilton",
                "J. Hammerich",
                "Q. Han",
                "X. Han",
                "S. Hansmann-Menzemer",
                "L. Hao",
                "N. Harnew",
                "T. Harrison",
                "M. Hartmann",
                "C. Hasse",
                "M. Hatch",
                "J. He",
                "K. Heijhoff",
                "F. Hemmer",
                "C. Henderson",
                "R. D. L. Henderson",
                "A. M. Hennequin",
                "K. Hennessy",
                "L. Henry",
                "J. Herd",
                "J. Heuel",
                "A. Hicheur",
                "D. Hill",
                "M. Hilton",
                "S. E. Hollitt",
                "J. Horswill",
                "R. Hou",
                "Y. Hou",
                "N. Howarth",
                "J. Hu",
                "J. Hu",
                "W. Hu",
                "X. Hu",
                "W. Huang",
                "X. Huang",
                "W. Hulsbergen",
                "R. J. Hunter",
                "M. Hushchyn",
                "D. Hutchcroft",
                "P. Ibis",
                "M. Idzik",
                "D. Ilin",
                "P. Ilten",
                "A. Inglessi",
                "A. Iniukhin",
                "A. Ishteev",
                "K. Ivshin",
                "R. Jacobsson",
                "H. Jage",
                "S. J. Jaimes Elles",
                "S. Jakobsen",
                "E. Jans",
                "B. K. Jashal",
                "A. Jawahery",
                "V. Jevtic",
                "E. Jiang",
                "X. Jiang",
                "Y. Jiang",
                "Y. J. Jiang",
                "M. John",
                "D. Johnson",
                "C. R. Jones",
                "T. P. Jones",
                "S. Joshi",
                "B. Jost",
                "N. Jurik",
                "I. Juszczak",
                "D. Kaminaris",
                "S. Kandybei",
                "Y. Kang",
                "M. Karacson",
                "D. Karpenkov",
                "M. Karpov",
                "A. M. Kauniskangas",
                "J. W. Kautz",
                "F. Keizer",
                "D. M. Keller",
                "M. Kenzie",
                "T. Ketel",
                "B. Khanji",
                "A. Kharisova",
                "S. Kholodenko",
                "G. Khreich",
                "T. Kirn",
                "V. S. Kirsebom",
                "O. Kitouni",
                "S. Klaver",
                "N. Kleijne",
                "K. Klimaszewski",
                "M. R. Kmiec",
                "S. Koliiev",
                "L. Kolk",
                "A. Kondybayeva",
                "A. Konoplyannikov",
                "P. Kopciewicz",
                "R. Kopecna",
                "P. Koppenburg",
                "M. Korolev",
                "I. Kostiuk",
                "O. Kot",
                "S. Kotriakhova",
                "A. Kozachuk",
                "P. Kravchenko",
                "L. Kravchuk",
                "M. Kreps",
                "S. Kretzschmar",
                "P. Krokovny",
                "W. Krupa",
                "W. Krzemien",
                "J. Kubat",
                "S. Kubis",
                "W. Kucewicz",
                "M. Kucharczyk",
                "V. Kudryavtsev",
                "E. Kulikova",
                "A. Kupsc",
                "B. K. Kutsenko",
                "D. Lacarrere",
                "G. Lafferty",
                "A. Lai",
                "A. Lampis",
                "D. Lancierini",
                "C. Landesa Gomez",
                "J. J. Lane",
                "R. Lane",
                "C. Langenbruch",
                "J. Langer",
                "O. Lantwin",
                "T. Latham",
                "F. Lazzari",
                "C. Lazzeroni",
                "R. Le Gac",
                "S. H. Lee",
                "R. Lef\u00e8vre",
                "A. Leflat",
                "S. Legotin",
                "P. Lenisa",
                "O. Leroy",
                "T. Lesiak",
                "B. Leverington",
                "A. Li",
                "H. Li",
                "K. Li",
                "L. Li",
                "P. Li",
                "P. -R. Li",
                "S. Li",
                "T. Li",
                "T. Li",
                "Y. Li",
                "Z. Li",
                "Z. Lian",
                "X. Liang",
                "C. Lin",
                "T. Lin",
                "R. Lindner",
                "V. Lisovskyi",
                "R. Litvinov",
                "G. Liu",
                "H. Liu",
                "K. Liu",
                "Q. Liu",
                "S. Liu",
                "Y. Liu",
                "Y. Liu",
                "A. Lobo Salvia",
                "A. Loi",
                "J. Lomba Castro",
                "T. Long",
                "I. Longstaff",
                "J. H. Lopes",
                "A. Lopez Huertas",
                "S. L\u00f3pez Soli\u00f1o",
                "G. H. Lovell",
                "Y. Lu",
                "C. Lucarelli",
                "D. Lucchesi",
                "S. Luchuk",
                "M. Lucio Martinez",
                "V. Lukashenko",
                "Y. Luo",
                "A. Lupato",
                "E. Luppi",
                "K. Lynch",
                "X. -R. Lyu",
                "R. Ma",
                "S. Maccolini",
                "F. Machefert",
                "F. Maciuc",
                "I. Mackay",
                "L. R. Madhan Mohan",
                "M. M. Madurai",
                "A. Maevskiy",
                "D. Magdalinski",
                "D. Maisuzenko",
                "M. W. Majewski",
                "J. J. Malczewski",
                "S. Malde",
                "B. Malecki",
                "L. Malentacca",
                "A. Malinin",
                "T. Maltsev",
                "G. Manca",
                "G. Mancinelli",
                "C. Mancuso",
                "R. Manera Escalero",
                "D. Manuzzi",
                "C. A. Manzari",
                "D. Marangotto",
                "J. F. Marchand",
                "U. Marconi",
                "S. Mariani",
                "C. Marin Benito",
                "J. Marks",
                "A. M. Marshall",
                "P. J. Marshall",
                "G. Martelli",
                "G. Martellotti",
                "L. Martinazzoli",
                "M. Martinelli",
                "D. Martinez Santos",
                "F. Martinez Vidal",
                "A. Massafferri",
                "M. Materok",
                "R. Matev",
                "A. Mathad",
                "V. Matiunin",
                "C. Matteuzzi",
                "K. R. Mattioli",
                "A. Mauri",
                "E. Maurice",
                "J. Mauricio",
                "M. Mazurek",
                "M. McCann",
                "L. Mcconnell",
                "T. H. McGrath",
                "N. T. McHugh",
                "A. McNab",
                "R. McNulty",
                "B. Meadows",
                "G. Meier",
                "D. Melnychuk",
                "M. Merk",
                "A. Merli",
                "L. Meyer Garcia",
                "D. Miao",
                "H. Miao",
                "M. Mikhasenko",
                "D. A. Milanes",
                "M. -N. Minard",
                "A. Minotti",
                "E. Minucci",
                "T. Miralles",
                "S. E. Mitchell",
                "B. Mitreska",
                "D. S. Mitzel",
                "A. Modak",
                "A. M\u00f6dden",
                "R. A. Mohammed",
                "R. D. Moise",
                "S. Mokhnenko",
                "T. Momb\u00e4cher",
                "M. Monk",
                "I. A. Monroy",
                "S. Monteil",
                "A. Morcillo Gomez",
                "G. Morello",
                "M. J. Morello",
                "M. P. Morgenthaler",
                "J. Moron",
                "A. B. Morris",
                "A. G. Morris",
                "R. Mountain",
                "H. Mu",
                "Z. M. Mu",
                "E. Muhammad",
                "F. Muheim",
                "M. Mulder",
                "K. M\u00fcller",
                "F. M\u0169noz-Rojas",
                "R. Murta",
                "P. Naik",
                "T. Nakada",
                "R. Nandakumar",
                "T. Nanut",
                "I. Nasteva",
                "M. Needham",
                "N. Neri",
                "S. Neubert",
                "N. Neufeld",
                "P. Neustroev",
                "R. Newcombe",
                "J. Nicolini",
                "D. Nicotra",
                "E. M. Niel",
                "N. Nikitin",
                "P. Nogga",
                "N. S. Nolte",
                "C. Normand",
                "J. Novoa Fernandez",
                "G. Nowak",
                "C. Nunez",
                "H. N. Nur",
                "A. Oblakowska-Mucha",
                "V. Obraztsov",
                "T. Oeser",
                "S. Okamura",
                "R. Oldeman",
                "F. Oliva",
                "M. Olocco",
                "C. J. G. Onderwater",
                "R. H. O'Neil",
                "J. M. Otalora Goicochea",
                "T. Ovsiannikova",
                "P. Owen",
                "A. Oyanguren",
                "O. Ozcelik",
                "K. O. Padeken",
                "B. Pagare",
                "P. R. Pais",
                "T. Pajero",
                "A. Palano",
                "M. Palutan",
                "G. Panshin",
                "L. Paolucci",
                "A. Papanestis",
                "M. Pappagallo",
                "L. L. Pappalardo",
                "C. Pappenheimer",
                "C. Parkes",
                "B. Passalacqua",
                "G. Passaleva",
                "D. Passaro",
                "A. Pastore",
                "M. Patel",
                "J. Patoc",
                "C. Patrignani",
                "C. J. Pawley",
                "A. Pellegrino",
                "M. Pepe Altarelli",
                "S. Perazzini",
                "D. Pereima",
                "A. Pereiro Castro",
                "P. Perret",
                "A. Perro",
                "K. Petridis",
                "A. Petrolini",
                "S. Petrucci",
                "H. Pham",
                "A. Philippov",
                "L. Pica",
                "M. Piccini",
                "B. Pietrzyk",
                "G. Pietrzyk",
                "D. Pinci",
                "F. Pisani",
                "M. Pizzichemi",
                "V. Placinta",
                "M. Plo Casasus",
                "F. Polci",
                "M. Poli Lener",
                "A. Poluektov",
                "N. Polukhina",
                "I. Polyakov",
                "E. Polycarpo",
                "S. Ponce",
                "D. Popov",
                "S. Poslavskii",
                "K. Prasanth",
                "L. Promberger",
                "C. Prouve",
                "V. Pugatch",
                "V. Puill",
                "G. Punzi",
                "H. R. Qi",
                "W. Qian",
                "N. Qin",
                "S. Qu",
                "R. Quagliani",
                "B. Rachwal",
                "J. H. Rademacker",
                "R. Rajagopalan",
                "M. Rama",
                "M. Ram\u00edrez Garc\u00eda",
                "M. Ramos Pernas",
                "M. S. Rangel",
                "F. Ratnikov",
                "G. Raven",
                "M. Rebollo De Miguel",
                "F. Redi",
                "J. Reich",
                "F. Reiss",
                "Z. Ren",
                "P. K. Resmi",
                "R. Ribatti",
                "G. R. Ricart",
                "D. Riccardi",
                "S. Ricciardi",
                "K. Richardson",
                "M. Richardson-Slipper",
                "K. Rinnert",
                "P. Robbe",
                "G. Robertson",
                "E. Rodrigues",
                "E. Rodriguez Fernandez",
                "J. A. Rodriguez Lopez",
                "E. Rodriguez Rodriguez",
                "A. Rogovskiy",
                "D. L. Rolf",
                "A. Rollings",
                "P. Roloff",
                "V. Romanovskiy",
                "M. Romero Lamas",
                "A. Romero Vidal",
                "G. Romolini",
                "F. Ronchetti",
                "M. Rotondo",
                "M. S. Rudolph",
                "T. Ruf",
                "R. A. Ruiz Fernandez",
                "J. Ruiz Vidal",
                "A. Ryzhikov",
                "J. Ryzka",
                "J. J. Saborido Silva",
                "N. Sagidova",
                "N. Sahoo",
                "B. Saitta",
                "M. Salomoni",
                "C. Sanchez Gras",
                "I. Sanderswood",
                "R. Santacesaria",
                "C. Santamarina Rios",
                "M. Santimaria",
                "L. Santoro",
                "E. Santovetti",
                "D. Saranin",
                "G. Sarpis",
                "M. Sarpis",
                "A. Sarti",
                "C. Satriano",
                "A. Satta",
                "M. Saur",
                "D. Savrina",
                "H. Sazak",
                "L. G. Scantlebury Smead",
                "A. Scarabotto",
                "S. Schael",
                "S. Scherl",
                "A. M. Schertz",
                "M. Schiller",
                "H. Schindler",
                "M. Schmelling",
                "B. Schmidt",
                "S. Schmitt",
                "O. Schneider",
                "A. Schopper",
                "M. Schubiger",
                "N. Schulte",
                "S. Schulte",
                "M. H. Schune",
                "R. Schwemmer",
                "G. Schwering",
                "B. Sciascia",
                "A. Sciuccati",
                "S. Sellam",
                "A. Semennikov",
                "M. Senghi Soares",
                "A. Sergi",
                "N. Serra",
                "L. Sestini",
                "A. Seuthe",
                "Y. Shang",
                "D. M. Shangase",
                "M. Shapkin",
                "I. Shchemerov",
                "L. Shchutska",
                "T. Shears",
                "L. Shekhtman",
                "Z. Shen",
                "S. Sheng",
                "V. Shevchenko",
                "B. Shi",
                "E. B. Shields",
                "Y. Shimizu",
                "E. Shmanin",
                "R. Shorkin",
                "J. D. Shupperd",
                "B. G. Siddi",
                "R. Silva Coutinho",
                "G. Simi",
                "S. Simone",
                "M. Singla",
                "N. Skidmore",
                "R. Skuza",
                "T. Skwarnicki",
                "M. W. Slater",
                "J. C. Smallwood",
                "J. G. Smeaton",
                "E. Smith",
                "K. Smith",
                "M. Smith",
                "A. Snoch",
                "L. Soares Lavra",
                "M. D. Sokoloff",
                "F. J. P. Soler",
                "A. Solomin",
                "A. Solovev",
                "I. Solovyev",
                "R. Song",
                "Y. Song",
                "Y. Song",
                "Y. S. Song",
                "F. L. Souza De Almeida",
                "B. Souza De Paula",
                "E. Spadaro Norella",
                "E. Spedicato",
                "J. G. Speer",
                "E. Spiridenkov",
                "P. Spradlin",
                "V. Sriskaran",
                "F. Stagni",
                "M. Stahl",
                "S. Stahl",
                "S. Stanislaus",
                "E. N. Stein",
                "O. Steinkamp",
                "O. Stenyakin",
                "H. Stevens",
                "D. Strekalina",
                "Y. Su",
                "F. Suljik",
                "J. Sun",
                "L. Sun",
                "Y. Sun",
                "P. N. Swallow",
                "K. Swientek",
                "F. Swystun",
                "A. Szabelski",
                "T. Szumlak",
                "M. Szymanski",
                "Y. Tan",
                "S. Taneja",
                "M. D. Tat",
                "A. Terentev",
                "F. Teubert",
                "E. Thomas",
                "D. J. D. Thompson",
                "H. Tilquin",
                "V. Tisserand",
                "S. T'Jampens",
                "M. Tobin",
                "L. Tomassetti",
                "G. Tonani",
                "X. Tong",
                "D. Torres Machado",
                "L. Toscano",
                "D. Y. Tou",
                "C. Trippl",
                "G. Tuci",
                "N. Tuning",
                "A. Ukleja",
                "D. J. Unverzagt",
                "E. Ursov",
                "A. Usachov",
                "A. Ustyuzhanin",
                "U. Uwer",
                "V. Vagnoni",
                "A. Valassi",
                "G. Valenti",
                "N. Valls Canudas",
                "M. Van Dijk",
                "H. Van Hecke",
                "E. van Herwijnen",
                "C. B. Van Hulse",
                "R. Van Laak",
                "M. van Veghel",
                "R. Vazquez Gomez",
                "P. Vazquez Regueiro",
                "C. V\u00e1zquez Sierra",
                "S. Vecchi",
                "J. J. Velthuis",
                "M. Veltri",
                "A. Venkateswaran",
                "M. Vesterinen",
                "D. Vieira",
                "M. Vieites Diaz",
                "X. Vilasis-Cardona",
                "E. Vilella Figueras",
                "A. Villa",
                "P. Vincent",
                "F. C. Volle",
                "D. vom Bruch",
                "V. Vorobyev",
                "N. Voropaev",
                "K. Vos",
                "C. Vrahas",
                "J. Walsh",
                "E. J. Walton",
                "G. Wan",
                "C. Wang",
                "G. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "M. Wang",
                "N. W. Wang",
                "R. Wang",
                "X. Wang",
                "Y. Wang",
                "Z. Wang",
                "Z. Wang",
                "Z. Wang",
                "J. A. Ward",
                "N. K. Watson",
                "D. Websdale",
                "Y. Wei",
                "B. D. C. Westhenry",
                "D. J. White",
                "M. Whitehead",
                "A. R. Wiederhold",
                "D. Wiedner",
                "G. Wilkinson",
                "M. K. Wilkinson",
                "I. Williams",
                "M. Williams",
                "M. R. J. Williams",
                "R. Williams",
                "F. F. Wilson",
                "W. Wislicki",
                "M. Witek",
                "L. Witola",
                "C. P. Wong",
                "G. Wormser",
                "S. A. Wotton",
                "H. Wu",
                "J. Wu",
                "Y. Wu",
                "K. Wyllie",
                "S. Xian",
                "Z. Xiang",
                "Y. Xie",
                "A. Xu",
                "J. Xu",
                "L. Xu",
                "L. Xu",
                "M. Xu",
                "Z. Xu",
                "Z. Xu",
                "Z. Xu",
                "D. Yang",
                "S. Yang",
                "X. Yang",
                "Y. Yang",
                "Z. Yang",
                "Z. Yang",
                "V. Yeroshenko",
                "H. Yeung",
                "H. Yin",
                "C. Y. Yu",
                "J. Yu",
                "X. Yuan",
                "E. Zaffaroni",
                "M. Zavertyaev",
                "M. Zdybal",
                "M. Zeng",
                "C. Zhang",
                "D. Zhang",
                "J. Zhang",
                "L. Zhang",
                "S. Zhang",
                "S. Zhang",
                "Y. Zhang",
                "Y. Zhang",
                "Y. Zhao",
                "A. Zharkova",
                "A. Zhelezov",
                "Y. Zheng",
                "T. Zhou",
                "X. Zhou",
                "Y. Zhou",
                "V. Zhovkovska",
                "L. Z. Zhu",
                "X. Zhu",
                "X. Zhu",
                "Z. Zhu",
                "V. Zhukov",
                "J. Zhuo",
                "Q. Zou",
                "S. Zucchelli",
                "D. Zuliani",
                "G. Zunica"
            ],
            "link": [
                "http://dx.doi.org/10.1007/JHEP10(2023)106",
                "http://arxiv.org/abs/2308.00587v2",
                "http://arxiv.org/pdf/2308.00587v2"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00581v1",
            "title": "New results on the 1-isolation number of graphs without short cycles",
            "updated": "2023-08-01T14:53:17Z",
            "published": "2023-08-01T14:53:17Z",
            "summary": "Let $G$ be a graph. A subset $D \\subseteq V(G)$ is called a 1-isolating set\nof $G$ if $\\Delta(G-N[D]) \\leq 1$, that is, $G-N[D]$ consists of isolated edges\nand isolated vertices only. The $1$-isolation number of $G$, denoted by\n$\\iota_1(G)$, is the cardinality of a smallest $1$-isolating set of $G$. In\nthis paper, we prove that if $G \\notin \\{P_3,C_3,C_7,C_{11}\\}$ is a connected\ngraph of order $n$ without $6$-cycles, or without induced 5- and 6-cycles, then\n$\\iota_1(G) \\leq \\frac{n}{4}$. Both bounds are sharp.",
            "author": [
                "Yirui Huang",
                "Gang Zhang",
                "Xian'an Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00581v1",
                "http://arxiv.org/pdf/2308.00581v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C69"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01419v1",
            "title": "Graph Neural Networks for Forecasting Multivariate Realized Volatility\n  with Spillover Effects",
            "updated": "2023-08-01T14:39:03Z",
            "published": "2023-08-01T14:39:03Z",
            "summary": "We present a novel methodology for modeling and forecasting multivariate\nrealized volatilities using customized graph neural networks to incorporate\nspillover effects across stocks. The proposed model offers the benefits of\nincorporating spillover effects from multi-hop neighbors, capturing nonlinear\nrelationships, and flexible training with different loss functions. Our\nempirical findings provide compelling evidence that incorporating spillover\neffects from multi-hop neighbors alone does not yield a clear advantage in\nterms of predictive accuracy. However, modeling nonlinear spillover effects\nenhances the forecasting accuracy of realized volatilities, particularly for\nshort-term horizons of up to one week. Moreover, our results consistently\nindicate that training with the Quasi-likelihood loss leads to substantial\nimprovements in model performance compared to the commonly-used mean squared\nerror. A comprehensive series of empirical evaluations in alternative settings\nconfirm the robustness of our results.",
            "author": [
                "Chao Zhang",
                "Xingyue Pu",
                "Mihai Cucuringu",
                "Xiaowen Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01419v1",
                "http://arxiv.org/pdf/2308.01419v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG",
                "q-fin.RM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00574v1",
            "title": "PVG: Progressive Vision Graph for Vision Recognition",
            "updated": "2023-08-01T14:35:29Z",
            "published": "2023-08-01T14:35:29Z",
            "summary": "Convolution-based and Transformer-based vision backbone networks process\nimages into the grid or sequence structures, respectively, which are inflexible\nfor capturing irregular objects. Though Vision GNN (ViG) adopts graph-level\nfeatures for complex images, it has some issues, such as inaccurate neighbor\nnode selection, expensive node information aggregation calculation, and\nover-smoothing in the deep layers. To address the above problems, we propose a\nProgressive Vision Graph (PVG) architecture for vision recognition task.\nCompared with previous works, PVG contains three main components: 1)\nProgressively Separated Graph Construction (PSGC) to introduce second-order\nsimilarity by gradually increasing the channel of the global graph branch and\ndecreasing the channel of local branch as the layer deepens; 2) Neighbor nodes\ninformation aggregation and update module by using Max pooling and mathematical\nExpectation (MaxE) to aggregate rich neighbor information; 3) Graph error\nLinear Unit (GraphLU) to enhance low-value information in a relaxed form to\nreduce the compression of image detail information for alleviating the\nover-smoothing. Extensive experiments on mainstream benchmarks demonstrate the\nsuperiority of PVG over state-of-the-art methods, e.g., our PVG-S obtains 83.0%\nTop-1 accuracy on ImageNet-1K that surpasses GNN-based ViG-S by +0.9 with the\nparameters reduced by 18.5%, while the largest PVG-B obtains 84.2% that has\n+0.5 improvement than ViG-B. Furthermore, our PVG-S obtains +1.3 box AP and\n+0.4 mask AP gains than ViG-S on COCO dataset.",
            "author": [
                "Jiafu Wu",
                "Jian Li",
                "Jiangning Zhang",
                "Boshen Zhang",
                "Mingmin Chi",
                "Yabiao Wang",
                "Chengjie Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612122",
                "http://arxiv.org/abs/2308.00574v1",
                "http://arxiv.org/pdf/2308.00574v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00569v2",
            "title": "A New View on the Application of Gold Nanoparticles in Cancer Therapy",
            "updated": "2023-08-03T04:26:13Z",
            "published": "2023-08-01T14:17:21Z",
            "summary": "In biomedical research and the practice of cancer therapy, gold nanoparticles\nhave been used to visualize malignant tumors, as the heated bodies for\nhyperthermia of cancer cells, as drug carriers to deliver drugs to a cancer\ncell, but, to the best of our knowledge, they have not yet been used\nconsciously as the sources of terahertz (THz) radiation delivered to a cancer\ncell that contributes to the inhibition of cell activity. It is predicted here\nthat gold nanoparticles less than 8 nm in size are sources of spontaneous THz\nradiation, and the possibility of their application in oncology is due to the\nknown effects of THz radiation on the cells of living organisms. There are\nindications that nanoparticles with a size comparable to the width of the major\ngroove of the DNA molecule will be the most effective. Another effect that has\nnot yet been taken into account in biomedical studies using gold nanoparticles\nis that of local electric fields due to the contact potential difference above\nedges and vertices of gold nanoclusters. The prerequisites and possibilities\nfor searching for the manifestations of these two effects when gold\nnanoparticles are introduced into living cells of organisms are considered.",
            "author": [
                "A. M. Dadabaev",
                "Yu. Kh. -M. Shidakov",
                "V. M. Lelevkin",
                "A. A. Sorokin",
                "K. A. Moldosanov"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00569v2",
                "http://arxiv.org/pdf/2308.00569v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00565v1",
            "title": "AOSoar: Autonomous Orographic Soaring of a Micro Air Vehicle",
            "updated": "2023-08-01T14:09:19Z",
            "published": "2023-08-01T14:09:19Z",
            "summary": "Utilizing wind hovering techniques of soaring birds can save energy\nexpenditure and improve the flight endurance of micro air vehicles (MAVs).\nHere, we present a novel method for fully autonomous orographic soaring without\na priori knowledge of the wind field. Specifically, we devise an Incremental\nNonlinear Dynamic Inversion (INDI) controller with control allocation, adapting\nit for autonomous soaring. This allows for both soaring and the use of the\nthrottle if necessary, without changing any gain or parameter during the\nflight. Furthermore, we propose a simulated-annealing-based optimization method\nto search for soaring positions. This enables for the first time an MAV to\nautonomously find a feasible soaring position while minimizing throttle usage\nand other control efforts. Autonomous orographic soaring was performed in the\nwind tunnel. The wind speed and incline of a ramp were changed during the\nsoaring flight. The MAV was able to perform autonomous orographic soaring for\nflight times of up to 30 minutes. The mean throttle usage was only 0.25% for\nthe entire soaring flight, whereas normal powered flight requires 38%. Also, it\nwas shown that the MAV can find a new soaring spot when the wind field changes\nduring the flight.",
            "author": [
                "Sunyou Hwang",
                "Bart D. W. Remes",
                "Guido C. H. E. de Croon"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00565v1",
                "http://arxiv.org/pdf/2308.00565v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.02540v2",
            "title": "Top-down Automated Theorem Proving (Notes for Sir Timothy)",
            "updated": "2023-08-08T08:17:52Z",
            "published": "2023-08-01T14:03:40Z",
            "summary": "We describe a \"top down\" approach for automated theorem proving (ATP).\nResearchers might usefully investigate the forms of the theorems mathematicians\nuse in practice, carefully examine how they differ and are proved in practice,\nand code all relevant domain concepts. These concepts encode a large portion of\nthe knowledge in any domain. Furthermore, researchers should write programs\nthat produce proofs of the kind that human mathematicians write (and publish);\nthis means proofs that might sometimes have mistakes; and this means making\ninferences that are sometimes invalid.\n  This approach is meant to contrast with the historically dominant \"bottom up\"\napproach: coding fundamental types (typically sets), axioms and rules for\n(valid) inference, and building up from this foundation to the theorems of\nmathematical practice and to their outstanding questions. It is an important\nfact that the actual proofs that mathematicians publish in math journals do not\nlook like the formalized proofs of Russell & Whitehead's Principia Mathematica\n(or modern computer systems like Lean that automate some of this\nformalization). We believe some \"lack of rigor\" (in mathematical practice) is\nhuman-like, and can and should be leveraged for ATP.",
            "author": [
                "C. E. Larson",
                "N. Van Cleemput"
            ],
            "link": [
                "http://arxiv.org/abs/2308.02540v2",
                "http://arxiv.org/pdf/2308.02540v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "I.2.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00560v2",
            "title": "Reinforcement Learning-based Non-Autoregressive Solver for Traveling\n  Salesman Problems",
            "updated": "2023-10-18T01:47:29Z",
            "published": "2023-08-01T14:00:31Z",
            "summary": "The Traveling Salesman Problem (TSP) is a well-known combinatorial\noptimization problem with broad real-world applications. Recently, neural\nnetworks have gained popularity in this research area because they provide\nstrong heuristic solutions to TSPs. Compared to autoregressive neural\napproaches, non-autoregressive (NAR) networks exploit the inference parallelism\nto elevate inference speed but suffer from comparatively low solution quality.\nIn this paper, we propose a novel NAR model named NAR4TSP, which incorporates a\nspecially designed architecture and an enhanced reinforcement learning\nstrategy. To the best of our knowledge, NAR4TSP is the first TSP solver that\nsuccessfully combines RL and NAR networks. The key lies in the incorporation of\nNAR network output decoding into the training process. NAR4TSP efficiently\nrepresents TSP encoded information as rewards and seamlessly integrates it into\nreinforcement learning strategies, while maintaining consistent TSP sequence\nconstraints during both training and testing phases. Experimental results on\nboth synthetic and real-world TSP instances demonstrate that NAR4TSP\noutperforms four state-of-the-art models in terms of solution quality,\ninference speed, and generalization to unseen scenarios.",
            "author": [
                "Yubin Xiao",
                "Di Wang",
                "Boyang Li",
                "Huanhuan Chen",
                "Wei Pang",
                "Xuan Wu",
                "Hao Li",
                "Dong Xu",
                "Yanchun Liang",
                "You Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00560v2",
                "http://arxiv.org/pdf/2308.00560v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00537v1",
            "title": "Graph Embedding Dynamic Feature-based Supervised Contrastive Learning of\n  Transient Stability for Changing Power Grid Topologies",
            "updated": "2023-08-01T13:30:36Z",
            "published": "2023-08-01T13:30:36Z",
            "summary": "Accurate online transient stability prediction is critical for ensuring power\nsystem stability when facing disturbances. While traditional transient stablity\nanalysis replies on the time domain simulations can not be quickly adapted to\nthe power grid toplogy change. In order to vectorize high-dimensional power\ngrid topological structure information into low-dimensional node-based graph\nembedding streaming data, graph embedding dynamic feature (GEDF) has been\nproposed. The transient stability GEDF-based supervised contrastive learning\n(GEDF-SCL) model uses supervised contrastive learning to predict transient\nstability with GEDFs, considering power grid topology information. To evaluate\nthe performance of the proposed GEDF-SCL model, power grids of varying\ntopologies were generated based on the IEEE 39-bus system model. Transient\noperational data was obtained by simulating N-1 and N-$\\bm{m}$-1 contingencies\non these generated power system topologies. Test result demonstrated that the\nGEDF-SCL model can achieve high accuracy in transient stability prediction and\nadapt well to changing power grid topologies.",
            "author": [
                "Zijian Lv",
                "Xin Chen",
                "Zijian Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00537v1",
                "http://arxiv.org/pdf/2308.00537v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00535v1",
            "title": "Graph Contrastive Learning with Generative Adversarial Network",
            "updated": "2023-08-01T13:28:24Z",
            "published": "2023-08-01T13:28:24Z",
            "summary": "Graph Neural Networks (GNNs) have demonstrated promising results on\nexploiting node representations for many downstream tasks through supervised\nend-to-end training. To deal with the widespread label scarcity issue in\nreal-world applications, Graph Contrastive Learning (GCL) is leveraged to train\nGNNs with limited or even no labels by maximizing the mutual information\nbetween nodes in its augmented views generated from the original graph.\nHowever, the distribution of graphs remains unconsidered in view generation,\nresulting in the ignorance of unseen edges in most existing literature, which\nis empirically shown to be able to improve GCL's performance in our\nexperiments. To this end, we propose to incorporate graph generative\nadversarial networks (GANs) to learn the distribution of views for GCL, in\norder to i) automatically capture the characteristic of graphs for\naugmentations, and ii) jointly train the graph GAN model and the GCL model.\nSpecifically, we present GACN, a novel Generative Adversarial Contrastive\nlearning Network for graph representation learning. GACN develops a view\ngenerator and a view discriminator to generate augmented views automatically in\nan adversarial style. Then, GACN leverages these views to train a GNN encoder\nwith two carefully designed self-supervised learning losses, including the\ngraph contrastive loss and the Bayesian personalized ranking Loss. Furthermore,\nwe design an optimization framework to train all GACN modules jointly.\nExtensive experiments on seven real-world datasets show that GACN is able to\ngenerate high-quality augmented views for GCL and is superior to twelve\nstate-of-the-art baseline methods. Noticeably, our proposed GACN surprisingly\ndiscovers that the generated views in data augmentation finally conform to the\nwell-known preferential attachment rule in online networks.",
            "author": [
                "Cheng Wu",
                "Chaokun Wang",
                "Jingcao Xu",
                "Ziyang Liu",
                "Kai Zheng",
                "Xiaowei Wang",
                "Yang Song",
                "Kun Gai"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3580305.3599370",
                "http://arxiv.org/abs/2308.00535v1",
                "http://arxiv.org/pdf/2308.00535v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00520v1",
            "title": "NormKD: Normalized Logits for Knowledge Distillation",
            "updated": "2023-08-01T12:59:33Z",
            "published": "2023-08-01T12:59:33Z",
            "summary": "Logit based knowledge distillation gets less attention in recent years since\nfeature based methods perform better in most cases. Nevertheless, we find it\nstill has untapped potential when we re-investigate the temperature, which is a\ncrucial hyper-parameter to soften the logit outputs. For most of the previous\nworks, it was set as a fixed value for the entire distillation procedure.\nHowever, as the logits from different samples are distributed quite variously,\nit is not feasible to soften all of them to an equal degree by just a single\ntemperature, which may make the previous work transfer the knowledge of each\nsample inadequately. In this paper, we restudy the hyper-parameter temperature\nand figure out its incapability to distill the knowledge from each sample\nsufficiently when it is a single value. To address this issue, we propose\nNormalized Knowledge Distillation (NormKD), with the purpose of customizing the\ntemperature for each sample according to the characteristic of the sample's\nlogit distribution. Compared to the vanilla KD, NormKD barely has extra\ncomputation or storage cost but performs significantly better on CIRAR-100 and\nImageNet for image classification. Furthermore, NormKD can be easily applied to\nthe other logit based methods and achieve better performance which can be\ncloser to or even better than the feature based method.",
            "author": [
                "Zhihao Chi",
                "Tu Zheng",
                "Hengjia Li",
                "Zheng Yang",
                "Boxi Wu",
                "Binbin Lin",
                "Deng Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00520v1",
                "http://arxiv.org/pdf/2308.00520v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00514v1",
            "title": "Understanding URDF: A Dataset and Analysis",
            "updated": "2023-08-01T12:54:12Z",
            "published": "2023-08-01T12:54:12Z",
            "summary": "As the complexity of robot systems increases, it becomes more effective to\nsimulate them before deployment. To do this, a model of the robot's kinematics\nor dynamics is required, and the most commonly used format is the Unified Robot\nDescription Format (URDF). This article presents, to our knowledge, the first\ndataset of URDF files from various industrial and research organizations, with\nmetadata describing each robot, its type, manufacturer, and the source of the\nmodel. The dataset contains 322 URDF files of which 195 are unique robot\nmodels, meaning the excess URDFs are either of a robot that is multiply defined\nacross sources or URDF variants of the same robot. We analyze the files in the\ndataset, where we, among other things, provide information on how they were\ngenerated, which mesh file types are most commonly used, and compare models of\nmultiply defined robots. The intention of this article is to build a foundation\nof knowledge on URDF and how it is used based on publicly available URDF files.\nPublishing the dataset, analysis, and the scripts and tools used enables others\nusing, researching or developing URDFs to easily access this data and use it in\ntheir own work.",
            "author": [
                "Daniella Tola",
                "Peter Corke"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00514v1",
                "http://arxiv.org/pdf/2308.00514v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00504v1",
            "title": "Explainable Graph Spectral Clustering of Text Documents",
            "updated": "2023-08-01T12:39:42Z",
            "published": "2023-08-01T12:39:42Z",
            "summary": "Spectral clustering methods are known for their ability to represent clusters\nof diverse shapes, densities etc. However, results of such algorithms, when\napplied e.g. to text documents, are hard to explain to the user, especially due\nto embedding in the spectral space which has no obvious relation to document\ncontents. Therefore there is an urgent need to elaborate methods for explaining\nthe outcome of the clustering. This paper presents a contribution towards this\ngoal. We present a proposal of explanation of results of combinatorial\nLaplacian based graph spectral clustering. It is based on showing (approximate)\nequivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in\nthis paper) and term vector space embedding. Hence a bridge is constructed\nbetween the textual contents and the clustering results. We provide theoretical\nbackground for this approach. We performed experimental study showing that\n$K$-embedding approximates well Laplacian embedding under favourable block\nmatrix conditions and show that approximation is good enough under other\nconditions.",
            "author": [
                "Bart\u0142omiej Starosta",
                "Mieczys\u0142aw A. K\u0142opotek",
                "S\u0142awomir T. Wierzcho\u0144"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00504v1",
                "http://arxiv.org/pdf/2308.00504v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00503v1",
            "title": "Massively Parallel Algorithms for High-Dimensional Euclidean Minimum\n  Spanning Tree",
            "updated": "2023-08-01T12:36:58Z",
            "published": "2023-08-01T12:36:58Z",
            "summary": "We study the classic Euclidean Minimum Spanning Tree (MST) problem in the\nMassively Parallel Computation (MPC) model. Given a set $X \\subset\n\\mathbb{R}^d$ of $n$ points, the goal is to produce a spanning tree for $X$\nwith weight within a small factor of optimal. Euclidean MST is one of the most\nfundamental hierarchical geometric clustering algorithms, and with the\nproliferation of enormous high-dimensional data sets, such as massive\ntransformer-based embeddings, there is now a critical demand for efficient\ndistributed algorithms to cluster such data sets.\n  In low-dimensional space, where $d = O(1)$, Andoni, Nikolov, Onak, and\nYaroslavtsev [STOC '14] gave a constant round MPC algorithm that obtains a high\naccuracy $(1+\\epsilon)$-approximate solution. However, the situation is much\nmore challenging for high-dimensional spaces: the best-known algorithm to\nobtain a constant approximation requires $O(\\log n)$ rounds. Recently Chen,\nJayaram, Levi, and Waingarten [STOC '22] gave a $\\tilde{O}(\\log n)$\napproximation algorithm in a constant number of rounds based on embeddings into\ntree metrics. However, to date, no known algorithm achieves both a constant\nnumber of rounds and approximation.\n  In this paper, we make strong progress on this front by giving a constant\nfactor approximation in $\\tilde{O}(\\log \\log n)$ rounds of the MPC model. In\ncontrast to tree-embedding-based approaches, which necessarily must pay\n$\\Omega(\\log n)$-distortion, our algorithm is based on a new combination of\ngraph-based distributed MST algorithms and geometric space partitions.\nAdditionally, although the approximate MST we return can have a large depth, we\nshow that it can be modified to obtain a $\\tilde{O}(\\log \\log n)$-round\nconstant factor approximation to the Euclidean Traveling Salesman Problem (TSP)\nin the MPC model. Previously, only a $O(\\log n)$ round was known for the\nproblem.",
            "author": [
                "Rajesh Jayaram",
                "Vahab Mirrokni",
                "Shyam Narayanan",
                "Peilin Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00503v1",
                "http://arxiv.org/pdf/2308.00503v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00501v1",
            "title": "Structural Parameterizations of the Biclique-Free Vertex Deletion\n  Problem",
            "updated": "2023-08-01T12:35:20Z",
            "published": "2023-08-01T12:35:20Z",
            "summary": "In this work, we study the Biclique-Free Vertex Deletion problem: Given a\ngraph $G$ and integers $k$ and $i \\le j$, find a set of at most $k$ vertices\nthat intersects every (not necessarily induced) biclique $K_{i, j}$ in $G$.\nThis is a natural generalization of the Bounded-Degree Deletion problem,\nwherein one asks whether there is a set of at most $k$ vertices whose deletion\nresults in a graph of a given maximum degree $r$. The two problems coincide\nwhen $i = 1$ and $j = r + 1$. We show that Biclique-Free Vertex Deletion is\nfixed-parameter tractable with respect to $k + d$ for the degeneracy $d$ by\ndeveloping a $2^{O(d k^2)} \\cdot n^{O(1)}$-time algorithm. We also show that it\ncan be solved in $2^{O(f k)} \\cdot n^{O(1)}$ time for the feedback vertex\nnumber $f$ when $i \\ge 2$. In contrast, we find that it is W[1]-hard for the\ntreedepth for any integer $i \\ge 1$. Finally, we show that Biclique-Free Vertex\nDeletion has a polynomial kernel for every $i \\ge 1$ when parameterized by the\nfeedback edge number. Previously, for this parameter, its fixed-parameter\ntractability for $i = 1$ was known [Betzler et al., DAM '12] but the existence\nof polynomial kernel was open.",
            "author": [
                "Lito Goldmann",
                "Leon Kellerhals",
                "Tomohiro Koana"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00501v1",
                "http://arxiv.org/pdf/2308.00501v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00498v1",
            "title": "Slow graph bootstrap percolation I: Cycles",
            "updated": "2023-08-01T12:34:26Z",
            "published": "2023-08-01T12:34:26Z",
            "summary": "Given a fixed graph $H$ and an $n$-vertex graph $G$, the $H$-bootstrap\npercolation process on $G$ is defined to be the sequence of graphs $G_i$,\n$i\\geq 0$ which starts with $G_0:=G$ and in which $G_{i+1}$ is obtained from\n$G_i$ by adding every edge that completes a copy of $H$. We are interested in\nthe maximum number of steps, over all $n$-vertex graphs $G$, that this process\ntakes to stabilise. In the first of a series of papers exploring the behaviour\nof this function, denoted $M_H(n)$, and its dependence on certain properties of\n$H$, we investigate the case when $H$ is a cycle. We determine the running time\nprecisely, giving the first infinite family of graphs $H$ for which an exact\nsolution is known. The maximum running time of the $C_k$-bootstrap process is\nof the order $\\log_{k-1}(n)$ for all $3\\leq k\\in \\mathbb{N}$. Interestingly\nthough, the function exhibits different behaviour depending on the parity of\n$k$ and the exact location of the values of $n$ for which $M_H(n)$ increases is\ndetermined by the Frobenius number of a certain numerical semigroup depending\non $k$.",
            "author": [
                "David Fabian",
                "Patrick Morris",
                "Tibor Szab\u00f3"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00498v1",
                "http://arxiv.org/pdf/2308.00498v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00496v1",
            "title": "On damping a control system with global aftereffect on quantum graphs",
            "updated": "2023-08-01T12:32:14Z",
            "published": "2023-08-01T12:32:14Z",
            "summary": "This paper naturally connects the theory of quantum graphs, the control\ntheory and the theory of functional-differential equations. Specifically, we\nstudy the problem of damping a control system described by first-order\nequations on an arbitrary tree graph with global delay. The latter means that\nthe constant delay imposed starting from the initial moment of time propagates\nthrough all internal vertices of the graph. By minimizing the energy\nfunctional, we arrive at the corresponding variational problem and then prove\nits equivalence to a self-adjoint boundary value problem on the tree for\nsecond-order equations involving both the global delay and the global advance.\nIt is remarkable that the resulting problem acquires Kirchhoff's conditions at\nthe internal vertices of the graph, which often appear in the theory of quantum\ngraphs as well as various applications. The unique solvability of this boundary\nvalue problem is proved.",
            "author": [
                "Sergey Buterin"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00496v1",
                "http://arxiv.org/pdf/2308.00496v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "34K35 34K10 93C30 49K21"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00490v1",
            "title": "Discovery of Stable Hybrid Organic-inorganic Double Perovskites for\n  High-performance Solar Cells via Machine-learning Algorithms and Crystal\n  Graph Convolution Neural Network Method",
            "updated": "2023-08-01T12:22:44Z",
            "published": "2023-08-01T12:22:44Z",
            "summary": "Hybrid peroskite solar cells are newly emergent high-performance photovoltaic\ndevices, which suffer from disadvantages such as toxic elements, short-term\nstabilities, and so on. Searching for alternative perovskites with high\nphotovoltaic performances and thermally stabilities is urgent in this field. In\nthis work, stimulated by the recently proposed materials-genome initiative\nproject, firstly we build classical machine-learning algorithms for the models\nof formation energies, bangdaps and Deybe temperatures for hybrid\norganic-inorganic double perovskites, then we choose the high-precision models\nto screen a large scale of double-perovskite chemical space, to filter out good\npervoskite candidates for solar cells. We also analyze features of importances\nfor the the three target properties to reveal the underlying mechanisms and\ndiscover the typical characteristics of high-performances double perovskites.\nSecondly we adopt the Crystal graph convolution neural network (CGCNN), to\nbuild precise model for bandgaps of perovskites for further filtering. Finally\nwe use the ab-initio method to verify the results predicted by the CGCNN\nmethod, and find that, six out of twenty randomly chosen (CH3)2NH2-based HOIDP\ncandidates possess finite bandgaps, and especially, (CH3)2NH2AuSbCl6 and\n(CH3)2NH2CsPdF6 possess the bandgaps of 0.633 eV and 0.504 eV, which are\nappropriate for photovoltaic applications. Our work not only provides a large\nscale of potential high-performance double-perovskite candidates for futural\nexperimental or theoretical verification, but also showcases the effective and\npowerful prediction of the combined ML and CGCNN method proposed for the first\ntime here.",
            "author": [
                "Linkang Zhan",
                "Danfeng Ye",
                "Xinjian Qiu",
                "Yan Cen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00490v1",
                "http://arxiv.org/pdf/2308.00490v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CE",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00477v1",
            "title": "A many-sorted epistemic logic for chromatic hypergraphs",
            "updated": "2023-08-01T12:02:17Z",
            "published": "2023-08-01T12:02:17Z",
            "summary": "We propose a many-sorted modal logic for reasoning about knowledge in\nmulti-agent systems. Our logic introduces a clear distinction between\nparticipating agents and the environment. This allows to express local\nproperties of agents and global properties of worlds in a uniform way, as well\nas to talk about the presence or absence of agents in a world. The logic\nsubsumes the standard epistemic logic and is a conservative extension of it.\nThe semantics is given in chromatic hypergraphs, a generalization of chromatic\nsimplicial complexes, which were recently used to model knowledge in\ndistributed systems. We show that the logic is sound and complete with respect\nto the intended semantics. We also show a further connection of chromatic\nhypergraphs with neighborhood frames.",
            "author": [
                "Eric Goubault",
                "Roman Kniazev",
                "J\u00e9r\u00e9my Ledent"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00477v1",
                "http://arxiv.org/pdf/2308.00477v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.MA",
                "math.LO",
                "F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00461v2",
            "title": "Non-invasive in silico determination of ventricular wall pre-straining\n  and characteristic cavity pressures",
            "updated": "2023-08-02T08:26:58Z",
            "published": "2023-08-01T11:33:45Z",
            "summary": "The clinical application of patient-specific modelling of the heart can\nprovide valuable insights in supplementing and advancing methods of diagnosis\nas well as helping to devise the best possible therapeutic approach for each\nindividual pathological heart condition. The potential of computational cardiac\nmechanics, however, has not yet been fully leveraged due to the heart's complex\nphysiology and limitations in the non-invasive in vivo characterisation of\nheart properties necessary required for accurate patient-specific modelling\nsuch as the heart anatomy in an unloaded state, ventricular pressure, the\nelastic constitutive parameters and the myocardial muscle fibre orientation\ndistribution. From a solid mechanics point of view without prior knowledge of\nthe unloaded heart configuration and the cavity pressure-volume evolution, in\nparticular, the constitutive parameters cannot be accurately estimated to\ndescribe the highly nonlinear elastic material behaviour of myocardial tissue.\nHere, knowledge of the volume-normalized end-diastolic pressure relation for\nlarger mammals is exploited in combination with a novel iterative inverse\nparameter optimisation framework to determine end-systolic and end diastolic\npressures, ventricular wall pre-straining and pre-stressing due the residual\nend-systolic cavity pressure as well as myocardial tissue stiffness parameters\nfor biventricular heart models.",
            "author": [
                "Sebastian Skatulla",
                "Carlo Sansour",
                "Mary Familusi",
                "Jagir Hussan",
                "Ntobeko Ntusi"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00461v2",
                "http://arxiv.org/pdf/2308.00461v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00447v1",
            "title": "Structural Embeddings of Tools for Large Language Models",
            "updated": "2023-08-01T10:46:09Z",
            "published": "2023-08-01T10:46:09Z",
            "summary": "It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.",
            "author": [
                "Eren Unlu"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00447v1",
                "http://arxiv.org/pdf/2308.00447v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00446v1",
            "title": "Complexity evaluation of network configurations and abstractions",
            "updated": "2023-08-01T10:46:02Z",
            "published": "2023-08-01T10:46:02Z",
            "summary": "Computer networks have been traditionally configured by humans using\ncommand-line interfaces. Some network abstractions have emerged in the last 10\nyears, but there is no easy way of comparing them to each other objectively.\nTherefore, there is no consensus in the industry of what direction modern\nnetwork abstractions should take, and the adoption of these abstractions lags\nas a consequence. In this paper I propose a comparison framework using metrics\nderived from graph structures to evaluate the simplicity, efficiency, and\neffectiveness of different network abstraction models. The result of this\ncomparison is that while some of the existing network abstractions are quite\nefficient to store network policy (such as the Kubernetes or the Cisco\nApplication Centric Infrastructure models), others (notably public cloud) are\nstill very infrastructure-centric and suffer from excessive complexity.",
            "author": [
                "Jose Moreno"
            ],
            "link": [
                "http://dx.doi.org/10.5121/csit.2023.131325",
                "http://arxiv.org/abs/2308.00446v1",
                "http://arxiv.org/pdf/2308.00446v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00420v1",
            "title": "The complexity of the Timetable-Based Railway Network Design Problem",
            "updated": "2023-08-01T09:59:04Z",
            "published": "2023-08-01T09:59:04Z",
            "summary": "Because of the long planning periods and their long life cycle, railway\ninfrastructure has to be outlined long ahead. At the present, the\ninfrastructure is designed while only little about the intended operation is\nknown. Hence, the timetable and the operation are adjusted to the\ninfrastructure. Since space, time and money for extension measures of railway\ninfrastructure are limited, each modification has to be done carefully and long\nlasting and should be appropriate for the future unknown demand.\n  To take this into account, we present the robust network design problem for\nrailway infrastructure under capacity constraints and uncertain timetables.\nHere, we plan the required expansion measures for an uncertain long-term\ntimetable. We show that this problem is NP-hard even when restricted to\nbipartite graphs and very simple timetables and present easier solvable special\ncases.\n  This problem corresponds to the fixed-charge network design problem where the\nexpansion costs are minimized such that the timetable is conductible. We model\nthis problem by an integer linear program using time expanded networks.\n  To incorporate the uncertainty of the future timetable, we use a\nscenario-based approach. We define scenarios with individual departure and\narrival times and optional trains. The network is then optimized such that a\ngiven percentage of the scenarios can be operated while minimizing the\nexpansion costs and potential penalty costs for not scheduled optional trains.",
            "author": [
                "Nadine Friesen",
                "Tim Sander",
                "Karl Nachtigall",
                "Nils Nie\u00dfen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00420v1",
                "http://arxiv.org/pdf/2308.00420v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00419v1",
            "title": "Cooperative Positioning for Sparsely Distributed High-Mobility Wireless\n  Networks with EKF Based Spatio-Temporal Data Fusion",
            "updated": "2023-08-01T09:56:33Z",
            "published": "2023-08-01T09:56:33Z",
            "summary": "We propose a distributed cooperative positioning algorithm using the extended\nKalman filter (EKF) based spatio-temporal data fusion (STDF) for a wireless\nnetwork composed of sparsely distributed high-mobility nodes. Our algorithm\nfirst makes a coarse estimation of the position and mobility state of the nodes\nby using the prediction step of EKF. Then it utilizes the coarse estimate as\nthe prior of STDF that relies on factor graph (FG), thus facilitates inferring\na posteriori distributions of the agents' positions in a distributed manner. We\napproximate the nonlinear terms of the messages passed on the associated FG\nwith high precision by exploiting the second-order Taylor polynomial and obtain\nclosed-form representations of each message in the data fusion step, where\ntemporal measurements by imperfect hardware are considered additionally. In the\nthird stage, refinement of position estimate is performed by invoking the\nupdate step of EKF. Simulation results and analysis show that our EKF-STDF has\na lower computational complexity than the state-of-the-art EKF-based\nalgorithms, while achieving an even superior positioning performance in harsh\nenvironment.",
            "author": [
                "Yue Cao",
                "Shaoshi Yang",
                "Xiao Ma",
                "Zhiyong Feng"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LCOMM.2023.3296022",
                "http://arxiv.org/abs/2308.00419v1",
                "http://arxiv.org/pdf/2308.00419v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00415v1",
            "title": "Generative Query Reformulation for Effective Adhoc Search",
            "updated": "2023-08-01T09:51:35Z",
            "published": "2023-08-01T09:51:35Z",
            "summary": "Performing automatic reformulations of a user's query is a popular paradigm\nused in information retrieval (IR) for improving effectiveness -- as\nexemplified by the pseudo-relevance feedback approaches, which expand the query\nin order to alleviate the vocabulary mismatch problem. Recent advancements in\ngenerative language models have demonstrated their ability in generating\nresponses that are relevant to a given prompt. In light of this success, we\nseek to study the capacity of such models to perform query reformulation and\nhow they compare with long-standing query reformulation methods that use\npseudo-relevance feedback. In particular, we investigate two representative\nquery reformulation frameworks, GenQR and GenPRF. GenQR directly reformulates\nthe user's input query, while GenPRF provides additional context for the query\nby making use of pseudo-relevance feedback information. For each reformulation\nmethod, we leverage different techniques, including fine-tuning and direct\nprompting, to harness the knowledge of language models. The reformulated\nqueries produced by the generative models are demonstrated to markedly benefit\nthe effectiveness of a state-of-the-art retrieval pipeline on four TREC test\ncollections (varying from TREC 2004 Robust to the TREC 2019 Deep Learning).\nFurthermore, our results indicate that our studied generative models can\noutperform various statistical query expansion approaches while remaining\ncomparable to other existing complex neural query reformulation models, with\nthe added benefit of being simpler to implement.",
            "author": [
                "Xiao Wang",
                "Sean MacAvaney",
                "Craig Macdonald",
                "Iadh Ounis"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00415v1",
                "http://arxiv.org/pdf/2308.00415v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.01207v1",
            "title": "BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel\n  Optimization",
            "updated": "2023-08-01T09:31:51Z",
            "published": "2023-08-01T09:31:51Z",
            "summary": "Evolutionary reinforcement learning (ERL) algorithms recently raise attention\nin tackling complex reinforcement learning (RL) problems due to high\nparallelism, while they are prone to insufficient exploration or model collapse\nwithout carefully tuning hyperparameters (aka meta-parameters). In the paper,\nwe propose a general meta ERL framework via bilevel optimization (BiERL) to\njointly update hyperparameters in parallel to training the ERL model within a\nsingle agent, which relieves the need for prior domain knowledge or costly\noptimization procedure before model deployment. We design an elegant meta-level\narchitecture that embeds the inner-level's evolving experience into an\ninformative population representation and introduce a simple and feasible\nevaluation of the meta-level fitness function to facilitate learning\nefficiency. We perform extensive experiments in MuJoCo and Box2D tasks to\nverify that as a general framework, BiERL outperforms various baselines and\nconsistently improves the learning performance for a diversity of ERL\nalgorithms.",
            "author": [
                "Junyi Wang",
                "Yuanyang Zhu",
                "Zhi Wang",
                "Yan Zheng",
                "Jianye Hao",
                "Chunlin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2308.01207v1",
                "http://arxiv.org/pdf/2308.01207v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00404v1",
            "title": "Challenging the Myth of Graph Collaborative Filtering: a Reasoned and\n  Reproducibility-driven Analysis",
            "updated": "2023-08-01T09:31:44Z",
            "published": "2023-08-01T09:31:44Z",
            "summary": "The success of graph neural network-based models (GNNs) has significantly\nadvanced recommender systems by effectively modeling users and items as a\nbipartite, undirected graph. However, many original graph-based works often\nadopt results from baseline papers without verifying their validity for the\nspecific configuration under analysis. Our work addresses this issue by\nfocusing on the replicability of results. We present a code that successfully\nreplicates results from six popular and recent graph recommendation models\n(NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark\ndatasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these\ngraph models with traditional collaborative filtering models that historically\nperformed well in offline evaluations. Furthermore, we extend our study to two\nnew datasets (Allrecipes and BookCrossing) that lack established setups in\nexisting literature. As the performance on these datasets differs from the\nprevious benchmarks, we analyze the impact of specific dataset characteristics\non recommendation accuracy. By investigating the information flow from users'\nneighborhoods, we aim to identify which models are influenced by intrinsic\nfeatures in the dataset structure. The code to reproduce our experiments is\navailable at: https://github.com/sisinflab/Graph-RSs-Reproducibility.",
            "author": [
                "Vito Walter Anelli",
                "Daniele Malitesta",
                "Claudio Pomo",
                "Alejandro Bellog\u00edn",
                "Tommaso Di Noia",
                "Eugenio Di Sciascio"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604915.3608759",
                "http://arxiv.org/abs/2308.00404v1",
                "http://arxiv.org/pdf/2308.00404v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00391v1",
            "title": "Counterfactual Graph Transformer for Traffic Flow Prediction",
            "updated": "2023-08-01T09:12:08Z",
            "published": "2023-08-01T09:12:08Z",
            "summary": "Traffic flow prediction (TFP) is a fundamental problem of the Intelligent\nTransportation System (ITS), as it models the latent spatial-temporal\ndependency of traffic flow for potential congestion prediction. Recent\ngraph-based models with multiple kinds of attention mechanisms have achieved\npromising performance. However, existing methods for traffic flow prediction\ntend to inherit the bias pattern from the dataset and lack interpretability. To\nthis end, we propose a Counterfactual Graph Transformer (CGT) model with an\ninstance-level explainer (e.g., finding the important subgraphs) specifically\ndesigned for TFP. We design a perturbation mask generator over input sensor\nfeatures at the time dimension and the graph structure on the graph transformer\nmodule to obtain spatial and temporal counterfactual explanations. By searching\nthe optimal perturbation masks on the input data feature and graph structures,\nwe can obtain the concise and dominant data or graph edge links for the\nsubsequent TFP task. After re-training the utilized graph transformer model\nafter counterfactual perturbation, we can obtain improved and interpretable\ntraffic flow prediction. Extensive results on three real-world public datasets\nshow that CGT can produce reliable explanations and is promising for traffic\nflow prediction.",
            "author": [
                "Ying Yang",
                "Kai Du",
                "Xingyuan Dai",
                "Jianwu Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00391v1",
                "http://arxiv.org/pdf/2308.00391v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00390v1",
            "title": "Some results on 2-distance coloring of planar graphs with girth five",
            "updated": "2023-08-01T09:11:59Z",
            "published": "2023-08-01T09:11:59Z",
            "summary": "A vertex coloring of a graph $G$ is called a 2-distance coloring if any two\nvertices at a distance at most $2$ from each other receive different colors.\nSuppose that $G$ is a planar graph with girth $5$ and maximum degree $\\Delta$.\nWe prove that $G$ admits a $2$-distance $\\Delta+7$ coloring, which improves the\nresult of Dong and Lin (J. Comb. Optim. 32(2), 645-655, 2016). Moreover, we\nprove that $G$ admits a $2$-distance $\\Delta+6$ coloring when $\\Delta\\geq 10$.",
            "author": [
                "Zakir Deniz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00390v1",
                "http://arxiv.org/pdf/2308.00390v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2308.00380v1",
            "title": "Side-Contact Representations with Convex Polygons in 3D: New Results for\n  Complete Bipartite Graphs",
            "updated": "2023-08-01T08:48:20Z",
            "published": "2023-08-01T08:48:20Z",
            "summary": "A polyhedral surface~$\\mathcal{C}$ in $\\mathbb{R}^3$ with convex polygons as\nfaces is a side-contact representation of a graph~$G$ if there is a bijection\nbetween the vertices of $G$ and the faces of~$\\mathcal{C}$ such that the\npolygons of adjacent vertices are exactly the polygons sharing an entire common\nside in~$\\mathcal{C}$.\n  We show that $K_{3,8}$ has a side-contact representation but $K_{3,250}$ has\nnot. The latter result implies that the number of edges of a graph with\nside-contact representation and $n$ vertices is bounded by $O(n^{5/3})$.",
            "author": [
                "Andr\u00e9 Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2308.00380v1",
                "http://arxiv.org/pdf/2308.00380v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    }
]