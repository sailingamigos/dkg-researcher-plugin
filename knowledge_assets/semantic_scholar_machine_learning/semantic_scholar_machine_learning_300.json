[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0",
            "@type": "ScholarlyArticle",
            "paperId": "2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0",
            "corpusId": 15589402,
            "url": "https://www.semanticscholar.org/paper/2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0",
            "title": "Extreme learning machine: a new learning scheme of feedforward neural networks",
            "venue": "2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2134603844",
                "DOI": "10.1109/IJCNN.2004.1380068",
                "CorpusId": 15589402
            },
            "abstract": "It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: 1) the slow gradient-based learning algorithms are extensively used to train neural networks, and 2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these traditional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses the input weights and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide the best generalization performance at extremely fast learning speed. The experimental results based on real-world benchmarking function approximation and classification problems including large complex applications show that the new algorithm can produce best generalization performance in some cases and can learn much faster than traditional popular learning algorithms for feedforward neural networks.",
            "referenceCount": 17,
            "citationCount": 3803,
            "influentialCitationCount": 358,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference"
            ],
            "publicationDate": "2004-07-25",
            "journal": {
                "name": "2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Conference{Huang2004ExtremeLM,\n author = {G. Huang and Q. Zhu and C. Siew},\n booktitle = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},\n journal = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},\n pages = {985-990 vol.2},\n title = {Extreme learning machine: a new learning scheme of feedforward neural networks},\n volume = {2},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9d46dc975aeed3f96bddb144079b50238f746ecd",
            "@type": "ScholarlyArticle",
            "paperId": "9d46dc975aeed3f96bddb144079b50238f746ecd",
            "corpusId": 52037185,
            "url": "https://www.semanticscholar.org/paper/9d46dc975aeed3f96bddb144079b50238f746ecd",
            "title": "Machine learning in manufacturing: advantages, challenges, and applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2464234006",
                "DOI": "10.1080/21693277.2016.1192517",
                "CorpusId": 52037185
            },
            "abstract": "The nature of manufacturing systems faces ever more complex, dynamic and at times even chaotic behaviors. In order to being able to satisfy the demand for high-quality products in an efficient manner, it is essential to utilize all means available. One area, which saw fast pace developments in terms of not only promising results but also usability, is machine learning. Promising an answer to many of the old and new challenges of manufacturing, machine learning is widely discussed by researchers and practitioners alike. However, the field is very broad and even confusing which presents a challenge and a barrier hindering wide application. Here, this paper contributes in presenting an overview of available machine learning techniques and structuring this rather complicated area. A special focus is laid on the potential benefit, and examples of successful applications in a manufacturing environment.",
            "referenceCount": 111,
            "citationCount": 803,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.tandfonline.com/doi/pdf/10.1080/21693277.2016.1192517?needAccess=true",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2016-01-01",
            "journal": {
                "name": "Production & Manufacturing Research",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Wuest2016MachineLI,\n author = {Thorsten Wuest and Daniel Weimer and C. Irgens and K. Thoben},\n journal = {Production & Manufacturing Research},\n pages = {23 - 45},\n title = {Machine learning in manufacturing: advantages, challenges, and applications},\n volume = {4},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d68725804eadecf83d707d89e12c5132bf376187",
            "@type": "ScholarlyArticle",
            "paperId": "d68725804eadecf83d707d89e12c5132bf376187",
            "corpusId": 217295,
            "url": "https://www.semanticscholar.org/paper/d68725804eadecf83d707d89e12c5132bf376187",
            "title": "Sparse Bayesian Learning and the Relevance Vector Machine",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2940784271",
                "CorpusId": 217295
            },
            "abstract": ".",
            "referenceCount": 30,
            "citationCount": 4959,
            "influentialCitationCount": 1005,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{House2001SparseBL,\n author = {George Eastman House and Guildhall StreetCambridge},\n title = {Sparse Bayesian Learning and the Relevance Vector Machine},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:262c0e54370dfc03a7ad53d79930568d18dd448c",
            "@type": "ScholarlyArticle",
            "paperId": "262c0e54370dfc03a7ad53d79930568d18dd448c",
            "corpusId": 3442617,
            "url": "https://www.semanticscholar.org/paper/262c0e54370dfc03a7ad53d79930568d18dd448c",
            "title": "Speeding Up Distributed Machine Learning Using Codes",
            "venue": "IEEE Transactions on Information Theory",
            "publicationVenue": {
                "id": "urn:research:748e730b-add9-47ee-819d-8ae54e504ef9",
                "name": "IEEE Transactions on Information Theory",
                "alternate_names": [
                    "IEEE Trans Inf Theory"
                ],
                "issn": "0018-9448",
                "url": "http://www.comm.utoronto.ca/trans-it/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2963290814",
                "ArXiv": "1512.02673",
                "DBLP": "journals/corr/LeeLPPR15",
                "DOI": "10.1109/TIT.2017.2736066",
                "CorpusId": 3442617
            },
            "abstract": "Codes are widely used in many engineering applications to offer <italic>robustness</italic> against <italic>noise</italic>. In large-scale systems, there are several types of noise that can affect the performance of distributed machine learning algorithms\u2014straggler nodes, system failures, or communication bottlenecks\u2014but there has been little interaction cutting across codes, machine learning, and distributed systems. In this paper, we provide theoretical insights on how <italic>coded</italic> solutions can achieve significant gains compared with uncoded ones. We focus on two of the most basic building blocks of distributed learning algorithms: <italic>matrix multiplication</italic> and <italic>data shuffling</italic>. For matrix multiplication, we use codes to alleviate the effect of stragglers and show that if the number of homogeneous workers is <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>, and the runtime of each subtask has an exponential tail, coded computation can speed up distributed matrix multiplication by a factor of <inline-formula> <tex-math notation=\"LaTeX\">$\\log n$ </tex-math></inline-formula>. For data shuffling, we use codes to reduce communication bottlenecks, exploiting the excess in storage. We show that when a constant fraction <inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula> of the data matrix can be cached at each worker, and <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> is the number of workers, <italic>coded shuffling</italic> reduces the communication cost by a factor of <inline-formula> <tex-math notation=\"LaTeX\">$\\left({\\alpha + \\frac {1}{n}}\\right)\\gamma (n)$ </tex-math></inline-formula> compared with uncoded shuffling, where <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma (n)$ </tex-math></inline-formula> is the ratio of the cost of unicasting <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> messages to <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> users to multicasting a common message (of the same size) to <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> users. For instance, <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma (n) \\simeq n$ </tex-math></inline-formula> if multicasting a message to <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> users is as cheap as unicasting a message to one user. We also provide experimental results, corroborating our theoretical gains of the coded algorithms.",
            "referenceCount": 101,
            "citationCount": 750,
            "influentialCitationCount": 123,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-12-08",
            "journal": {
                "name": "IEEE Transactions on Information Theory",
                "volume": "64"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2015SpeedingUD,\n author = {Kangwook Lee and Maximilian Lam and Ramtin Pedarsani and Dimitris Papailiopoulos and K. Ramchandran},\n booktitle = {IEEE Transactions on Information Theory},\n journal = {IEEE Transactions on Information Theory},\n pages = {1514-1529},\n title = {Speeding Up Distributed Machine Learning Using Codes},\n volume = {64},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3af7252f7e3ca8e9bc8f45e6cbf567b10ecb5d95",
            "@type": "ScholarlyArticle",
            "paperId": "3af7252f7e3ca8e9bc8f45e6cbf567b10ecb5d95",
            "corpusId": 207672473,
            "url": "https://www.semanticscholar.org/paper/3af7252f7e3ca8e9bc8f45e6cbf567b10ecb5d95",
            "title": "Machine learning models and bankruptcy prediction",
            "venue": "Expert systems with applications",
            "publicationVenue": {
                "id": "urn:research:987139ae-a65d-49bb-aaf6-fb764dc40b19",
                "name": "Expert systems with applications",
                "alternate_names": [
                    "Expert syst appl",
                    "Expert Systems With Applications",
                    "Expert Syst Appl"
                ],
                "issn": "0957-4174",
                "url": "https://www.journals.elsevier.com/expert-systems-with-applications/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/eswa/BarbozaKA17",
                "MAG": "2606916050",
                "DOI": "10.1016/j.eswa.2017.04.006",
                "CorpusId": 207672473
            },
            "abstract": null,
            "referenceCount": 60,
            "citationCount": 491,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-15",
            "journal": {
                "name": "Expert Syst. Appl.",
                "volume": "83"
            },
            "citationStyles": {
                "bibtex": "@Article{Barboza2017MachineLM,\n author = {Flavio Barboza and H. Kimura and E. Altman},\n booktitle = {Expert systems with applications},\n journal = {Expert Syst. Appl.},\n pages = {405-417},\n title = {Machine learning models and bankruptcy prediction},\n volume = {83},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:73811a7f8b89de1b8bdad6bb938e58059a9076d3",
            "@type": "ScholarlyArticle",
            "paperId": "73811a7f8b89de1b8bdad6bb938e58059a9076d3",
            "corpusId": 42966081,
            "url": "https://www.semanticscholar.org/paper/73811a7f8b89de1b8bdad6bb938e58059a9076d3",
            "title": "Introduction to machine learning: k-nearest neighbors.",
            "venue": "Annals of Translational Medicine",
            "publicationVenue": {
                "id": "urn:research:15a12adf-61c6-4c5f-9edc-675b2ee2f6e2",
                "name": "Annals of Translational Medicine",
                "alternate_names": [
                    "Ann Transl Med"
                ],
                "issn": "2305-5839",
                "url": "http://atm.amegroups.com/index"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2342603028",
                "DOI": "10.21037/atm.2016.03.37",
                "CorpusId": 42966081,
                "PubMed": "27386492"
            },
            "abstract": "Machine learning techniques have been widely used in many scientific fields, but its use in medical literature is limited partly because of technical difficulties. k-nearest neighbors (kNN) is a simple method of machine learning. The article introduces some basic ideas underlying the kNN algorithm, and then focuses on how to perform kNN modeling with R. The dataset should be prepared before running the knn() function in R. After prediction of outcome with kNN algorithm, the diagnostic performance of the model should be checked. Average accuracy is the mostly widely used statistic to reflect the kNN algorithm. Factors such as k value, distance calculation and choice of appropriate predictors all have significant impact on the model performance.",
            "referenceCount": 11,
            "citationCount": 485,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc4916348?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-04-20",
            "journal": {
                "name": "Annals of translational medicine",
                "volume": "4 11"
            },
            "citationStyles": {
                "bibtex": "@Article{Bao2016IntroductionTM,\n author = {Wentao Bao},\n booktitle = {Annals of Translational Medicine},\n journal = {Annals of translational medicine},\n pages = {\n          218\n        },\n title = {Introduction to machine learning: k-nearest neighbors.},\n volume = {4 11},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c87a4433c57ddabd50f32ca2c2d2197244692106",
            "@type": "ScholarlyArticle",
            "paperId": "c87a4433c57ddabd50f32ca2c2d2197244692106",
            "corpusId": 27867893,
            "url": "https://www.semanticscholar.org/paper/c87a4433c57ddabd50f32ca2c2d2197244692106",
            "title": "mlr: Machine Learning in R",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/jmlr/BischlLKSRSCJ16",
                "MAG": "2544745230",
                "CorpusId": 27867893
            },
            "abstract": "The MLR package provides a generic, object-oriented, and extensible framework for classification, regression, survival analysis and clustering for the R language. It provides a unified interface to more than 160 basic learners and includes meta-algorithms and model selection techniques to improve and extend the functionality of basic learners with, e.g., hyperparameter tuning, feature selection, and ensemble construction. Parallel high-performance computing is natively supported. The package targets practitioners who want to quickly apply machine learning algorithms, as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment.",
            "referenceCount": 16,
            "citationCount": 567,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Bischl2016mlrML,\n author = {B. Bischl and Michel Lang and Lars Kotthoff and J. Schiffner and Jakob Richter and Erich Studerus and Giuseppe Casalicchio and Zachary M. Jones},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {170:1-170:5},\n title = {mlr: Machine Learning in R},\n volume = {17},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e355a8f42becb6648efc4cf0c129a7f560789be",
            "@type": "ScholarlyArticle",
            "paperId": "7e355a8f42becb6648efc4cf0c129a7f560789be",
            "corpusId": 3489958,
            "url": "https://www.semanticscholar.org/paper/7e355a8f42becb6648efc4cf0c129a7f560789be",
            "title": "Machine Learning Methods for Histopathological Image Analysis",
            "venue": "Computational and Structural Biotechnology Journal",
            "publicationVenue": {
                "id": "urn:research:6fccd61b-6529-4c58-bb83-76a7ad759677",
                "name": "Computational and Structural Biotechnology Journal",
                "alternate_names": [
                    "Comput struct biotechnol j",
                    "Comput Struct Biotechnol J",
                    "Computational and structural biotechnology journal"
                ],
                "issn": "2001-0370",
                "url": "https://www.journals.elsevier.com/computational-and-structural-biotechnology-journal/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2751723768",
                "DBLP": "journals/corr/abs-1709-00786",
                "ArXiv": "1709.00786",
                "PubMedCentral": "6158771",
                "DOI": "10.1016/j.csbj.2018.01.001",
                "CorpusId": 3489958,
                "PubMed": "30275936"
            },
            "abstract": null,
            "referenceCount": 111,
            "citationCount": 585,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-09-04",
            "journal": {
                "name": "Computational and Structural Biotechnology Journal",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Komura2017MachineLM,\n author = {D. Komura and S. Ishikawa},\n booktitle = {Computational and Structural Biotechnology Journal},\n journal = {Computational and Structural Biotechnology Journal},\n pages = {34 - 42},\n title = {Machine Learning Methods for Histopathological Image Analysis},\n volume = {16},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14b417f0d88e0d26a1c26a4d616d1093b616c6d0",
            "@type": "ScholarlyArticle",
            "paperId": "14b417f0d88e0d26a1c26a4d616d1093b616c6d0",
            "corpusId": 3126100,
            "url": "https://www.semanticscholar.org/paper/14b417f0d88e0d26a1c26a4d616d1093b616c6d0",
            "title": "A survey of machine learning for big data processing",
            "venue": "EURASIP Journal on Advances in Signal Processing",
            "publicationVenue": {
                "id": "urn:research:63f2d4cb-31e9-465e-a09f-a48b034b7210",
                "name": "EURASIP Journal on Advances in Signal Processing",
                "alternate_names": [
                    "EURASIP J Adv Signal Process"
                ],
                "issn": "1687-6172",
                "url": "http://asp.eurasipjournals.com/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/ejasp/QiuWDXF16",
                "MAG": "2406349003",
                "DOI": "10.1186/S13634-016-0355-X",
                "CorpusId": 3126100
            },
            "abstract": null,
            "referenceCount": 144,
            "citationCount": 649,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://asp-eurasipjournals.springeropen.com/track/pdf/10.1186/s13634-016-0355-x",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-05-28",
            "journal": {
                "name": "EURASIP Journal on Advances in Signal Processing",
                "volume": "2016"
            },
            "citationStyles": {
                "bibtex": "@Article{Qiu2016ASO,\n author = {Junfei Qiu and Qi-hui Wu and Guoru Ding and Yuhua Xu and S. Feng},\n booktitle = {EURASIP Journal on Advances in Signal Processing},\n journal = {EURASIP Journal on Advances in Signal Processing},\n pages = {1-16},\n title = {A survey of machine learning for big data processing},\n volume = {2016},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09755f549468209199565f8037061281080c968f",
            "@type": "ScholarlyArticle",
            "paperId": "09755f549468209199565f8037061281080c968f",
            "corpusId": 4649427,
            "url": "https://www.semanticscholar.org/paper/09755f549468209199565f8037061281080c968f",
            "title": "Interactive machine learning for health informatics: when do we need the human-in-the-loop?",
            "venue": "Brain Informatics",
            "publicationVenue": {
                "id": "urn:research:b409d450-86da-43c3-b686-a9eb1f61675c",
                "name": "Brain Informatics",
                "alternate_names": null,
                "issn": "2198-4026",
                "url": "http://www.springer.com/40708"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2300445845",
                "DBLP": "journals/braininf/Holzinger16",
                "PubMedCentral": "4883171",
                "DOI": "10.1007/s40708-016-0042-6",
                "CorpusId": 4649427,
                "PubMed": "27747607"
            },
            "abstract": null,
            "referenceCount": 107,
            "citationCount": 628,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://braininformatics.springeropen.com/counter/pdf/10.1007/s40708-016-0042-6",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-02",
            "journal": {
                "name": "Brain Informatics",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Holzinger2016InteractiveML,\n author = {Andreas Holzinger},\n booktitle = {Brain Informatics},\n journal = {Brain Informatics},\n pages = {119 - 131},\n title = {Interactive machine learning for health informatics: when do we need the human-in-the-loop?},\n volume = {3},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:192f45d07d16c47e8194e1e3d00ec8c8b05f128c",
            "@type": "ScholarlyArticle",
            "paperId": "192f45d07d16c47e8194e1e3d00ec8c8b05f128c",
            "corpusId": 187788834,
            "url": "https://www.semanticscholar.org/paper/192f45d07d16c47e8194e1e3d00ec8c8b05f128c",
            "title": "Materials discovery and design using machine learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2742835787",
                "DOI": "10.1016/J.JMAT.2017.08.002",
                "CorpusId": 187788834
            },
            "abstract": null,
            "referenceCount": 135,
            "citationCount": 697,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Materials Science",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2017-09-01",
            "journal": {
                "name": "Journal of Materiomics",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2017MaterialsDA,\n author = {Yue Liu and Tianlu Zhao and Wangwei Ju and S. Shi},\n journal = {Journal of Materiomics},\n pages = {159-177},\n title = {Materials discovery and design using machine learning},\n volume = {3},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:079b2cfe950a96d5a43a3febc983d151fb533b53",
            "@type": "ScholarlyArticle",
            "paperId": "079b2cfe950a96d5a43a3febc983d151fb533b53",
            "corpusId": 42373344,
            "url": "https://www.semanticscholar.org/paper/079b2cfe950a96d5a43a3febc983d151fb533b53",
            "title": "Machine learning on big data: Opportunities and challenges",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/ijon/ZhouPWV17",
                "MAG": "2576683119",
                "DOI": "10.1016/j.neucom.2017.01.026",
                "CorpusId": 42373344
            },
            "abstract": null,
            "referenceCount": 106,
            "citationCount": 603,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://manuscript.elsevier.com/S0925231217300577/pdf/S0925231217300577.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-10",
            "journal": {
                "name": "Neurocomputing",
                "volume": "237"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2017MachineLO,\n author = {Lina Zhou and Shimei Pan and Jianwu Wang and A. Vasilakos},\n booktitle = {Neurocomputing},\n journal = {Neurocomputing},\n pages = {350-361},\n title = {Machine learning on big data: Opportunities and challenges},\n volume = {237},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:44479cc5266788c3bafcc0b12ef0758827741fe3",
            "@type": "ScholarlyArticle",
            "paperId": "44479cc5266788c3bafcc0b12ef0758827741fe3",
            "corpusId": 3794211,
            "url": "https://www.semanticscholar.org/paper/44479cc5266788c3bafcc0b12ef0758827741fe3",
            "title": "Guidelines for Developing and Reporting Machine Learning Predictive Models in Biomedical Research: A Multidisciplinary View",
            "venue": "Journal of Medical Internet Research",
            "publicationVenue": {
                "id": "urn:research:2baad992-2268-4c38-9120-e453622f2eeb",
                "name": "Journal of Medical Internet Research",
                "alternate_names": [
                    "J Med Internet Res"
                ],
                "issn": "1438-8871",
                "url": "http://www.symposion.com/jmir/index.htm"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2562251009",
                "PubMedCentral": "5238707",
                "DOI": "10.2196/JMIR.5870",
                "CorpusId": 3794211,
                "PubMed": "27986644"
            },
            "abstract": "Background As more and more researchers are turning to big data for new opportunities of biomedical discoveries, machine learning models, as the backbone of big data analysis, are mentioned more often in biomedical journals. However, owing to the inherent complexity of machine learning methods, they are prone to misuse. Because of the flexibility in specifying machine learning models, the results are often insufficiently reported in research articles, hindering reliable assessment of model validity and consistent interpretation of model outputs. Objective To attain a set of guidelines on the use of machine learning predictive models within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence. Methods A multidisciplinary panel of machine learning experts, clinicians, and traditional statisticians were interviewed, using an iterative process in accordance with the Delphi method. Results The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models. Conclusions A set of guidelines was generated to enable correct application of machine learning models and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis, particularly with machine learning methods, in the biomedical research community.",
            "referenceCount": 59,
            "citationCount": 547,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://assetapi.jmir.pub/download?file=00c13a5c5bb7c2f89d189a1c358532cb.pdf&alt_file=5870-106977-3-SP.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-12-01",
            "journal": {
                "name": "Journal of Medical Internet Research",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2016GuidelinesFD,\n author = {Wei Luo and Dinh Phung and T. Tran and Sunil Gupta and Santu Rana and C. Karmakar and A. Shilton and J. Yearwood and N. Dimitrova and T. Ho and S. Venkatesh and M. Berk},\n booktitle = {Journal of Medical Internet Research},\n journal = {Journal of Medical Internet Research},\n title = {Guidelines for Developing and Reporting Machine Learning Predictive Models in Biomedical Research: A Multidisciplinary View},\n volume = {18},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e5ee400be272be9c64c40f19ea91efb11046202",
            "@type": "ScholarlyArticle",
            "paperId": "2e5ee400be272be9c64c40f19ea91efb11046202",
            "corpusId": 3299789,
            "url": "https://www.semanticscholar.org/paper/2e5ee400be272be9c64c40f19ea91efb11046202",
            "title": "Bypassing the Kohn-Sham equations with machine learning",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "3099950071",
                "DBLP": "journals/corr/BrockherdeLBM16",
                "PubMedCentral": "5636838",
                "ArXiv": "1609.02815",
                "DOI": "10.1038/s41467-017-00839-3",
                "CorpusId": 3299789,
                "PubMed": "29021555"
            },
            "abstract": null,
            "referenceCount": 100,
            "citationCount": 506,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-017-00839-3.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Physics",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-09",
            "journal": {
                "name": "Nature Communications",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Brockherde2016BypassingTK,\n author = {Felix Brockherde and Leslie Vogt and Li Li and M. Tuckerman and K. Burke and K. M\u00fcller},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Bypassing the Kohn-Sham equations with machine learning},\n volume = {8},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7c8858eba8571d86abd90252e734a11e3a6dd73f",
            "@type": "ScholarlyArticle",
            "paperId": "7c8858eba8571d86abd90252e734a11e3a6dd73f",
            "corpusId": 38363,
            "url": "https://www.semanticscholar.org/paper/7c8858eba8571d86abd90252e734a11e3a6dd73f",
            "title": "An Introduction to MCMC for Machine Learning",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "journals/ml/AndrieuFDJ03",
                "MAG": "2135194391",
                "DOI": "10.1023/A:1020281327116",
                "CorpusId": 38363
            },
            "abstract": null,
            "referenceCount": 153,
            "citationCount": 2553,
            "influentialCitationCount": 224,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1023%2FA%3A1020281327116.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Machine Learning",
                "volume": "50"
            },
            "citationStyles": {
                "bibtex": "@Article{Andrieu2004AnIT,\n author = {C. Andrieu and Nando de Freitas and A. Doucet and Michael I. Jordan},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {5-43},\n title = {An Introduction to MCMC for Machine Learning},\n volume = {50},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1202d5a0da9790ae5d8a5d67125e83c82d33faf9",
            "@type": "ScholarlyArticle",
            "paperId": "1202d5a0da9790ae5d8a5d67125e83c82d33faf9",
            "corpusId": 45174648,
            "url": "https://www.semanticscholar.org/paper/1202d5a0da9790ae5d8a5d67125e83c82d33faf9",
            "title": "Encyclopedia of Machine Learning and Data Mining",
            "venue": "Encyclopedia of Machine Learning and Data Mining",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "reference/ml/2017",
                "MAG": "2783365435",
                "DOI": "10.1007/978-1-4899-7687-1",
                "CorpusId": 45174648
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 411,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-1-4899-7687-1/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-03-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Sammut2017EncyclopediaOM,\n author = {C. Sammut and Geoffrey I. Webb},\n booktitle = {Encyclopedia of Machine Learning and Data Mining},\n title = {Encyclopedia of Machine Learning and Data Mining},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c5c3fa019574988c479474c32f34debecd12e8d1",
            "@type": "ScholarlyArticle",
            "paperId": "c5c3fa019574988c479474c32f34debecd12e8d1",
            "corpusId": 9950600,
            "url": "https://www.semanticscholar.org/paper/c5c3fa019574988c479474c32f34debecd12e8d1",
            "title": "Procedural Content Generation via Machine Learning (PCGML)",
            "venue": "IEEE Transactions on Games",
            "publicationVenue": {
                "id": "urn:research:c8bd8d97-dbc6-4af1-aa49-9a852cb59f96",
                "name": "IEEE Transactions on Games",
                "alternate_names": [
                    "IEEE Trans Game"
                ],
                "issn": "2475-1502",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=7782673"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963690854",
                "DBLP": "journals/tciaig/SummervilleSGHH18",
                "ArXiv": "1702.00539",
                "DOI": "10.1109/TG.2018.2846639",
                "CorpusId": 9950600
            },
            "abstract": "This survey explores procedural content generation via machine learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content, such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content, such as sprites and sound effects. In addition to using PCG for autonomous generation, cocreativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the generated content. Multiple PCGML methods are covered, including neural networks: long short-term memory networks, autoencoders, and deep convolutional networks; Markov models: $n$-grams and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in PCGML, including learning from small data sets, lack of training data, multilayered learning, style-transfer, parameter tuning, and PCG as a game mechanic.",
            "referenceCount": 102,
            "citationCount": 306,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1702.00539",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-02-02",
            "journal": {
                "name": "IEEE Transactions on Games",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Summerville2017ProceduralCG,\n author = {A. Summerville and Sam Snodgrass and Matthew J. Guzdial and Christoffer Holmg\u00e5rd and Amy K. Hoover and Aaron Isaksen and Andy Nealen and J. Togelius},\n booktitle = {IEEE Transactions on Games},\n journal = {IEEE Transactions on Games},\n pages = {257-270},\n title = {Procedural Content Generation via Machine Learning (PCGML)},\n volume = {10},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:033c08ca48aaed2d5ab0a17d668d410538678ed8",
            "@type": "ScholarlyArticle",
            "paperId": "033c08ca48aaed2d5ab0a17d668d410538678ed8",
            "corpusId": 18716873,
            "url": "https://www.semanticscholar.org/paper/033c08ca48aaed2d5ab0a17d668d410538678ed8",
            "title": "Evasion Attacks against Machine Learning at Test Time",
            "venue": "ECML/PKDD",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "journals/corr/abs-1708-06131",
                "MAG": "3103836116",
                "ArXiv": "1708.06131",
                "DOI": "10.1007/978-3-642-40994-3_25",
                "CorpusId": 18716873
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 1843,
            "influentialCitationCount": 85,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-642-40994-3_25.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-09-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1708.06131"
            },
            "citationStyles": {
                "bibtex": "@Article{Biggio2013EvasionAA,\n author = {B. Biggio and Igino Corona and Davide Maiorca and B. Nelson and Nedim Srndic and P. Laskov and G. Giacinto and F. Roli},\n booktitle = {ECML/PKDD},\n journal = {ArXiv},\n title = {Evasion Attacks against Machine Learning at Test Time},\n volume = {abs/1708.06131},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a8797f1d253c75669d96e6fcceda2be3f8534e1d",
            "@type": "ScholarlyArticle",
            "paperId": "a8797f1d253c75669d96e6fcceda2be3f8534e1d",
            "corpusId": 7806109,
            "url": "https://www.semanticscholar.org/paper/a8797f1d253c75669d96e6fcceda2be3f8534e1d",
            "title": "Support Vector Machine Active Learning with Applications to Text Classification",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2002,
            "externalIds": {
                "DBLP": "journals/jmlr/TongK01",
                "MAG": "2426031434",
                "DOI": "10.1162/153244302760185243",
                "CorpusId": 7806109
            },
            "abstract": "Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using pool-based active learning. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a version space. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.",
            "referenceCount": 35,
            "citationCount": 3379,
            "influentialCitationCount": 277,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-03-01",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Tong2002SupportVM,\n author = {Simon Tong and D. Koller},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {45-66},\n title = {Support Vector Machine Active Learning with Applications to Text Classification},\n volume = {2},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:765d93759b7888fa1f7b2f3576809ad558c60caf",
            "@type": "ScholarlyArticle",
            "paperId": "765d93759b7888fa1f7b2f3576809ad558c60caf",
            "corpusId": 4463634,
            "url": "https://www.semanticscholar.org/paper/765d93759b7888fa1f7b2f3576809ad558c60caf",
            "title": "Machine-learning-assisted materials discovery using failed experiments",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2347129741",
                "DBLP": "journals/nature/RaccugliaEAFWMZ16",
                "DOI": "10.1038/nature17439",
                "CorpusId": 4463634,
                "PubMed": "27147027"
            },
            "abstract": null,
            "referenceCount": 39,
            "citationCount": 997,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-04",
            "journal": {
                "name": "Nature",
                "volume": "533"
            },
            "citationStyles": {
                "bibtex": "@Article{Raccuglia2016MachinelearningassistedMD,\n author = {Paul Raccuglia and Katherine C. Elbert and Philip Adler and Casey Falk and Malia B. Wenny and Aurelio Mollo and M. Zeller and Sorelle A. Friedler and Joshua Schrier and A. Norquist},\n booktitle = {Nature},\n journal = {Nature},\n pages = {73-76},\n title = {Machine-learning-assisted materials discovery using failed experiments},\n volume = {533},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d4de528645fdfc6d954364a8e6eeeed9480ccfa2",
            "@type": "ScholarlyArticle",
            "paperId": "d4de528645fdfc6d954364a8e6eeeed9480ccfa2",
            "corpusId": 3113937,
            "url": "https://www.semanticscholar.org/paper/d4de528645fdfc6d954364a8e6eeeed9480ccfa2",
            "title": "Machine Learning for Networking: Workflow, Advances and Opportunities",
            "venue": "IEEE Network",
            "publicationVenue": {
                "id": "urn:research:3b4e0d11-3211-4ead-848c-99928b5ef30e",
                "name": "IEEE Network",
                "alternate_names": [
                    "IEEE Netw"
                ],
                "issn": "0890-8044",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=65"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1709.08339",
                "DBLP": "journals/corr/abs-1709-08339",
                "MAG": "2759910885",
                "DOI": "10.1109/MNET.2017.1700200",
                "CorpusId": 3113937
            },
            "abstract": "Recently, machine learning has been used in every possible field to leverage its amazing power. For a long time, the networking and distributed computing system is the key infrastructure to provide efficient computational resources for machine learning. Networking itself can also benefit from this promising technology. This article focuses on the application of MLN, which can not only help solve the intractable old network questions but also stimulate new network applications. In this article, we summarize the basic workflow to explain how to apply machine learning technology in the networking domain. Then we provide a selective survey of the latest representative advances with explanations of their design principles and benefits. These advances are divided into several network design objectives and the detailed information of how they perform in each step of MLN workflow is presented. Finally, we shed light on the new opportunities in networking design and community building of this new inter-discipline. Our goal is to provide a broad research guideline on networking with machine learning to help motivate researchers to develop innovative algorithms, standards and frameworks.",
            "referenceCount": 16,
            "citationCount": 329,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1709.08339",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-09-25",
            "journal": {
                "name": "IEEE Network",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017MachineLF,\n author = {Mowei Wang and Yong Cui and Xin Wang and Shihan Xiao and Junchen Jiang},\n booktitle = {IEEE Network},\n journal = {IEEE Network},\n pages = {92-99},\n title = {Machine Learning for Networking: Workflow, Advances and Opportunities},\n volume = {32},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1eb131a34fbb508a9dd8b646950c65901d6f1a5b",
            "@type": "ScholarlyArticle",
            "paperId": "1eb131a34fbb508a9dd8b646950c65901d6f1a5b",
            "corpusId": 17699480,
            "url": "https://www.semanticscholar.org/paper/1eb131a34fbb508a9dd8b646950c65901d6f1a5b",
            "title": "Hidden Technical Debt in Machine Learning Systems",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2189162242",
                "DBLP": "conf/nips/SculleyHGDPECYC15",
                "CorpusId": 17699480
            },
            "abstract": "Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.",
            "referenceCount": 15,
            "citationCount": 833,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sculley2015HiddenTD,\n author = {D. Sculley and Gary Holt and D. Golovin and Eugene Davydov and Todd Phillips and D. Ebner and Vinay Chaudhary and Michael Young and Jean-Fran\u00e7ois Crespo and Dan Dennison},\n booktitle = {Neural Information Processing Systems},\n pages = {2503-2511},\n title = {Hidden Technical Debt in Machine Learning Systems},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6850869aa5e78a107c378d2e8bfa39633158c0c",
            "@type": "ScholarlyArticle",
            "paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c",
            "corpusId": 3603249,
            "url": "https://www.semanticscholar.org/paper/c6850869aa5e78a107c378d2e8bfa39633158c0c",
            "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1609.08144",
                "MAG": "2525778437",
                "DBLP": "journals/corr/WuSCLNMKCGMKSJL16",
                "CorpusId": 3603249
            },
            "abstract": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system.",
            "referenceCount": 53,
            "citationCount": 5967,
            "influentialCitationCount": 434,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1609.08144"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2016GooglesNM,\n author = {Yonghui Wu and M. Schuster and Z. Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and M. Krikun and Yuan Cao and Qin Gao and Klaus Macherey and J. Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and Lukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and H. Kazawa and K. Stevens and George Kurian and Nishant Patil and Wei Wang and C. Young and Jason R. Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and G. Corrado and Macduff Hughes and J. Dean},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation},\n volume = {abs/1609.08144},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "@type": "ScholarlyArticle",
            "paperId": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "corpusId": 8909022,
            "url": "https://www.semanticscholar.org/paper/be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "title": "Matching Networks for One Shot Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2432717477",
                "DBLP": "journals/corr/VinyalsBLKW16",
                "ArXiv": "1606.04080",
                "CorpusId": 8909022
            },
            "abstract": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.",
            "referenceCount": 30,
            "citationCount": 5817,
            "influentialCitationCount": 1290,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vinyals2016MatchingNF,\n author = {Oriol Vinyals and C. Blundell and T. Lillicrap and K. Kavukcuoglu and Daan Wierstra},\n booktitle = {Neural Information Processing Systems},\n pages = {3630-3638},\n title = {Matching Networks for One Shot Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be08c04637a5f0ba13bfb52c670dbeb227dcb4cc",
            "@type": "ScholarlyArticle",
            "paperId": "be08c04637a5f0ba13bfb52c670dbeb227dcb4cc",
            "corpusId": 5109735,
            "url": "https://www.semanticscholar.org/paper/be08c04637a5f0ba13bfb52c670dbeb227dcb4cc",
            "title": "PMLB: a large benchmark suite for machine learning evaluation and comparison",
            "venue": "BioData Mining",
            "publicationVenue": {
                "id": "urn:research:3b0987fd-daa6-4dd4-947c-4925c14712c0",
                "name": "BioData Mining",
                "alternate_names": [
                    "Biodata Mining",
                    "Biodata Min"
                ],
                "issn": "1756-0381",
                "url": "https://biodatamining.biomedcentral.com/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2950577464",
                "DBLP": "journals/corr/OlsonCOUM17",
                "ArXiv": "1703.00512",
                "PubMedCentral": "5725843",
                "DOI": "10.1186/s13040-017-0154-4",
                "CorpusId": 5109735,
                "PubMed": "29238404"
            },
            "abstract": null,
            "referenceCount": 27,
            "citationCount": 297,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://biodatamining.biomedcentral.com/track/pdf/10.1186/s13040-017-0154-4",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-01",
            "journal": {
                "name": "BioData Mining",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Olson2017PMLBAL,\n author = {Randal S. Olson and W. L. Cava and P. Orzechowski and R. Urbanowicz and J. Moore},\n booktitle = {BioData Mining},\n journal = {BioData Mining},\n title = {PMLB: a large benchmark suite for machine learning evaluation and comparison},\n volume = {10},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:31fbba3638f0d930a678d85247045ea5a1a4ec88",
            "@type": "ScholarlyArticle",
            "paperId": "31fbba3638f0d930a678d85247045ea5a1a4ec88",
            "corpusId": 119458935,
            "url": "https://www.semanticscholar.org/paper/31fbba3638f0d930a678d85247045ea5a1a4ec88",
            "title": "Unsupervised Machine Learning on a Hybrid Quantum Computer",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1712.05771",
                "MAG": "2774424698",
                "CorpusId": 119458935
            },
            "abstract": "Machine learning techniques have led to broad adoption of a statistical model of computing. The statistical distributions natively available on quantum processors are a superset of those available classically. Harnessing this attribute has the potential to accelerate or otherwise improve machine learning relative to purely classical performance. A key challenge toward that goal is learning to hybridize classical computing resources and traditional learning techniques with the emerging capabilities of general purpose quantum processors. Here, we demonstrate such hybridization by training a 19-qubit gate model processor to solve a clustering problem, a foundational challenge in unsupervised learning. We use the quantum approximate optimization algorithm in conjunction with a gradient-free Bayesian optimization to train the quantum machine. This quantum/classical hybrid algorithm shows robustness to realistic noise, and we find evidence that classical optimization can be used to train around both coherent and incoherent imperfections.",
            "referenceCount": 45,
            "citationCount": 256,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-12-15",
            "journal": {
                "name": "arXiv: Quantum Physics",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Otterbach2017UnsupervisedML,\n author = {J. Otterbach and R. Manenti and N. Alidoust and A. Bestwick and M. Block and B. Bloom and S. Caldwell and N. Didier and E. Fried and S. Hong and Peter J. Karalekas and C. Osborn and A. Papageorge and E. C. Peterson and G. Prawiroatmodjo and N. Rubin and C. Ryan and D. Scarabelli and M. Scheer and E. Sete and P. Sivarajah and Robert S. Smith and A. Staley and N. Tezak and W. Zeng and A. Hudson and Blake R. Johnson and M. Reagor and M. Silva and C. Rigetti},\n journal = {arXiv: Quantum Physics},\n title = {Unsupervised Machine Learning on a Hybrid Quantum Computer},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:53b55682222692323a3a0d546d9e1a3de29454f0",
            "@type": "ScholarlyArticle",
            "paperId": "53b55682222692323a3a0d546d9e1a3de29454f0",
            "corpusId": 27775741,
            "url": "https://www.semanticscholar.org/paper/53b55682222692323a3a0d546d9e1a3de29454f0",
            "title": "A review of supervised machine learning algorithms",
            "venue": "International Conference on Computing for Sustainable Global Development",
            "publicationVenue": {
                "id": "urn:research:6336131c-2f71-4f61-bc3b-1bf31ec9fa3d",
                "name": "International Conference on Computing for Sustainable Global Development",
                "alternate_names": [
                    "INDIACom",
                    "Int Conf Comput Sustain Glob Dev"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2547480331",
                "CorpusId": 27775741
            },
            "abstract": "Supervised machine learning is the construction of algorithms that are able to produce general patterns and hypotheses by using externally supplied instances to predict the fate of future instances. Supervised machine learning classification algorithms aim at categorizing data from prior information. Classification is carried out very frequently in data science problems. Various successful techniques have been proposed to solve such problems viz. Rule-based techniques, Logic-based techniques, Instance-based techniques, stochastic techniques. This paper discusses the efficacy of supervised machine learning algorithms in terms of the accuracy, speed of learning, complexity and risk of over fitting measures. The main objective of this paper is to provide a general comparison with state of art machine learning algorithms.",
            "referenceCount": 2,
            "citationCount": 400,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2016-03-16",
            "journal": {
                "name": "2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Singh2016ARO,\n author = {Amanpreet Singh and Narina Thakur and Aakanksha Sharma},\n booktitle = {International Conference on Computing for Sustainable Global Development},\n journal = {2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)},\n pages = {1310-1315},\n title = {A review of supervised machine learning algorithms},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f6000c3be00335633cd490f03d642fcf101cd0d",
            "@type": "ScholarlyArticle",
            "paperId": "2f6000c3be00335633cd490f03d642fcf101cd0d",
            "corpusId": 118842086,
            "url": "https://www.semanticscholar.org/paper/2f6000c3be00335633cd490f03d642fcf101cd0d",
            "title": "Machine Learning Predicts Laboratory Earthquakes",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1702.05774",
                "MAG": "2625710583",
                "DOI": "10.1002/2017GL074677",
                "CorpusId": 118842086
            },
            "abstract": "We apply machine learning to data sets from shear laboratory experiments, with the goal of identifying hidden signals that precede earthquakes. Here we show that by listening to the acoustic signal emitted by a laboratory fault, machine learning can predict the time remaining before it fails with great accuracy. These predictions are based solely on the instantaneous physical characteristics of the acoustical signal and do not make use of its history. Surprisingly, machine learning identifies a signal emitted from the fault zone previously thought to be low\u2010amplitude noise that enables failure forecasting throughout the laboratory quake cycle. We infer that this signal originates from continuous grain motions of the fault gouge as the fault blocks displace. We posit that applying this approach to continuous seismic data may lead to significant advances in identifying currently unknown signals, in providing new insights into fault physics, and in placing bounds on fault failure times.",
            "referenceCount": 44,
            "citationCount": 253,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Geology",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Geology",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Geology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-02-19",
            "journal": {
                "name": "Geophysical Research Letters",
                "volume": "44"
            },
            "citationStyles": {
                "bibtex": "@Article{Rouet-Leduc2017MachineLP,\n author = {B. Rouet-Leduc and Claudia Hulbert and N. Lubbers and K. Barros and C. Humphreys and P. Johnson},\n journal = {Geophysical Research Letters},\n pages = {9276 - 9282},\n title = {Machine Learning Predicts Laboratory Earthquakes},\n volume = {44},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e1f9ef01ab55d53349096a58d76fd0cfa7bb051d",
            "@type": "ScholarlyArticle",
            "paperId": "e1f9ef01ab55d53349096a58d76fd0cfa7bb051d",
            "corpusId": 3306944,
            "url": "https://www.semanticscholar.org/paper/e1f9ef01ab55d53349096a58d76fd0cfa7bb051d",
            "title": "Quantum machine learning: a classical perspective",
            "venue": "Proceedings of the Royal Society A",
            "publicationVenue": {
                "id": "urn:research:b61ce141-a434-431b-a154-68fc26e348f3",
                "name": "Proceedings of the Royal Society A",
                "alternate_names": [
                    "Proc R Soc A",
                    "Proc R Soc Math Phys Eng Sci",
                    "Proceedings of The Royal Society A: Mathematical, Physical and Engineering Sciences"
                ],
                "issn": "1364-5021",
                "url": "https://www.jstor.org/journal/procmathphysengi"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3102885034",
                "PubMedCentral": "5806018",
                "ArXiv": "1707.08561",
                "DBLP": "journals/corr/CilibertoHIPRSW17",
                "DOI": "10.1098/rspa.2017.0551",
                "CorpusId": 3306944,
                "PubMed": "29434508"
            },
            "abstract": "Recently, increased computational power and data availability, as well as algorithmic advances, have led machine learning (ML) techniques to impressive results in regression, classification, data generation and reinforcement learning tasks. Despite these successes, the proximity to the physical limits of chip fabrication alongside the increasing size of datasets is motivating a growing number of researchers to explore the possibility of harnessing the power of quantum computation to speed up classical ML algorithms. Here we review the literature in quantum ML and discuss perspectives for a mixed readership of classical ML and quantum computation experts. Particular emphasis will be placed on clarifying the limitations of quantum algorithms, how they compare with their best classical counterparts and why quantum resources are expected to provide advantages for learning problems. Learning in the presence of noise and certain computationally hard problems in ML are identified as promising directions for the field. Practical questions, such as how to upload classical data into quantum form, will also be addressed.",
            "referenceCount": 197,
            "citationCount": 319,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2017.0551",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Physics",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-07-26",
            "journal": {
                "name": "Proceedings. Mathematical, Physical, and Engineering Sciences",
                "volume": "474"
            },
            "citationStyles": {
                "bibtex": "@Article{Ciliberto2017QuantumML,\n author = {C. Ciliberto and M. Herbster and Alessandro Davide Ialongo and M. Pontil and Andrea Rocchetto and S. Severini and Leonard Wossnig},\n booktitle = {Proceedings of the Royal Society A},\n journal = {Proceedings. Mathematical, Physical, and Engineering Sciences},\n title = {Quantum machine learning: a classical perspective},\n volume = {474},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:95615c6bce2123f12e39c3d9eb293ebb759501aa",
            "@type": "ScholarlyArticle",
            "paperId": "95615c6bce2123f12e39c3d9eb293ebb759501aa",
            "corpusId": 46798472,
            "url": "https://www.semanticscholar.org/paper/95615c6bce2123f12e39c3d9eb293ebb759501aa",
            "title": "Machine learning, social learning and the governance of self-driving cars",
            "venue": "Social Studies of Science",
            "publicationVenue": {
                "id": "urn:research:0cfd46d3-bc04-49e9-9bfe-6c194b418613",
                "name": "Social Studies of Science",
                "alternate_names": [
                    "Soc Stud Sci"
                ],
                "issn": "0306-3127",
                "url": "http://sss.sagepub.com/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2607757716",
                "DOI": "10.1177/0306312717741687",
                "CorpusId": 46798472,
                "PubMed": "29160165"
            },
            "abstract": "Self-driving cars, a quintessentially \u2018smart\u2019 technology, are not born smart. The algorithms that control their movements are learning as the technology emerges. Self-driving cars represent a high-stakes test of the powers of machine learning, as well as a test case for social learning in technology governance. Society is learning about the technology while the technology learns about society. Understanding and governing the politics of this technology means asking \u2018Who is learning, what are they learning and how are they learning?\u2019 Focusing on the successes and failures of social learning around the much-publicized crash of a Tesla Model S in 2016, I argue that trajectories and rhetorics of machine learning in transport pose a substantial governance challenge. \u2018Self-driving\u2019 or \u2018autonomous\u2019 cars are misnamed. As with other technologies, they are shaped by assumptions about social needs, solvable problems, and economic opportunities. Governing these technologies in the public interest means improving social learning by constructively engaging with the contingencies of machine learning.",
            "referenceCount": 181,
            "citationCount": 249,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://discovery.ucl.ac.uk/10038434/1/Stilgoe_Machine%20learning%2C%20social%20learning%20and%20the%20governance%20of%20self-driving%20cars_AAM.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Engineering",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Political Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-19",
            "journal": {
                "name": "Social Studies of Science",
                "volume": "48"
            },
            "citationStyles": {
                "bibtex": "@Article{Stilgoe2017MachineLS,\n author = {J. Stilgoe},\n booktitle = {Social Studies of Science},\n journal = {Social Studies of Science},\n pages = {25 - 56},\n title = {Machine learning, social learning and the governance of self-driving cars},\n volume = {48},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a09a9f69ff145508a12e6dbb81ccd7f5be4bd2fc",
            "@type": "ScholarlyArticle",
            "paperId": "a09a9f69ff145508a12e6dbb81ccd7f5be4bd2fc",
            "corpusId": 3632078,
            "url": "https://www.semanticscholar.org/paper/a09a9f69ff145508a12e6dbb81ccd7f5be4bd2fc",
            "title": "Machine Learning for High-Throughput Stress Phenotyping in Plants.",
            "venue": "Trends in Plant Science",
            "publicationVenue": {
                "id": "urn:research:5713b1b2-02f7-4129-b9a9-1fad7dd10b44",
                "name": "Trends in Plant Science",
                "alternate_names": [
                    "Trends Plant Sci"
                ],
                "issn": "1360-1385",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/30960/description#description"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2185489349",
                "DOI": "10.1016/j.tplants.2015.10.015",
                "CorpusId": 3632078,
                "PubMed": "26651918"
            },
            "abstract": null,
            "referenceCount": 82,
            "citationCount": 626,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cell.com/article/S1360138515002630/pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-02-01",
            "journal": {
                "name": "Trends in plant science",
                "volume": "21 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Singh2016MachineLF,\n author = {Arti Singh and B. Ganapathysubramanian and Ashutosh Kumar Singh and S. Sarkar},\n booktitle = {Trends in Plant Science},\n journal = {Trends in plant science},\n pages = {\n          110-124\n        },\n title = {Machine Learning for High-Throughput Stress Phenotyping in Plants.},\n volume = {21 2},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:32e29041fa352a9df0889f42807ed6141bc0b5ff",
            "@type": "ScholarlyArticle",
            "paperId": "32e29041fa352a9df0889f42807ed6141bc0b5ff",
            "corpusId": 44635588,
            "url": "https://www.semanticscholar.org/paper/32e29041fa352a9df0889f42807ed6141bc0b5ff",
            "title": "Machine learning in geosciences and remote sensing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2218047931",
                "DOI": "10.1016/J.GSF.2015.07.003",
                "CorpusId": 44635588
            },
            "abstract": null,
            "referenceCount": 95,
            "citationCount": 694,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Geology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Geoscience frontiers",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Lary2016MachineLI,\n author = {David John Lary and A. Alavi and A. Gandomi and A. Walker},\n journal = {Geoscience frontiers},\n pages = {3-10},\n title = {Machine learning in geosciences and remote sensing},\n volume = {7},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3683f5b5bfa6533b2c0eacd653e19ac1ec33d57",
            "@type": "ScholarlyArticle",
            "paperId": "b3683f5b5bfa6533b2c0eacd653e19ac1ec33d57",
            "corpusId": 11819780,
            "url": "https://www.semanticscholar.org/paper/b3683f5b5bfa6533b2c0eacd653e19ac1ec33d57",
            "title": "Distributed GraphLab: A Framework for Machine Learning in the Cloud",
            "venue": "Proceedings of the VLDB Endowment",
            "publicationVenue": {
                "id": "urn:research:fcbcaf18-8ab1-43e1-a973-604bbc7e344e",
                "name": "Proceedings of the VLDB Endowment",
                "alternate_names": [
                    "Proceedings of The Vldb Endowment",
                    "Proc VLDB Endow",
                    "Proc Vldb Endow"
                ],
                "issn": "2150-8097",
                "url": "http://dl.acm.org/toc.cfm?id=J1174"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2096544401",
                "DBLP": "journals/pvldb/LowGKBGH12",
                "ArXiv": "1204.6078",
                "DOI": "10.14778/2212351.2212354",
                "CorpusId": 11819780
            },
            "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. \n \nWe develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",
            "referenceCount": 39,
            "citationCount": 1272,
            "influentialCitationCount": 188,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-04-01",
            "journal": {
                "name": "Proc. VLDB Endow.",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Low2012DistributedGA,\n author = {Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and J. Hellerstein},\n booktitle = {Proceedings of the VLDB Endowment},\n journal = {Proc. VLDB Endow.},\n pages = {716-727},\n title = {Distributed GraphLab: A Framework for Machine Learning in the Cloud},\n volume = {5},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:05d20fda297c9afb347214bd1693bd049674e0c6",
            "@type": "ScholarlyArticle",
            "paperId": "05d20fda297c9afb347214bd1693bd049674e0c6",
            "corpusId": 42476116,
            "url": "https://www.semanticscholar.org/paper/05d20fda297c9afb347214bd1693bd049674e0c6",
            "title": "Machine Learning for the Geosciences: Challenges and Opportunities",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1711.04708",
                "MAG": "2950029135",
                "DBLP": "journals/corr/abs-1711-04708",
                "DOI": "10.1109/TKDE.2018.2861006",
                "CorpusId": 42476116
            },
            "abstract": "Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML)\u2014that has been widely successful in commercial domains\u2014offers immense potential to contribute to problems in geosciences. However, geoscience applications introduce novel challenges for ML due to combinations of geoscience properties encountered in every problem, requiring novel research in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their common properties. We then describe some of the common categories of geoscience problems where machine learning can play a role, discussing the challenges faced by existing ML methods and opportunities for novel ML research. We conclude by discussing some of the cross-cutting research themes in machine learning that are applicable across several geoscience problems, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.",
            "referenceCount": 132,
            "citationCount": 276,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1711.04708",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Geology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-13",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Karpatne2017MachineLF,\n author = {A. Karpatne and I. Ebert\u2010Uphoff and S. Ravela and H. Babaie and Vipin Kumar},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {1544-1554},\n title = {Machine Learning for the Geosciences: Challenges and Opportunities},\n volume = {31},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "@type": "ScholarlyArticle",
            "paperId": "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "corpusId": 207241585,
            "url": "https://www.semanticscholar.org/paper/e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "title": "Deep Learning with Differential Privacy",
            "venue": "Conference on Computer and Communications Security",
            "publicationVenue": {
                "id": "urn:research:73f7fe95-b68b-468f-b7ba-3013ca879e50",
                "name": "Conference on Computer and Communications Security",
                "alternate_names": [
                    "Int Workshop Cogn Cell Syst",
                    "CCS",
                    "Comput Commun Secur",
                    "CcS",
                    "International Symposium on Community-centric Systems",
                    "International Workshop on Cognitive Cellular Systems",
                    "Conf Comput Commun Secur",
                    "Comb Comput Sci",
                    "Int Symp Community-centric Syst",
                    "Combinatorics and Computer Science",
                    "Circuits, Signals, and Systems",
                    "Computer and Communications Security",
                    "Circuit Signal Syst"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/ccs"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "3098586851",
                "ArXiv": "1607.00133",
                "DBLP": "conf/ccs/AbadiCGMMT016",
                "DOI": "10.1145/2976749.2978318",
                "CorpusId": 207241585
            },
            "abstract": "Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.",
            "referenceCount": 63,
            "citationCount": 4269,
            "influentialCitationCount": 963,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1607.00133",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-07-01",
            "journal": {
                "name": "Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Abadi2016DeepLW,\n author = {Mart\u00edn Abadi and Andy Chu and I. Goodfellow and H. B. McMahan and Ilya Mironov and Kunal Talwar and Li Zhang},\n booktitle = {Conference on Computer and Communications Security},\n journal = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},\n title = {Deep Learning with Differential Privacy},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b1059d25d092e0e872a1d2db01b24c73eb869ad9",
            "@type": "ScholarlyArticle",
            "paperId": "b1059d25d092e0e872a1d2db01b24c73eb869ad9",
            "corpusId": 1238757,
            "url": "https://www.semanticscholar.org/paper/b1059d25d092e0e872a1d2db01b24c73eb869ad9",
            "title": "Machine Learning for Neural Decoding",
            "venue": "eNeuro",
            "publicationVenue": {
                "id": "urn:research:6c38e807-0b8c-433f-919b-9fa30f6fe6a5",
                "name": "eNeuro",
                "alternate_names": null,
                "issn": "2373-2822",
                "url": "https://epub.uni-regensburg.de/40454/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1708.00909",
                "PubMedCentral": "7470933",
                "MAG": "3046749939",
                "DBLP": "journals/corr/abs-1708-00909",
                "DOI": "10.1523/ENEURO.0506-19.2020",
                "CorpusId": 1238757,
                "PubMed": "32737181"
            },
            "abstract": "Abstract Despite rapid advances in machine learning tools, the majority of neural decoding approaches still use traditional methods. Modern machine learning tools, which are versatile and easy to use, have the potential to significantly improve decoding performance. This tutorial describes how to effectively apply these algorithms for typical decoding problems. We provide descriptions, best practices, and code for applying common machine learning methods, including neural networks and gradient boosting. We also provide detailed comparisons of the performance of various methods at the task of decoding spiking activity in motor cortex, somatosensory cortex, and hippocampus. Modern methods, particularly neural networks and ensembles, significantly outperform traditional approaches, such as Wiener and Kalman filters. Improving the performance of neural decoding algorithms allows neuroscientists to better understand the information contained in a neural population and can help to advance engineering applications such as brain\u2013machine interfaces. Our code package is available at github.com/kordinglab/neural_decoding.",
            "referenceCount": 85,
            "citationCount": 179,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.eneuro.org/content/eneuro/7/4/ENEURO.0506-19.2020.full.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-08-02",
            "journal": {
                "name": "eNeuro",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Glaser2017MachineLF,\n author = {Joshua I. Glaser and Raeed H. Chowdhury and M. Perich and L. Miller and Konrad Paul Kording},\n booktitle = {eNeuro},\n journal = {eNeuro},\n title = {Machine Learning for Neural Decoding},\n volume = {7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:227e0591634cef50d0bcfc73fe6c5b34a2256e5f",
            "@type": "ScholarlyArticle",
            "paperId": "227e0591634cef50d0bcfc73fe6c5b34a2256e5f",
            "corpusId": 114654356,
            "url": "https://www.semanticscholar.org/paper/227e0591634cef50d0bcfc73fe6c5b34a2256e5f",
            "title": "Radio Machine Learning Dataset Generation with GNU Radio",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2562146178",
                "CorpusId": 114654356
            },
            "abstract": "This paper surveys emerging applications of Machine Learning (ML) to the Radio Signal Processing domain. \u00a0Provides some brief background on enabling methods and discusses some of the potential advancements for the field. \u00a0It discusses the critical importance of good datasets for model learning, testing, and evaluation and introduces several public open source synthetic datasets for various radio machine learning tasks. \u00a0These are intended to provide a robust common baselines for those working in the field and to provide a benchmark measure against which many techniques can be rapidly evaluated and compared.",
            "referenceCount": 17,
            "citationCount": 343,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2016-09-06",
            "journal": {
                "name": "",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{O'Shea2016RadioML,\n author = {Tim O'Shea and Nathan E. West},\n title = {Radio Machine Learning Dataset Generation with GNU Radio},\n volume = {1},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c61134ada9f0e3f3373d635c31a8b3caa37f9977",
            "@type": "ScholarlyArticle",
            "paperId": "c61134ada9f0e3f3373d635c31a8b3caa37f9977",
            "corpusId": 2043246,
            "url": "https://www.semanticscholar.org/paper/c61134ada9f0e3f3373d635c31a8b3caa37f9977",
            "title": "Genetic algorithms and Machine Learning",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 1988,
            "externalIds": {
                "DBLP": "journals/ml/GoldbergH88",
                "MAG": "1541288193",
                "DOI": "10.1007/BF00113892",
                "CorpusId": 2043246
            },
            "abstract": null,
            "referenceCount": 13,
            "citationCount": 3098,
            "influentialCitationCount": 101,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1023%2FA%3A1022602019183.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1988-10-01",
            "journal": {
                "name": "Machine Learning",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Goldberg1988GeneticAA,\n author = {D. Goldberg and J. Holland},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {95-99},\n title = {Genetic algorithms and Machine Learning},\n volume = {3},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9e6060316394393c226b5c86ce51b06c4c75bee1",
            "@type": "ScholarlyArticle",
            "paperId": "9e6060316394393c226b5c86ce51b06c4c75bee1",
            "corpusId": 2259147,
            "url": "https://www.semanticscholar.org/paper/9e6060316394393c226b5c86ce51b06c4c75bee1",
            "title": "Machine Learning Classification over Encrypted Data",
            "venue": "Network and Distributed System Security Symposium",
            "publicationVenue": {
                "id": "urn:research:e6904c24-9546-4135-8344-e3999e375558",
                "name": "Network and Distributed System Security Symposium",
                "alternate_names": [
                    "Netw Distrib Syst Secur Symp",
                    "NDSS"
                ],
                "issn": null,
                "url": "http://www.isoc.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2950800519",
                "DBLP": "journals/iacr/BostPTG14",
                "DOI": "10.14722/NDSS.2015.23241",
                "CorpusId": 2259147
            },
            "abstract": "Machine learning classification is used for numerous tasks nowadays, such as medical or genomics predictions, spam detection, face recognition, and financial predictions. Due to privacy concerns, in some of these applications, it is important that the data and the classifier remain confidential. In this work, we construct three major classification protocols that satisfy this privacy constraint: hyperplane decision, Na\u00efve Bayes, and decision trees. We also enable these protocols to be combined with AdaBoost. At the basis of these constructions is a new library of building blocks, which enables constructing a wide range of privacy-preserving classifiers; we demonstrate how this library can be used to construct other classifiers than the three mentioned above, such as a multiplexer and a face detection classifier. We implemented and evaluated our library and our classifiers. Our protocols are efficient, taking milliseconds to a few seconds to perform a classification when running on real medical datasets.",
            "referenceCount": 63,
            "citationCount": 679,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://eprint.iacr.org/2014/331.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IACR Cryptol. ePrint Arch.",
                "volume": "2014"
            },
            "citationStyles": {
                "bibtex": "@Article{Bost2015MachineLC,\n author = {Raphael Bost and R. A. Popa and Stephen Tu and S. Goldwasser},\n booktitle = {Network and Distributed System Security Symposium},\n journal = {IACR Cryptol. ePrint Arch.},\n pages = {331},\n title = {Machine Learning Classification over Encrypted Data},\n volume = {2014},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f488e4a252c018f9391b0dc90036687a0b361844",
            "@type": "ScholarlyArticle",
            "paperId": "f488e4a252c018f9391b0dc90036687a0b361844",
            "corpusId": 34292426,
            "url": "https://www.semanticscholar.org/paper/f488e4a252c018f9391b0dc90036687a0b361844",
            "title": "Implementing Machine Learning in Radiology Practice and Research.",
            "venue": "AJR. American journal of roentgenology",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2582555581",
                "DOI": "10.2214/AJR.16.17224",
                "CorpusId": 34292426,
                "PubMed": "28125274"
            },
            "abstract": "OBJECTIVE\nThe purposes of this article are to describe concepts that radiologists should understand to evaluate machine learning projects, including common algorithms, supervised as opposed to unsupervised techniques, statistical pitfalls, and data considerations for training and evaluation, and to briefly describe ethical dilemmas and legal risk.\n\n\nCONCLUSION\nMachine learning includes a broad class of computer programs that improve with experience. The complexity of creating, training, and monitoring machine learning indicates that the success of the algorithms will require radiologist involvement for years to come, leading to engagement rather than replacement.",
            "referenceCount": 12,
            "citationCount": 212,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-01-26",
            "journal": {
                "name": "AJR. American journal of roentgenology",
                "volume": "208 4"
            },
            "citationStyles": {
                "bibtex": "@Article{Kohli2017ImplementingML,\n author = {M. Kohli and L. Prevedello and Ross W. Filice and J. R. Geis},\n booktitle = {AJR. American journal of roentgenology},\n journal = {AJR. American journal of roentgenology},\n pages = {\n          754-760\n        },\n title = {Implementing Machine Learning in Radiology Practice and Research.},\n volume = {208 4},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:233e1651094717e3df60d231c65000eb2105e283",
            "@type": "ScholarlyArticle",
            "paperId": "233e1651094717e3df60d231c65000eb2105e283",
            "corpusId": 63737241,
            "url": "https://www.semanticscholar.org/paper/233e1651094717e3df60d231c65000eb2105e283",
            "title": "Python Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2562618250",
                "CorpusId": 63737241
            },
            "abstract": "Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analyticsAbout This BookLeverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualizationLearn effective strategies and best practices to improve and optimize machine learning systems and algorithmsAsk and answer tough questions of your data with robust statistical models, built for a range of datasetsWho This Book Is ForIf you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource.What You Will LearnExplore how to use different machine learning models to ask different questions of your dataLearn how to build neural networks using Keras and TheanoFind out how to write clean and elegant Python code that will optimize the strength of your algorithmsDiscover how to embed your machine learning model in a web application for increased accessibilityPredict continuous target outcomes using regression analysisUncover hidden patterns and structures in data with clusteringOrganize data using effective pre-processing techniquesGet to grips with sentiment analysis to delve deeper into textual and social media dataIn DetailMachine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success.Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization.Style and approachPython Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.",
            "referenceCount": 2,
            "citationCount": 676,
            "influentialCitationCount": 49,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-09-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Raschka2015PythonML,\n author = {S. Raschka},\n title = {Python Machine Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c396ba3ce3c58591b8ee282e65ab5a6d610e16ed",
            "@type": "ScholarlyArticle",
            "paperId": "c396ba3ce3c58591b8ee282e65ab5a6d610e16ed",
            "corpusId": 42064048,
            "url": "https://www.semanticscholar.org/paper/c396ba3ce3c58591b8ee282e65ab5a6d610e16ed",
            "title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/SimardACPGMRSVW17",
                "ArXiv": "1707.06742",
                "MAG": "2738647029",
                "CorpusId": 42064048
            },
            "abstract": "The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible. \nWhile machine learning focuses on creating new algorithms and improving the accuracy of \"learners\", the machine teaching discipline focuses on the efficacy of the \"teachers\". Machine teaching as a discipline is a paradigm shift that follows and extends principles of software engineering and programming languages. We put a strong emphasis on the teacher and the teacher's interaction with data, as well as crucial components such as techniques and design principles of interaction and visualization. \nIn this paper, we present our position regarding the discipline of machine teaching and articulate fundamental machine teaching principles. We also describe how, by decoupling knowledge about machine learning algorithms from the process of teaching, we can accelerate innovation and empower millions of new uses for machine learning models.",
            "referenceCount": 11,
            "citationCount": 152,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1707.06742"
            },
            "citationStyles": {
                "bibtex": "@Article{Simard2017MachineTA,\n author = {P. Simard and S. Amershi and D. M. Chickering and Alicia Edelman Pelton and S. Ghorashi and Christopher Meek and Gonzalo A. Ramos and Jina Suh and J. Verwey and Mo Wang and J. Wernsing},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Machine Teaching: A New Paradigm for Building Machine Learning Systems},\n volume = {abs/1707.06742},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77233d2f6fd10465a574ca33b869707822bf0c0b",
            "@type": "ScholarlyArticle",
            "paperId": "77233d2f6fd10465a574ca33b869707822bf0c0b",
            "corpusId": 3933947,
            "url": "https://www.semanticscholar.org/paper/77233d2f6fd10465a574ca33b869707822bf0c0b",
            "title": "A brief survey of machine learning methods and their sensor and IoT applications",
            "venue": "International Conference on Information, Intelligence, Systems and Applications",
            "publicationVenue": {
                "id": "urn:research:bbdd88c4-fb38-40a7-9a05-df99e3d1eee2",
                "name": "International Conference on Information, Intelligence, Systems and Applications",
                "alternate_names": [
                    "Int Conf Inf Intell Syst Appl",
                    "IISA"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iisa/ShanthamalluSTS17",
                "MAG": "2792005857",
                "DOI": "10.1109/IISA.2017.8316459",
                "CorpusId": 3933947
            },
            "abstract": "This paper provides a brief survey of the basic concepts and algorithms used for Machine Learning and its applications. We begin with a broader definition of machine learning and then introduce various learning modalities including supervised and unsupervised methods and deep learning paradigms. In the rest of the paper, we discuss applications of machine learning algorithms in various fields including pattern recognition, sensor networks, anomaly detection, Internet of Things (IoT) and health monitoring. In the final sections, we present some of the software tools and an extensive bibliography.",
            "referenceCount": 197,
            "citationCount": 191,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shanthamallu2017ABS,\n author = {U. Shanthamallu and A. Spanias and C. Tepedelenlio\u011flu and M. Stanley},\n booktitle = {International Conference on Information, Intelligence, Systems and Applications},\n journal = {2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)},\n pages = {1-8},\n title = {A brief survey of machine learning methods and their sensor and IoT applications},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3804ca5590a0829c5d56e84d860a2b2a456e3757",
            "@type": "ScholarlyArticle",
            "paperId": "3804ca5590a0829c5d56e84d860a2b2a456e3757",
            "corpusId": 9966416,
            "url": "https://www.semanticscholar.org/paper/3804ca5590a0829c5d56e84d860a2b2a456e3757",
            "title": "Principles of Explanatory Debugging to Personalize Interactive Machine Learning",
            "venue": "International Conference on Intelligent User Interfaces",
            "publicationVenue": {
                "id": "urn:research:d43f0f26-43c9-4009-a1ed-63624522c166",
                "name": "International Conference on Intelligent User Interfaces",
                "alternate_names": [
                    "IUI",
                    "Intell User Interface",
                    "Int Conf Intell User Interface",
                    "Intelligent User Interfaces"
                ],
                "issn": null,
                "url": "http://www.iuiconf.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2053075547",
                "DBLP": "conf/iui/KuleszaBWS15",
                "DOI": "10.1145/2678025.2701399",
                "CorpusId": 9966416
            },
            "abstract": "How can end users efficiently influence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants' understanding of the learning system by 52% and allowed participants to correct its mistakes up to twice as efficiently as participants using a traditional learning system.",
            "referenceCount": 52,
            "citationCount": 492,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://openaccess.city.ac.uk/id/eprint/13819/1/paper326.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-03-18",
            "journal": {
                "name": "Proceedings of the 20th International Conference on Intelligent User Interfaces",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Kulesza2015PrinciplesOE,\n author = {Todd Kulesza and M. Burnett and Weng-Keen Wong and S. Stumpf},\n booktitle = {International Conference on Intelligent User Interfaces},\n journal = {Proceedings of the 20th International Conference on Intelligent User Interfaces},\n title = {Principles of Explanatory Debugging to Personalize Interactive Machine Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f38513dc4350cfb987a8f0b774fc361c4d910a17",
            "@type": "ScholarlyArticle",
            "paperId": "f38513dc4350cfb987a8f0b774fc361c4d910a17",
            "corpusId": 39921602,
            "url": "https://www.semanticscholar.org/paper/f38513dc4350cfb987a8f0b774fc361c4d910a17",
            "title": "Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2378208052",
                "CorpusId": 39921602
            },
            "abstract": "Machine learning is often used to build predictive models by extracting patterns from large datasets. These models are used in predictive data analytics applications including price prediction, risk assessment, predicting customer behavior, and document classification. This introductory textbook offers a detailed and focused treatment of the most important machine learning approaches used in predictive data analytics, covering both theoretical concepts and practical applications. Technical and mathematical material is augmented with explanatory worked examples, and case studies illustrate the application of these models in the broader business context. After discussing the trajectory from data to insight to decision, the book describes four approaches to machine learning: information-based learning, similarity-based learning, probability-based learning, and error-based learning. Each of these approaches is introduced by a nontechnical explanation of the underlying concept, followed by mathematical models and algorithms illustrated by detailed worked examples. Finally, the book considers techniques for evaluating prediction models and offers two case studies that describe specific data analytics projects through each phase of development, from formulating the business problem to implementation of the analytics solution. The book, informed by the authors' many years of teaching machine learning, and working on predictive data analytics projects, is suitable for use by undergraduates in computer science, engineering, mathematics, or statistics; by graduate students in disciplines with applications for predictive data analytics; and as a reference for professionals.",
            "referenceCount": 171,
            "citationCount": 500,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-07-24",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kelleher2015FundamentalsOM,\n author = {John D. Kelleher and Brian Mac Namee and Aoife D'Arcy},\n title = {Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:31e12b8d558a7515f3a1e3337551f5f30e466cde",
            "@type": "ScholarlyArticle",
            "paperId": "31e12b8d558a7515f3a1e3337551f5f30e466cde",
            "corpusId": 109774536,
            "url": "https://www.semanticscholar.org/paper/31e12b8d558a7515f3a1e3337551f5f30e466cde",
            "title": "Unified representation of molecules and crystals for machine learning",
            "venue": "Machine Learning: Science and Technology",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/mlst/HuoR22",
                "MAG": "2923868908",
                "ArXiv": "1704.06439",
                "DOI": "10.1088/2632-2153/aca005",
                "CorpusId": 109774536
            },
            "abstract": "Accurate simulations of atomistic systems from first principles are limited by computational cost. In high-throughput settings, machine learning can reduce these costs significantly by accurately interpolating between reference calculations. For this, kernel learning approaches crucially require a representation that accommodates arbitrary atomistic systems. We introduce a many-body tensor representation that is invariant to translations, rotations, and nuclear permutations of same elements, unique, differentiable, can represent molecules and crystals, and is fast to compute. Empirical evidence for competitive energy and force prediction errors is presented for changes in molecular structure, crystal chemistry, and molecular dynamics using kernel regression and symmetric gradient-domain machine learning as models. Applicability is demonstrated for phase diagrams of Pt-group/transition-metal binary systems.",
            "referenceCount": 102,
            "citationCount": 156,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://kops.uni-konstanz.de/bitstreams/ef286cd2-85ab-4686-a98b-ee2492d6c898/download",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Chemistry"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-21",
            "journal": {
                "name": "Machine Learning: Science and Technology",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Huo2017UnifiedRO,\n author = {Haoyan Huo and M. Rupp},\n booktitle = {Machine Learning: Science and Technology},\n journal = {Machine Learning: Science and Technology},\n title = {Unified representation of molecules and crystals for machine learning},\n volume = {3},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ebe14ab38c7bc8187737c8aed7fef3d7cd2becf7",
            "@type": "ScholarlyArticle",
            "paperId": "ebe14ab38c7bc8187737c8aed7fef3d7cd2becf7",
            "corpusId": 2776777,
            "url": "https://www.semanticscholar.org/paper/ebe14ab38c7bc8187737c8aed7fef3d7cd2becf7",
            "title": "Machine Learning methods for Quantitative Radiomic Biomarkers",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1408981388",
                "PubMedCentral": "4538374",
                "DOI": "10.1038/srep13087",
                "CorpusId": 2776777,
                "PubMed": "26278466"
            },
            "abstract": null,
            "referenceCount": 48,
            "citationCount": 748,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/srep13087.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-08-17",
            "journal": {
                "name": "Scientific Reports",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Parmar2015MachineLM,\n author = {C. Parmar and P. Grossmann and J. Bussink and P. Lambin and H. Aerts},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Machine Learning methods for Quantitative Radiomic Biomarkers},\n volume = {5},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a5c0309b9895066ebd08acfe326b01ce2fdefdd4",
            "@type": "ScholarlyArticle",
            "paperId": "a5c0309b9895066ebd08acfe326b01ce2fdefdd4",
            "corpusId": 1862788,
            "url": "https://www.semanticscholar.org/paper/a5c0309b9895066ebd08acfe326b01ce2fdefdd4",
            "title": "Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges",
            "venue": "European Heart Journal",
            "publicationVenue": {
                "id": "urn:research:3e3fb1ae-7d3b-430c-9f51-5d7b4f6906e0",
                "name": "European Heart Journal",
                "alternate_names": [
                    "Eur Heart J",
                    "Eur heart j",
                    "European heart journal"
                ],
                "issn": "0195-668X",
                "url": "http://www.arsxxi.com/"
            },
            "year": 2016,
            "externalIds": {
                "PubMedCentral": "5837244",
                "MAG": "2496911238",
                "DOI": "10.1093/eurheartj/ehw302",
                "CorpusId": 1862788,
                "PubMed": "27436868"
            },
            "abstract": "Abstract Risk prediction plays an important role in clinical cardiology research. Traditionally, most risk models have been based on regression models. While useful and robust, these statistical methods are limited to using a small number of predictors which operate in the same way on everyone, and uniformly throughout their range. The purpose of this review is to illustrate the use of machine-learning methods for development of risk prediction models. Typically presented as black box approaches, most machine-learning methods are aimed at solving particular challenges that arise in data analysis that are not well addressed by typical regression approaches. To illustrate these challenges, as well as how different methods can address them, we consider trying to predicting mortality after diagnosis of acute myocardial infarction. We use data derived from our institution's electronic health record and abstract data on 13 regularly measured laboratory markers. We walk through different challenges that arise in modelling these data and then introduce different machine-learning approaches. Finally, we discuss general issues in the application of machine-learning methods including tuning parameters, loss functions, variable importance, and missing data. Overall, this review serves as an introduction for those working on risk modelling to approach the diffuse field of machine learning.",
            "referenceCount": 56,
            "citationCount": 335,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/eurheartj/article-pdf/38/23/1805/24120384/ehw302.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-07-19",
            "journal": {
                "name": "European Heart Journal",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Goldstein2016MovingBR,\n author = {B. Goldstein and A. Navar and R. Carter},\n booktitle = {European Heart Journal},\n journal = {European Heart Journal},\n pages = {1805 - 1814},\n title = {Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges},\n volume = {38},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:825ca26af5a2a510dbc1a7b97587212bc98ae968",
            "@type": "ScholarlyArticle",
            "paperId": "825ca26af5a2a510dbc1a7b97587212bc98ae968",
            "corpusId": 127197,
            "url": "https://www.semanticscholar.org/paper/825ca26af5a2a510dbc1a7b97587212bc98ae968",
            "title": "Power to the People: The Role of Humans in Interactive Machine Learning",
            "venue": "The AI Magazine",
            "publicationVenue": {
                "id": "urn:research:6fedff74-7525-4b7f-bbb4-4df4e23948e4",
                "name": "The AI Magazine",
                "alternate_names": [
                    "AI Mag",
                    "Ai Mag",
                    "Ai Magazine"
                ],
                "issn": "0738-4602",
                "url": "https://www.aaai.org/Library/Magazine/magazine-library.php"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1501005121",
                "DBLP": "journals/aim/AmershiCKK14",
                "DOI": "10.1609/AIMAG.V35I4.2513",
                "CorpusId": 127197
            },
            "abstract": "Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.",
            "referenceCount": 54,
            "citationCount": 809,
            "influentialCitationCount": 61,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aaai.org/ojs/index.php/aimagazine/article/download/2513/2456",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-22",
            "journal": {
                "name": "AI Mag.",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Amershi2014PowerTT,\n author = {S. Amershi and M. Cakmak and W. B. Knox and Todd Kulesza},\n booktitle = {The AI Magazine},\n journal = {AI Mag.},\n pages = {105-120},\n title = {Power to the People: The Role of Humans in Interactive Machine Learning},\n volume = {35},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:534362486b5ae4b839f124af3413032c95c0483e",
            "@type": "ScholarlyArticle",
            "paperId": "534362486b5ae4b839f124af3413032c95c0483e",
            "corpusId": 8283795,
            "url": "https://www.semanticscholar.org/paper/534362486b5ae4b839f124af3413032c95c0483e",
            "title": "Instance spaces for machine learning classification",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2775947831",
                "DBLP": "journals/ml/MunozVBS18",
                "DOI": "10.1007/s10994-017-5629-5",
                "CorpusId": 8283795
            },
            "abstract": null,
            "referenceCount": 85,
            "citationCount": 110,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10994-017-5629-5.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Machine Learning",
                "volume": "107"
            },
            "citationStyles": {
                "bibtex": "@Article{Mu\u00f1oz2017InstanceSF,\n author = {Mario Andr\u00e9s Mu\u00f1oz and Laura Villanova and Davaatseren Baatar and K. Smith\u2010Miles},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {109-147},\n title = {Instance spaces for machine learning classification},\n volume = {107},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:92ace17730c2173e642934d64f96d359697b7a93",
            "@type": "ScholarlyArticle",
            "paperId": "92ace17730c2173e642934d64f96d359697b7a93",
            "corpusId": 6664936,
            "url": "https://www.semanticscholar.org/paper/92ace17730c2173e642934d64f96d359697b7a93",
            "title": "Bayesian reasoning and machine learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "310810636",
                "DBLP": "books/lib/Barber12",
                "DOI": "10.1017/CBO9780511804779.017",
                "CorpusId": 6664936
            },
            "abstract": "Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.",
            "referenceCount": 308,
            "citationCount": 1475,
            "influentialCitationCount": 160,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/270212.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-03-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Barber2012BayesianRA,\n author = {D. Barber},\n pages = {I-XXIV, 1-697},\n title = {Bayesian reasoning and machine learning},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a4cec122a08216fe8a3bc19b22e78fbaea096256",
            "@type": "ScholarlyArticle",
            "paperId": "a4cec122a08216fe8a3bc19b22e78fbaea096256",
            "corpusId": 3074096,
            "url": "https://www.semanticscholar.org/paper/a4cec122a08216fe8a3bc19b22e78fbaea096256",
            "title": "Deep Learning",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/nature/LeCunBH15",
                "MAG": "2557283755",
                "DOI": "10.1038/nature14539",
                "CorpusId": 3074096,
                "PubMed": "26017442"
            },
            "abstract": null,
            "referenceCount": 820,
            "citationCount": 58244,
            "influentialCitationCount": 2325,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2015-05-27",
            "journal": {
                "name": "Nature",
                "volume": "521"
            },
            "citationStyles": {
                "bibtex": "@Article{LeCun2015DeepL,\n author = {Yann LeCun and Yoshua Bengio and Geoffrey E. Hinton},\n booktitle = {Nature},\n journal = {Nature},\n pages = {436-444},\n title = {Deep Learning},\n volume = {521},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:19a28325b68346f7715e17a97eb71db1b2b3c1af",
            "@type": "ScholarlyArticle",
            "paperId": "19a28325b68346f7715e17a97eb71db1b2b3c1af",
            "corpusId": 18888927,
            "url": "https://www.semanticscholar.org/paper/19a28325b68346f7715e17a97eb71db1b2b3c1af",
            "title": "Machine Learning for Predictive Maintenance: A Multiple Classifier Approach",
            "venue": "IEEE Transactions on Industrial Informatics",
            "publicationVenue": {
                "id": "urn:research:2135230a-3b24-4b71-9583-60624389377a",
                "name": "IEEE Transactions on Industrial Informatics",
                "alternate_names": [
                    "IEEE Trans Ind Informatics"
                ],
                "issn": "1551-3203",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=9424"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/tii/SustoSPMB15",
                "MAG": "1999393241",
                "DOI": "10.1109/TII.2014.2349359",
                "CorpusId": 18888927
            },
            "abstract": "In this paper, a multiple classifier machine learning (ML) methodology for predictive maintenance (PdM) is presented. PdM is a prominent strategy for dealing with maintenance issues given the increasing need to minimize downtime and associated costs. One of the challenges with PdM is generating the so-called \u201chealth factors,\u201d or quantitative indicators, of the status of a system associated with a given maintenance issue, and determining their relationship to operating costs and failure risk. The proposed PdM methodology allows dynamical decision rules to be adopted for maintenance management, and can be used with high-dimensional and censored data problems. This is achieved by training multiple classification modules with different prediction horizons to provide different performance tradeoffs in terms of frequency of unexpected breaks and unexploited lifetime, and then employing this information in an operating cost-based maintenance decision system to minimize expected costs. The effectiveness of the methodology is demonstrated using a simulated example and a benchmark semiconductor manufacturing maintenance problem.",
            "referenceCount": 36,
            "citationCount": 519,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://pureadmin.qub.ac.uk/ws/files/17844756/machine.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-06-01",
            "journal": {
                "name": "IEEE Transactions on Industrial Informatics",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Susto2015MachineLF,\n author = {Gian Antonio Susto and A. Schirru and S. Pampuri and S. McLoone and A. Beghi},\n booktitle = {IEEE Transactions on Industrial Informatics},\n journal = {IEEE Transactions on Industrial Informatics},\n pages = {812-820},\n title = {Machine Learning for Predictive Maintenance: A Multiple Classifier Approach},\n volume = {11},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f86366feecbcfdf6c5be165fcf38c679164cc89",
            "@type": "ScholarlyArticle",
            "paperId": "9f86366feecbcfdf6c5be165fcf38c679164cc89",
            "corpusId": 205066748,
            "url": "https://www.semanticscholar.org/paper/9f86366feecbcfdf6c5be165fcf38c679164cc89",
            "title": "Machine Learning and the Profession of Medicine.",
            "venue": "Journal of the American Medical Association (JAMA)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2254050631",
                "DOI": "10.1001/jama.2015.18421",
                "CorpusId": 205066748,
                "PubMed": "26864406"
            },
            "abstract": "This Viewpoint discusses the opportunities and ethical implications of using machine learning technologies, which can rapidly collect and learn from large amounts of personal data, to provide individalized patient care.",
            "referenceCount": 6,
            "citationCount": 302,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-02-09",
            "journal": {
                "name": "JAMA",
                "volume": "315 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Darcy2016MachineLA,\n author = {Alison M Darcy and A. Louie and L. Roberts},\n booktitle = {Journal of the American Medical Association (JAMA)},\n journal = {JAMA},\n pages = {\n          551-2\n        },\n title = {Machine Learning and the Profession of Medicine.},\n volume = {315 6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad0d1149875291d9b1177bc47e53e09237beeca0",
            "@type": "ScholarlyArticle",
            "paperId": "ad0d1149875291d9b1177bc47e53e09237beeca0",
            "corpusId": 12698722,
            "url": "https://www.semanticscholar.org/paper/ad0d1149875291d9b1177bc47e53e09237beeca0",
            "title": "Quantum-enhanced machine learning",
            "venue": "Physical Review Letters",
            "publicationVenue": {
                "id": "urn:research:16c9f9d4-bee1-435d-8c85-22a3deba109d",
                "name": "Physical Review Letters",
                "alternate_names": [
                    "Phys Rev Lett"
                ],
                "issn": "0031-9007",
                "url": "https://journals.aps.org/prl/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/DunjkoTB16",
                "ArXiv": "1610.08251",
                "MAG": "2521267242",
                "DOI": "10.1103/PhysRevLett.117.130501",
                "CorpusId": 12698722,
                "PubMed": "27715099"
            },
            "abstract": "The emerging field of quantum machine learning has the potential to substantially aid in the problems and scope of artificial intelligence. This is only enhanced by recent successes in the field of classical machine learning. In this work we propose an approach for the systematic treatment of machine learning, from the perspective of quantum information. Our approach is general and covers all three main branches of machine learning: supervised, unsupervised, and reinforcement learning. While quantum improvements in supervised and unsupervised learning have been reported, reinforcement learning has received much less attention. Within our approach, we tackle the problem of quantum enhancements in reinforcement learning as well, and propose a systematic scheme for providing improvements. As an example, we show that quadratic improvements in learning efficiency, and exponential improvements in performance over limited time periods, can be obtained for a broad class of learning problems.",
            "referenceCount": 37,
            "citationCount": 284,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevLett.117.130501",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-20",
            "journal": {
                "name": "Physical review letters",
                "volume": "117 13"
            },
            "citationStyles": {
                "bibtex": "@Article{Dunjko2016QuantumenhancedML,\n author = {V. Dunjko and Jacob M. Taylor and H. Briegel},\n booktitle = {Physical Review Letters},\n journal = {Physical review letters},\n pages = {\n          130501\n        },\n title = {Quantum-enhanced machine learning},\n volume = {117 13},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a",
            "@type": "ScholarlyArticle",
            "paperId": "0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a",
            "corpusId": 308592,
            "url": "https://www.semanticscholar.org/paper/0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a",
            "title": "A review of automatic selection methods for machine learning algorithms and hyper-parameter values",
            "venue": "Network Modeling Analysis in Health Informatics and Bioinformatics",
            "publicationVenue": {
                "id": "urn:research:a6935d84-c149-452d-8d38-799076f769a9",
                "name": "Network Modeling Analysis in Health Informatics and Bioinformatics",
                "alternate_names": [
                    "Network Modeling Analysis in Health Informatics and BioInformatics",
                    "Netw Model Anal Health Informatics Bioinform"
                ],
                "issn": "2192-6670",
                "url": "http://www.springer.com/new+&+forthcoming+titles+(default)/journal/13721"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2407212869",
                "DBLP": "journals/netmahib/Luo16",
                "DOI": "10.1007/s13721-016-0125-6",
                "CorpusId": 308592
            },
            "abstract": null,
            "referenceCount": 81,
            "citationCount": 239,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-05-23",
            "journal": {
                "name": "Network Modeling Analysis in Health Informatics and Bioinformatics",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2016ARO,\n author = {G. Luo},\n booktitle = {Network Modeling Analysis in Health Informatics and Bioinformatics},\n journal = {Network Modeling Analysis in Health Informatics and Bioinformatics},\n pages = {1-16},\n title = {A review of automatic selection methods for machine learning algorithms and hyper-parameter values},\n volume = {5},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4ec306ab408839fa060cfe4f6ce969c43df65ed9",
            "@type": "ScholarlyArticle",
            "paperId": "4ec306ab408839fa060cfe4f6ce969c43df65ed9",
            "corpusId": 96428775,
            "url": "https://www.semanticscholar.org/paper/4ec306ab408839fa060cfe4f6ce969c43df65ed9",
            "title": "Machine Learning Phases of Strongly Correlated Fermions",
            "venue": "Physical Review X",
            "publicationVenue": {
                "id": "urn:research:98eedf55-1e67-4c3d-a25d-79861b87ae04",
                "name": "Physical Review X",
                "alternate_names": [
                    "Phys Rev X"
                ],
                "issn": "2160-3308",
                "url": "https://journals.aps.org/prx/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2520014252",
                "ArXiv": "1609.02552",
                "DOI": "10.1103/PhysRevX.7.031038",
                "CorpusId": 96428775
            },
            "abstract": "Machine learning offers an unprecedented perspective for the problem of classifying phases in condensed matter physics. We employ neural-network machine learning techniques to distinguish finite-temperature phases of the strongly correlated fermions on cubic lattices. We show that a three dimensional convolutional network trained on auxiliary field configurations produced by quantum Monte Carlo simulations of the Hubbard model can correctly predict the magnetic phase diagram of the model at the average density of one (half filling). We then use the network, trained at half filling, to explore the trend in the transition temperature as the system is doped away from half filling. This transfer learning approach predicts that the instability to the magnetic phase extends to at least 5% doping in this region. Our results pave the way for other machine learning applications in correlated quantum many-body systems.",
            "referenceCount": 31,
            "citationCount": 281,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevX.7.031038",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-09-08",
            "journal": {
                "name": "Physical Review X",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Ch'ng2016MachineLP,\n author = {K. Ch'ng and J. Carrasquilla and R. Melko and E. Khatami},\n booktitle = {Physical Review X},\n journal = {Physical Review X},\n title = {Machine Learning Phases of Strongly Correlated Fermions},\n volume = {7},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:49d1f40312af25d01da721e33f4a8be8cea29551",
            "@type": "ScholarlyArticle",
            "paperId": "49d1f40312af25d01da721e33f4a8be8cea29551",
            "corpusId": 59701880,
            "url": "https://www.semanticscholar.org/paper/49d1f40312af25d01da721e33f4a8be8cea29551",
            "title": "Data mining - practical machine learning tools and techniques, Second Edition",
            "venue": "The Morgan Kaufmann series in data management systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "books/daglib/0020109",
                "CorpusId": 59701880
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 2168,
            "influentialCitationCount": 246,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Witten2005DataM,\n author = {I. Witten and E. Frank},\n booktitle = {The Morgan Kaufmann series in data management systems},\n pages = {I-XXXI, 1-525},\n title = {Data mining - practical machine learning tools and techniques, Second Edition},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "@type": "ScholarlyArticle",
            "paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "corpusId": 160705,
            "url": "https://www.semanticscholar.org/paper/f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2964059111",
                "DBLP": "conf/icml/GalG16",
                "ArXiv": "1506.02142",
                "CorpusId": 160705
            },
            "abstract": "Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.",
            "referenceCount": 56,
            "citationCount": 6983,
            "influentialCitationCount": 1195,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gal2015DropoutAA,\n author = {Y. Gal and Zoubin Ghahramani},\n booktitle = {International Conference on Machine Learning},\n pages = {1050-1059},\n title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f8c7783a92d4c2f388902fffb3b378921f9e8ad",
            "@type": "ScholarlyArticle",
            "paperId": "7f8c7783a92d4c2f388902fffb3b378921f9e8ad",
            "corpusId": 8475881,
            "url": "https://www.semanticscholar.org/paper/7f8c7783a92d4c2f388902fffb3b378921f9e8ad",
            "title": "Machine Learning in Wireless Sensor Networks: Algorithms, Strategies, and Applications",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2128569883",
                "DBLP": "journals/comsur/AlsheikhLNT14",
                "ArXiv": "1405.4463",
                "DOI": "10.1109/COMST.2014.2320099",
                "CorpusId": 8475881
            },
            "abstract": "Wireless sensor networks (WSNs) monitor dynamic environments that change rapidly over time. This dynamic behavior is either caused by external factors or initiated by the system designers themselves. To adapt to such conditions, sensor networks often adopt machine learning techniques to eliminate the need for unnecessary redesign. Machine learning also inspires many practical solutions that maximize resource utilization and prolong the lifespan of the network. In this paper, we present an extensive literature review over the period 2002-2013 of machine learning methods that were used to address common issues in WSNs. The advantages and disadvantages of each proposed algorithm are evaluated against the corresponding problem. We also provide a comparative guide to aid WSN designers in developing suitable machine learning solutions for their specific application challenges.",
            "referenceCount": 164,
            "citationCount": 750,
            "influentialCitationCount": 40,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-04-24",
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Alsheikh2014MachineLI,\n author = {Mohammad Abu Alsheikh and Shaowei Lin and D. Niyato and H. Tan},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {1996-2018},\n title = {Machine Learning in Wireless Sensor Networks: Algorithms, Strategies, and Applications},\n volume = {16},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:139b2afafdaccba02c983d2f40f257db64860320",
            "@type": "ScholarlyArticle",
            "paperId": "139b2afafdaccba02c983d2f40f257db64860320",
            "corpusId": 119304927,
            "url": "https://www.semanticscholar.org/paper/139b2afafdaccba02c983d2f40f257db64860320",
            "title": "Machine Learning Topological States",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2769287225",
                "ArXiv": "1609.09060",
                "DOI": "10.1103/PhysRevB.96.195145",
                "CorpusId": 119304927
            },
            "abstract": "Machine learning, the core of artificial intelligence and data science, is a very active field, with vast applications throughout science and technology. Recently, machine learning techniques have been adopted to tackle intricate quantum many-body problems and phase transitions. In this work, the authors construct exact mappings from exotic quantum states to machine learning network models. This work shows for the first time that the restricted Boltzmann machine can be used to study both symmetry-protected topological phases and intrinsic topological order. The exact results are expected to provide a substantial boost to the field of machine learning of phases of matter.",
            "referenceCount": 85,
            "citationCount": 210,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.aps.org/accepted/10.1103/PhysRevB.96.195145",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-09-28",
            "journal": {
                "name": "Physical Review B",
                "volume": "96"
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2016MachineLT,\n author = {D. Deng and Xiaopeng Li and Xiaopeng Li and S. Sarma},\n journal = {Physical Review B},\n pages = {195145},\n title = {Machine Learning Topological States},\n volume = {96},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:24e6c5bfe9bb0751e5708b501d04e860011b2953",
            "@type": "ScholarlyArticle",
            "paperId": "24e6c5bfe9bb0751e5708b501d04e860011b2953",
            "corpusId": 3595292,
            "url": "https://www.semanticscholar.org/paper/24e6c5bfe9bb0751e5708b501d04e860011b2953",
            "title": "Applications of Support Vector Machine (SVM) Learning in Cancer Genomics.",
            "venue": "Cancer Genomics & Proteomics",
            "publicationVenue": {
                "id": "urn:research:d03d0f51-5944-496b-9d0d-180dbc4edddc",
                "name": "Cancer Genomics & Proteomics",
                "alternate_names": [
                    "Cancer Genom  Proteom"
                ],
                "issn": "1109-6535",
                "url": "http://www.cgp-journal.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2778455075",
                "DOI": "10.21873/CGP.20063",
                "CorpusId": 3595292,
                "PubMed": "29275361"
            },
            "abstract": "Machine learning with maximization (support) of separating margin (vector), called support vector machine (SVM) learning, is a powerful classification tool that has been used for cancer genomic classification or subtyping. Today, as advancements in high-throughput technologies lead to production of large amounts of genomic and epigenomic data, the classification feature of SVMs is expanding its use in cancer genomics, leading to the discovery of new biomarkers, new drug targets, and a better understanding of cancer driver genes. Herein we reviewed the recent progress of SVMs in cancer genomic studies. We intend to comprehend the strength of the SVM learning and its future perspective in cancer genomic applications.",
            "referenceCount": 68,
            "citationCount": 738,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://cgp.iiarjournals.org/content/15/1/41.full.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Cancer genomics & proteomics",
                "volume": "15 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2018ApplicationsOS,\n author = {Shujun Huang and Nianguang Cai and Pedro Penzuti Pacheco and Shavira Narrandes and Yang Wang and Wayne W. Xu},\n booktitle = {Cancer Genomics & Proteomics},\n journal = {Cancer genomics & proteomics},\n pages = {\n          41-51\n        },\n title = {Applications of Support Vector Machine (SVM) Learning in Cancer Genomics.},\n volume = {15 1},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:85d2d4cb2ca1dcd9da2d5a765cc2aa4911b0a175",
            "@type": "ScholarlyArticle",
            "paperId": "85d2d4cb2ca1dcd9da2d5a765cc2aa4911b0a175",
            "corpusId": 119263556,
            "url": "https://www.semanticscholar.org/paper/85d2d4cb2ca1dcd9da2d5a765cc2aa4911b0a175",
            "title": "An introduction to quantum machine learning",
            "venue": "Contemporary physics (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2015811642",
                "ArXiv": "1409.3097",
                "DOI": "10.1080/00107514.2014.964942",
                "CorpusId": 119263556
            },
            "abstract": "Machine learning algorithms learn a desired input-output relation from examples in order to interpret new inputs. This is important for tasks such as image and speech recognition or strategy optimisation, with growing applications in the IT industry. In the last couple of years, researchers investigated if quantum computing can help to improve classical machine learning algorithms. Ideas range from running computationally costly algorithms or their subroutines efficiently on a quantum computer to the translation of stochastic methods into the language of quantum theory. This contribution gives a systematic overview of the emerging field of quantum machine learning. It presents the approaches as well as technical details in an accessible way, and discusses the potential of a future theory of quantum learning.",
            "referenceCount": 79,
            "citationCount": 729,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1409.3097",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2014-09-10",
            "journal": {
                "name": "Contemporary Physics",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Schuld2014AnIT,\n author = {M. Schuld and I. Sinayskiy and Francesco Petruccione},\n booktitle = {Contemporary physics (Print)},\n journal = {Contemporary Physics},\n pages = {172 - 185},\n title = {An introduction to quantum machine learning},\n volume = {56},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f839dc673d4889688bae5d3b6460bb2eb718cd2",
            "@type": "ScholarlyArticle",
            "paperId": "0f839dc673d4889688bae5d3b6460bb2eb718cd2",
            "corpusId": 218507894,
            "url": "https://www.semanticscholar.org/paper/0f839dc673d4889688bae5d3b6460bb2eb718cd2",
            "title": "Machine learning",
            "venue": "Preview",
            "publicationVenue": {
                "id": "urn:research:43059831-a686-4842-8325-39838ccc51f1",
                "name": "Preview",
                "alternate_names": null,
                "issn": "1443-2471",
                "url": "http://www.publish.csiro.au/nid/228.htm"
            },
            "year": 2019,
            "externalIds": {
                "DOI": "10.1080/14432471.2019.1597409",
                "CorpusId": 218507894
            },
            "abstract": "Initialize G to the set of maximally general hypotheses in H Initialize S to the set of maximally specific hypotheses in H For each training example d, do \u2022 If d is a positive example \u2022 Remove from G any hypothesis inconsistent with d \u2022 For each hypothesis s in S that is not consistent with d \u2022 Remove s from S \u2022 Add to S all minimal generalizations h of s such that \u2022 h is consistent with d, and some member of G is more general than h \u2022 Remove from S any hypothesis that is more general than another hypothesis in S",
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.tandfonline.com/doi/pdf/10.1080/14432471.2019.1597409?needAccess=true",
                "status": "BRONZE"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-03-04",
            "journal": {
                "name": "Preview",
                "volume": "2019"
            },
            "citationStyles": {
                "bibtex": "@Article{Keeping2019MachineL,\n author = {Tim Keeping},\n booktitle = {Preview},\n journal = {Preview},\n pages = {37 - 37},\n title = {Machine learning},\n volume = {2019},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bdb5f7fc1608dd80e2d3fdb1575cec2d3c074ad6",
            "@type": "ScholarlyArticle",
            "paperId": "bdb5f7fc1608dd80e2d3fdb1575cec2d3c074ad6",
            "corpusId": 17860116,
            "url": "https://www.semanticscholar.org/paper/bdb5f7fc1608dd80e2d3fdb1575cec2d3c074ad6",
            "title": "A survey of feature selection and feature extraction techniques in machine learning",
            "venue": "Sai",
            "publicationVenue": {
                "id": "urn:research:e12d355b-ad1e-428d-ba3e-8373fd3a7bd8",
                "name": "Sai",
                "alternate_names": [
                    "Science and Information Conference",
                    "Sci Inf Conf",
                    "SAI"
                ],
                "issn": "1975-7743",
                "url": "http://www.koreanst.org/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2087016914",
                "DOI": "10.1109/SAI.2014.6918213",
                "CorpusId": 17860116
            },
            "abstract": "Dimensionality reduction as a preprocessing step to machine learning is effective in removing irrelevant and redundant data, increasing learning accuracy, and improving result comprehensibility. However, the recent increase of dimensionality of data poses a severe challenge to many existing feature selection and feature extraction methods with respect to efficiency and effectiveness. In the field of machine learning and pattern recognition, dimensionality reduction is important area, where many approaches have been proposed. In this paper, some widely used feature selection and feature extraction techniques have analyzed with the purpose of how effectively these techniques can be used to achieve high performance of learning algorithms that ultimately improves predictive accuracy of classifier. An endeavor to analyze dimensionality reduction techniques briefly with the purpose to investigate strengths and weaknesses of some widely used dimensionality reduction methods is presented.",
            "referenceCount": 29,
            "citationCount": 712,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2014-10-09",
            "journal": {
                "name": "2014 Science and Information Conference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Khalid2014ASO,\n author = {S. Khalid and Tehmina Khalil and Shamila Nasreen},\n booktitle = {Sai},\n journal = {2014 Science and Information Conference},\n pages = {372-378},\n title = {A survey of feature selection and feature extraction techniques in machine learning},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:04ca5de59edbdd49a9c0502c58331524d220bc8c",
            "@type": "ScholarlyArticle",
            "paperId": "04ca5de59edbdd49a9c0502c58331524d220bc8c",
            "corpusId": 2235165,
            "url": "https://www.semanticscholar.org/paper/04ca5de59edbdd49a9c0502c58331524d220bc8c",
            "title": "Communication Efficient Distributed Machine Learning with the Parameter Server",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2127941149",
                "DBLP": "conf/nips/LiASY14",
                "CorpusId": 2235165
            },
            "abstract": "This paper describes a third-generation parameter server framework for distributed machine learning. This framework offers two relaxations to balance system performance and algorithm efficiency. We propose a new algorithm that takes advantage of this framework to solve non-convex non-smooth problems with convergence guarantees. We present an in-depth analysis of two large scale machine learning problems ranging from l1 -regularized logistic regression on CPUs to reconstruction ICA on GPUs, using 636TB of real data with hundreds of billions of samples and dimensions. We demonstrate using these examples that the parameter server framework is an effective and straightforward way to scale machine learning to larger problems and systems than have been previously achieved.",
            "referenceCount": 39,
            "citationCount": 558,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-12-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2014CommunicationED,\n author = {Mu Li and D. Andersen and Alex Smola and Kai Yu},\n booktitle = {Neural Information Processing Systems},\n pages = {19-27},\n title = {Communication Efficient Distributed Machine Learning with the Parameter Server},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aaa76e15235d937d093a7063c0be86ed84494dee",
            "@type": "ScholarlyArticle",
            "paperId": "aaa76e15235d937d093a7063c0be86ed84494dee",
            "corpusId": 60186769,
            "url": "https://www.semanticscholar.org/paper/aaa76e15235d937d093a7063c0be86ed84494dee",
            "title": "Machine Learning: A Bayesian and Optimization Perspective",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "368469426",
                "CorpusId": 60186769
            },
            "abstract": "This tutorial text gives a unifying perspective on machine learning by covering bothprobabilistic and deterministic approaches -which are based on optimization techniques together with the Bayesian inference approach, whose essence liesin the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts. The book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models. All major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods. The latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling. Case studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied. MATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.",
            "referenceCount": 0,
            "citationCount": 459,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2015-04-10",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Theodoridis2015MachineLA,\n author = {S. Theodoridis},\n title = {Machine Learning: A Bayesian and Optimization Perspective},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3449b65008b27f6e60a73d80c1fd990f0481126b",
            "@type": "ScholarlyArticle",
            "paperId": "3449b65008b27f6e60a73d80c1fd990f0481126b",
            "corpusId": 14365368,
            "url": "https://www.semanticscholar.org/paper/3449b65008b27f6e60a73d80c1fd990f0481126b",
            "title": "Torch7: A Matlab-like Environment for Machine Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "753012316",
                "CorpusId": 14365368
            },
            "abstract": "Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be interfaced to third-party software thanks to Lua\u2019s light interface.",
            "referenceCount": 3,
            "citationCount": 1516,
            "influentialCitationCount": 121,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Collobert2011Torch7AM,\n author = {Ronan Collobert and K. Kavukcuoglu and C. Farabet},\n booktitle = {Neural Information Processing Systems},\n title = {Torch7: A Matlab-like Environment for Machine Learning},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c3a159d6a85be68af4c985c281718bc5801ada19",
            "@type": "ScholarlyArticle",
            "paperId": "c3a159d6a85be68af4c985c281718bc5801ada19",
            "corpusId": 264145480,
            "url": "https://www.semanticscholar.org/paper/c3a159d6a85be68af4c985c281718bc5801ada19",
            "title": "Lifelong Machine Learning",
            "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
            "publicationVenue": {
                "id": "urn:research:84e95d47-8c6e-4f56-b8c8-2fc3088cfb6b",
                "name": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
                "alternate_names": [
                    "Synth Lect Artif Intell Mach Learn"
                ],
                "issn": "1939-4608",
                "url": "https://www.morganclaypool.com/toc/aim/1/1"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2565989828",
                "DBLP": "series/synthesis/2016Chen",
                "DOI": "10.1007/978-3-031-01575-5",
                "CorpusId": 264145480
            },
            "abstract": null,
            "referenceCount": 92,
            "citationCount": 106,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-031-01581-6/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2016-11-07",
            "journal": {
                "name": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2016LifelongML,\n author = {Zhiyuan Chen and Bing Liu},\n booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},\n journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},\n title = {Lifelong Machine Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e",
            "@type": "ScholarlyArticle",
            "paperId": "a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e",
            "corpusId": 206764370,
            "url": "https://www.semanticscholar.org/paper/a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e",
            "title": "Faster and Better: A Machine Learning Approach to Corner Detection",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2170282673",
                "DBLP": "journals/pami/RostenPD10",
                "ArXiv": "0810.2434",
                "DOI": "10.1109/TPAMI.2008.275",
                "CorpusId": 206764370,
                "PubMed": "19926902"
            },
            "abstract": "The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is important because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection and, using machine learning, we derive a feature detector from this which can fully process live PAL video using less than 5 percent of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115 percent, SIFT 195 percent). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that, despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and of very high quality.",
            "referenceCount": 107,
            "citationCount": 1836,
            "influentialCitationCount": 201,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/0810.2434",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-10-14",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Rosten2008FasterAB,\n author = {E. Rosten and R. Porter and T. Drummond},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {105-119},\n title = {Faster and Better: A Machine Learning Approach to Corner Detection},\n volume = {32},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f743833c22961537791171ef1d3fb42db8f357a3",
            "@type": "ScholarlyArticle",
            "paperId": "f743833c22961537791171ef1d3fb42db8f357a3",
            "corpusId": 12237987,
            "url": "https://www.semanticscholar.org/paper/f743833c22961537791171ef1d3fb42db8f357a3",
            "title": "Machine Learning Methods for Attack Detection in the Smart Grid",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1503.06468",
                "MAG": "2002254092",
                "DBLP": "journals/tnn/OzayEVKP16",
                "DOI": "10.1109/TNNLS.2015.2404803",
                "CorpusId": 12237987,
                "PubMed": "25807571"
            },
            "abstract": "Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework.",
            "referenceCount": 56,
            "citationCount": 419,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1503.06468",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-03-22",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Ozay2015MachineLM,\n author = {M. Ozay and I. Esnaola and Fatos Tunay and Yarman Vural and S. Kulkarni and H. Vincent Poor},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {1773-1786},\n title = {Machine Learning Methods for Attack Detection in the Smart Grid},\n volume = {27},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:611544418ca53cdad254df444addc7814abcfddc",
            "@type": "ScholarlyArticle",
            "paperId": "611544418ca53cdad254df444addc7814abcfddc",
            "corpusId": 239237883,
            "url": "https://www.semanticscholar.org/paper/611544418ca53cdad254df444addc7814abcfddc",
            "title": "An introduction to statistical learning with applications in R",
            "venue": "Statistical Theory and Related Fields",
            "publicationVenue": {
                "id": "urn:research:63d5660f-c56d-4a40-b401-f460e483e476",
                "name": "Statistical Theory and Related Fields",
                "alternate_names": [
                    "Stat Theory Relat Field"
                ],
                "issn": "2475-4269",
                "url": "http://www.tandfonline.com/loi/tstf20"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1080/24754269.2021.1980261",
                "CorpusId": 239237883
            },
            "abstract": "The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts. Every chapter includes worked examples and exercises to test understanding. Programming tutorials are offered on the book's web site. This textbook considers statistical learning applications when interest centers on the conditional distribution of a response variable, given a set of predictors, and in the absence of a credible model that can be specified before the data analysis begins. Consistent with modern data analytics, it emphasizes that a proper statistical learning data analysis depends in an integrated fashion on sound data collection, intelligent data management, appropriate statistical procedures, and an",
            "referenceCount": 0,
            "citationCount": 2591,
            "influentialCitationCount": 235,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.tandfonline.com/doi/pdf/10.1080/24754269.2021.1980261?needAccess=true",
                "status": "HYBRID"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2021-09-26",
            "journal": {
                "name": "Statistical Theory and Related Fields",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Sohil2021AnIT,\n author = {Fariha Sohil and Muhammad Umair Sohali and J. Shabbir},\n booktitle = {Statistical Theory and Related Fields},\n journal = {Statistical Theory and Related Fields},\n pages = {87 - 87},\n title = {An introduction to statistical learning with applications in R},\n volume = {6},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c35bab85900cd6c09eaddc1b1a9541bbc0bbcc3",
            "@type": "ScholarlyArticle",
            "paperId": "1c35bab85900cd6c09eaddc1b1a9541bbc0bbcc3",
            "corpusId": 10213552,
            "url": "https://www.semanticscholar.org/paper/1c35bab85900cd6c09eaddc1b1a9541bbc0bbcc3",
            "title": "A survey of open source tools for machine learning with big data in the Hadoop ecosystem",
            "venue": "Journal of Big Data",
            "publicationVenue": {
                "id": "urn:research:d60da343-ab92-4310-b3d7-2c0860287a9d",
                "name": "Journal of Big Data",
                "alternate_names": [
                    "J Big Data",
                    "Journal on Big Data"
                ],
                "issn": "2196-1115",
                "url": "http://www.journalofbigdata.com/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2126623642",
                "DBLP": "journals/jbd/LandsetKRH15",
                "DOI": "10.1186/s40537-015-0032-1",
                "CorpusId": 10213552
            },
            "abstract": null,
            "referenceCount": 122,
            "citationCount": 391,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-015-0032-1",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2015-11-05",
            "journal": {
                "name": "Journal of Big Data",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Landset2015ASO,\n author = {Sara Landset and T. Khoshgoftaar and Aaron N. Richter and Tawfiq Hasanin},\n booktitle = {Journal of Big Data},\n journal = {Journal of Big Data},\n pages = {1-36},\n title = {A survey of open source tools for machine learning with big data in the Hadoop ecosystem},\n volume = {2},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cc242e85615d38ab166295753823180ec9099951",
            "@type": "ScholarlyArticle",
            "paperId": "cc242e85615d38ab166295753823180ec9099951",
            "corpusId": 16908169,
            "url": "https://www.semanticscholar.org/paper/cc242e85615d38ab166295753823180ec9099951",
            "title": "Scikit-learn: Machine Learning Without Learning the Machinery",
            "venue": "GETMBL",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2244501064",
                "DBLP": "journals/sigmobile/VaroquauxBLGPM15",
                "DOI": "10.1145/2786984.2786995",
                "CorpusId": 16908169
            },
            "abstract": "Machine learning is a pervasive development at the intersection of statistics and computer science. While it can benefit many data-related applications, the technical nature of the research literature and the corresponding algorithms slows down its adoption. Scikit-learn is an open-source software project that aims at making machine learning accessible to all, whether it be in academia or in industry. It benefits from the general-purpose Python language, which is both broadly adopted in the scientific world, and supported by a thriving ecosystem of contributors. Here we give a quick introduction to scikit-learn as well as to machine-learning basics.",
            "referenceCount": 20,
            "citationCount": 363,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-06-01",
            "journal": {
                "name": "GetMobile Mob. Comput. Commun.",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Varoquaux2015ScikitlearnML,\n author = {G. Varoquaux and L. Buitinck and Gilles Louppe and O. Grisel and Fabian Pedregosa and A. Mueller},\n booktitle = {GETMBL},\n journal = {GetMobile Mob. Comput. Commun.},\n pages = {29-33},\n title = {Scikit-learn: Machine Learning Without Learning the Machinery},\n volume = {19},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0173ca962e4ab3d084c89568345e06f67d3d7efc",
            "@type": "ScholarlyArticle",
            "paperId": "0173ca962e4ab3d084c89568345e06f67d3d7efc",
            "corpusId": 17147092,
            "url": "https://www.semanticscholar.org/paper/0173ca962e4ab3d084c89568345e06f67d3d7efc",
            "title": "Hyperparameter Search in Machine Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2951143820",
                "ArXiv": "1502.02127",
                "DBLP": "journals/corr/ClaesenM15",
                "CorpusId": 17147092
            },
            "abstract": "We introduce the hyperparameter search problem in the field of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can significantly affect the resulting model's performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential.",
            "referenceCount": 47,
            "citationCount": 356,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-02-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.02127"
            },
            "citationStyles": {
                "bibtex": "@Article{Claesen2015HyperparameterSI,\n author = {M. Claesen and B. Moor},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Hyperparameter Search in Machine Learning},\n volume = {abs/1502.02127},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5888c776e38f39efb9b96d0ba2713981008a86b1",
            "@type": "ScholarlyArticle",
            "paperId": "5888c776e38f39efb9b96d0ba2713981008a86b1",
            "corpusId": 60745434,
            "url": "https://www.semanticscholar.org/paper/5888c776e38f39efb9b96d0ba2713981008a86b1",
            "title": "Structural Health Monitoring: A Machine Learning Perspective",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "1582368210",
                "DOI": "10.1002/9781118443118",
                "CorpusId": 60745434
            },
            "abstract": "This book focuses on structural health monitoring in the context of machine learning. The authors review the technical literature and include case studies. Chapters include: operational evaluation, sensing and data acquisition, introduction to probability and statistics, machine learning and statistical pattern recognition, and data prognosis.",
            "referenceCount": 75,
            "citationCount": 1164,
            "influentialCitationCount": 97,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://ela.kpi.ua/bitstream/123456789/21467/1/2016_2825.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2012-11-19",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Farrar2012StructuralHM,\n author = {C. Farrar and K. Worden},\n title = {Structural Health Monitoring: A Machine Learning Perspective},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:68837728232463651283edbb7ef0c93b2f502b2b",
            "@type": "ScholarlyArticle",
            "paperId": "68837728232463651283edbb7ef0c93b2f502b2b",
            "corpusId": 8940335,
            "url": "https://www.semanticscholar.org/paper/68837728232463651283edbb7ef0c93b2f502b2b",
            "title": "PuDianNao: A Polyvalent Machine Learning Accelerator",
            "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems",
            "publicationVenue": {
                "id": "urn:research:d4610af5-85e0-480b-8773-5c71d92a7b99",
                "name": "International Conference on Architectural Support for Programming Languages and Operating Systems",
                "alternate_names": [
                    "ASPLOS",
                    "Int Conf Archit Support Program Lang Oper Syst",
                    "Archit Support Program Lang Oper Syst",
                    "Architectural Support for Programming Languages and Operating Systems"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigplan/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/asplos/LiuCLZZTFZC15",
                "MAG": "2000967104",
                "DOI": "10.1145/2694344.2694358",
                "CorpusId": 8940335
            },
            "abstract": "Machine Learning (ML) techniques are pervasive tools in various emerging commercial applications, but have to be accommodated by powerful computer systems to process very large data. Although general-purpose CPUs and GPUs have provided straightforward solutions, their energy-efficiencies are limited due to their excessive supports for flexibility. Hardware accelerators may achieve better energy-efficiencies, but each accelerator often accommodates only a single ML technique (family). According to the famous No-Free-Lunch theorem in the ML domain, however, an ML technique performs well on a dataset may perform poorly on another dataset, which implies that such accelerator may sometimes lead to poor learning accuracy. Even if regardless of the learning accuracy, such accelerator can still become inapplicable simply because the concrete ML task is altered, or the user chooses another ML technique. In this study, we present an ML accelerator called PuDianNao, which accommodates seven representative ML techniques, including k-means, k-nearest neighbors, naive bayes, support vector machine, linear regression, classification tree, and deep neural network. Benefited from our thorough analysis on computational primitives and locality properties of different ML techniques, PuDianNao can perform up to 1056 GOP/s (e.g., additions and multiplications) in an area of 3.51 mm^2, and consumes 596 mW only. Compared with the NVIDIA K20M GPU (28nm process), PuDianNao (65nm process) is 1.20x faster, and can reduce the energy by 128.41x.",
            "referenceCount": 40,
            "citationCount": 287,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2015-03-14",
            "journal": {
                "name": "Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2015PuDianNaoAP,\n author = {Dao-Fu Liu and Tianshi Chen and Shaoli Liu and Jinhong Zhou and Shengyuan Zhou and O. Temam and Xiaobing Feng and Xuehai Zhou and Yunji Chen},\n booktitle = {International Conference on Architectural Support for Programming Languages and Operating Systems},\n journal = {Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems},\n title = {PuDianNao: A Polyvalent Machine Learning Accelerator},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5df0a0e9ceec70a9321b0555288222bf53216342",
            "@type": "ScholarlyArticle",
            "paperId": "5df0a0e9ceec70a9321b0555288222bf53216342",
            "corpusId": 62529370,
            "url": "https://www.semanticscholar.org/paper/5df0a0e9ceec70a9321b0555288222bf53216342",
            "title": "Neural Networks in Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2096338573",
                "CorpusId": 62529370
            },
            "abstract": "Machine Learning is associated with the study and construction of systems that can learn on their own rather than following instructions. It is used in search engines, optical character recognition, computer vision etc. Neural networks are one of the several techniques used in machine learning. Here we are trying to discuss neural network approaches used in machine learning.",
            "referenceCount": 11,
            "citationCount": 414,
            "influentialCitationCount": 50,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2014-11-18",
            "journal": {
                "name": "International Journal of Computer Applications",
                "volume": "105"
            },
            "citationStyles": {
                "bibtex": "@Article{Parashar2014NeuralNI,\n author = {Parul Parashar},\n journal = {International Journal of Computer Applications},\n pages = {1-3},\n title = {Neural Networks in Machine Learning},\n volume = {105},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29b9ff8f4a26acc90e6182e1e749f15f688bc7cf",
            "@type": "ScholarlyArticle",
            "paperId": "29b9ff8f4a26acc90e6182e1e749f15f688bc7cf",
            "corpusId": 94314605,
            "url": "https://www.semanticscholar.org/paper/29b9ff8f4a26acc90e6182e1e749f15f688bc7cf",
            "title": "Machine learning for quantum mechanics in a nutshell",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1584846110",
                "DOI": "10.1002/QUA.24954",
                "CorpusId": 94314605
            },
            "abstract": "Models that combine quantum mechanics (QM) with machine learning (ML) promise to deliver the accuracy of QM at the speed of ML. This hands-on tutorial introduces the reader to QM/ML models based on kernel learning, an elegant, systematically nonlinear form of ML. Pseudocode and a reference implementation are provided, enabling the reader to reproduce results from recent publications where atomization energies of small organic molecules are predicted using kernel ridge regression. \u00a9 2015 Wiley Periodicals, Inc.",
            "referenceCount": 110,
            "citationCount": 300,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/qua.24954",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2015-08-15",
            "journal": {
                "name": "International Journal of Quantum Chemistry",
                "volume": "115"
            },
            "citationStyles": {
                "bibtex": "@Article{Rupp2015MachineLF,\n author = {M. Rupp},\n journal = {International Journal of Quantum Chemistry},\n pages = {1058-1073},\n title = {Machine learning for quantum mechanics in a nutshell},\n volume = {115},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2878d9936f494ed7d0c8aec47e9bcc5e51609f9a",
            "@type": "ScholarlyArticle",
            "paperId": "2878d9936f494ed7d0c8aec47e9bcc5e51609f9a",
            "corpusId": 206757279,
            "url": "https://www.semanticscholar.org/paper/2878d9936f494ed7d0c8aec47e9bcc5e51609f9a",
            "title": "Extreme Learning Machine for Multilayer Perceptron",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/tnn/TangDH16",
                "MAG": "2301541953",
                "DOI": "10.1109/TNNLS.2015.2424995",
                "CorpusId": 206757279,
                "PubMed": "25966483"
            },
            "abstract": "Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parameters are randomly generated and the output weights are analytically computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via \u21131 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme.",
            "referenceCount": 34,
            "citationCount": 1138,
            "influentialCitationCount": 106,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-04-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Tang2016ExtremeLM,\n author = {Jiexiong Tang and Chenwei Deng and G. Huang},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {809-821},\n title = {Extreme Learning Machine for Multilayer Perceptron},\n volume = {27},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30",
            "@type": "ScholarlyArticle",
            "paperId": "ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30",
            "corpusId": 206823005,
            "url": "https://www.semanticscholar.org/paper/ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30",
            "title": "MLaaS: Machine Learning as a Service",
            "venue": "International Conference on Machine Learning and Applications",
            "publicationVenue": {
                "id": "urn:research:f6752838-f268-4a1b-87e7-c5f30a36713c",
                "name": "International Conference on Machine Learning and Applications",
                "alternate_names": [
                    "Int Conf Mach Learn Appl",
                    "ICMLA"
                ],
                "issn": null,
                "url": "http://www.icmla-conference.org/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/icmla/RibeiroGC15",
                "MAG": "2294710185",
                "DOI": "10.1109/ICMLA.2015.152",
                "CorpusId": 206823005
            },
            "abstract": "The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.",
            "referenceCount": 12,
            "citationCount": 272,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://publish.uwo.ca/%7Ekgroling/papers/MLaaS.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-01",
            "journal": {
                "name": "2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ribeiro2015MLaaSML,\n author = {Mauro Ribeiro and Katarina Grolinger and Miriam A. M. Capretz},\n booktitle = {International Conference on Machine Learning and Applications},\n journal = {2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)},\n pages = {896-902},\n title = {MLaaS: Machine Learning as a Service},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
            "@type": "ScholarlyArticle",
            "paperId": "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
            "corpusId": 51975610,
            "url": "https://www.semanticscholar.org/paper/48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
            "title": "Determinantal Point Processes for Machine Learning",
            "venue": "Found. Trends Mach. Learn.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "journals/corr/abs-1207-6083",
                "MAG": "2138779671",
                "ArXiv": "1207.6083",
                "DOI": "10.1561/2200000044",
                "CorpusId": 51975610
            },
            "abstract": "Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. While they have been studied extensively by mathematicians, giving rise to a deep and beautiful theory, DPPs are relatively new in machine learning. Determinantal Point Processes for Machine Learning provides a comprehensible introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and shows how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories. It presents the general mathematical background to DPPs along with a range of modeling extensions, efficient algorithms, and theoretical results that aim to enable practical modeling and learning.",
            "referenceCount": 162,
            "citationCount": 945,
            "influentialCitationCount": 195,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1207.6083",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-07-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1207.6083"
            },
            "citationStyles": {
                "bibtex": "@Article{Kulesza2012DeterminantalPP,\n author = {Alex Kulesza and B. Taskar},\n booktitle = {Found. Trends Mach. Learn.},\n journal = {ArXiv},\n title = {Determinantal Point Processes for Machine Learning},\n volume = {abs/1207.6083},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a15067563a18378dac71a206c6cc2e2d8c871301",
            "@type": "ScholarlyArticle",
            "paperId": "a15067563a18378dac71a206c6cc2e2d8c871301",
            "corpusId": 1609914,
            "url": "https://www.semanticscholar.org/paper/a15067563a18378dac71a206c6cc2e2d8c871301",
            "title": "Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "1491953704",
                "DBLP": "conf/icml/Hall00",
                "CorpusId": 1609914
            },
            "abstract": "Algorithms for feature selection fall into two broad categories: wrappers that use the learning algorithm itself to evaluate the usefulness of features and filters that evaluate features according to heuristics based on general characteristics of the data. For application to large databases, filters have proven to be more practical than wrappers because they are much faster. However, most existing filter algorithms only work with discrete classification problems. This paper describes a fast, correlation-based filter algorithm that can be applied to continuous and discrete problems. The algorithm often outperforms the well-known ReliefF attribute estimator when used as a preprocessing step for naive Bayes, instance-based learning, decision trees, locally weighted regression, and model trees. It performs more feature selection than ReliefF does\u2014reducing the data dimensionality by fifty percent in most cases. Also, decision and model trees built from the preprocessed data are often significantly smaller.",
            "referenceCount": 27,
            "citationCount": 1966,
            "influentialCitationCount": 221,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1999-04-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hall1999CorrelationbasedFS,\n author = {M. Hall},\n booktitle = {International Conference on Machine Learning},\n pages = {359-366},\n title = {Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aa6df100cb0a22a941c4dd89de07a0e34b344b4f",
            "@type": "ScholarlyArticle",
            "paperId": "aa6df100cb0a22a941c4dd89de07a0e34b344b4f",
            "corpusId": 202782967,
            "url": "https://www.semanticscholar.org/paper/aa6df100cb0a22a941c4dd89de07a0e34b344b4f",
            "title": "Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2970990348",
                "DOI": "10.1016/c2017-0-03724-2",
                "CorpusId": 202782967
            },
            "abstract": null,
            "referenceCount": 5,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-11-13",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chandramouli2018MachineL,\n author = {Saikat Dutt And Subramanian Chandramouli and Subramanian Chandramouli},\n title = {Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b51fd7b391431201bcbd729c0d1b26e00bf550f4",
            "@type": "ScholarlyArticle",
            "paperId": "b51fd7b391431201bcbd729c0d1b26e00bf550f4",
            "corpusId": 239323607,
            "url": "https://www.semanticscholar.org/paper/b51fd7b391431201bcbd729c0d1b26e00bf550f4",
            "title": "Machine Learning",
            "venue": "Numerical Python",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DOI": "10.1007/978-1-4842-4246-9_15",
                "CorpusId": 239323607
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-12-25",
            "journal": {
                "name": "Numerical Python",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Johansson2018MachineL,\n author = {R. Johansson},\n booktitle = {Numerical Python},\n journal = {Numerical Python},\n title = {Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e8dccfb88a6524a67b6239f6b38a8fdaf15f6b39",
            "@type": "ScholarlyArticle",
            "paperId": "e8dccfb88a6524a67b6239f6b38a8fdaf15f6b39",
            "corpusId": 53857142,
            "url": "https://www.semanticscholar.org/paper/e8dccfb88a6524a67b6239f6b38a8fdaf15f6b39",
            "title": "Quantum Machine Learning: What Quantum Computing Means to Data Mining",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "118877790",
                "CorpusId": 53857142
            },
            "abstract": "Quantum Machine Learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning. Paring down the complexity of the disciplines involved, it ...",
            "referenceCount": 208,
            "citationCount": 306,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2014-08-28",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wittek2014QuantumML,\n author = {P. Wittek},\n title = {Quantum Machine Learning: What Quantum Computing Means to Data Mining},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ccf73e723d8308f28a98cb435dfb585581f59e2c",
            "@type": "ScholarlyArticle",
            "paperId": "ccf73e723d8308f28a98cb435dfb585581f59e2c",
            "corpusId": 215851379,
            "url": "https://www.semanticscholar.org/paper/ccf73e723d8308f28a98cb435dfb585581f59e2c",
            "title": "Genetic Algorithms in Search, Optimization & Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "3011460294",
                "CorpusId": 215851379
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 2577,
            "influentialCitationCount": 140,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Goldberg1989GeneticAI,\n author = {D. E. Goldberg},\n title = {Genetic Algorithms in Search, Optimization & Machine Learning},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b4adef6c659ab62943ce1e68db4d9409d2ce3878",
            "@type": "ScholarlyArticle",
            "paperId": "b4adef6c659ab62943ce1e68db4d9409d2ce3878",
            "corpusId": 2811065,
            "url": "https://www.semanticscholar.org/paper/b4adef6c659ab62943ce1e68db4d9409d2ce3878",
            "title": "Machine learning methods in chemoinformatics",
            "venue": "Wiley Interdisciplinary Reviews. Computational Molecular Science",
            "publicationVenue": {
                "id": "urn:research:da30b89e-2ee3-434f-99d0-55d94b4cac1b",
                "name": "Wiley Interdisciplinary Reviews. Computational Molecular Science",
                "alternate_names": [
                    "Wiley Interdisciplinary Reviews: Computational Molecular Science",
                    "Wiley Interdiscip Rev Comput Mol Sci"
                ],
                "issn": "1759-0884",
                "url": "http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1759-0884"
            },
            "year": 2014,
            "externalIds": {
                "PubMedCentral": "4180928",
                "MAG": "2171830166",
                "DOI": "10.1002/wcms.1183",
                "CorpusId": 2811065,
                "PubMed": "25285160"
            },
            "abstract": "Machine learning algorithms are generally developed in computer science or adjacent disciplines and find their way into chemical modeling by a process of diffusion. Though particular machine learning methods are popular in chemoinformatics and quantitative structure\u2013activity relationships (QSAR), many others exist in the technical literature. This discussion is methods\u2010based and focused on some algorithms that chemoinformatics researchers frequently use. It makes no claim to be exhaustive. We concentrate on methods for supervised learning, predicting the unknown property values of a test set of instances, usually molecules, based on the known values for a training set. Particularly relevant approaches include Artificial Neural Networks, Random Forest, Support Vector Machine, k\u2010Nearest Neighbors and na\u00efve Bayes classifiers. WIREs Comput Mol Sci 2014, 4:468\u2013481.",
            "referenceCount": 115,
            "citationCount": 341,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcms.1183",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-02-24",
            "journal": {
                "name": "Wiley Interdisciplinary Reviews. Computational Molecular Science",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Mitchell2014MachineLM,\n author = {John B. O. Mitchell},\n booktitle = {Wiley Interdisciplinary Reviews. Computational Molecular Science},\n journal = {Wiley Interdisciplinary Reviews. Computational Molecular Science},\n pages = {468 - 481},\n title = {Machine learning methods in chemoinformatics},\n volume = {4},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b6df5c2ac2f91d71b1d08d76135e2a470ac1ad1e",
            "@type": "ScholarlyArticle",
            "paperId": "b6df5c2ac2f91d71b1d08d76135e2a470ac1ad1e",
            "corpusId": 3065629,
            "url": "https://www.semanticscholar.org/paper/b6df5c2ac2f91d71b1d08d76135e2a470ac1ad1e",
            "title": "Machine learning - an artificial intelligence approach",
            "venue": "Symbolic computation",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1982,
            "externalIds": {
                "DBLP": "books/lib/MichalskiA84",
                "MAG": "1596324102",
                "CorpusId": 3065629
            },
            "abstract": "This book contains tutorial overviews and research papers on contemporary trends in the area of machine learning viewed from an AI perspective. Research directions covered include: learning from examples, modeling human learning strategies, knowledge acquisition for expert systems, learning heuristics, discovery systems, and conceptual data analysis.",
            "referenceCount": 34,
            "citationCount": 2870,
            "influentialCitationCount": 50,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1982-10-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Michalski1982MachineL,\n author = {R. Michalski and John R. Anderson},\n booktitle = {Symbolic computation},\n pages = {I-XI, 1-572},\n title = {Machine learning - an artificial intelligence approach},\n year = {1982}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:469460d71ede47dc1082a3123e39f84dc33ba2cc",
            "@type": "ScholarlyArticle",
            "paperId": "469460d71ede47dc1082a3123e39f84dc33ba2cc",
            "corpusId": 916066,
            "url": "https://www.semanticscholar.org/paper/469460d71ede47dc1082a3123e39f84dc33ba2cc",
            "title": "Big data classification: problems and challenges in network intrusion prediction with machine learning",
            "venue": "PERV",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2025001960",
                "DBLP": "journals/sigmetrics/Suthaharan14",
                "DOI": "10.1145/2627534.2627557",
                "CorpusId": 916066
            },
            "abstract": "This paper focuses on the specific problem of Big Data classification of network intrusion traffic. It discusses the system challenges presented by the Big Data problems associated with network intrusion prediction. The prediction of a possible intrusion attack in a network requires continuous collection of traffic data and learning of their characteristics on the fly. The continuous collection of traffic data by the network leads to Big Data problems that are caused by the volume, variety and velocity properties of Big Data. The learning of the network characteristics require machine learning techniques that capture global knowledge of the traffic patterns. The Big Data properties will lead to significant system challenges to implement machine learning frameworks. This paper discusses the problems and challenges in handling Big Data classification using geometric representation-learning techniques and the modern Big Data networking technologies. In particular this paper discusses the issues related to combining supervised learning techniques, representation-learning techniques, machine lifelong learning techniques and Big Data technologies (e.g. Hadoop, Hive and Cloud) for solving network traffic classification problems.",
            "referenceCount": 19,
            "citationCount": 333,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-04-17",
            "journal": {
                "name": "SIGMETRICS Perform. Evaluation Rev.",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Suthaharan2014BigDC,\n author = {S. Suthaharan},\n booktitle = {PERV},\n journal = {SIGMETRICS Perform. Evaluation Rev.},\n pages = {70-73},\n title = {Big data classification: problems and challenges in network intrusion prediction with machine learning},\n volume = {41},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e5278af5fd3ac8796992cb291e23fa8d47b5460f",
            "@type": "ScholarlyArticle",
            "paperId": "e5278af5fd3ac8796992cb291e23fa8d47b5460f",
            "corpusId": 62273226,
            "url": "https://www.semanticscholar.org/paper/e5278af5fd3ac8796992cb291e23fa8d47b5460f",
            "title": "Kernel Methods for Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2308302929",
                "CorpusId": 62273226
            },
            "abstract": null,
            "referenceCount": 1,
            "citationCount": 317,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Rabadi2015KernelMF,\n author = {Michael Rabadi},\n title = {Kernel Methods for Machine Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6",
            "@type": "ScholarlyArticle",
            "paperId": "1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6",
            "corpusId": 16631020,
            "url": "https://www.semanticscholar.org/paper/1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6",
            "title": "Transfer Learning for Low-Resource Neural Machine Translation",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/emnlp/ZophYMK16",
                "ArXiv": "1604.02201",
                "ACL": "D16-1163",
                "MAG": "2950108887",
                "DOI": "10.18653/v1/D16-1163",
                "CorpusId": 16631020
            },
            "abstract": "The encoder-decoder framework for neural machine translation (NMT) has been shown effective in large data scenarios, but is much less effective for low-resource languages. We present a transfer learning method that significantly improves Bleu scores across a range of low-resource languages. Our key idea is to first train a high-resource language pair (the parent model), then transfer some of the learned parameters to the low-resource pair (the child model) to initialize and constrain training. Using our transfer learning method we improve baseline NMT models by an average of 5.6 Bleu on four low-resource language pairs. Ensembling and unknown word replacement add another 2 Bleu which brings the NMT performance on low-resource machine translation close to a strong syntax based machine translation (SBMT) system, exceeding its performance on one language pair. Additionally, using the transfer learning model for re-scoring, we can improve the SBMT system by an average of 1.3 Bleu, improving the state-of-the-art on low-resource machine translation.",
            "referenceCount": 28,
            "citationCount": 719,
            "influentialCitationCount": 86,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D16-1163.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1604.02201"
            },
            "citationStyles": {
                "bibtex": "@Article{Zoph2016TransferLF,\n author = {Barret Zoph and Deniz Yuret and Jonathan May and Kevin Knight},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Transfer Learning for Low-Resource Neural Machine Translation},\n volume = {abs/1604.02201},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9b0aa51901f05278928bdfcb4e9826a429a81293",
            "@type": "ScholarlyArticle",
            "paperId": "9b0aa51901f05278928bdfcb4e9826a429a81293",
            "corpusId": 117928740,
            "url": "https://www.semanticscholar.org/paper/9b0aa51901f05278928bdfcb4e9826a429a81293",
            "title": "Quantum algorithms for supervised and unsupervised machine learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "199424061",
                "ArXiv": "1307.0411",
                "CorpusId": 117928740
            },
            "abstract": "Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms.",
            "referenceCount": 9,
            "citationCount": 642,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2013-07-01",
            "journal": {
                "name": "arXiv: Quantum Physics",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Lloyd2013QuantumAF,\n author = {S. Lloyd and M. Mohseni and P. Rebentrost},\n journal = {arXiv: Quantum Physics},\n title = {Quantum algorithms for supervised and unsupervised machine learning},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3fdd37c3a30da1dd0e376889bf2bdddc637b0b34",
            "@type": "ScholarlyArticle",
            "paperId": "3fdd37c3a30da1dd0e376889bf2bdddc637b0b34",
            "corpusId": 3331324,
            "url": "https://www.semanticscholar.org/paper/3fdd37c3a30da1dd0e376889bf2bdddc637b0b34",
            "title": "A survey of multi-view machine learning",
            "venue": "Neural computing & applications (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "journals/nca/Sun13",
                "MAG": "2085789144",
                "DOI": "10.1007/s00521-013-1362-6",
                "CorpusId": 3331324
            },
            "abstract": null,
            "referenceCount": 60,
            "citationCount": 754,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2013-02-17",
            "journal": {
                "name": "Neural Computing and Applications",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2013ASO,\n author = {Shiliang Sun},\n booktitle = {Neural computing & applications (Print)},\n journal = {Neural Computing and Applications},\n pages = {2031-2038},\n title = {A survey of multi-view machine learning},\n volume = {23},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6eabf6e67c29778265bc9fef3b58b2756c739c83",
            "@type": "ScholarlyArticle",
            "paperId": "6eabf6e67c29778265bc9fef3b58b2756c739c83",
            "corpusId": 114890196,
            "url": "https://www.semanticscholar.org/paper/6eabf6e67c29778265bc9fef3b58b2756c739c83",
            "title": "Machine Learning for Aerial Image Labeling",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2623331213",
                "DBLP": "phd/ca/Mnih13",
                "CorpusId": 114890196
            },
            "abstract": "Information extracted from aerial photographs has found applications in a wide range of areas including urban planning, crop and forest management, disaster relief, and climate modeling. At present, much of the extraction is still performed by human experts, making the process slow, costly, and error prone. The goal of this thesis is to develop methods for automatically extracting the locations of objects such as roads, buildings, and trees directly from aerial images. \nWe investigate the use of machine learning methods trained on aligned aerial images and possibly outdated maps for labeling the pixels of an aerial image with semantic labels. We show how deep neural networks implemented on modern GPUs can be used to efficiently learn highly discriminative image features. We then introduce new loss functions for training neural networks that are partially robust to incomplete and poorly registered target maps. Finally, we propose two ways of improving the predictions of our system by introducing structure into the outputs of the neural networks. \nWe evaluate our system on the largest and most-challenging road and building detection datasets considered in the literature and show that it works reliably under a wide variety of conditions. Furthermore, we are releasing the first large-scale road and building detection datasets to the public in order to facilitate future comparisons with other methods.",
            "referenceCount": 60,
            "citationCount": 545,
            "influentialCitationCount": 110,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hinton2013MachineLF,\n author = {Geoffrey E. Hinton and Volodymyr Mnih},\n title = {Machine Learning for Aerial Image Labeling},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:40c9b59c95ab1c98d6b4ef3c514a5db3a9b8ccb7",
            "@type": "ScholarlyArticle",
            "paperId": "40c9b59c95ab1c98d6b4ef3c514a5db3a9b8ccb7",
            "corpusId": 60971644,
            "url": "https://www.semanticscholar.org/paper/40c9b59c95ab1c98d6b4ef3c514a5db3a9b8ccb7",
            "title": "Machine Learning with R",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1740337471",
                "DOI": "10.1002/9781119183464.ch12",
                "CorpusId": 60971644
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 273,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-08-14",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bell2015MachineLW,\n author = {J. Bell},\n pages = {315-348},\n title = {Machine Learning with R},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:84bb60b83f82ad847e19d96403ad0011abfc888f",
            "@type": "ScholarlyArticle",
            "paperId": "84bb60b83f82ad847e19d96403ad0011abfc888f",
            "corpusId": 221284382,
            "url": "https://www.semanticscholar.org/paper/84bb60b83f82ad847e19d96403ad0011abfc888f",
            "title": "The Boosting Approach to Machine Learning An Overview",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2168020168",
                "DOI": "10.1007/978-0-387-21579-2_9",
                "CorpusId": 221284382
            },
            "abstract": null,
            "referenceCount": 88,
            "citationCount": 2076,
            "influentialCitationCount": 116,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Schapire2003TheBA,\n author = {R. Schapire},\n pages = {149-171},\n title = {The Boosting Approach to Machine Learning An Overview},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23b559b5ab27f2fca6f56c0a7b6478bcf69db509",
            "@type": "ScholarlyArticle",
            "paperId": "23b559b5ab27f2fca6f56c0a7b6478bcf69db509",
            "corpusId": 5758868,
            "url": "https://www.semanticscholar.org/paper/23b559b5ab27f2fca6f56c0a7b6478bcf69db509",
            "title": "Dual Learning for Machine Translation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1611.00179",
                "DBLP": "journals/corr/XiaHQWYLM16",
                "MAG": "2950359962",
                "CorpusId": 5758868
            },
            "abstract": "While neural machine translation (NMT) is making good progress in the past two years, tens of millions of bilingual sentence pairs are needed for its training. However, human labeling is very costly. To tackle this training data bottleneck, we develop a dual-learning mechanism, which can enable an NMT system to automatically learn from unlabeled data through a dual-learning game. This mechanism is inspired by the following observation: any machine translation task has a dual task, e.g., English-to-French translation (primal) versus French-to-English translation (dual); the primal and dual tasks can form a closed loop, and generate informative feedback signals to train the translation models, even if without the involvement of a human labeler. In the dual-learning mechanism, we use one agent to represent the model for the primal task and the other agent to represent the model for the dual task, then ask them to teach each other through a reinforcement learning process. Based on the feedback signals generated during this process (e.g., the language-model likelihood of the output of a model, and the reconstruction error of the original sentence after the primal and dual translations), we can iteratively update the two models until convergence (e.g., using the policy gradient methods). We call the corresponding approach to neural machine translation dual-NMT. Experiments show that dual-NMT works very well on English \u2194 French translation; especially, by learning from monolingual data (with 10% bilingual data for warm start), it achieves a comparable accuracy to NMT trained from the full bilingual data for the French-to-English translation task.",
            "referenceCount": 19,
            "citationCount": 770,
            "influentialCitationCount": 62,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{He2016DualLF,\n author = {Di He and Yingce Xia and Tao Qin and Liwei Wang and Nenghai Yu and Tie-Yan Liu and Wei-Ying Ma},\n booktitle = {Neural Information Processing Systems},\n pages = {820-828},\n title = {Dual Learning for Machine Translation},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8346b9a8e156d6e7a7012bcd47bc4f5d4be59e92",
            "@type": "ScholarlyArticle",
            "paperId": "8346b9a8e156d6e7a7012bcd47bc4f5d4be59e92",
            "corpusId": 206578669,
            "url": "https://www.semanticscholar.org/paper/8346b9a8e156d6e7a7012bcd47bc4f5d4be59e92",
            "title": "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection",
            "venue": "IEEE Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:29b9c461-963e-4d11-b2ab-92c182243942",
                "name": "IEEE Symposium on Security and Privacy",
                "alternate_names": [
                    "S&P",
                    "IEEE Symp Secur Priv"
                ],
                "issn": null,
                "url": "http://www.ieee-security.org/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "1985987493",
                "DBLP": "conf/sp/SommerP10",
                "DOI": "10.1109/SP.2010.25",
                "CorpusId": 206578669
            },
            "abstract": "In network intrusion detection research, one popular strategy for finding attacks is monitoring a network's activity for anomalies: deviations from profiles of normality previously learned from benign traffic, typically identified using tools borrowed from the machine learning community. However, despite extensive academic research one finds a striking gap in terms of actual deployments of such systems: compared with other intrusion detection approaches, machine learning is rarely employed in operational \"real world\" settings. We examine the differences between the network intrusion detection problem and other areas where machine learning regularly finds much more success. Our main claim is that the task of finding attacks is fundamentally different from these other applications, making it significantly harder for the intrusion detection community to employ machine learning effectively. We support this claim by identifying challenges particular to network intrusion detection, and provide a set of guidelines meant to strengthen future research on anomaly detection.",
            "referenceCount": 68,
            "citationCount": 1381,
            "influentialCitationCount": 134,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.icir.org/robin/papers/oakland10-ml.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-05-16",
            "journal": {
                "name": "2010 IEEE Symposium on Security and Privacy",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sommer2010OutsideTC,\n author = {Robin Sommer and V. Paxson},\n booktitle = {IEEE Symposium on Security and Privacy},\n journal = {2010 IEEE Symposium on Security and Privacy},\n pages = {305-316},\n title = {Outside the Closed World: On Using Machine Learning for Network Intrusion Detection},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c62043a7d2537bbf40a84b9913957452a47fdb83",
            "@type": "ScholarlyArticle",
            "paperId": "c62043a7d2537bbf40a84b9913957452a47fdb83",
            "corpusId": 61294087,
            "url": "https://www.semanticscholar.org/paper/c62043a7d2537bbf40a84b9913957452a47fdb83",
            "title": "Dataset Shift in Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2162651021",
                "DOI": "10.7551/MITPRESS/9780262170055.001.0001",
                "CorpusId": 61294087
            },
            "abstract": "Dataset shift is a common problem in predictive modeling that occurs when the joint distribution of inputs and outputs differs between training and test stages. Covariate shift, a particular case of dataset shift, occurs when only the input distribution changes. Dataset shift is present in most practical applications, for reasons ranging from the bias introduced by experimental design to the irreproducibility of the testing conditions at training time. (An example is -email spam filtering, which may fail to recognize spam that differs in form from the spam the automatic filter has been built on.) Despite this, and despite the attention given to the apparently similar problems of semi-supervised learning and active learning, dataset shift has received relatively little attention in the machine learning community until recently. This volume offers an overview of current efforts to deal with dataset and covariate shift. The chapters offer a mathematical and philosophical introduction to the problem, place dataset shift in relationship to transfer learning, transduction, local learning, active learning, and semi-supervised learning, provide theoretical views of dataset and covariate shift (including decision theoretic and Bayesian perspectives), and present algorithms for covariate shift. Contributors: Shai Ben-David, Steffen Bickel, Karsten Borgwardt, Michael Brckner, David Corfield, Amir Globerson, Arthur Gretton, Lars Kai Hansen, Matthias Hein, Jiayuan Huang, Takafumi Kanamori, Klaus-Robert Mller, Sam Roweis, Neil Rubens, Tobias Scheffer, Marcel Schmittfull, Bernhard Schlkopf, Hidetoshi Shimodaira, Alex Smola, Amos Storkey, Masashi Sugiyama, Choon Hui Teo Neural Information Processing series",
            "referenceCount": 162,
            "citationCount": 1679,
            "influentialCitationCount": 51,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.acad.bg/ebook/ml/The.MIT.Press.Dataset.Shift.in.Machine.Learning.Feb.2009.eBook-DDU.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2009-02-27",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Quionero-Candela2009DatasetSI,\n author = {Joaquin Quionero-Candela and Masashi Sugiyama and A. Schwaighofer and Neil D. Lawrence},\n pages = {29-38},\n title = {Dataset Shift in Machine Learning},\n year = {2009}\n}\n"
            }
        }
    }
]