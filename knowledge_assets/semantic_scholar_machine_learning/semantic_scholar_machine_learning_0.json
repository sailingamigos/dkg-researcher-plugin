[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f9c602cc436a9ea2f9e7db48c77d924e09ce3c32",
            "@type": "ScholarlyArticle",
            "paperId": "f9c602cc436a9ea2f9e7db48c77d924e09ce3c32",
            "corpusId": 702279,
            "url": "https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32",
            "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2750384547",
                "DBLP": "journals/corr/abs-1708-07747",
                "ArXiv": "1708.07747",
                "CorpusId": 702279
            },
            "abstract": "We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL",
            "referenceCount": 6,
            "citationCount": 6411,
            "influentialCitationCount": 1708,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1708.07747"
            },
            "citationStyles": {
                "bibtex": "@Article{Xiao2017FashionMNISTAN,\n author = {Han Xiao and Kashif Rasul and Roland Vollgraf},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},\n volume = {abs/1708.07747},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4954fa180728932959997a4768411ff9136aac81",
            "@type": "ScholarlyArticle",
            "paperId": "4954fa180728932959997a4768411ff9136aac81",
            "corpusId": 6287870,
            "url": "https://www.semanticscholar.org/paper/4954fa180728932959997a4768411ff9136aac81",
            "title": "TensorFlow: A system for large-scale machine learning",
            "venue": "USENIX Symposium on Operating Systems Design and Implementation",
            "publicationVenue": {
                "id": "urn:research:86c43745-31d9-4c1a-b33f-ce3aa0042dbb",
                "name": "USENIX Symposium on Operating Systems Design and Implementation",
                "alternate_names": [
                    "Oper Syst Des Implement",
                    "Operating Systems Design and Implementation",
                    "OSDI",
                    "USENIX Symp Oper Syst Des Implement"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2402144811",
                "DBLP": "conf/osdi/AbadiBCCDDDGIIK16",
                "ArXiv": "1605.08695",
                "CorpusId": 6287870
            },
            "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",
            "referenceCount": 91,
            "citationCount": 16315,
            "influentialCitationCount": 1875,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Abadi2016TensorFlowAS,\n author = {Mart\u00edn Abadi and P. Barham and Jianmin Chen and Z. Chen and Andy Davis and J. Dean and Matthieu Devin and S. Ghemawat and G. Irving and M. Isard and M. Kudlur and J. Levenberg and R. Monga and Sherry Moore and D. Murray and Benoit Steiner and P. Tucker and Vijay Vasudevan and P. Warden and M. Wicke and Yuan Yu and Xiaoqiang Zhang},\n booktitle = {USENIX Symposium on Operating Systems Design and Implementation},\n pages = {265-283},\n title = {TensorFlow: A system for large-scale machine learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "@type": "ScholarlyArticle",
            "paperId": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "corpusId": 5707386,
            "url": "https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2271840356",
                "ArXiv": "1603.04467",
                "DBLP": "journals/corr/AbadiABBCCCDDDG16",
                "CorpusId": 5707386
            },
            "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
            "referenceCount": 60,
            "citationCount": 10167,
            "influentialCitationCount": 1042,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.04467"
            },
            "citationStyles": {
                "bibtex": "@Article{Abadi2016TensorFlowLM,\n author = {Mart\u00edn Abadi and Ashish Agarwal and P. Barham and E. Brevdo and Z. Chen and C. Citro and G. Corrado and Andy Davis and J. Dean and Matthieu Devin and S. Ghemawat and I. Goodfellow and A. Harp and G. Irving and M. Isard and Yangqing Jia and R. J\u00f3zefowicz and Lukasz Kaiser and M. Kudlur and J. Levenberg and Dandelion Man\u00e9 and R. Monga and Sherry Moore and D. Murray and C. Olah and M. Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and P. Tucker and Vincent Vanhoucke and Vijay Vasudevan and F. Vi\u00e9gas and Oriol Vinyals and P. Warden and M. Wattenberg and M. Wicke and Yuan Yu and Xiaoqiang Zheng},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},\n volume = {abs/1603.04467},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f9c990b1b5724e50e5632b94fdb7484ece8a6ce7",
            "@type": "ScholarlyArticle",
            "paperId": "f9c990b1b5724e50e5632b94fdb7484ece8a6ce7",
            "corpusId": 6352419,
            "url": "https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7",
            "title": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1506.04214",
                "DBLP": "conf/nips/ShiCWYWW15",
                "MAG": "2953118818",
                "CorpusId": 6352419
            },
            "abstract": "The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.",
            "referenceCount": 27,
            "citationCount": 6105,
            "influentialCitationCount": 919,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shi2015ConvolutionalLN,\n author = {Xingjian Shi and Zhourong Chen and Hao Wang and D. Yeung and W. Wong and W. Woo},\n booktitle = {Neural Information Processing Systems},\n pages = {802-810},\n title = {Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f5b82d9915d0752957602224c5056be7e749c83",
            "@type": "ScholarlyArticle",
            "paperId": "9f5b82d9915d0752957602224c5056be7e749c83",
            "corpusId": 38553870,
            "url": "https://www.semanticscholar.org/paper/9f5b82d9915d0752957602224c5056be7e749c83",
            "title": "Foundations of Machine Learning",
            "venue": "Introduction to AI Techniques for Renewable Energy Systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.2139/ssrn.3399990",
                "CorpusId": 38553870
            },
            "abstract": "Understanding Machine LearningProbabilistic Machine LearningHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlowFundamentals of Machine LearningReinforcement Learning, second editionDeep LearningIntroducing Machine LearningFoundations of Data ScienceFundamentals of Deep LearningIntelligent SystemsMachine Learning RefinedAn Introduction to Deep Reinforcement LearningDeep Learning: Fundamentals, Theory and ApplicationsDeep LearningDeep Learning for Coders with fastai and PyTorchMachine LearningA Brief Introduction to Machine Learning for EngineersElements of Causal InferenceFundamentals of Machine Learning for Predictive Data Analytics, second editionMachine Learning in Clinical NeuroscienceLearning Deep Architectures for AIArtificial IntelligenceStatistical Foundations of Data ScienceThe Mathematical Foundations of Learning MachinesFoundations of Machine LearningMachine Learning FoundationsBoostingThe Algorithmic Foundations of Differential PrivacyMathematics for Machine LearningFoundations of Rule LearningDeep Learning with PyTorchNeural Network LearningDeep Learning IllustratedFoundations of Deep Reinforcement LearningFoundations of Machine Learning, second editionImbalanced LearningFoundations of Knowledge AcquisitionOn the Path to AIMachine Learning: Theoretical Foundations and Practical ApplicationsArtificial Intelligence and Machine Learning Fundamentals",
            "referenceCount": 5,
            "citationCount": 2691,
            "influentialCitationCount": 392,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-10-07",
            "journal": {
                "name": "Introduction to AI Techniques for Renewable Energy Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nathani2021FoundationsOM,\n author = {N. Nathani and Abhishek Singh},\n booktitle = {Introduction to AI Techniques for Renewable Energy Systems},\n journal = {Introduction to AI Techniques for Renewable Energy Systems},\n title = {Foundations of Machine Learning},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bc00ff34ec7772080c7039b17f7069a2f7df0889",
            "@type": "ScholarlyArticle",
            "paperId": "bc00ff34ec7772080c7039b17f7069a2f7df0889",
            "corpusId": 182656421,
            "url": "https://www.semanticscholar.org/paper/bc00ff34ec7772080c7039b17f7069a2f7df0889",
            "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2974440810",
                "DBLP": "journals/natmi/Rudin19",
                "DOI": "10.1038/s42256-019-0048-x",
                "CorpusId": 182656421,
                "PubMed": "35603010"
            },
            "abstract": null,
            "referenceCount": 87,
            "citationCount": 3830,
            "influentialCitationCount": 258,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s42256-019-0048-x.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-26",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Rudin2018StopEB,\n author = {C. Rudin},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {206 - 215},\n title = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},\n volume = {1},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d422df8bff4e677a3077635db116679d25142bfc",
            "@type": "ScholarlyArticle",
            "paperId": "d422df8bff4e677a3077635db116679d25142bfc",
            "corpusId": 677218,
            "url": "https://www.semanticscholar.org/paper/d422df8bff4e677a3077635db116679d25142bfc",
            "title": "Machine learning: Trends, perspectives, and prospects",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1901616594",
                "DOI": "10.1126/science.aaa8415",
                "CorpusId": 677218,
                "PubMed": "26185243"
            },
            "abstract": "Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today\u2019s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",
            "referenceCount": 73,
            "citationCount": 4625,
            "influentialCitationCount": 88,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2015-07-17",
            "journal": {
                "name": "Science",
                "volume": "349"
            },
            "citationStyles": {
                "bibtex": "@Article{Jordan2015MachineLT,\n author = {Michael I. Jordan and T. Mitchell},\n booktitle = {Science},\n journal = {Science},\n pages = {255 - 260},\n title = {Machine learning: Trends, perspectives, and prospects},\n volume = {349},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:730ca170962a58607e092035beb2afc4b5fa6242",
            "@type": "ScholarlyArticle",
            "paperId": "730ca170962a58607e092035beb2afc4b5fa6242",
            "corpusId": 64641472,
            "url": "https://www.semanticscholar.org/paper/730ca170962a58607e092035beb2afc4b5fa6242",
            "title": "Data Mining Practical Machine Learning Tools and Techniques",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2725149427",
                "CorpusId": 64641472
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 16799,
            "influentialCitationCount": 1644,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Journal of management science",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{\u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c2014DataMP,\n author = {\u0e2d\u0e19\u0e34\u0e23\u0e38\u0e18 \u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c},\n journal = {Journal of management science},\n pages = {92-96},\n title = {Data Mining Practical Machine Learning Tools and Techniques},\n volume = {3},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:25badc676197a70aaf9911865eb03469e402ba57",
            "@type": "ScholarlyArticle",
            "paperId": "25badc676197a70aaf9911865eb03469e402ba57",
            "corpusId": 17793133,
            "url": "https://www.semanticscholar.org/paper/25badc676197a70aaf9911865eb03469e402ba57",
            "title": "Machine learning - a probabilistic perspective",
            "venue": "Adaptive computation and machine learning series",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "books/lib/Murphy12",
                "MAG": "1503398984",
                "CorpusId": 17793133
            },
            "abstract": "Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.",
            "referenceCount": 1022,
            "citationCount": 8564,
            "influentialCitationCount": 1066,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-08-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Murphy2012MachineL,\n author = {Kevin P. Murphy},\n booktitle = {Adaptive computation and machine learning series},\n pages = {I-XXIX, 1-1067},\n title = {Machine learning - a probabilistic perspective},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:17da94c4491c80b923dd8e6fe0be2b9d4d3c1926",
            "@type": "ScholarlyArticle",
            "paperId": "17da94c4491c80b923dd8e6fe0be2b9d4d3c1926",
            "corpusId": 6134427,
            "url": "https://www.semanticscholar.org/paper/17da94c4491c80b923dd8e6fe0be2b9d4d3c1926",
            "title": "What Is Machine Learning?",
            "venue": "Machine Learning and AI for Healthcare",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2912420099",
                "DOI": "10.1007/978-1-4842-3799-1_3",
                "CorpusId": 6134427
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 2527,
            "influentialCitationCount": 199,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Machine Learning and AI for Healthcare",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dietterich2019WhatIM,\n author = {Thomas G. Dietterich},\n booktitle = {Machine Learning and AI for Healthcare},\n journal = {Machine Learning and AI for Healthcare},\n title = {What Is Machine Learning?},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0090023afc66cd2741568599057f4e82b566137c",
            "@type": "ScholarlyArticle",
            "paperId": "0090023afc66cd2741568599057f4e82b566137c",
            "corpusId": 201666566,
            "url": "https://www.semanticscholar.org/paper/0090023afc66cd2741568599057f4e82b566137c",
            "title": "A Survey on Bias and Fairness in Machine Learning",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1908.09635",
                "MAG": "2969896603",
                "DBLP": "journals/csur/MehrabiMSLG21",
                "DOI": "10.1145/3457607",
                "CorpusId": 201666566
            },
            "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
            "referenceCount": 188,
            "citationCount": 2415,
            "influentialCitationCount": 143,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1908.09635",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-08-23",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Mehrabi2019ASO,\n author = {Ninareh Mehrabi and Fred Morstatter and N. Saxena and Kristina Lerman and A. Galstyan},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 35},\n title = {A Survey on Bias and Fairness in Machine Learning},\n volume = {54},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74",
            "@type": "ScholarlyArticle",
            "paperId": "168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74",
            "corpusId": 10659969,
            "url": "https://www.semanticscholar.org/paper/168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74",
            "title": "Scikit-learn: Machine Learning in Python",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2950511172",
                "DBLP": "journals/corr/abs-1201-0490",
                "ArXiv": "1201.0490",
                "DOI": "10.5555/1953048.2078195",
                "CorpusId": 10659969
            },
            "abstract": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",
            "referenceCount": 18,
            "citationCount": 60680,
            "influentialCitationCount": 3839,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-02-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1201.0490"
            },
            "citationStyles": {
                "bibtex": "@Article{Pedregosa2011ScikitlearnML,\n author = {Fabian Pedregosa and G. Varoquaux and Alexandre Gramfort and V. Michel and B. Thirion and O. Grisel and Mathieu Blondel and Gilles Louppe and P. Prettenhofer and Ron Weiss and Ron J. Weiss and J. Vanderplas and Alexandre Passos and D. Cournapeau and M. Brucher and M. Perrot and E. Duchesnay},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {Scikit-learn: Machine Learning in Python},\n volume = {abs/1201.0490},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:597bd2e45427563cdf025e53a3239006aa364cfc",
            "@type": "ScholarlyArticle",
            "paperId": "597bd2e45427563cdf025e53a3239006aa364cfc",
            "corpusId": 218487328,
            "url": "https://www.semanticscholar.org/paper/597bd2e45427563cdf025e53a3239006aa364cfc",
            "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3021975806",
                "DBLP": "journals/corr/abs-2005-00687",
                "ArXiv": "2005.00687",
                "CorpusId": 218487328
            },
            "abstract": "We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL .",
            "referenceCount": 109,
            "citationCount": 1616,
            "influentialCitationCount": 357,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-05-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2005.00687"
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2020OpenGB,\n author = {Weihua Hu and Matthias Fey and M. Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and J. Leskovec},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Open Graph Benchmark: Datasets for Machine Learning on Graphs},\n volume = {abs/2005.00687},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e2089ae76fe914706e6fa90081a79c8fe01611e",
            "@type": "ScholarlyArticle",
            "paperId": "2e2089ae76fe914706e6fa90081a79c8fe01611e",
            "corpusId": 632197,
            "url": "https://www.semanticscholar.org/paper/2e2089ae76fe914706e6fa90081a79c8fe01611e",
            "title": "Practical Bayesian Optimization of Machine Learning Algorithms",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2012,
            "externalIds": {
                "ArXiv": "1206.2944",
                "MAG": "2950182411",
                "DBLP": "conf/nips/SnoekLA12",
                "CorpusId": 632197
            },
            "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",
            "referenceCount": 28,
            "citationCount": 6514,
            "influentialCitationCount": 517,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-06-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Snoek2012PracticalBO,\n author = {Jasper Snoek and H. Larochelle and Ryan P. Adams},\n booktitle = {Neural Information Processing Systems},\n pages = {2960-2968},\n title = {Practical Bayesian Optimization of Machine Learning Algorithms},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:62ccd99a65bfc7c735ae1f33b75b107665de95df",
            "@type": "ScholarlyArticle",
            "paperId": "62ccd99a65bfc7c735ae1f33b75b107665de95df",
            "corpusId": 219878182,
            "url": "https://www.semanticscholar.org/paper/62ccd99a65bfc7c735ae1f33b75b107665de95df",
            "title": "Federated Machine Learning",
            "venue": "ACM Transactions on Intelligent Systems and Technology",
            "publicationVenue": {
                "id": "urn:research:0d993d4a-09ba-4df8-90a4-7dfe25f0cb9e",
                "name": "ACM Transactions on Intelligent Systems and Technology",
                "alternate_names": [
                    "ACM Trans Intell Syst Technol"
                ],
                "issn": "2157-6904",
                "url": "http://portal.acm.org/tist"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1902.04885",
                "MAG": "2949522309",
                "DBLP": "journals/corr/abs-1902-04885",
                "DOI": "10.1145/3298981",
                "CorpusId": 219878182
            },
            "abstract": "Today\u2019s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.",
            "referenceCount": 80,
            "citationCount": 2479,
            "influentialCitationCount": 162,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-01-28",
            "journal": {
                "name": "ACM Transactions on Intelligent Systems and Technology (TIST)",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2019FederatedML,\n author = {Qiang Yang and Yang Liu and Tianjian Chen and Yongxin Tong},\n booktitle = {ACM Transactions on Intelligent Systems and Technology},\n journal = {ACM Transactions on Intelligent Systems and Technology (TIST)},\n pages = {1 - 19},\n title = {Federated Machine Learning},\n volume = {10},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6a6ad9eb495739f4c80e7c09598720c3d5c5dff7",
            "@type": "ScholarlyArticle",
            "paperId": "6a6ad9eb495739f4c80e7c09598720c3d5c5dff7",
            "corpusId": 251659795,
            "url": "https://www.semanticscholar.org/paper/6a6ad9eb495739f4c80e7c09598720c3d5c5dff7",
            "title": "Federated Learning: Collaborative Machine Learning without\nCentralized Training Data",
            "venue": "International Journal of Engineering Technology and Management Sciences",
            "publicationVenue": {
                "id": "urn:research:099b11f4-fbe6-40a6-9c6d-a1a83f28b9a3",
                "name": "International Journal of Engineering Technology and Management Sciences",
                "alternate_names": [
                    "Int J Eng Technol Manag Sci"
                ],
                "issn": "2581-4621",
                "url": "http://ijetms.in/"
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.46647/ijetms.2022.v06i05.052",
                "CorpusId": 251659795
            },
            "abstract": "Federated learning (also known as collaborative learning) is a machine learning technique that trains\nan algorithm without transferring data samples across numerous decentralized edge devices or\nservers. This strategy differs from standard centralized machine learning techniques in which all local\ndatasets are uploaded to a single server, as well as more traditional decentralized alternatives, which\nfrequently presume that local data samples are uniformly distributed.\nFederated learning allows several actors to collaborate on the development of a single, robust\nmachine learning model without sharing data, allowing crucial issues such as data privacy, data\nsecurity, data access rights, and access to heterogeneous data to be addressed. Defence,\ntelecommunications, internet of things, and pharmaceutical industries are just a few of the sectors\nwhere it has applications.",
            "referenceCount": 6,
            "citationCount": 509,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2022-09-28",
            "journal": {
                "name": "international journal of engineering technology and management sciences",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{A2022FederatedLC,\n author = {Abhishek V A and Binny S and Johan T R and Nithin Raj and Vishal Thomas},\n booktitle = {International Journal of Engineering Technology and Management Sciences},\n journal = {international journal of engineering technology and management sciences},\n title = {Federated Learning: Collaborative Machine Learning without\nCentralized Training Data},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:807c1f19047f96083e13614f7ce20f2ac98c239a",
            "@type": "ScholarlyArticle",
            "paperId": "807c1f19047f96083e13614f7ce20f2ac98c239a",
            "corpusId": 5262555,
            "url": "https://www.semanticscholar.org/paper/807c1f19047f96083e13614f7ce20f2ac98c239a",
            "title": "C4.5: Programs for Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "books/mk/Quinlan93",
                "MAG": "2125055259",
                "CorpusId": 5262555
            },
            "abstract": "From the Publisher: \nClassifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation. \n \nC4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies. \n \nThis book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses.",
            "referenceCount": 0,
            "citationCount": 22778,
            "influentialCitationCount": 1242,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1992-10-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Quinlan1992C45PF,\n author = {J. R. Quinlan},\n title = {C4.5: Programs for Machine Learning},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b0c34618ffd1154f35863e2ce7250ac6b6f2c424",
            "@type": "ScholarlyArticle",
            "paperId": "b0c34618ffd1154f35863e2ce7250ac6b6f2c424",
            "corpusId": 209379623,
            "url": "https://www.semanticscholar.org/paper/b0c34618ffd1154f35863e2ce7250ac6b6f2c424",
            "title": "Interpretable Machine Learning",
            "venue": "Hands-On Machine Learning with R",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3098109070",
                "DOI": "10.1201/9780367816377-16",
                "CorpusId": 209379623
            },
            "abstract": "Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.",
            "referenceCount": 199,
            "citationCount": 1887,
            "influentialCitationCount": 181,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12184120880002346/13184120870002346",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-11-07",
            "journal": {
                "name": "Hands-On Machine Learning with R",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Boehmke2019InterpretableML,\n author = {Bradley C. Boehmke and Brandon M. Greenwell},\n booktitle = {Hands-On Machine Learning with R},\n journal = {Hands-On Machine Learning with R},\n title = {Interpretable Machine Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5c39e37022661f81f79e481240ed9b175dec6513",
            "@type": "ScholarlyArticle",
            "paperId": "5c39e37022661f81f79e481240ed9b175dec6513",
            "corpusId": 11319376,
            "url": "https://www.semanticscholar.org/paper/5c39e37022661f81f79e481240ed9b175dec6513",
            "title": "Towards A Rigorous Science of Interpretable Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2594475271",
                "ArXiv": "1702.08608",
                "CorpusId": 11319376
            },
            "abstract": "As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.",
            "referenceCount": 56,
            "citationCount": 2758,
            "influentialCitationCount": 237,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-02-28",
            "journal": {
                "name": "arXiv: Machine Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Doshi-Velez2017TowardsAR,\n author = {F. Doshi-Velez and Been Kim},\n journal = {arXiv: Machine Learning},\n title = {Towards A Rigorous Science of Interpretable Machine Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:794b3ffd28d28606230efc975eeec9f0522fb139",
            "@type": "ScholarlyArticle",
            "paperId": "794b3ffd28d28606230efc975eeec9f0522fb139",
            "corpusId": 12540005,
            "url": "https://www.semanticscholar.org/paper/794b3ffd28d28606230efc975eeec9f0522fb139",
            "title": "An Introduction to Machine Learning",
            "venue": "Cambridge International Law Journal",
            "publicationVenue": {
                "id": "urn:research:43d8ff46-e680-4c40-84dc-a8f86d3f559b",
                "name": "Cambridge International Law Journal",
                "alternate_names": [
                    "Springer International Publishing",
                    "Springer Int Publ",
                    "Camb Int Law J"
                ],
                "issn": "2398-9173",
                "url": "https://www.elgaronline.com/view/journals/cilj/cilj-overview.xml"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "books/sp/Kubat17",
                "DOI": "10.1007/978-3-319-63913-0",
                "CorpusId": 12540005
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 3924,
            "influentialCitationCount": 307,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kub\u00e1t2017AnIT,\n author = {M. Kub\u00e1t},\n booktitle = {Cambridge International Law Journal},\n pages = {1-348},\n title = {An Introduction to Machine Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:53b047e503f4c24602f376a774d653f7ed56c024",
            "@type": "ScholarlyArticle",
            "paperId": "53b047e503f4c24602f376a774d653f7ed56c024",
            "corpusId": 1090603,
            "url": "https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024",
            "title": "Practical Black-Box Attacks against Machine Learning",
            "venue": "ACM Asia Conference on Computer and Communications Security",
            "publicationVenue": {
                "id": "urn:research:87fc9c3c-cc7f-42aa-ba71-2700729a6788",
                "name": "ACM Asia Conference on Computer and Communications Security",
                "alternate_names": [
                    "AsiaCCS",
                    "ACM Asia Conf Comput Commun Secur",
                    "ACM Symposium on Information, Computer and Communications Security",
                    "ACM Symp Inf Comput Commun Secur",
                    "ASIACCS"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/asia-ccs"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1602.02697",
                "MAG": "2603766943",
                "DBLP": "conf/ccs/PapernotMGJCS17",
                "DOI": "10.1145/3052973.3053009",
                "CorpusId": 1090603
            },
            "abstract": "Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.",
            "referenceCount": 41,
            "citationCount": 3080,
            "influentialCitationCount": 243,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1602.02697",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-08",
            "journal": {
                "name": "Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Papernot2016PracticalBA,\n author = {Nicolas Papernot and P. Mcdaniel and I. Goodfellow and S. Jha and Z. B. Celik and A. Swami},\n booktitle = {ACM Asia Conference on Computer and Communications Security},\n journal = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},\n title = {Practical Black-Box Attacks against Machine Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2936cbd6a90d7153a9fa34e8e4fd947907fe7f6c",
            "@type": "ScholarlyArticle",
            "paperId": "2936cbd6a90d7153a9fa34e8e4fd947907fe7f6c",
            "corpusId": 69997935,
            "url": "https://www.semanticscholar.org/paper/2936cbd6a90d7153a9fa34e8e4fd947907fe7f6c",
            "title": "Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2884745705",
                "CorpusId": 69997935
            },
            "abstract": "Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. By using concrete examples, minimal theory, and two production-ready Python frameworks-scikit-learn and TensorFlow-author Aurelien Geron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what you've learned, all you need is programming experience to get started. Explore the machine learning landscape, particularly neural nets Use scikit-learn to track an example machine-learning project end-to-end Explore several training models, including support vector machines, decision trees, random forests, and ensemble methods Use the TensorFlow library to build and train neural nets Dive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learning Learn techniques for training and scaling deep neural nets Apply practical code examples without acquiring excessive machine learning theory or algorithm details",
            "referenceCount": 0,
            "citationCount": 2319,
            "influentialCitationCount": 326,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-04-18",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{G\u00e9ron2017HandsOnML,\n author = {Aur\u00e9lien G\u00e9ron},\n title = {Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d",
            "@type": "ScholarlyArticle",
            "paperId": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d",
            "corpusId": 10488675,
            "url": "https://www.semanticscholar.org/paper/f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d",
            "title": "Membership Inference Attacks Against Machine Learning Models",
            "venue": "IEEE Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:29b9c461-963e-4d11-b2ab-92c182243942",
                "name": "IEEE Symposium on Security and Privacy",
                "alternate_names": [
                    "S&P",
                    "IEEE Symp Secur Priv"
                ],
                "issn": null,
                "url": "http://www.ieee-security.org/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/ShokriSS16",
                "MAG": "2535690855",
                "ArXiv": "1610.05820",
                "DOI": "10.1109/SP.2017.41",
                "CorpusId": 10488675
            },
            "abstract": "We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. We empirically evaluate our inference techniques on classification models trained by commercial \"machine learning as a service\" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies.",
            "referenceCount": 40,
            "citationCount": 2841,
            "influentialCitationCount": 436,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1610.05820",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-18",
            "journal": {
                "name": "2017 IEEE Symposium on Security and Privacy (SP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shokri2016MembershipIA,\n author = {R. Shokri and Marco Stronati and Congzheng Song and Vitaly Shmatikov},\n booktitle = {IEEE Symposium on Security and Privacy},\n journal = {2017 IEEE Symposium on Security and Privacy (SP)},\n pages = {3-18},\n title = {Membership Inference Attacks Against Machine Learning Models},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4512fd274da1d5b83b10e5dfe76d36332f2da9a0",
            "@type": "ScholarlyArticle",
            "paperId": "4512fd274da1d5b83b10e5dfe76d36332f2da9a0",
            "corpusId": 63955376,
            "url": "https://www.semanticscholar.org/paper/4512fd274da1d5b83b10e5dfe76d36332f2da9a0",
            "title": "Gaussian Processes for Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2063686375",
                "DOI": "10.1198/jasa.2008.s219",
                "CorpusId": 63955376
            },
            "abstract": "Hogg, R. V., McKean, J. W., and Craig, A. T. (2005), Introduction to Mathematical Statistics (6th ed.), Upper Saddle River, NJ: Prentice-Hall. Lohr, S. L. (1999), Sampling: Design and Analysis, Pacific Grove, CA: Duxbury Press. Mittelhammer, R. C. (1996), Mathematical Statistics for Economics and Business Administration, New York: Springer. S\u00e4rndal, C.-E., Swensson, B., and Wretman, J. (1992), Model-Assisted Survey Sampling, New York: Springer.",
            "referenceCount": 3,
            "citationCount": 20157,
            "influentialCitationCount": 3183,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Philosophy"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Philosophy",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2008-03-01",
            "journal": {
                "name": "Journal of the American Statistical Association",
                "volume": "103"
            },
            "citationStyles": {
                "bibtex": "@Article{Ounpraseuth2008GaussianPF,\n author = {S. Ounpraseuth},\n journal = {Journal of the American Statistical Association},\n pages = {429 - 429},\n title = {Gaussian Processes for Machine Learning},\n volume = {103},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e62d1345b340d5fda3b092c460264b9543bc4b5",
            "@type": "ScholarlyArticle",
            "paperId": "2e62d1345b340d5fda3b092c460264b9543bc4b5",
            "corpusId": 38613589,
            "url": "https://www.semanticscholar.org/paper/2e62d1345b340d5fda3b092c460264b9543bc4b5",
            "title": "Genetic Algorithms in Search Optimization and Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1988,
            "externalIds": {
                "MAG": "1639032689",
                "DBLP": "books/aw/Goldberg89",
                "DOI": "10.5860/choice.27-0936",
                "CorpusId": 38613589
            },
            "abstract": "From the Publisher: \nThis book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. \n \nMajor concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.",
            "referenceCount": 1,
            "citationCount": 60093,
            "influentialCitationCount": 3504,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Goldberg1988GeneticAI,\n author = {D. Goldberg},\n title = {Genetic Algorithms in Search Optimization and Machine Learning},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:668b1277fbece28c4841eeab1c97e4ebd0079700",
            "@type": "ScholarlyArticle",
            "paperId": "668b1277fbece28c4841eeab1c97e4ebd0079700",
            "corpusId": 31993898,
            "url": "https://www.semanticscholar.org/paper/668b1277fbece28c4841eeab1c97e4ebd0079700",
            "title": "Pattern Recognition and Machine Learning",
            "venue": "J. Electronic Imaging",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "1663973292",
                "DBLP": "journals/jei/BishopN07",
                "DOI": "10.1007/978-0-387-45528-0",
                "CorpusId": 31993898
            },
            "abstract": null,
            "referenceCount": 360,
            "citationCount": 34077,
            "influentialCitationCount": 3960,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2006-08-17",
            "journal": {
                "name": "Pattern Recognition and Machine Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Neal2006PatternRA,\n author = {Radford M. Neal},\n booktitle = {J. Electronic Imaging},\n journal = {Pattern Recognition and Machine Learning},\n title = {Pattern Recognition and Machine Learning},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ffa5e04a55da0cfd151053beeca3d470d26cb35d",
            "@type": "ScholarlyArticle",
            "paperId": "ffa5e04a55da0cfd151053beeca3d470d26cb35d",
            "corpusId": 235703044,
            "url": "https://www.semanticscholar.org/paper/ffa5e04a55da0cfd151053beeca3d470d26cb35d",
            "title": "Physics-Informed Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "CorpusId": 235703044
            },
            "abstract": "Traditional lithium-ion (Li-ion) battery state of health (SOH) estimation methodologies that focused on estimating present cell capacity do not provide sufficient information to determine the cell\u2019s lifecycle stage or value in second-life use. Quantifying the underlying degradation modes that cause capacity fade can give further insight into the electrochemical state of the cell and provide more detailed health information such as the remaining active materials and lithium inventory. However, current physics-based methods for degradation diagnostics require long-term cycling data and are computationally expensive to deploy locally on a device. To improve upon current methods, we propose and extensively test two light-weight physics-informed machine learning methods for online estimating the capacity of a battery cell and diagnosing its primary degradation modes using only limited early-life experimental degradation data. To enable late-life prediction (e.g. > 1.5 years) without the use of late-life experimental data, each of the methods is trained using simulation data from a physics-based half-cell model and early-life (e.g. < 3 months) degradation data obtained from cycling tests. The proposed methods are comprehensively evaluated using data from a long-term (3.5 years) cycling experiment of 16 implantable-grade Li-ion cells cycled under two temperatures and C-rates. Results from a four-fold cross-validation study show that the proposed physics-informed machine learning models are capable of improving the estimation accuracy of cell capacity and the state of three primary degradation modes by over 50% compared to a purely data-driven approach. Additionally, this work provides insights into the role of temperature and C-rate in cell degradation. loss in lithiated active material in one of the electrodes (LAM PE/NE,li ) and 10% loss of lithium due to the solid electrolyte interface (SEI) growth (pure LLI), the total loss of lithium inventory quantified by the LII parameter is 20%, and the total LAM PE/NE is 10%. The LAM parameter used throughout this study is used to quantify delithiated LAM, whereas lithiated LAM can be quantified by a linear combination of both LAM and LII. Practically, the increase of LLI results from the accumulation of parasitic reactions in the cell that contribute to lithium inventory loss (e.g., SEI growth, electrolyte decomposition, and delamination of lithiated electrode materials).",
            "referenceCount": 51,
            "citationCount": 915,
            "influentialCitationCount": 56,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wahlstr\u00f6m2021PhysicsInformedML,\n author = {Niklas Wahlstr\u00f6m and A. Wills and J. Hendriks and Alexander Gregg and C. Wensrich and A. Solin and S. S\u00e4rkk\u00e4},\n title = {Physics-Informed Machine Learning},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eb9e0da8b7170e3ca4364f2f9010599c2d2556f1",
            "@type": "ScholarlyArticle",
            "paperId": "eb9e0da8b7170e3ca4364f2f9010599c2d2556f1",
            "corpusId": 67183937,
            "url": "https://www.semanticscholar.org/paper/eb9e0da8b7170e3ca4364f2f9010599c2d2556f1",
            "title": "Machine Learning With Python",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2970296819",
                "CorpusId": 67183937
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 2046,
            "influentialCitationCount": 63,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-05-08",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Singh2019MachineLW,\n author = {Ajit Singh},\n title = {Machine Learning With Python},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea",
            "@type": "ScholarlyArticle",
            "paperId": "7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea",
            "corpusId": 232322114,
            "url": "https://www.semanticscholar.org/paper/7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea",
            "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions",
            "venue": "SN Computer Science",
            "publicationVenue": {
                "id": "urn:research:7a7dc89b-e1a6-44df-a496-46c330a87840",
                "name": "SN Computer Science",
                "alternate_names": [
                    "SN Comput Sci"
                ],
                "issn": "2661-8907",
                "url": "https://link.springer.com/journal/42979"
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3146760956",
                "PubMedCentral": "7983091",
                "DBLP": "journals/sncs/Sarker21a",
                "DOI": "10.1007/s42979-021-00592-x",
                "CorpusId": 232322114,
                "PubMed": "33778771"
            },
            "abstract": null,
            "referenceCount": 146,
            "citationCount": 1049,
            "influentialCitationCount": 36,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s42979-021-00592-x.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2021-03-08",
            "journal": {
                "name": "Sn Computer Science",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Sarker2021MachineLA,\n author = {Iqbal H. Sarker},\n booktitle = {SN Computer Science},\n journal = {Sn Computer Science},\n title = {Machine Learning: Algorithms, Real-World Applications and Research Directions},\n volume = {2},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c292e473b3825eeb9db03c70b2e1c033aea190d5",
            "@type": "ScholarlyArticle",
            "paperId": "c292e473b3825eeb9db03c70b2e1c033aea190d5",
            "corpusId": 50780992,
            "url": "https://www.semanticscholar.org/paper/c292e473b3825eeb9db03c70b2e1c033aea190d5",
            "title": "Machine learning for molecular and materials science",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2884430236",
                "DOI": "10.1038/s41586-018-0337-2",
                "CorpusId": 50780992,
                "PubMed": "30046072"
            },
            "abstract": null,
            "referenceCount": 116,
            "citationCount": 2139,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://purl.org/net/epubs/manifestation/44000149/STFC-AAM-2019-065.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Chemistry",
                "Materials Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Chemistry",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Nature",
                "volume": "559"
            },
            "citationStyles": {
                "bibtex": "@Article{Butler2018MachineLF,\n author = {K. Butler and D. Davies and H. Cartwright and O. Isayev and A. Walsh},\n booktitle = {Nature},\n journal = {Nature},\n pages = {547 - 555},\n title = {Machine learning for molecular and materials science},\n volume = {559},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:53c9f3c34d8481adaf24df3b25581ccf1bc53f5c",
            "@type": "ScholarlyArticle",
            "paperId": "53c9f3c34d8481adaf24df3b25581ccf1bc53f5c",
            "corpusId": 236407461,
            "url": "https://www.semanticscholar.org/paper/53c9f3c34d8481adaf24df3b25581ccf1bc53f5c",
            "title": "Physics-informed machine learning",
            "venue": "Nature Reviews Physics",
            "publicationVenue": {
                "id": "urn:research:3639d55b-36ef-4fa6-97fd-1bdc155f9081",
                "name": "Nature Reviews Physics",
                "alternate_names": [
                    "Nat Rev Phys"
                ],
                "issn": "2522-5820",
                "url": "https://www.nature.com/natrevphys/"
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3163993681",
                "DOI": "10.1038/s42254-021-00314-5",
                "CorpusId": 236407461
            },
            "abstract": null,
            "referenceCount": 219,
            "citationCount": 1052,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2021-05-24",
            "journal": {
                "name": "Nature Reviews Physics",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Karniadakis2021PhysicsinformedML,\n author = {G. Karniadakis and I. Kevrekidis and Lu Lu and P. Perdikaris and Sifan Wang and Liu Yang},\n booktitle = {Nature Reviews Physics},\n journal = {Nature Reviews Physics},\n pages = {422 - 440},\n title = {Physics-informed machine learning},\n volume = {3},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2097ff87df3cb9427c7388bc7b997ed56907d45b",
            "@type": "ScholarlyArticle",
            "paperId": "2097ff87df3cb9427c7388bc7b997ed56907d45b",
            "corpusId": 204081381,
            "url": "https://www.semanticscholar.org/paper/2097ff87df3cb9427c7388bc7b997ed56907d45b",
            "title": "Optimization and Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "MAG": "2976265969",
                "DOI": "10.1002/9781119902881",
                "CorpusId": 204081381
            },
            "abstract": "Problem 1 (20%) Consider the function f(x1, x2) = (x1 + x 2 2) 2 At the point xk = [1, 0] T , find (a) the gradient descent direction (b) xk+1 by exact line search on the gradient descent direction (c) the Newton direction (d) xk+1 by exact line search on the Newton direction Problem 2 (40%) Consider the following quadratic function: f(x) = 1 2 xQx\u2212 bx Assume Q is symmetric and positive definite. (a) What\u2019s the gradient of f(x)?",
            "referenceCount": 0,
            "citationCount": 350,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ora.ox.ac.uk/objects/uuid:7b9b387a-fcce-425c-8186-5d161789a52a/files/dm900nt43b",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2022-03-21",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Goldberg2022OptimizationAM,\n author = {D. Goldberg},\n title = {Optimization and Machine Learning},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:60caa5b3d066e13feac496fd0736e976970eb09f",
            "@type": "ScholarlyArticle",
            "paperId": "60caa5b3d066e13feac496fd0736e976970eb09f",
            "corpusId": 295023,
            "url": "https://www.semanticscholar.org/paper/60caa5b3d066e13feac496fd0736e976970eb09f",
            "title": "Overview of Machine Learning",
            "venue": "International Journal of Advanced Research in Science, Communication and Technology",
            "publicationVenue": {
                "id": "urn:research:18be6e14-0ac5-454e-b78d-100e2dddd04e",
                "name": "International Journal of Advanced Research in Science, Communication and Technology",
                "alternate_names": [
                    "Int J Adv Res Sci Commun Technol"
                ],
                "issn": "2581-9429",
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.48175/ijarsct-4844",
                "CorpusId": 295023
            },
            "abstract": "The machine learning field, which can be briefly defined as enabling computers make successful predictions using past experiences, has exhibited an impressive development recently with the help of the rapid increase in the storage capacity and processing power of computers. Together with many other disciplines, machine learning methods have been widely employed in bioinformatics. The difficulties and cost of biological analyses have led to the development of sophisticated machine learning approaches for this application area. In this chapter, we first review the fundamental concepts of machine learning such as feature assessment, unsupervised versus supervised learning and types of classification. Then, we point out the main issues of designing machine learning experiments and their performance evaluation. Finally, we introduce some supervised learning methods",
            "referenceCount": 5,
            "citationCount": 173,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2022-06-18",
            "journal": {
                "name": "International Journal of Advanced Research in Science, Communication and Technology",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hsu2022OverviewOM,\n author = {Daniel Hsu},\n booktitle = {International Journal of Advanced Research in Science, Communication and Technology},\n journal = {International Journal of Advanced Research in Science, Communication and Technology},\n title = {Overview of Machine Learning},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb0cec8f2d34cfb9dbf8bffd1a5de499311ae098",
            "@type": "ScholarlyArticle",
            "paperId": "bb0cec8f2d34cfb9dbf8bffd1a5de499311ae098",
            "corpusId": 246381993,
            "url": "https://www.semanticscholar.org/paper/bb0cec8f2d34cfb9dbf8bffd1a5de499311ae098",
            "title": "Understanding Machine Learning",
            "venue": "Machine Learning for Cyber Agents",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.1007/978-3-030-91585-8_2",
                "CorpusId": 246381993
            },
            "abstract": null,
            "referenceCount": 7,
            "citationCount": 115,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Machine Learning for Cyber Agents",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Abaimov2022UnderstandingML,\n author = {Stanislav Abaimov and M. Martellini},\n booktitle = {Machine Learning for Cyber Agents},\n journal = {Machine Learning for Cyber Agents},\n title = {Understanding Machine Learning},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fbc6562814e08e416e28a268ce7beeaa3d0708c8",
            "@type": "ScholarlyArticle",
            "paperId": "fbc6562814e08e416e28a268ce7beeaa3d0708c8",
            "corpusId": 115963355,
            "url": "https://www.semanticscholar.org/paper/fbc6562814e08e416e28a268ce7beeaa3d0708c8",
            "title": "Large-Scale Machine Learning with Stochastic Gradient Descent",
            "venue": "International Conference on Computational Statistics",
            "publicationVenue": {
                "id": "urn:research:2d0a5631-36a3-47fd-a909-2b08e82bdf02",
                "name": "International Conference on Computational Statistics",
                "alternate_names": [
                    "COMPSTAT",
                    "Int Conf Comput Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "114517082",
                "DBLP": "conf/compstat/Bottou10",
                "DOI": "10.1007/978-3-7908-2604-3_16",
                "CorpusId": 115963355
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 5310,
            "influentialCitationCount": 722,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://leon.bottou.org/publications/pdf/compstat-2010.pdf",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bottou2010LargeScaleML,\n author = {L. Bottou},\n booktitle = {International Conference on Computational Statistics},\n pages = {177-186},\n title = {Large-Scale Machine Learning with Stochastic Gradient Descent},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0b544dfe355a5070b60986319a3f51fb45d1348e",
            "@type": "ScholarlyArticle",
            "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "corpusId": 5590763,
            "url": "https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e",
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2950635152",
                "DBLP": "conf/emnlp/ChoMGBBSB14",
                "ACL": "D14-1179",
                "ArXiv": "1406.1078",
                "DOI": "10.3115/v1/D14-1179",
                "CorpusId": 5590763
            },
            "abstract": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
            "referenceCount": 34,
            "citationCount": 19714,
            "influentialCitationCount": 3408,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://doi.org/10.3115/v1/d14-1179",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cho2014LearningPR,\n author = {Kyunghyun Cho and Bart van Merrienboer and \u00c7aglar G\u00fcl\u00e7ehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1724-1734},\n title = {Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "@type": "ScholarlyArticle",
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "corpusId": 11212020,
            "url": "https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2133564696",
                "ArXiv": "1409.0473",
                "DBLP": "journals/corr/BahdanauCB14",
                "CorpusId": 11212020
            },
            "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
            "referenceCount": 33,
            "citationCount": 24202,
            "influentialCitationCount": 2789,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-09-01",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1409.0473"
            },
            "citationStyles": {
                "bibtex": "@Article{Bahdanau2014NeuralMT,\n author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Neural Machine Translation by Jointly Learning to Align and Translate},\n volume = {abs/1409.0473},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
            "@type": "ScholarlyArticle",
            "paperId": "12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
            "corpusId": 7105713,
            "url": "https://www.semanticscholar.org/paper/12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
            "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2002,
            "externalIds": {
                "DBLP": "conf/emnlp/PangLV02",
                "MAG": "2951278869",
                "ACL": "W02-1011",
                "ArXiv": "cs/0205070",
                "DOI": "10.3115/1118693.1118704",
                "CorpusId": 7105713
            },
            "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.",
            "referenceCount": 39,
            "citationCount": 9064,
            "influentialCitationCount": 784,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1118693.1118704",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2002-05-27",
            "journal": {
                "name": "ArXiv",
                "volume": "cs.CL/0205070"
            },
            "citationStyles": {
                "bibtex": "@Article{Pang2002ThumbsUS,\n author = {B. Pang and Lillian Lee and Shivakumar Vaithyanathan},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Thumbs up? Sentiment Classification using Machine Learning Techniques},\n volume = {cs.CL/0205070},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2a85a6766b982ff7c8980e57ca6342d22493827",
            "@type": "ScholarlyArticle",
            "paperId": "e2a85a6766b982ff7c8980e57ca6342d22493827",
            "corpusId": 9059612,
            "url": "https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827",
            "title": "Adversarial Machine Learning at Scale",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/iclr/KurakinGB17",
                "ArXiv": "1611.01236",
                "MAG": "2552767274",
                "CorpusId": 9059612
            },
            "abstract": "Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a \"label leaking\" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.",
            "referenceCount": 22,
            "citationCount": 2593,
            "influentialCitationCount": 479,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.01236"
            },
            "citationStyles": {
                "bibtex": "@Article{Kurakin2016AdversarialML,\n author = {Alexey Kurakin and I. Goodfellow and Samy Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Adversarial Machine Learning at Scale},\n volume = {abs/1611.01236},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d433da6d0f143f20936379910104d2bb139d4ae",
            "@type": "ScholarlyArticle",
            "paperId": "5d433da6d0f143f20936379910104d2bb139d4ae",
            "corpusId": 203609613,
            "url": "https://www.semanticscholar.org/paper/5d433da6d0f143f20936379910104d2bb139d4ae",
            "title": "ilastik: interactive machine learning for (bio)image analysis",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2975634117",
                "DOI": "10.1038/s41592-019-0582-9",
                "CorpusId": 203609613,
                "PubMed": "31570887"
            },
            "abstract": null,
            "referenceCount": 44,
            "citationCount": 1485,
            "influentialCitationCount": 86,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://zenodo.org/records/3795652/files/Article_revised(1).pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-09-30",
            "journal": {
                "name": "Nature Methods",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Berg2019ilastikIM,\n author = {S. Berg and D. Kutra and Thorben Kroeger and C. Straehle and Bernhard X. Kausler and Carsten Haubold and Martin Schiegg and J. Ales and T. Beier and Markus Rudy and Kemal Eren and Jaime I Cervantes and Buote Xu and Fynn Beuttenmueller and A. Wolny and Chong Zhang and U. K\u00f6the and F. Hamprecht and A. Kreshuk},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {1226 - 1232},\n title = {ilastik: interactive machine learning for (bio)image analysis},\n volume = {16},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d21703674ae562bae4a849a75847cdd9ead417df",
            "@type": "ScholarlyArticle",
            "paperId": "d21703674ae562bae4a849a75847cdd9ead417df",
            "corpusId": 3119488,
            "url": "https://www.semanticscholar.org/paper/d21703674ae562bae4a849a75847cdd9ead417df",
            "title": "Optimization Methods for Large-Scale Machine Learning",
            "venue": "SIAM Review",
            "publicationVenue": {
                "id": "urn:research:8f59dd66-e4cd-4341-8ea9-9a03d965a009",
                "name": "SIAM Review",
                "alternate_names": [
                    "SIAM Rev",
                    "Siam Rev",
                    "Siam Review"
                ],
                "issn": "0036-1445",
                "url": "https://www.jstor.org/journal/siamreview"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2950363690",
                "DBLP": "journals/siamrev/BottouCN18",
                "ArXiv": "1606.04838",
                "DOI": "10.1137/16M1080173",
                "CorpusId": 3119488
            },
            "abstract": "This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.",
            "referenceCount": 183,
            "citationCount": 2519,
            "influentialCitationCount": 327,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1606.04838",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-06-15",
            "journal": {
                "name": "SIAM Rev.",
                "volume": "60"
            },
            "citationStyles": {
                "bibtex": "@Article{Bottou2016OptimizationMF,\n author = {L. Bottou and Frank E. Curtis and J. Nocedal},\n booktitle = {SIAM Review},\n journal = {SIAM Rev.},\n pages = {223-311},\n title = {Optimization Methods for Large-Scale Machine Learning},\n volume = {60},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b20af22b0734757d9ead382b201a65f9dd637cc",
            "@type": "ScholarlyArticle",
            "paperId": "6b20af22b0734757d9ead382b201a65f9dd637cc",
            "corpusId": 3091,
            "url": "https://www.semanticscholar.org/paper/6b20af22b0734757d9ead382b201a65f9dd637cc",
            "title": "Machine learning in automated text categorization",
            "venue": "CSUR",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/csur/Sebastiani02",
                "MAG": "2953226330",
                "ArXiv": "cs/0110053",
                "DOI": "10.1145/505282.505283",
                "CorpusId": 3091
            },
            "abstract": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.",
            "referenceCount": 201,
            "citationCount": 8777,
            "influentialCitationCount": 739,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/cs/0110053",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2001-10-26",
            "journal": {
                "name": "ArXiv",
                "volume": "cs.IR/0110053"
            },
            "citationStyles": {
                "bibtex": "@Article{Sebastiani2001MachineLI,\n author = {F. Sebastiani},\n booktitle = {CSUR},\n journal = {ArXiv},\n title = {Machine learning in automated text categorization},\n volume = {cs.IR/0110053},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f9ae5196908d21336ab02f5c20258dc760d125d6",
            "@type": "ScholarlyArticle",
            "paperId": "f9ae5196908d21336ab02f5c20258dc760d125d6",
            "corpusId": 623013,
            "url": "https://www.semanticscholar.org/paper/f9ae5196908d21336ab02f5c20258dc760d125d6",
            "title": "Adversarial machine learning",
            "venue": "Security and Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:63c420a6-4772-4d27-bb54-2b7f2e6635a6",
                "name": "Security and Artificial Intelligence",
                "alternate_names": [
                    "AISec",
                    "Secur Artif Intell"
                ],
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2095577883",
                "DBLP": "conf/ccs/HuangJNRT11",
                "DOI": "10.1145/2046684.2046692",
                "CorpusId": 623013
            },
            "abstract": "In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning---the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques.",
            "referenceCount": 200,
            "citationCount": 1277,
            "influentialCitationCount": 82,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.berkeley.edu/~tygar/papers/SML2/Adversarial_AISEC.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-02-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2019AdversarialML,\n author = {Ling Huang and A. Joseph and B. Nelson and Benjamin I. P. Rubinstein and J. D. Tygar},\n booktitle = {Security and Artificial Intelligence},\n pages = {43-58},\n title = {Adversarial machine learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e068be31ded63600aea068eacd12931efd2a1029",
            "@type": "ScholarlyArticle",
            "paperId": "e068be31ded63600aea068eacd12931efd2a1029",
            "corpusId": 62622768,
            "url": "https://www.semanticscholar.org/paper/e068be31ded63600aea068eacd12931efd2a1029",
            "title": "UCI Repository of machine learning databases",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2084812512",
                "CorpusId": 62622768
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 14044,
            "influentialCitationCount": 858,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Blake1998UCIRO,\n author = {Catherine Blake},\n title = {UCI Repository of machine learning databases},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9e27190f2d9b2167d4a66b88696def4585072fd5",
            "@type": "ScholarlyArticle",
            "paperId": "9e27190f2d9b2167d4a66b88696def4585072fd5",
            "corpusId": 14728657,
            "url": "https://www.semanticscholar.org/paper/9e27190f2d9b2167d4a66b88696def4585072fd5",
            "title": "SoilGrids250m: Global gridded soil information based on machine learning",
            "venue": "PLoS ONE",
            "publicationVenue": {
                "id": "urn:research:0aed7a40-85f3-4c66-9e1b-c1556c57001b",
                "name": "PLoS ONE",
                "alternate_names": [
                    "Plo ONE",
                    "PLOS ONE",
                    "PLO ONE"
                ],
                "issn": "1932-6203",
                "url": "https://journals.plos.org/plosone/"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5313206",
                "MAG": "2588003345",
                "DOI": "10.1371/journal.pone.0169748",
                "CorpusId": 14728657,
                "PubMed": "28207752"
            },
            "abstract": "This paper describes the technical development and accuracy assessment of the most recent and improved version of the SoilGrids system at 250m resolution (June 2016 update). SoilGrids provides global predictions for standard numeric soil properties (organic carbon, bulk density, Cation Exchange Capacity (CEC), pH, soil texture fractions and coarse fragments) at seven standard depths (0, 5, 15, 30, 60, 100 and 200 cm), in addition to predictions of depth to bedrock and distribution of soil classes based on the World Reference Base (WRB) and USDA classification systems (ca. 280 raster layers in total). Predictions were based on ca. 150,000 soil profiles used for training and a stack of 158 remote sensing-based soil covariates (primarily derived from MODIS land products, SRTM DEM derivatives, climatic images and global landform and lithology maps), which were used to fit an ensemble of machine learning methods\u2014random forest and gradient boosting and/or multinomial logistic regression\u2014as implemented in the R packages ranger, xgboost, nnet and caret. The results of 10\u2013fold cross-validation show that the ensemble models explain between 56% (coarse fragments) and 83% (pH) of variation with an overall average of 61%. Improvements in the relative accuracy considering the amount of variation explained, in comparison to the previous version of SoilGrids at 1 km spatial resolution, range from 60 to 230%. Improvements can be attributed to: (1) the use of machine learning instead of linear regression, (2) to considerable investments in preparing finer resolution covariate layers and (3) to insertion of additional soil profiles. Further development of SoilGrids could include refinement of methods to incorporate input uncertainties and derivation of posterior probability distributions (per pixel), and further automation of spatial modeling so that soil maps can be generated for potentially hundreds of soil variables. Another area of future research is the development of methods for multiscale merging of SoilGrids predictions with local and/or national gridded soil products (e.g. up to 50 m spatial resolution) so that increasingly more accurate, complete and consistent global soil information can be produced. SoilGrids are available under the Open Data Base License.",
            "referenceCount": 107,
            "citationCount": 2242,
            "influentialCitationCount": 141,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Environmental Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-16",
            "journal": {
                "name": "PLoS ONE",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Hengl2017SoilGrids250mGG,\n author = {T. Hengl and Jorge Mendes de Jesus and G. Heuvelink and Maria Ruiperez Gonz\u00e1lez and M. Kilibarda and Aleksandar Blagoti\u0107 and Shangguan Wei and Marvin N. Wright and X. Geng and B. Bauer-Marschallinger and M. Guevara and R. Vargas and R. MacMillan and N. Batjes and J. Leenaars and E. Ribeiro and Ichsani Wheeler and S. Mantel and B. Kempen},\n booktitle = {PLoS ONE},\n journal = {PLoS ONE},\n title = {SoilGrids250m: Global gridded soil information based on machine learning},\n volume = {12},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80d9f0eb47b712988d19cbe29a7bfa63f2a175d0",
            "@type": "ScholarlyArticle",
            "paperId": "80d9f0eb47b712988d19cbe29a7bfa63f2a175d0",
            "corpusId": 237504441,
            "url": "https://www.semanticscholar.org/paper/80d9f0eb47b712988d19cbe29a7bfa63f2a175d0",
            "title": "A guide to machine learning for biologists",
            "venue": "Nature reviews. Molecular cell biology",
            "publicationVenue": {
                "id": "urn:research:b3b8f19c-c31b-4847-bc7b-66a18aebedfe",
                "name": "Nature reviews. Molecular cell biology",
                "alternate_names": [
                    "Nat Rev Mol Cell Biology",
                    "Nature Reviews Molecular Cell Biology",
                    "Nat rev Mol cell biology"
                ],
                "issn": "1471-0072",
                "url": "https://www.nature.com/nrm/"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1038/s41580-021-00407-0",
                "CorpusId": 237504441,
                "PubMed": "34518686"
            },
            "abstract": null,
            "referenceCount": 172,
            "citationCount": 445,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://discovery.ucl.ac.uk/10134478/1/NRMCB-review-accepted-forRPS.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2021-09-13",
            "journal": {
                "name": "Nature Reviews Molecular Cell Biology",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Greener2021AGT,\n author = {Joe G. Greener and Shaun M. Kandathil and Lewis Moffat and David T. Jones},\n booktitle = {Nature reviews. Molecular cell biology},\n journal = {Nature Reviews Molecular Cell Biology},\n pages = {40 - 55},\n title = {A guide to machine learning for biologists},\n volume = {23},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a0f303b6e22ef52943355993f57d65938997066a",
            "@type": "ScholarlyArticle",
            "paperId": "a0f303b6e22ef52943355993f57d65938997066a",
            "corpusId": 233210772,
            "url": "https://www.semanticscholar.org/paper/a0f303b6e22ef52943355993f57d65938997066a",
            "title": "Machine learning and deep learning",
            "venue": "Electronic Markets",
            "publicationVenue": {
                "id": "urn:research:21b370ff-cb87-4599-b39a-25cd5a1b03cb",
                "name": "Electronic Markets",
                "alternate_names": [
                    "Electron Mark"
                ],
                "issn": "1019-6781",
                "url": "http://www.metapress.com/openurl.asp?genre=journal&issn=1019-6781"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2104-05314",
                "ArXiv": "2104.05314",
                "DOI": "10.1007/s12525-021-00475-2",
                "CorpusId": 233210772
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 427,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-04-08",
            "journal": {
                "name": "Electronic Markets",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Janiesch2021MachineLA,\n author = {Christian Janiesch and Patrick Zschech and K. Heinrich},\n booktitle = {Electronic Markets},\n journal = {Electronic Markets},\n pages = {685 - 695},\n title = {Machine learning and deep learning},\n volume = {31},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:256db9dba1978f004a67c86ffc321563b1aee79a",
            "@type": "ScholarlyArticle",
            "paperId": "256db9dba1978f004a67c86ffc321563b1aee79a",
            "corpusId": 232307437,
            "url": "https://www.semanticscholar.org/paper/256db9dba1978f004a67c86ffc321563b1aee79a",
            "title": "Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges",
            "venue": "Statistics Survey",
            "publicationVenue": {
                "id": "urn:research:aa48c648-ec9a-4625-9a7a-68c91ccb54ea",
                "name": "Statistics Survey",
                "alternate_names": [
                    "Stat Surv",
                    "Statistics Surveys"
                ],
                "issn": "1935-7516",
                "url": "https://www.imstat.org/journals-and-publications/statistics-surveys/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2103.11251",
                "DBLP": "journals/corr/abs-2103-11251",
                "DOI": "10.1214/21-ss133",
                "CorpusId": 232307437
            },
            "abstract": "Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the\"Rashomon set\"of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.",
            "referenceCount": 346,
            "citationCount": 332,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://projecteuclid.org/journals/statistics-surveys/volume-16/issue-none/Interpretable-machine-learning-Fundamental-principles-and-10-grand-challenges/10.1214/21-SS133.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-03-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2103.11251"
            },
            "citationStyles": {
                "bibtex": "@Article{Rudin2021InterpretableML,\n author = {C. Rudin and Chaofan Chen and Zhi Chen and Haiyang Huang and Lesia Semenova and Chudi Zhong},\n booktitle = {Statistics Survey},\n journal = {ArXiv},\n title = {Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges},\n volume = {abs/2103.11251},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:24d21ecaeb2d2ecc20e26a5e3f5128247704ccfe",
            "@type": "ScholarlyArticle",
            "paperId": "24d21ecaeb2d2ecc20e26a5e3f5128247704ccfe",
            "corpusId": 235217766,
            "url": "https://www.semanticscholar.org/paper/24d21ecaeb2d2ecc20e26a5e3f5128247704ccfe",
            "title": "Swarm Learning for decentralized and confidential clinical machine learning",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2021,
            "externalIds": {
                "PubMedCentral": "8189907",
                "DOI": "10.1038/s41586-021-03583-3",
                "CorpusId": 235217766,
                "PubMed": "34040261"
            },
            "abstract": null,
            "referenceCount": 47,
            "citationCount": 351,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41586-021-03583-3.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-05-26",
            "journal": {
                "name": "Nature",
                "volume": "594"
            },
            "citationStyles": {
                "bibtex": "@Article{Warnat-Herresthal2021SwarmLF,\n author = {Stefanie Warnat-Herresthal and Hartmut Schultze and Krishnaprasad Shastry and Sathyanarayanan Manamohan and Saikat Mukherjee and Vishesh Garg and Ravi Sarveswara and K. H\u00e4ndler and P. Pickkers and N. Aziz and S. Ktena and F. Tran and M. Bitzer and S. Ossowski and Nicolas Casadei and C. Herr and Daniel Petersheim and U. Behrends and Fabian Kern and Tobias Fehlmann and P. Schommers and C. Lehmann and M. Augustin and J. Rybniker and J. Altm\u00fcller and N. Mishra and J. P. Bernardes and B. Kr\u00e4mer and L. Bonaguro and J. Schulte-Schrepping and Elena De Domenico and Christian Siever and Michael Kraut and Milind Desai and Bruno Monnet and M. Saridaki and Charles Siegel and A. Drews and Melanie Nuesch-Germano and Heidi Theis and J. Heyckendorf and S. Schreiber and Sarah Kim-Hellmuth and J. Nattermann and D. Skowasch and I. Kurth and A. Keller and R. Bals and P. N\u00fcrnberg and O. Riess and P. Rosenstiel and M. Netea and F. Theis and S. Mukherjee and Michael Backes and A. Aschenbrenner and T. Ulas and M. Breteler and E. Giamarellos\u2010Bourboulis and M. Kox and M. Becker and S. Cheran and M. Woodacre and E. L. Goh and J. Schultze},\n booktitle = {Nature},\n journal = {Nature},\n pages = {265 - 270},\n title = {Swarm Learning for decentralized and confidential clinical machine learning},\n volume = {594},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:287ba5bf00d96af1596aaf80c178392a9c4fcc28",
            "@type": "ScholarlyArticle",
            "paperId": "287ba5bf00d96af1596aaf80c178392a9c4fcc28",
            "corpusId": 58429428,
            "url": "https://www.semanticscholar.org/paper/287ba5bf00d96af1596aaf80c178392a9c4fcc28",
            "title": "Machine Learning Basics",
            "venue": "Intelligent Computing for Interactive System Design",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3197971679",
                "DBLP": "books/mc/21/ChatzilygeroudisHP21",
                "DOI": "10.1145/3447404.3447414",
                "CorpusId": 58429428
            },
            "abstract": "coined in 1959 by Arthur Samuel [Samuel 1959], Tom Mitchell [Mitchell 1997] provided a more formal definition: \u201cA computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\u201d ML has be applied to many real-world problems or tasks, like medical diagno\u00ad sis, robotics, recommendation systems, facial recognition, stock prices prediction, and sentiment analysis, with great success. We can divide ML algorithms into three main categories (see Figure 4.1): Machine Learning Basics",
            "referenceCount": 51,
            "citationCount": 207,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book"
            ],
            "publicationDate": "2021-02-23",
            "journal": {
                "name": "Intelligent Computing for Interactive System Design",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Chatzilygeroudis2021MachineLB,\n author = {Konstantinos Chatzilygeroudis and I. Hatzilygeroudis and I. Perikos},\n booktitle = {Intelligent Computing for Interactive System Design},\n journal = {Intelligent Computing for Interactive System Design},\n title = {Machine Learning Basics},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4d8f0ae904779a50b2e18fec49e51a5661a98d8a",
            "@type": "ScholarlyArticle",
            "paperId": "4d8f0ae904779a50b2e18fec49e51a5661a98d8a",
            "corpusId": 232405927,
            "url": "https://www.semanticscholar.org/paper/4d8f0ae904779a50b2e18fec49e51a5661a98d8a",
            "title": "MRI-Based Brain Tumor Classification Using Ensemble of Deep Features and Machine Learning Classifiers",
            "venue": "Italian National Conference on Sensors",
            "publicationVenue": {
                "id": "urn:research:3dbf084c-ef47-4b74-9919-047b40704538",
                "name": "Italian National Conference on Sensors",
                "alternate_names": [
                    "SENSORS",
                    "IEEE Sens",
                    "Ital National Conf Sens",
                    "IEEE Sensors",
                    "Sensors"
                ],
                "issn": "1424-8220",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001"
            },
            "year": 2021,
            "externalIds": {
                "PubMedCentral": "8004778",
                "DBLP": "journals/sensors/KangUG21",
                "DOI": "10.3390/s21062222",
                "CorpusId": 232405927,
                "PubMed": "33810176"
            },
            "abstract": "Brain tumor classification plays an important role in clinical diagnosis and effective treatment. In this work, we propose a method for brain tumor classification using an ensemble of deep features and machine learning classifiers. In our proposed framework, we adopt the concept of transfer learning and uses several pre-trained deep convolutional neural networks to extract deep features from brain magnetic resonance (MR) images. The extracted deep features are then evaluated by several machine learning classifiers. The top three deep features which perform well on several machine learning classifiers are selected and concatenated as an ensemble of deep features which is then fed into several machine learning classifiers to predict the final output. To evaluate the different kinds of pre-trained models as a deep feature extractor, machine learning classifiers, and the effectiveness of an ensemble of deep feature for brain tumor classification, we use three different brain magnetic resonance imaging (MRI) datasets that are openly accessible from the web. Experimental results demonstrate that an ensemble of deep features can help improving performance significantly, and in most cases, support vector machine (SVM) with radial basis function (RBF) kernel outperforms other machine learning classifiers, especially for large datasets.",
            "referenceCount": 77,
            "citationCount": 185,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/1424-8220/21/6/2222/pdf?version=1616574103",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-03-01",
            "journal": {
                "name": "Sensors (Basel, Switzerland)",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Kang2021MRIBasedBT,\n author = {Jaeyong Kang and Z. Ullah and Jeonghwan Gwak},\n booktitle = {Italian National Conference on Sensors},\n journal = {Sensors (Basel, Switzerland)},\n title = {MRI-Based Brain Tumor Classification Using Ensemble of Deep Features and Machine Learning Classifiers},\n volume = {21},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f1664bbaddedea8c250873e7610ab07e53fa7132",
            "@type": "ScholarlyArticle",
            "paperId": "f1664bbaddedea8c250873e7610ab07e53fa7132",
            "corpusId": 231740624,
            "url": "https://www.semanticscholar.org/paper/f1664bbaddedea8c250873e7610ab07e53fa7132",
            "title": "Machine learning pipeline for battery state-of-health estimation",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2102.00837",
                "MAG": "3126452185",
                "DBLP": "journals/natmi/RomanSRPF21",
                "DOI": "10.1038/s42256-021-00312-3",
                "CorpusId": 231740624
            },
            "abstract": null,
            "referenceCount": 89,
            "citationCount": 182,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://eprints.gla.ac.uk/267970/1/267970.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-02-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Roman2021MachineLP,\n author = {D. Roman and Saurabh Saxena and V. Robu and Michael G. Pecht and D. Flynn},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {447 - 456},\n title = {Machine learning pipeline for battery state-of-health estimation},\n volume = {3},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ae2783a9196fb4bc2a610ae812d19722daddce5",
            "@type": "ScholarlyArticle",
            "paperId": "7ae2783a9196fb4bc2a610ae812d19722daddce5",
            "corpusId": 213446703,
            "url": "https://www.semanticscholar.org/paper/7ae2783a9196fb4bc2a610ae812d19722daddce5",
            "title": "Applications of machine learning to machine fault diagnosis: A review and roadmap",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "2998506103",
                "DOI": "10.1016/j.ymssp.2019.106587",
                "CorpusId": 213446703
            },
            "abstract": null,
            "referenceCount": 440,
            "citationCount": 1162,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://bura.brunel.ac.uk/bitstream/2438/20040/1/FullText.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-04-01",
            "journal": {
                "name": "Mechanical Systems and Signal Processing",
                "volume": "138"
            },
            "citationStyles": {
                "bibtex": "@Article{Lei2020ApplicationsOM,\n author = {Y. Lei and Bin Yang and Xinwei Jiang and Feng Jia and Naipeng Li and A. Nandi},\n journal = {Mechanical Systems and Signal Processing},\n pages = {106587},\n title = {Applications of machine learning to machine fault diagnosis: A review and roadmap},\n volume = {138},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7feb0fc888cd55360949554db032d7d1cba9e947",
            "@type": "ScholarlyArticle",
            "paperId": "7feb0fc888cd55360949554db032d7d1cba9e947",
            "corpusId": 60499165,
            "url": "https://www.semanticscholar.org/paper/7feb0fc888cd55360949554db032d7d1cba9e947",
            "title": "Programs for Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "1504694836",
                "CorpusId": 60499165
            },
            "abstract": "Algorithms for constructing decision trees are among the most well known and widely used of all machine learning methods. Among decision tree algorithms, J. Ross Quinlan's ID3 and its successor, C4.5, are probably the most popular in the machine learning community. These algorithms and variations on them have been the subject of numerous research papers since Quinlan introduced ID3. Until recently, most researchers looking for an introduction to decision trees turned to Quinlan's seminal 1986 Machine Learning journal article [Quinlan, 1986]. In his new book, C4.5: Programs for Machine Learning, Quinlan has put together a definitive, much needed description of his complete system, including the latest developments. As such, this book will be a welcome addition to the library of many researchers and students.",
            "referenceCount": 3,
            "citationCount": 8758,
            "influentialCitationCount": 470,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Salzberg1994ProgramsFM,\n author = {S. Salzberg and Alberto Maria Segre},\n title = {Programs for Machine Learning},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f381c53aeb7742e4047d06d84f9e0c4f523231a3",
            "@type": "ScholarlyArticle",
            "paperId": "f381c53aeb7742e4047d06d84f9e0c4f523231a3",
            "corpusId": 234796260,
            "url": "https://www.semanticscholar.org/paper/f381c53aeb7742e4047d06d84f9e0c4f523231a3",
            "title": "Coronavirus disease (COVID-19) cases analysis using machine-learning applications",
            "venue": "Applied Nanoscience",
            "publicationVenue": {
                "id": "urn:research:b478fd19-64fa-4b39-8546-7b253fad9c1c",
                "name": "Applied Nanoscience",
                "alternate_names": [
                    "Appl Nanosci"
                ],
                "issn": "2190-5517",
                "url": "http://www.springer.com/13204"
            },
            "year": 2021,
            "externalIds": {
                "PubMedCentral": "8138510",
                "DOI": "10.1007/s13204-021-01868-7",
                "CorpusId": 234796260,
                "PubMed": "34036034"
            },
            "abstract": null,
            "referenceCount": 40,
            "citationCount": 238,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s13204-021-01868-7.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-05-21",
            "journal": {
                "name": "Applied Nanoscience",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Kwekha-Rashid2021CoronavirusD,\n author = {Ameer Sardar Kwekha-Rashid and H. N. Abduljabbar and Bilal S. A. Alhayani},\n booktitle = {Applied Nanoscience},\n journal = {Applied Nanoscience},\n pages = {2013 - 2025},\n title = {Coronavirus disease (COVID-19) cases analysis using machine-learning applications},\n volume = {13},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:696b388ee6221c6dbcfd647a06883b2bfee773d9",
            "@type": "ScholarlyArticle",
            "paperId": "696b388ee6221c6dbcfd647a06883b2bfee773d9",
            "corpusId": 210164697,
            "url": "https://www.semanticscholar.org/paper/696b388ee6221c6dbcfd647a06883b2bfee773d9",
            "title": "Universal Differential Equations for Scientific Machine Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2001-04385",
                "MAG": "2999026783",
                "ArXiv": "2001.04385",
                "DOI": "10.21203/RS.3.RS-55125/V1",
                "CorpusId": 210164697
            },
            "abstract": "\n In the context of science, the well-known adage \u201ca picture is worth a thousand words\u201d might well be \u201ca model is worth a thousand datasets.\u201d Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring \"big data\". In this work demonstrate how a mathematical object, which we denote universal differential equations (UDEs), can be utilized as a theoretical underpinning to a diverse array of problems in scientific machine learning to yield efficient algorithms and generalized approaches. The UDE model augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating the training of physics-informed neural networks and large-eddy simulations, can all be transformed into UDE training problems that are efficiently solved by a single software methodology.",
            "referenceCount": 133,
            "citationCount": 414,
            "influentialCitationCount": 39,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.researchsquare.com/article/rs-55125/v1.pdf?c=1631854486000",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-01-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2001.04385"
            },
            "citationStyles": {
                "bibtex": "@Article{Rackauckas2020UniversalDE,\n author = {Christopher Rackauckas and Yingbo Ma and Julius Martensen and Collin Warner and K. Zubov and R. Supekar and Dominic J. Skinner and A. Ramadhan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Universal Differential Equations for Scientific Machine Learning},\n volume = {abs/2001.04385},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:61a1565016477b2092a212e7af0e789a250bc552",
            "@type": "ScholarlyArticle",
            "paperId": "61a1565016477b2092a212e7af0e789a250bc552",
            "corpusId": 60688891,
            "url": "https://www.semanticscholar.org/paper/61a1565016477b2092a212e7af0e789a250bc552",
            "title": "Pattern Recognition and Machine Learning (Information Science and Statistics)",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "1506806321",
                "CorpusId": 60688891
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 7472,
            "influentialCitationCount": 842,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2006-08-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bishop2006PatternRA,\n author = {Christopher M. Bishop},\n title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e0408181bccb7e3754dd5e6785ec47d8beb8b6bd",
            "@type": "ScholarlyArticle",
            "paperId": "e0408181bccb7e3754dd5e6785ec47d8beb8b6bd",
            "corpusId": 1388140,
            "url": "https://www.semanticscholar.org/paper/e0408181bccb7e3754dd5e6785ec47d8beb8b6bd",
            "title": "Machine Learning for High-Speed Corner Detection",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2584333262",
                "DBLP": "conf/eccv/RostenD06",
                "DOI": "10.1007/11744023_34",
                "CorpusId": 1388140
            },
            "abstract": null,
            "referenceCount": 39,
            "citationCount": 4488,
            "influentialCitationCount": 506,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/11744023_34.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-05-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rosten2006MachineLF,\n author = {E. Rosten and T. Drummond},\n booktitle = {European Conference on Computer Vision},\n pages = {430-443},\n title = {Machine Learning for High-Speed Corner Detection},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:62df84d6a4d26f95e4714796c2337c9848cc13b5",
            "@type": "ScholarlyArticle",
            "paperId": "62df84d6a4d26f95e4714796c2337c9848cc13b5",
            "corpusId": 1507815,
            "url": "https://www.semanticscholar.org/paper/62df84d6a4d26f95e4714796c2337c9848cc13b5",
            "title": "MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1512.01274",
                "DBLP": "journals/corr/ChenLLLWWXXZZ15",
                "MAG": "2186615578",
                "CorpusId": 1507815
            },
            "abstract": "MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. \nThis paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines.",
            "referenceCount": 13,
            "citationCount": 2139,
            "influentialCitationCount": 273,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-12-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1512.01274"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2015MXNetAF,\n author = {Tianqi Chen and Mu Li and Yutian Li and Min Lin and Naiyan Wang and Minjie Wang and Tianjun Xiao and Bing Xu and Chiyuan Zhang and Zheng Zhang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems},\n volume = {abs/1512.01274},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6d873542f9722a520a9a6602378d6344907b1183",
            "@type": "ScholarlyArticle",
            "paperId": "6d873542f9722a520a9a6602378d6344907b1183",
            "corpusId": 222142011,
            "url": "https://www.semanticscholar.org/paper/6d873542f9722a520a9a6602378d6344907b1183",
            "title": "DOME: recommendations for supervised machine learning validation in biology",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1038/s41592-021-01205-4",
                "CorpusId": 222142011,
                "PubMed": "34316068"
            },
            "abstract": null,
            "referenceCount": 41,
            "citationCount": 94,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41592-021-01205-4.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-07-27",
            "journal": {
                "name": "Nature Methods",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Walsh2021DOMERF,\n author = {Ian Walsh and D. Fishman and D. Garc\u00eda-Gasulla and T. Titma and G. Pollastri and The Elixir Machine Learning focus group and J. Harrow and Fotis Psomopoulos and Silvio C. E. Tosatto},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {1122 - 1127},\n title = {DOME: recommendations for supervised machine learning validation in biology},\n volume = {18},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f86f1748d1b6d22870f4347fd5d65314ba800583",
            "@type": "ScholarlyArticle",
            "paperId": "f86f1748d1b6d22870f4347fd5d65314ba800583",
            "corpusId": 198496504,
            "url": "https://www.semanticscholar.org/paper/f86f1748d1b6d22870f4347fd5d65314ba800583",
            "title": "Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1812.11118",
                "MAG": "2963518130",
                "DOI": "10.1073/pnas.1903070116",
                "CorpusId": 198496504,
                "PubMed": "31341078"
            },
            "abstract": "Significance While breakthroughs in machine learning and artificial intelligence are changing society, our fundamental understanding has lagged behind. It is traditionally believed that fitting models to the training data exactly is to be avoided as it leads to poor performance on unseen data. However, powerful modern classifiers frequently have near-perfect fit in training, a disconnect that spurred recent intensive research and controversy on whether theory provides practical insights. In this work, we show how classical theory and modern practice can be reconciled within a single unified performance curve and propose a mechanism underlying its emergence. We believe this previously unknown pattern connecting the structure and performance of learning architectures will help shape design and understanding of learning algorithms. Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias\u2013variance trade-off, appears to be at odds with the observed behavior of methods used in modern machine-learning practice. The bias\u2013variance trade-off implies that a model should balance underfitting and overfitting: Rich enough to express underlying structure in data and simple enough to avoid fitting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This \u201cdouble-descent\u201d curve subsumes the textbook U-shaped bias\u2013variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine-learning models delineates the limits of classical analyses and has implications for both the theory and the practice of machine learning.",
            "referenceCount": 48,
            "citationCount": 1190,
            "influentialCitationCount": 116,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/116/32/15849.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-28",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "116"
            },
            "citationStyles": {
                "bibtex": "@Article{Belkin2018ReconcilingMM,\n author = {M. Belkin and Daniel J. Hsu and Siyuan Ma and Soumik Mandal},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {15849 - 15854},\n title = {Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off},\n volume = {116},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b55e490637babd50dab3cdaaa3a60a2be6eb1cbb",
            "@type": "ScholarlyArticle",
            "paperId": "b55e490637babd50dab3cdaaa3a60a2be6eb1cbb",
            "corpusId": 68018984,
            "url": "https://www.semanticscholar.org/paper/b55e490637babd50dab3cdaaa3a60a2be6eb1cbb",
            "title": "Automated Machine Learning - Methods, Systems, Challenges",
            "venue": "Automated Machine Learning",
            "publicationVenue": {
                "id": "urn:research:a688800a-ab93-4531-9258-c10e1b6ddf68",
                "name": "Automated Machine Learning",
                "alternate_names": [
                    "Automation and Machine Learning",
                    "Autom Mach Learn"
                ],
                "issn": "2520-131X",
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "books/sp/HKV2019",
                "CorpusId": 68018984
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 955,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{None,\n booktitle = {Automated Machine Learning},\n title = {Automated Machine Learning - Methods, Systems, Challenges},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97ac11e5a6440eccb70ae7146392ac138c36fa6c",
            "@type": "ScholarlyArticle",
            "paperId": "97ac11e5a6440eccb70ae7146392ac138c36fa6c",
            "corpusId": 216228079,
            "url": "https://www.semanticscholar.org/paper/97ac11e5a6440eccb70ae7146392ac138c36fa6c",
            "title": "Fairness in Machine Learning",
            "venue": "INNSBDDL",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2012-15816",
                "MAG": "3014590323",
                "ArXiv": "2012.15816",
                "DOI": "10.1007/978-3-030-43883-8_7",
                "CorpusId": 216228079
            },
            "abstract": null,
            "referenceCount": 369,
            "citationCount": 402,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iris.unige.it/bitstream/11567/1032155/1/BC006.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-12-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2012.15816"
            },
            "citationStyles": {
                "bibtex": "@Article{Oneto2020FairnessIM,\n author = {L. Oneto and S. Chiappa},\n booktitle = {INNSBDDL},\n journal = {ArXiv},\n title = {Fairness in Machine Learning},\n volume = {abs/2012.15816},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4087e84fc695bb6433d0104ee94f9d7e9f4b7da5",
            "@type": "ScholarlyArticle",
            "paperId": "4087e84fc695bb6433d0104ee94f9d7e9f4b7da5",
            "corpusId": 166227999,
            "url": "https://www.semanticscholar.org/paper/4087e84fc695bb6433d0104ee94f9d7e9f4b7da5",
            "title": "Machine Learning for Fluid Mechanics",
            "venue": "Annual Review of Fluid Mechanics",
            "publicationVenue": {
                "id": "urn:research:db4b98e5-3f60-4140-b07c-7b9d73023183",
                "name": "Annual Review of Fluid Mechanics",
                "alternate_names": [
                    "Annu Rev Fluid Mech"
                ],
                "issn": "0066-4189",
                "url": "https://www.annualreviews.org/journal/fluid"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3102140816",
                "DBLP": "journals/corr/abs-1905-11075",
                "ArXiv": "1905.11075",
                "DOI": "10.1146/annurev-fluid-010719-060214",
                "CorpusId": 166227999
            },
            "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.",
            "referenceCount": 170,
            "citationCount": 1352,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1905.11075",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-05-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1905.11075"
            },
            "citationStyles": {
                "bibtex": "@Article{Brunton2019MachineLF,\n author = {S. Brunton and B. R. Noack and P. Koumoutsakos},\n booktitle = {Annual Review of Fluid Mechanics},\n journal = {ArXiv},\n title = {Machine Learning for Fluid Mechanics},\n volume = {abs/1905.11075},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fee8f63972906214b77f16cfeca0b93ee8f36ba2",
            "@type": "ScholarlyArticle",
            "paperId": "fee8f63972906214b77f16cfeca0b93ee8f36ba2",
            "corpusId": 222208640,
            "url": "https://www.semanticscholar.org/paper/fee8f63972906214b77f16cfeca0b93ee8f36ba2",
            "title": "Fairness in Machine Learning: A Survey",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2010-04053",
                "MAG": "3092541244",
                "ArXiv": "2010.04053",
                "DOI": "10.1145/3616865",
                "CorpusId": 222208640
            },
            "abstract": "When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organises approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarising open challenges articulated as five dilemmas for fairness research.",
            "referenceCount": 352,
            "citationCount": 315,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3616865",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-10-04",
            "journal": {
                "name": "ACM Computing Surveys",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Caton2020FairnessIM,\n author = {Simon Caton and C. Haas},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys},\n title = {Fairness in Machine Learning: A Survey},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57e6cca1479a4642f867e69b4dee93d14259dc3d",
            "@type": "ScholarlyArticle",
            "paperId": "57e6cca1479a4642f867e69b4dee93d14259dc3d",
            "corpusId": 226246283,
            "url": "https://www.semanticscholar.org/paper/57e6cca1479a4642f867e69b4dee93d14259dc3d",
            "title": "Power of data in quantum machine learning",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "8113501",
                "MAG": "3096052452",
                "ArXiv": "2011.01938",
                "DBLP": "journals/corr/abs-2011-01938",
                "DOI": "10.1038/s41467-021-22539-9",
                "CorpusId": 226246283,
                "PubMed": "33976136"
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 355,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-021-22539-9.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-11-03",
            "journal": {
                "name": "Nature Communications",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2020PowerOD,\n author = {Hsin-Yuan Huang and M. Broughton and M. Mohseni and R. Babbush and S. Boixo and H. Neven and J. McClean},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Power of data in quantum machine learning},\n volume = {12},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6068d39e92aef1bb0e1291e9931894c35692a85e",
            "@type": "ScholarlyArticle",
            "paperId": "6068d39e92aef1bb0e1291e9931894c35692a85e",
            "corpusId": 224818450,
            "url": "https://www.semanticscholar.org/paper/6068d39e92aef1bb0e1291e9931894c35692a85e",
            "title": "Counterfactual Explanations for Machine Learning: A Review",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3094613840",
                "DBLP": "journals/corr/abs-2010-10596",
                "CorpusId": 224818450
            },
            "abstract": "Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine-learning-based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this paper, we seek to review and categorize research on counterfactual explanations, a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently-proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.",
            "referenceCount": 102,
            "citationCount": 328,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-10-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2010.10596"
            },
            "citationStyles": {
                "bibtex": "@Article{Verma2020CounterfactualEF,\n author = {Sahil Verma and John P. Dickerson and Keegan E. Hines},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Counterfactual Explanations for Machine Learning: A Review},\n volume = {abs/2010.10596},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:69d49a06f09cf934310ccbf3bb2a360fa719272d",
            "@type": "ScholarlyArticle",
            "paperId": "69d49a06f09cf934310ccbf3bb2a360fa719272d",
            "corpusId": 230794987,
            "url": "https://www.semanticscholar.org/paper/69d49a06f09cf934310ccbf3bb2a360fa719272d",
            "title": "Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3136933888",
                "DBLP": "journals/natmi/RobertsDTGYUAEM21",
                "ArXiv": "2008.06388",
                "DOI": "10.1038/s42256-021-00307-0",
                "CorpusId": 230794987
            },
            "abstract": null,
            "referenceCount": 117,
            "citationCount": 595,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s42256-021-00307-0.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-08-14",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Roberts2020CommonPA,\n author = {M. Roberts and D. Driggs and Matthew Thorpe and J. Gilbey and Michael Yeung and Stephan Ursprung and Angelica I. Avil\u00e9s-Rivero and Christian Etmann and C. McCague and L. Beer and J. Weir-McCall and Z. Teng and E. Gkrania-Klotsas and Alessandro Anna Emily Emmanuel Georg Ghassem Guang Helmut Jac Ruggiero Korhonen Jefferson Ako Langs Gozaliasl Ya and A. Ruggiero and A. Korhonen and E. Jefferson and E. Ako and G. Langs and G. Gozaliasl and Guang Yang and H. Prosch and J. Preller and Jan Stanczuk and Jingjing Tang and J. Hofmanninger and J. Babar and L. E. Sanchez and M. Thillai and Paula Martin Gonzalez and P. Teare and Xiaoxiang Zhu and Mishal N. Patel and Conor Cafolla and H. Azadbakht and Joseph Jacob and Josh Lowe and Kang Zhang and Kyle Bradley and Marcel Wassin and Markus Holzer and Kangyu Ji and Maria Delgado Ortet and T. Ai and N. Walton and P. Li\u00f2 and S. Stranks and Tolou Shadbahr and Weizhe Lin and Y. Zha and Zhangming Niu and J. H. Rudd and E. Sala and C. Sch\u00f6nlieb},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {199 - 217},\n title = {Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans},\n volume = {3},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1e701665e73faa648cb15473952576f40e8e122",
            "@type": "ScholarlyArticle",
            "paperId": "d1e701665e73faa648cb15473952576f40e8e122",
            "corpusId": 216232243,
            "url": "https://www.semanticscholar.org/paper/d1e701665e73faa648cb15473952576f40e8e122",
            "title": "The Machine\u2010Learning Approach",
            "venue": "Machine Learning for iOS Developers",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DOI": "10.1002/9781119602927.ch2",
                "CorpusId": 216232243
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 552,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://cbio.ensmp.fr/~jvert/svn/bibli/local/Zhou2004Recognizing.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-02-20",
            "journal": {
                "name": "Machine Learning for iOS Developers",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{None,\n booktitle = {Machine Learning for iOS Developers},\n journal = {Machine Learning for iOS Developers},\n title = {The Machine\u2010Learning Approach},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:82266f6103bade9005ec555ed06ba20b5210ff22",
            "@type": "ScholarlyArticle",
            "paperId": "82266f6103bade9005ec555ed06ba20b5210ff22",
            "corpusId": 262910797,
            "url": "https://www.semanticscholar.org/paper/82266f6103bade9005ec555ed06ba20b5210ff22",
            "title": "Gaussian processes for machine learning",
            "venue": "Adaptive computation and machine learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2997654710",
                "DBLP": "books/lib/RasmussenW06",
                "DOI": "10.7551/mitpress/3206.001.0001",
                "CorpusId": 262910797
            },
            "abstract": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics.The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.",
            "referenceCount": 178,
            "citationCount": 3761,
            "influentialCitationCount": 536,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://mlg.eng.cam.ac.uk/pub/pdf/Ras04.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-11-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Rasmussen2005GaussianPF,\n author = {Carl E. Rasmussen and Christopher K. I. Williams},\n booktitle = {Adaptive computation and machine learning},\n pages = {I-XVIII, 1-248},\n title = {Gaussian processes for machine learning},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:db0cc2f21b20cbc0ab8946090967399c25709614",
            "@type": "ScholarlyArticle",
            "paperId": "db0cc2f21b20cbc0ab8946090967399c25709614",
            "corpusId": 3833774,
            "url": "https://www.semanticscholar.org/paper/db0cc2f21b20cbc0ab8946090967399c25709614",
            "title": "Practical Secure Aggregation for Privacy-Preserving Machine Learning",
            "venue": "IACR Cryptology ePrint Archive",
            "publicationVenue": {
                "id": "urn:research:166fd2b5-a928-4a98-a449-3b90935cc101",
                "name": "IACR Cryptology ePrint Archive",
                "alternate_names": [
                    "IACR Cryptol eprint Arch"
                ],
                "issn": null,
                "url": "http://eprint.iacr.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949130532",
                "DBLP": "journals/iacr/BonawitzIKMMPRS17",
                "DOI": "10.1145/3133956.3133982",
                "CorpusId": 3833774
            },
            "abstract": "We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers $1.73 x communication expansion for 210 users and 220-dimensional vectors, and 1.98 x expansion for 214 users and 224-dimensional vectors over sending data in the clear.",
            "referenceCount": 64,
            "citationCount": 2052,
            "influentialCitationCount": 295,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=3133982&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2017-10-30",
            "journal": {
                "name": "Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bonawitz2017PracticalSA,\n author = {Keith Bonawitz and Vladimir Ivanov and Ben Kreuter and Antonio Marcedone and H. B. McMahan and Sarvar Patel and Daniel Ramage and Aaron Segal and Karn Seth},\n booktitle = {IACR Cryptology ePrint Archive},\n journal = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},\n title = {Practical Secure Aggregation for Privacy-Preserving Machine Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:739769f4862753fc80057194456d758d2a148ee3",
            "@type": "ScholarlyArticle",
            "paperId": "739769f4862753fc80057194456d758d2a148ee3",
            "corpusId": 15037168,
            "url": "https://www.semanticscholar.org/paper/739769f4862753fc80057194456d758d2a148ee3",
            "title": "Extreme Learning Machine for Regression and Multiclass Classification",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2026131661",
                "DBLP": "journals/tsmc/HuangZDZ12",
                "DOI": "10.1109/TSMCB.2011.2168604",
                "CorpusId": 15037168,
                "PubMed": "21984515"
            },
            "abstract": "Due to the simplicity of their implementations, least square support vector machine (LS-SVM) and proximal support vector machine (PSVM) have been widely used in binary classification applications. The conventional LS-SVM and PSVM cannot be used in regression and multiclass classification applications directly, although variants of LS-SVM and PSVM have been proposed to handle such cases. This paper shows that both LS-SVM and PSVM can be simplified further and a unified learning framework of LS-SVM, PSVM, and other regularization algorithms referred to extreme learning machine (ELM) can be built. ELM works for the \u201cgeneralized\u201d single-hidden-layer feedforward networks (SLFNs), but the hidden layer (or called feature mapping) in ELM need not be tuned. Such SLFNs include but are not limited to SVM, polynomial network, and the conventional feedforward neural networks. This paper shows the following: 1) ELM provides a unified learning platform with a widespread type of feature mappings and can be applied in regression and multiclass classification applications directly; 2) from the optimization method point of view, ELM has milder optimization constraints compared to LS-SVM and PSVM; 3) in theory, compared to ELM, LS-SVM and PSVM achieve suboptimal solutions and require higher computational complexity; and 4) in theory, ELM can approximate any target continuous function and classify any disjoint regions. As verified by the simulation results, ELM tends to have better scalability and achieve similar (for regression and binary class cases) or much better (for multiclass cases) generalization performance at much faster learning speed (up to thousands times) than traditional SVM and LS-SVM.",
            "referenceCount": 61,
            "citationCount": 4896,
            "influentialCitationCount": 513,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ntu.edu.sg/home/egbhuang/pdf/ELM-Unified-Learning.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-04-01",
            "journal": {
                "name": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2012ExtremeLM,\n author = {G. Huang and Hongming Zhou and Xiaojian Ding and Rui Zhang},\n booktitle = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},\n journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},\n pages = {513-529},\n title = {Extreme Learning Machine for Regression and Multiclass Classification},\n volume = {42},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f75b70c9d7078724b592ec3e21de705e7b6ff73f",
            "@type": "ScholarlyArticle",
            "paperId": "f75b70c9d7078724b592ec3e21de705e7b6ff73f",
            "corpusId": 21698746,
            "url": "https://www.semanticscholar.org/paper/f75b70c9d7078724b592ec3e21de705e7b6ff73f",
            "title": "Double/Debiased Machine Learning for Treatment and Structural Parameters",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2622003161",
                "DOI": "10.1111/ectj.12097",
                "CorpusId": 21698746
            },
            "abstract": "We revisit the classic semiparametric problem of inference on a low dimensional parameter \u03b8_0 in the presence of high-dimensional nuisance parameters \u03b7_0. We depart from the classical setting by allowing for \u03b7_0 to be so high-dimensional that the traditional assumptions, such as Donsker properties, that limit complexity of the parameter space for this object break down. To estimate \u03b7_0, we consider the use of statistical or machine learning (ML) methods which are particularly well-suited to estimation in modern, very high-dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating \u03b7_0 cause a heavy bias in estimators of \u03b8_0 that are obtained by naively plugging ML estimators of \u03b7_0 into estimating equations for \u03b8_0. This bias results in the naive estimator failing to be N^(-1/2) consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest \u03b8_0 can be removed by using two simple, yet critical, ingredients: (1) using Neyman-orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate \u03b8_0, and (2) making use of cross-fitting which provides an efficient form of data-splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in a N^(-1/2)-neighborhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of DML applied to learn the main regression parameter in a partially linear regression model, DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model, DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness, and DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.",
            "referenceCount": 99,
            "citationCount": 1511,
            "influentialCitationCount": 402,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-06-01",
            "journal": {
                "name": "Econometrics: Econometric & Statistical Methods - Special Topics eJournal",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chernozhukov2017DoubleDebiasedML,\n author = {V. Chernozhukov and D. Chetverikov and Mert Demirer and E. Duflo and Christian Hansen and Whitney Newey and J. Robins},\n journal = {Econometrics: Econometric & Statistical Methods - Special Topics eJournal},\n title = {Double/Debiased Machine Learning for Treatment and Structural Parameters},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0273507eb05f1135f3a05f9c7adc9a56f12c7c5c",
            "@type": "ScholarlyArticle",
            "paperId": "0273507eb05f1135f3a05f9c7adc9a56f12c7c5c",
            "corpusId": 199492241,
            "url": "https://www.semanticscholar.org/paper/0273507eb05f1135f3a05f9c7adc9a56f12c7c5c",
            "title": "Recent advances and applications of machine learning in solid-state materials science",
            "venue": "npj Computational Materials",
            "publicationVenue": {
                "id": "urn:research:a7cc9d16-b88e-439c-a9bc-f7d032668c52",
                "name": "npj Computational Materials",
                "alternate_names": [
                    "npj Comput Mater"
                ],
                "issn": "2057-3960",
                "url": "http://www.nature.com/npjcompumats/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2968923792",
                "DOI": "10.1038/s41524-019-0221-0",
                "CorpusId": 199492241
            },
            "abstract": null,
            "referenceCount": 499,
            "citationCount": 1207,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41524-019-0221-0.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-08-08",
            "journal": {
                "name": "npj Computational Materials",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Schmidt2019RecentAA,\n author = {Jonathan Schmidt and M\u00e1rio R. G. Marques and S. Botti and Miguel A. L. Marques},\n booktitle = {npj Computational Materials},\n journal = {npj Computational Materials},\n pages = {1-36},\n title = {Recent advances and applications of machine learning in solid-state materials science},\n volume = {5},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b7a717233ec3ff37385ab1b06816d0ca375f5bb3",
            "@type": "ScholarlyArticle",
            "paperId": "b7a717233ec3ff37385ab1b06816d0ca375f5bb3",
            "corpusId": 102350503,
            "url": "https://www.semanticscholar.org/paper/b7a717233ec3ff37385ab1b06816d0ca375f5bb3",
            "title": "Data Shapley: Equitable Valuation of Data for Machine Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2939984132",
                "ArXiv": "1904.02868",
                "DBLP": "conf/icml/GhorbaniZ19",
                "CorpusId": 102350503
            },
            "abstract": "As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this work, we develop a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on $n$ data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley value uniquely satisfies several natural properties of equitable data valuation. We develop Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. In addition to being equitable, extensive experiments across biomedical, image and synthetic data demonstrate that data Shapley has several other benefits: 1) it is more powerful than the popular leave-one-out or leverage score in providing insight on what data is more valuable for a given learning task; 2) low Shapley value data effectively capture outliers and corruptions; 3) high Shapley value data inform what type of new data to acquire to improve the predictor.",
            "referenceCount": 50,
            "citationCount": 452,
            "influentialCitationCount": 105,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.02868"
            },
            "citationStyles": {
                "bibtex": "@Article{Ghorbani2019DataSE,\n author = {Amirata Ghorbani and James Y. Zou},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Data Shapley: Equitable Valuation of Data for Machine Learning},\n volume = {abs/1904.02868},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f70b2f20be241f445a61f33c4b8e76e554760340",
            "@type": "ScholarlyArticle",
            "paperId": "f70b2f20be241f445a61f33c4b8e76e554760340",
            "corpusId": 88499204,
            "url": "https://www.semanticscholar.org/paper/f70b2f20be241f445a61f33c4b8e76e554760340",
            "title": "Software Engineering for Machine Learning: A Case Study",
            "venue": "2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2922234936",
                "DBLP": "conf/icse/AmershiBBDGKNN019",
                "DOI": "10.1109/ICSE-SEIP.2019.00042",
                "CorpusId": 88499204
            },
            "abstract": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
            "referenceCount": 44,
            "citationCount": 564,
            "influentialCitationCount": 86,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-01",
            "journal": {
                "name": "2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Amershi2019SoftwareEF,\n author = {S. Amershi and Andrew Begel and C. Bird and R. Deline and H. Gall and Ece Kamar and Nachiappan Nagappan and Besmira Nushi and Thomas Zimmermann},\n booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},\n journal = {2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},\n pages = {291-300},\n title = {Software Engineering for Machine Learning: A Case Study},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:71a85e735a3686bef8cce3725ae5ba82e2cabb1b",
            "@type": "ScholarlyArticle",
            "paperId": "71a85e735a3686bef8cce3725ae5ba82e2cabb1b",
            "corpusId": 226278105,
            "url": "https://www.semanticscholar.org/paper/71a85e735a3686bef8cce3725ae5ba82e2cabb1b",
            "title": "Underspecification Presents Challenges for Credibility in Modern Machine Learning",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2011-03395",
                "MAG": "3100511085",
                "ArXiv": "2011.03395",
                "CorpusId": 226278105
            },
            "abstract": "ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.",
            "referenceCount": 149,
            "citationCount": 501,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-11-06",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{D'Amour2020UnderspecificationPC,\n author = {A. D'Amour and K. Heller and D. Moldovan and Ben Adlam and B. Alipanahi and Alex Beutel and Christina Chen and Jonathan Deaton and Jacob Eisenstein and M. Hoffman and F. Hormozdiari and N. Houlsby and Shaobo Hou and Ghassen Jerfel and A. Karthikesalingam and Mario Lucic and Yi-An Ma and C. McLean and Diana Mincu and A. Mitani and A. Montanari and Zachary Nado and Vivek Natarajan and Christopher Nielson and T. Osborne and R. Raman and K. Ramasamy and R. Sayres and J. Schrouff and Martin G. Seneviratne and Shannon Sequeira and Harini Suresh and Victor Veitch and Max Vladymyrov and Xuezhi Wang and Kellie Webster and Steve Yadlowsky and T. Yun and Xiaohua Zhai and D. Sculley},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {226:1-226:61},\n title = {Underspecification Presents Challenges for Credibility in Modern Machine Learning},\n volume = {23},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e5d2f2dc01b150dffc163a9f457848e9b5b5c38",
            "@type": "ScholarlyArticle",
            "paperId": "2e5d2f2dc01b150dffc163a9f457848e9b5b5c38",
            "corpusId": 220919678,
            "url": "https://www.semanticscholar.org/paper/2e5d2f2dc01b150dffc163a9f457848e9b5b5c38",
            "title": "On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2007.15745",
                "DBLP": "journals/ijon/YangS20",
                "MAG": "3045004532",
                "DOI": "10.1016/j.neucom.2020.07.061",
                "CorpusId": 220919678
            },
            "abstract": null,
            "referenceCount": 131,
            "citationCount": 841,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2007.15745",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-07-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2007.15745"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2020OnHO,\n author = {Li Yang and A. Shami},\n booktitle = {Neurocomputing},\n journal = {ArXiv},\n title = {On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice},\n volume = {abs/2007.15745},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6e23398447a022fb9495c44fa80e9de593a574bc",
            "@type": "ScholarlyArticle",
            "paperId": "6e23398447a022fb9495c44fa80e9de593a574bc",
            "corpusId": 52010796,
            "url": "https://www.semanticscholar.org/paper/6e23398447a022fb9495c44fa80e9de593a574bc",
            "title": "Machine Learning in Agriculture: A Review",
            "venue": "Italian National Conference on Sensors",
            "publicationVenue": {
                "id": "urn:research:3dbf084c-ef47-4b74-9919-047b40704538",
                "name": "Italian National Conference on Sensors",
                "alternate_names": [
                    "SENSORS",
                    "IEEE Sens",
                    "Ital National Conf Sens",
                    "IEEE Sensors",
                    "Sensors"
                ],
                "issn": "1424-8220",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "6111295",
                "DBLP": "journals/sensors/LiakosBMPB18",
                "MAG": "2885770726",
                "DOI": "10.3390/s18082674",
                "CorpusId": 52010796,
                "PubMed": "30110960"
            },
            "abstract": "Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.",
            "referenceCount": 119,
            "citationCount": 1291,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-08-01",
            "journal": {
                "name": "Sensors (Basel, Switzerland)",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Liakos2018MachineLI,\n author = {Konstantinos G. Liakos and P. Busato and D. Moshou and S. Pearson and D. Bochtis},\n booktitle = {Italian National Conference on Sensors},\n journal = {Sensors (Basel, Switzerland)},\n title = {Machine Learning in Agriculture: A Review},\n volume = {18},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4a7eea3ec3080ecb277bfe466afce4822a1071d7",
            "@type": "ScholarlyArticle",
            "paperId": "4a7eea3ec3080ecb277bfe466afce4822a1071d7",
            "corpusId": 210164391,
            "url": "https://www.semanticscholar.org/paper/4a7eea3ec3080ecb277bfe466afce4822a1071d7",
            "title": "Quantum embeddings for machine learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2001.03622",
                "MAG": "2998932335",
                "CorpusId": 210164391
            },
            "abstract": "Quantum classifiers are trainable quantum circuits used as machine learning models. The first part of the circuit implements a quantum feature map that encodes classical inputs into quantum states, embedding the data in a high-dimensional Hilbert space; the second part of the circuit executes a quantum measurement interpreted as the output of the model. Usually, the measurement is trained to distinguish quantum-embedded data. We propose to instead train the first part of the circuit---the embedding---with the objective of maximally separating data classes in Hilbert space, a strategy we call quantum metric learning. As a result, the measurement minimizing a linear classification loss is already known and depends on the metric used: for embeddings separating data using the l1 or trace distance, this is the Helstrom measurement, while for the l2 or Hilbert-Schmidt distance, it is a simple overlap measurement. This approach provides a powerful analytic framework for quantum machine learning and eliminates a major component in current models, freeing up more precious resources to best leverage the capabilities of near-term quantum information processors.",
            "referenceCount": 22,
            "citationCount": 232,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-01-10",
            "journal": {
                "name": "arXiv: Quantum Physics",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Lloyd2020QuantumEF,\n author = {S. Lloyd and M. Schuld and Aroosa Ijaz and J. Izaac and N. Killoran},\n journal = {arXiv: Quantum Physics},\n title = {Quantum embeddings for machine learning},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bc43977fb11cceed0b9aa55b23c6dd29dd9a132",
            "@type": "ScholarlyArticle",
            "paperId": "6bc43977fb11cceed0b9aa55b23c6dd29dd9a132",
            "corpusId": 8312711,
            "url": "https://www.semanticscholar.org/paper/6bc43977fb11cceed0b9aa55b23c6dd29dd9a132",
            "title": "Correlation-based Feature Selection for Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1495061682",
                "CorpusId": 8312711
            },
            "abstract": "A central problem in machine learning is identifying a representative set of features from which to construct a classification model for a particular task. This thesis addresses the problem of feature selection for machine learning through a correlation based approach. The central hypothesis is that good feature sets contain features that are highly correlated with the class, yet uncorrelated with each other. A feature evaluation formula, based on ideas from test theory, provides an operational definition of this hypothesis. CFS (Correlation based Feature Selection) is an algorithm that couples this evaluation formula with an appropriate correlation measure and a heuristic search strategy. CFS was evaluated by experiments on artificial and natural datasets. Three machine learning algorithms were used: C4.5 (a decision tree learner), IB1 (an instance based learner), and naive Bayes. Experiments on artificial datasets showed that CFS quickly identifies and screens irrelevant, redundant, and noisy features, and identifies relevant features as long as their relevance does not strongly depend on other features. On natural domains, CFS typically eliminated well over half the features. In most cases, classification accuracy using the reduced feature set equaled or bettered accuracy using the complete feature set. Feature selection degraded machine learning performance in cases where some features were eliminated which were highly predictive of very small areas of the instance space. Further experiments compared CFS with a wrapper\u2014a well known approach to feature selection that employs the target learning algorithm to evaluate feature sets. In many cases CFS gave comparable results to the wrapper, and in general, outperformed the wrapper on small datasets. CFS executes many times faster than the wrapper, which allows it to scale to larger datasets. Two methods of extending CFS to handle feature interaction are presented and experimentally evaluated. The first considers pairs of features and the second incorporates iii feature weights calculated by the RELIEF algorithm. Experiments on artificial domains showed that both methods were able to identify interacting features. On natural domains, the pairwise method gave more reliable results than using weights provided by RELIEF.",
            "referenceCount": 108,
            "citationCount": 3818,
            "influentialCitationCount": 456,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hall2003CorrelationbasedFS,\n author = {M. Hall},\n title = {Correlation-based Feature Selection for Machine Learning},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:218062f45c15f39bc8f4fb2c930ddf20b5809b11",
            "@type": "ScholarlyArticle",
            "paperId": "218062f45c15f39bc8f4fb2c930ddf20b5809b11",
            "corpusId": 195657970,
            "url": "https://www.semanticscholar.org/paper/218062f45c15f39bc8f4fb2c930ddf20b5809b11",
            "title": "Machine Learning Testing: Survey, Landscapes and Horizons",
            "venue": "IEEE Transactions on Software Engineering",
            "publicationVenue": {
                "id": "urn:research:c99cfe66-b71c-4ca4-bedd-26267b9cb068",
                "name": "IEEE Transactions on Software Engineering",
                "alternate_names": [
                    "IEEE Trans Softw Eng"
                ],
                "issn": "0098-5589",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=32"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.10742",
                "DBLP": "journals/tse/ZhangHML22",
                "MAG": "2954855426",
                "DOI": "10.1109/tse.2019.2962027",
                "CorpusId": 195657970
            },
            "abstract": "This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.",
            "referenceCount": 280,
            "citationCount": 536,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.10742",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-19",
            "journal": {
                "name": "IEEE Transactions on Software Engineering",
                "volume": "48"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2019MachineLT,\n author = {J Zhang and M. Harman and Lei Ma and Yang Liu},\n booktitle = {IEEE Transactions on Software Engineering},\n journal = {IEEE Transactions on Software Engineering},\n pages = {1-36},\n title = {Machine Learning Testing: Survey, Landscapes and Horizons},\n volume = {48},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:206261db1196e4e391ca42077f6fca6b3ece34d0",
            "@type": "ScholarlyArticle",
            "paperId": "206261db1196e4e391ca42077f6fca6b3ece34d0",
            "corpusId": 203610177,
            "url": "https://www.semanticscholar.org/paper/206261db1196e4e391ca42077f6fca6b3ece34d0",
            "title": "The Non-IID Data Quagmire of Decentralized Machine Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1910.00189",
                "MAG": "3034713518",
                "DBLP": "journals/corr/abs-1910-00189",
                "CorpusId": 203610177
            },
            "abstract": "Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across devices/locations. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization; and (iii) the degree of data skew is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the accuracy loss of batch normalization.",
            "referenceCount": 71,
            "citationCount": 384,
            "influentialCitationCount": 43,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-10-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1910.00189"
            },
            "citationStyles": {
                "bibtex": "@Article{Hsieh2019TheND,\n author = {Kevin Hsieh and Amar Phanishayee and O. Mutlu and Phillip B. Gibbons},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {The Non-IID Data Quagmire of Decentralized Machine Learning},\n volume = {abs/1910.00189},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9cbbef8f4426329d0687025b34287c35bdd8b38",
            "@type": "ScholarlyArticle",
            "paperId": "a9cbbef8f4426329d0687025b34287c35bdd8b38",
            "corpusId": 85517132,
            "url": "https://www.semanticscholar.org/paper/a9cbbef8f4426329d0687025b34287c35bdd8b38",
            "title": "Machine learning and the physical sciences",
            "venue": "Reviews of Modern Physics",
            "publicationVenue": {
                "id": "urn:research:8558aef1-7952-4eac-8e2c-e095c1a741a0",
                "name": "Reviews of Modern Physics",
                "alternate_names": [
                    "Rev Mod Phys"
                ],
                "issn": "0034-6861",
                "url": "https://journals.aps.org/rmp/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2923537029",
                "ArXiv": "1903.10563",
                "DOI": "10.1103/RevModPhys.91.045002",
                "CorpusId": 85517132
            },
            "abstract": "Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges.",
            "referenceCount": 427,
            "citationCount": 1145,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1903.10563",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-03-25",
            "journal": {
                "name": "Reviews of Modern Physics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Carleo2019MachineLA,\n author = {Giuseppe Carleo and I. Cirac and Kyle Cranmer and L. Daudet and M. Schuld and Naftali Tishby and Leslie Vogt-Maranto and Lenka Zdeborov'a},\n booktitle = {Reviews of Modern Physics},\n journal = {Reviews of Modern Physics},\n title = {Machine learning and the physical sciences},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d7701e78e0bfc92b03a89582e80cfb751ac03f26",
            "@type": "ScholarlyArticle",
            "paperId": "d7701e78e0bfc92b03a89582e80cfb751ac03f26",
            "corpusId": 59600034,
            "url": "https://www.semanticscholar.org/paper/d7701e78e0bfc92b03a89582e80cfb751ac03f26",
            "title": "Explaining Explanations: An Overview of Interpretability of Machine Learning",
            "venue": "International Conference on Data Science and Advanced Analytics",
            "publicationVenue": {
                "id": "urn:research:770f1d88-52c2-43dc-a897-6881e70b2f32",
                "name": "International Conference on Data Science and Advanced Analytics",
                "alternate_names": [
                    "Int Conf Data Sci Adv Anal",
                    "IEEE International Conference on Data Science and Advanced Analytics",
                    "IEEE Int Conf Data Sci Adv Anal",
                    "DSAA"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2953315354",
                "ArXiv": "1806.00069",
                "DBLP": "conf/dsaa/GilpinBYBSK18",
                "DOI": "10.1109/DSAA.2018.00018",
                "CorpusId": 59600034
            },
            "abstract": "There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.",
            "referenceCount": 92,
            "citationCount": 1409,
            "influentialCitationCount": 73,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1806.00069",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2018-05-31",
            "journal": {
                "name": "2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gilpin2018ExplainingEA,\n author = {Leilani H. Gilpin and David Bau and Ben Z. Yuan and Ayesha Bajwa and Michael A. Specter and Lalana Kagal},\n booktitle = {International Conference on Data Science and Advanced Analytics},\n journal = {2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)},\n pages = {80-89},\n title = {Explaining Explanations: An Overview of Interpretability of Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2bc3644ce4de7fce5812c1455e056649a47c1bbf",
            "@type": "ScholarlyArticle",
            "paperId": "2bc3644ce4de7fce5812c1455e056649a47c1bbf",
            "corpusId": 195775136,
            "url": "https://www.semanticscholar.org/paper/2bc3644ce4de7fce5812c1455e056649a47c1bbf",
            "title": "Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/access/MohanTS19",
                "MAG": "2949767632",
                "DOI": "10.1109/ACCESS.2019.2923707",
                "CorpusId": 195775136
            },
            "abstract": "Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).",
            "referenceCount": 46,
            "citationCount": 715,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08740989.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-19",
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohan2019EffectiveHD,\n author = {Senthilkumar Mohan and Chandrasegar Thirumalai and Gautam Srivastava},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {81542-81554},\n title = {Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:638e41912f314c74436205aa8d332dca963ab1dc",
            "@type": "ScholarlyArticle",
            "paperId": "638e41912f314c74436205aa8d332dca963ab1dc",
            "corpusId": 189999815,
            "url": "https://www.semanticscholar.org/paper/638e41912f314c74436205aa8d332dca963ab1dc",
            "title": "Parameterized quantum circuits as machine learning models",
            "venue": "Quantum Science and Technology",
            "publicationVenue": {
                "id": "urn:research:8eb00c73-e022-4bd6-b48b-1d3b2ccf107d",
                "name": "Quantum Science and Technology",
                "alternate_names": [
                    "Quantum Sci Technol"
                ],
                "issn": "2364-9062",
                "url": "https://iopscience.iop.org/2058-9565"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2980446414",
                "ArXiv": "1906.07682",
                "DBLP": "journals/corr/abs-1906-07682",
                "DOI": "10.1088/2058-9565/ab4eb5",
                "CorpusId": 189999815
            },
            "abstract": "Hybrid quantum\u2013classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.",
            "referenceCount": 124,
            "citationCount": 569,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5/pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-18",
            "journal": {
                "name": "Quantum Science and Technology",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Benedetti2019ParameterizedQC,\n author = {Marcello Benedetti and Erika Lloyd and Stefan H. Sack and Mattia Fiorentini},\n booktitle = {Quantum Science and Technology},\n journal = {Quantum Science and Technology},\n title = {Parameterized quantum circuits as machine learning models},\n volume = {4},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f1b962fb4070fedd46758e334db3ba4f00ddc3ec",
            "@type": "ScholarlyArticle",
            "paperId": "f1b962fb4070fedd46758e334db3ba4f00ddc3ec",
            "corpusId": 47128183,
            "url": "https://www.semanticscholar.org/paper/f1b962fb4070fedd46758e334db3ba4f00ddc3ec",
            "title": "Supervised Machine Learning: A Review of Classification Techniques",
            "venue": "Informatica",
            "publicationVenue": {
                "id": "urn:research:729a1139-78df-40c0-899b-17b6212e786f",
                "name": "Informatica",
                "alternate_names": [
                    "Inform (lithuanian Acad Sci",
                    "Informatica (lithuanian Academy of Sciences)"
                ],
                "issn": "0868-4952",
                "url": "http://content.iospress.com/journals/informatica"
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "journals/informaticaSI/Kotsiantis07",
                "MAG": "2295155158",
                "CorpusId": 47128183
            },
            "abstract": "The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various supervised machine learning classification techniques. Of course, a single chapter cannot be a complete review of all supervised machine learning classification algorithms (also known induction classification algorithms), yet we hope that the references cited will cover the major theoretical issues, guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored.",
            "referenceCount": 163,
            "citationCount": 4506,
            "influentialCitationCount": 259,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2007-06-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kotsiantis2007SupervisedML,\n author = {S. Kotsiantis},\n booktitle = {Informatica},\n pages = {3-24},\n title = {Supervised Machine Learning: A Review of Classification Techniques},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b9518627db25f05930e931f56497602363a75491",
            "@type": "ScholarlyArticle",
            "paperId": "b9518627db25f05930e931f56497602363a75491",
            "corpusId": 204755862,
            "url": "https://www.semanticscholar.org/paper/b9518627db25f05930e931f56497602363a75491",
            "title": "Definitions, methods, and applications in interpretable machine learning",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1901.04592",
                "MAG": "2910705748",
                "DBLP": "journals/corr/abs-1901-04592",
                "DOI": "10.1073/pnas.1900654116",
                "CorpusId": 204755862,
                "PubMed": "31619572"
            },
            "abstract": "Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.",
            "referenceCount": 112,
            "citationCount": 976,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/116/44/22071.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-01-14",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "116"
            },
            "citationStyles": {
                "bibtex": "@Article{Murdoch2019DefinitionsMA,\n author = {W. James Murdoch and Chandan Singh and Karl Kumbier and R. Abbasi-Asl and Bin Yu},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {22071 - 22080},\n title = {Definitions, methods, and applications in interpretable machine learning},\n volume = {116},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff8eea01cbb5de505672cf9bbda3a6a91624cf52",
            "@type": "ScholarlyArticle",
            "paperId": "ff8eea01cbb5de505672cf9bbda3a6a91624cf52",
            "corpusId": 25062002,
            "url": "https://www.semanticscholar.org/paper/ff8eea01cbb5de505672cf9bbda3a6a91624cf52",
            "title": "Quantum Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2791140209",
                "CorpusId": 25062002
            },
            "abstract": null,
            "referenceCount": 1,
            "citationCount": 1302,
            "influentialCitationCount": 51,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-03-07",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Schuld2018QuantumML,\n author = {M. Schuld and Francesco Petruccione},\n title = {Quantum Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e",
            "@type": "ScholarlyArticle",
            "paperId": "8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e",
            "corpusId": 173990571,
            "url": "https://www.semanticscholar.org/paper/8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e",
            "title": "Evaluating Differentially Private Machine Learning in Practice",
            "venue": "USENIX Security Symposium",
            "publicationVenue": {
                "id": "urn:research:54649c1d-6bcc-4232-9cd1-aa446867b8d0",
                "name": "USENIX Security Symposium",
                "alternate_names": [
                    "USENIX Secur Symp"
                ],
                "issn": null,
                "url": "http://www.usenix.org/events/bytopic/security.html"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2947693768",
                "DBLP": "conf/uss/Jayaraman019",
                "CorpusId": 173990571
            },
            "abstract": "Differential privacy is a strong notion for privacy that can be used to prove formal guarantees, in terms of a privacy budget, $\\epsilon$, about how much information is leaked by a mechanism. However, implementations of privacy-preserving machine learning often select large values of $\\epsilon$ in order to get acceptable utility of the model, with little understanding of the impact of such choices on meaningful privacy. Moreover, in scenarios where iterative learning procedures are used, differential privacy variants that offer tighter analyses are used which appear to reduce the needed privacy budget but present poorly understood trade-offs between privacy and utility. In this paper, we quantify the impact of these choices on privacy in experiments with logistic regression and neural network models. Our main finding is that there is a huge gap between the upper bounds on privacy loss that can be guaranteed, even with advanced mechanisms, and the effective privacy loss that can be measured using current inference attacks. Current mechanisms for differentially private machine learning rarely offer acceptable utility-privacy trade-offs with guarantees for complex learning tasks: settings that provide limited accuracy loss provide meaningless privacy guarantees, and settings that provide strong privacy guarantees result in useless models. Code for the experiments can be found here: this https URL",
            "referenceCount": 88,
            "citationCount": 381,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-02-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jayaraman2019EvaluatingDP,\n author = {Bargav Jayaraman and David E. Evans},\n booktitle = {USENIX Security Symposium},\n pages = {1895-1912},\n title = {Evaluating Differentially Private Machine Learning in Practice},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "@type": "ScholarlyArticle",
            "paperId": "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "corpusId": 11605311,
            "url": "https://www.semanticscholar.org/paper/2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "title": "SecureML: A System for Scalable Privacy-Preserving Machine Learning",
            "venue": "IEEE Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:29b9c461-963e-4d11-b2ab-92c182243942",
                "name": "IEEE Symposium on Security and Privacy",
                "alternate_names": [
                    "S&P",
                    "IEEE Symp Secur Priv"
                ],
                "issn": null,
                "url": "http://www.ieee-security.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/sp/MohasselZ17",
                "MAG": "2952489823",
                "DOI": "10.1109/SP.2017.12",
                "CorpusId": 11605311
            },
            "abstract": "Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.",
            "referenceCount": 42,
            "citationCount": 1369,
            "influentialCitationCount": 251,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-22",
            "journal": {
                "name": "2017 IEEE Symposium on Security and Privacy (SP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mohassel2017SecureMLAS,\n author = {Payman Mohassel and Yupeng Zhang},\n booktitle = {IEEE Symposium on Security and Privacy},\n journal = {2017 IEEE Symposium on Security and Privacy (SP)},\n pages = {19-38},\n title = {SecureML: A System for Scalable Privacy-Preserving Machine Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f156ecbbb9243522275490d698c6825f4d2e01af",
            "@type": "ScholarlyArticle",
            "paperId": "f156ecbbb9243522275490d698c6825f4d2e01af",
            "corpusId": 229722844,
            "url": "https://www.semanticscholar.org/paper/f156ecbbb9243522275490d698c6825f4d2e01af",
            "title": "Explainable AI: A Review of Machine Learning Interpretability Methods",
            "venue": "Entropy",
            "publicationVenue": {
                "id": "urn:research:8270cfe1-3713-4325-a7bd-c6a87eed889e",
                "name": "Entropy",
                "alternate_names": null,
                "issn": "1099-4300",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-155606"
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "7824368",
                "DBLP": "journals/entropy/LinardatosPK21",
                "DOI": "10.3390/e23010018",
                "CorpusId": 229722844,
                "PubMed": "33375658"
            },
            "abstract": "Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into \u201cblack box\u201d approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.",
            "referenceCount": 166,
            "citationCount": 933,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-12-25",
            "journal": {
                "name": "Entropy",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Linardatos2020ExplainableAA,\n author = {Pantelis Linardatos and Vasilis Papastefanopoulos and S. Kotsiantis},\n booktitle = {Entropy},\n journal = {Entropy},\n title = {Explainable AI: A Review of Machine Learning Interpretability Methods},\n volume = {23},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0fcd8359aa964a118adf10dd524a90d61e10048b",
            "@type": "ScholarlyArticle",
            "paperId": "0fcd8359aa964a118adf10dd524a90d61e10048b",
            "corpusId": 160011452,
            "url": "https://www.semanticscholar.org/paper/0fcd8359aa964a118adf10dd524a90d61e10048b",
            "title": "Auto-sklearn: Efficient and Robust Automated Machine Learning",
            "venue": "Automated Machine Learning",
            "publicationVenue": {
                "id": "urn:research:a688800a-ab93-4531-9258-c10e1b6ddf68",
                "name": "Automated Machine Learning",
                "alternate_names": [
                    "Automation and Machine Learning",
                    "Autom Mach Learn"
                ],
                "issn": "2520-131X",
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "books/sp/19/FeurerKES0H19",
                "MAG": "2945790622",
                "DOI": "10.1007/978-3-030-05318-5_6",
                "CorpusId": 160011452
            },
            "abstract": null,
            "referenceCount": 46,
            "citationCount": 278,
            "influentialCitationCount": 39,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-05318-5_6.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Feurer2019AutosklearnEA,\n author = {Matthias Feurer and Aaron Klein and Katharina Eggensperger and J. T. Springenberg and Manuel Blum and F. Hutter},\n booktitle = {Automated Machine Learning},\n pages = {113-134},\n title = {Auto-sklearn: Efficient and Robust Automated Machine Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:48ddd9101a90fe65e3061de69626741b843ff5e4",
            "@type": "ScholarlyArticle",
            "paperId": "48ddd9101a90fe65e3061de69626741b843ff5e4",
            "corpusId": 13806304,
            "url": "https://www.semanticscholar.org/paper/48ddd9101a90fe65e3061de69626741b843ff5e4",
            "title": "The use of the area under the ROC curve in the evaluation of machine learning algorithms",
            "venue": "Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:266f640f-003e-453b-ab76-57e4053252f8",
                "name": "Pattern Recognition",
                "alternate_names": [
                    "Pattern Recognit"
                ],
                "issn": "0031-3203",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "2771514092",
                "DBLP": "journals/pr/Bradley97",
                "DOI": "10.1016/S0031-3203(96)00142-2",
                "CorpusId": 13806304
            },
            "abstract": null,
            "referenceCount": 45,
            "citationCount": 5837,
            "influentialCitationCount": 693,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://eprints.qut.edu.au/180272/1/114256.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-07-01",
            "journal": {
                "name": "Pattern Recognit.",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Bradley1997TheUO,\n author = {A. Bradley},\n booktitle = {Pattern Recognition},\n journal = {Pattern Recognit.},\n pages = {1145-1159},\n title = {The use of the area under the ROC curve in the evaluation of machine learning algorithms},\n volume = {30},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91",
            "@type": "ScholarlyArticle",
            "paperId": "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91",
            "corpusId": 10137425,
            "url": "https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91",
            "title": "Multimodal Machine Learning: A Survey and Taxonomy",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1705.09406",
                "DBLP": "journals/pami/BaltrusaitisAM19",
                "MAG": "2951127645",
                "DOI": "10.1109/TPAMI.2018.2798607",
                "CorpusId": 10137425,
                "PubMed": "29994351"
            },
            "abstract": "Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.",
            "referenceCount": 271,
            "citationCount": 1965,
            "influentialCitationCount": 133,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1705.09406",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-05-26",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Baltru\u0161aitis2017MultimodalML,\n author = {T. Baltru\u0161aitis and Chaitanya Ahuja and Louis-Philippe Morency},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {423-443},\n title = {Multimodal Machine Learning: A Survey and Taxonomy},\n volume = {41},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a0456c27cdd58f197032c1c8b4f304f09d4c9bc5",
            "@type": "ScholarlyArticle",
            "paperId": "a0456c27cdd58f197032c1c8b4f304f09d4c9bc5",
            "corpusId": 56776745,
            "url": "https://www.semanticscholar.org/paper/a0456c27cdd58f197032c1c8b4f304f09d4c9bc5",
            "title": "Ensemble Methods in Machine Learning",
            "venue": "International Workshop on Multiple Classifier Systems",
            "publicationVenue": {
                "id": "urn:research:98ecd781-2903-4ed9-a7e6-f50b599e1b6f",
                "name": "International Workshop on Multiple Classifier Systems",
                "alternate_names": [
                    "Mult Classif Syst",
                    "Multiple Classifier Systems",
                    "Int Workshop Mult Classif Syst",
                    "Mobile Cloud Computing & Services",
                    "MCS",
                    "Int Conf Mult Classif Syst",
                    "Mob Cloud Comput  Serv",
                    "International Conference on Multiple Classifier Systems"
                ],
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "1534477342",
                "DBLP": "conf/mcs/Dietterich00",
                "DOI": "10.1007/3-540-45014-9_1",
                "CorpusId": 56776745
            },
            "abstract": null,
            "referenceCount": 34,
            "citationCount": 6953,
            "influentialCitationCount": 305,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://web.engr.oregonstate.edu/%7Etgd/publications/mcs-ensembles.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2000-06-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dietterich2000EnsembleMI,\n author = {Thomas G. Dietterich},\n booktitle = {International Workshop on Multiple Classifier Systems},\n pages = {1-15},\n title = {Ensemble Methods in Machine Learning},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a39e6a8a4b18baf8bb77952cbe631ec5f3b09daa",
            "@type": "ScholarlyArticle",
            "paperId": "a39e6a8a4b18baf8bb77952cbe631ec5f3b09daa",
            "corpusId": 249256702,
            "url": "https://www.semanticscholar.org/paper/a39e6a8a4b18baf8bb77952cbe631ec5f3b09daa",
            "title": "Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.47715/jpc.b.82.2022.9789391303372",
                "CorpusId": 249256702
            },
            "abstract": "Since the beginning of the Industrial Revolution, machines have made great strides. They continue to be a common sight on factory floors and in manufacturing plants, but their capabilities have evolved to the point where they can now perform cognitive tasks in addition to the manual labour that was previously the exclusive domain of humans. There are many specific complex tasks that machines are now capable of simulating, such as judging music competitions, driving automobiles, and playing chess with professional players. Other examples include mopping the floor with professional chess players. However, studies on the planned automation of jobs and predictions about the future development of machines and artificial intelligence (AI) should be read with a healthy dose of skepticism. The development of AI technology is accelerating, but widespread implementation is still in its infancy and faces a number of known and unknown obstacles. There will inevitably be snags, holdups, and other hurdles. The concept of machine learning is also not as straightforward as turning a switch and then asking the computer to make you a tasty martini while predicting the winner of the Super Bowl. In the realm of problem-solving, machine learning is not even close to being a \"out-of-the-box\" option. Skilled personnel, also known as data scientists and machine learning engineers, are responsible for managing and supervising the statistical algorithms that are the basis for the operation of machines. In this particular labour market, the number of available jobs is expected to increase in the future, but the supply is now having trouble keeping up with demand. The lack of an adequate supply of professionals who possess the necessary expertise and training is one of the most significant obstacles that is delaying the progress of artificial intelligence, according to industry experts who lament this fact. This book focuses on the high-level basics of machine learning as well as the mathematical and statistical underpinnings of creating machine learning models. The book is written as per the common University syllabus compiled from Indian Universities to facilitate the B.E., B.Tech., MSc., and MCA students. Keywords: Machine Learning, Artificial Intelligence",
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2022-05-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Rameshbabu2022MachineL,\n author = {V. Rameshbabu and C. Vijayakumaran and P. B. Edwin Prabhakar},\n title = {Machine Learning},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5fca8bbec714e403fa0f95a56b355c8ca835bcc0",
            "@type": "ScholarlyArticle",
            "paperId": "5fca8bbec714e403fa0f95a56b355c8ca835bcc0",
            "corpusId": 226964842,
            "url": "https://www.semanticscholar.org/paper/5fca8bbec714e403fa0f95a56b355c8ca835bcc0",
            "title": "A Survey on the Explainability of Supervised Machine Learning",
            "venue": "Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:aef12dca-60a0-4ca3-819b-cad26d309d4e",
                "name": "Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "JAIR",
                    "J Artif Intell Res",
                    "The Journal of Artificial Intelligence Research"
                ],
                "issn": "1076-9757",
                "url": "http://www.jair.org/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2011-07876",
                "ArXiv": "2011.07876",
                "MAG": "3101981467",
                "DOI": "10.1613/jair.1.12228",
                "CorpusId": 226964842
            },
            "abstract": "Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions.",
            "referenceCount": 271,
            "citationCount": 441,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jair.org/index.php/jair/article/download/12228/26647",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-11-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2011.07876"
            },
            "citationStyles": {
                "bibtex": "@Article{Burkart2020ASO,\n author = {Nadia Burkart and Marco F. Huber},\n booktitle = {Journal of Artificial Intelligence Research},\n journal = {ArXiv},\n title = {A Survey on the Explainability of Supervised Machine Learning},\n volume = {abs/2011.07876},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e67121cd31e95fba6c892724e619323ad7564b03",
            "@type": "ScholarlyArticle",
            "paperId": "e67121cd31e95fba6c892724e619323ad7564b03",
            "corpusId": 191166260,
            "url": "https://www.semanticscholar.org/paper/e67121cd31e95fba6c892724e619323ad7564b03",
            "title": "A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning",
            "venue": "Archives of Computational Methods in Engineering",
            "publicationVenue": {
                "id": "urn:research:f9c1272f-e8c2-4e8c-bdae-fc9c2bb2cb85",
                "name": "Archives of Computational Methods in Engineering",
                "alternate_names": [
                    "Arch Comput Method Eng"
                ],
                "issn": "1134-3060",
                "url": "http://www.cimne.com/arcme/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "2947411064",
                "DOI": "10.1007/S11831-019-09344-W",
                "CorpusId": 191166260
            },
            "abstract": null,
            "referenceCount": 81,
            "citationCount": 525,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-09-01",
            "journal": {
                "name": "Archives of Computational Methods in Engineering",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Dargan2020ASO,\n author = {Shaveta Dargan and Munish Kumar and M. Ayyagari and G. Kumar},\n booktitle = {Archives of Computational Methods in Engineering},\n journal = {Archives of Computational Methods in Engineering},\n pages = {1-22},\n title = {A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning},\n year = {2020}\n}\n"
            }
        }
    }
]