[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:46f74231b9afeb0c290d6d550043c55045284e5f",
            "@type": "ScholarlyArticle",
            "paperId": "46f74231b9afeb0c290d6d550043c55045284e5f",
            "corpusId": 5280072,
            "url": "https://www.semanticscholar.org/paper/46f74231b9afeb0c290d6d550043c55045284e5f",
            "title": "The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2182396527",
                "DBLP": "journals/spm/Deng12",
                "DOI": "10.1109/MSP.2012.2211477",
                "CorpusId": 5280072
            },
            "abstract": "In this issue, \u201cBest of the Web\u201d presents the modified National Institute of Standards and Technology (MNIST) resources, consisting of a collection of handwritten digit images used extensively in optical character recognition and machine learning research.",
            "referenceCount": 7,
            "citationCount": 2732,
            "influentialCitationCount": 561,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-10-18",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2012TheMD,\n author = {L. Deng},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n pages = {141-142},\n title = {The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]},\n volume = {29},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5cae4598b1de79fb5a26d92fcb0435bf2a20691e",
            "@type": "ScholarlyArticle",
            "paperId": "5cae4598b1de79fb5a26d92fcb0435bf2a20691e",
            "corpusId": 222341615,
            "url": "https://www.semanticscholar.org/paper/5cae4598b1de79fb5a26d92fcb0435bf2a20691e",
            "title": "Machine Learning Force Fields",
            "venue": "Chemical Reviews",
            "publicationVenue": {
                "id": "urn:research:f458795b-af97-4b7c-ba4e-d57bbb57f90a",
                "name": "Chemical Reviews",
                "alternate_names": [
                    "Chem Rev"
                ],
                "issn": "0009-2665",
                "url": "https://pubs.acs.org/journal/chreay"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2010.07067",
                "PubMedCentral": "8391964",
                "MAG": "3093149769",
                "DOI": "10.1021/acs.chemrev.0c01111",
                "CorpusId": 222341615,
                "PubMed": "33705118"
            },
            "abstract": "In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.",
            "referenceCount": 328,
            "citationCount": 435,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://orbilu.uni.lu/bitstream/10993/49416/1/acs.chemrev.0c01111.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Physics",
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-10-14",
            "journal": {
                "name": "Chemical Reviews",
                "volume": "121"
            },
            "citationStyles": {
                "bibtex": "@Article{Unke2020MachineLF,\n author = {Oliver T. Unke and Stefan Chmiela and H. E. Sauceda and M. Gastegger and I. Poltavsky and Kristof T. Sch\u00fctt and A. Tkatchenko and K. M\u00fcller},\n booktitle = {Chemical Reviews},\n journal = {Chemical Reviews},\n pages = {10142 - 10186},\n title = {Machine Learning Force Fields},\n volume = {121},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5c7e5248d9eb7f373f10277410bf8506160907ea",
            "@type": "ScholarlyArticle",
            "paperId": "5c7e5248d9eb7f373f10277410bf8506160907ea",
            "corpusId": 13753997,
            "url": "https://www.semanticscholar.org/paper/5c7e5248d9eb7f373f10277410bf8506160907ea",
            "title": "All-optical machine learning using diffractive deep neural networks",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2798701005",
                "ArXiv": "1804.08711",
                "DBLP": "journals/corr/abs-1804-08711",
                "DOI": "10.1126/science.aat8084",
                "CorpusId": 13753997,
                "PubMed": "30049787"
            },
            "abstract": "All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science, this issue p. 1004 All-optical deep learning can be implemented with 3D-printed passive optical components. Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning\u2013based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.",
            "referenceCount": 55,
            "citationCount": 1069,
            "influentialCitationCount": 52,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.science.org/cms/asset/e0345a34-e2a8-46ff-81d8-e68e47e223c6/pap.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-14",
            "journal": {
                "name": "Science",
                "volume": "361"
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2018AllopticalML,\n author = {Xing Lin and Y. Rivenson and N. Yardimci and Muhammed Veli and Yilin Luo and M. Jarrahi and A. Ozcan},\n booktitle = {Science},\n journal = {Science},\n pages = {1004 - 1008},\n title = {All-optical machine learning using diffractive deep neural networks},\n volume = {361},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09e85ad84c4ed40461340ac1bd5fadbd2a5b2340",
            "@type": "ScholarlyArticle",
            "paperId": "09e85ad84c4ed40461340ac1bd5fadbd2a5b2340",
            "corpusId": 212657607,
            "url": "https://www.semanticscholar.org/paper/09e85ad84c4ed40461340ac1bd5fadbd2a5b2340",
            "title": "Integrating Physics-Based Modeling with Machine Learning: A Survey",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3010993481",
                "DBLP": "journals/corr/abs-2003-04919",
                "CorpusId": 212657607
            },
            "abstract": "In this manuscript, we provide a structured and comprehensive overview of techniques to integrate machine learning with physics-based modeling. First, we provide a summary of application areas for which these approaches have been applied. Then, we describe classes of methodologies used to construct physics-guided machine learning models and hybrid physics-machine learning frameworks from a machine learning standpoint. With this foundation, we then provide a systematic organization of these existing techniques and discuss ideas for future research.",
            "referenceCount": 323,
            "citationCount": 277,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-03-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2003.04919"
            },
            "citationStyles": {
                "bibtex": "@Article{Willard2020IntegratingPM,\n author = {J. Willard and X. Jia and Shaoming Xu and M. Steinbach and Vipin Kumar},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Integrating Physics-Based Modeling with Machine Learning: A Survey},\n volume = {abs/2003.04919},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80c3c1cb86eeb9f2ab0934d6f914918889d34db7",
            "@type": "ScholarlyArticle",
            "paperId": "80c3c1cb86eeb9f2ab0934d6f914918889d34db7",
            "corpusId": 226440756,
            "url": "https://www.semanticscholar.org/paper/80c3c1cb86eeb9f2ab0934d6f914918889d34db7",
            "title": "Tslearn, A Machine Learning Toolkit for Time Series Data",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/jmlr/TavenardFVDAHPY20",
                "MAG": "3039352388",
                "CorpusId": 226440756
            },
            "abstract": "tslearn is a general-purpose Python machine learning library for time series that offers tools for pre-processing and feature extraction as well as dedicated models for clustering, classification and regression. It follows scikit-learn's Application Programming Interface for transformers and estimators, allowing the use of standard pipelines and model selection tools on top of tslearn objects. It is distributed under the BSD-2-Clause license, and its source code is available at https://github.com/tslearn-team/tslearn.",
            "referenceCount": 23,
            "citationCount": 241,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Tavenard2020TslearnAM,\n author = {R. Tavenard and Johann Faouzi and Gilles Vandewiele and Felix Divo and Guillaume Androz and Chester Holtz and Marie Payne and R. Yurchak and M. Ru\u00dfwurm and Kushal Kolar and E. Woods},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {118:1-118:6},\n title = {Tslearn, A Machine Learning Toolkit for Time Series Data},\n volume = {21},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:86788a38467e1f2f1df713f5d5694bfee9f8ae29",
            "@type": "ScholarlyArticle",
            "paperId": "86788a38467e1f2f1df713f5d5694bfee9f8ae29",
            "corpusId": 215947098,
            "url": "https://www.semanticscholar.org/paper/86788a38467e1f2f1df713f5d5694bfee9f8ae29",
            "title": "Predicting the state of charge and health of batteries using data-driven machine learning",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/natmi/NgZYCS20",
                "MAG": "3009652674",
                "DOI": "10.1038/s42256-020-0156-7",
                "CorpusId": 215947098
            },
            "abstract": null,
            "referenceCount": 129,
            "citationCount": 279,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.repository.cam.ac.uk/bitstream/1810/308657/1/Batter004.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-03-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Ng2020PredictingTS,\n author = {M. Ng and Jin Zhao and Qingyu Yan and G. Conduit and Z. Seh},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {161-170},\n title = {Predicting the state of charge and health of batteries using data-driven machine learning},\n volume = {2},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
            "@type": "ScholarlyArticle",
            "paperId": "6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
            "corpusId": 216022295,
            "url": "https://www.semanticscholar.org/paper/6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
            "title": "Introduction to Machine Learning, Neural Networks, and Deep Learning",
            "venue": "Translational Vision Science & Technology",
            "publicationVenue": {
                "id": "urn:research:faac363d-9835-4bf0-a7a6-38b1a494b1aa",
                "name": "Translational Vision Science & Technology",
                "alternate_names": [
                    "Transl Vis Sci  Technol"
                ],
                "issn": "2164-2591",
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "7347027",
                "MAG": "3009207988",
                "DOI": "10.1167/tvst.9.2.14",
                "CorpusId": 216022295,
                "PubMed": "32704420"
            },
            "abstract": "Purpose To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning. Methods A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology. Results A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background. Conclusions Artificial intelligence has a promising future in medicine; however, many challenges remain. Translational Relevance The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.",
            "referenceCount": 34,
            "citationCount": 225,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-01-28",
            "journal": {
                "name": "Translational Vision Science & Technology",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Choi2020IntroductionTM,\n author = {Rene Y. Choi and Aaron S. Coyner and Jayashree Kalpathy-Cramer and M. Chiang and J. Campbell},\n booktitle = {Translational Vision Science & Technology},\n journal = {Translational Vision Science & Technology},\n title = {Introduction to Machine Learning, Neural Networks, and Deep Learning},\n volume = {9},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e331bf7887e2e634bf5b12788849d2d2b74bc7f",
            "@type": "ScholarlyArticle",
            "paperId": "5e331bf7887e2e634bf5b12788849d2d2b74bc7f",
            "corpusId": 214693121,
            "url": "https://www.semanticscholar.org/paper/5e331bf7887e2e634bf5b12788849d2d2b74bc7f",
            "title": "Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2003.12206",
                "DBLP": "journals/corr/abs-2003-12206",
                "MAG": "3013688454",
                "CorpusId": 214693121
            },
            "abstract": "One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.",
            "referenceCount": 44,
            "citationCount": 226,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-03-27",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Pineau2020ImprovingRI,\n author = {Joelle Pineau and Philippe Vincent-Lamarre and Koustuv Sinha and V. Larivi\u00e8re and A. Beygelzimer and Florence d'Alch\u00e9-Buc and E. Fox and H. Larochelle},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {164:1-164:20},\n title = {Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)},\n volume = {22},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:caf9e0fa2c340fb07cef8d547ea8849508e5c358",
            "@type": "ScholarlyArticle",
            "paperId": "caf9e0fa2c340fb07cef8d547ea8849508e5c358",
            "corpusId": 88482625,
            "url": "https://www.semanticscholar.org/paper/caf9e0fa2c340fb07cef8d547ea8849508e5c358",
            "title": "Empirical Asset Pricing Via Machine Learning",
            "venue": "The Review of financial studies",
            "publicationVenue": {
                "id": "urn:research:5dc79bde-acf4-4b60-b7ad-5bb769def869",
                "name": "The Review of financial studies",
                "alternate_names": [
                    "Rev Financial Stud",
                    "Review of Financial Studies",
                    "Rev financial stud"
                ],
                "issn": "0893-9454",
                "url": "https://www.jstor.org/journal/revifinastud"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3121664121",
                "DOI": "10.2139/ssrn.3159577",
                "CorpusId": 88482625
            },
            "abstract": "\n We perform a comparative analysis of machine learning methods for the canonical problem of empirical asset pricing: measuring asset risk premiums. We demonstrate large economic gains to investors using machine learning forecasts, in some cases doubling the performance of leading regression-based strategies from the literature. We identify the best-performing methods (trees and neural networks) and trace their predictive gains to allowing nonlinear predictor interactions missed by other methods. All methods agree on the same set of dominant predictive signals, a set that includes variations on momentum, liquidity, and volatility.\n Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.",
            "referenceCount": 125,
            "citationCount": 998,
            "influentialCitationCount": 115,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/rfs/article-pdf/33/5/2223/33209812/hhaa009.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Economics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-12-01",
            "journal": {
                "name": "NBER Working Paper Series",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gu2018EmpiricalAP,\n author = {Shihao Gu and B. Kelly and D. Xiu},\n booktitle = {The Review of financial studies},\n journal = {NBER Working Paper Series},\n title = {Empirical Asset Pricing Via Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291",
            "@type": "ScholarlyArticle",
            "paperId": "6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291",
            "corpusId": 226847956,
            "url": "https://www.semanticscholar.org/paper/6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291",
            "title": "Advancing Biosensors with Machine Learning.",
            "venue": "ACS Sensors",
            "publicationVenue": {
                "id": "urn:research:3d6827a9-8d5b-489b-ba8e-fb372b6e52e3",
                "name": "ACS Sensors",
                "alternate_names": [
                    "AC Sens"
                ],
                "issn": "2379-3694",
                "url": "https://pubs.acs.org/journal/ascefj"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3100709371",
                "DOI": "10.1021/acssensors.0c01424",
                "CorpusId": 226847956,
                "PubMed": "33185417"
            },
            "abstract": "Chemometrics play a critical role in biosensors-based detection, analysis, and diagnosis. Nowadays, as a branch of artificial intelligence (AI), machine learning (ML) have achieved impressive advances. However, novel advanced ML methods, especially deep learning, which is famous for image analysis, facial recognition, and speech recognition, has remained relatively elusive to the biosensor community. Herein, how ML can be beneficial to biosensors is systematically discussed. The advantages and drawbacks of most popular ML algorithms are summarized on the basis of sensing data analysis. Specially, deep learning methods such as convolutional neural network (CNN) and recurrent neural network (RNN) are emphasized. Diverse ML-assisted electrochemical biosensors, wearable electronics, SERS and other spectra-based biosensors, fluorescence biosensors and colorimetric biosensors are comprehensively discussed. Furthermore, biosensor networks and multibiosensor data fusion are introduced. This review will nicely bridge ML with biosensors, and greatly expand chemometrics for detection, analysis, and diagnosis.",
            "referenceCount": 136,
            "citationCount": 217,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-11-13",
            "journal": {
                "name": "ACS sensors",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cui2020AdvancingBW,\n author = {Feiyun Cui and Yun Yue and Yi Zhang and Ziming Zhang and H. S. Zhou},\n booktitle = {ACS Sensors},\n journal = {ACS sensors},\n title = {Advancing Biosensors with Machine Learning.},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c0bc4ef587b4cbebd5839baeed95274fbf26c43a",
            "@type": "ScholarlyArticle",
            "paperId": "c0bc4ef587b4cbebd5839baeed95274fbf26c43a",
            "corpusId": 220540790,
            "url": "https://www.semanticscholar.org/paper/c0bc4ef587b4cbebd5839baeed95274fbf26c43a",
            "title": "Applications of machine learning to diagnosis and treatment of neurodegenerative diseases",
            "venue": "Nature Reviews Neurology",
            "publicationVenue": {
                "id": "urn:research:acdcc82c-368c-442a-92e8-0a2913177701",
                "name": "Nature Reviews Neurology",
                "alternate_names": [
                    "Nat Rev Neurol"
                ],
                "issn": "1759-4758",
                "url": "http://www.nature.com/ncpneuro/index.html"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3043374725",
                "DOI": "10.1038/s41582-020-0377-8",
                "CorpusId": 220540790,
                "PubMed": "32669685"
            },
            "abstract": null,
            "referenceCount": 236,
            "citationCount": 215,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://eprints.whiterose.ac.uk/163905/1/41582_2020_377_Author%20%281%29.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-07-15",
            "journal": {
                "name": "Nature Reviews Neurology",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Myszczynska2020ApplicationsOM,\n author = {Monika A. Myszczynska and P. Ojamies and A. Lacoste and Daniel Neil and Amir Saffari and R. Mead and Guillaume M. Hautbergue and J. Holbrook and L. Ferraiuolo},\n booktitle = {Nature Reviews Neurology},\n journal = {Nature Reviews Neurology},\n pages = {440 - 456},\n title = {Applications of machine learning to diagnosis and treatment of neurodegenerative diseases},\n volume = {16},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:46c266b3d1274dacd7fce27ee8cb4d587f087a58",
            "@type": "ScholarlyArticle",
            "paperId": "46c266b3d1274dacd7fce27ee8cb4d587f087a58",
            "corpusId": 199659548,
            "url": "https://www.semanticscholar.org/paper/46c266b3d1274dacd7fce27ee8cb4d587f087a58",
            "title": "Machine Learning Interpretability: A Survey on Methods and Metrics",
            "venue": "Electronics",
            "publicationVenue": {
                "id": "urn:research:ccd8e532-73c6-414f-bc91-271bbb2933e2",
                "name": "Electronics",
                "alternate_names": null,
                "issn": "1450-5843",
                "url": "http://www.electronics.etfbl.net/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2964303497",
                "DOI": "10.3390/ELECTRONICS8080832",
                "CorpusId": 199659548
            },
            "abstract": "Machine learning systems are becoming increasingly ubiquitous. These systems\u2019s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.",
            "referenceCount": 141,
            "citationCount": 821,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-07-26",
            "journal": {
                "name": "Electronics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Carvalho2019MachineLI,\n author = {D. V. Carvalho and E. M. Pereira and Jaime S. Cardoso},\n booktitle = {Electronics},\n journal = {Electronics},\n title = {Machine Learning Interpretability: A Survey on Methods and Metrics},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5904cd5dbf73b8d5ff13517de490c292d877ee0",
            "@type": "ScholarlyArticle",
            "paperId": "b5904cd5dbf73b8d5ff13517de490c292d877ee0",
            "corpusId": 108292630,
            "url": "https://www.semanticscholar.org/paper/b5904cd5dbf73b8d5ff13517de490c292d877ee0",
            "title": "Applications of machine learning in drug discovery and development",
            "venue": "Nature reviews. Drug discovery",
            "publicationVenue": {
                "id": "urn:research:8a257033-ea67-4623-90da-49cbbe0d6e5b",
                "name": "Nature reviews. Drug discovery",
                "alternate_names": [
                    "Nat rev Drug discov",
                    "Nat Rev Drug Discov",
                    "Nature Reviews Drug Discovery"
                ],
                "issn": "1474-1776",
                "url": "https://www.nature.com/nrd/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2937307539",
                "DOI": "10.1038/s41573-019-0024-5",
                "CorpusId": 108292630,
                "PubMed": "30976107"
            },
            "abstract": null,
            "referenceCount": 120,
            "citationCount": 1130,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6552674?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-04-11",
            "journal": {
                "name": "Nature Reviews Drug Discovery",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Vamathevan2019ApplicationsOM,\n author = {J. Vamathevan and Dominic Clark and P. Czodrowski and I. Dunham and Edgardo Ferran and George Lee and Bin Li and A. Madabhushi and Parantu K. Shah and M. Spitzer and Shanrong Zhao},\n booktitle = {Nature reviews. Drug discovery},\n journal = {Nature Reviews Drug Discovery},\n pages = {463 - 477},\n title = {Applications of machine learning in drug discovery and development},\n volume = {18},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21dfbc88b21b27fe8a245ab1df98edd45f655ae7",
            "@type": "ScholarlyArticle",
            "paperId": "21dfbc88b21b27fe8a245ab1df98edd45f655ae7",
            "corpusId": 92996321,
            "url": "https://www.semanticscholar.org/paper/21dfbc88b21b27fe8a245ab1df98edd45f655ae7",
            "title": "Machine Learning in Medicine",
            "venue": "New England Journal of Medicine",
            "publicationVenue": {
                "id": "urn:research:dc31f077-7737-4e33-baa3-bceeff44ec27",
                "name": "New England Journal of Medicine",
                "alternate_names": [
                    "n engl J Med",
                    "The New England Journal of Medicine",
                    "N Engl J Med"
                ],
                "issn": "0028-4793",
                "url": "https://www.nejm.org/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2934399013",
                "DOI": "10.1056/NEJMra1814259",
                "CorpusId": 92996321,
                "PubMed": "30943338"
            },
            "abstract": "Machine Learning in Medicine In this view of the future of medicine, patient\u2013provider interactions are informed and supported by massive amounts of data from interactions with similar patients. The...",
            "referenceCount": 89,
            "citationCount": 883,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-04-03",
            "journal": {
                "name": "The New England Journal of Medicine",
                "volume": "380"
            },
            "citationStyles": {
                "bibtex": "@Article{Rajkomar2019MachineLI,\n author = {A. Rajkomar and Jeffrey Dean and I. Kohane},\n booktitle = {New England Journal of Medicine},\n journal = {The New England Journal of Medicine},\n pages = {1347\u20131358},\n title = {Machine Learning in Medicine},\n volume = {380},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d75356e2bf674902a06a14bb55d18ee88af5b4bb",
            "@type": "ScholarlyArticle",
            "paperId": "d75356e2bf674902a06a14bb55d18ee88af5b4bb",
            "corpusId": 85496677,
            "url": "https://www.semanticscholar.org/paper/d75356e2bf674902a06a14bb55d18ee88af5b4bb",
            "title": "Machine Learning Methods That Economists Should Know About",
            "venue": "Annual Review of Economics",
            "publicationVenue": {
                "id": "urn:research:c80ce50a-b28d-47e7-a27c-31a7527e5ad9",
                "name": "Annual Review of Economics",
                "alternate_names": [
                    "Annu Rev Econ"
                ],
                "issn": "1941-1383",
                "url": "https://www.annualreviews.org/journal/economics"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1903.10075",
                "MAG": "2950295835",
                "DOI": "10.1146/ANNUREV-ECONOMICS-080217-053433",
                "CorpusId": 85496677
            },
            "abstract": "We discuss the relevance of the recent machine learning (ML) literature for economics and econometrics. First we discuss the differences in goals, methods, and settings between the ML literature and the traditional econometrics and statistics literatures. Then we discuss some specific methods from the ML literature that we view as important for empirical researchers in economics. These include supervised learning methods for regression and classification, unsupervised learning methods, and matrix completion methods. Finally, we highlight newly developed methods at the intersection of ML and econometrics that typically perform better than either off-the-shelf ML or more traditional econometric methods when applied to particular classes of problems, including causal inference for average treatment effects, optimal policy estimation, and estimation of the counterfactual effect of price changes in consumer choice models.",
            "referenceCount": 145,
            "citationCount": 461,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Economics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-03-24",
            "journal": {
                "name": "Annual Review of Economics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Athey2019MachineLM,\n author = {S. Athey and G. Imbens},\n booktitle = {Annual Review of Economics},\n journal = {Annual Review of Economics},\n title = {Machine Learning Methods That Economists Should Know About},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3ea2d9c8e5ea3b87ace121f0bece71565abc187",
            "@type": "ScholarlyArticle",
            "paperId": "b3ea2d9c8e5ea3b87ace121f0bece71565abc187",
            "corpusId": 204823751,
            "url": "https://www.semanticscholar.org/paper/b3ea2d9c8e5ea3b87ace121f0bece71565abc187",
            "title": "Quantifying the Carbon Emissions of Machine Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1910.09700",
                "MAG": "2981540061",
                "DBLP": "journals/corr/abs-1910-09700",
                "CorpusId": 204823751
            },
            "abstract": "From an environmental standpoint, there are a few crucial aspects of training a neural network that have a major impact on the quantity of carbon that it emits. These factors include: the location of the server used for training and the energy grid that it uses, the length of the training procedure, and even the make and model of hardware on which the training takes place. In order to approximate these emissions, we present our Machine Learning Emissions Calculator, a tool for our community to better understand the environmental impact of training ML models. We accompany this tool with an explanation of the factors cited above, as well as concrete actions that individual practitioners and organizations can take to mitigate their carbon emissions.",
            "referenceCount": 26,
            "citationCount": 392,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1910.09700"
            },
            "citationStyles": {
                "bibtex": "@Article{Lacoste2019QuantifyingTC,\n author = {Alexandre Lacoste and A. Luccioni and V. Schmidt and Thomas Dandres},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Quantifying the Carbon Emissions of Machine Learning},\n volume = {abs/1910.09700},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b631ba962b4403a9c0fd9cce446ef3b1e21ea059",
            "@type": "ScholarlyArticle",
            "paperId": "b631ba962b4403a9c0fd9cce446ef3b1e21ea059",
            "corpusId": 216465307,
            "url": "https://www.semanticscholar.org/paper/b631ba962b4403a9c0fd9cce446ef3b1e21ea059",
            "title": "Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1910.09457",
                "DBLP": "journals/ml/HullermeierW21",
                "MAG": "3014596384",
                "DOI": "10.1007/s10994-021-05946-3",
                "CorpusId": 216465307
            },
            "abstract": null,
            "referenceCount": 125,
            "citationCount": 672,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10994-021-05946-3.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-10-21",
            "journal": {
                "name": "Machine Learning",
                "volume": "110"
            },
            "citationStyles": {
                "bibtex": "@Article{H\u00fcllermeier2019AleatoricAE,\n author = {E. H\u00fcllermeier and W. Waegeman},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {457 - 506},\n title = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},\n volume = {110},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:67df7bf02fe2d618c7c18448c2668a526dc4d423",
            "@type": "ScholarlyArticle",
            "paperId": "67df7bf02fe2d618c7c18448c2668a526dc4d423",
            "corpusId": 89617717,
            "url": "https://www.semanticscholar.org/paper/67df7bf02fe2d618c7c18448c2668a526dc4d423",
            "title": "Machine Learning at Facebook: Understanding Inference at the Edge",
            "venue": "International Symposium on High-Performance Computer Architecture",
            "publicationVenue": {
                "id": "urn:research:b7aa40ac-729b-49d6-9064-4d1a9480e9a9",
                "name": "International Symposium on High-Performance Computer Architecture",
                "alternate_names": [
                    "HPCA",
                    "High Perform Comput Appl",
                    "Int Symp High-performance Comput Archit",
                    "High Performance Computing and Applications"
                ],
                "issn": null,
                "url": "https://web.archive.org/web/*/http://www.hpcaconf.org/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2931743911",
                "DBLP": "conf/hpca/WuBCCCDHIJJLLLQ19",
                "DOI": "10.1109/HPCA.2019.00048",
                "CorpusId": 89617717
            },
            "abstract": "At Facebook, machine learning provides a wide range of capabilities that drive many aspects of user experience including ranking posts, content understanding, object detection and tracking for augmented and virtual reality, speech and text translations. While machine learning models are currently trained on customized datacenter infrastructure, Facebook is working to bring machine learning inference to the edge. By doing so, user experience is improved with reduced latency (inference time) and becomes less dependent on network connectivity. Furthermore, this also enables many more applications of deep learning with important features only made available at the edge. This paper takes a datadriven approach to present the opportunities and design challenges faced by Facebook in order to enable machine learning inference locally on smartphones and other edge platforms.",
            "referenceCount": 74,
            "citationCount": 357,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-26",
            "journal": {
                "name": "2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2019MachineLA,\n author = {Carole-Jean Wu and D. Brooks and Kevin Chen and Douglas Chen and Sy Choudhury and Marat Dukhan and K. Hazelwood and Eldad Isaac and Yangqing Jia and Bill Jia and Tommer Leyvand and Hao Lu and Yang Lu and Lin Qiao and Brandon Reagen and Joe Spisak and Fei Sun and Andrew Tulloch and P\u00e9ter Vajda and Xiaodong Wang and Yanghan Wang and Bram Wasti and Yiming Wu and Ran Xian and S. Yoo and Peizhao Zhang},\n booktitle = {International Symposium on High-Performance Computer Architecture},\n journal = {2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)},\n pages = {331-344},\n title = {Machine Learning at Facebook: Understanding Inference at the Edge},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5123717445799d8137327f4041e8d5a5a2c91379",
            "@type": "ScholarlyArticle",
            "paperId": "5123717445799d8137327f4041e8d5a5a2c91379",
            "corpusId": 219917683,
            "url": "https://www.semanticscholar.org/paper/5123717445799d8137327f4041e8d5a5a2c91379",
            "title": "Secure, privacy-preserving and federated machine learning in medical imaging",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/natmi/KaissisMRB20",
                "MAG": "3033511014",
                "DOI": "10.1038/s42256-020-0186-1",
                "CorpusId": 219917683
            },
            "abstract": null,
            "referenceCount": 77,
            "citationCount": 497,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s42256-020-0186-1.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-06-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Kaissis2020SecurePA,\n author = {Georgios Kaissis and M. Makowski and D. R\u00fcckert and R. Braren},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {305-311},\n title = {Secure, privacy-preserving and federated machine learning in medical imaging},\n volume = {2},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:83e89d56d0d0e1dfd8b52213e6cc2e191aaaf34b",
            "@type": "ScholarlyArticle",
            "paperId": "83e89d56d0d0e1dfd8b52213e6cc2e191aaaf34b",
            "corpusId": 218571031,
            "url": "https://www.semanticscholar.org/paper/83e89d56d0d0e1dfd8b52213e6cc2e191aaaf34b",
            "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2005-03675",
                "MAG": "3022208364",
                "ArXiv": "2005.03675",
                "CorpusId": 218571031
            },
            "abstract": "There has been a surge of recent interest in learning representations for graph-structured data. Graph representation learning methods have generally fallen into three main categories, based on the availability of labeled data. The first, network embedding (such as shallow graph embedding or graph auto-encoders), focuses on learning unsupervised representations of relational structure. The second, graph regularized neural networks, leverages graphs to augment neural network losses with a regularization objective for semi-supervised learning. The third, graph neural networks, aims to learn differentiable functions over discrete topologies with arbitrary structure. However, despite the popularity of these areas there has been surprisingly little work on unifying the three paradigms. Here, we aim to bridge the gap between graph neural networks, network embedding and graph regularization models. We propose a comprehensive taxonomy of representation learning methods for graph-structured data, aiming to unify several disparate bodies of work. Specifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which generalizes popular algorithms for semi-supervised learning on graphs (e.g. GraphSage, Graph Convolutional Networks, Graph Attention Networks), and unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc) into a single consistent approach. To illustrate the generality of this approach, we fit over thirty existing methods into this framework. We believe that this unifying view both provides a solid foundation for understanding the intuition behind these methods, and enables future research in the area.",
            "referenceCount": 173,
            "citationCount": 214,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-05-07",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Chami2020MachineLO,\n author = {Ines Chami and Sami Abu-El-Haija and Bryan Perozzi and Christopher R\u00e9 and K. Murphy},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {89:1-89:64},\n title = {Machine Learning on Graphs: A Model and Comprehensive Taxonomy},\n volume = {23},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d0ab11de3077490c80a08abd0fb8827bac84c454",
            "@type": "ScholarlyArticle",
            "paperId": "d0ab11de3077490c80a08abd0fb8827bac84c454",
            "corpusId": 217680306,
            "url": "https://www.semanticscholar.org/paper/d0ab11de3077490c80a08abd0fb8827bac84c454",
            "title": "MoleculeNet: A Benchmark for Molecular Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949858440",
                "CorpusId": 217680306
            },
            "abstract": "Molecular machine learning has been maturing rapidly over the last few years. Improved methods and the presence of larger datasets have enabled machine learning algorithms to make increasingly accurate predictions about molecular properties. However, algorithmic progress has been limited due to the lack of a standard benchmark to compare the efficacy of proposed methods; most new algorithms are benchmarked on different datasets making it challenging to gauge the quality of proposed methods. This work introduces MoleculeNet, a large scale benchmark for molecular machine learning. MoleculeNet curates multiple public datasets, establishes metrics for evaluation, and offers high quality open-source implementations of multiple previously proposed molecular featurization and learning algorithms (released as part of the DeepChem open source library). MoleculeNet benchmarks demonstrate that learnable representations are powerful tools for molecular machine learning and broadly offer the best performance. However, this result comes with caveats. Learnable representations still struggle to deal with complex tasks under data scarcity and highly imbalanced classification. For quantum mechanical and biophysical datasets, the use of physics-aware featurizations can be more important than choice of particular learning algorithm.",
            "referenceCount": 35,
            "citationCount": 1169,
            "influentialCitationCount": 227,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-03-02",
            "journal": {
                "name": "arXiv: Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2017MoleculeNetAB,\n author = {Zhenqin Wu and Bharath Ramsundar and Evan N. Feinberg and Joseph Gomes and Caleb Geniesse and Aneesh S. Pappu and K. Leswing and V. Pande},\n journal = {arXiv: Learning},\n title = {MoleculeNet: A Benchmark for Molecular Machine Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3de1062d8a462dfdc2938558258f8884abe9f4e",
            "@type": "ScholarlyArticle",
            "paperId": "b3de1062d8a462dfdc2938558258f8884abe9f4e",
            "corpusId": 134296492,
            "url": "https://www.semanticscholar.org/paper/b3de1062d8a462dfdc2938558258f8884abe9f4e",
            "title": "Implementation of machine-learning classification in remote sensing: an applied review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2793927960",
                "DOI": "10.1080/01431161.2018.1433343",
                "CorpusId": 134296492
            },
            "abstract": "ABSTRACT Machine learning offers the potential for effective and efficient classification of remotely sensed imagery. The strengths of machine learning include the capacity to handle data of high dimensionality and to map classes with very complex characteristics. Nevertheless, implementing a machine-learning classification is not straightforward, and the literature provides conflicting advice regarding many key issues. This article therefore provides an overview of machine learning from an applied perspective. We focus on the relatively mature methods of support vector machines, single decision trees (DTs), Random Forests, boosted DTs, artificial neural networks, and k-nearest neighbours (k-NN). Issues considered include the choice of algorithm, training data requirements, user-defined parameter selection and optimization, feature space impacts and reduction, and computational costs. We illustrate these issues through applying machine-learning classification to two publically available remotely sensed data sets.",
            "referenceCount": 115,
            "citationCount": 1000,
            "influentialCitationCount": 56,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-02-02",
            "journal": {
                "name": "International Journal of Remote Sensing",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Maxwell2018ImplementationOM,\n author = {A. Maxwell and T. Warner and Fang Fang},\n journal = {International Journal of Remote Sensing},\n pages = {2784 - 2817},\n title = {Implementation of machine-learning classification in remote sensing: an applied review},\n volume = {39},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7b08c2e69a338e8d0c8444ce081b51caa50b273",
            "@type": "ScholarlyArticle",
            "paperId": "c7b08c2e69a338e8d0c8444ce081b51caa50b273",
            "corpusId": 195584180,
            "url": "https://www.semanticscholar.org/paper/c7b08c2e69a338e8d0c8444ce081b51caa50b273",
            "title": "Monte Carlo Gradient Estimation in Machine Learning",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3082278101",
                "DBLP": "journals/jmlr/MohamedRFM20",
                "ArXiv": "1906.10652",
                "CorpusId": 195584180
            },
            "abstract": "This paper is a broad and accessible survey of the methods we have at our disposal for Monte Carlo gradient estimation in machine learning and across the statistical sciences: the problem of computing the gradient of an expectation of a function with respect to parameters defining the distribution that is integrated; the problem of sensitivity analysis. In machine learning research, this gradient problem lies at the core of many learning problems, in supervised, unsupervised and reinforcement learning. We will generally seek to rewrite such gradients in a form that allows for Monte Carlo estimation, allowing them to be easily and efficiently used and analysed. We explore three strategies--the pathwise, score function, and measure-valued gradient estimators--exploring their historical developments, derivation, and underlying assumptions. We describe their use in other fields, show how they are related and can be combined, and expand on their possible generalisations. Wherever Monte Carlo gradient estimators have been derived and deployed in the past, important advances have followed. A deeper and more widely-held understanding of this problem will lead to further advances, and it is these advances that we wish to support.",
            "referenceCount": 164,
            "citationCount": 291,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-25",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohamed2019MonteCG,\n author = {S. Mohamed and Mihaela Rosca and Michael Figurnov and A. Mnih},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {132:1-132:62},\n title = {Monte Carlo Gradient Estimation in Machine Learning},\n volume = {21},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:53eef24a59b12107e6188e121c85f85fa8a78100",
            "@type": "ScholarlyArticle",
            "paperId": "53eef24a59b12107e6188e121c85f85fa8a78100",
            "corpusId": 81621267,
            "url": "https://www.semanticscholar.org/paper/53eef24a59b12107e6188e121c85f85fa8a78100",
            "title": "Explainable machine-learning predictions for the prevention of hypoxaemia during surgery",
            "venue": "Nature Biomedical Engineering",
            "publicationVenue": {
                "id": "urn:research:5619586e-de5a-4bc3-ac80-04dd8530d80c",
                "name": "Nature Biomedical Engineering",
                "alternate_names": [
                    "Nat Biomed Eng"
                ],
                "issn": "2157-846X",
                "url": "http://www.nature.com/natbiomedeng/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2892741787",
                "PubMedCentral": "6467492",
                "DOI": "10.1038/s41551-018-0304-0",
                "CorpusId": 81621267,
                "PubMed": "31001455"
            },
            "abstract": null,
            "referenceCount": 31,
            "citationCount": 928,
            "influentialCitationCount": 42,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6467492?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-10-01",
            "journal": {
                "name": "Nature biomedical engineering",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Lundberg2018ExplainableMP,\n author = {Scott M. Lundberg and B. Nair and M. Vavilala and M. Horibe and Michael J. Eisses and Trevor L. Adams and D. Liston and Daniel King-Wai Low and Shu-Fang Newman and Jerry H. Kim and Su-In Lee},\n booktitle = {Nature Biomedical Engineering},\n journal = {Nature biomedical engineering},\n pages = {749 - 760},\n title = {Explainable machine-learning predictions for the prevention of hypoxaemia during surgery},\n volume = {2},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:61306b52c2d292928f7cbb2f2ef5711d15a2566c",
            "@type": "ScholarlyArticle",
            "paperId": "61306b52c2d292928f7cbb2f2ef5711d15a2566c",
            "corpusId": 44182124,
            "url": "https://www.semanticscholar.org/paper/61306b52c2d292928f7cbb2f2ef5711d15a2566c",
            "title": "ABY3: A Mixed Protocol Framework for Machine Learning",
            "venue": "IACR Cryptology ePrint Archive",
            "publicationVenue": {
                "id": "urn:research:166fd2b5-a928-4a98-a449-3b90935cc101",
                "name": "IACR Cryptology ePrint Archive",
                "alternate_names": [
                    "IACR Cryptol eprint Arch"
                ],
                "issn": null,
                "url": "http://eprint.iacr.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952362077",
                "DBLP": "journals/iacr/MohasselR18",
                "DOI": "10.1145/3243734.3243760",
                "CorpusId": 44182124
            },
            "abstract": "Machine learning is widely used to produce models for a range of applications and is increasingly offered as a service by major technology companies. However, the required massive data collection raises privacy concerns during both training and prediction stages. In this paper, we design and implement a general framework for privacy-preserving machine learning and use it to obtain new solutions for training linear regression, logistic regression and neural network models. Our protocols are in a three-server model wherein data owners secret share their data among three servers who train and evaluate models on the joint data using three-party computation (3PC). Our main contribution is a new and complete framework ($\\textABY ^3$) for efficiently switching back and forth between arithmetic, binary, and Yao 3PC which is of independent interest. Many of the conversions are based on new techniques that are designed and optimized for the first time in this paper. We also propose new techniques for fixed-point multiplication of shared decimal values that extends beyond the three-party case, and customized protocols for evaluating piecewise polynomial functions. We design variants of each building block that is secure against \\em malicious adversaries who deviate arbitrarily. We implement our system in C++. Our protocols are up to \\em four orders of magnitude faster than the best prior work, hence significantly reducing the gap between privacy-preserving and plaintext training.",
            "referenceCount": 62,
            "citationCount": 512,
            "influentialCitationCount": 94,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2018-10-08",
            "journal": {
                "name": "Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Mohassel2018ABY3AM,\n author = {Payman Mohassel and Peter Rindal},\n booktitle = {IACR Cryptology ePrint Archive},\n journal = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},\n title = {ABY3: A Mixed Protocol Framework for Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:821fde6dc36d1264c765d249d4247ea66daff55f",
            "@type": "ScholarlyArticle",
            "paperId": "821fde6dc36d1264c765d249d4247ea66daff55f",
            "corpusId": 218506587,
            "url": "https://www.semanticscholar.org/paper/821fde6dc36d1264c765d249d4247ea66daff55f",
            "title": "Edge Machine Learning for AI-Enabled IoT Devices: A Review",
            "venue": "Italian National Conference on Sensors",
            "publicationVenue": {
                "id": "urn:research:3dbf084c-ef47-4b74-9919-047b40704538",
                "name": "Italian National Conference on Sensors",
                "alternate_names": [
                    "SENSORS",
                    "IEEE Sens",
                    "Ital National Conf Sens",
                    "IEEE Sensors",
                    "Sensors"
                ],
                "issn": "1424-8220",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/sensors/MerendaPI20",
                "MAG": "3023935494",
                "PubMedCentral": "7273223",
                "DOI": "10.3390/s20092533",
                "CorpusId": 218506587,
                "PubMed": "32365645"
            },
            "abstract": "In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors\u2019 data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning \u201cHello World\u201d.",
            "referenceCount": 190,
            "citationCount": 191,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/1424-8220/20/9/2533/pdf?version=1589338738",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-04-29",
            "journal": {
                "name": "Sensors (Basel, Switzerland)",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Merenda2020EdgeML,\n author = {M. Merenda and Carlo Porcaro and D. Iero},\n booktitle = {Italian National Conference on Sensors},\n journal = {Sensors (Basel, Switzerland)},\n title = {Edge Machine Learning for AI-Enabled IoT Devices: A Review},\n volume = {20},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e3c221ee33f9082d8d47a363ed763d62044b60f6",
            "@type": "ScholarlyArticle",
            "paperId": "e3c221ee33f9082d8d47a363ed763d62044b60f6",
            "corpusId": 219076144,
            "url": "https://www.semanticscholar.org/paper/e3c221ee33f9082d8d47a363ed763d62044b60f6",
            "title": "Introduction to Machine Learning with Python",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3020799383",
                "DOI": "10.1007/978-3-030-36826-5_10",
                "CorpusId": 219076144
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 193,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Cutler2020IntroductionTM,\n author = {Josh Cutler and Matt Dickenson},\n pages = {129-142},\n title = {Introduction to Machine Learning with Python},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b293e4659e20815bcf0b6d31ce46b8bd9437c1fa",
            "@type": "ScholarlyArticle",
            "paperId": "b293e4659e20815bcf0b6d31ce46b8bd9437c1fa",
            "corpusId": 227152059,
            "url": "https://www.semanticscholar.org/paper/b293e4659e20815bcf0b6d31ce46b8bd9437c1fa",
            "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3107001518",
                "ArXiv": "2011.11819",
                "DBLP": "journals/corr/abs-2011-11819",
                "CorpusId": 227152059
            },
            "abstract": "The newly emerged machine learning (e.g. deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning (ML) is still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This paper surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.",
            "referenceCount": 184,
            "citationCount": 192,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Law",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-11-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2011.11819"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2020WhenML,\n author = {B. Liu and Ming Ding and Sina Shaham and W. Rahayu and F. Farokhi and Zihuai Lin},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {When Machine Learning Meets Privacy: A Survey and Outlook},\n volume = {abs/2011.11819},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e",
            "@type": "ScholarlyArticle",
            "paperId": "8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e",
            "corpusId": 2984526,
            "url": "https://www.semanticscholar.org/paper/8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e",
            "title": "Stealing Machine Learning Models via Prediction APIs",
            "venue": "USENIX Security Symposium",
            "publicationVenue": {
                "id": "urn:research:54649c1d-6bcc-4232-9cd1-aa446867b8d0",
                "name": "USENIX Security Symposium",
                "alternate_names": [
                    "USENIX Secur Symp"
                ],
                "issn": null,
                "url": "http://www.usenix.org/events/bytopic/security.html"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2461943168",
                "ArXiv": "1609.02943",
                "DBLP": "conf/uss/TramerZJRR16",
                "CorpusId": 2984526
            },
            "abstract": "Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (\"predictive analytics\") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis. \nThe tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., \"steal\") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.",
            "referenceCount": 66,
            "citationCount": 1423,
            "influentialCitationCount": 155,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-08-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tram\u00e8r2016StealingML,\n author = {Florian Tram\u00e8r and Fan Zhang and A. Juels and M. Reiter and T. Ristenpart},\n booktitle = {USENIX Security Symposium},\n pages = {601-618},\n title = {Stealing Machine Learning Models via Prediction APIs},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e7eb0f93c9550d7336f4bbfad5fe89604295705",
            "@type": "ScholarlyArticle",
            "paperId": "7e7eb0f93c9550d7336f4bbfad5fe89604295705",
            "corpusId": 73432134,
            "url": "https://www.semanticscholar.org/paper/7e7eb0f93c9550d7336f4bbfad5fe89604295705",
            "title": "Quantum Machine Learning in Feature Hilbert Spaces.",
            "venue": "Physical Review Letters",
            "publicationVenue": {
                "id": "urn:research:16c9f9d4-bee1-435d-8c85-22a3deba109d",
                "name": "Physical Review Letters",
                "alternate_names": [
                    "Phys Rev Lett"
                ],
                "issn": "0031-9007",
                "url": "https://journals.aps.org/prl/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1803.07128",
                "MAG": "2792946961",
                "DOI": "10.1103/PhysRevLett.122.040504",
                "CorpusId": 73432134,
                "PubMed": "30768345"
            },
            "abstract": "A basic idea of quantum computing is surprisingly similar to that of kernel methods in machine learning, namely, to efficiently perform computations in an intractably large Hilbert space. In this Letter we explore some theoretical foundations of this link and show how it opens up a new avenue for the design of quantum machine learning algorithms. We interpret the process of encoding inputs in a quantum state as a nonlinear feature map that maps data to quantum Hilbert space. A quantum computer can now analyze the input data in this feature space. Based on this link, we discuss two approaches for building a quantum model for classification. In the first approach, the quantum device estimates inner products of quantum states to compute a classically intractable kernel. The kernel can be fed into any classical kernel method such as a support vector machine. In the second approach, we use a variational quantum circuit as a linear model that classifies data explicitly in Hilbert space. We illustrate these ideas with a feature map based on squeezing in a continuous-variable system, and visualize the working principle with two-dimensional minibenchmark datasets.",
            "referenceCount": 48,
            "citationCount": 756,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1803.07128",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-19",
            "journal": {
                "name": "Physical review letters",
                "volume": "122 4"
            },
            "citationStyles": {
                "bibtex": "@Article{Schuld2018QuantumML,\n author = {M. Schuld and N. Killoran},\n booktitle = {Physical Review Letters},\n journal = {Physical review letters},\n pages = {\n          040504\n        },\n title = {Quantum Machine Learning in Feature Hilbert Spaces.},\n volume = {122 4},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695",
            "@type": "ScholarlyArticle",
            "paperId": "efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695",
            "corpusId": 4551073,
            "url": "https://www.semanticscholar.org/paper/efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695",
            "title": "Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning",
            "venue": "IEEE Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:29b9c461-963e-4d11-b2ab-92c182243942",
                "name": "IEEE Symposium on Security and Privacy",
                "alternate_names": [
                    "S&P",
                    "IEEE Symp Secur Priv"
                ],
                "issn": null,
                "url": "http://www.ieee-security.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2962763344",
                "DBLP": "conf/sp/JagielskiOBLNL18",
                "ArXiv": "1804.00308",
                "DOI": "10.1109/SP.2018.00057",
                "CorpusId": 4551073
            },
            "abstract": "As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",
            "referenceCount": 62,
            "citationCount": 574,
            "influentialCitationCount": 51,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418594.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-01",
            "journal": {
                "name": "2018 IEEE Symposium on Security and Privacy (SP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jagielski2018ManipulatingML,\n author = {Matthew Jagielski and Alina Oprea and B. Biggio and Chang Liu and C. Nita-Rotaru and Bo Li},\n booktitle = {IEEE Symposium on Security and Privacy},\n journal = {2018 IEEE Symposium on Security and Privacy (SP)},\n pages = {19-35},\n title = {Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:528ecb0f88a9ea6110ba309b98cc2f0678f257c9",
            "@type": "ScholarlyArticle",
            "paperId": "528ecb0f88a9ea6110ba309b98cc2f0678f257c9",
            "corpusId": 64259583,
            "url": "https://www.semanticscholar.org/paper/528ecb0f88a9ea6110ba309b98cc2f0678f257c9",
            "title": "Data Mining Practical Machine Learning Tools And Techniques With Java Implementations",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2466512847",
                "CorpusId": 64259583
            },
            "abstract": "Thank you for reading data mining practical machine learning tools and techniques with java implementations. As you may know, people have look hundreds times for their favorite novels like this data mining practical machine learning tools and techniques with java implementations, but end up in infectious downloads. Rather than reading a good book with a cup of tea in the afternoon, instead they juggled with some malicious bugs inside their laptop.",
            "referenceCount": 1,
            "citationCount": 1461,
            "influentialCitationCount": 128,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Abendroth2016DataMP,\n author = {Marcel Abendroth},\n title = {Data Mining Practical Machine Learning Tools And Techniques With Java Implementations},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:219355e8c58b78c409e34677da50b49fb4c1eacd",
            "@type": "ScholarlyArticle",
            "paperId": "219355e8c58b78c409e34677da50b49fb4c1eacd",
            "corpusId": 212634211,
            "url": "https://www.semanticscholar.org/paper/219355e8c58b78c409e34677da50b49fb4c1eacd",
            "title": "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2003.03384",
                "DBLP": "conf/icml/RealLSL20",
                "MAG": "3010604601",
                "CorpusId": 212634211
            },
            "abstract": "Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.",
            "referenceCount": 115,
            "citationCount": 169,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-03-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Real2020AutoMLZeroEM,\n author = {Esteban Real and Chen Liang and David R. So and Quoc V. Le},\n booktitle = {International Conference on Machine Learning},\n pages = {8007-8019},\n title = {AutoML-Zero: Evolving Machine Learning Algorithms From Scratch},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8",
            "@type": "ScholarlyArticle",
            "paperId": "8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8",
            "corpusId": 3726330,
            "url": "https://www.semanticscholar.org/paper/8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8",
            "title": "Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification",
            "venue": "Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2601810315",
                "DBLP": "journals/bioinformatics/Arganda-Carreras17",
                "DOI": "10.1093/bioinformatics/btx180",
                "CorpusId": 3726330,
                "PubMed": "28369169"
            },
            "abstract": "Summary: State\u2010of\u2010the\u2010art light and electron microscopes are capable of acquiring large image datasets, but quantitatively evaluating the data often involves manually annotating structures of interest. This process is time\u2010consuming and often a major bottleneck in the evaluation pipeline. To overcome this problem, we have introduced the Trainable Weka Segmentation (TWS), a machine learning tool that leverages a limited number of manual annotations in order to train a classifier and segment the remaining data automatically. In addition, TWS can provide unsupervised segmentation learning schemes (clustering) and can be customized to employ user\u2010designed image features or classifiers. Availability and Implementation: TWS is distributed as open\u2010source software as part of the Fiji image processing distribution of ImageJ at http://imagej.net/Trainable_Weka_Segmentation. Contact: ignacio.arganda@ehu.eus Supplementary information: Supplementary data are available at Bioinformatics online.",
            "referenceCount": 8,
            "citationCount": 1334,
            "influentialCitationCount": 59,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/bioinformatics/article-pdf/33/15/2424/25157856/btx180.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "Bioinformatics",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Arganda-Carreras2017TrainableWS,\n author = {Ignacio Arganda-Carreras and V. Kaynig and C. Rueden and K. Eliceiri and J. Schindelin and A. Cardona and H. Seung},\n booktitle = {Bioinform.},\n journal = {Bioinformatics},\n pages = {2424\u20132426},\n title = {Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification},\n volume = {33},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ed33896e82cc3810b349cdffc2039f0b8edd82e",
            "@type": "ScholarlyArticle",
            "paperId": "1ed33896e82cc3810b349cdffc2039f0b8edd82e",
            "corpusId": 125608550,
            "url": "https://www.semanticscholar.org/paper/1ed33896e82cc3810b349cdffc2039f0b8edd82e",
            "title": "Deep learning and its applications to machine health monitoring",
            "venue": "Mechanical systems and signal processing",
            "publicationVenue": {
                "id": "urn:research:dc4b3846-1e31-4c19-a196-e8b1d091037f",
                "name": "Mechanical systems and signal processing",
                "alternate_names": [
                    "Mech syst signal process",
                    "Mech Syst Signal Process",
                    "Mechanical Systems and Signal Processing"
                ],
                "issn": "0888-3270",
                "url": "https://www.journals.elsevier.com/mechanical-systems-and-signal-processing"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2810292802",
                "DOI": "10.1016/J.YMSSP.2018.05.050",
                "CorpusId": 125608550
            },
            "abstract": null,
            "referenceCount": 110,
            "citationCount": 1552,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-01-01",
            "journal": {
                "name": "Mechanical Systems and Signal Processing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2019DeepLA,\n author = {Rui Zhao and Ruqiang Yan and Zhenghua Chen and K. Mao and Peng Wang and R. Gao},\n booktitle = {Mechanical systems and signal processing},\n journal = {Mechanical Systems and Signal Processing},\n title = {Deep learning and its applications to machine health monitoring},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9583ac53a19cdf0db81fef6eb0b63e66adbe2324",
            "@type": "ScholarlyArticle",
            "paperId": "9583ac53a19cdf0db81fef6eb0b63e66adbe2324",
            "corpusId": 28527385,
            "url": "https://www.semanticscholar.org/paper/9583ac53a19cdf0db81fef6eb0b63e66adbe2324",
            "title": "Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/nips/BlanchardMGS17",
                "MAG": "2752689052",
                "CorpusId": 28527385
            },
            "abstract": "We study the resilience to Byzantine failures of distributed implementations of Stochastic Gradient Descent (SGD). So far, distributed machine learning frameworks have largely ignored the possibility of failures, especially arbitrary (i.e., Byzantine) ones. Causes of failures include software bugs, network asynchrony, biases in local datasets, as well as attackers trying to compromise the entire system. Assuming a set of n workers, up to f being Byzantine, we ask how resilient can SGD be, without limiting the dimension, nor the size of the parameter space. We first show that no gradient aggregation rule based on a linear combination of the vectors proposed by the workers (i.e, current approaches) tolerates a single Byzantine failure. We then formulate a resilience property of the aggregation rule capturing the basic requirements to guarantee convergence despite f Byzantine workers. We propose Krum, an aggregation rule that satisfies our resilience property, which we argue is the first provably Byzantine-resilient algorithm for distributed SGD. We also report on experimental evaluations of Krum.",
            "referenceCount": 33,
            "citationCount": 1037,
            "influentialCitationCount": 324,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-12-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Blanchard2017MachineLW,\n author = {Peva Blanchard and El Mahdi El Mhamdi and R. Guerraoui and J. Stainer},\n booktitle = {Neural Information Processing Systems},\n pages = {119-129},\n title = {Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:adade3149b2a6177296de352f003471eefa958b8",
            "@type": "ScholarlyArticle",
            "paperId": "adade3149b2a6177296de352f003471eefa958b8",
            "corpusId": 67460253,
            "url": "https://www.semanticscholar.org/paper/adade3149b2a6177296de352f003471eefa958b8",
            "title": "The Impact of Machine Learning on Economics",
            "venue": "The Economics of Artificial Intelligence",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2770958024",
                "DOI": "10.7208/chicago/9780226613475.003.0021",
                "CorpusId": 67460253
            },
            "abstract": "This paper provides an assessment of the early contributions of machine learning to economics, as well as predictions about its future contributions. It begins by briefly overviewing some themes from the literature on machine learning, and then draws some contrasts with traditional approaches to estimating the impact of counterfactual policies in economics. Next, we review some of the initial \u201coff-the-shelf\u201d applications of machine learning to economics, including applications in analyzing text and images. We then describe new types of questions that have been posed surrounding the application of machine learning to policy problems, including \u201cprediction policy problems,\u201d as well as considerations of fairness and manipulability. We present some highlights from the emerging econometric literature combining machine learning and causal inference. Finally, we overview a set of broader predictions about the future impact of machine learning on economics, including its impacts on the nature of collaboration, funding, research tools, and research questions.",
            "referenceCount": 86,
            "citationCount": 361,
            "influentialCitationCount": 47,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-01-10",
            "journal": {
                "name": "The Economics of Artificial Intelligence",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Athey2018TheIO,\n author = {S. Athey},\n booktitle = {The Economics of Artificial Intelligence},\n journal = {The Economics of Artificial Intelligence},\n title = {The Impact of Machine Learning on Economics},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:223846b7b56e250e1b6f521997b4c1b809cc0da7",
            "@type": "ScholarlyArticle",
            "paperId": "223846b7b56e250e1b6f521997b4c1b809cc0da7",
            "corpusId": 234356203,
            "url": "https://www.semanticscholar.org/paper/223846b7b56e250e1b6f521997b4c1b809cc0da7",
            "title": "An open source machine learning framework for efficient and transparent systematic reviews",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2006.12166",
                "MAG": "3128349626",
                "DBLP": "journals/natmi/SchootBSZBWKHHF21",
                "DOI": "10.1038/s42256-020-00287-7",
                "CorpusId": 234356203
            },
            "abstract": null,
            "referenceCount": 74,
            "citationCount": 172,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s42256-020-00287-7.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-06-22",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Schoot2020AnOS,\n author = {R. Schoot and J. D. Bruin and Raoul Schram and Parisa Zahedi and J. D. Boer and F. Weijdema and Bianca Kramer and M. Huijts and M. Hoogerwerf and Gerbrich Ferdinands and Albert Harkema and Joukje Willemsen and Yongchao Ma and Qixiang Fang and Sybren Hindriks and L. Tummers and D. Oberski},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {125 - 133},\n title = {An open source machine learning framework for efficient and transparent systematic reviews},\n volume = {3},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a178a0bdee7549d87402b6c6128c569109128458",
            "@type": "ScholarlyArticle",
            "paperId": "a178a0bdee7549d87402b6c6128c569109128458",
            "corpusId": 227053929,
            "url": "https://www.semanticscholar.org/paper/a178a0bdee7549d87402b6c6128c569109128458",
            "title": "Challenges in Deploying Machine Learning: A Survey of Case Studies",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3104128335",
                "DBLP": "journals/csur/PaleyesUL23",
                "ArXiv": "2011.09926",
                "DOI": "10.1145/3533378",
                "CorpusId": 227053929
            },
            "abstract": "In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.",
            "referenceCount": 178,
            "citationCount": 178,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3533378",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-11-18",
            "journal": {
                "name": "ACM Computing Surveys",
                "volume": "55"
            },
            "citationStyles": {
                "bibtex": "@Article{Paleyes2020ChallengesID,\n author = {Andrei Paleyes and Raoul-Gabriel Urma and Neil D. Lawrence},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys},\n pages = {1 - 29},\n title = {Challenges in Deploying Machine Learning: A Survey of Case Studies},\n volume = {55},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:78aa018ee7d52360e15d103390ea1cdb3a0beb41",
            "@type": "ScholarlyArticle",
            "paperId": "78aa018ee7d52360e15d103390ea1cdb3a0beb41",
            "corpusId": 17362994,
            "url": "https://www.semanticscholar.org/paper/78aa018ee7d52360e15d103390ea1cdb3a0beb41",
            "title": "Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/PapernotMG16",
                "ArXiv": "1605.07277",
                "MAG": "2408141691",
                "CorpusId": 17362994
            },
            "abstract": "Many machine learning models are vulnerable to adversarial examples: inputs that are specially crafted to cause a machine learning model to produce an incorrect output. Adversarial examples that affect one model often affect another model, even if the two models have different architectures or were trained on different training sets, so long as both models were trained to perform the same task. An attacker may therefore train their own substitute model, craft adversarial examples against the substitute, and transfer them to a victim model, with very little information about the victim. Recent work has further developed a technique that uses the victim model as an oracle to label a synthetic training set for the substitute, so the attacker need not even collect a training set to mount the attack. We extend these recent techniques using reservoir sampling to greatly enhance the efficiency of the training procedure for the substitute model. We introduce new transferability attacks between previously unexplored (substitute, victim) pairs of machine learning model classes, most notably SVMs and decision trees. We demonstrate our attacks on two commercial machine learning classification systems from Amazon (96.19% misclassification rate) and Google (88.94%) using only 800 queries of the victim model, thereby showing that existing machine learning approaches are in general vulnerable to systematic black-box attacks regardless of their structure.",
            "referenceCount": 26,
            "citationCount": 1507,
            "influentialCitationCount": 114,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.07277"
            },
            "citationStyles": {
                "bibtex": "@Article{Papernot2016TransferabilityIM,\n author = {Nicolas Papernot and P. Mcdaniel and I. Goodfellow},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples},\n volume = {abs/1605.07277},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9909975dec989fcd55d99533c712c28bab99040e",
            "@type": "ScholarlyArticle",
            "paperId": "9909975dec989fcd55d99533c712c28bab99040e",
            "corpusId": 214355969,
            "url": "https://www.semanticscholar.org/paper/9909975dec989fcd55d99533c712c28bab99040e",
            "title": "Machine learning for active matter",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/natmi/CichosGMV20",
                "MAG": "3006249533",
                "DOI": "10.1038/s42256-020-0146-9",
                "CorpusId": 214355969
            },
            "abstract": null,
            "referenceCount": 115,
            "citationCount": 141,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-02-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Cichos2020MachineLF,\n author = {F. Cichos and K. Gustavsson and B. Mehlig and G. Volpe},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {94-103},\n title = {Machine learning for active matter},\n volume = {2},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:88a97c8ef539589c55a6fe869c243792e470d6a3",
            "@type": "ScholarlyArticle",
            "paperId": "88a97c8ef539589c55a6fe869c243792e470d6a3",
            "corpusId": 3541031,
            "url": "https://www.semanticscholar.org/paper/88a97c8ef539589c55a6fe869c243792e470d6a3",
            "title": "Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective",
            "venue": "International Symposium on High-Performance Computer Architecture",
            "publicationVenue": {
                "id": "urn:research:b7aa40ac-729b-49d6-9064-4d1a9480e9a9",
                "name": "International Symposium on High-Performance Computer Architecture",
                "alternate_names": [
                    "HPCA",
                    "High Perform Comput Appl",
                    "Int Symp High-performance Comput Archit",
                    "High Performance Computing and Applications"
                ],
                "issn": null,
                "url": "https://web.archive.org/web/*/http://www.hpcaconf.org/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/hpca/HazelwoodBBCDDF18",
                "MAG": "2794670651",
                "DOI": "10.1109/HPCA.2018.00059",
                "CorpusId": 3541031
            },
            "abstract": "Machine learning sits at the core of many essential products and services at Facebook. This paper describes the hardware and software infrastructure that supports machine learning at global scale. Facebook's machine learning workloads are extremely diverse: services require many different types of models in practice. This diversity has implications at all layers in the system stack. In addition, a sizable fraction of all data stored at Facebook flows through machine learning pipelines, presenting significant challenges in delivering data to high-performance distributed training flows. Computational requirements are also intense, leveraging both GPU and CPU platforms for training and abundant CPU capacity for real-time inference. Addressing these and other emerging challenges continues to require diverse efforts that span machine learning algorithms, software, and hardware design.",
            "referenceCount": 17,
            "citationCount": 492,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hazelwood2018AppliedML,\n author = {K. Hazelwood and Sarah Bird and D. Brooks and Soumith Chintala and Utku Diril and Dmytro Dzhulgakov and Mohamed Fawzy and Bill Jia and Yangqing Jia and Aditya Kalro and James Law and Kevin Lee and Jason Lu and P. Noordhuis and M. Smelyanskiy and Liang Xiong and Xiaodong Wang},\n booktitle = {International Symposium on High-Performance Computer Architecture},\n journal = {2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)},\n pages = {620-629},\n title = {Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:175e37bca3762b3a52c6a0e153060b98a251d061",
            "@type": "ScholarlyArticle",
            "paperId": "175e37bca3762b3a52c6a0e153060b98a251d061",
            "corpusId": 50787617,
            "url": "https://www.semanticscholar.org/paper/175e37bca3762b3a52c6a0e153060b98a251d061",
            "title": "Inverse molecular design using machine learning: Generative models for matter engineering",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2883583109",
                "DOI": "10.1126/science.aat2663",
                "CorpusId": 50787617,
                "PubMed": "30049875"
            },
            "abstract": "The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.",
            "referenceCount": 93,
            "citationCount": 1056,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://science.sciencemag.org/content/sci/361/6400/360.full.pdf",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-07-27",
            "journal": {
                "name": "Science",
                "volume": "361"
            },
            "citationStyles": {
                "bibtex": "@Article{S\u00e1nchez-Lengeling2018InverseMD,\n author = {Benjam\u00edn S\u00e1nchez-Lengeling and Al\u00e1n Aspuru-Guzik},\n booktitle = {Science},\n journal = {Science},\n pages = {360 - 365},\n title = {Inverse molecular design using machine learning: Generative models for matter engineering},\n volume = {361},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5286e20ccf512bda27950d043858c1ae3508f8f6",
            "@type": "ScholarlyArticle",
            "paperId": "5286e20ccf512bda27950d043858c1ae3508f8f6",
            "corpusId": 196044394,
            "url": "https://www.semanticscholar.org/paper/5286e20ccf512bda27950d043858c1ae3508f8f6",
            "title": "Machine Learning",
            "venue": "Machine Learning for Risk Calculations",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.4135/9781483386874.n311",
                "CorpusId": 196044394
            },
            "abstract": "Machine Learning (ML) is a form of Artificial Intelligence (AI) that uses data to train a computer to perform tasks. Unlike traditional programming, in which rules are programmed explicitly, machine learning uses algorithms to build rulesets automatically. At a high level, machine learning is a collection of techniques borrowed from many disciplines including statistics, probability theory, and neuroscience combined with novel ideas for the purpose of gaining insight through data and computation.",
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-12-16",
            "journal": {
                "name": "Machine Learning for Risk Calculations",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{None,\n booktitle = {Machine Learning for Risk Calculations},\n journal = {Machine Learning for Risk Calculations},\n title = {Machine Learning},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ec6200bdcc23b79a71555962cde50306c4029f1a",
            "@type": "ScholarlyArticle",
            "paperId": "ec6200bdcc23b79a71555962cde50306c4029f1a",
            "corpusId": 201889859,
            "url": "https://www.semanticscholar.org/paper/ec6200bdcc23b79a71555962cde50306c4029f1a",
            "title": "Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2967663220",
                "DOI": "10.11989/JEST.1674-862X.80904120",
                "CorpusId": 201889859
            },
            "abstract": "Hyperparameters are important for machine learning algorithms since they directly control the behaviors of training algorithms and have a significant effect on the performance of machine learning models. Several techniques have been developed and successfully applied for certain application domains. However, this work demands professional knowledge and expert experience. And sometimes it has to resort to the brute-force search. Therefore, if an efficient hyperparameter optimization algorithm can be developed to optimize any given machine learning method, it will greatly improve the efficiency of machine learning. In this paper, we consider building the relationship between the performance of the machine learning models and their hyperparameters by Gaussian processes. In this way, the hyperparameter tuning problem can be abstracted as an optimization problem and Bayesian optimization is used to solve the problem. Bayesian optimization is based on the Bayesian theorem. It sets a prior over the optimization function and gathers the information from the previous sample to update the posterior of the optimization function. A utility function selects the next sample point to maximize the optimization function. Several experiments were conducted on standard test datasets. Experiment results show that the proposed method can find the best hyperparameters for the widely used machine learning models, such as the random forest algorithm and the neural networks, even multi-grained cascade forest under the consideration of time cost.",
            "referenceCount": 29,
            "citationCount": 620,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-03-01",
            "journal": {
                "name": "Journal of Electronic Science and Technology",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2019HyperparameterOF,\n author = {Jia Wu and Xiuyun Chen and H. Zhang and Li-Dong Xiong and Hang Lei and S. Deng},\n journal = {Journal of Electronic Science and Technology},\n pages = {26-40},\n title = {Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization},\n volume = {17},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c8ac6060d34179871b81ecd19621c63360347f8e",
            "@type": "ScholarlyArticle",
            "paperId": "c8ac6060d34179871b81ecd19621c63360347f8e",
            "corpusId": 209432822,
            "url": "https://www.semanticscholar.org/paper/c8ac6060d34179871b81ecd19621c63360347f8e",
            "title": "Comparing different supervised machine learning algorithms for disease prediction",
            "venue": "BMC Medical Informatics and Decision Making",
            "publicationVenue": {
                "id": "urn:research:76da9cc5-c5a7-42b4-a250-3e708c5f4980",
                "name": "BMC Medical Informatics and Decision Making",
                "alternate_names": [
                    "BMC Med Informatics Decis Mak"
                ],
                "issn": "1472-6947",
                "url": "http://www.biomedcentral.com/bmcmedinformdecismak/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2995098893",
                "PubMedCentral": "6925840",
                "DBLP": "journals/midm/UddinKHM19",
                "DOI": "10.1186/s12911-019-1004-8",
                "CorpusId": 209432822,
                "PubMed": "31864346"
            },
            "abstract": null,
            "referenceCount": 87,
            "citationCount": 618,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-1004-8",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-12-01",
            "journal": {
                "name": "BMC Medical Informatics and Decision Making",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Uddin2019ComparingDS,\n author = {S. Uddin and Arif Khan and Md Ekramul Hossain and M. Moni},\n booktitle = {BMC Medical Informatics and Decision Making},\n journal = {BMC Medical Informatics and Decision Making},\n title = {Comparing different supervised machine learning algorithms for disease prediction},\n volume = {19},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7924a71ff89f37f66298a6b42bcd26fa7c0f33b",
            "@type": "ScholarlyArticle",
            "paperId": "e7924a71ff89f37f66298a6b42bcd26fa7c0f33b",
            "corpusId": 228063845,
            "url": "https://www.semanticscholar.org/paper/e7924a71ff89f37f66298a6b42bcd26fa7c0f33b",
            "title": "River: machine learning for streaming data in Python",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2012-04740",
                "MAG": "3111828510",
                "ArXiv": "2012.04740",
                "CorpusId": 228063845
            },
            "abstract": "River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of the two most popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river.",
            "referenceCount": 48,
            "citationCount": 107,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-12-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2012.04740"
            },
            "citationStyles": {
                "bibtex": "@Article{Montiel2020RiverML,\n author = {Jacob Montiel and Max Halford and S. M. Mastelini and Geoffrey Bolmier and Raphael Sourty and Robin Vaysse and Adil Zouitine and Heitor Murilo Gomes and Jesse Read and T. Abdessalem and A. Bifet},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {River: machine learning for streaming data in Python},\n volume = {abs/2012.04740},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fbf9812f29156024ec693b4633a21303eead309d",
            "@type": "ScholarlyArticle",
            "paperId": "fbf9812f29156024ec693b4633a21303eead309d",
            "corpusId": 207942622,
            "url": "https://www.semanticscholar.org/paper/fbf9812f29156024ec693b4633a21303eead309d",
            "title": "Machine learning algorithm validation with a limited sample size",
            "venue": "PLoS ONE",
            "publicationVenue": {
                "id": "urn:research:0aed7a40-85f3-4c66-9e1b-c1556c57001b",
                "name": "PLoS ONE",
                "alternate_names": [
                    "Plo ONE",
                    "PLOS ONE",
                    "PLO ONE"
                ],
                "issn": "1932-6203",
                "url": "https://journals.plos.org/plosone/"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "6837442",
                "MAG": "2981679558",
                "DOI": "10.1371/journal.pone.0224365",
                "CorpusId": 207942622,
                "PubMed": "31697686"
            },
            "abstract": "Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.",
            "referenceCount": 33,
            "citationCount": 643,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0224365&type=printable",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-11-07",
            "journal": {
                "name": "PLoS ONE",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Vabalas2019MachineLA,\n author = {A. Vabalas and E. Gowen and E. Poliakoff and A. Casson},\n booktitle = {PLoS ONE},\n journal = {PLoS ONE},\n title = {Machine learning algorithm validation with a limited sample size},\n volume = {14},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c",
            "@type": "ScholarlyArticle",
            "paperId": "d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c",
            "corpusId": 65340678,
            "url": "https://www.semanticscholar.org/paper/d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c",
            "title": "A Detailed Investigation and Analysis of Using Machine Learning Techniques for Intrusion Detection",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/comsur/MishraVTP19",
                "MAG": "2807786182",
                "DOI": "10.1109/COMST.2018.2847722",
                "CorpusId": 65340678
            },
            "abstract": "Intrusion detection is one of the important security problems in todays cyber world. A significant number of techniques have been developed which are based on machine learning approaches. However, they are not very successful in identifying all types of intrusions. In this paper, a detailed investigation and analysis of various machine learning techniques have been carried out for finding the cause of problems associated with various machine learning techniques in detecting intrusive activities. Attack classification and mapping of the attack features is provided corresponding to each attack. Issues which are related to detecting low-frequency attacks using network attack dataset are also discussed and viable methods are suggested for improvement. Machine learning techniques have been analyzed and compared in terms of their detection capability for detecting the various category of attacks. Limitations associated with each category of them are also discussed. Various data mining tools for machine learning have also been included in the paper. At the end, future directions are provided for attack detection using machine learning techniques.",
            "referenceCount": 181,
            "citationCount": 393,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Mishra2019ADI,\n author = {Preeti Mishra and V. Varadharajan and U. Tupakula and E. Pilli},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {686-728},\n title = {A Detailed Investigation and Analysis of Using Machine Learning Techniques for Intrusion Detection},\n volume = {21},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4eca52f892f288c0b33b74aa4cfed56ed968fb4e",
            "@type": "ScholarlyArticle",
            "paperId": "4eca52f892f288c0b33b74aa4cfed56ed968fb4e",
            "corpusId": 162168885,
            "url": "https://www.semanticscholar.org/paper/4eca52f892f288c0b33b74aa4cfed56ed968fb4e",
            "title": "Explainable Machine Learning for Scientific Insights and Discoveries",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1905-08883",
                "MAG": "3008070519",
                "ArXiv": "1905.08883",
                "DOI": "10.1109/ACCESS.2020.2976199",
                "CorpusId": 162168885
            },
            "abstract": "Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article, we review explainable machine learning in view of applications in the natural sciences and discuss three core elements that we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas.",
            "referenceCount": 142,
            "citationCount": 457,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09007737.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-05-22",
            "journal": {
                "name": "IEEE Access",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Roscher2019ExplainableML,\n author = {R. Roscher and B. Bohn and Marco F. Duarte and J. Garcke},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {42200-42216},\n title = {Explainable Machine Learning for Scientific Insights and Discoveries},\n volume = {8},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1b0f4bd3872bb590d457990ac2b26b29f770fc44",
            "@type": "ScholarlyArticle",
            "paperId": "1b0f4bd3872bb590d457990ac2b26b29f770fc44",
            "corpusId": 202572724,
            "url": "https://www.semanticscholar.org/paper/1b0f4bd3872bb590d457990ac2b26b29f770fc44",
            "title": "Explainable machine learning in deployment",
            "venue": "FAT*",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1909-06342",
                "MAG": "3013149459",
                "ArXiv": "1909.06342",
                "DOI": "10.1145/3351095.3375624",
                "CorpusId": 202572724
            },
            "abstract": "Explainable machine learning offers the potential to provide stakeholders with insights into model behavior by using various methods such as feature importance scores, counterfactual explanations, or influential training data. Yet there is little understanding of how organizations use these methods in practice. This study explores how organizations view and use explainability for stakeholder consumption. We find that, currently, the majority of deployments are not for end users affected by the model but rather for machine learning engineers, who use explainability to debug the model itself. There is thus a gap between explainability in practice and the goal of transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations of current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability. We end by discussing concerns raised regarding explainability.",
            "referenceCount": 91,
            "citationCount": 433,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3375624",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2019-09-13",
            "journal": {
                "name": "Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bhatt2019ExplainableML,\n author = {Umang Bhatt and Alice Xiang and Shubham Sharma and Adrian Weller and Ankur Taly and Yunhan Jia and Joydeep Ghosh and R. Puri and J. Moura and P. Eckersley},\n booktitle = {FAT*},\n journal = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},\n title = {Explainable machine learning in deployment},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:236dfdeb4511754cf71ba220ac569b11973502cd",
            "@type": "ScholarlyArticle",
            "paperId": "236dfdeb4511754cf71ba220ac569b11973502cd",
            "corpusId": 208843362,
            "url": "https://www.semanticscholar.org/paper/236dfdeb4511754cf71ba220ac569b11973502cd",
            "title": "Machine Learning and Deep Learning Methods for Intrusion Detection Systems: A Survey",
            "venue": "Applied Sciences",
            "publicationVenue": {
                "id": "urn:research:136edf8d-0f88-4c2c-830f-461c6a9b842e",
                "name": "Applied Sciences",
                "alternate_names": [
                    "Appl Sci"
                ],
                "issn": "2076-3417",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2980576170",
                "DOI": "10.3390/app9204396",
                "CorpusId": 208843362
            },
            "abstract": "Networks play important roles in modern life, and cyber security has become a vital research area. An intrusion detection system (IDS) which is an important cyber security technique, monitors the state of software and hardware running in the network. Despite decades of development, existing IDSs still face challenges in improving the detection accuracy, reducing the false alarm rate and detecting unknown attacks. To solve the above problems, many researchers have focused on developing IDSs that capitalize on machine learning methods. Machine learning methods can automatically discover the essential differences between normal data and abnormal data with high accuracy. In addition, machine learning methods have strong generalizability, so they are also able to detect unknown attacks. Deep learning is a branch of machine learning, whose performance is remarkable and has become a research hotspot. This survey proposes a taxonomy of IDS that takes data objects as the main dimension to classify and summarize machine learning-based and deep learning-based IDS literature. We believe that this type of taxonomy framework is fit for cyber security researchers. The survey first clarifies the concept and taxonomy of IDSs. Then, the machine learning algorithms frequently used in IDSs, metrics, and benchmark datasets are introduced. Next, combined with the representative literature, we take the proposed taxonomic system as a baseline and explain how to solve key IDS issues with machine learning and deep learning techniques. Finally, challenges and future developments are discussed by reviewing recent representative studies.",
            "referenceCount": 91,
            "citationCount": 413,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2076-3417/9/20/4396/pdf?version=1571308126",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-10-17",
            "journal": {
                "name": "Applied Sciences",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2019MachineLA,\n author = {Hongyu Liu and Bo Lang},\n booktitle = {Applied Sciences},\n journal = {Applied Sciences},\n title = {Machine Learning and Deep Learning Methods for Intrusion Detection Systems: A Survey},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f9a855ae59579d16dca6a5133cd8daddd3305582",
            "@type": "ScholarlyArticle",
            "paperId": "f9a855ae59579d16dca6a5133cd8daddd3305582",
            "corpusId": 209439571,
            "url": "https://www.semanticscholar.org/paper/f9a855ae59579d16dca6a5133cd8daddd3305582",
            "title": "A Survey on Distributed Machine Learning",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2996075766",
                "ArXiv": "1912.09789",
                "DBLP": "journals/corr/abs-1912-09789",
                "DOI": "10.1145/3377454",
                "CorpusId": 209439571
            },
            "abstract": "The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.",
            "referenceCount": 185,
            "citationCount": 390,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3377454",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-12-20",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "53"
            },
            "citationStyles": {
                "bibtex": "@Article{Verbraeken2019ASO,\n author = {Joost Verbraeken and Matthijs Wolting and J. Katzy and Jeroen Kloppenburg and Tim Verbelen and Jan S. Rellermeyer},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 33},\n title = {A Survey on Distributed Machine Learning},\n volume = {53},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5461f9c5d65e87561e00848921ee797902dae14",
            "@type": "ScholarlyArticle",
            "paperId": "b5461f9c5d65e87561e00848921ee797902dae14",
            "corpusId": 208267600,
            "url": "https://www.semanticscholar.org/paper/b5461f9c5d65e87561e00848921ee797902dae14",
            "title": "Causality for Machine Learning",
            "venue": "Probabilistic and Causal Inference",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2990408532",
                "DBLP": "books/acm/22/Scholkopf22",
                "ArXiv": "1911.10500",
                "DOI": "10.1145/3501714.3501755",
                "CorpusId": 208267600
            },
            "abstract": "Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. \nThis article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them.",
            "referenceCount": 141,
            "citationCount": 361,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1911.10500",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2019-11-24",
            "journal": {
                "name": "Probabilistic and Causal Inference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Scholkopf2019CausalityFM,\n author = {B. Scholkopf},\n booktitle = {Probabilistic and Causal Inference},\n journal = {Probabilistic and Causal Inference},\n title = {Causality for Machine Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac644a74a0ebc8cfbe1b0af8120004909828d283",
            "@type": "ScholarlyArticle",
            "paperId": "ac644a74a0ebc8cfbe1b0af8120004909828d283",
            "corpusId": 85446221,
            "url": "https://www.semanticscholar.org/paper/ac644a74a0ebc8cfbe1b0af8120004909828d283",
            "title": "Adversarial attacks on medical machine learning",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2924551358",
                "DOI": "10.1126/science.aaw4399",
                "CorpusId": 85446221,
                "PubMed": "30898923"
            },
            "abstract": "Emerging vulnerabilities demand new conversations With public and academic attention increasingly focused on the new role of machine learning in the health information economy, an unusual and no-longer-esoteric category of vulnerabilities in machine-learning systems could prove important. These vulnerabilities allow a small, carefully designed change in how inputs are presented to a system to completely alter its output, causing it to confidently arrive at manifestly wrong conclusions. These advanced techniques to subvert otherwise-reliable machine-learning systems\u2014so-called adversarial attacks\u2014have, to date, been of interest primarily to computer science researchers (1). However, the landscape of often-competing interests within health care, and billions of dollars at stake in systems' outputs, implies considerable problems. We outline motivations that various players in the health care system may have to use adversarial attacks and begin a discussion of what to do about them. Far from discouraging continued innovation with medical machine learning, we call for active engagement of medical, technical, legal, and ethical experts in pursuit of efficient, broadly available, and effective health care that machine learning will enable.",
            "referenceCount": 10,
            "citationCount": 584,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-21",
            "journal": {
                "name": "Science",
                "volume": "363"
            },
            "citationStyles": {
                "bibtex": "@Article{Finlayson2019AdversarialAO,\n author = {S. G. Finlayson and John Bowers and Joichi Ito and Jonathan Zittrain and Andrew Beam and I. Kohane},\n booktitle = {Science},\n journal = {Science},\n pages = {1287 - 1289},\n title = {Adversarial attacks on medical machine learning},\n volume = {363},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f",
            "@type": "ScholarlyArticle",
            "paperId": "a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f",
            "corpusId": 67867204,
            "url": "https://www.semanticscholar.org/paper/a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f",
            "title": "A Survey of Machine Learning Techniques Applied to Software Defined Networking (SDN): Research Issues and Challenges",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2915905517",
                "DBLP": "journals/comsur/XieYHXLWL19",
                "DOI": "10.1109/COMST.2018.2866942",
                "CorpusId": 67867204
            },
            "abstract": "In recent years, with the rapid development of current Internet and mobile communication technologies, the infrastructure, devices and resources in networking systems are becoming more complex and heterogeneous. In order to efficiently organize, manage, maintain and optimize networking systems, more intelligence needs to be deployed. However, due to the inherently distributed feature of traditional networks, machine learning techniques are hard to be applied and deployed to control and operate networks. Software defined networking (SDN) brings us new chances to provide intelligence inside the networks. The capabilities of SDN (e.g., logically centralized control, global view of the network, software-based traffic analysis, and dynamic updating of forwarding rules) make it easier to apply machine learning techniques. In this paper, we provide a comprehensive survey on the literature involving machine learning algorithms applied to SDN. First, the related works and background knowledge are introduced. Then, we present an overview of machine learning algorithms. In addition, we review how machine learning algorithms are applied in the realm of SDN, from the perspective of traffic classification, routing optimization, quality of service/quality of experience prediction, resource management and security. Finally, challenges and broader perspectives are discussed.",
            "referenceCount": 251,
            "citationCount": 399,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Xie2019ASO,\n author = {Jun-feng Xie and F. Yu and Tao Huang and Renchao Xie and Jiang Liu and Chen-meng Wang and Yun-jie Liu},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {393-430},\n title = {A Survey of Machine Learning Techniques Applied to Software Defined Networking (SDN): Research Issues and Challenges},\n volume = {21},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d73149832c5dc18c8a74b2cc0924eceb51be2e60",
            "@type": "ScholarlyArticle",
            "paperId": "d73149832c5dc18c8a74b2cc0924eceb51be2e60",
            "corpusId": 202771101,
            "url": "https://www.semanticscholar.org/paper/d73149832c5dc18c8a74b2cc0924eceb51be2e60",
            "title": "Hands-On Machine Learning with R",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2971797472",
                "DOI": "10.1201/9780367816377",
                "CorpusId": 202771101
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 265,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-11-11",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Boehmke2019HandsOnML,\n author = {Bradley C. Boehmke and Brandon M. Greenwell},\n title = {Hands-On Machine Learning with R},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b0f8a829450e782fe879d9d48a188d611b6dd74d",
            "@type": "ScholarlyArticle",
            "paperId": "b0f8a829450e782fe879d9d48a188d611b6dd74d",
            "corpusId": 201060023,
            "url": "https://www.semanticscholar.org/paper/b0f8a829450e782fe879d9d48a188d611b6dd74d",
            "title": "Do no harm: a roadmap for responsible machine learning for health care",
            "venue": "Nature Network Boston",
            "publicationVenue": {
                "id": "urn:research:9e995b6d-f30b-4ab4-a13b-3dc2cc992f47",
                "name": "Nature Network Boston",
                "alternate_names": [
                    "Nat Netw Boston",
                    "Nat Med",
                    "Nature Medicine"
                ],
                "issn": "1744-7933",
                "url": "https://www.nature.com/nature/articles?code=archive_news"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2969881216",
                "DOI": "10.1038/s41591-019-0548-6",
                "CorpusId": 201060023,
                "PubMed": "31427808"
            },
            "abstract": null,
            "referenceCount": 26,
            "citationCount": 446,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-08-19",
            "journal": {
                "name": "Nature Medicine",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Wiens2019DoNH,\n author = {J. Wiens and S. Saria and M. Sendak and M. Ghassemi and V. Liu and F. Doshi-Velez and Kenneth Jung and K. Heller and David C. Kale and Mohammed Saeed and P. Ossorio and Sonoo Thadaney-Israni and A. Goldenberg},\n booktitle = {Nature Network Boston},\n journal = {Nature Medicine},\n pages = {1337 - 1340},\n title = {Do no harm: a roadmap for responsible machine learning for health care},\n volume = {25},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:998039a4876edc440e0cabb0bc42239b0eb29644",
            "@type": "ScholarlyArticle",
            "paperId": "998039a4876edc440e0cabb0bc42239b0eb29644",
            "corpusId": 189762063,
            "url": "https://www.semanticscholar.org/paper/998039a4876edc440e0cabb0bc42239b0eb29644",
            "title": "Tackling Climate Change with Machine Learning",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-05433",
                "MAG": "2950398529",
                "ArXiv": "1906.05433",
                "DOI": "10.1145/3485128",
                "CorpusId": 189762063
            },
            "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",
            "referenceCount": 893,
            "citationCount": 468,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3485128",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-10",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "55"
            },
            "citationStyles": {
                "bibtex": "@Article{Rolnick2019TacklingCC,\n author = {D. Rolnick and P. Donti and L. Kaack and K. Kochanski and Alexandre Lacoste and K. Sankaran and A. Ross and Nikola Milojevic-Dupont and Natasha Jaques and Anna Waldman-Brown and A. Luccioni and Tegan Maharaj and Evan D. Sherwin and S. Mukkavilli and Konrad Paul Kording and Carla P. Gomes and Andrew Y. Ng and D. Hassabis and John C. Platt and F. Creutzig and J. Chayes and Yoshua Bengio},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 96},\n title = {Tackling Climate Change with Machine Learning},\n volume = {55},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2b49156cf855dbb39768ae0ba7d7cb9263d17e5c",
            "@type": "ScholarlyArticle",
            "paperId": "2b49156cf855dbb39768ae0ba7d7cb9263d17e5c",
            "corpusId": 211096763,
            "url": "https://www.semanticscholar.org/paper/2b49156cf855dbb39768ae0ba7d7cb9263d17e5c",
            "title": "Informed Machine Learning \u2013 A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3006087551",
                "DBLP": "journals/tkde/RudenMBGGHKPPRW23",
                "ArXiv": "1903.12394",
                "DOI": "10.1109/TKDE.2021.3079836",
                "CorpusId": 211096763
            },
            "abstract": "Despite its great success, machine learning can have its limits when dealing with insufficient training data. A potential solution is the additional integration of prior knowledge into the training process which leads to the notion of informed machine learning. In this paper, we present a structured overview of various approaches in this field. We provide a definition and propose a concept for informed machine learning which illustrates its building blocks and distinguishes it from conventional machine learning. We introduce a taxonomy that serves as a classification framework for informed machine learning approaches. It considers the source of knowledge, its representation, and its integration into the machine learning pipeline. Based on this taxonomy, we survey related research and describe how different knowledge representations such as algebraic equations, logic rules, or simulation results can be used in learning systems. This evaluation of numerous papers on the basis of our taxonomy uncovers key methods in the field of informed machine learning.",
            "referenceCount": 203,
            "citationCount": 332,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/69/4358933/09429985.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-03-29",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Rueden2019InformedML,\n author = {Laura von Rueden and S. Mayer and Katharina Beckh and B. Georgiev and Sven Giesselbach and R. Heese and Birgit Kirsch and Julius Pfrommer and Annika Pick and Rajkumar Ramamurthy and Michal Walczak and J. Garcke and C. Bauckhage and Jannis Schuecker},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {614-633},\n title = {Informed Machine Learning \u2013 A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems},\n volume = {35},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3119ea9c7ad7a5e044dc7c267329a4bbf00d0158",
            "@type": "ScholarlyArticle",
            "paperId": "3119ea9c7ad7a5e044dc7c267329a4bbf00d0158",
            "corpusId": 189928307,
            "url": "https://www.semanticscholar.org/paper/3119ea9c7ad7a5e044dc7c267329a4bbf00d0158",
            "title": "A Survey of Optimization Methods From a Machine Learning Perspective",
            "venue": "IEEE Transactions on Cybernetics",
            "publicationVenue": {
                "id": "urn:research:404813e7-95da-4137-be14-2ba73d2df4fd",
                "name": "IEEE Transactions on Cybernetics",
                "alternate_names": [
                    "IEEE Trans Cybern"
                ],
                "issn": "2168-2267",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6221036"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2990346675",
                "DBLP": "journals/tcyb/SunCZZ20",
                "ArXiv": "1906.06821",
                "DOI": "10.1109/TCYB.2019.2950779",
                "CorpusId": 189928307,
                "PubMed": "31751262"
            },
            "abstract": "Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this article, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Finally, we explore and give some challenges and open problems for the optimization in machine learning.",
            "referenceCount": 235,
            "citationCount": 345,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.06821",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-17",
            "journal": {
                "name": "IEEE Transactions on Cybernetics",
                "volume": "50"
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2019ASO,\n author = {Shiliang Sun and Zehui Cao and Han Zhu and Jing Zhao},\n booktitle = {IEEE Transactions on Cybernetics},\n journal = {IEEE Transactions on Cybernetics},\n pages = {3668-3681},\n title = {A Survey of Optimization Methods From a Machine Learning Perspective},\n volume = {50},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8db8166249dfb94dd8d52f88d27917b5755ae049",
            "@type": "ScholarlyArticle",
            "paperId": "8db8166249dfb94dd8d52f88d27917b5755ae049",
            "corpusId": 204229941,
            "url": "https://www.semanticscholar.org/paper/8db8166249dfb94dd8d52f88d27917b5755ae049",
            "title": "A Quick Review of Machine Learning Algorithms",
            "venue": "International Conference Machine Learning, Big Data, Cloud and Parallel Computing",
            "publicationVenue": {
                "id": "urn:research:2f8b7930-6b40-4467-bd0c-33f7de6cbcd7",
                "name": "International Conference Machine Learning, Big Data, Cloud and Parallel Computing",
                "alternate_names": [
                    "ComitCon",
                    "Int Conf Mach Learn Big Data Cloud Parallel Comput"
                ],
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2979543333",
                "DOI": "10.1109/COMITCon.2019.8862451",
                "CorpusId": 204229941
            },
            "abstract": "Machine learning is predominantly an area of Artificial Intelligence which has been a key component of digitalization solutions that has caught major attention in the digital arena. In this paper author intends to do a brief review of various machine learning algorithms which are most frequently used and therefore are the most popular ones. The author intends to highlight the merits and demerits of the machine learning algorithms from their application perspective to aid in an informed decision making towards selecting the appropriate learning algorithm to meet the specific requirement of the application.",
            "referenceCount": 10,
            "citationCount": 353,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2019-02-01",
            "journal": {
                "name": "2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Ray2019AQR,\n author = {Susmita Ray},\n booktitle = {International Conference Machine Learning, Big Data, Cloud and Parallel Computing},\n journal = {2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)},\n pages = {35-39},\n title = {A Quick Review of Machine Learning Algorithms},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97f4a6f87f258053f2677504647696f1803c6794",
            "@type": "ScholarlyArticle",
            "paperId": "97f4a6f87f258053f2677504647696f1803c6794",
            "corpusId": 207951924,
            "url": "https://www.semanticscholar.org/paper/97f4a6f87f258053f2677504647696f1803c6794",
            "title": "How to Read Articles That Use Machine Learning: Users' Guides to the Medical Literature.",
            "venue": "Journal of the American Medical Association (JAMA)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2988716771",
                "DOI": "10.1001/jama.2019.16489",
                "CorpusId": 207951924,
                "PubMed": "31714992"
            },
            "abstract": "In recent years, many new clinical diagnostic tools have been developed using complicated machine learning methods. Irrespective of how a diagnostic tool is derived, it must be evaluated using a 3-step process of deriving, validating, and establishing the clinical effectiveness of the tool. Machine learning-based tools should also be assessed for the type of machine learning model used and its appropriateness for the input data type and data set size. Machine learning models also generally have additional prespecified settings called hyperparameters, which must be tuned on a data set independent of the validation set. On the validation set, the outcome against which the model is evaluated is termed the reference standard. The rigor of the reference standard must be assessed, such as against a universally accepted gold standard or expert grading.",
            "referenceCount": 36,
            "citationCount": 297,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-11-12",
            "journal": {
                "name": "JAMA",
                "volume": "322 18"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2019HowTR,\n author = {Yun Liu and Po-Hsuan Cameron Chen and Jonathan Krause and L. Peng},\n booktitle = {Journal of the American Medical Association (JAMA)},\n journal = {JAMA},\n pages = {\n          1806-1816\n        },\n title = {How to Read Articles That Use Machine Learning: Users' Guides to the Medical Literature.},\n volume = {322 18},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f13a5148f7caa51ea946193d261d4f8ed32d81a",
            "@type": "ScholarlyArticle",
            "paperId": "3f13a5148f7caa51ea946193d261d4f8ed32d81a",
            "corpusId": 53427953,
            "url": "https://www.semanticscholar.org/paper/3f13a5148f7caa51ea946193d261d4f8ed32d81a",
            "title": "Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon",
            "venue": "European Journal of Operational Research",
            "publicationVenue": {
                "id": "urn:research:0acd87e7-c1b4-434a-955a-c26983a4b9f4",
                "name": "European Journal of Operational Research",
                "alternate_names": [
                    "Eur J Oper Res"
                ],
                "issn": "0377-2217",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/505543/description#description"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1811-06128",
                "MAG": "2900896126",
                "ArXiv": "1811.06128",
                "DOI": "10.1016/j.ejor.2020.07.063",
                "CorpusId": 53427953
            },
            "abstract": null,
            "referenceCount": 74,
            "citationCount": 885,
            "influentialCitationCount": 51,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1811.06128",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-11-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1811.06128"
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2018MachineLF,\n author = {Yoshua Bengio and Andrea Lodi and Antoine Prouvost},\n booktitle = {European Journal of Operational Research},\n journal = {ArXiv},\n title = {Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon},\n volume = {abs/1811.06128},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d093bd376ba63495ea442241bc8bc2f0ff30c2b",
            "@type": "ScholarlyArticle",
            "paperId": "5d093bd376ba63495ea442241bc8bc2f0ff30c2b",
            "corpusId": 84183143,
            "url": "https://www.semanticscholar.org/paper/5d093bd376ba63495ea442241bc8bc2f0ff30c2b",
            "title": "Machine learning in medicine: a practical introduction",
            "venue": "BMC Medical Research Methodology",
            "publicationVenue": {
                "id": "urn:research:6c68e781-5ebc-47cf-a4a0-77b077106aef",
                "name": "BMC Medical Research Methodology",
                "alternate_names": [
                    "BMC Med Res Methodol"
                ],
                "issn": "1471-2288",
                "url": "http://www.biomedcentral.com/bmcmedresmethodol/"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "6425557",
                "MAG": "2936573766",
                "DOI": "10.1186/s12874-019-0681-4",
                "CorpusId": 84183143,
                "PubMed": "30890124"
            },
            "abstract": null,
            "referenceCount": 39,
            "citationCount": 539,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-019-0681-4",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-19",
            "journal": {
                "name": "BMC Medical Research Methodology",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Sidey-Gibbons2019MachineLI,\n author = {Jenni A. M. Sidey-Gibbons and C. Sidey-Gibbons},\n booktitle = {BMC Medical Research Methodology},\n journal = {BMC Medical Research Methodology},\n title = {Machine learning in medicine: a practical introduction},\n volume = {19},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:05c5b732fb92546c7d6eeabfadb5c14610d07373",
            "@type": "ScholarlyArticle",
            "paperId": "05c5b732fb92546c7d6eeabfadb5c14610d07373",
            "corpusId": 1426815,
            "url": "https://www.semanticscholar.org/paper/05c5b732fb92546c7d6eeabfadb5c14610d07373",
            "title": "Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2949824731",
                "DBLP": "journals/jmlr/LemaitreNA17",
                "ArXiv": "1609.06570",
                "CorpusId": 1426815
            },
            "abstract": "Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub: this https URL.",
            "referenceCount": 23,
            "citationCount": 1602,
            "influentialCitationCount": 73,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1609.06570"
            },
            "citationStyles": {
                "bibtex": "@Article{Lema\u00eetre2016ImbalancedlearnAP,\n author = {G. Lema\u00eetre and Fernando Nogueira and Christos K. Aridas},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},\n volume = {abs/1609.06570},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18aaf8664bbae17a7d20bcb422c36e5d52201aa5",
            "@type": "ScholarlyArticle",
            "paperId": "18aaf8664bbae17a7d20bcb422c36e5d52201aa5",
            "corpusId": 67770057,
            "url": "https://www.semanticscholar.org/paper/18aaf8664bbae17a7d20bcb422c36e5d52201aa5",
            "title": "Machine learning-assisted directed protein evolution with combinatorial libraries",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/pnas/WuKLWA19",
                "MAG": "2953282879",
                "ArXiv": "1902.07231",
                "DOI": "10.1073/pnas.1901979116",
                "CorpusId": 67770057,
                "PubMed": "30979809"
            },
            "abstract": "Significance Proteins often function poorly when used outside their natural contexts; directed evolution can be used to engineer them to be more efficient in new roles. We propose that the expense of experimentally testing a large number of protein variants can be decreased and the outcome can be improved by incorporating machine learning with directed evolution. Simulations on an empirical fitness landscape demonstrate that the expected performance improvement is greater with this approach. Machine learning-assisted directed evolution from a single parent produced enzyme variants that selectively synthesize the enantiomeric products of a new-to-nature chemical transformation. By exploring multiple mutations simultaneously, machine learning efficiently navigates large regions of sequence space to identify improved proteins and also produces diverse solutions to engineering problems. To reduce experimental effort associated with directed protein evolution and to explore the sequence space encoded by mutating multiple positions simultaneously, we incorporate machine learning into the directed evolution workflow. Combinatorial sequence space can be quite expensive to sample experimentally, but machine-learning models trained on tested variants provide a fast method for testing sequence space computationally. We validated this approach on a large published empirical fitness landscape for human GB1 binding protein, demonstrating that machine learning-guided directed evolution finds variants with higher fitness than those found by other directed evolution approaches. We then provide an example application in evolving an enzyme to produce each of the two possible product enantiomers (i.e., stereodivergence) of a new-to-nature carbene Si\u2013H insertion reaction. The approach predicted libraries enriched in functional enzymes and fixed seven mutations in two rounds of evolution to identify variants for selective catalysis with 93% and 79% ee (enantiomeric excess). By greatly increasing throughput with in silico modeling, machine learning enhances the quality and diversity of sequence solutions for a protein engineering problem.",
            "referenceCount": 52,
            "citationCount": 306,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/116/18/8852.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Medicine",
                "Chemistry"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-02-20",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "116"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2019MachineLD,\n author = {Zachary Wu and S. Kan and Russell D. Lewis and Bruce J. Wittmann and F. Arnold},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {8852 - 8858},\n title = {Machine learning-assisted directed protein evolution with combinatorial libraries},\n volume = {116},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8fd8fe76b3fc76adb47b1f1597e2e182a8280225",
            "@type": "ScholarlyArticle",
            "paperId": "8fd8fe76b3fc76adb47b1f1597e2e182a8280225",
            "corpusId": 67279885,
            "url": "https://www.semanticscholar.org/paper/8fd8fe76b3fc76adb47b1f1597e2e182a8280225",
            "title": "Survey on SDN based network intrusion detection system using machine learning approaches",
            "venue": "Peer-to-Peer Networking and Applications",
            "publicationVenue": {
                "id": "urn:research:bb2109e3-dbea-40f7-8bf4-67a5ef512a18",
                "name": "Peer-to-Peer Networking and Applications",
                "alternate_names": [
                    "Peer-to-peer Netw Appl",
                    "Peer-to-peer Networking and Applications"
                ],
                "issn": "1936-6442",
                "url": "https://www.springer.com/engineering/signals/journal/12083"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/ppna/SultanaCPA19",
                "MAG": "2782735691",
                "DOI": "10.1007/S12083-017-0630-0",
                "CorpusId": 67279885
            },
            "abstract": null,
            "referenceCount": 44,
            "citationCount": 313,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-03-01",
            "journal": {
                "name": "Peer-to-Peer Networking and Applications",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Sultana2019SurveyOS,\n author = {N. Sultana and N. Chilamkurti and Wei Peng and Rabei Alhadad},\n booktitle = {Peer-to-Peer Networking and Applications},\n journal = {Peer-to-Peer Networking and Applications},\n pages = {493-501},\n title = {Survey on SDN based network intrusion detection system using machine learning approaches},\n volume = {12},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:561269a24f2f2a06409109723a8ab93a01696efc",
            "@type": "ScholarlyArticle",
            "paperId": "561269a24f2f2a06409109723a8ab93a01696efc",
            "corpusId": 2549272,
            "url": "https://www.semanticscholar.org/paper/561269a24f2f2a06409109723a8ab93a01696efc",
            "title": "Federated Optimization: Distributed Machine Learning for On-Device Intelligence",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2530417694",
                "DBLP": "journals/corr/KonecnyMRR16",
                "ArXiv": "1610.02527",
                "CorpusId": 2549272
            },
            "abstract": "We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. \nA motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. \nWe show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of \\federated optimization.",
            "referenceCount": 112,
            "citationCount": 1449,
            "influentialCitationCount": 108,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.02527"
            },
            "citationStyles": {
                "bibtex": "@Article{Konecn\u00fd2016FederatedOD,\n author = {Jakub Konecn\u00fd and H. B. McMahan and Daniel Ramage and Peter Richt\u00e1rik},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Federated Optimization: Distributed Machine Learning for On-Device Intelligence},\n volume = {abs/1610.02527},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2bac6b71d252f93c4841e325ca111f2752109931",
            "@type": "ScholarlyArticle",
            "paperId": "2bac6b71d252f93c4841e325ca111f2752109931",
            "corpusId": 207847600,
            "url": "https://www.semanticscholar.org/paper/2bac6b71d252f93c4841e325ca111f2752109931",
            "title": "Certified Data Removal from Machine Learning Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1911.03030",
                "DBLP": "conf/icml/GuoGHM20",
                "MAG": "3035556513",
                "CorpusId": 207847600
            },
            "abstract": "Good data stewardship requires removal of data at the request of the data's owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to \"remove\" data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical.",
            "referenceCount": 36,
            "citationCount": 201,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-11-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1911.03030"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2019CertifiedDR,\n author = {Chuan Guo and T. Goldstein and Awni Y. Hannun and L. Maaten},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Certified Data Removal from Machine Learning Models},\n volume = {abs/1911.03030},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b674a7aee72e9b9cc5390eca13f9c5c7812f2ba0",
            "@type": "ScholarlyArticle",
            "paperId": "b674a7aee72e9b9cc5390eca13f9c5c7812f2ba0",
            "corpusId": 207847659,
            "url": "https://www.semanticscholar.org/paper/b674a7aee72e9b9cc5390eca13f9c5c7812f2ba0",
            "title": "Machine learning for molecular simulation",
            "venue": "Annual review of physical chemistry (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2988055229",
                "ArXiv": "1911.02792",
                "DBLP": "journals/corr/abs-1911-02792",
                "DOI": "10.1146/annurev-physchem-042018-052331",
                "CorpusId": 207847659,
                "PubMed": "32092281"
            },
            "abstract": "Machine learning (ML) is transforming all areas of science. The complex and time-consuming calculations in molecular simulations are particularly suitable for an ML revolution and have already been profoundly affected by the application of existing ML methods. Here we review recent ML methods for molecular simulation, with particular focus on (deep) neural networks for the prediction of quantum-mechanical energies and forces, on coarse-grained molecular dynamics, on the extraction of free energy surfaces and kinetics, and on generative network approaches to sample molecular equilibrium structures and compute thermodynamics. To explain these methods and illustrate open methodological problems, we review some important principles of molecular physics and describe how they can be incorporated into ML structures. Finally, we identify and describe a list of open challenges for the interface between ML and molecular simulation. Expected final online publication date for the Annual Review of Physical Chemistry, Volume 71 is April 20, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",
            "referenceCount": 150,
            "citationCount": 429,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://orbilu.uni.lu/bitstream/10993/45768/1/159-ML-molecular-simulations-ARPhysChem-2020.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-11-07",
            "journal": {
                "name": "Annual review of physical chemistry",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{No\u00e92019MachineLF,\n author = {F. No\u00e9 and A. Tkatchenko and K. M\u00fcller and C. Clementi},\n booktitle = {Annual review of physical chemistry (Print)},\n journal = {Annual review of physical chemistry},\n title = {Machine learning for molecular simulation},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:790985a4bee821046992ff3d5322ff11dd1b4262",
            "@type": "ScholarlyArticle",
            "paperId": "790985a4bee821046992ff3d5322ff11dd1b4262",
            "corpusId": 211259075,
            "url": "https://www.semanticscholar.org/paper/790985a4bee821046992ff3d5322ff11dd1b4262",
            "title": "Coresets for Data-efficient Training of Machine Learning Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/icml/MirzasoleimanBL20",
                "MAG": "3048688049",
                "CorpusId": 211259075
            },
            "abstract": "Incremental gradient (IG) methods, such as stochastic gradient descent and its variants are commonly used for large scale optimization in machine learning. Despite the sustained effort to make IG methods more data-efficient, it remains an open question how to select a training data subset that can theoretically and practically perform on par with the full dataset. Here we develop CRAIG, a method to select a weighted subset (or coreset) of training data that closely estimates the full gradient by maximizing a submodular function. We prove that applying IG to this subset is guaranteed to converge to the (near)optimal solution with the same convergence rate as that of IG for convex optimization. As a result, CRAIG achieves a speedup that is inversely proportional to the size of the subset. To our knowledge, this is the first rigorous method for data-efficient training of general machine learning models. Our extensive set of experiments show that CRAIG, while achieving practically the same solution, speeds up various IG methods by up to 6x for logistic regression and 3x for training deep neural networks.",
            "referenceCount": 51,
            "citationCount": 173,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-06-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mirzasoleiman2019CoresetsFD,\n author = {Baharan Mirzasoleiman and J. Bilmes and J. Leskovec},\n booktitle = {International Conference on Machine Learning},\n pages = {6950-6960},\n title = {Coresets for Data-efficient Training of Machine Learning Models},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39361b3507c9f8b0a97780568b645f80a208d78a",
            "@type": "ScholarlyArticle",
            "paperId": "39361b3507c9f8b0a97780568b645f80a208d78a",
            "corpusId": 49866160,
            "url": "https://www.semanticscholar.org/paper/39361b3507c9f8b0a97780568b645f80a208d78a",
            "title": "Machine Learning and Deep Learning Methods for Cybersecurity",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/access/XinK0CLZGHW18",
                "MAG": "2803881474",
                "DOI": "10.1109/ACCESS.2018.2836950",
                "CorpusId": 49866160
            },
            "abstract": "With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.",
            "referenceCount": 76,
            "citationCount": 620,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-05-15",
            "journal": {
                "name": "IEEE Access",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Xin2018MachineLA,\n author = {Yang Xin and Lingshuang Kong and Zhi Liu and Yuling Chen and Yanmiao Li and Hongliang Zhu and Mingcheng Gao and Haixia Hou and Chunhua Wang},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {35365-35381},\n title = {Machine Learning and Deep Learning Methods for Cybersecurity},\n volume = {6},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3784b73a1f392160523400ec0309191c0a96d86f",
            "@type": "ScholarlyArticle",
            "paperId": "3784b73a1f392160523400ec0309191c0a96d86f",
            "corpusId": 7956687,
            "url": "https://www.semanticscholar.org/paper/3784b73a1f392160523400ec0309191c0a96d86f",
            "title": "MLlib: Machine Learning in Apache Spark",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "410850256",
                "DBLP": "journals/corr/MengBYSVLFTAOXX15",
                "ArXiv": "1505.06807",
                "CorpusId": 7956687
            },
            "abstract": "Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.",
            "referenceCount": 27,
            "citationCount": 1688,
            "influentialCitationCount": 168,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-05-26",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Meng2015MLlibML,\n author = {Xiangrui Meng and Joseph K. Bradley and Burak Yavuz and Evan R. Sparks and S. Venkataraman and Davies Liu and Jeremy Freeman and D. B. Tsai and Manish Amde and Sean Owen and Doris Xin and Reynold Xin and M. Franklin and R. Zadeh and M. Zaharia and Ameet Talwalkar},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {34:1-34:7},\n title = {MLlib: Machine Learning in Apache Spark},\n volume = {17},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f2baff3195b6fc43a38e3e869496dab9fe9dbc3",
            "@type": "ScholarlyArticle",
            "paperId": "4f2baff3195b6fc43a38e3e869496dab9fe9dbc3",
            "corpusId": 4701888,
            "url": "https://www.semanticscholar.org/paper/4f2baff3195b6fc43a38e3e869496dab9fe9dbc3",
            "title": "Delayed Impact of Fair Machine Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952026991",
                "DBLP": "conf/icml/LiuDRSH18",
                "ArXiv": "1803.04383",
                "DOI": "10.24963/ijcai.2019/862",
                "CorpusId": 4701888
            },
            "abstract": "Static classification has been the predominant focus of the study of fairness in machine learning. While most models do not consider how decisions change populations over time, it is conventional wisdom that fairness criteria promote the long-term well-being of groups they aim to protect. This work studies the interaction of static fairness criteria with temporal indicators of well-being. We show a simple one-step feedback model in which common criteria do not generally promote improvement over time, and may in fact cause harm. Our results highlight the importance of temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.",
            "referenceCount": 36,
            "citationCount": 388,
            "influentialCitationCount": 36,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2019/0862.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2018DelayedIO,\n author = {Lydia T. Liu and Sarah Dean and Esther Rolf and Max Simchowitz and Moritz Hardt},\n booktitle = {International Conference on Machine Learning},\n pages = {3156-3164},\n title = {Delayed Impact of Fair Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:daf468f001c3a5c6f9e667417becb94fa83efb2f",
            "@type": "ScholarlyArticle",
            "paperId": "daf468f001c3a5c6f9e667417becb94fa83efb2f",
            "corpusId": 122565911,
            "url": "https://www.semanticscholar.org/paper/daf468f001c3a5c6f9e667417becb94fa83efb2f",
            "title": "Exploiting machine learning for end-to-end drug discovery and development",
            "venue": "Nature Materials",
            "publicationVenue": {
                "id": "urn:research:2cc29e11-7fb1-434f-bc7c-efbf9e64672a",
                "name": "Nature Materials",
                "alternate_names": [
                    "Nat Mater"
                ],
                "issn": "1476-1122",
                "url": "https://www.nature.com/nmat/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2940242941",
                "DOI": "10.1038/s41563-019-0338-z",
                "CorpusId": 122565911,
                "PubMed": "31000803"
            },
            "abstract": null,
            "referenceCount": 94,
            "citationCount": 288,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6594828?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-18",
            "journal": {
                "name": "Nature Materials",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Ekins2019ExploitingML,\n author = {S. Ekins and A. C. Puhl and Kimberley M. Zorn and T. Lane and Daniel P. Russo and Jennifer J Klein and A. Hickey and A. Clark},\n booktitle = {Nature Materials},\n journal = {Nature Materials},\n pages = {435-441},\n title = {Exploiting machine learning for end-to-end drug discovery and development},\n volume = {18},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f2b9cb774489c1a600c224c75edb8da07a24064",
            "@type": "ScholarlyArticle",
            "paperId": "4f2b9cb774489c1a600c224c75edb8da07a24064",
            "corpusId": 71144356,
            "url": "https://www.semanticscholar.org/paper/4f2b9cb774489c1a600c224c75edb8da07a24064",
            "title": "Machine-learning reprogrammable metasurface imager",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2919338369",
                "PubMedCentral": "6403242",
                "DOI": "10.1038/s41467-019-09103-2",
                "CorpusId": 71144356,
                "PubMed": "30842417"
            },
            "abstract": null,
            "referenceCount": 36,
            "citationCount": 341,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-019-09103-2.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-06",
            "journal": {
                "name": "Nature Communications",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2019MachinelearningRM,\n author = {Lianlin Li and Hengxin Ruan and Che Liu and Ying Li and Ya Shuang and A. Al\u00fa and C. Qiu and T. Cui},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Machine-learning reprogrammable metasurface imager},\n volume = {10},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:643da4c4de1954daeac571a82367241db012a8bf",
            "@type": "ScholarlyArticle",
            "paperId": "643da4c4de1954daeac571a82367241db012a8bf",
            "corpusId": 3766791,
            "url": "https://www.semanticscholar.org/paper/643da4c4de1954daeac571a82367241db012a8bf",
            "title": "Automatic differentiation in machine learning: a survey",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1853291804",
                "ArXiv": "1502.05767",
                "DBLP": "journals/corr/BaydinPR15",
                "CorpusId": 3766791
            },
            "abstract": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply \u201cauto-diff\u201d, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until \nvery recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other\u2019s results. Despite its \nrelevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names \u201cdynamic computational \ngraphs\u201d and \u201cdifferentiable programming\u201d. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main imple- \nmentation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms \u201cautodiff\u201d, \u201cautomatic differentiation\u201d, and \u201csymbolic differentiation\u201d as these are encountered more and more in machine learning settings.",
            "referenceCount": 242,
            "citationCount": 2007,
            "influentialCitationCount": 97,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2015-02-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.05767"
            },
            "citationStyles": {
                "bibtex": "@Article{Baydin2015AutomaticDI,\n author = {A. G. Baydin and Barak A. Pearlmutter and Alexey Radul and J. Siskind},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {Automatic differentiation in machine learning: a survey},\n volume = {abs/1502.05767},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f2df0c1026ffa474f603a535e48e5c115d3d8629",
            "@type": "ScholarlyArticle",
            "paperId": "f2df0c1026ffa474f603a535e48e5c115d3d8629",
            "corpusId": 116858,
            "url": "https://www.semanticscholar.org/paper/f2df0c1026ffa474f603a535e48e5c115d3d8629",
            "title": "Extreme learning machine: Theory and applications",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "journals/ijon/HuangZS06",
                "MAG": "2111072639",
                "DOI": "10.1016/J.NEUCOM.2005.12.126",
                "CorpusId": 116858
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 10990,
            "influentialCitationCount": 1115,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-12-01",
            "journal": {
                "name": "Neurocomputing",
                "volume": "70"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2006ExtremeLM,\n author = {G. Huang and Q. Zhu and C. Siew},\n booktitle = {Neurocomputing},\n journal = {Neurocomputing},\n pages = {489-501},\n title = {Extreme learning machine: Theory and applications},\n volume = {70},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29524f145db94cab2336da99f157e869d805dead",
            "@type": "ScholarlyArticle",
            "paperId": "29524f145db94cab2336da99f157e869d805dead",
            "corpusId": 44237208,
            "url": "https://www.semanticscholar.org/paper/29524f145db94cab2336da99f157e869d805dead",
            "title": "SoK: Security and Privacy in Machine Learning",
            "venue": "European Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:4c2b8cb8-e51c-4ece-9122-89595989b56f",
                "name": "European Symposium on Security and Privacy",
                "alternate_names": [
                    "EuroS&P",
                    "IEEE European Symposium on Security and Privacy",
                    "Eur Symp Secur Priv",
                    "IEEE Eur Symp Secur Priv",
                    "EUROS&P"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2838094497",
                "DBLP": "conf/eurosp/PapernotMSW18",
                "DOI": "10.1109/EuroSP.2018.00035",
                "CorpusId": 44237208
            },
            "abstract": "Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive\u2014new systems and models are being deployed in every domain imaginable, leading to widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date.We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. In particular, it is apparent that constructing a theoretical understanding of the sensitivity of modern ML algorithms to the data they analyze, \u00e0 la PAC theory, will foster a science of security and privacy in ML.",
            "referenceCount": 135,
            "citationCount": 411,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-01",
            "journal": {
                "name": "2018 IEEE European Symposium on Security and Privacy (EuroS&P)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Papernot2018SoKSA,\n author = {Nicolas Papernot and P. Mcdaniel and Arunesh Sinha and Michael P. Wellman},\n booktitle = {European Symposium on Security and Privacy},\n journal = {2018 IEEE European Symposium on Security and Privacy (EuroS&P)},\n pages = {399-414},\n title = {SoK: Security and Privacy in Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:775a4e375cc79b53b94e37fa3eedff481823e4a6",
            "@type": "ScholarlyArticle",
            "paperId": "775a4e375cc79b53b94e37fa3eedff481823e4a6",
            "corpusId": 856717,
            "url": "https://www.semanticscholar.org/paper/775a4e375cc79b53b94e37fa3eedff481823e4a6",
            "title": "Efficient and Robust Automated Machine Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/nips/FeurerKESBH15",
                "MAG": "2182361439",
                "CorpusId": 856717
            },
            "abstract": "The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.",
            "referenceCount": 29,
            "citationCount": 1471,
            "influentialCitationCount": 208,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Feurer2015EfficientAR,\n author = {Matthias Feurer and Aaron Klein and Katharina Eggensperger and J. T. Springenberg and Manuel Blum and F. Hutter},\n booktitle = {Neural Information Processing Systems},\n pages = {2962-2970},\n title = {Efficient and Robust Automated Machine Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2346d121f38fc19c77e0b062415519843f478163",
            "@type": "ScholarlyArticle",
            "paperId": "2346d121f38fc19c77e0b062415519843f478163",
            "corpusId": 3688849,
            "url": "https://www.semanticscholar.org/paper/2346d121f38fc19c77e0b062415519843f478163",
            "title": "Machine Learning in Medicine",
            "venue": "Mach. Learn. under Resour. Constraints Vol. 3",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2177870565",
                "DBLP": "books/degruyter/22/JutzelerB22",
                "DOI": "10.1161/CIRCULATIONAHA.115.001593",
                "CorpusId": 3688849,
                "PubMed": "26572668"
            },
            "abstract": "Spurred by advances in processing power, memory, storage, and an unprecedented wealth of data, computers are being asked to tackle increasingly complex learning tasks, often with astonishing success. Computers have now mastered a popular variant of poker, learned the laws of physics from experimental data, and become experts in video games - tasks that would have been deemed impossible not too long ago. In parallel, the number of companies centered on applying complex data analysis to varying industries has exploded, and it is thus unsurprising that some analytic companies are turning attention to problems in health care. The purpose of this review is to explore what problems in medicine might benefit from such learning approaches and use examples from the literature to introduce basic concepts in machine learning. It is important to note that seemingly large enough medical data sets and adequate learning algorithms have been available for many decades, and yet, although there are thousands of papers applying machine learning algorithms to medical data, very few have contributed meaningfully to clinical care. This lack of impact stands in stark contrast to the enormous relevance of machine learning to many other industries. Thus, part of my effort will be to identify what obstacles there may be to changing the practice of medicine through statistical learning approaches, and discuss how these might be overcome.",
            "referenceCount": 38,
            "citationCount": 2077,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc5831252?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2015-11-17",
            "journal": {
                "name": "Circulation",
                "volume": "132 20"
            },
            "citationStyles": {
                "bibtex": "@Article{Jutzeler2015MachineLI,\n author = {C. Jutzeler and K. Borgwardt},\n booktitle = {Mach. Learn. under Resour. Constraints Vol. 3},\n journal = {Circulation},\n pages = {\n          1920-30\n        },\n title = {Machine Learning in Medicine},\n volume = {132 20},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
            "@type": "ScholarlyArticle",
            "paperId": "efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
            "corpusId": 45552660,
            "url": "https://www.semanticscholar.org/paper/efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
            "title": "Big Data and Machine Learning in Health Care.",
            "venue": "Journal of the American Medical Association (JAMA)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2789894922",
                "DOI": "10.1001/jama.2017.18391",
                "CorpusId": 45552660,
                "PubMed": "29532063"
            },
            "abstract": "Nearly all aspects of modern life are in some way being changed by big data and machine learning. Netflix knows what movies people like to watch and Google knows what people want to know based on their search histories. Indeed, Google has recently begun to replace much of its existing non\u2013machine learning technology with machine learning algorithms, and there is great optimism that these techniques can provide similar improvements across many sectors. It isnosurprisethenthatmedicineisawashwithclaims of revolution from the application of machine learning to big health care data. Recent examples have demonstrated that big data and machine learning can create algorithms that perform on par with human physicians.1 Though machine learning and big data may seem mysterious at first, they are in fact deeply related to traditional statistical models that are recognizable to most clinicians. It is our hope that elucidating these connections will demystify these techniques and provide a set of reasonable expectations for the role of machine learning and big data in health care. Machine learning was originally described as a program that learns to perform a task or make a decision automatically from data, rather than having the behavior explicitlyprogrammed.However,thisdefinitionisverybroad and could cover nearly any form of data-driven approach. For instance, consider the Framingham cardiovascular risk score,whichassignspointstovariousfactorsandproduces a number that predicts 10-year cardiovascular risk. Should this be considered an example of machine learning? The answer might obviously seem to be no. Closer inspection oftheFraminghamriskscorerevealsthattheanswermight not be as obvious as it first seems. The score was originally created2 by fitting a proportional hazards model to data frommorethan5300patients,andsothe\u201crule\u201dwasinfact learnedentirelyfromdata.Designatingariskscoreasamachine learning algorithm might seem a strange notion, but this example reveals the uncertain nature of the original definition of machine learning. It is perhaps more useful to imagine an algorithm as existing along a continuum between fully human-guided vs fully machine-guided data analysis. To understand the degree to which a predictive or diagnostic algorithm can said to be an instance of machine learning requires understanding how much of its structure or parameters were predetermined by humans. The trade-off between human specificationofapredictivealgorithm\u2019spropertiesvslearning those properties from data is what is known as the machine learning spectrum. Returning to the Framingham study, to create the original risk score statisticians and clinical experts worked together to make many important decisions, such as which variables to include in the model, therelationshipbetweenthedependentandindependent variables, and variable transformations and interactions. Since considerable human effort was used to define these properties, it would place low on the machine learning spectrum (#19 in the Figure and Supplement). Many evidence-based clinical practices are based on a statistical model of this sort, and so many clinical decisions in fact exist on the machine learning spectrum (middle left of Figure). On the extreme low end of the machine learning spectrum would be heuristics and rules of thumb that do not directly involve the use of any rules or models explicitly derived from data (bottom left of Figure). Suppose a new cardiovascular risk score is created that includes possible extensions to the original model. For example, it could be that risk factors should not be added but instead should be multiplied or divided, or perhaps a particularly important risk factor should square the entire score if it is present. Moreover, if it is not known in advance which variables will be important, but thousands of individual measurements have been collected, how should a good model be identified from among the infinite possibilities? This is precisely what a machine learning algorithm attempts to do. As humans impose fewer assumptions on the algorithm, it moves further up the machine learning spectrum. However, there is never a specific threshold wherein a model suddenly becomes \u201cmachine learning\u201d; rather, all of these approaches exist along a continuum, determined by how many human assumptions are placed onto the algorithm. An example of an approach high on the machine learning spectrum has recently emerged in the form of so-called deep learning models. Deep learning models are stunningly complex networks of artificial neurons that were designed expressly to create accurate models directly from raw data. Researchers recently demonstrated a deep learning algorithm capable of detecting diabetic retinopathy (#4 in the Figure, top center) from retinal photographs at a sensitivity equal to or greater than that of ophthalmologists.1 This model learned the diagnosis procedure directly from the raw pixels of the images with no human intervention outside of a team of ophthalmologists who annotated each image with the correct diagnosis. Because they are able to learn the task with little human instruction or prior assumptions, these deep learning algorithms rank very high on the machine learning spectrum (Figure, light blue circles). Though they require less human guidance, deep learning algorithms for image recognition require enormous amounts of data to capture the full complexity, variety, and nuance inherent to real-world images. Consequently, these algorithms often require hundreds of thousands of examples to extract the salient image features that are correlated with the outcome of interest. Higher placement on the machine learning spectrum does not imply superiority, because different tasks require different levels of human involvement. While algorithms high on the spectrum are often very flexible and can learn many tasks, they are often uninterpretable VIEWPOINT",
            "referenceCount": 3,
            "citationCount": 975,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-03",
            "journal": {
                "name": "JAMA",
                "volume": "319 13"
            },
            "citationStyles": {
                "bibtex": "@Article{Beam2018BigDA,\n author = {Andrew Beam and I. Kohane},\n booktitle = {Journal of the American Medical Association (JAMA)},\n journal = {JAMA},\n pages = {\n          1317-1318\n        },\n title = {Big Data and Machine Learning in Health Care.},\n volume = {319 13},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4d1fdd81f033cd58f3723bfc61e7d12079647a7a",
            "@type": "ScholarlyArticle",
            "paperId": "4d1fdd81f033cd58f3723bfc61e7d12079647a7a",
            "corpusId": 38041040,
            "url": "https://www.semanticscholar.org/paper/4d1fdd81f033cd58f3723bfc61e7d12079647a7a",
            "title": "Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.",
            "venue": "New England Journal of Medicine",
            "publicationVenue": {
                "id": "urn:research:dc31f077-7737-4e33-baa3-bceeff44ec27",
                "name": "New England Journal of Medicine",
                "alternate_names": [
                    "n engl J Med",
                    "The New England Journal of Medicine",
                    "N Engl J Med"
                ],
                "issn": "0028-4793",
                "url": "https://www.nejm.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2525984666",
                "DOI": "10.1056/NEJMp1606181",
                "CorpusId": 38041040,
                "PubMed": "27682033"
            },
            "abstract": "The algorithms of machine learning, which can sift through vast numbers of variables looking for combinations that reliably predict outcomes, will improve prognosis, displace much of the work of radiologists and anatomical pathologists, and improve diagnostic accuracy.",
            "referenceCount": 7,
            "citationCount": 1788,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc5070532?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-28",
            "journal": {
                "name": "The New England journal of medicine",
                "volume": "375 13"
            },
            "citationStyles": {
                "bibtex": "@Article{Obermeyer2016PredictingTF,\n author = {Z. Obermeyer and E. Emanuel},\n booktitle = {New England Journal of Medicine},\n journal = {The New England journal of medicine},\n pages = {\n          1216-9\n        },\n title = {Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.},\n volume = {375 13},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:330b5844d170b6b77f5f9fa4c2024150cef2af18",
            "@type": "ScholarlyArticle",
            "paperId": "330b5844d170b6b77f5f9fa4c2024150cef2af18",
            "corpusId": 210064426,
            "url": "https://www.semanticscholar.org/paper/330b5844d170b6b77f5f9fa4c2024150cef2af18",
            "title": "Benchmark and Survey of Automated Machine Learning Frameworks",
            "venue": "Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:aef12dca-60a0-4ca3-819b-cad26d309d4e",
                "name": "Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "JAIR",
                    "J Artif Intell Res",
                    "The Journal of Artificial Intelligence Research"
                ],
                "issn": "1076-9757",
                "url": "http://www.jair.org/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/jair/ZollerH21",
                "MAG": "2999356315",
                "DOI": "10.1613/jair.1.11854",
                "CorpusId": 210064426
            },
            "abstract": "Machine learning (ML) has become a vital part in many aspects of our daily life. However, building well performing machine learning applications requires highly specialized data scientists and domain experts. Automated machine learning (AutoML) aims to reduce the demand for data scientists by enabling domain experts to automatically build machine learning applications without extensive knowledge of statistics and machine learning. This paper is a combination of a survey on current AutoML methods and a benchmark of popular AutoML frameworks on real data sets. Driven by the selected frameworks for evaluation, we summarize and review important AutoML techniques and methods concerning every step in building an ML pipeline. The selected AutoML frameworks are evaluated on 137 different data sets.",
            "referenceCount": 209,
            "citationCount": 243,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.jair.org/index.php/jair/article/download/11854/26651",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-04-26",
            "journal": {
                "name": "J. Artif. Intell. Res.",
                "volume": "70"
            },
            "citationStyles": {
                "bibtex": "@Article{Z\u00f6ller2019BenchmarkAS,\n author = {M. Z\u00f6ller and Marco F. Huber},\n booktitle = {Journal of Artificial Intelligence Research},\n journal = {J. Artif. Intell. Res.},\n pages = {409-472},\n title = {Benchmark and Survey of Automated Machine Learning Frameworks},\n volume = {70},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9d75cc322a4e06d0a3a868cb91b04219a289c12c",
            "@type": "ScholarlyArticle",
            "paperId": "9d75cc322a4e06d0a3a868cb91b04219a289c12c",
            "corpusId": 157481740,
            "url": "https://www.semanticscholar.org/paper/9d75cc322a4e06d0a3a868cb91b04219a289c12c",
            "title": "Machine Learning: An Applied Econometric Approach",
            "venue": "Journal of Economic Perspectives",
            "publicationVenue": {
                "id": "urn:research:ff06c08d-4001-4156-91dc-db2dbc056067",
                "name": "Journal of Economic Perspectives",
                "alternate_names": [
                    "J Econ Perspect"
                ],
                "issn": "0895-3309",
                "url": "http://www.aeaweb.org/jep/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2610886376",
                "DOI": "10.1257/JEP.31.2.87",
                "CorpusId": 157481740
            },
            "abstract": "Machines are increasingly doing \u201cintelligent\u201d things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble\u2014and thus where they can be most usefully applied.",
            "referenceCount": 250,
            "citationCount": 1169,
            "influentialCitationCount": 73,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-05-01",
            "journal": {
                "name": "Journal of Economic Perspectives",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Mullainathan2017MachineLA,\n author = {S. Mullainathan and Jann Spiess},\n booktitle = {Journal of Economic Perspectives},\n journal = {Journal of Economic Perspectives},\n pages = {87-106},\n title = {Machine Learning: An Applied Econometric Approach},\n volume = {31},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f6d9106b0e169204a506eb1deec2b85e0f296e4a",
            "@type": "ScholarlyArticle",
            "paperId": "f6d9106b0e169204a506eb1deec2b85e0f296e4a",
            "corpusId": 21707180,
            "url": "https://www.semanticscholar.org/paper/f6d9106b0e169204a506eb1deec2b85e0f296e4a",
            "title": "Feature selection in machine learning: A new perspective",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2791315675",
                "DBLP": "journals/ijon/CaiLWY18",
                "DOI": "10.1016/j.neucom.2017.11.077",
                "CorpusId": 21707180
            },
            "abstract": null,
            "referenceCount": 187,
            "citationCount": 1088,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://manuscript.elsevier.com/S0925231218302911/pdf/S0925231218302911.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Neurocomputing",
                "volume": "300"
            },
            "citationStyles": {
                "bibtex": "@Article{Cai2018FeatureSI,\n author = {Jie Cai and Jiawei Luo and Shulin Wang and Sheng Yang},\n booktitle = {Neurocomputing},\n journal = {Neurocomputing},\n pages = {70-79},\n title = {Feature selection in machine learning: A new perspective},\n volume = {300},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ea6a93199c9227fa0c1c7de13725f918c9be3a4",
            "@type": "ScholarlyArticle",
            "paperId": "2ea6a93199c9227fa0c1c7de13725f918c9be3a4",
            "corpusId": 6155330,
            "url": "https://www.semanticscholar.org/paper/2ea6a93199c9227fa0c1c7de13725f918c9be3a4",
            "title": "Dlib-ml: A Machine Learning Toolkit",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "journals/jmlr/King09",
                "MAG": "2115252128",
                "DOI": "10.5555/1577069.1755843",
                "CorpusId": 6155330
            },
            "abstract": "There are many excellent toolkits which provide support for developing machine learning software in Python, R, Matlab, and similar environments. Dlib-ml is an open source library, targeted at both engineers and research scientists, which aims to provide a similarly rich environment for developing machine learning software in the C++ language. Towards this end, dlib-ml contains an extensible linear algebra toolkit with built in BLAS support. It also houses implementations of algorithms for performing inference in Bayesian networks and kernel-based methods for classification, regression, clustering, anomaly detection, and feature ranking. To enable easy use of these tools, the entire library has been developed with contract programming, which provides complete and precise documentation as well as powerful debugging tools.",
            "referenceCount": 11,
            "citationCount": 2795,
            "influentialCitationCount": 211,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-12-01",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{King2009DlibmlAM,\n author = {Davis E. King},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {1755-1758},\n title = {Dlib-ml: A Machine Learning Toolkit},\n volume = {10},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:adfc508b9b3d4fc3903aa383a290dc68fb8bbe5a",
            "@type": "ScholarlyArticle",
            "paperId": "adfc508b9b3d4fc3903aa383a290dc68fb8bbe5a",
            "corpusId": 3936418,
            "url": "https://www.semanticscholar.org/paper/adfc508b9b3d4fc3903aa383a290dc68fb8bbe5a",
            "title": "Implementing Machine Learning in Health Care - Addressing Ethical Challenges.",
            "venue": "New England Journal of Medicine",
            "publicationVenue": {
                "id": "urn:research:dc31f077-7737-4e33-baa3-bceeff44ec27",
                "name": "New England Journal of Medicine",
                "alternate_names": [
                    "n engl J Med",
                    "The New England Journal of Medicine",
                    "N Engl J Med"
                ],
                "issn": "0028-4793",
                "url": "https://www.nejm.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2789970635",
                "DOI": "10.1056/NEJMp1714229",
                "CorpusId": 3936418,
                "PubMed": "29539284"
            },
            "abstract": "Implementing Machine Learning in Health Care We need to consider the ethical challenges inherent in implementing machine learning in health care if its benefits are to be realized. Some of these ch...",
            "referenceCount": 6,
            "citationCount": 644,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc5962261?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-14",
            "journal": {
                "name": "The New England journal of medicine",
                "volume": "378 11"
            },
            "citationStyles": {
                "bibtex": "@Article{Char2018ImplementingML,\n author = {Danton Char and N. Shah and D. Magnus},\n booktitle = {New England Journal of Medicine},\n journal = {The New England journal of medicine},\n pages = {\n          981-983\n        },\n title = {Implementing Machine Learning in Health Care - Addressing Ethical Challenges.},\n volume = {378 11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3df952d4a724655f7520ff95d4b2cef90fff0cae",
            "@type": "ScholarlyArticle",
            "paperId": "3df952d4a724655f7520ff95d4b2cef90fff0cae",
            "corpusId": 51893222,
            "url": "https://www.semanticscholar.org/paper/3df952d4a724655f7520ff95d4b2cef90fff0cae",
            "title": "Techniques for interpretable machine learning",
            "venue": "Communications of the ACM",
            "publicationVenue": {
                "id": "urn:research:4d9ce1c4-dc84-46b9-903e-e3751c00c7dd",
                "name": "Communications of the ACM",
                "alternate_names": [
                    "Commun ACM",
                    "Communications of The ACM"
                ],
                "issn": "0001-0782",
                "url": "http://www.acm.org/pubs/cacm/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1808-00033",
                "MAG": "2996061341",
                "ArXiv": "1808.00033",
                "DOI": "10.1145/3359786",
                "CorpusId": 51893222
            },
            "abstract": "Uncovering the mysterious ways machine learning models make decisions.",
            "referenceCount": 52,
            "citationCount": 774,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1808.00033",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-07-31",
            "journal": {
                "name": "Communications of the ACM",
                "volume": "63"
            },
            "citationStyles": {
                "bibtex": "@Article{Du2018TechniquesFI,\n author = {Mengnan Du and Ninghao Liu and Xia Hu},\n booktitle = {Communications of the ACM},\n journal = {Communications of the ACM},\n pages = {68 - 77},\n title = {Techniques for interpretable machine learning},\n volume = {63},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fa9906b466bbbff3a8c206b499cd34323a91d1b2",
            "@type": "ScholarlyArticle",
            "paperId": "fa9906b466bbbff3a8c206b499cd34323a91d1b2",
            "corpusId": 4559362,
            "url": "https://www.semanticscholar.org/paper/fa9906b466bbbff3a8c206b499cd34323a91d1b2",
            "title": "Points of Significance: Statistics versus machine learning",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2792919287",
                "DOI": "10.1038/nmeth.4642",
                "CorpusId": 4559362
            },
            "abstract": null,
            "referenceCount": 12,
            "citationCount": 711,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/nmeth.4642.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-04-03",
            "journal": {
                "name": "Nature Methods",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Bzdok2018PointsOS,\n author = {D. Bzdok and Naomi Altman and M. Krzywinski},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {233-234},\n title = {Points of Significance: Statistics versus machine learning},\n volume = {15},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5327bb691a1c63791a06de2d3f0478e47785add5",
            "@type": "ScholarlyArticle",
            "paperId": "5327bb691a1c63791a06de2d3f0478e47785add5",
            "corpusId": 53216044,
            "url": "https://www.semanticscholar.org/paper/5327bb691a1c63791a06de2d3f0478e47785add5",
            "title": "Predicting Diabetes Mellitus With Machine Learning Techniques",
            "venue": "Frontiers in Genetics",
            "publicationVenue": {
                "id": "urn:research:9ec189b3-db0f-41d8-9c82-21ef5fa9b87e",
                "name": "Frontiers in Genetics",
                "alternate_names": [
                    "Front Genet"
                ],
                "issn": "1664-8021",
                "url": "http://www.frontiersin.org/genetics/"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "6232260",
                "MAG": "2900329012",
                "DOI": "10.3389/fgene.2018.00515",
                "CorpusId": 53216044,
                "PubMed": "30459809"
            },
            "abstract": "Diabetes mellitus is a chronic disease characterized by hyperglycemia. It may cause many complications. According to the growing morbidity in recent years, in 2040, the world\u2019s diabetic patients will reach 642 million, which means that one of the ten adults in the future is suffering from diabetes. There is no doubt that this alarming figure needs great attention. With the rapid development of machine learning, machine learning has been applied to many aspects of medical health. In this study, we used decision tree, random forest and neural network to predict diabetes mellitus. The dataset is the hospital physical examination data in Luzhou, China. It contains 14 attributes. In this study, five-fold cross validation was used to examine the models. In order to verity the universal applicability of the methods, we chose some methods that have the better performance to conduct independent test experiments. We randomly selected 68994 healthy people and diabetic patients\u2019 data, respectively as training set. Due to the data unbalance, we randomly extracted 5 times data. And the result is the average of these five experiments. In this study, we used principal component analysis (PCA) and minimum redundancy maximum relevance (mRMR) to reduce the dimensionality. The results showed that prediction with random forest could reach the highest accuracy (ACC = 0.8084) when all the attributes were used.",
            "referenceCount": 63,
            "citationCount": 498,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fgene.2018.00515/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-06",
            "journal": {
                "name": "Frontiers in Genetics",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Zou2018PredictingDM,\n author = {Q. Zou and Kaiyang Qu and Ya-ling Luo and Dehui Yin and Y. Ju and Hua Tang},\n booktitle = {Frontiers in Genetics},\n journal = {Frontiers in Genetics},\n title = {Predicting Diabetes Mellitus With Machine Learning Techniques},\n volume = {9},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eef183687fab4d762a381f2e80e357e08e923f0a",
            "@type": "ScholarlyArticle",
            "paperId": "eef183687fab4d762a381f2e80e357e08e923f0a",
            "corpusId": 49529756,
            "url": "https://www.semanticscholar.org/paper/eef183687fab4d762a381f2e80e357e08e923f0a",
            "title": "Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2902240649",
                "ArXiv": "1811.12808",
                "DBLP": "journals/corr/abs-1811-12808",
                "CorpusId": 49529756
            },
            "abstract": "The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.",
            "referenceCount": 36,
            "citationCount": 553,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-11-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1811.12808"
            },
            "citationStyles": {
                "bibtex": "@Article{Raschka2018ModelEM,\n author = {S. Raschka},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning},\n volume = {abs/1811.12808},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d5125164c7fec457d1442cce807a3436841715d0",
            "@type": "ScholarlyArticle",
            "paperId": "d5125164c7fec457d1442cce807a3436841715d0",
            "corpusId": 46867148,
            "url": "https://www.semanticscholar.org/paper/d5125164c7fec457d1442cce807a3436841715d0",
            "title": "Machine Learning Approaches for Clinical Psychology and Psychiatry.",
            "venue": "Annual Review of Clinical Psychology",
            "publicationVenue": {
                "id": "urn:research:859022e2-49ca-45d4-8e43-0fa45d44e934",
                "name": "Annual Review of Clinical Psychology",
                "alternate_names": [
                    "Annu Rev Clin Psychol"
                ],
                "issn": "1548-5943",
                "url": "https://www.annualreviews.org/journal/clinpsy"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2787427645",
                "DOI": "10.1146/annurev-clinpsy-032816-045037",
                "CorpusId": 46867148,
                "PubMed": "29401044"
            },
            "abstract": "Machine learning approaches for clinical psychology and psychiatry explicitly focus on learning statistical functions from multidimensional data sets to make generalizable predictions about individuals. The goal of this review is to provide an accessible understanding of why this approach is important for future practice given its potential to augment decisions associated with the diagnosis, prognosis, and treatment of people suffering from mental illness using clinical and biological data. To this end, the limitations of current statistical paradigms in mental health research are critiqued, and an introduction is provided to critical machine learning methods used in clinical studies. A selective literature review is then presented aiming to reinforce the usefulness of machine learning methods and provide evidence of their potential. In the context of promising initial results, the current limitations of machine learning approaches are addressed, and considerations for future clinical translation are outlined.",
            "referenceCount": 0,
            "citationCount": 466,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-05-07",
            "journal": {
                "name": "Annual review of clinical psychology",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Dwyer2018MachineLA,\n author = {D. Dwyer and P. Falkai and N. Koutsouleris},\n booktitle = {Annual Review of Clinical Psychology},\n journal = {Annual review of clinical psychology},\n pages = {\n          91-118\n        },\n title = {Machine Learning Approaches for Clinical Psychology and Psychiatry.},\n volume = {14},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:64f6dab6b4bcf5cd792e352ea15aeca05572e21e",
            "@type": "ScholarlyArticle",
            "paperId": "64f6dab6b4bcf5cd792e352ea15aeca05572e21e",
            "corpusId": 88515435,
            "url": "https://www.semanticscholar.org/paper/64f6dab6b4bcf5cd792e352ea15aeca05572e21e",
            "title": "Tunability: Importance of Hyperparameters of Machine Learning Algorithms",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/jmlr/ProbstBB19",
                "ArXiv": "1802.09596",
                "MAG": "2964284859",
                "CorpusId": 88515435
            },
            "abstract": "Modern supervised machine learning algorithms involve hyperparameters that have to be set before running them. Options for setting hyperparameters are default values from the software package, manual configuration by the user or configuring them for optimal predictive performance by a tuning procedure. The goal of this paper is two-fold. Firstly, we formalize the problem of tuning from a statistical point of view, define data-based defaults and suggest general measures quantifying the tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale benchmarking study based on 38 datasets from the OpenML platform and six common machine learning algorithms. We apply our measures to assess the tunability of their parameters. Our results yield default values for hyperparameters and enable users to decide whether it is worth conducting a possibly time consuming tuning strategy, to focus on the most important hyperparameters and to chose adequate hyperparameter spaces for tuning.",
            "referenceCount": 36,
            "citationCount": 408,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-26",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Probst2018TunabilityIO,\n author = {Philipp Probst and A. Boulesteix and B. Bischl},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {53:1-53:32},\n title = {Tunability: Importance of Hyperparameters of Machine Learning Algorithms},\n volume = {20},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f5476c9629f8093e8ba8c6a41868415c6a7f2f1",
            "@type": "ScholarlyArticle",
            "paperId": "0f5476c9629f8093e8ba8c6a41868415c6a7f2f1",
            "corpusId": 3423242,
            "url": "https://www.semanticscholar.org/paper/0f5476c9629f8093e8ba8c6a41868415c6a7f2f1",
            "title": "Stealing Hyperparameters in Machine Learning",
            "venue": "IEEE Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:29b9c461-963e-4d11-b2ab-92c182243942",
                "name": "IEEE Symposium on Security and Privacy",
                "alternate_names": [
                    "S&P",
                    "IEEE Symp Secur Priv"
                ],
                "issn": null,
                "url": "http://www.ieee-security.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963844355",
                "DBLP": "conf/sp/WangG18",
                "ArXiv": "1802.05351",
                "DOI": "10.1109/SP.2018.00038",
                "CorpusId": 3423242
            },
            "abstract": "Hyperparameters are critical in machine learning, as different hyperparameters often result in models with significantly different performance. Hyperparameters may be deemed confidential because of their commercial value and the confidentiality of the proprietary algorithms that the learner uses to learn them. In this work, we propose attacks on stealing the hyperparameters that are learned by a learner. We call our attacks hyperparameter stealing attacks. Our attacks are applicable to a variety of popular machine learning algorithms such as ridge regression, logistic regression, support vector machine, and neural network. We evaluate the effectiveness of our attacks both theoretically and empirically. For instance, we evaluate our attacks on Amazon Machine Learning. Our results demonstrate that our attacks can accurately steal hyperparameters. We also study countermeasures. Our results highlight the need for new defenses against our hyperparameter stealing attacks for certain machine learning algorithms.",
            "referenceCount": 55,
            "citationCount": 386,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418595.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-14",
            "journal": {
                "name": "2018 IEEE Symposium on Security and Privacy (SP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2018StealingHI,\n author = {Binghui Wang and N. Gong},\n booktitle = {IEEE Symposium on Security and Privacy},\n journal = {2018 IEEE Symposium on Security and Privacy (SP)},\n pages = {36-52},\n title = {Stealing Hyperparameters in Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:730fba26faa7f91dc6742a0c3521eb439670a825",
            "@type": "ScholarlyArticle",
            "paperId": "730fba26faa7f91dc6742a0c3521eb439670a825",
            "corpusId": 128342395,
            "url": "https://www.semanticscholar.org/paper/730fba26faa7f91dc6742a0c3521eb439670a825",
            "title": "Machine-learning-guided directed evolution for protein engineering",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2938803199",
                "DOI": "10.1038/s41592-019-0496-6",
                "CorpusId": 128342395,
                "PubMed": "31308553"
            },
            "abstract": null,
            "referenceCount": 132,
            "citationCount": 539,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://authors.library.caltech.edu/97142/3/1811.10775.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-11-27",
            "journal": {
                "name": "Nature Methods",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2018MachinelearningguidedDE,\n author = {Kevin Kaichuang Yang and Zachary Wu and F. Arnold},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {687 - 694},\n title = {Machine-learning-guided directed evolution for protein engineering},\n volume = {16},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7d065e649e3bfc7d6d36166f50eab37b8404eae0",
            "@type": "ScholarlyArticle",
            "paperId": "7d065e649e3bfc7d6d36166f50eab37b8404eae0",
            "corpusId": 51721535,
            "url": "https://www.semanticscholar.org/paper/7d065e649e3bfc7d6d36166f50eab37b8404eae0",
            "title": "Interpretable Machine Learning in Healthcare",
            "venue": "IEEE International Conference on Healthcare Informatics",
            "publicationVenue": {
                "id": "urn:research:4c82b394-c401-4ce2-982e-7ab79de2bd24",
                "name": "IEEE International Conference on Healthcare Informatics",
                "alternate_names": [
                    "IEEE Int Conf Healthc Informatics",
                    "ICHI"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2883817443",
                "DBLP": "conf/bcb/AhmadET18",
                "DOI": "10.1145/3233547.3233667",
                "CorpusId": 51721535
            },
            "abstract": "This tutorial extensively covers the definitions, nuances, challenges, and requirements for the design of interpretable and explainable machine learning models and systems in healthcare. We discuss many uses in which interpretable machine learning models are needed in healthcare and how they should be deployed. Additionally, we explore the landscape of recent advances to address the challenges model interpretability in healthcare and also describe how one would go about choosing the right interpretable machine learnig algorithm for a given problem in healthcare.",
            "referenceCount": 47,
            "citationCount": 422,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference",
                "Review"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE International Conference on Healthcare Informatics (ICHI)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ahmad2018InterpretableML,\n author = {M. Ahmad and A. Teredesai and C. Eckert},\n booktitle = {IEEE International Conference on Healthcare Informatics},\n journal = {2018 IEEE International Conference on Healthcare Informatics (ICHI)},\n pages = {447-447},\n title = {Interpretable Machine Learning in Healthcare},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:920e561cee4fd4888212ed127d51aa09c02be6c3",
            "@type": "ScholarlyArticle",
            "paperId": "920e561cee4fd4888212ed127d51aa09c02be6c3",
            "corpusId": 202449518,
            "url": "https://www.semanticscholar.org/paper/920e561cee4fd4888212ed127d51aa09c02be6c3",
            "title": "Advances in Financial Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2968584812",
                "CorpusId": 202449518
            },
            "abstract": "Machine learning (ML) is changing virtually every aspect of our lives. Today ML algorithms accomplish tasks that until recently only expert humans could perform. As it relates to finance, this is the most exciting time to adopt a disruptive technology that will transform how everyone invests for generations. Readers will learn how to structure Big data in a way that is amenable to ML algorithms; how to conduct research with ML algorithms on that data; how to use supercomputing methods; how to backtest your discoveries while avoiding false positives. The book addresses real-life problems faced by practitioners on a daily basis, and explains scientifically sound solutions using math, supported by code and examples. Readers become active users who can test the proposed solutions in their particular setting. Written by a recognized expert and portfolio manager, this book will equip investment professionals with the groundbreaking tools needed to succeed in modern finance.",
            "referenceCount": 0,
            "citationCount": 224,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-02-02",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Prado2018AdvancesIF,\n author = {M. L. Prado},\n title = {Advances in Financial Machine Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca62b1904a4f3982b172c85204a588f494cb6a22",
            "@type": "ScholarlyArticle",
            "paperId": "ca62b1904a4f3982b172c85204a588f494cb6a22",
            "corpusId": 53109768,
            "url": "https://www.semanticscholar.org/paper/ca62b1904a4f3982b172c85204a588f494cb6a22",
            "title": "Taking Human out of Learning Applications: A Survey on Automated Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1810.13306",
                "CorpusId": 53109768
            },
            "abstract": "Machine learning techniques have deeply rooted in our everyday life. However, since it is knowledge- and labor-intensive to pursue good learning performance, human experts are heavily involved in every aspect of machine learning. In order to make machine learning techniques easier to apply and reduce the demand for experienced human experts, automated machine learning (AutoML) has emerged as a hot topic with both industrial and academic interest. In this paper, we provide an up to date survey on AutoML. First, we introduce and define the AutoML problem, with inspiration from both realms of automation and machine learning. Then, we propose a general AutoML framework that not only covers most existing approaches to date but also can guide the design for new methods. Subsequently, we categorize and review the existing works from two aspects, i.e., the problem setup and the employed techniques. Finally, we provide a detailed analysis of AutoML approaches and explain the reasons underneath their successful applications. We hope this survey can serve as not only an insightful guideline for AutoML beginners but also an inspiration for future research.",
            "referenceCount": 201,
            "citationCount": 338,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-10-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Yao2018TakingHO,\n author = {Quanming Yao and Mengshuo Wang and H. Escalante and Isabelle M Guyon and Yi-Qi Hu and Yu-Feng Li and Wei-Wei Tu and Qiang Yang and Yang Yu},\n title = {Taking Human out of Learning Applications: A Survey on Automated Machine Learning},\n year = {2018}\n}\n"
            }
        }
    }
]