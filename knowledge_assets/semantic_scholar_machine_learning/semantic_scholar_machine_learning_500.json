[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2e0e226f1f74ff65c0de3e5ad565bcd8b9710da",
            "@type": "ScholarlyArticle",
            "paperId": "e2e0e226f1f74ff65c0de3e5ad565bcd8b9710da",
            "corpusId": 51921962,
            "url": "https://www.semanticscholar.org/paper/e2e0e226f1f74ff65c0de3e5ad565bcd8b9710da",
            "title": "Adaptive Federated Learning in Resource Constrained Edge Computing Systems",
            "venue": "IEEE Journal on Selected Areas in Communications",
            "publicationVenue": {
                "id": "urn:research:68f20e73-515e-4c73-9cd5-5684926b45f7",
                "name": "IEEE Journal on Selected Areas in Communications",
                "alternate_names": [
                    "IEEE J Sel Area Commun"
                ],
                "issn": "0733-8716",
                "url": "http://www.comsoc.org/jsac/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952696465",
                "DBLP": "journals/jsac/WangTSLMHC19",
                "ArXiv": "1804.05271",
                "DOI": "10.1109/JSAC.2019.2904348",
                "CorpusId": 51921962
            },
            "abstract": "Emerging technologies and applications including Internet of Things, social networking, and crowd-sourcing generate large amounts of data at the network edge. Machine learning models are often built from the collected data, to enable the detection, classification, and prediction of future events. Due to bandwidth, storage, and privacy concerns, it is often impractical to send all the data to a centralized location. In this paper, we consider the problem of learning model parameters from data distributed across multiple edge nodes, without sending raw data to a centralized place. Our focus is on a generic class of machine learning models that are trained using gradient-descent-based approaches. We analyze the convergence bound of distributed gradient descent from a theoretical point of view, based on which we propose a control algorithm that determines the best tradeoff between local update and global parameter aggregation to minimize the loss function under a given resource budget. The performance of the proposed algorithm is evaluated via extensive experiments with real datasets, both on a networked prototype system and in a larger-scale simulated environment. The experimentation results show that our proposed approach performs near to the optimum with various machine learning models and different data distributions.",
            "referenceCount": 52,
            "citationCount": 1214,
            "influentialCitationCount": 100,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1804.05271",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-14",
            "journal": {
                "name": "IEEE Journal on Selected Areas in Communications",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2018AdaptiveFL,\n author = {Shiqiang Wang and Tiffany Tuor and T. Salonidis and K. Leung and C. Makaya and T. He and K. Chan},\n booktitle = {IEEE Journal on Selected Areas in Communications},\n journal = {IEEE Journal on Selected Areas in Communications},\n pages = {1205-1221},\n title = {Adaptive Federated Learning in Resource Constrained Edge Computing Systems},\n volume = {37},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bf8fe437f779f2098f9af82b534aa51dc9edb06f",
            "@type": "ScholarlyArticle",
            "paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f",
            "corpusId": 44131019,
            "url": "https://www.semanticscholar.org/paper/bf8fe437f779f2098f9af82b534aa51dc9edb06f",
            "title": "Scaling Neural Machine Translation",
            "venue": "Conference on Machine Translation",
            "publicationVenue": {
                "id": "urn:research:9aacb914-3edf-4e02-b8fe-5abf21c4d2ba",
                "name": "Conference on Machine Translation",
                "alternate_names": [
                    "WMT",
                    "Conf Mach Transl"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ACL": "W18-6301",
                "ArXiv": "1806.00187",
                "MAG": "2806311723",
                "DBLP": "journals/corr/abs-1806-00187",
                "DOI": "10.18653/v1/W18-6301",
                "CorpusId": 44131019
            },
            "abstract": "Sequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation. On WMT\u201914 English-German translation, we match the accuracy of Vaswani et al. (2017) in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT\u201914 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.",
            "referenceCount": 42,
            "citationCount": 570,
            "influentialCitationCount": 71,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/W18-6301.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.00187"
            },
            "citationStyles": {
                "bibtex": "@Article{Ott2018ScalingNM,\n author = {Myle Ott and Sergey Edunov and David Grangier and Michael Auli},\n booktitle = {Conference on Machine Translation},\n journal = {ArXiv},\n title = {Scaling Neural Machine Translation},\n volume = {abs/1806.00187},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c99179ca3784e3465fd9ed049d7f34b50d39393e",
            "@type": "ScholarlyArticle",
            "paperId": "c99179ca3784e3465fd9ed049d7f34b50d39393e",
            "corpusId": 49291826,
            "url": "https://www.semanticscholar.org/paper/c99179ca3784e3465fd9ed049d7f34b50d39393e",
            "title": "Ensemble learning: A survey",
            "venue": "WIREs Data Mining Knowl. Discov.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/widm/SagiR18",
                "MAG": "2789758093",
                "DOI": "10.1002/widm.1249",
                "CorpusId": 49291826
            },
            "abstract": "Ensemble methods are considered the state\u2010of\u2010the art solution for many machine learning challenges. Such methods improve the predictive performance of a single model by training multiple models and combining their predictions. This paper introduce the concept of ensemble learning, reviews traditional, novel and state\u2010of\u2010the\u2010art ensemble methods and discusses current challenges and trends in the field.",
            "referenceCount": 160,
            "citationCount": 1519,
            "influentialCitationCount": 47,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1249",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Sagi2018EnsembleLA,\n author = {Omer Sagi and L. Rokach},\n booktitle = {WIREs Data Mining Knowl. Discov.},\n journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},\n title = {Ensemble learning: A survey},\n volume = {8},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f6487d61ba6c2afa44be0e870599bb292e27638",
            "@type": "ScholarlyArticle",
            "paperId": "4f6487d61ba6c2afa44be0e870599bb292e27638",
            "corpusId": 14542723,
            "url": "https://www.semanticscholar.org/paper/4f6487d61ba6c2afa44be0e870599bb292e27638",
            "title": "Uncovering social spammers: social honeypots + machine learning",
            "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "publicationVenue": {
                "id": "urn:research:8dce23a9-44e0-4381-a39e-2acc1edff700",
                "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "alternate_names": [
                    "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "Int ACM SIGIR Conf Res Dev Inf Retr",
                    "SIGIR",
                    "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigir/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "1996802155",
                "DBLP": "conf/sigir/LeeCW10",
                "DOI": "10.1145/1835449.1835522",
                "CorpusId": 14542723
            },
            "abstract": "Web-based social systems enable new community-based opportunities for participants to engage, share, and interact. This community value and related services like search and advertising are threatened by spammers, content polluters, and malware disseminators. In an effort to preserve community value and ensure longterm success, we propose and evaluate a honeypot-based approach for uncovering social spammers in online social systems. Two of the key components of the proposed approach are: (1) The deployment of social honeypots for harvesting deceptive spam profiles from social networking communities; and (2) Statistical analysis of the properties of these spam profiles for creating spam classifiers to actively filter out existing and new spammers. We describe the conceptual framework and design considerations of the proposed approach, and we present concrete observations from the deployment of social honeypots in MySpace and Twitter. We find that the deployed social honeypots identify social spammers with low false positive rates and that the harvested spam data contains signals that are strongly correlated with observable profile features (e.g., content, friend information, posting patterns, etc.). Based on these profile features, we develop machine learning based classifiers for identifying previously unknown spammers with high precision and a low rate of false positives.",
            "referenceCount": 28,
            "citationCount": 750,
            "influentialCitationCount": 52,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2010-07-19",
            "journal": {
                "name": "Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2010UncoveringSS,\n author = {Kyumin Lee and James Caverlee and Steve Webb},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval},\n title = {Uncovering social spammers: social honeypots + machine learning},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:87a22424c8995f2d6f65b49a3f59eb1b712e8ed7",
            "@type": "ScholarlyArticle",
            "paperId": "87a22424c8995f2d6f65b49a3f59eb1b712e8ed7",
            "corpusId": 37214152,
            "url": "https://www.semanticscholar.org/paper/87a22424c8995f2d6f65b49a3f59eb1b712e8ed7",
            "title": "Scaling up machine learning: parallel and distributed approaches",
            "venue": "KDD '11 Tutorials",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2009537245",
                "DOI": "10.1145/2107736.2107740",
                "CorpusId": 37214152
            },
            "abstract": "This tutorial gives a broad view of modern approaches for scaling up machine learning and data mining methods on parallel/distributed platforms. Demand for scaling up machine learning is task-specific: for some tasks it is driven by the enormous dataset sizes, for others by model complexity or by the requirement for real-time prediction. Selecting a task-appropriate parallelization platform and algorithm requires understanding their benefits, trade-offs and constraints. This tutorial focuses on providing an integrated overview of state-of-the-art platforms and algorithm choices. These span a range of hardware options (from FPGAs and GPUs to multi-core systems and commodity clusters), programming frameworks (including CUDA, MPI, MapReduce, and DryadLINQ), and learning settings (e.g., semi-supervised and online learning). The tutorial is example-driven, covering a number of popular algorithms (e.g., boosted trees, spectral clustering, belief propagation) and diverse applications (e.g., recommender systems and object recognition in vision).\n The tutorial is based on (but not limited to) the material from our upcoming Cambridge U. Press edited book which is currently in production.\n Visit the tutorial website at http://hunch.net/~large_scale_survey/",
            "referenceCount": 6,
            "citationCount": 428,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2011-08-21",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bekkerman2011ScalingUM,\n author = {R. Bekkerman and M. Bilenko and J. Langford},\n booktitle = {KDD '11 Tutorials},\n title = {Scaling up machine learning: parallel and distributed approaches},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4e55e4f5352d843bcf71a046b211dc72d0da1e1c",
            "@type": "ScholarlyArticle",
            "paperId": "4e55e4f5352d843bcf71a046b211dc72d0da1e1c",
            "corpusId": 6050316,
            "url": "https://www.semanticscholar.org/paper/4e55e4f5352d843bcf71a046b211dc72d0da1e1c",
            "title": "Human Decisions and Machine Predictions",
            "venue": "Quarterly Journal of Economics",
            "publicationVenue": {
                "id": "urn:research:4ef064ce-f0c1-4f08-89e1-9cf2e2df44b7",
                "name": "Quarterly Journal of Economics",
                "alternate_names": [
                    "Q J Econ"
                ],
                "issn": "0033-5533",
                "url": "https://www.jstor.org/journal/quarjecon"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2551317447",
                "DOI": "10.1093/qje/qjx032",
                "CorpusId": 6050316,
                "PubMed": "29755141"
            },
            "abstract": "Can machine learning improve human decision making? Bail decisions provide a good test case. Millions of times each year, judges make jail-or-release decisions that hinge on a prediction of what a defendant would do if released. The concreteness of the prediction task combined with the volume of data available makes this a promising machine-learning application. Yet comparing the algorithm to judges proves complicated. First, the available data are generated by prior judge decisions. We only observe crime outcomes for released defendants, not for those judges detained. This makes it hard to evaluate counterfactual decision rules based on algorithmic predictions. Second, judges may have a broader set of preferences than the variable the algorithm predicts; for instance, judges may care specifically about violent crimes or about racial inequities. We deal with these problems using different econometric strategies, such as quasi-random assignment of cases to judges. Even accounting for these concerns, our results suggest potentially large welfare gains: one policy simulation shows crime reductions up to 24.7% with no change in jailing rates, or jailing rate reductions up to 41.9% with no increase in crime rates. Moreover, all categories of crime, including violent crimes, show reductions; and these gains can be achieved while simultaneously reducing racial disparities. These results suggest that while machine learning can be valuable, realizing this value requires integrating these tools into an economic framework: being clear about the link between predictions and decisions; specifying the scope of payoff functions; and constructing unbiased decision counterfactuals. JEL Codes: C10 (Econometric and statistical methods and methodology), C55 (Large datasets: Modeling and analysis), K40 (Legal procedure, the legal system, and illegal behavior).",
            "referenceCount": 68,
            "citationCount": 822,
            "influentialCitationCount": 64,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nber.org/system/files/working_papers/w23180/w23180.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Economics",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Economics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Law",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-01",
            "journal": {
                "name": "Economics of Networks eJournal",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kleinberg2017HumanDA,\n author = {J. Kleinberg and Himabindu Lakkaraju and J. Leskovec and J. Ludwig and S. Mullainathan},\n booktitle = {Quarterly Journal of Economics},\n journal = {Economics of Networks eJournal},\n title = {Human Decisions and Machine Predictions},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d8d74c7fd9375b17e9d6123773919b2aa512c56",
            "@type": "ScholarlyArticle",
            "paperId": "2d8d74c7fd9375b17e9d6123773919b2aa512c56",
            "corpusId": 56177573,
            "url": "https://www.semanticscholar.org/paper/2d8d74c7fd9375b17e9d6123773919b2aa512c56",
            "title": "U-Net: deep learning for cell counting, detection, and morphometry",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2900936384",
                "DOI": "10.1038/s41592-018-0261-2",
                "CorpusId": 56177573,
                "PubMed": "30559429"
            },
            "abstract": null,
            "referenceCount": 14,
            "citationCount": 1186,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-17",
            "journal": {
                "name": "Nature Methods",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Falk2018UNetDL,\n author = {Thorsten Falk and Dominic Mai and R. Bensch and \u00d6zg\u00fcn \u00c7i\u00e7ek and A. Abdulkadir and Yassine Marrakchi and Anton B\u00f6hm and Jan Deubner and Zoe J\u00e4ckel and Katharina Seiwald and A. Dovzhenko and O. Tietz and C. Dal Bosco and Sean Walsh and Deniz Saltukoglu and Tuan Leng Tay and M. Prinz and K. Palme and M. Simons and I. Diester and T. Brox and O. Ronneberger},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {67 - 70},\n title = {U-Net: deep learning for cell counting, detection, and morphometry},\n volume = {16},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6c10262a5d4230c7c85fbe528b8bbd9444116bca",
            "@type": "ScholarlyArticle",
            "paperId": "6c10262a5d4230c7c85fbe528b8bbd9444116bca",
            "corpusId": 14135833,
            "url": "https://www.semanticscholar.org/paper/6c10262a5d4230c7c85fbe528b8bbd9444116bca",
            "title": "Finding Density Functionals with Machine Learning",
            "venue": "Physical Review Letters",
            "publicationVenue": {
                "id": "urn:research:16c9f9d4-bee1-435d-8c85-22a3deba109d",
                "name": "Physical Review Letters",
                "alternate_names": [
                    "Phys Rev Lett"
                ],
                "issn": "0031-9007",
                "url": "https://journals.aps.org/prl/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2752791407",
                "ArXiv": "1112.5441",
                "DBLP": "journals/corr/abs-1112-5441",
                "DOI": "10.1103/PhysRevLett.108.253002",
                "CorpusId": 14135833,
                "PubMed": "23004593"
            },
            "abstract": "Machine learning is used to approximate density functionals. For the model problem of the kinetic energy of noninteracting fermions in 1D, mean absolute errors below 1 kcal/mol on test densities similar to the training set are reached with fewer than 100 training densities. A predictor identifies if a test density is within the interpolation region. Via principal component analysis, a projected functional derivative finds highly accurate self-consistent densities. The challenges for application of our method to real electronic structure problems are discussed.",
            "referenceCount": 21,
            "citationCount": 431,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.aps.org/accepted/10.1103/PhysRevLett.108.253002",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-12-22",
            "journal": {
                "name": "Physical review letters",
                "volume": "108 25"
            },
            "citationStyles": {
                "bibtex": "@Article{Snyder2011FindingDF,\n author = {John C. Snyder and M. Rupp and K. Hansen and K. M\u00fcller and K. Burke},\n booktitle = {Physical Review Letters},\n journal = {Physical review letters},\n pages = {\n          253002\n        },\n title = {Finding Density Functionals with Machine Learning},\n volume = {108 25},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
            "@type": "ScholarlyArticle",
            "paperId": "3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
            "corpusId": 1348207,
            "url": "https://www.semanticscholar.org/paper/3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
            "title": "Supplementary for: Deep learning with convolutional neural networks for EEG decoding and visualization",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "CorpusId": 1348207
            },
            "abstract": "Translational Neurotechnology Lab, Epilepsy Center, Medical Center \u2013 University of Freiburg, Engelberger Str. 21, 79106 Freiburg, Germany BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-K\u00f6hler-Allee 79, 79110 Freiburg, Germany Machine Learning Lab, Computer Science Dept., University of Freiburg, Georges-K\u00f6hler-Allee 79, 79110 Freiburg, Germany Neurobiology and Biophysics, Faculty of Biology, University of Freiburg, Hansastr. 9a, 79104 Freiburg, Germany Machine Learning for Automated Algorithm Design Lab, Computer Science Dept., University of Freiburg, Georges-K\u00f6hler-Allee 52, 79110 Freiburg im Breisgau, Germany Brain State Decoding Lab, Computer Science Dept., University of Freiburg, Albertstr. 23, 79104 Freiburg, Germany Autonomous Intelligent Systems Lab, Computer Science Dept., University of Freiburg, Georges-K\u00f6hler-Allee 79, 79110 Freiburg, Germany",
            "referenceCount": 37,
            "citationCount": 1600,
            "influentialCitationCount": 289,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Schirrmeister2017SupplementaryFD,\n author = {R. Schirrmeister and J. T. Springenberg and L. Fiederer and Martin Glasstetter and Katharina Eggensperger and M. Tangermann and F. Hutter and Wolfram Burgard and T. Ball},\n title = {Supplementary for: Deep learning with convolutional neural networks for EEG decoding and visualization},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:edb4643a71d734543fa4ae3cdf7a89177c5e9ebe",
            "@type": "ScholarlyArticle",
            "paperId": "edb4643a71d734543fa4ae3cdf7a89177c5e9ebe",
            "corpusId": 11227964,
            "url": "https://www.semanticscholar.org/paper/edb4643a71d734543fa4ae3cdf7a89177c5e9ebe",
            "title": "Introduction to machine learning for brain imaging",
            "venue": "NeuroImage",
            "publicationVenue": {
                "id": "urn:research:fd4c7628-c16e-4b50-8555-3ac3ad6da2d7",
                "name": "NeuroImage",
                "alternate_names": null,
                "issn": "1053-8119",
                "url": "http://www.elsevier.com/locate/ynimg"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "journals/neuroimage/LemmBDM11",
                "MAG": "2072735345",
                "DOI": "10.1016/j.neuroimage.2010.11.004",
                "CorpusId": 11227964,
                "PubMed": "21172442"
            },
            "abstract": null,
            "referenceCount": 136,
            "citationCount": 609,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2011-05-15",
            "journal": {
                "name": "NeuroImage",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Lemm2011IntroductionTM,\n author = {S. Lemm and B. Blankertz and T. Dickhaus and K. M\u00fcller},\n booktitle = {NeuroImage},\n journal = {NeuroImage},\n pages = {387-399},\n title = {Introduction to machine learning for brain imaging},\n volume = {56},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:727f14e94f33f7bf9d1fa9d3d4649cc828a30ba6",
            "@type": "ScholarlyArticle",
            "paperId": "727f14e94f33f7bf9d1fa9d3d4649cc828a30ba6",
            "corpusId": 29605054,
            "url": "https://www.semanticscholar.org/paper/727f14e94f33f7bf9d1fa9d3d4649cc828a30ba6",
            "title": "Intrusion detection by machine learning: A review",
            "venue": "Expert systems with applications",
            "publicationVenue": {
                "id": "urn:research:987139ae-a65d-49bb-aaf6-fb764dc40b19",
                "name": "Expert systems with applications",
                "alternate_names": [
                    "Expert syst appl",
                    "Expert Systems With Applications",
                    "Expert Syst Appl"
                ],
                "issn": "0957-4174",
                "url": "https://www.journals.elsevier.com/expert-systems-with-applications/"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "journals/eswa/TsaiHLL09",
                "MAG": "2101109743",
                "DOI": "10.1016/j.eswa.2009.05.029",
                "CorpusId": 29605054
            },
            "abstract": null,
            "referenceCount": 77,
            "citationCount": 912,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2009-12-01",
            "journal": {
                "name": "Expert Syst. Appl.",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Tsai2009IntrusionDB,\n author = {Chih-Fong Tsai and Yu-Feng Hsu and Chia-Ying Lin and Wei-Yang Lin},\n booktitle = {Expert systems with applications},\n journal = {Expert Syst. Appl.},\n pages = {11994-12000},\n title = {Intrusion detection by machine learning: A review},\n volume = {36},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
            "@type": "ScholarlyArticle",
            "paperId": "2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
            "corpusId": 10694510,
            "url": "https://www.semanticscholar.org/paper/2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
            "title": "Deep learning for sentiment analysis: A survey",
            "venue": "WIREs Data Mining Knowl. Discov.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2784772534",
                "DBLP": "journals/corr/abs-1801-07883",
                "ArXiv": "1801.07883",
                "DOI": "10.1002/widm.1253",
                "CorpusId": 10694510
            },
            "abstract": "Deep learning has emerged as a powerful machine learning technique that learns multiple layers of representations or features of the data and produces state\u2010of\u2010the\u2010art prediction results. Along with the success of deep learning in many application domains, deep learning is also used in sentiment analysis in recent years. This paper gives an overview of deep learning and then provides a comprehensive survey of its current applications in sentiment analysis.",
            "referenceCount": 149,
            "citationCount": 1268,
            "influentialCitationCount": 48,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1253",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-01-24",
            "journal": {
                "name": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018DeepLF,\n author = {Lei Zhang and Shuai Wang and B. Liu},\n booktitle = {WIREs Data Mining Knowl. Discov.},\n journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},\n title = {Deep learning for sentiment analysis: A survey},\n volume = {8},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90972e7394b5fc884470cf78a657aae3932a8d8a",
            "@type": "ScholarlyArticle",
            "paperId": "90972e7394b5fc884470cf78a657aae3932a8d8a",
            "corpusId": 9745068,
            "url": "https://www.semanticscholar.org/paper/90972e7394b5fc884470cf78a657aae3932a8d8a",
            "title": "Using Machine Learning to Detect Cyberbullying",
            "venue": "2011 10th International Conference on Machine Learning and Applications and Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "conf/icmla/ReynoldsKE11",
                "MAG": "2034757259",
                "DOI": "10.1109/ICMLA.2011.152",
                "CorpusId": 9745068
            },
            "abstract": "Cyber bullying is the use of technology as a medium to bully someone. Although it has been an issue for many years, the recognition of its impact on young people has recently increased. Social networking sites provide a fertile medium for bullies, and teens and young adults who use these sites are vulnerable to attacks. Through machine learning, we can detect language patterns used by bullies and their victims, and develop rules to automatically detect cyber bullying content. The data we used for our project was collected from the website Formspring.me, a question-and-answer formatted website that contains a high percentage of bullying content. The data was labeled using a web service, Amazon's Mechanical Turk. We used the labeled data, in conjunction with machine learning techniques provided by the Weka tool kit, to train a computer to recognize bullying content. Both a C4.5 decision tree learner and an instance-based learner were able to identify the true positives with 78.5% accuracy.",
            "referenceCount": 17,
            "citationCount": 388,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://webpages.ursinus.edu/akontostathis/ReynoldsKontostathisEdwardsFINAL.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-12-18",
            "journal": {
                "name": "2011 10th International Conference on Machine Learning and Applications and Workshops",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Reynolds2011UsingML,\n author = {Kelly Reynolds and April Kontostathis and Lynne Edwards},\n booktitle = {2011 10th International Conference on Machine Learning and Applications and Workshops},\n journal = {2011 10th International Conference on Machine Learning and Applications and Workshops},\n pages = {241-244},\n title = {Using Machine Learning to Detect Cyberbullying},\n volume = {2},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:02ccfc9b550d381b5df4365a2ae48bb5f7f7578e",
            "@type": "ScholarlyArticle",
            "paperId": "02ccfc9b550d381b5df4365a2ae48bb5f7f7578e",
            "corpusId": 3846544,
            "url": "https://www.semanticscholar.org/paper/02ccfc9b550d381b5df4365a2ae48bb5f7f7578e",
            "title": "Noise2Noise: Learning Image Restoration without Clean Data",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1803.04189",
                "MAG": "2793146153",
                "DBLP": "journals/corr/abs-1803-04189",
                "CorpusId": 3846544
            },
            "abstract": "We apply basic statistical reasoning to signal reconstruction by machine learning -- learning to map corrupted observations to clean signals -- with a simple and powerful conclusion: under certain common circumstances, it is possible to learn to restore signals without ever observing clean ones, at performance close or equal to training using clean exemplars. We show applications in photographic noise removal, denoising of synthetic Monte Carlo images, and reconstruction of MRI scans from undersampled inputs, all based on only observing corrupted data.",
            "referenceCount": 28,
            "citationCount": 1145,
            "influentialCitationCount": 228,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.04189"
            },
            "citationStyles": {
                "bibtex": "@Article{Lehtinen2018Noise2NoiseLI,\n author = {J. Lehtinen and Jacob Munkberg and J. Hasselgren and S. Laine and Tero Karras and M. Aittala and Timo Aila},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Noise2Noise: Learning Image Restoration without Clean Data},\n volume = {abs/1803.04189},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
            "@type": "ScholarlyArticle",
            "paperId": "da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
            "corpusId": 6318455,
            "url": "https://www.semanticscholar.org/paper/da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
            "title": "Deep Bayesian Active Learning with Image Data",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/GalIG17",
                "MAG": "2951786554",
                "ArXiv": "1703.02910",
                "DOI": "10.17863/CAM.11070",
                "CorpusId": 6318455
            },
            "abstract": "Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).",
            "referenceCount": 43,
            "citationCount": 1334,
            "influentialCitationCount": 198,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.02910"
            },
            "citationStyles": {
                "bibtex": "@Article{Gal2017DeepBA,\n author = {Y. Gal and Riashat Islam and Zoubin Ghahramani},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Deep Bayesian Active Learning with Image Data},\n volume = {abs/1703.02910},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c2a7afbb5609a723f8eea91bfde4b02579b048d6",
            "@type": "ScholarlyArticle",
            "paperId": "c2a7afbb5609a723f8eea91bfde4b02579b048d6",
            "corpusId": 3515219,
            "url": "https://www.semanticscholar.org/paper/c2a7afbb5609a723f8eea91bfde4b02579b048d6",
            "title": "Unsupervised Neural Machine Translation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2962824887",
                "DBLP": "conf/iclr/ArtetxeLAC18",
                "ArXiv": "1710.11041",
                "CorpusId": 3515219
            },
            "abstract": "In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French-to-English and German-to-English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our implementation is released as an open source project.",
            "referenceCount": 38,
            "citationCount": 708,
            "influentialCitationCount": 151,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.11041"
            },
            "citationStyles": {
                "bibtex": "@Article{Artetxe2017UnsupervisedNM,\n author = {Mikel Artetxe and Gorka Labaka and Eneko Agirre and Kyunghyun Cho},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Unsupervised Neural Machine Translation},\n volume = {abs/1710.11041},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d5b8b4bffc457150310dd3713241310a7f5c6165",
            "@type": "ScholarlyArticle",
            "paperId": "d5b8b4bffc457150310dd3713241310a7f5c6165",
            "corpusId": 4336217,
            "url": "https://www.semanticscholar.org/paper/d5b8b4bffc457150310dd3713241310a7f5c6165",
            "title": "SystemML: Declarative machine learning on MapReduce",
            "venue": "IEEE International Conference on Data Engineering",
            "publicationVenue": {
                "id": "urn:research:764e3630-ddac-4c21-af4b-9d32ffef082e",
                "name": "IEEE International Conference on Data Engineering",
                "alternate_names": [
                    "ICDE",
                    "Int Conf Data Eng",
                    "IEEE Int Conf Data Eng",
                    "International Conference on Data Engineering"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=1331"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "conf/icde/GhotingKPRSTTV11",
                "MAG": "2102458936",
                "DOI": "10.1109/ICDE.2011.5767930",
                "CorpusId": 4336217
            },
            "abstract": "MapReduce is emerging as a generic parallel programming paradigm for large clusters of machines. This trend combined with the growing need to run machine learning (ML) algorithms on massive datasets has led to an increased interest in implementing ML algorithms on MapReduce. However, the cost of implementing a large class of ML algorithms as low-level MapReduce jobs on varying data and machine cluster sizes can be prohibitive. In this paper, we propose SystemML in which ML algorithms are expressed in a higher-level language and are compiled and executed in a MapReduce environment. This higher-level language exposes several constructs including linear algebra primitives that constitute key building blocks for a broad class of supervised and unsupervised ML algorithms. The algorithms expressed in SystemML are compiled and optimized into a set of MapReduce jobs that can run on a cluster of machines. We describe and empirically evaluate a number of optimization strategies for efficiently executing these algorithms on Hadoop, an open-source MapReduce implementation. We report an extensive performance evaluation on three ML algorithms on varying data and cluster sizes.",
            "referenceCount": 23,
            "citationCount": 316,
            "influentialCitationCount": 40,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-04-11",
            "journal": {
                "name": "2011 IEEE 27th International Conference on Data Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ghoting2011SystemMLDM,\n author = {A. Ghoting and R. Krishnamurthy and E. Pednault and B. Reinwald and Vikas Sindhwani and S. Tatikonda and Yuanyuan Tian and Shivakumar Vaithyanathan},\n booktitle = {IEEE International Conference on Data Engineering},\n journal = {2011 IEEE 27th International Conference on Data Engineering},\n pages = {231-242},\n title = {SystemML: Declarative machine learning on MapReduce},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:642c1b4a9da95ea4239708afc5929a5007a1870d",
            "@type": "ScholarlyArticle",
            "paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d",
            "corpusId": 3988816,
            "url": "https://www.semanticscholar.org/paper/642c1b4a9da95ea4239708afc5929a5007a1870d",
            "title": "Tensor2Tensor for Neural Machine Translation",
            "venue": "Conference of the Association for Machine Translation in the Americas",
            "publicationVenue": {
                "id": "urn:research:cd648e4a-f86b-4c14-8c82-0fc488d998ff",
                "name": "Conference of the Association for Machine Translation in the Americas",
                "alternate_names": [
                    "AMTA",
                    "Conf Assoc Mach Transl Am"
                ],
                "issn": null,
                "url": "http://www.amtaweb.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2950159712",
                "ACL": "W18-1819",
                "ArXiv": "1803.07416",
                "DBLP": "journals/corr/abs-1803-07416",
                "CorpusId": 3988816
            },
            "abstract": "Tensor2Tensor is a library for deep learning models that is well-suited for neural machine translation and includes the reference implementation of the state-of-the-art Transformer model.",
            "referenceCount": 21,
            "citationCount": 454,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vaswani2018Tensor2TensorFN,\n author = {Ashish Vaswani and Samy Bengio and E. Brevdo and Fran\u00e7ois Chollet and Aidan N. Gomez and Stephan Gouws and Llion Jones and Lukasz Kaiser and Nal Kalchbrenner and Niki Parmar and Ryan Sepassi and Noam M. Shazeer and Jakob Uszkoreit},\n booktitle = {Conference of the Association for Machine Translation in the Americas},\n pages = {193-199},\n title = {Tensor2Tensor for Neural Machine Translation},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cd49acefc8d51e324aa562e5337e1c2aff067053",
            "@type": "ScholarlyArticle",
            "paperId": "cd49acefc8d51e324aa562e5337e1c2aff067053",
            "corpusId": 90063862,
            "url": "https://www.semanticscholar.org/paper/cd49acefc8d51e324aa562e5337e1c2aff067053",
            "title": "An Overview of Multi-task Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2753709519",
                "DOI": "10.1093/NSR/NWX105",
                "CorpusId": 90063862
            },
            "abstract": "As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.",
            "referenceCount": 136,
            "citationCount": 1311,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/nsr/article-pdf/5/1/30/24164435/nwx105.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "National Science Review",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018AnOO,\n author = {Yu Zhang and Qiang Yang},\n journal = {National Science Review},\n pages = {30-43},\n title = {An Overview of Multi-task Learning},\n volume = {5},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
            "@type": "ScholarlyArticle",
            "paperId": "8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
            "corpusId": 115606413,
            "url": "https://www.semanticscholar.org/paper/8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
            "title": "A State-of-the-Art Survey on Deep Learning Theory and Architectures",
            "venue": "Electronics",
            "publicationVenue": {
                "id": "urn:research:ccd8e532-73c6-414f-bc91-271bbb2933e2",
                "name": "Electronics",
                "alternate_names": null,
                "issn": "1450-5843",
                "url": "http://www.electronics.etfbl.net/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2919358988",
                "DOI": "10.3390/ELECTRONICS8030292",
                "CorpusId": 115606413
            },
            "abstract": "In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning (DL), starting with the Deep Neural Network (DNN). The survey goes on to cover Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). Additionally, we have discussed recent developments, such as advanced variant DL techniques based on these DL approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on DL using neural networks and a survey on Reinforcement Learning (RL). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models.",
            "referenceCount": 272,
            "citationCount": 944,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2079-9292/8/3/292/pdf?version=1552274432",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-03-05",
            "journal": {
                "name": "Electronics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Alom2019ASS,\n author = {Md. Zahangir Alom and T. Taha and C. Yakopcic and Stefan Westberg and P. Sidike and M. S. Nasrin and Mahmudul Hasan and B. V. Van Essen and A. Awwal and V. Asari},\n booktitle = {Electronics},\n journal = {Electronics},\n title = {A State-of-the-Art Survey on Deep Learning Theory and Architectures},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a4ba0c1699965381fb2ba802157a89edd217943",
            "@type": "ScholarlyArticle",
            "paperId": "2a4ba0c1699965381fb2ba802157a89edd217943",
            "corpusId": 60906316,
            "url": "https://www.semanticscholar.org/paper/2a4ba0c1699965381fb2ba802157a89edd217943",
            "title": "Data Mining and Machine Learning in Cybersecurity",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "1530215515",
                "DOI": "10.1201/b10867",
                "CorpusId": 60906316
            },
            "abstract": "With the rapid advancement of information discovery techniques, machine learning and data mining continue to play a significant role in cybersecurity. Although several conferences, workshops, and journals focus on the fragmented research topics in this area, there has been no single interdisciplinary resource on past and current works and possible paths for future research in this area. This book fills this need. From basic concepts in machine learning and data mining to advanced problems in the machine learning domain, Data Mining and Machine Learning in Cybersecurity provides a unified reference for specific machine learning solutions to cybersecurity problems. It supplies a foundation in cybersecurity fundamentals and surveys contemporary challengesdetailing cutting-edge machine learning and data mining techniques. It also: Unveils cutting-edge techniques for detectingnew attacks Contains in-depth discussions of machine learning solutions to detection problems Categorizes methods for detecting, scanning, and profiling intrusions and anomalies Surveys contemporary cybersecurity problems and unveils state-of-the-art machine learning and data mining solutions Details privacy-preserving data mining methods This interdisciplinary resource includes technique review tables that allow for speedy access to common cybersecurity problems and associated data mining methods. Numerous illustrative figures help readers visualize the workflow of complex techniques and more than forty case studies provide a clear understanding of the design and application of data mining and machine learning techniques in cybersecurity.",
            "referenceCount": 0,
            "citationCount": 340,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2011-04-25",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dua2011DataMA,\n author = {S. Dua and Xian Du},\n title = {Data Mining and Machine Learning in Cybersecurity},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b87c0cf95208caacb025bf87d9ba451a87aacaca",
            "@type": "ScholarlyArticle",
            "paperId": "b87c0cf95208caacb025bf87d9ba451a87aacaca",
            "corpusId": 8292451,
            "url": "https://www.semanticscholar.org/paper/b87c0cf95208caacb025bf87d9ba451a87aacaca",
            "title": "Machine Health Monitoring Using Local Feature-Based Gated Recurrent Unit Networks",
            "venue": "IEEE transactions on industrial electronics (1982. Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2740570963",
                "DBLP": "journals/tie/ZhaoWYMSW18",
                "DOI": "10.1109/TIE.2017.2733438",
                "CorpusId": 8292451
            },
            "abstract": "In modern industries, machine health monitoring systems (MHMS) have been applied wildly with the goal of realizing predictive maintenance including failures tracking, downtime reduction, and assets preservation. In the era of big machinery data, data-driven MHMS have achieved remarkable results in the detection of faults after the occurrence of certain failures (diagnosis) and prediction of the future working conditions and the remaining useful life (prognosis). The numerical representation for raw sensory data is the key stone for various successful MHMS. Conventional methods are the labor-extensive as they usually depend on handcrafted features, which require expert knowledge. Inspired by the success of deep learning methods that redefine representation learning from raw data, we propose local feature-based gated recurrent unit (LFGRU) networks. It is a hybrid approach that combines handcrafted feature design with automatic feature learning for machine health monitoring. First, features from windows of input time series are extracted. Then, an enhanced bidirectional GRU network is designed and applied on the generated sequence of local features to learn the representation. A supervised learning layer is finally trained to predict machine condition. Experiments on three machine health monitoring tasks: tool wear prediction, gearbox fault diagnosis, and incipient bearing fault detection verify the effectiveness and generalization of the proposed LFGRU.",
            "referenceCount": 33,
            "citationCount": 538,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "IEEE Transactions on Industrial Electronics",
                "volume": "65"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2018MachineHM,\n author = {Rui Zhao and Dongzhe Wang and Ruqiang Yan and K. Mao and Fei Shen and Jinjiang Wang},\n booktitle = {IEEE transactions on industrial electronics (1982. Print)},\n journal = {IEEE Transactions on Industrial Electronics},\n pages = {1539-1548},\n title = {Machine Health Monitoring Using Local Feature-Based Gated Recurrent Unit Networks},\n volume = {65},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f308f4305a7295d89ca6d287c351ce117952a710",
            "@type": "ScholarlyArticle",
            "paperId": "f308f4305a7295d89ca6d287c351ce117952a710",
            "corpusId": 123988552,
            "url": "https://www.semanticscholar.org/paper/f308f4305a7295d89ca6d287c351ce117952a710",
            "title": "Machine Learning: The ingredients of machine learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2293582561",
                "DOI": "10.1017/CBO9780511973000.003",
                "CorpusId": 123988552
            },
            "abstract": "MACHINE LEARNING IS ALL ABOUT using the right features to build the right models that achieve the right tasks \u2013 this is the slogan, visualised in Figure 3 on p.11, with which we ended the Prologue. In essence, features define a \u2018language\u2019 in which we describe the relevant objects in our domain, be they e-mails or complex organic molecules. We should not normally have to go back to the domain objects themselves once we have a suitable feature representation, which is why features play such an important role in machine learning. We will take a closer look at them in Section 1.3. A task is an abstract representation of a problem we want to solve regarding those domain objects: the most common form of these is classifying them into two or more classes, but we shall encounter other tasks throughout the book. Many of these tasks can be represented as a mapping from data points to outputs. This mapping or model is itself produced as the output of a machine learning algorithm applied to training data; there is a wide variety of models to choose from, as we shall see in Section 1.2. We start this chapter by discussing tasks, the problems that can be solved with machine learning. No matter what variety of machine learning models you may encounter, you will find that they are designed to solve one of only a small number of tasks and use only a few different types of features.",
            "referenceCount": 0,
            "citationCount": 1,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-09-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Flach2012MachineLT,\n author = {P. Flach},\n pages = {13-48},\n title = {Machine Learning: The ingredients of machine learning},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:78989616eeeac55b202e3e4205225e7135054185",
            "@type": "ScholarlyArticle",
            "paperId": "78989616eeeac55b202e3e4205225e7135054185",
            "corpusId": 5224205,
            "url": "https://www.semanticscholar.org/paper/78989616eeeac55b202e3e4205225e7135054185",
            "title": "An Introduction to Deep Learning for the Physical Layer",
            "venue": "IEEE Transactions on Cognitive Communications and Networking",
            "publicationVenue": {
                "id": "urn:research:65e58b80-9699-4da6-bd60-929b57b8533d",
                "name": "IEEE Transactions on Cognitive Communications and Networking",
                "alternate_names": [
                    "IEEE Trans Cogn Commun Netw"
                ],
                "issn": "2332-7731",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6687307"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1702.00832",
                "MAG": "2950937143",
                "DBLP": "journals/tccn/OSheaH17",
                "DOI": "10.1109/TCCN.2017.2758370",
                "CorpusId": 5224205
            },
            "abstract": "We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. This paper is concluded with a discussion of open challenges and areas for future investigation.",
            "referenceCount": 78,
            "citationCount": 1807,
            "influentialCitationCount": 166,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1702.00832",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-02",
            "journal": {
                "name": "IEEE Transactions on Cognitive Communications and Networking",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{O'Shea2017AnIT,\n author = {Tim O'Shea and J. Hoydis},\n booktitle = {IEEE Transactions on Cognitive Communications and Networking},\n journal = {IEEE Transactions on Cognitive Communications and Networking},\n pages = {563-575},\n title = {An Introduction to Deep Learning for the Physical Layer},\n volume = {3},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ffe8872748d183d792c1b45aa5e4eb3b2116741",
            "@type": "ScholarlyArticle",
            "paperId": "6ffe8872748d183d792c1b45aa5e4eb3b2116741",
            "corpusId": 57140259,
            "url": "https://www.semanticscholar.org/paper/6ffe8872748d183d792c1b45aa5e4eb3b2116741",
            "title": "The immune system, adaptation, and machine learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1986,
            "externalIds": {
                "MAG": "2076526693",
                "DOI": "10.1016/0167-2789(81)90072-5",
                "CorpusId": 57140259
            },
            "abstract": null,
            "referenceCount": 22,
            "citationCount": 1417,
            "influentialCitationCount": 68,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1986-10-01",
            "journal": {
                "name": "Physica D: Nonlinear Phenomena",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Farmer1986TheIS,\n author = {J. Farmer and N. Packard and A. Perelson},\n journal = {Physica D: Nonlinear Phenomena},\n pages = {187-204},\n title = {The immune system, adaptation, and machine learning},\n volume = {2},\n year = {1986}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ecf6c42d84351f34e1625a6a2e4cc6526da45c74",
            "@type": "ScholarlyArticle",
            "paperId": "ecf6c42d84351f34e1625a6a2e4cc6526da45c74",
            "corpusId": 3215337,
            "url": "https://www.semanticscholar.org/paper/ecf6c42d84351f34e1625a6a2e4cc6526da45c74",
            "title": "Representation Learning on Graphs: Methods and Applications",
            "venue": "IEEE Data Engineering Bulletin",
            "publicationVenue": {
                "id": "urn:research:7bf8fd30-543b-48f6-bb8a-8c518006bdd2",
                "name": "IEEE Data Engineering Bulletin",
                "alternate_names": [
                    "IEEE Data Eng Bull"
                ],
                "issn": null,
                "url": "https://tc.computer.org/tcde/tcde-bulletin-issues/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1709-05584",
                "ArXiv": "1709.05584",
                "MAG": "2755092149",
                "CorpusId": 3215337
            },
            "abstract": "Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.",
            "referenceCount": 67,
            "citationCount": 1728,
            "influentialCitationCount": 166,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-09-17",
            "journal": {
                "name": "IEEE Data Eng. Bull.",
                "volume": "40"
            },
            "citationStyles": {
                "bibtex": "@Article{Hamilton2017RepresentationLO,\n author = {William L. Hamilton and Rex Ying and J. Leskovec},\n booktitle = {IEEE Data Engineering Bulletin},\n journal = {IEEE Data Eng. Bull.},\n pages = {52-74},\n title = {Representation Learning on Graphs: Methods and Applications},\n volume = {40},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
            "@type": "ScholarlyArticle",
            "paperId": "3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
            "corpusId": 38948903,
            "url": "https://www.semanticscholar.org/paper/3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
            "title": "Deep Learning with Python",
            "venue": "Apress",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2605516844",
                "DOI": "10.1007/978-1-4842-2766-4",
                "CorpusId": 38948903
            },
            "abstract": null,
            "referenceCount": 1,
            "citationCount": 1705,
            "influentialCitationCount": 171,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ketkar2017DeepLW,\n author = {Nikhil S. Ketkar},\n booktitle = {Apress},\n title = {Deep Learning with Python},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:71683e224ab91617950956b5005ed0439a733a71",
            "@type": "ScholarlyArticle",
            "paperId": "71683e224ab91617950956b5005ed0439a733a71",
            "corpusId": 2928017,
            "url": "https://www.semanticscholar.org/paper/71683e224ab91617950956b5005ed0439a733a71",
            "title": "Learning to learn by gradient descent by gradient descent",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1606.04474",
                "MAG": "2427497464",
                "DBLP": "conf/nips/AndrychowiczDCH16",
                "CorpusId": 2928017
            },
            "abstract": "The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.",
            "referenceCount": 43,
            "citationCount": 1739,
            "influentialCitationCount": 178,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Andrychowicz2016LearningTL,\n author = {Marcin Andrychowicz and Misha Denil and Sergio Gomez Colmenarejo and Matthew W. Hoffman and David Pfau and T. Schaul and Nando de Freitas},\n booktitle = {Neural Information Processing Systems},\n pages = {3981-3989},\n title = {Learning to learn by gradient descent by gradient descent},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5",
            "@type": "ScholarlyArticle",
            "paperId": "0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5",
            "corpusId": 1008003,
            "url": "https://www.semanticscholar.org/paper/0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5",
            "title": "A Review on Multi-Label Learning Algorithms",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/tkde/ZhangZ14",
                "MAG": "2114315281",
                "DOI": "10.1109/TKDE.2013.39",
                "CorpusId": 1008003
            },
            "abstract": "Multi-label learning studies the problem where each example is represented by a single instance while associated with a set of labels simultaneously. During the past decade, significant amount of progresses have been made toward this emerging machine learning paradigm. This paper aims to provide a timely review on this area with emphasis on state-of-the-art multi-label learning algorithms. Firstly, fundamentals on multi-label learning including formal definition and evaluation metrics are given. Secondly and primarily, eight representative multi-label learning algorithms are scrutinized under common notations with relevant analyses and discussions. Thirdly, several related learning settings are briefly summarized. As a conclusion, online resources and open research problems on multi-label learning are outlined for reference purposes.",
            "referenceCount": 199,
            "citationCount": 2454,
            "influentialCitationCount": 213,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-08-01",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2014ARO,\n author = {Min-Ling Zhang and Zhi-Hua Zhou},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {1819-1837},\n title = {A Review on Multi-Label Learning Algorithms},\n volume = {26},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:19de9ed920d9ed406274dd3595ef81e5e4398537",
            "@type": "ScholarlyArticle",
            "paperId": "19de9ed920d9ed406274dd3595ef81e5e4398537",
            "corpusId": 20185835,
            "url": "https://www.semanticscholar.org/paper/19de9ed920d9ed406274dd3595ef81e5e4398537",
            "title": "Transfer Learning",
            "venue": "Encyclopedia of Machine Learning and Data Mining",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "reference/ml/X17xq",
                "DOI": "10.1007/978-1-4899-7687-1_100487",
                "CorpusId": 20185835
            },
            "abstract": null,
            "referenceCount": 69,
            "citationCount": 390,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-11-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Pan2020TransferL,\n author = {Sinno Jialin Pan},\n booktitle = {Encyclopedia of Machine Learning and Data Mining},\n pages = {1342},\n title = {Transfer Learning},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63dc0896fd3fd7a6c40beff5beca638e778db4fc",
            "@type": "ScholarlyArticle",
            "paperId": "63dc0896fd3fd7a6c40beff5beca638e778db4fc",
            "corpusId": 14168355,
            "url": "https://www.semanticscholar.org/paper/63dc0896fd3fd7a6c40beff5beca638e778db4fc",
            "title": "OptiML: An Implicitly Parallel Domain-Specific Language for Machine Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "conf/icml/SujeethLBRCWAOO11",
                "MAG": "2240938131",
                "CorpusId": 14168355
            },
            "abstract": "As the size of datasets continues to grow, machine learning applications are becoming increasingly limited by the amount of available computational power. Taking advantage of modern hardware requires using multiple parallel programming models targeted at different devices (e.g. CPUs and GPUs). However, programming these devices to run efficiently and correctly is difficult, error-prone, and results in software that is harder to read and maintain. We present OptiML, a domain-specific language (DSL) for machine learning. OptiML is an implicitly parallel, expressive and high performance alternative to MATLAB and C++. OptiML performs domain-specific analyses and optimizations and automatically generates CUDA code for GPUs. We show that OptiML outperforms explicitly parallelized MATLAB code in nearly all cases.",
            "referenceCount": 15,
            "citationCount": 222,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-06-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sujeeth2011OptiMLAI,\n author = {Arvind K. Sujeeth and HyoukJoong Lee and Kevin J. Brown and Tiark Rompf and Hassan Chafi and Michael Wu and Anand R. Atreya and Martin Odersky and K. Olukotun},\n booktitle = {International Conference on Machine Learning},\n pages = {609-616},\n title = {OptiML: An Implicitly Parallel Domain-Specific Language for Machine Learning},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f34f684f7a4210db05a852da446e5aa3d8b0bd58",
            "@type": "ScholarlyArticle",
            "paperId": "f34f684f7a4210db05a852da446e5aa3d8b0bd58",
            "corpusId": 260444932,
            "url": "https://www.semanticscholar.org/paper/f34f684f7a4210db05a852da446e5aa3d8b0bd58",
            "title": "Adversarial Machine Learning",
            "venue": "IEEE Internet Computing",
            "publicationVenue": {
                "id": "urn:research:2e2fed97-17e5-488e-9efa-833a387a842d",
                "name": "IEEE Internet Computing",
                "alternate_names": [
                    "IEEE Internet Comput"
                ],
                "issn": "1089-7801",
                "url": "http://www.computer.org/internet/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "1974314988",
                "DBLP": "journals/internet/Tygar11",
                "DOI": "10.1109/MIC.2011.112",
                "CorpusId": 260444932
            },
            "abstract": "The author briefly introduces the emerging field of adversarial machine learning, in which opponents can cause traditional machine learning algorithms to behave poorly in security applications. He gives a high-level overview and mentions several types of attacks, as well as several types of defenses, and theoretical limits derived from a study of near-optimal evasion.",
            "referenceCount": 0,
            "citationCount": 183,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2011-09-01",
            "journal": {
                "name": "IEEE Internet Comput.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Tygar2011AdversarialML,\n author = {J. D. Tygar},\n booktitle = {IEEE Internet Computing},\n journal = {IEEE Internet Comput.},\n pages = {4-6},\n title = {Adversarial Machine Learning},\n volume = {15},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:37259f7132fc9dc604ab8211b85a20cf5bb559fe",
            "@type": "ScholarlyArticle",
            "paperId": "37259f7132fc9dc604ab8211b85a20cf5bb559fe",
            "corpusId": 20525271,
            "url": "https://www.semanticscholar.org/paper/37259f7132fc9dc604ab8211b85a20cf5bb559fe",
            "title": "A First Course in Machine Learning",
            "venue": "Chapman and Hall / CRC machine learning and pattern recognition series",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "books/daglib/0036858",
                "MAG": "1507957806",
                "DOI": "10.1201/9781466506299",
                "CorpusId": 20525271
            },
            "abstract": "A First Course in Machine Learning covers the core mathematical and statistical techniques needed to understand some of the most popular machine learning algorithms. The algorithms presented span the main problem areas within machine learning: classification, clustering and projection. The text gives detailed descriptions and derivations for a small number of algorithms rather than cover many algorithms in less detail. Referenced throughout the text and available on a supporting website (http://bit.ly/firstcourseml), an extensive collection of MATLAB/Octave scripts enables students to recreate plots that appear in the book and investigate changing model specifications and parameter values. By experimenting with the various algorithms and concepts, students see how an abstract set of equations can be used to solve real problems. Requiring minimal mathematical prerequisites, the classroom-tested material in this text offers a concise, accessible introduction to machine learning. It provides students with the knowledge and confidence to explore the machine learning literature and research specific methods in more detail.",
            "referenceCount": 0,
            "citationCount": 187,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2011-10-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Rogers2011AFC,\n author = {Simon Rogers and M. Girolami},\n booktitle = {Chapman and Hall / CRC machine learning and pattern recognition series},\n pages = {I-XX, 1-285},\n title = {A First Course in Machine Learning},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:35aebe08b34e5cb0d012a16563e5c3f6fd17a906",
            "@type": "ScholarlyArticle",
            "paperId": "35aebe08b34e5cb0d012a16563e5c3f6fd17a906",
            "corpusId": 208526865,
            "url": "https://www.semanticscholar.org/paper/35aebe08b34e5cb0d012a16563e5c3f6fd17a906",
            "title": "Federated Learning with Personalization Layers",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1912.00818",
                "DBLP": "journals/corr/abs-1912-00818",
                "MAG": "2990789643",
                "CorpusId": 208526865
            },
            "abstract": "The emerging paradigm of federated learning strives to enable collaborative training of machine learning models on the network edge without centrally aggregating raw data and hence, improving data privacy. This sharply deviates from traditional machine learning and necessitates the design of algorithms robust to various sources of heterogeneity. Specifically, statistical heterogeneity of data across user devices can severely degrade the performance of standard federated averaging for traditional machine learning applications like personalization with deep learning. This paper pro-posesFedPer, a base + personalization layer approach for federated training of deep feedforward neural networks, which can combat the ill-effects of statistical heterogeneity. We demonstrate effectiveness ofFedPerfor non-identical data partitions ofCIFARdatasetsand on a personalized image aesthetics dataset from Flickr.",
            "referenceCount": 21,
            "citationCount": 410,
            "influentialCitationCount": 69,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1912.00818"
            },
            "citationStyles": {
                "bibtex": "@Article{Arivazhagan2019FederatedLW,\n author = {Manoj Ghuhan Arivazhagan and V. Aggarwal and Aaditya Kumar Singh and Sunav Choudhary},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Federated Learning with Personalization Layers},\n volume = {abs/1912.00818},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ad66cba3b7e3abae7ef33122588512a146f7f77",
            "@type": "ScholarlyArticle",
            "paperId": "7ad66cba3b7e3abae7ef33122588512a146f7f77",
            "corpusId": 11311635,
            "url": "https://www.semanticscholar.org/paper/7ad66cba3b7e3abae7ef33122588512a146f7f77",
            "title": "A Survey on Multi-Task Learning",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ZhangY17aa",
                "ArXiv": "1707.08114",
                "MAG": "3141797743",
                "DOI": "10.1109/TKDE.2021.3070203",
                "CorpusId": 11311635
            },
            "abstract": "Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL from the perspective of algorithmic modeling, applications and theoretical analyses. For algorithmic modeling, we give a definition of MTL and then classify different MTL algorithms into five categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach and decomposition approach as well as discussing the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, we review online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works in this paper. Finally, we present theoretical analyses and discuss several future directions for MTL.",
            "referenceCount": 277,
            "citationCount": 1394,
            "influentialCitationCount": 87,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.08114",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-07-25",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2017ASO,\n author = {Yu Zhang and Qiang Yang},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {5586-5609},\n title = {A Survey on Multi-Task Learning},\n volume = {34},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:276194e96ebd620b5cff35a9168bdda39a0be57b",
            "@type": "ScholarlyArticle",
            "paperId": "276194e96ebd620b5cff35a9168bdda39a0be57b",
            "corpusId": 3586416,
            "url": "https://www.semanticscholar.org/paper/276194e96ebd620b5cff35a9168bdda39a0be57b",
            "title": "Federated Multi-Task Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951372312",
                "DBLP": "conf/nips/SmithCST17",
                "ArXiv": "1705.10467",
                "CorpusId": 3586416
            },
            "abstract": "Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices. In this work, we show that multi-task learning is naturally suited to handle the statistical challenges of this setting, and propose a novel systems-aware optimization method, MOCHA, that is robust to practical systems issues. Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. The resulting method achieves significant speedups compared to alternatives in the federated setting, as we demonstrate through simulations on real-world federated datasets.",
            "referenceCount": 57,
            "citationCount": 1235,
            "influentialCitationCount": 106,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Smith2017FederatedML,\n author = {Virginia Smith and Chao-Kai Chiang and Maziar Sanjabi and Ameet Talwalkar},\n booktitle = {Neural Information Processing Systems},\n pages = {4424-4434},\n title = {Federated Multi-Task Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3904315e2eca50d0086e4b7273f7fd707c652230",
            "@type": "ScholarlyArticle",
            "paperId": "3904315e2eca50d0086e4b7273f7fd707c652230",
            "corpusId": 6466088,
            "url": "https://www.semanticscholar.org/paper/3904315e2eca50d0086e4b7273f7fd707c652230",
            "title": "Meta-Learning with Memory-Augmented Neural Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/icml/SantoroBBWL16",
                "MAG": "2472819217",
                "CorpusId": 6466088
            },
            "abstract": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \"one-shot learning.\" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.",
            "referenceCount": 20,
            "citationCount": 1478,
            "influentialCitationCount": 81,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Santoro2016MetaLearningWM,\n author = {Adam Santoro and Sergey Bartunov and M. Botvinick and Daan Wierstra and T. Lillicrap},\n booktitle = {International Conference on Machine Learning},\n pages = {1842-1850},\n title = {Meta-Learning with Memory-Augmented Neural Networks},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:713a14e98f65a74652956dae94874eeab61a71cd",
            "@type": "ScholarlyArticle",
            "paperId": "713a14e98f65a74652956dae94874eeab61a71cd",
            "corpusId": 5882426,
            "url": "https://www.semanticscholar.org/paper/713a14e98f65a74652956dae94874eeab61a71cd",
            "title": "The changing science of machine learning",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2038507439",
                "DBLP": "journals/ml/Langley11",
                "DOI": "10.1007/s10994-011-5242-y",
                "CorpusId": 5882426
            },
            "abstract": null,
            "referenceCount": 12,
            "citationCount": 138,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10994-011-5242-y.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Sociology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-03-01",
            "journal": {
                "name": "Machine Learning",
                "volume": "82"
            },
            "citationStyles": {
                "bibtex": "@Article{Langley2011TheCS,\n author = {P. Langley},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {275-279},\n title = {The changing science of machine learning},\n volume = {82},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:04f4085c0126ba29453a582cd1e62e05c8e15c82",
            "@type": "ScholarlyArticle",
            "paperId": "04f4085c0126ba29453a582cd1e62e05c8e15c82",
            "corpusId": 349242,
            "url": "https://www.semanticscholar.org/paper/04f4085c0126ba29453a582cd1e62e05c8e15c82",
            "title": "Automating the Construction of Internet Portals with Machine Learning",
            "venue": "Information retrieval (Boston)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "journals/ir/McCallumNRS00",
                "MAG": "2162630660",
                "DOI": "10.1023/A:1009953814988",
                "CorpusId": 349242
            },
            "abstract": null,
            "referenceCount": 50,
            "citationCount": 1077,
            "influentialCitationCount": 181,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-07-21",
            "journal": {
                "name": "Information Retrieval",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{McCallum2000AutomatingTC,\n author = {A. McCallum and K. Nigam and Jason D. M. Rennie and K. Seymore},\n booktitle = {Information retrieval (Boston)},\n journal = {Information Retrieval},\n pages = {127-163},\n title = {Automating the Construction of Internet Portals with Machine Learning},\n volume = {3},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:856d5dcba4772328b8fb784494e3d41d39669b0d",
            "@type": "ScholarlyArticle",
            "paperId": "856d5dcba4772328b8fb784494e3d41d39669b0d",
            "corpusId": 3454285,
            "url": "https://www.semanticscholar.org/paper/856d5dcba4772328b8fb784494e3d41d39669b0d",
            "title": "Machine Theory of Mind",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icml/RabinowitzPSZEB18",
                "MAG": "2950112459",
                "ArXiv": "1802.07740",
                "CorpusId": 3454285
            },
            "abstract": "Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans' ability to represent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We design a Theory of Mind neural network -- a ToMnet -- which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' behaviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep reinforcement learning agents from varied populations, and that it passes classic ToM tasks such as the \"Sally-Anne\" test (Wimmer & Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system -- which autonomously learns how to model other agents in its world -- is an important step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advancing the progress on interpretable AI.",
            "referenceCount": 77,
            "citationCount": 346,
            "influentialCitationCount": 33,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.07740"
            },
            "citationStyles": {
                "bibtex": "@Article{Rabinowitz2018MachineTO,\n author = {Neil C. Rabinowitz and Frank Perbet and H. F. Song and Chiyuan Zhang and S. Eslami and M. Botvinick},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Machine Theory of Mind},\n volume = {abs/1802.07740},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd62a4d907ff9a98cd69926b7dd72cb980713715",
            "@type": "ScholarlyArticle",
            "paperId": "fd62a4d907ff9a98cd69926b7dd72cb980713715",
            "corpusId": 35132623,
            "url": "https://www.semanticscholar.org/paper/fd62a4d907ff9a98cd69926b7dd72cb980713715",
            "title": "Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources",
            "venue": "IEEE Geoscience and Remote Sensing Magazine",
            "publicationVenue": {
                "id": "urn:research:f3b9cfef-ea93-4f7f-a14f-95fbf796875e",
                "name": "IEEE Geoscience and Remote Sensing Magazine",
                "alternate_names": [
                    "IEEE Geosci Remote Sens Mag"
                ],
                "issn": "2168-6831",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6245518"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2782522152",
                "DOI": "10.1109/MGRS.2017.2762307",
                "CorpusId": 35132623
            },
            "abstract": "Central to the looming paradigm shift toward data-intensive science, machine-learning techniques are becoming increasingly important. In particular, deep learning has proven to be both a major breakthrough and an extremely powerful tool in many fields. Shall we embrace deep learning as the key to everything? Or should we resist a black-box solution? These are controversial issues within the remote-sensing community. In this article, we analyze the challenges of using deep learning for remote-sensing data analysis, review recent advances, and provide resources we hope will make deep learning in remote sensing seem ridiculously simple. More importantly, we encourage remote-sensing scientists to bring their expertise into deep learning and use it as an implicit general model to tackle unprecedented, large-scale, influential challenges, such as climate change and urbanization.",
            "referenceCount": 188,
            "citationCount": 1650,
            "influentialCitationCount": 46,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://cdr.lib.unc.edu/downloads/6969z593j",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2017-12-01",
            "journal": {
                "name": "IEEE Geoscience and Remote Sensing Magazine",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2017DeepLI,\n author = {Xiaoxiang Zhu and D. Tuia and Lichao Mou and Gui-Song Xia and Liangpei Zhang and Feng Xu and F. Fraundorfer},\n booktitle = {IEEE Geoscience and Remote Sensing Magazine},\n journal = {IEEE Geoscience and Remote Sensing Magazine},\n pages = {8-36},\n title = {Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources},\n volume = {5},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:208cd4b25768f0096fb2e80e7690473da0e2a563",
            "@type": "ScholarlyArticle",
            "paperId": "208cd4b25768f0096fb2e80e7690473da0e2a563",
            "corpusId": 29153681,
            "url": "https://www.semanticscholar.org/paper/208cd4b25768f0096fb2e80e7690473da0e2a563",
            "title": "Meta-learning with differentiable closed-form solvers",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952292344",
                "ArXiv": "1805.08136",
                "DBLP": "journals/corr/abs-1805-08136",
                "CorpusId": 29153681
            },
            "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures. Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.",
            "referenceCount": 72,
            "citationCount": 752,
            "influentialCitationCount": 191,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1805.08136"
            },
            "citationStyles": {
                "bibtex": "@Article{Bertinetto2018MetalearningWD,\n author = {Luca Bertinetto and Jo\u00e3o F. Henriques and Philip H. S. Torr and A. Vedaldi},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Meta-learning with differentiable closed-form solvers},\n volume = {abs/1805.08136},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "@type": "ScholarlyArticle",
            "paperId": "d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "corpusId": 115196194,
            "url": "https://www.semanticscholar.org/paper/d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "title": "Deep Learning Approach for Intelligent Intrusion Detection System",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2926701059",
                "DBLP": "journals/access/VinayakumarASPA19",
                "DOI": "10.1109/ACCESS.2019.2895334",
                "CorpusId": 115196194
            },
            "abstract": "Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01\u20130.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data by passing them into many hidden layers. Through a rigorous experimental testing, it is confirmed that DNNs perform well in comparison with the classical machine learning classifiers. Finally, we propose a highly scalable and hybrid DNNs framework called scale-hybrid-IDS-AlertNet which can be used in real-time to effectively monitor the network traffic and host-level events to proactively alert possible cyberattacks.",
            "referenceCount": 84,
            "citationCount": 795,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08681044.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-03",
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Vinayakumar2019DeepLA,\n author = {R. Vinayakumar and M. Alazab and K. Soman and P. Poornachandran and Ameer Al-Nemrat and S. Venkatraman},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {41525-41550},\n title = {Deep Learning Approach for Intelligent Intrusion Detection System},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ab4850b6151ca9a9337dbba94115bde342876d50",
            "@type": "ScholarlyArticle",
            "paperId": "ab4850b6151ca9a9337dbba94115bde342876d50",
            "corpusId": 1067591,
            "url": "https://www.semanticscholar.org/paper/ab4850b6151ca9a9337dbba94115bde342876d50",
            "title": "From machine learning to machine reasoning",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2952952750",
                "ArXiv": "1102.1808",
                "DBLP": "journals/corr/abs-1102-1808",
                "DOI": "10.1007/s10994-013-5335-x",
                "CorpusId": 1067591
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 255,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2Fs10994-013-5335-x.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-02-09",
            "journal": {
                "name": "Machine Learning",
                "volume": "94"
            },
            "citationStyles": {
                "bibtex": "@Article{Bottou2011FromML,\n author = {L. Bottou},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {133 - 149},\n title = {From machine learning to machine reasoning},\n volume = {94},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a0f17e0ee66ad5f50cd35932747e6a806ef03cf",
            "@type": "ScholarlyArticle",
            "paperId": "8a0f17e0ee66ad5f50cd35932747e6a806ef03cf",
            "corpusId": 14110875,
            "url": "https://www.semanticscholar.org/paper/8a0f17e0ee66ad5f50cd35932747e6a806ef03cf",
            "title": "Applications of Machine Learning in Cancer Prediction and Prognosis",
            "venue": "Cancer Informatics",
            "publicationVenue": {
                "id": "urn:research:9bb66e11-4952-4228-997b-bdf48fdc94d5",
                "name": "Cancer Informatics",
                "alternate_names": null,
                "issn": "1176-9351",
                "url": "http://la-press.com/journal.php?journal_id=10"
            },
            "year": 2006,
            "externalIds": {
                "PubMedCentral": "2675494",
                "MAG": "1651586605",
                "DOI": "10.1177/117693510600200030",
                "CorpusId": 14110875,
                "PubMed": "19458758"
            },
            "abstract": "Machine learning is a branch of artificial intelligence that employs a variety of statistical, probabilistic and optimization techniques that allows computers to \u201clearn\u201d from past examples and to detect hard-to-discern patterns from large, noisy or complex data sets. This capability is particularly well-suited to medical applications, especially those that depend on complex proteomic and genomic measurements. As a result, machine learning is frequently used in cancer diagnosis and detection. More recently machine learning has been applied to cancer prognosis and prediction. This latter approach is particularly interesting as it is part of a growing trend towards personalized, predictive medicine. In assembling this review we conducted a broad survey of the different types of machine learning methods being used, the types of data being integrated and the performance of these methods in cancer prediction and prognosis. A number of trends are noted, including a growing dependence on protein biomarkers and microarray data, a strong bias towards applications in prostate and breast cancer, and a heavy reliance on \u201colder\u201d technologies such artificial neural networks (ANNs) instead of more recently developed or more easily interpretable machine learning methods. A number of published studies also appear to lack an appropriate level of validation or testing. Among the better designed and validated studies it is clear that machine learning methods can be used to substantially (15\u201325%) improve the accuracy of predicting cancer susceptibility, recurrence and mortality. At a more fundamental level, it is also evident that machine learning is also helping to improve our basic understanding of cancer development and progression.",
            "referenceCount": 139,
            "citationCount": 1023,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journals.sagepub.com/doi/pdf/10.1177/117693510600200030",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2006-01-01",
            "journal": {
                "name": "Cancer Informatics",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Cruz2006ApplicationsOM,\n author = {Joseph A. Cruz and D. Wishart},\n booktitle = {Cancer Informatics},\n journal = {Cancer Informatics},\n pages = {59 - 77},\n title = {Applications of Machine Learning in Cancer Prediction and Prognosis},\n volume = {2},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ab0f0da686cd4094fd96f5a30e0b6072525fd09",
            "@type": "ScholarlyArticle",
            "paperId": "7ab0f0da686cd4094fd96f5a30e0b6072525fd09",
            "corpusId": 207614217,
            "url": "https://www.semanticscholar.org/paper/7ab0f0da686cd4094fd96f5a30e0b6072525fd09",
            "title": "Deep Learning in Medical Image Analysis.",
            "venue": "Annual Review of Biomedical Engineering",
            "publicationVenue": {
                "id": "urn:research:b1aef0b1-58ef-4dd9-aad5-2f40c42e19c4",
                "name": "Annual Review of Biomedical Engineering",
                "alternate_names": [
                    "Annu Rev Biomed Eng"
                ],
                "issn": "1523-9829",
                "url": "https://www.annualreviews.org/journal/bioeng"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2533800772",
                "DOI": "10.1146/annurev-bioeng-071516-044442",
                "CorpusId": 207614217,
                "PubMed": "28301734"
            },
            "abstract": "This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.",
            "referenceCount": 126,
            "citationCount": 1876,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-071516-044442",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-06-20",
            "journal": {
                "name": "Annual review of biomedical engineering",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Shen2017DeepLI,\n author = {D. Shen and Guorong Wu and Heung-Il Suk},\n booktitle = {Annual Review of Biomedical Engineering},\n journal = {Annual review of biomedical engineering},\n pages = {\n          221-248\n        },\n title = {Deep Learning in Medical Image Analysis.},\n volume = {19},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5a9e85af0bc45472e9c14e956819f1324085aaa1",
            "@type": "ScholarlyArticle",
            "paperId": "5a9e85af0bc45472e9c14e956819f1324085aaa1",
            "corpusId": 14774186,
            "url": "https://www.semanticscholar.org/paper/5a9e85af0bc45472e9c14e956819f1324085aaa1",
            "title": "A Review of Machine Learning Algorithms for Text-Documents Classification",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "1965398296",
                "DOI": "10.4304/JAIT.1.1.4-20",
                "CorpusId": 14774186
            },
            "abstract": "With the increasing availability of electronic documents and the rapid growth of the World Wide Web, the task of automatic categorization of documents became the key method for organizing the information and know- ledge discovery. Proper classification of e-documents, online news, blogs, e-mails and digital libraries need text mining, machine learning and natural language processing tech- niques to get meaningful knowledge. The aim of this paper is to highlight the important techniques and methodologies that are employed in text documents classification, while at the same time making awareness of some of the interesting challenges that remain to be solved, focused mainly on text representation and machine learning techniques. This paper provides a review of the theory and methods of document classification and text mining, focusing on the existing litera- ture.",
            "referenceCount": 126,
            "citationCount": 616,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2010-01-02",
            "journal": {
                "name": "Journal of Advances in Information Technology",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Baharudin2010ARO,\n author = {B. Baharudin and Lam Hong Lee and Khairullah Khan},\n journal = {Journal of Advances in Information Technology},\n pages = {4-20},\n title = {A Review of Machine Learning Algorithms for Text-Documents Classification},\n volume = {1},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:818826f356444f3daa3447755bf63f171f39ec47",
            "@type": "ScholarlyArticle",
            "paperId": "818826f356444f3daa3447755bf63f171f39ec47",
            "corpusId": 324600,
            "url": "https://www.semanticscholar.org/paper/818826f356444f3daa3447755bf63f171f39ec47",
            "title": "Active Learning Literature Survey",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2903158431",
                "CorpusId": 324600
            },
            "abstract": "The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer labeled training instances if it is allowed to choose the data from which is learns. An active learner may ask queries in the form of unlabeled instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant but labels are dif\ufb01cult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for active learning, a summary of several problem setting variants, and a discussion of related topics in machine learning research are also presented.",
            "referenceCount": 168,
            "citationCount": 5607,
            "influentialCitationCount": 584,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Settles2009ActiveLL,\n author = {Burr Settles},\n title = {Active Learning Literature Survey},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d7009d10dd80d556ac28becad1e035c7cc2cde90",
            "@type": "ScholarlyArticle",
            "paperId": "d7009d10dd80d556ac28becad1e035c7cc2cde90",
            "corpusId": 220633602,
            "url": "https://www.semanticscholar.org/paper/d7009d10dd80d556ac28becad1e035c7cc2cde90",
            "title": "The MLIP package: moment tensor potentials with MPI and active learning",
            "venue": "Machine Learning: Science and Technology",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3042629843",
                "DBLP": "journals/mlst/NovikovGPS21",
                "ArXiv": "2007.08555",
                "DOI": "10.1088/2632-2153/abc9fe",
                "CorpusId": 220633602
            },
            "abstract": "The subject of this paper is the technology (the \u2018how\u2019) of constructing machine-learning interatomic potentials, rather than science (the \u2018what\u2019 and \u2018why\u2019) of atomistic simulations using machine-learning potentials. Namely, we illustrate how to construct moment tensor potentials using active learning as implemented in the MLIP package, focusing on the efficient ways to automatically sample configurations for the training set, how expanding the training set changes the error of predictions, how to set up ab initio calculations in a cost-effective manner, etc. The MLIP package (short for Machine-Learning Interatomic Potentials) is available at https://mlip.skoltech.ru/download/.",
            "referenceCount": 88,
            "citationCount": 214,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iopscience.iop.org/article/10.1088/2632-2153/abc9fe/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-07-16",
            "journal": {
                "name": "Machine Learning: Science and Technology",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Novikov2020TheMP,\n author = {I. Novikov and Konstantin Gubaev and E. Podryabinkin and A. Shapeev},\n booktitle = {Machine Learning: Science and Technology},\n journal = {Machine Learning: Science and Technology},\n title = {The MLIP package: moment tensor potentials with MPI and active learning},\n volume = {2},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9d3e0fce253a4ae4a4456b2f24c03329a2b74621",
            "@type": "ScholarlyArticle",
            "paperId": "9d3e0fce253a4ae4a4456b2f24c03329a2b74621",
            "corpusId": 18121764,
            "url": "https://www.semanticscholar.org/paper/9d3e0fce253a4ae4a4456b2f24c03329a2b74621",
            "title": "Deep Learning for Health Informatics",
            "venue": "IEEE journal of biomedical and health informatics",
            "publicationVenue": {
                "id": "urn:research:eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                "name": "IEEE journal of biomedical and health informatics",
                "alternate_names": [
                    "IEEE Journal of Biomedical and Health Informatics",
                    "IEEE j biomed health informatics",
                    "IEEE J Biomed Health Informatics"
                ],
                "issn": "2168-2194",
                "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/titb/RaviWDBPLY17",
                "MAG": "2561981131",
                "DOI": "10.1109/JBHI.2016.2636665",
                "CorpusId": 18121764,
                "PubMed": "28055930"
            },
            "abstract": "With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. This article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.",
            "referenceCount": 151,
            "citationCount": 1280,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Journal of Biomedical and Health Informatics",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Rav\u00ec2017DeepLF,\n author = {D. Rav\u00ec and Charence Wong and F. Deligianni and M. Berthelot and Javier Andreu-Perez and Benny P. L. Lo and Guang-Zhong Yang},\n booktitle = {IEEE journal of biomedical and health informatics},\n journal = {IEEE Journal of Biomedical and Health Informatics},\n pages = {4-21},\n title = {Deep Learning for Health Informatics},\n volume = {21},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:704aa23d0be8817dd0aa2d4794068fc167243b85",
            "@type": "ScholarlyArticle",
            "paperId": "704aa23d0be8817dd0aa2d4794068fc167243b85",
            "corpusId": 28232901,
            "url": "https://www.semanticscholar.org/paper/704aa23d0be8817dd0aa2d4794068fc167243b85",
            "title": "Findings of the 2017 Conference on Machine Translation (WMT17)",
            "venue": "Conference on Machine Translation",
            "publicationVenue": {
                "id": "urn:research:9aacb914-3edf-4e02-b8fe-5abf21c4d2ba",
                "name": "Conference on Machine Translation",
                "alternate_names": [
                    "WMT",
                    "Conf Mach Transl"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2760656271",
                "DBLP": "conf/wmt/BojarCFGHHHKLLM17",
                "ACL": "W17-4717",
                "DOI": "10.18653/v1/W17-4717",
                "CorpusId": 28232901
            },
            "abstract": "This paper presents the results of the WMT17 shared tasks, which included \nthree machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task.",
            "referenceCount": 95,
            "citationCount": 446,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/W17-4717.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bojar2017FindingsOT,\n author = {Ondrej Bojar and R. Chatterjee and C. Federmann and Yvette Graham and B. Haddow and Shujian Huang and Matthias Huck and Philipp Koehn and Qun Liu and V. Logacheva and Christof Monz and Matteo Negri and Matt Post and Rapha\u00ebl Rubino and Lucia Specia and M. Turchi},\n booktitle = {Conference on Machine Translation},\n pages = {169-214},\n title = {Findings of the 2017 Conference on Machine Translation (WMT17)},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57e4afe9ca74414fa02f2e0a929b64dc9a03334d",
            "@type": "ScholarlyArticle",
            "paperId": "57e4afe9ca74414fa02f2e0a929b64dc9a03334d",
            "corpusId": 11141395,
            "url": "https://www.semanticscholar.org/paper/57e4afe9ca74414fa02f2e0a929b64dc9a03334d",
            "title": "Application of Machine Learning To Epileptic Seizure Detection",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2138190513",
                "DBLP": "conf/icml/ShoebG10",
                "CorpusId": 11141395
            },
            "abstract": "We present and evaluate a machine learning approach to constructing patient-specific classifiers that detect the onset of an epileptic seizure through analysis of the scalp EEG, a non-invasive measure of the brain's electrical activity. This problem is challenging because the brain's electrical activity is composed of numerous classes with overlapping characteristics. The key steps involved in realizing a high performance algorithm included shaping the problem into an appropriate machine learning framework, and identifying the features critical to separating seizure from other types of brain activity. When trained on 2 or more seizures per patient and tested on 916 hours of continuous EEG from 24 patients, our algorithm detected 96% of 173 test seizures with a median detection delay of 3 seconds and a median false detection rate of 2 false detections per 24 hour period. We also provide information about how to download the CHB-MIT database, which contains the data used in this study.",
            "referenceCount": 12,
            "citationCount": 490,
            "influentialCitationCount": 72,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2010-06-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shoeb2010ApplicationOM,\n author = {Ali H. Shoeb and J. Guttag},\n booktitle = {International Conference on Machine Learning},\n pages = {975-982},\n title = {Application of Machine Learning To Epileptic Seizure Detection},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36dd3331060e5e6157d9558563b95253308709cb",
            "@type": "ScholarlyArticle",
            "paperId": "36dd3331060e5e6157d9558563b95253308709cb",
            "corpusId": 1721126,
            "url": "https://www.semanticscholar.org/paper/36dd3331060e5e6157d9558563b95253308709cb",
            "title": "Machine learning: a review of classification and combining techniques",
            "venue": "Artificial Intelligence Review",
            "publicationVenue": {
                "id": "urn:research:ea8553fe-2467-4367-afee-c4deb3754820",
                "name": "Artificial Intelligence Review",
                "alternate_names": [
                    "Artif Intell Rev"
                ],
                "issn": "0269-2821",
                "url": "https://link.springer.com/journal/10462"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2096352448",
                "DBLP": "journals/air/KotsiantisZP06",
                "DOI": "10.1007/s10462-007-9052-3",
                "CorpusId": 1721126
            },
            "abstract": null,
            "referenceCount": 134,
            "citationCount": 1105,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2006-11-01",
            "journal": {
                "name": "Artificial Intelligence Review",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Kotsiantis2006MachineLA,\n author = {S. Kotsiantis and I. Zaharakis and P. Pintelas},\n booktitle = {Artificial Intelligence Review},\n journal = {Artificial Intelligence Review},\n pages = {159-190},\n title = {Machine learning: a review of classification and combining techniques},\n volume = {26},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4b61c25a86083c20730c9b12737ac6ac4178c364",
            "@type": "ScholarlyArticle",
            "paperId": "4b61c25a86083c20730c9b12737ac6ac4178c364",
            "corpusId": 54434537,
            "url": "https://www.semanticscholar.org/paper/4b61c25a86083c20730c9b12737ac6ac4178c364",
            "title": "An Introduction to Deep Reinforcement Learning",
            "venue": "Found. Trends Mach. Learn.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3100366369",
                "DBLP": "journals/corr/abs-1811-12560",
                "ArXiv": "1811.12560",
                "DOI": "10.1561/2200000071",
                "CorpusId": 54434537
            },
            "abstract": "Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.",
            "referenceCount": 352,
            "citationCount": 874,
            "influentialCitationCount": 50,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://repositorio.unal.edu.co/bitstream/unal/80758/2/98554412.2021.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-30",
            "journal": {
                "name": "Found. Trends Mach. Learn.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Fran\u00e7ois-Lavet2018AnIT,\n author = {Vincent Fran\u00e7ois-Lavet and Peter Henderson and Riashat Islam and Marc G. Bellemare and Joelle Pineau},\n booktitle = {Found. Trends Mach. Learn.},\n journal = {Found. Trends Mach. Learn.},\n pages = {219-354},\n title = {An Introduction to Deep Reinforcement Learning},\n volume = {11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc0c84b7c5e6521216da789f8171544709120cf0",
            "@type": "ScholarlyArticle",
            "paperId": "dc0c84b7c5e6521216da789f8171544709120cf0",
            "corpusId": 4641273,
            "url": "https://www.semanticscholar.org/paper/dc0c84b7c5e6521216da789f8171544709120cf0",
            "title": "Opportunities and obstacles for deep learning in biology and medicine",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951934944",
                "PubMedCentral": "5938574",
                "DOI": "10.1098/rsif.2017.0387",
                "CorpusId": 4641273,
                "PubMed": "29618526"
            },
            "abstract": "Deep learning, which describes a class of machine learning algorithms, has recently showed impressive results across a variety of domains. Biology and medicine are data rich, but the data are complex and often ill-understood. Problems of this nature may be particularly well-suited to deep learning techniques. We examine applications of deep learning to a variety of biomedical problems -- patient classification, fundamental biological processes, and treatment of patients -- to predict whether deep learning will transform these tasks or if the biomedical sphere poses unique challenges. We find that deep learning has yet to revolutionize or definitively resolve any of these problems, but promising advances have been made on the prior state of the art. Even when improvement over a previous baseline has been modest, we have seen signs that deep learning methods may speed or aid human investigation. More work is needed to address concerns related to interpretability and how to best model each problem. Furthermore, the limited amount of labeled data for training presents problems in some domains, as can legal and privacy constraints on work with sensitive health records. Nonetheless, we foresee deep learning powering changes at the bench and bedside with the potential to transform several areas of biology and medicine.",
            "referenceCount": 625,
            "citationCount": 1399,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2017.0387",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-05-28",
            "journal": {
                "name": "Journal of the Royal Society Interface",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Ching2017OpportunitiesAO,\n author = {T. Ching and Daniel S. Himmelstein and B. Beaulieu-Jones and Alexandr A Kalinin and Brian T Do and G. Way and E. Ferrero and P. Agapow and M. Zietz and M. M. Hoffman and W. Xie and G. Rosen and Benjamin J. Lengerich and Johnny Israeli and Jack Lanchantin and Stephen Woloszynek and Anne E Carpenter and Avanti Shrikumar and Jinbo Xu and Evan M. Cofer and Christopher A. Lavender and Srinivas C. Turaga and Amr M. Alexandari and Zhiyong Lu and David J Harris and D. DeCaprio and Yanjun Qi and A. Kundaje and Yifan Peng and L. K. Wiley and Marwin H. S. Segler and S. Boca and S. Joshua Swamidass and Austin Huang and A. Gitter and C. Greene},\n booktitle = {bioRxiv},\n journal = {Journal of the Royal Society Interface},\n title = {Opportunities and obstacles for deep learning in biology and medicine},\n volume = {15},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2968a1ec5479b89384886bdd6cc6cc76056c5318",
            "@type": "ScholarlyArticle",
            "paperId": "2968a1ec5479b89384886bdd6cc6cc76056c5318",
            "corpusId": 3761015,
            "url": "https://www.semanticscholar.org/paper/2968a1ec5479b89384886bdd6cc6cc76056c5318",
            "title": "A survey of transfer learning",
            "venue": "Journal of Big Data",
            "publicationVenue": {
                "id": "urn:research:d60da343-ab92-4310-b3d7-2c0860287a9d",
                "name": "Journal of Big Data",
                "alternate_names": [
                    "J Big Data",
                    "Journal on Big Data"
                ],
                "issn": "2196-1115",
                "url": "http://www.journalofbigdata.com/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2395579298",
                "DBLP": "journals/jbd/WeissK016",
                "DOI": "10.1186/s40537-016-0043-6",
                "CorpusId": 3761015
            },
            "abstract": null,
            "referenceCount": 141,
            "citationCount": 1892,
            "influentialCitationCount": 36,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-016-0043-6",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-05-28",
            "journal": {
                "name": "Journal of Big Data",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Weiss2016ASO,\n author = {Karl R. Weiss and T. Khoshgoftaar and Dingding Wang},\n booktitle = {Journal of Big Data},\n journal = {Journal of Big Data},\n pages = {1-40},\n title = {A survey of transfer learning},\n volume = {3},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4d931ea98be69882f547ec6c1b42b78c3e13c36d",
            "@type": "ScholarlyArticle",
            "paperId": "4d931ea98be69882f547ec6c1b42b78c3e13c36d",
            "corpusId": 117542570,
            "url": "https://www.semanticscholar.org/paper/4d931ea98be69882f547ec6c1b42b78c3e13c36d",
            "title": "Quantum circuit learning",
            "venue": "Physical Review A",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1803.00745",
                "MAG": "2891917641",
                "DOI": "10.1103/PhysRevA.98.032309",
                "CorpusId": 117542570
            },
            "abstract": "We propose a classical-quantum hybrid algorithm for machine learning on near-term quantum processors, which we call quantum circuit learning. A quantum circuit driven by our framework learns a given task by tuning parameters implemented on it. The iterative optimization of the parameters allows us to circumvent the high-depth circuit. Theoretical investigation shows that a quantum circuit can approximate nonlinear functions, which is further confirmed by numerical simulations. Hybridizing a low-depth quantum circuit and a classical computer for machine learning, the proposed framework paves the way toward applications of near-term quantum devices for quantum machine learning.",
            "referenceCount": 35,
            "citationCount": 816,
            "influentialCitationCount": 56,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.aps.org/accepted/10.1103/PhysRevA.98.032309",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-03-02",
            "journal": {
                "name": "Physical Review A",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mitarai2018QuantumCL,\n author = {K. Mitarai and M. Negoro and M. Kitagawa and K. Fujii},\n booktitle = {Physical Review A},\n journal = {Physical Review A},\n title = {Quantum circuit learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b57e6468740d9320f3f14c6079168b8e21366416",
            "@type": "ScholarlyArticle",
            "paperId": "b57e6468740d9320f3f14c6079168b8e21366416",
            "corpusId": 3680335,
            "url": "https://www.semanticscholar.org/paper/b57e6468740d9320f3f14c6079168b8e21366416",
            "title": "The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2793022090",
                "DBLP": "journals/corr/abs-1803-01164",
                "ArXiv": "1803.01164",
                "CorpusId": 3680335
            },
            "abstract": "Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].",
            "referenceCount": 284,
            "citationCount": 661,
            "influentialCitationCount": 73,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-03-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.01164"
            },
            "citationStyles": {
                "bibtex": "@Article{Alom2018TheHB,\n author = {Md. Zahangir Alom and T. Taha and C. Yakopcic and Stefan Westberg and P. Sidike and M. S. Nasrin and B. V. Essen and A. Awwal and V. Asari},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches},\n volume = {abs/1803.01164},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e1b41796b752d6fb6032bbad2f8998302209d79b",
            "@type": "ScholarlyArticle",
            "paperId": "e1b41796b752d6fb6032bbad2f8998302209d79b",
            "corpusId": 201667785,
            "url": "https://www.semanticscholar.org/paper/e1b41796b752d6fb6032bbad2f8998302209d79b",
            "title": "A survey on ensemble learning",
            "venue": "Frontiers of Computer Science",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/fcsc/DongYCSM20",
                "MAG": "2970602317",
                "DOI": "10.1007/s11704-019-8208-z",
                "CorpusId": 201667785
            },
            "abstract": null,
            "referenceCount": 186,
            "citationCount": 686,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-08-30",
            "journal": {
                "name": "Frontiers of Computer Science",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Dong2019ASO,\n author = {Xibin Dong and Zhiwen Yu and Wenming Cao and Yifan Shi and Qianli Ma},\n booktitle = {Frontiers of Computer Science},\n journal = {Frontiers of Computer Science},\n pages = {241 - 258},\n title = {A survey on ensemble learning},\n volume = {14},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:791ca7f9f3eb5c0914880711f109e7372fb05959",
            "@type": "ScholarlyArticle",
            "paperId": "791ca7f9f3eb5c0914880711f109e7372fb05959",
            "corpusId": 106411220,
            "url": "https://www.semanticscholar.org/paper/791ca7f9f3eb5c0914880711f109e7372fb05959",
            "title": "Deep learning: new computational modelling techniques for genomics",
            "venue": "Nature reviews genetics",
            "publicationVenue": {
                "id": "urn:research:f44976b5-2cb9-402a-bc59-6a174239987b",
                "name": "Nature reviews genetics",
                "alternate_names": [
                    "Nature Reviews Genetics",
                    "Nat rev genet",
                    "Nat Rev Genet"
                ],
                "issn": "1471-0056",
                "url": "https://www.nature.com/nrg/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2935703330",
                "DOI": "10.1038/s41576-019-0122-6",
                "CorpusId": 106411220,
                "PubMed": "30971806"
            },
            "abstract": null,
            "referenceCount": 151,
            "citationCount": 665,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-07-01",
            "journal": {
                "name": "Nature Reviews Genetics",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Eraslan2019DeepLN,\n author = {G\u00f6k\u00e7en Eraslan and \u017diga Avsec and J. Gagneur and Fabian J Theis},\n booktitle = {Nature reviews genetics},\n journal = {Nature Reviews Genetics},\n pages = {389-403},\n title = {Deep learning: new computational modelling techniques for genomics},\n volume = {20},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:308106a9a8c85241b42bfe447bcf9eab01de3133",
            "@type": "ScholarlyArticle",
            "paperId": "308106a9a8c85241b42bfe447bcf9eab01de3133",
            "corpusId": 233176472,
            "url": "https://www.semanticscholar.org/paper/308106a9a8c85241b42bfe447bcf9eab01de3133",
            "title": "Federated Learning",
            "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
            "publicationVenue": {
                "id": "urn:research:84e95d47-8c6e-4f56-b8c8-2fc3088cfb6b",
                "name": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
                "alternate_names": [
                    "Synth Lect Artif Intell Mach Learn"
                ],
                "issn": "1939-4608",
                "url": "https://www.morganclaypool.com/toc/aim/1/1"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "series/synthesis/2019YangLCKCY",
                "DOI": "10.2200/s00960ed2v01y201910aim043",
                "CorpusId": 233176472
            },
            "abstract": "Over the past few years, machine learning has revolutionized fields such as computer vision, natural language processing, and speech recognition. Much of this success is based on collecting vast amounts of data, often in privacy-invasive ways. Federated Learning is a new subfield of machine learning that allows training models without collecting the data itself. Instead of sharing data, users collaboratively train a model by only sending weight updates to a server. While this better respects privacy and is more flexible in some situations, it does come at a cost. Naively implementing the concept scales poorly when applied to models with millions of parameters. To make Federated Learning feasible, this thesis proposes changes to the optimization process and explains how dedicated compression methods can be employed. With the use of Differential Privacy techniques, it can be ensured that sending weight updates does not leak significant information about individuals. Furthermore, strategies for additionally personalizing models locally are proposed. To empirically evaluate Federated Learning, a large-scale system was implemented for Mozilla Firefox. 360,000 users helped to train and evaluate a model that aims to improve search results in the Firefox URL bar. Eidesstattliche Erkl\u00e4rung Ich versichere hiermit an Eides Statt, dass diese Arbeit von niemand anderem als meiner Person verfasst worden ist. Alle verwendeten Hilfsmittel wie Berichte, B\u00fccher, Internetseiten oder \u00e4hnliches sind im Literaturverzeichnis angegeben, Zitate aus fremden Arbeiten sind als solche kenntlich gemacht. Die Arbeit wurde bisher in gleicher oder \u00e4hnlicher Form keiner anderen Pr\u00fcfungskommission vorgelegt und auch nicht ver\u00f6ffentlicht. Berlin, 20. August 2018",
            "referenceCount": 254,
            "citationCount": 583,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-031-01585-4/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-12-19",
            "journal": {
                "name": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2019FederatedL,\n author = {Qiang Yang and Yang Liu and Yong Cheng and Yan Kang and Tianjian Chen and Han Yu},\n booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},\n journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},\n title = {Federated Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:26b342333376fd7bf162f24f2e9a9de062f41d36",
            "@type": "ScholarlyArticle",
            "paperId": "26b342333376fd7bf162f24f2e9a9de062f41d36",
            "corpusId": 220687717,
            "url": "https://www.semanticscholar.org/paper/26b342333376fd7bf162f24f2e9a9de062f41d36",
            "title": "Optimization for Machine Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "DOI": "10.7551/mitpress/8996.001.0001",
                "CorpusId": 220687717
            },
            "abstract": "This is a draft containing only sra chapter.tex and an abbreviated front matter. Please check that the formatting and small changes have been performed correctly. Please verify the affiliation. Please use this version for sending us future modifications.",
            "referenceCount": 297,
            "citationCount": 619,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Optimization%20for%20Machine%20Learning%20%5BSra%2C%20Nowozin%20%26%20Wright%202011-09-30%5D.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Sra2010OptimizationFM,\n author = {S. Sra and Sebastian Nowozin and Stephen J. Wright},\n title = {Optimization for Machine Learning},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a20bfec3c95aad003dcb45a21a220c19cca8bb66",
            "@type": "ScholarlyArticle",
            "paperId": "a20bfec3c95aad003dcb45a21a220c19cca8bb66",
            "corpusId": 1586370,
            "url": "https://www.semanticscholar.org/paper/a20bfec3c95aad003dcb45a21a220c19cca8bb66",
            "title": "A Machine Learning Approach to Coreference Resolution of Noun Phrases",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "ACL": "J01-4004",
                "DBLP": "journals/coling/SoonNL01",
                "MAG": "2164455818",
                "DOI": "10.1162/089120101753342653",
                "CorpusId": 1586370
            },
            "abstract": "In this paper, we present a learning approach to coreference resolution of noun phrases in unrestricted text. The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases. It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of organization, person, or other types. We evaluate our approach on common data sets (namely, the MUC-6 and MUC-7 coreference corpora) and obtain encouraging results, indicating that on the general noun phrase coreference task, the learning approach holds promise and achieves accuracy comparable to that of nonlearning approaches. Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.",
            "referenceCount": 20,
            "citationCount": 1094,
            "influentialCitationCount": 136,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-12-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Soon2001AML,\n author = {Wee Meng Soon and H. Ng and Chung Yong Lim},\n booktitle = {International Conference on Computational Logic},\n journal = {Computational Linguistics},\n pages = {521-544},\n title = {A Machine Learning Approach to Coreference Resolution of Noun Phrases},\n volume = {27},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:93d6752f11d5db3687cc9f895f219b1bed7e1023",
            "@type": "ScholarlyArticle",
            "paperId": "93d6752f11d5db3687cc9f895f219b1bed7e1023",
            "corpusId": 198179889,
            "url": "https://www.semanticscholar.org/paper/93d6752f11d5db3687cc9f895f219b1bed7e1023",
            "title": "A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1907.09693",
                "DBLP": "journals/tkde/LiWWHWLLH23",
                "MAG": "2992272656",
                "DOI": "10.1109/TKDE.2021.3124599",
                "CorpusId": 198179889
            },
            "abstract": "As data privacy increasingly becomes a critical societal concern, federated learning has been a hot research topic in enabling the collaborative training of machine learning models among different organizations under the privacy restrictions. As researchers try to support more machine learning models with different privacy-preserving approaches, there is a requirement in developing systems and infrastructures to ease the development of various federated learning algorithms. Similar to deep learning systems such as PyTorch and TensorFlow that boost the development of deep learning, federated learning systems (FLSs) are equivalently important, and face challenges from various aspects such as effectiveness, efficiency, and privacy. In this survey, we conduct a comprehensive review on federated learning systems. To understand the key design system components and guide future research, we introduce the definition of federated learning systems and analyze the system components. Moreover, we provide a thorough categorization for federated learning systems according to six different aspects, including data distribution, machine learning model, privacy mechanism, communication architecture, scale of federation and motivation of federation. The categorization can help the design of federated learning systems as shown in our case studies. By systematically summarizing the existing federated learning systems, we present the design factors, case studies, and future research opportunities.",
            "referenceCount": 297,
            "citationCount": 468,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1907.09693",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-07-23",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2019ASO,\n author = {Q. Li and Zeyi Wen and Zhaomin Wu and Bingsheng He},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {3347-3366},\n title = {A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection},\n volume = {35},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8de174ab5419b9d3127695405efd079808e956e8",
            "@type": "ScholarlyArticle",
            "paperId": "8de174ab5419b9d3127695405efd079808e956e8",
            "corpusId": 873046,
            "url": "https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8",
            "title": "Curriculum learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2296073425",
                "DBLP": "conf/icml/BengioLCW09",
                "DOI": "10.1145/1553374.1553380",
                "CorpusId": 873046
            },
            "abstract": "Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them \"curriculum learning\". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).",
            "referenceCount": 33,
            "citationCount": 4367,
            "influentialCitationCount": 353,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2009CurriculumL,\n author = {Yoshua Bengio and J. Louradour and Ronan Collobert and J. Weston},\n booktitle = {International Conference on Machine Learning},\n pages = {41-48},\n title = {Curriculum learning},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:44058a625cb64c311043145655645d8206e272c2",
            "@type": "ScholarlyArticle",
            "paperId": "44058a625cb64c311043145655645d8206e272c2",
            "corpusId": 3544583,
            "url": "https://www.semanticscholar.org/paper/44058a625cb64c311043145655645d8206e272c2",
            "title": "Scalable Private Learning with PATE",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2785361959",
                "ArXiv": "1802.08908",
                "DBLP": "journals/corr/abs-1802-08908",
                "CorpusId": 3544583
            },
            "abstract": "The rapid adoption of machine learning has increased concerns about the privacy implications of machine learning models trained on sensitive data, such as medical records or other personal information. To address those concerns, one promising approach is Private Aggregation of Teacher Ensembles, or PATE, which transfers to a \"student\" model the knowledge of an ensemble of \"teacher\" models, with intuitive privacy provided by training teachers on disjoint data and strong privacy guaranteed by noisy aggregation of teachers' answers. However, PATE has so far been evaluated only on simple classification tasks like MNIST, leaving unclear its utility when applied to larger-scale learning tasks and real-world datasets. \nIn this work, we show how PATE can scale to learning tasks with large numbers of output classes and uncurated, imbalanced training data with errors. For this, we introduce new noisy aggregation mechanisms for teacher ensembles that are more selective and add less noise, and prove their tighter differential-privacy guarantees. Our new mechanisms build on two insights: the chance of teacher consensus is increased by using more concentrated noise and, lacking consensus, no answer need be given to a student. The consensus answers used are more likely to be correct, offer better intuitive privacy, and incur lower-differential privacy cost. Our evaluation shows our mechanisms improve on the original PATE on all measures, and scale to larger tasks with both high utility and very strong privacy ($\\varepsilon$ < 1.0).",
            "referenceCount": 41,
            "citationCount": 490,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.08908"
            },
            "citationStyles": {
                "bibtex": "@Article{Papernot2018ScalablePL,\n author = {Nicolas Papernot and Shuang Song and Ilya Mironov and A. Raghunathan and Kunal Talwar and \u00da. Erlingsson},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Scalable Private Learning with PATE},\n volume = {abs/1802.08908},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
            "@type": "ScholarlyArticle",
            "paperId": "0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
            "corpusId": 1946600,
            "url": "https://www.semanticscholar.org/paper/0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
            "title": "A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2762776925",
                "DBLP": "journals/access/YinZFH17",
                "DOI": "10.1109/ACCESS.2017.2762418",
                "CorpusId": 1946600
            },
            "abstract": "Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.",
            "referenceCount": 27,
            "citationCount": 1098,
            "influentialCitationCount": 84,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-12",
            "journal": {
                "name": "IEEE Access",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Yin2017ADL,\n author = {Chuanlong Yin and Yuefei Zhu and Jin-long Fei and Xin-Zheng He},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {21954-21961},\n title = {A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks},\n volume = {5},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "@type": "ScholarlyArticle",
            "paperId": "9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "corpusId": 17540505,
            "url": "https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "title": "Deep Reinforcement Learning: An Overview",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2580175322",
                "DBLP": "journals/corr/Li17b",
                "ArXiv": "1701.07274",
                "CorpusId": 17540505
            },
            "abstract": "We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions. \nPlease see Deep Reinforcement Learning, arXiv:1810.06339, for a significant update.",
            "referenceCount": 578,
            "citationCount": 1131,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-01-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.07274"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017DeepRL,\n author = {Yuxi Li},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Reinforcement Learning: An Overview},\n volume = {abs/1701.07274},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "@type": "ScholarlyArticle",
            "paperId": "12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "corpusId": 1708582,
            "url": "https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "title": "Reinforcement Learning: A Survey",
            "venue": "Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:aef12dca-60a0-4ca3-819b-cad26d309d4e",
                "name": "Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "JAIR",
                    "J Artif Intell Res",
                    "The Journal of Artificial Intelligence Research"
                ],
                "issn": "1076-9757",
                "url": "http://www.jair.org/"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/jair/KaelblingLM96",
                "MAG": "2107726111",
                "ArXiv": "cs/9605103",
                "DOI": "10.1613/jair.301",
                "CorpusId": 1708582
            },
            "abstract": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.",
            "referenceCount": 131,
            "citationCount": 8266,
            "influentialCitationCount": 386,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.jair.org/index.php/jair/article/download/10166/24110",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1996-04-30",
            "journal": {
                "name": "J. Artif. Intell. Res.",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Kaelbling1996ReinforcementLA,\n author = {L. Kaelbling and M. Littman and A. Moore},\n booktitle = {Journal of Artificial Intelligence Research},\n journal = {J. Artif. Intell. Res.},\n pages = {237-285},\n title = {Reinforcement Learning: A Survey},\n volume = {4},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:64be9999b68e12d260ba7423f6b55ffd41552ad3",
            "@type": "ScholarlyArticle",
            "paperId": "64be9999b68e12d260ba7423f6b55ffd41552ad3",
            "corpusId": 206491372,
            "url": "https://www.semanticscholar.org/paper/64be9999b68e12d260ba7423f6b55ffd41552ad3",
            "title": "Deep Learning Applications in Medical Image Analysis",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2777186991",
                "DBLP": "journals/access/KerWRL18",
                "DOI": "10.1109/ACCESS.2017.2788044",
                "CorpusId": 206491372
            },
            "abstract": "The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.",
            "referenceCount": 124,
            "citationCount": 878,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Access",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Ker2018DeepLA,\n author = {Justin Ker and Lipo Wang and J. Rao and Tchoyoson C. C. Lim},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {9375-9389},\n title = {Deep Learning Applications in Medical Image Analysis},\n volume = {6},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23dac921784d65530ba798109ded94996c533d47",
            "@type": "ScholarlyArticle",
            "paperId": "23dac921784d65530ba798109ded94996c533d47",
            "corpusId": 1737296,
            "url": "https://www.semanticscholar.org/paper/23dac921784d65530ba798109ded94996c533d47",
            "title": "The SHOGUN Machine Learning Toolbox",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/jmlr/SonnenburgRHWBZBBGF10",
                "MAG": "1571024744",
                "DOI": "10.5555/1756006.1859911",
                "CorpusId": 1737296
            },
            "abstract": "We have developed a machine learning toolbox, called SHOGUN, which is designed for unified large-scale learning for a broad range of feature types and learning settings. It offers a considerable number of machine learning models such as support vector machines, hidden Markov models, multiple kernel learning, linear discriminant analysis, and more. Most of the specific algorithms are able to deal with several different data classes. We have used this toolbox in several applications from computational biology, some of them coming with no less than 50 million training examples and others with 7 billion test examples. With more than a thousand installations worldwide, SHOGUN is already widely adopted in the machine learning community and beyond. \n \nSHOGUN is implemented in C++ and interfaces to MATLABTM, R, Octave, Python, and has a stand-alone command line interface. The source code is freely available under the GNU General Public License, Version 3 at http://www.shogun-toolbox.org.",
            "referenceCount": 11,
            "citationCount": 301,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-03-01",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Sonnenburg2010TheSM,\n author = {S. Sonnenburg and G. R\u00e4tsch and S. Henschel and Christian Widmer and Jonas Behr and A. Zien and F. D. Bona and Alexander Binder and Christian Gehl and Vojtech Franc},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {1799-1802},\n title = {The SHOGUN Machine Learning Toolbox},\n volume = {11},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a154e688baa929c335dd9a673592797ec3c27281",
            "@type": "ScholarlyArticle",
            "paperId": "a154e688baa929c335dd9a673592797ec3c27281",
            "corpusId": 53280687,
            "url": "https://www.semanticscholar.org/paper/a154e688baa929c335dd9a673592797ec3c27281",
            "title": "Learning from positive and unlabeled data: a survey",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3015027483",
                "ArXiv": "1811.04820",
                "DBLP": "journals/ml/BekkerD20",
                "DOI": "10.1007/s10994-020-05877-5",
                "CorpusId": 53280687
            },
            "abstract": null,
            "referenceCount": 151,
            "citationCount": 363,
            "influentialCitationCount": 48,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10994-020-05877-5.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-11-12",
            "journal": {
                "name": "Machine Learning",
                "volume": "109"
            },
            "citationStyles": {
                "bibtex": "@Article{Bekker2018LearningFP,\n author = {Jessa Bekker and Jesse Davis},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {719 - 760},\n title = {Learning from positive and unlabeled data: a survey},\n volume = {109},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a206216c3f67605ac6e25b0178c3f156dc0f7ba0",
            "@type": "ScholarlyArticle",
            "paperId": "a206216c3f67605ac6e25b0178c3f156dc0f7ba0",
            "corpusId": 17629797,
            "url": "https://www.semanticscholar.org/paper/a206216c3f67605ac6e25b0178c3f156dc0f7ba0",
            "title": "WEKA: a machine learning workbench",
            "venue": "Proceedings of ANZIIS '94 - Australian New Zealnd Intelligent Information Systems Conference",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "1566376227",
                "DOI": "10.1109/ANZIIS.1994.396988",
                "CorpusId": 17629797
            },
            "abstract": "WEKA is a workbench for machine learning that is intended to aid in the application of machine learning techniques to a variety of real-world problems, in particular, those arising from agricultural and horticultural domains. Unlike other machine learning projects, the emphasis is on providing a working environment for the domain specialist rather than the machine learning expert. Lessons learned include the necessity of providing a wealth of interactive tools for data manipulation, result visualization, database linkage, and cross-validation and comparison of rule sets, to complement the basic machine learning tools.<<ETX>>",
            "referenceCount": 17,
            "citationCount": 1103,
            "influentialCitationCount": 115,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://researchcommons.waikato.ac.nz/bitstream/10289/1138/1/uow-cs-wp-1994-09.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference"
            ],
            "publicationDate": "1994-11-29",
            "journal": {
                "name": "Proceedings of ANZIIS '94 - Australian New Zealnd Intelligent Information Systems Conference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Holmes1994WEKAAM,\n author = {G. Holmes and A. Donkin and I. Witten},\n booktitle = {Proceedings of ANZIIS '94 - Australian New Zealnd Intelligent Information Systems Conference},\n journal = {Proceedings of ANZIIS '94 - Australian New Zealnd Intelligent Information Systems Conference},\n pages = {357-361},\n title = {WEKA: a machine learning workbench},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ec7c724aa1d906e9e9f81c58497adddb22175b8",
            "@type": "ScholarlyArticle",
            "paperId": "6ec7c724aa1d906e9e9f81c58497adddb22175b8",
            "corpusId": 60486887,
            "url": "https://www.semanticscholar.org/paper/6ec7c724aa1d906e9e9f81c58497adddb22175b8",
            "title": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "1563088657",
                "DBLP": "books/cu/CS2000",
                "DOI": "10.1017/CBO9780511801389.013",
                "CorpusId": 60486887
            },
            "abstract": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software.",
            "referenceCount": 0,
            "citationCount": 8422,
            "influentialCitationCount": 338,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.gbv.de/dms/goettingen/512565724.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2000-03-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Cristianini2000AnIT,\n author = {N. Cristianini and J. Shawe-Taylor},\n title = {An Introduction to Support Vector Machines and Other Kernel-based Learning Methods},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5ae39d8bf8a06ae91b236ef115fdab8921e6455",
            "@type": "ScholarlyArticle",
            "paperId": "b5ae39d8bf8a06ae91b236ef115fdab8921e6455",
            "corpusId": 207101649,
            "url": "https://www.semanticscholar.org/paper/b5ae39d8bf8a06ae91b236ef115fdab8921e6455",
            "title": "Optimization method based extreme learning machine for classification",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2157595416",
                "DBLP": "journals/ijon/HuangDZ10",
                "DOI": "10.1016/j.neucom.2010.02.019",
                "CorpusId": 207101649
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 850,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-12-01",
            "journal": {
                "name": "Neurocomputing",
                "volume": "74"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2010OptimizationMB,\n author = {G. Huang and Xiaojian Ding and Hongming Zhou},\n booktitle = {Neurocomputing},\n journal = {Neurocomputing},\n pages = {155-163},\n title = {Optimization method based extreme learning machine for classification},\n volume = {74},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:293987e14d64dc768a432115c93171ab8653e3bb",
            "@type": "ScholarlyArticle",
            "paperId": "293987e14d64dc768a432115c93171ab8653e3bb",
            "corpusId": 17609011,
            "url": "https://www.semanticscholar.org/paper/293987e14d64dc768a432115c93171ab8653e3bb",
            "title": "Machine Learning in Medical Imaging",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/spm/WernickYBYS10",
                "MAG": "2045732268",
                "DOI": "10.1109/MSP.2010.936730",
                "CorpusId": 17609011,
                "PubMed": "25382956"
            },
            "abstract": "This article will discuss very different ways of using machine learning that may be less familiar, and we will demonstrate through examples the role of these concepts in medical imaging. Although the term machine learning is relatively recent, the ideas of machine learning have been applied to medical imaging for decades, perhaps most notably in the areas of computer-aided diagnosis (CAD) and functional brain mapping. We will not attempt in this brief article to survey the rich literature of this field. Instead our goals will be 1) to acquaint the reader with some modern techniques that are now staples of the machine-learning field and 2) to illustrate how these techniques can be employed in various ways in medical imaging.",
            "referenceCount": 51,
            "citationCount": 206,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc4220564?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-06-14",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Wernick2010MachineLI,\n author = {M. Wernick and Yongyi Yang and J. Brankov and G. Yourganov and S. Strother},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n pages = {25-38},\n title = {Machine Learning in Medical Imaging},\n volume = {27},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb8a1b8d87a3fef15635eb4a32173f9c6f966055",
            "@type": "ScholarlyArticle",
            "paperId": "cb8a1b8d87a3fef15635eb4a32173f9c6f966055",
            "corpusId": 52298127,
            "url": "https://www.semanticscholar.org/paper/cb8a1b8d87a3fef15635eb4a32173f9c6f966055",
            "title": "A Survey on Deep Learning",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2892341857",
                "DBLP": "journals/csur/PouyanfarSYTTRS19",
                "DOI": "10.1145/3234150",
                "CorpusId": 52298127
            },
            "abstract": "The field of machine learning is witnessing its golden era as deep learning slowly becomes the leader in this domain. Deep learning uses multiple layers to represent the abstractions of data to build computational models. Some key enabler deep learning algorithms such as generative adversarial networks, convolutional neural networks, and model transfers have completely changed our perception of information processing. However, there exists an aperture of understanding behind this tremendously fast-paced domain, because it was never previously represented from a multiscope perspective. The lack of core understanding renders these powerful methods as black-box machines that inhibit development at a fundamental level. Moreover, deep learning has repeatedly been perceived as a silver bullet to all stumbling blocks in machine learning, which is far from the truth. This article presents a comprehensive review of historical and recent state-of-the-art approaches in visual, audio, and text processing; social network analysis; and natural language processing, followed by the in-depth analysis on pivoting and groundbreaking advances in deep learning applications. It was also undertaken to review the issues faced in deep learning such as unsupervised learning, black-box models, and online learning and to illustrate how these challenges can be transformed into prolific future research avenues.",
            "referenceCount": 182,
            "citationCount": 567,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-09-18",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "51"
            },
            "citationStyles": {
                "bibtex": "@Article{Pouyanfar2018ASO,\n author = {Samira Pouyanfar and Saad Sadiq and Yilin Yan and Haiman Tian and Yudong Tao and Maria E. Presa-Reyes and M. Shyu and Shu\u2010Ching Chen and S. S. Iyengar},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 36},\n title = {A Survey on Deep Learning},\n volume = {51},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1671a665c636bec7d2eaff137d74e9b7f074892f",
            "@type": "ScholarlyArticle",
            "paperId": "1671a665c636bec7d2eaff137d74e9b7f074892f",
            "corpusId": 8197182,
            "url": "https://www.semanticscholar.org/paper/1671a665c636bec7d2eaff137d74e9b7f074892f",
            "title": "Learning Algorithms for the Classification Restricted Boltzmann Machine",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2105577021",
                "DBLP": "journals/jmlr/LarochelleMPB12",
                "DOI": "10.5555/2503308.2188407",
                "CorpusId": 8197182
            },
            "abstract": "Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artificial neural networks. In such settings, the RBM only yields a preprocessing or an initialization for some other model, instead of acting as a complete supervised model in its own right. In this paper, we argue that RBMs can provide a self-contained framework for developing competitive classifiers. We study the Classification RBM (ClassRBM), a variant on the RBM adapted to the classification setting. We study different strategies for training the ClassRBM and show that competitive classification performances can be reached when appropriately combining discriminative and generative training objectives. Since training according to the generative objective requires the computation of a generally intractable gradient, we also compare different approaches to estimating this gradient and address the issue of obtaining such a gradient for problems with very high dimensional inputs. Finally, we describe how to adapt the ClassRBM to two special cases of classification problems, namely semi-supervised and multitask learning.",
            "referenceCount": 52,
            "citationCount": 302,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Larochelle2012LearningAF,\n author = {H. Larochelle and Michael I. Mandel and Razvan Pascanu and Yoshua Bengio},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {643-669},\n title = {Learning Algorithms for the Classification Restricted Boltzmann Machine},\n volume = {13},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4ae802491724aee021f31f02327b9671cead3dc",
            "@type": "ScholarlyArticle",
            "paperId": "c4ae802491724aee021f31f02327b9671cead3dc",
            "corpusId": 53061796,
            "url": "https://www.semanticscholar.org/paper/c4ae802491724aee021f31f02327b9671cead3dc",
            "title": "Types of Machine Learning Algorithms",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "1583031633",
                "DOI": "10.5772/9385",
                "CorpusId": 53061796
            },
            "abstract": "\u2022 Supervised learning --where the algorithm generates a function that maps inputs to desired outputs. One standard formulation of the supervised learning task is the classification problem: the learner is required to learn (to approximate the behavior of) a function which maps a vector into one of several classes by looking at several input-output examples of the function. \u2022 Unsupervised learning --which models a set of inputs: labeled examples are not available. \u2022 Semi-supervised learning --which combines both labeled and unlabeled examples to generate an appropriate function or classifier. \u2022 Reinforcement learning --where the algorithm learns a policy of how to act given an observation of the world. Every action has some impact in the environment, and the environment provides feedback that guides the learning algorithm. \u2022 Transduction --similar to supervised learning, but does not explicitly construct a function: instead, tries to predict new outputs based on training inputs, training outputs, and new inputs. \u2022 Learning to learn --where the algorithm learns its own inductive bias based on previous experience.",
            "referenceCount": 51,
            "citationCount": 358,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2010-02-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ayodele2010TypesOM,\n author = {T. Ayodele},\n title = {Types of Machine Learning Algorithms},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4050c80ba36c6f86b0684a59be70182557b0770c",
            "@type": "ScholarlyArticle",
            "paperId": "4050c80ba36c6f86b0684a59be70182557b0770c",
            "corpusId": 225378014,
            "url": "https://www.semanticscholar.org/paper/4050c80ba36c6f86b0684a59be70182557b0770c",
            "title": "Ensemble deep learning in bioinformatics",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/natmi/CaoGYY20",
                "MAG": "3049002444",
                "DOI": "10.1038/s42256-020-0217-y",
                "CorpusId": 225378014
            },
            "abstract": null,
            "referenceCount": 113,
            "citationCount": 138,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-08-17",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Cao2020EnsembleDL,\n author = {Yue Cao and Thomas A. Geddes and J. Yang and Pengyi Yang},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {500 - 508},\n title = {Ensemble deep learning in bioinformatics},\n volume = {2},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:066dd3d09eb5815e8be1da560abd1abe08f87cb9",
            "@type": "ScholarlyArticle",
            "paperId": "066dd3d09eb5815e8be1da560abd1abe08f87cb9",
            "corpusId": 11124791,
            "url": "https://www.semanticscholar.org/paper/066dd3d09eb5815e8be1da560abd1abe08f87cb9",
            "title": "OP-ELM: Optimally Pruned Extreme Learning Machine",
            "venue": "IEEE Transactions on Neural Networks",
            "publicationVenue": {
                "id": "urn:research:2ac50919-507e-41c7-93a8-721c4b804757",
                "name": "IEEE Transactions on Neural Networks",
                "alternate_names": [
                    "IEEE Trans Neural Netw"
                ],
                "issn": "1045-9227",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=72"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/tnn/MicheSBSJL10",
                "MAG": "2130378394",
                "DOI": "10.1109/TNN.2009.2036259",
                "CorpusId": 11124791,
                "PubMed": "20007026"
            },
            "abstract": "In this brief, the optimally pruned extreme learning machine (OP-ELM) methodology is presented. It is based on the original extreme learning machine (ELM) algorithm with additional steps to make it more robust and generic. The whole methodology is presented in detail and then applied to several regression and classification problems. Results for both computational time and accuracy (mean square error) are compared to the original ELM and to three other widely used methodologies: multilayer perceptron (MLP), support vector machine (SVM), and Gaussian process (GP). As the experiments for both regression and classification illustrate, the proposed OP-ELM methodology performs several orders of magnitude faster than the other algorithms used in this brief, except the original ELM. Despite the simplicity and fast performance, the OP-ELM is still able to maintain an accuracy that is comparable to the performance of the SVM. A toolbox for the OP-ELM is publicly available online.",
            "referenceCount": 17,
            "citationCount": 763,
            "influentialCitationCount": 49,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Neural Networks",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Mich\u00e92010OPELMOP,\n author = {Y. Mich\u00e9 and A. Sorjamaa and P. Bas and O. Simula and C. Jutten and A. Lendasse},\n booktitle = {IEEE Transactions on Neural Networks},\n journal = {IEEE Transactions on Neural Networks},\n pages = {158-162},\n title = {OP-ELM: Optimally Pruned Extreme Learning Machine},\n volume = {21},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f7eb3e6221dc7bbe5eda0ce796755f5d71e7d61a",
            "@type": "ScholarlyArticle",
            "paperId": "f7eb3e6221dc7bbe5eda0ce796755f5d71e7d61a",
            "corpusId": 12567278,
            "url": "https://www.semanticscholar.org/paper/f7eb3e6221dc7bbe5eda0ce796755f5d71e7d61a",
            "title": "Machine learning in adversarial environments",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2005299943",
                "DBLP": "journals/ml/LaskovL10",
                "DOI": "10.1007/s10994-010-5207-6",
                "CorpusId": 12567278
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 132,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-11-01",
            "journal": {
                "name": "Machine Learning",
                "volume": "81"
            },
            "citationStyles": {
                "bibtex": "@Article{Laskov2010MachineLI,\n author = {P. Laskov and R. Lippmann},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {115-119},\n title = {Machine learning in adversarial environments},\n volume = {81},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:de9180ecc8b645aff238be05f645d50fa34a808f",
            "@type": "ScholarlyArticle",
            "paperId": "de9180ecc8b645aff238be05f645d50fa34a808f",
            "corpusId": 8259511,
            "url": "https://www.semanticscholar.org/paper/de9180ecc8b645aff238be05f645d50fa34a808f",
            "title": "Learning Curves in Machine Learning",
            "venue": "Encyclopedia of Machine Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "1597150962",
                "DBLP": "reference/ml/Perlich17",
                "DOI": "10.1007/978-0-387-30164-8_452",
                "CorpusId": 8259511
            },
            "abstract": null,
            "referenceCount": 12,
            "citationCount": 60,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Perlich2010LearningCI,\n author = {C. Perlich},\n booktitle = {Encyclopedia of Machine Learning},\n pages = {577-580},\n title = {Learning Curves in Machine Learning},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ba86604228b555475496e200f31878df3aabd6e",
            "@type": "ScholarlyArticle",
            "paperId": "0ba86604228b555475496e200f31878df3aabd6e",
            "corpusId": 3201232,
            "url": "https://www.semanticscholar.org/paper/0ba86604228b555475496e200f31878df3aabd6e",
            "title": "Never-Ending Learning",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2890648394",
                "DBLP": "journals/cacm/MitchellCHTYBCM18",
                "DOI": "10.1145/3191513",
                "CorpusId": 3201232
            },
            "abstract": "Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a neverending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidenceweighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.",
            "referenceCount": 48,
            "citationCount": 919,
            "influentialCitationCount": 64,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3191513",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-01-25",
            "journal": {
                "name": "Communications of the ACM",
                "volume": "61"
            },
            "citationStyles": {
                "bibtex": "@Article{Mitchell2015NeverEndingL,\n author = {Tom Michael Mitchell and William W. Cohen and Estevam Hruschka and Partha P. Talukdar and Bo Yang and Justin Betteridge and Andrew Carlson and Bhavana Dalvi and Matt Gardner and B. Kisiel and Jayant Krishnamurthy and N. Lao and Kathryn Mazaitis and Thahir Mohamed and Ndapandula Nakashole and Emmanouil Antonios Platanios and Alan Ritter and M. Samadi and Burr Settles and Richard C. Wang and D. Wijaya and A. Gupta and Xinlei Chen and Abulhair Saparov and Malcolm Greaves and Joel Welling},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {Communications of the ACM},\n pages = {103 - 115},\n title = {Never-Ending Learning},\n volume = {61},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5f198e9f1a6cace1fcee5ec53f5d35d9d83af6b7",
            "@type": "ScholarlyArticle",
            "paperId": "5f198e9f1a6cace1fcee5ec53f5d35d9d83af6b7",
            "corpusId": 15523031,
            "url": "https://www.semanticscholar.org/paper/5f198e9f1a6cace1fcee5ec53f5d35d9d83af6b7",
            "title": "Can machine learning be secure?",
            "venue": "ACM Asia Conference on Computer and Communications Security",
            "publicationVenue": {
                "id": "urn:research:87fc9c3c-cc7f-42aa-ba71-2700729a6788",
                "name": "ACM Asia Conference on Computer and Communications Security",
                "alternate_names": [
                    "AsiaCCS",
                    "ACM Asia Conf Comput Commun Secur",
                    "ACM Symposium on Information, Computer and Communications Security",
                    "ACM Symp Inf Comput Commun Secur",
                    "ASIACCS"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/asia-ccs"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/ccs/BarrenoNSJT06",
                "MAG": "2151298633",
                "DOI": "10.1145/1128817.1128824",
                "CorpusId": 15523031
            },
            "abstract": "Machine learning systems offer unparalled flexibility in dealing with evolving input in a variety of applications, such as intrusion detection systems and spam e-mail filtering. However, machine learning algorithms themselves can be a target of attack by a malicious adversary. This paper provides a framework for answering the question, \"Can machine learning be secure?\" Novel contributions of this paper include a taxonomy of different types of attacks on machine learning techniques and systems, a variety of defenses against those attacks, a discussion of ideas that are important to security for machine learning, an analytical model giving a lower bound on attacker's work function, and a list of open problems.",
            "referenceCount": 40,
            "citationCount": 864,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.berkeley.edu/~adj/publications/paper-files/asiaccs06.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-03-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Barreno2006CanML,\n author = {M. Barreno and B. Nelson and R. Sears and A. Joseph and J. D. Tygar},\n booktitle = {ACM Asia Conference on Computer and Communications Security},\n pages = {16-25},\n title = {Can machine learning be secure?},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7fc70d4cc5118fdbc8e8807979eae8b61948ff91",
            "@type": "ScholarlyArticle",
            "paperId": "7fc70d4cc5118fdbc8e8807979eae8b61948ff91",
            "corpusId": 124516008,
            "url": "https://www.semanticscholar.org/paper/7fc70d4cc5118fdbc8e8807979eae8b61948ff91",
            "title": "The elements of statistical learning: data mining, inference and prediction",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "1554944419",
                "DOI": "10.1007/BF02985802",
                "CorpusId": 124516008
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 3890,
            "influentialCitationCount": 277,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-03-01",
            "journal": {
                "name": "The Mathematical Intelligencer",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Franklin2005TheEO,\n author = {James Franklin},\n journal = {The Mathematical Intelligencer},\n pages = {83-85},\n title = {The elements of statistical learning: data mining, inference and prediction},\n volume = {27},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:49047883d555a536420faa0ac3c0684b70822643",
            "@type": "ScholarlyArticle",
            "paperId": "49047883d555a536420faa0ac3c0684b70822643",
            "corpusId": 195953,
            "url": "https://www.semanticscholar.org/paper/49047883d555a536420faa0ac3c0684b70822643",
            "title": "Searching for exotic particles in high-energy physics with deep learning",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2125621954",
                "ArXiv": "1402.4735",
                "DOI": "10.1038/ncomms5308",
                "CorpusId": 195953,
                "PubMed": "24986233"
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 1096,
            "influentialCitationCount": 92,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/ncomms5308.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Physics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-02-19",
            "journal": {
                "name": "Nature Communications",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Baldi2014SearchingFE,\n author = {P. Baldi and Peter Sadowski and D. Whiteson},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Searching for exotic particles in high-energy physics with deep learning},\n volume = {5},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:872352b0a53ab6cbb4420f81df64d215d86c7d9b",
            "@type": "ScholarlyArticle",
            "paperId": "872352b0a53ab6cbb4420f81df64d215d86c7d9b",
            "corpusId": 1260035,
            "url": "https://www.semanticscholar.org/paper/872352b0a53ab6cbb4420f81df64d215d86c7d9b",
            "title": "Emotions from Text: Machine Learning for Text-based Emotion Prediction",
            "venue": "Human Language Technology - The Baltic Perspectiv",
            "publicationVenue": {
                "id": "urn:research:f8e3f8d0-0f40-48c0-b3c0-0c540237b859",
                "name": "Human Language Technology - The Baltic Perspectiv",
                "alternate_names": [
                    "Human Language Technology",
                    "HLT",
                    "Hum Lang Technol",
                    "Hum Lang Technol  Balt Perspect"
                ],
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "ACL": "H05-1073",
                "DBLP": "conf/naacl/AlmRS05",
                "MAG": "2168493061",
                "DOI": "10.3115/1220575.1220648",
                "CorpusId": 1260035
            },
            "abstract": "In addition to information, text contains attitudinal, and more specifically, emotional content. This paper explores the text-based emotion prediction problem empirically, using supervised machine learning with the SNoW learning architecture. The goal is to classify the emotional affinity of sentences in the narrative domain of children's fairy tales, for subsequent usage in appropriate expressive rendering of text-to-speech synthesis. Initial experiments on a preliminary data set of 22 fairy tales show encouraging results over a naive baseline and BOW approach for classification of emotional versus non-emotional contents, with some dependency on parameter tuning. We also discuss results for a tripartite model which covers emotional valence, as well as feature set alternations. In addition, we present plans for a more cognitively sound sequential model, taking into consideration a larger set of basic emotions.",
            "referenceCount": 34,
            "citationCount": 914,
            "influentialCitationCount": 57,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1220648&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-10-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Alm2005EmotionsFT,\n author = {Cecilia Ovesdotter Alm and D. Roth and R. Sproat},\n booktitle = {Human Language Technology - The Baltic Perspectiv},\n pages = {579-586},\n title = {Emotions from Text: Machine Learning for Text-based Emotion Prediction},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1242d79573397094c5670f55e58c8333cced0beb",
            "@type": "ScholarlyArticle",
            "paperId": "1242d79573397094c5670f55e58c8333cced0beb",
            "corpusId": 5005167,
            "url": "https://www.semanticscholar.org/paper/1242d79573397094c5670f55e58c8333cced0beb",
            "title": "Deep Learning: A Primer for Radiologists.",
            "venue": "Radiographics",
            "publicationVenue": {
                "id": "urn:research:6a469aed-f8e3-456a-92e6-53237e43d3da",
                "name": "Radiographics",
                "alternate_names": null,
                "issn": "0271-5333",
                "url": "https://pubs.rsna.org/loi/radiographics"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2767236661",
                "DOI": "10.1148/rg.2017170077",
                "CorpusId": 5005167,
                "PubMed": "29131760"
            },
            "abstract": "Deep learning is a class of machine learning methods that are gaining success and attracting interest in many domains, including computer vision, speech recognition, natural language processing, and playing games. Deep learning methods produce a mapping from raw inputs to desired outputs (eg, image classes). Unlike traditional machine learning methods, which require hand-engineered feature extraction from inputs, deep learning methods learn these features directly from data. With the advent of large datasets and increased computing power, these methods can produce models with exceptional performance. These models are multilayer artificial neural networks, loosely inspired by biologic neural systems. Weighted connections between nodes (neurons) in the network are iteratively adjusted based on example pairs of inputs and target outputs by back-propagating a corrective error signal through the network. For computer vision tasks, convolutional neural networks (CNNs) have proven to be effective. Recently, several clinical applications of CNNs have been proposed and studied in radiology for classification, detection, and segmentation tasks. This article reviews the key concepts of deep learning for clinical radiologists, discusses technical requirements, describes emerging applications in clinical radiology, and outlines limitations and future directions in this field. Radiologists should become familiar with the principles and potential applications of deep learning in medical imaging. \u00a9RSNA, 2017.",
            "referenceCount": 28,
            "citationCount": 716,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-11-13",
            "journal": {
                "name": "Radiographics : a review publication of the Radiological Society of North America, Inc",
                "volume": "37 7"
            },
            "citationStyles": {
                "bibtex": "@Article{Chartrand2017DeepLA,\n author = {G. Chartrand and P. Cheng and Eugene Vorontsov and M. Drozdzal and S. Turcotte and C. Pal and S. Kadoury and A. Tang},\n booktitle = {Radiographics},\n journal = {Radiographics : a review publication of the Radiological Society of North America, Inc},\n pages = {\n          2113-2131\n        },\n title = {Deep Learning: A Primer for Radiologists.},\n volume = {37 7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a3b9a78c02bb3bbc18f7eb13041f4186fb9dec5",
            "@type": "ScholarlyArticle",
            "paperId": "3a3b9a78c02bb3bbc18f7eb13041f4186fb9dec5",
            "corpusId": 7419259,
            "url": "https://www.semanticscholar.org/paper/3a3b9a78c02bb3bbc18f7eb13041f4186fb9dec5",
            "title": "An Insight into Extreme Learning Machines: Random Neurons, Random Features and Kernels",
            "venue": "Cognitive Computation",
            "publicationVenue": {
                "id": "urn:research:d1e87771-68a0-40db-a4d3-6216158cc596",
                "name": "Cognitive Computation",
                "alternate_names": [
                    "Cogn Comput"
                ],
                "issn": "1866-9956",
                "url": "https://www.springer.com/biomed/neuroscience/journal/12559"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2101674911",
                "DBLP": "journals/cogcom/Huang14",
                "DOI": "10.1007/s12559-014-9255-2",
                "CorpusId": 7419259
            },
            "abstract": null,
            "referenceCount": 92,
            "citationCount": 879,
            "influentialCitationCount": 55,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-04-03",
            "journal": {
                "name": "Cognitive Computation",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2014AnII,\n author = {G. Huang},\n booktitle = {Cognitive Computation},\n journal = {Cognitive Computation},\n pages = {376-390},\n title = {An Insight into Extreme Learning Machines: Random Neurons, Random Features and Kernels},\n volume = {6},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "@type": "ScholarlyArticle",
            "paperId": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "corpusId": 2427083,
            "url": "https://www.semanticscholar.org/paper/40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "title": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features",
            "venue": "European Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:f9a81beb-9bcb-43bc-96a7-67cf23dba2d6",
                "name": "European Conference on Machine Learning",
                "alternate_names": [
                    "Eur Conf Mach Learn",
                    "European conference on Machine Learning",
                    "Eur conf Mach Learn",
                    "ECML"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/ecml"
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "conf/ecml/Joachims98",
                "MAG": "2149684865",
                "DOI": "10.1007/BFb0026683",
                "CorpusId": 2427083
            },
            "abstract": null,
            "referenceCount": 32,
            "citationCount": 8985,
            "influentialCitationCount": 713,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/BFb0026683.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-04-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Joachims1998TextCW,\n author = {T. Joachims},\n booktitle = {European Conference on Machine Learning},\n pages = {137-142},\n title = {Text Categorization with Support Vector Machines: Learning with Many Relevant Features},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:48234756b7cf798bfeb47328f7c5d597fd4838c2",
            "@type": "ScholarlyArticle",
            "paperId": "48234756b7cf798bfeb47328f7c5d597fd4838c2",
            "corpusId": 1438164,
            "url": "https://www.semanticscholar.org/paper/48234756b7cf798bfeb47328f7c5d597fd4838c2",
            "title": "ADASYN: Adaptive synthetic sampling approach for imbalanced learning",
            "venue": "IEEE World Congress on Computational Intelligence",
            "publicationVenue": {
                "id": "urn:research:1786f28f-85e4-4441-bb5d-a7bbc1dd3f24",
                "name": "IEEE World Congress on Computational Intelligence",
                "alternate_names": [
                    "WCCI",
                    "IEEE World Congr Comput Intell",
                    "World Congr Comput Intell",
                    "World Congress on Computational Intelligence"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=3017"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/ijcnn/HeBGL08",
                "MAG": "2104933073",
                "DOI": "10.1109/IJCNN.2008.4633969",
                "CorpusId": 1438164
            },
            "abstract": "This paper presents a novel adaptive synthetic (ADASYN) sampling approach for learning from imbalanced data sets. The essential idea of ADASYN is to use a weighted distribution for different minority class examples according to their level of difficulty in learning, where more synthetic data is generated for minority class examples that are harder to learn compared to those minority examples that are easier to learn. As a result, the ADASYN approach improves learning with respect to the data distributions in two ways: (1) reducing the bias introduced by the class imbalance, and (2) adaptively shifting the classification decision boundary toward the difficult examples. Simulation analyses on several machine learning data sets show the effectiveness of this method across five evaluation metrics.",
            "referenceCount": 37,
            "citationCount": 3041,
            "influentialCitationCount": 399,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-06-01",
            "journal": {
                "name": "2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{He2008ADASYNAS,\n author = {Haibo He and Yang Bai and E. A. Garcia and Shutao Li},\n booktitle = {IEEE World Congress on Computational Intelligence},\n journal = {2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)},\n pages = {1322-1328},\n title = {ADASYN: Adaptive synthetic sampling approach for imbalanced learning},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5bf9cebe3658cfbf7f67c0a2680c8233509aa5e4",
            "@type": "ScholarlyArticle",
            "paperId": "5bf9cebe3658cfbf7f67c0a2680c8233509aa5e4",
            "corpusId": 215908411,
            "url": "https://www.semanticscholar.org/paper/5bf9cebe3658cfbf7f67c0a2680c8233509aa5e4",
            "title": "UCI Repository of Machine Learning Database",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "3009784374",
                "CorpusId": 215908411
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1106,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Newman1998UCIRO,\n author = {D. Newman},\n title = {UCI Repository of Machine Learning Database},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d517b13f2b152c913b81ce534a149493517dbdad",
            "@type": "ScholarlyArticle",
            "paperId": "d517b13f2b152c913b81ce534a149493517dbdad",
            "corpusId": 10158224,
            "url": "https://www.semanticscholar.org/paper/d517b13f2b152c913b81ce534a149493517dbdad",
            "title": "Big Data Deep Learning: Challenges and Perspectives",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/access/ChenL14",
                "MAG": "1984020445",
                "DOI": "10.1109/ACCESS.2014.2325029",
                "CorpusId": 10158224
            },
            "abstract": "Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends.",
            "referenceCount": 115,
            "citationCount": 973,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-05-16",
            "journal": {
                "name": "IEEE Access",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2014BigDD,\n author = {Xue-wen Chen and Xiaotong Lin},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {514-525},\n title = {Big Data Deep Learning: Challenges and Perspectives},\n volume = {2},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b17862e73e79a554e6ad2b27f6df44be1b533a0d",
            "@type": "ScholarlyArticle",
            "paperId": "b17862e73e79a554e6ad2b27f6df44be1b533a0d",
            "corpusId": 45229864,
            "url": "https://www.semanticscholar.org/paper/b17862e73e79a554e6ad2b27f6df44be1b533a0d",
            "title": "Tuning Metaheuristics - A Machine Learning Perspective",
            "venue": "Studies in Computational Intelligence",
            "publicationVenue": {
                "id": "urn:research:bf2f9688-933d-44b9-9cd5-c738ddf60c56",
                "name": "Studies in Computational Intelligence",
                "alternate_names": [
                    "Stud Comput Intell",
                    "Studies in computational intelligence",
                    "Stud comput intell"
                ],
                "issn": "1860-949X",
                "url": "https://www.springer.com/series/7092"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "series/sci/2009-197",
                "MAG": "170314049",
                "DOI": "10.1007/978-3-642-00483-4",
                "CorpusId": 45229864
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 334,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2009-04-15",
            "journal": {
                "name": null,
                "volume": "197"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Birattari2009TuningM,\n author = {M. Birattari},\n booktitle = {Studies in Computational Intelligence},\n pages = {1-201},\n title = {Tuning Metaheuristics - A Machine Learning Perspective},\n volume = {197},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1605d856f4502c2ddd234b8c61bbbe1fc22af3ef",
            "@type": "ScholarlyArticle",
            "paperId": "1605d856f4502c2ddd234b8c61bbbe1fc22af3ef",
            "corpusId": 4505261,
            "url": "https://www.semanticscholar.org/paper/1605d856f4502c2ddd234b8c61bbbe1fc22af3ef",
            "title": "A survey of deep learning-based network anomaly detection",
            "venue": "Cluster Computing",
            "publicationVenue": {
                "id": "urn:research:f1d0ef3d-4e90-41e9-b454-f589a933654f",
                "name": "Cluster Computing",
                "alternate_names": [
                    "Clust Comput"
                ],
                "issn": "1386-7857",
                "url": "https://www.springer.com/computer/communication+networks/journal/10586"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2756489700",
                "DBLP": "journals/cluster/KwonKKSKK19",
                "DOI": "10.1007/s10586-017-1117-8",
                "CorpusId": 4505261
            },
            "abstract": null,
            "referenceCount": 42,
            "citationCount": 523,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Cluster Computing",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Kwon2017ASO,\n author = {Donghwoon Kwon and Hyunjoo Kim and Jinoh Kim and S. Suh and Ikkyun Kim and Kuinam J. Kim},\n booktitle = {Cluster Computing},\n journal = {Cluster Computing},\n pages = {949-961},\n title = {A survey of deep learning-based network anomaly detection},\n volume = {22},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:70bcdbac2c70c9f107123262cf5257b57839f708",
            "@type": "ScholarlyArticle",
            "paperId": "70bcdbac2c70c9f107123262cf5257b57839f708",
            "corpusId": 9600755,
            "url": "https://www.semanticscholar.org/paper/70bcdbac2c70c9f107123262cf5257b57839f708",
            "title": "Machine Learning",
            "venue": "Scientific Data Mining and Knowledge Discovery",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "books/daglib/p/HoffmannM10",
                "DOI": "10.1007/978-3-642-02788-8_2",
                "CorpusId": 9600755
            },
            "abstract": null,
            "referenceCount": 9,
            "citationCount": 47,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hoffmann2010MachineL,\n author = {A. Hoffmann and Ashesh Mahidadia},\n booktitle = {Scientific Data Mining and Knowledge Discovery},\n pages = {7-52},\n title = {Machine Learning},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:035256a8a6d8a73af2adb38245f4130daa1f0535",
            "@type": "ScholarlyArticle",
            "paperId": "035256a8a6d8a73af2adb38245f4130daa1f0535",
            "corpusId": 6944829,
            "url": "https://www.semanticscholar.org/paper/035256a8a6d8a73af2adb38245f4130daa1f0535",
            "title": "Machine learning in bioinformatics",
            "venue": "Briefings Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "journals/bib/LarranagaCSBGILASMR06",
                "MAG": "2098740506",
                "DOI": "10.1093/BIB/BBK007",
                "CorpusId": 6944829,
                "PubMed": "16761367"
            },
            "abstract": "This article reviews machine learning methods for bioinformatics. It presents modelling methods, such as supervised classification, clustering and probabilistic graphical models for knowledge discovery, as well as deterministic and stochastic heuristics for optimization. Applications in genomics, proteomics, systems biology, evolution and text mining are also shown.",
            "referenceCount": 296,
            "citationCount": 841,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/bib/article-pdf/7/1/86/23992771/bbk007.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2006-03-01",
            "journal": {
                "name": "Briefings in bioinformatics",
                "volume": "7 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Larra\u00f1aga2006MachineLI,\n author = {P. Larra\u00f1aga and Borja Calvo and Roberto Santana and C. Bielza and Josu Galdiano and I\u00f1aki Inza and J. A. Lozano and R. Arma\u00f1anzas and Guzm\u00e1n Santaf\u00e9 and Aritz P\u00e9rez Mart\u00ednez and V. Robles},\n booktitle = {Briefings Bioinform.},\n journal = {Briefings in bioinformatics},\n pages = {\n          86-112\n        },\n title = {Machine learning in bioinformatics},\n volume = {7 1},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "@type": "ScholarlyArticle",
            "paperId": "39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "corpusId": 9823884,
            "url": "https://www.semanticscholar.org/paper/39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "title": "Applications of Deep Learning and Reinforcement Learning to Biological Data",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2768956845",
                "DBLP": "journals/tnn/MahmudKHV18",
                "ArXiv": "1711.03985",
                "DOI": "10.1109/TNNLS.2018.2790388",
                "CorpusId": 9823884,
                "PubMed": "29771663"
            },
            "abstract": "Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)\u2013machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.",
            "referenceCount": 213,
            "citationCount": 565,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dspace.stir.ac.uk/bitstream/1893/26814/1/1711.03985.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-11-10",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Mahmud2017ApplicationsOD,\n author = {M. Mahmud and M. S. Kaiser and A. Hussain and S. Vassanelli},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {2063-2079},\n title = {Applications of Deep Learning and Reinforcement Learning to Biological Data},\n volume = {29},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1f135e98e867ffcde5b359e7b817bbe21f80cfce",
            "@type": "ScholarlyArticle",
            "paperId": "1f135e98e867ffcde5b359e7b817bbe21f80cfce",
            "corpusId": 118926724,
            "url": "https://www.semanticscholar.org/paper/1f135e98e867ffcde5b359e7b817bbe21f80cfce",
            "title": "Deep Learning and Its Application to LHC Physics",
            "venue": "Annual Review of Nuclear and Particle Science",
            "publicationVenue": {
                "id": "urn:research:9a1eb53e-bbc0-4488-976f-6db6d80789ca",
                "name": "Annual Review of Nuclear and Particle Science",
                "alternate_names": [
                    "Annu Rev Nucl Part Sci"
                ],
                "issn": "0163-8998",
                "url": "https://www.annualreviews.org/journal/nucl"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3099381338",
                "ArXiv": "1806.11484",
                "DOI": "10.1146/annurev-nucl-101917-021019",
                "CorpusId": 118926724
            },
            "abstract": "Machine learning has played an important role in the analysis of high-energy physics data for decades. The emergence of deep learning in 2012 allowed for machine learning tools which could adeptly handle higher-dimensional and more complex problems than previously feasible. This review is aimed at the reader who is familiar with high-energy physics but not machine learning. The connections between machine learning and high-energy physics data analysis are explored, followed by an introduction to the core concepts of neural networks, examples of the key results demonstrating the power of deep learning for analysis of LHC data, and discussion of future prospects and concerns.",
            "referenceCount": 41,
            "citationCount": 312,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1806.11484",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-06-29",
            "journal": {
                "name": "Annual Review of Nuclear and Particle Science",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Guest2018DeepLA,\n author = {D. Guest and Kyle Cranmer and D. Whiteson},\n booktitle = {Annual Review of Nuclear and Particle Science},\n journal = {Annual Review of Nuclear and Particle Science},\n title = {Deep Learning and Its Application to LHC Physics},\n year = {2018}\n}\n"
            }
        }
    }
]