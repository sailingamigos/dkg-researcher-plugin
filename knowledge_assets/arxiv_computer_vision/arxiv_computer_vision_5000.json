[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10162v1",
            "title": "K-space Cold Diffusion: Learning to Reconstruct Accelerated MRI without\n  Noise",
            "updated": "2023-11-16T19:34:18Z",
            "published": "2023-11-16T19:34:18Z",
            "summary": "Deep learning-based MRI reconstruction models have achieved superior\nperformance these days. Most recently, diffusion models have shown remarkable\nperformance in image generation, in-painting, super-resolution, image editing\nand more. As a generalized diffusion model, cold diffusion further broadens the\nscope and considers models built around arbitrary image transformations such as\nblurring, down-sampling, etc. In this paper, we propose a k-space cold\ndiffusion model that performs image degradation and restoration in k-space\nwithout the need for Gaussian noise. We provide comparisons with multiple deep\nlearning-based MRI reconstruction models and perform tests on a well-known\nlarge open-source MRI dataset. Our results show that this novel way of\nperforming degradation can generate high-quality reconstruction images for\naccelerated MRI.",
            "author": [
                "Guoyao Shen",
                "Mengyu Li",
                "Chad W. Farris",
                "Stephan Anderson",
                "Xin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10162v1",
                "http://arxiv.org/pdf/2311.10162v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10143v1",
            "title": "Observation of the non-Hermitian skin effect and Fermi skin on a digital\n  quantum computer",
            "updated": "2023-11-16T19:00:05Z",
            "published": "2023-11-16T19:00:05Z",
            "summary": "Non-Hermitian physics has attracted considerable attention in the recent\nyears, in particular the non-Hermitian skin effect (NHSE) for its extreme\nsensitivity and non-locality. While the NHSE has been physically observed in\nvarious classical metamaterials and even ultracold atomic arrays, its\nhighly-nontrivial implications in many-body dynamics have never been\nexperimentally investigated. In this work, we report the first observation of\nthe NHSE on a universal quantum processor, as well as its characteristic but\nelusive Fermi skin from many-fermion statistics. To implement NHSE dynamics on\na quantum computer, the effective time-evolution circuit not only needs to be\nnon-reciprocal and non-unitary, but must also be scaled up to a sufficient\nnumber of lattice qubits to achieve spatial non-locality. We show how such a\nnon-unitary operation can be systematically realized by post-selecting multiple\nancilla qubits, as demonstrated through two paradigmatic non-reciprocal models\non a noisy IBM quantum processor, with clear signatures of asymmetric spatial\npropagation and many-body Fermi skin accumulation. To minimize errors from\ninevitable device noise, time evolution is performed using a trainable\noptimized quantum circuit produced with variational quantum algorithms. Our\nstudy represents a critical milestone in the quantum simulation of\nnon-Hermitian lattice phenomena on present-day quantum computers, and can be\nreadily generalized to more sophisticated many-body models with the remarkable\nprogrammability of quantum computers.",
            "author": [
                "Ruizhe Shen",
                "Tianqi Chen",
                "Bo Yang",
                "Ching Hua Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10143v1",
                "http://arxiv.org/pdf/2311.10143v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10137v1",
            "title": "Optimal twirling depths for shadow tomography in the presence of noise",
            "updated": "2023-11-16T19:00:01Z",
            "published": "2023-11-16T19:00:01Z",
            "summary": "The classical shadows protocol is an efficient strategy for estimating\nproperties of an unknown state $\\rho$ using a small number of state copies and\nmeasurements. In its original form, it involves twirling the state with\nunitaries from some ensemble and measuring the twirled state in a fixed basis.\nIt was recently shown that for computing local properties, optimal sample\ncomplexity (copies of the state required) is remarkably achieved for unitaries\ndrawn from shallow depth circuits composed of local entangling gates, as\nopposed to purely local (zero depth) or global twirling (infinite depth)\nensembles. Here we consider the sample complexity as a function of the depth of\nthe circuit, in the presence of noise. We find that this noise has important\nimplications for determining the optimal twirling ensemble. Under fairly\ngeneral conditions, we i) show that any single-site noise can be accounted for\nusing a depolarizing noise channel with an appropriate damping parameter $f$;\nii) compute thresholds $f_{\\text{th}}$ at which optimal twirling reduces to\nlocal twirling for arbitrary operators and iii) $n^{\\text{th}}$ order Renyi\nentropies ($n \\ge 2$); and iv) provide a meaningful upper bound\n$t_{\\text{max}}$ on the optimal circuit depth for any finite noise strength\n$f$, which applies to all operators and entanglement entropy measurements.\nThese thresholds strongly constrain the search for optimal strategies to\nimplement shadow tomography and can be easily tailored to the experimental\nsystem at hand.",
            "author": [
                "Pierre-Gabriel Rozon",
                "Ning Bao",
                "Kartiek Agarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10137v1",
                "http://arxiv.org/pdf/2311.10137v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10093v2",
            "title": "The Chosen One: Consistent Characters in Text-to-Image Diffusion Models",
            "updated": "2023-11-27T15:58:30Z",
            "published": "2023-11-16T18:59:51Z",
            "summary": "Recent advances in text-to-image generation models have unlocked vast\npotential for visual creativity. However, these models struggle with generation\nof consistent characters, a crucial aspect for numerous real-world applications\nsuch as story visualization, game development asset design, advertising, and\nmore. Current methods typically rely on multiple pre-existing images of the\ntarget character or involve labor-intensive manual processes. In this work, we\npropose a fully automated solution for consistent character generation, with\nthe sole input being a text prompt. We introduce an iterative procedure that,\nat each stage, identifies a coherent set of images sharing a similar identity\nand extracts a more consistent identity from this set. Our quantitative\nanalysis demonstrates that our method strikes a better balance between prompt\nalignment and identity consistency compared to the baseline methods, and these\nfindings are reinforced by a user study. To conclude, we showcase several\npractical applications of our approach. Project page is available at\nhttps://omriavrahami.com/the-chosen-one",
            "author": [
                "Omri Avrahami",
                "Amir Hertz",
                "Yael Vinker",
                "Moab Arar",
                "Shlomi Fruchter",
                "Ohad Fried",
                "Daniel Cohen-Or",
                "Dani Lischinski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10093v2",
                "http://arxiv.org/pdf/2311.10093v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10092v1",
            "title": "Traffic Video Object Detection using Motion Prior",
            "updated": "2023-11-16T18:59:46Z",
            "published": "2023-11-16T18:59:46Z",
            "summary": "Traffic videos inherently differ from generic videos in their stationary\ncamera setup, thus providing a strong motion prior where objects often move in\na specific direction over a short time interval. Existing works predominantly\nemploy generic video object detection framework for traffic video object\ndetection, which yield certain advantages such as broad applicability and\nrobustness to diverse scenarios. However, they fail to harness the strength of\nmotion prior to enhance detection accuracy. In this work, we propose two\ninnovative methods to exploit the motion prior and boost the performance of\nboth fully-supervised and semi-supervised traffic video object detection.\nFirstly, we introduce a new self-attention module that leverages the motion\nprior to guide temporal information integration in the fully-supervised\nsetting. Secondly, we utilise the motion prior to develop a pseudo-labelling\nmechanism to eliminate noisy pseudo labels for the semi-supervised setting.\nBoth of our motion-prior-centred methods consistently demonstrates superior\nperformance, outperforming existing state-of-the-art approaches by a margin of\n2% in terms of mAP.",
            "author": [
                "Lihao Liu",
                "Yanqi Cheng",
                "Dongdong Chen",
                "Jing He",
                "Pietro Li\u00f2",
                "Carola-Bibiane Sch\u00f6nlieb",
                "Angelica I Aviles-Rivero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10092v1",
                "http://arxiv.org/pdf/2311.10092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10091v1",
            "title": "Adaptive Shells for Efficient Neural Radiance Field Rendering",
            "updated": "2023-11-16T18:58:55Z",
            "published": "2023-11-16T18:58:55Z",
            "summary": "Neural radiance fields achieve unprecedented quality for novel view\nsynthesis, but their volumetric formulation remains expensive, requiring a huge\nnumber of samples to render high-resolution images. Volumetric encodings are\nessential to represent fuzzy geometry such as foliage and hair, and they are\nwell-suited for stochastic optimization. Yet, many scenes ultimately consist\nlargely of solid surfaces which can be accurately rendered by a single sample\nper pixel. Based on this insight, we propose a neural radiance formulation that\nsmoothly transitions between volumetric- and surface-based rendering, greatly\naccelerating rendering speed and even improving visual fidelity. Our method\nconstructs an explicit mesh envelope which spatially bounds a neural volumetric\nrepresentation. In solid regions, the envelope nearly converges to a surface\nand can often be rendered with a single sample. To this end, we generalize the\nNeuS formulation with a learned spatially-varying kernel size which encodes the\nspread of the density, fitting a wide kernel to volume-like regions and a tight\nkernel to surface-like regions. We then extract an explicit mesh of a narrow\nband around the surface, with width determined by the kernel size, and\nfine-tune the radiance field within this band. At inference time, we cast rays\nagainst the mesh and evaluate the radiance field only within the enclosed\nregion, greatly reducing the number of samples required. Experiments show that\nour approach enables efficient rendering at very high fidelity. We also\ndemonstrate that the extracted envelope enables downstream applications such as\nanimation and simulation.",
            "author": [
                "Zian Wang",
                "Tianchang Shen",
                "Merlin Nimier-David",
                "Nicholas Sharp",
                "Jun Gao",
                "Alexander Keller",
                "Sanja Fidler",
                "Thomas M\u00fcller",
                "Zan Gojcic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10091v1",
                "http://arxiv.org/pdf/2311.10091v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10090v3",
            "title": "JaxMARL: Multi-Agent RL Environments in JAX",
            "updated": "2023-11-20T15:51:07Z",
            "published": "2023-11-16T18:58:43Z",
            "summary": "Benchmarks play an important role in the development of machine learning\nalgorithms. For example, research in reinforcement learning (RL) has been\nheavily influenced by available environments and benchmarks. However, RL\nenvironments are traditionally run on the CPU, limiting their scalability with\ntypical academic compute. Recent advancements in JAX have enabled the wider use\nof hardware acceleration to overcome these computational hurdles, enabling\nmassively parallel RL training pipelines and environments. This is particularly\nuseful for multi-agent reinforcement learning (MARL) research. First of all,\nmultiple agents must be considered at each environment step, adding\ncomputational burden, and secondly, the sample complexity is increased due to\nnon-stationarity, decentralised partial observability, or other MARL\nchallenges. In this paper, we present JaxMARL, the first open-source code base\nthat combines ease-of-use with GPU enabled efficiency, and supports a large\nnumber of commonly used MARL environments as well as popular baseline\nalgorithms. When considering wall clock time, our experiments show that per-run\nour JAX-based training pipeline is up to 12500x faster than existing\napproaches. This enables efficient and thorough evaluations, with the potential\nto alleviate the evaluation crisis of the field. We also introduce and\nbenchmark SMAX, a vectorised, simplified version of the popular StarCraft\nMulti-Agent Challenge, which removes the need to run the StarCraft II game\nengine. This not only enables GPU acceleration, but also provides a more\nflexible MARL environment, unlocking the potential for self-play,\nmeta-learning, and other future applications in MARL. We provide code at\nhttps://github.com/flairox/jaxmarl.",
            "author": [
                "Alexander Rutherford",
                "Benjamin Ellis",
                "Matteo Gallici",
                "Jonathan Cook",
                "Andrei Lupu",
                "Gardar Ingvarsson",
                "Timon Willi",
                "Akbir Khan",
                "Christian Schroeder de Witt",
                "Alexandra Souly",
                "Saptarashmi Bandyopadhyay",
                "Mikayel Samvelyan",
                "Minqi Jiang",
                "Robert Tjarko Lange",
                "Shimon Whiteson",
                "Bruno Lacerda",
                "Nick Hawes",
                "Tim Rocktaschel",
                "Chris Lu",
                "Jakob Nicolaus Foerster"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10090v3",
                "http://arxiv.org/pdf/2311.10090v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10089v1",
            "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
            "updated": "2023-11-16T18:55:58Z",
            "published": "2023-11-16T18:55:58Z",
            "summary": "Instruction-based image editing holds immense potential for a variety of\napplications, as it enables users to perform any editing operation using a\nnatural language instruction. However, current models in this domain often\nstruggle with accurately executing user instructions. We present Emu Edit, a\nmulti-task image editing model which sets state-of-the-art results in\ninstruction-based image editing. To develop Emu Edit we train it to multi-task\nacross an unprecedented range of tasks, such as region-based editing, free-form\nediting, and Computer Vision tasks, all of which are formulated as generative\ntasks. Additionally, to enhance Emu Edit's multi-task learning abilities, we\nprovide it with learned task embeddings which guide the generation process\ntowards the correct edit type. Both these elements are essential for Emu Edit's\noutstanding performance. Furthermore, we show that Emu Edit can generalize to\nnew tasks, such as image inpainting, super-resolution, and compositions of\nediting tasks, with just a few labeled examples. This capability offers a\nsignificant advantage in scenarios where high-quality samples are scarce.\nLastly, to facilitate a more rigorous and informed assessment of instructable\nimage editing models, we release a new challenging and versatile benchmark that\nincludes seven different image editing tasks.",
            "author": [
                "Shelly Sheynin",
                "Adam Polyak",
                "Uriel Singer",
                "Yuval Kirstain",
                "Amit Zohar",
                "Oron Ashual",
                "Devi Parikh",
                "Yaniv Taigman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10089v1",
                "http://arxiv.org/pdf/2311.10089v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10086v1",
            "title": "Double-Virtual NNLO QCD Corrections for Five-Parton Scattering: The\n  Gluon Channel",
            "updated": "2023-11-16T18:47:46Z",
            "published": "2023-11-16T18:47:46Z",
            "summary": "We compute the two-loop helicity amplitudes for the scattering of five\ngluons, including all contributions beyond the leading-color approximation. The\nanalytic expressions are represented as linear combinations of transcendental\nfunctions with rational coefficients, which we reconstruct from finite-field\nsamples obtained with the numerical unitarity method. Guided by the requirement\nof removing unphysical singularities, we find a remarkably compact generating\nset of rational coefficients, which we are able to display entirely in the\nmanuscript. We implement our results in a public code, which provides efficient\nand reliable numerical evaluations for phenomenological applications.",
            "author": [
                "Giuseppe De Laurentis",
                "Harald Ita",
                "Maximillian Klinkert",
                "Vasily Sotnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10086v1",
                "http://arxiv.org/pdf/2311.10086v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10085v1",
            "title": "A Computationally Efficient Sparsified Online Newton Method",
            "updated": "2023-11-16T18:44:22Z",
            "published": "2023-11-16T18:44:22Z",
            "summary": "Second-order methods hold significant promise for enhancing the convergence\nof deep neural network training; however, their large memory and computational\ndemands have limited their practicality. Thus there is a need for scalable\nsecond-order methods that can efficiently train large models. In this paper, we\nintroduce the Sparsified Online Newton (SONew) method, a memory-efficient\nsecond-order algorithm that yields a sparsified yet effective preconditioner.\nThe algorithm emerges from a novel use of the LogDet matrix divergence measure;\nwe combine it with sparsity constraints to minimize regret in the online convex\noptimization framework. Empirically, we test our method on large scale\nbenchmarks of up to 1B parameters. We achieve up to 30% faster convergence,\n3.4% relative improvement in validation performance, and 80% relative\nimprovement in training loss, in comparison to memory efficient optimizers\nincluding first order methods. Powering the method is a surprising fact --\nimposing structured sparsity patterns, like tridiagonal and banded structure,\nrequires little to no overhead, making it as efficient and parallelizable as\nfirst-order methods. In wall-clock time, tridiagonal SONew is only about 3%\nslower per step than first-order methods but gives overall gains due to much\nfaster convergence. In contrast, one of the state-of-the-art (SOTA)\nmemory-intensive second-order methods, Shampoo, is unable to scale to large\nbenchmarks. Additionally, while Shampoo necessitates significant engineering\nefforts to scale to large benchmarks, SONew offers a more straightforward\nimplementation, increasing its practical appeal. SONew code is available at:\nhttps://github.com/devvrit/SONew",
            "author": [
                "Fnu Devvrit",
                "Sai Surya Duvvuri",
                "Rohan Anil",
                "Vineet Gupta",
                "Cho-Jui Hsieh",
                "Inderjit Dhillon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10085v1",
                "http://arxiv.org/pdf/2311.10085v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10084v1",
            "title": "Soft Theorems, Anomalies and Precursors",
            "updated": "2023-11-16T18:43:56Z",
            "published": "2023-11-16T18:43:56Z",
            "summary": "1-loop amplitudes in 4d $N=4$ supergravity with non-vanishing soft-scalar\nlimits and anomalous $SU(1,1)$ duality present a 1-loop precursor of a 4-loop\nUV divergence. In this paper we find that in 6d maximal supergravity there are\n3-loop order amplitudes with non-vanishing soft-scalar limits and anomalous\n$E_{5(5)}$ duality, induced by a 3-loop UV divergence. If the relevant\nnon-vanishing soft-scalar limits are detected at 1-loop amplitudes, it would\nsupply a 1-loop precursor of a 3-loop UV divergence in 6d. In such case, an\nanalogous search of duality anomalies (non-vanishing soft-scalar limits) of\n1-loop multi-point amplitudes might provide precursors of higher loop UV\ndivergences in models where higher loop computations are extremely difficult.",
            "author": [
                "Renata Kallosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10084v1",
                "http://arxiv.org/pdf/2311.10084v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10785v1",
            "title": "Text Sanitization Beyond Specific Domains: Zero-Shot Redaction &\n  Substitution with Large Language Models",
            "updated": "2023-11-16T18:42:37Z",
            "published": "2023-11-16T18:42:37Z",
            "summary": "In the context of information systems, text sanitization techniques are used\nto identify and remove sensitive data to comply with security and regulatory\nrequirements. Even though many methods for privacy preservation have been\nproposed, most of them are focused on the detection of entities from specific\ndomains (e.g., credit card numbers, social security numbers), lacking\ngenerality and requiring customization for each desirable domain. Moreover,\nremoving words is, in general, a drastic measure, as it can degrade text\ncoherence and contextual information. Less severe measures include substituting\na word for a safe alternative, yet it can be challenging to automatically find\nmeaningful substitutions. We present a zero-shot text sanitization technique\nthat detects and substitutes potentially sensitive information using Large\nLanguage Models. Our evaluation shows that our method excels at protecting\nprivacy while maintaining text coherence and contextual information, preserving\ndata utility for downstream tasks.",
            "author": [
                "Federico Albanese",
                "Daniel Ciolek",
                "Nicolas D'Ippolito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10785v1",
                "http://arxiv.org/pdf/2311.10785v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10083v1",
            "title": "Characterizing Tradeoffs in Language Model Decoding with Informational\n  Interpretations",
            "updated": "2023-11-16T18:38:25Z",
            "published": "2023-11-16T18:38:25Z",
            "summary": "We propose a theoretical framework for formulating language model decoder\nalgorithms with dynamic programming and information theory. With dynamic\nprogramming, we lift the design of decoder algorithms from the logit space to\nthe action-state value function space, and show that the decoding algorithms\nare consequences of optimizing the action-state value functions. Each component\nin the action-state value function space has an information theoretical\ninterpretation. With the lifting and interpretation, it becomes evident what\nthe decoder algorithm is optimized for, and hence facilitating the arbitration\nof the tradeoffs in sensibleness, diversity, and attribution.",
            "author": [
                "Chung-Ching Chang",
                "William W. Cohen",
                "Yun-Hsuan Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10083v1",
                "http://arxiv.org/pdf/2311.10083v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10081v1",
            "title": "DRESS: Instructing Large Vision-Language Models to Align and Interact\n  with Humans via Natural Language Feedback",
            "updated": "2023-11-16T18:37:29Z",
            "published": "2023-11-16T18:37:29Z",
            "summary": "We present DRESS, a large vision language model (LVLM) that innovatively\nexploits Natural Language feedback (NLF) from Large Language Models to enhance\nits alignment and interactions by addressing two key limitations in the\nstate-of-the-art LVLMs. First, prior LVLMs generally rely only on the\ninstruction finetuning stage to enhance alignment with human preferences.\nWithout incorporating extra feedback, they are still prone to generate\nunhelpful, hallucinated, or harmful responses. Second, while the visual\ninstruction tuning data is generally structured in a multi-turn dialogue\nformat, the connections and dependencies among consecutive conversational turns\nare weak. This reduces the capacity for effective multi-turn interactions. To\ntackle these, we propose a novel categorization of the NLF into two key types:\ncritique and refinement. The critique NLF identifies the strengths and\nweaknesses of the responses and is used to align the LVLMs with human\npreferences. The refinement NLF offers concrete suggestions for improvement and\nis adopted to improve the interaction ability of the LVLMs-- which focuses on\nLVLMs' ability to refine responses by incorporating feedback in multi-turn\ninteractions. To address the non-differentiable nature of NLF, we generalize\nconditional reinforcement learning for training. Our experimental results\ndemonstrate that DRESS can generate more helpful (9.76%), honest (11.52%), and\nharmless (21.03%) responses, and more effectively learn from feedback during\nmulti-turn interactions compared to SOTA LVMLs.",
            "author": [
                "Yangyi Chen",
                "Karan Sikka",
                "Michael Cogswell",
                "Heng Ji",
                "Ajay Divakaran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10081v1",
                "http://arxiv.org/pdf/2311.10081v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10080v1",
            "title": "Asymptotics of approximate Bayesian computation when summary statistics\n  converge at heterogeneous rates",
            "updated": "2023-11-16T18:34:59Z",
            "published": "2023-11-16T18:34:59Z",
            "summary": "We consider the asymptotic properties of Approximate Bayesian Computation\n(ABC) for the realistic case of summary statistics with heterogeneous rates of\nconvergence. We allow some statistics to converge faster than the ABC\ntolerance, other statistics to converge slower, and cover the case where some\nstatistics do not converge at all. We give conditions for the ABC posterior to\nconverge, and provide an explicit representation of the shape of the ABC\nposterior distribution in our general setting; in particular, we show how the\nshape of the posterior depends on the number of slow statistics. We then\nquantify the gain brought by the local linear post-processing step.",
            "author": [
                "Caroline Lawless",
                "Christian P. Robert",
                "Judith Rousseau",
                "Robin J. Ryder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10080v1",
                "http://arxiv.org/pdf/2311.10080v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10077v1",
            "title": "A novel slacks-based interval DEA model and application",
            "updated": "2023-11-16T18:32:29Z",
            "published": "2023-11-16T18:32:29Z",
            "summary": "This paper proposes a novel slacks-based interval DEA approach that computes\ninterval targets, slacks, and crisp inefficiency scores. It uses interval\narithmetic and requires solving a mixed-integer linear program. The\ncorresponding super-efficiency formulation to discriminate among the efficient\nunits is also presented. We also provide a case study of its application to\nsustainable tourism in the Mediterranean region, assessing the sustainable\ntourism efficiency of twelve Mediterranean regions to validate the proposed\napproach. The inputs and outputs cover the three sustainability dimensions and\ninclude GHG emissions as an undesirable output. Three regions were found\ninefficient, and the corresponding inputs and output improvements were\ncomputed. A total rank of the regions was also obtained using the\nsuper-efficiency model.",
            "author": [
                "Manuel Arana-Jim\u00e9nez",
                "Julio Lozano-Ram\u00edrez",
                "M. Carmen S\u00e1nchez-Gil",
                "Atefeh Younesi",
                "Sebasti\u00e1n Lozano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10077v1",
                "http://arxiv.org/pdf/2311.10077v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.AP",
                "90"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10075v1",
            "title": "ChatGPT-3.5, ChatGPT-4, Google Bard, and Microsoft Bing to Improve\n  Health Literacy and Communication in Pediatric Populations and Beyond",
            "updated": "2023-11-16T18:30:14Z",
            "published": "2023-11-16T18:30:14Z",
            "summary": "Purpose: Enhanced health literacy has been linked to better health outcomes;\nhowever, few interventions have been studied. We investigate whether large\nlanguage models (LLMs) can serve as a medium to improve health literacy in\nchildren and other populations.\n  Methods: We ran 288 conditions using 26 different prompts through\nChatGPT-3.5, Microsoft Bing, and Google Bard. Given constraints imposed by rate\nlimits, we tested a subset of 150 conditions through ChatGPT-4. The primary\noutcome measurements were the reading grade level (RGL) and word counts of\noutput.\n  Results: Across all models, output for basic prompts such as \"Explain\" and\n\"What is (are)\" were at, or exceeded, a 10th-grade RGL. When prompts were\nspecified to explain conditions from the 1st to 12th RGL, we found that LLMs\nhad varying abilities to tailor responses based on RGL. ChatGPT-3.5 provided\nresponses that ranged from the 7th-grade to college freshmen RGL while\nChatGPT-4 outputted responses from the 6th-grade to the college-senior RGL.\nMicrosoft Bing provided responses from the 9th to 11th RGL while Google Bard\nprovided responses from the 7th to 10th RGL.\n  Discussion: ChatGPT-3.5 and ChatGPT-4 did better in achieving lower-grade\nlevel outputs. Meanwhile Bard and Bing tended to consistently produce an RGL\nthat is at the high school level regardless of prompt. Additionally, Bard's\nhesitancy in providing certain outputs indicates a cautious approach towards\nhealth information. LLMs demonstrate promise in enhancing health communication,\nbut future research should verify the accuracy and effectiveness of such tools\nin this context.\n  Implications: LLMs face challenges in crafting outputs below a sixth-grade\nreading level. However, their capability to modify outputs above this threshold\nprovides a potential mechanism to improve health literacy and communication in\na pediatric population and beyond.",
            "author": [
                "Kanhai S. Amin",
                "Linda Mayes",
                "Pavan Khosla",
                "Rushabh Doshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10075v1",
                "http://arxiv.org/pdf/2311.10075v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10072v1",
            "title": "Improving 3D Synthetic Jet Modeling in a Crossflow",
            "updated": "2023-11-16T18:17:55Z",
            "published": "2023-11-16T18:17:55Z",
            "summary": "Three different circular synthetic jet modeling inlet conditions are studied\nfor a turbulent crossflow. The study examines the differences when modeling the\nwhole SJA, neck-only or jet-slot-only under constant actuation frequency (f =\n300 Hz) and crossflow blowing ratio ( CB = 0.67). Phase-averaged and\ntime-averaged results reveal that both whole SJA and neck-only methods\ngenerated nearly identical flow fields. For the neck-only case, a notable\nreduction in computational cost is achieved through the implementation of an\nanalytical jet profile. The jet-slot-only method, on the other hand, introduces\nreversed flow during the ingestion cycle, leading to the injection of\nfalse-momentum into the crossflow. However, the false-momentum primarily\naffects the flow immediately downstream of the jet exit, with the boundary\nlayer profile recovering rapidly. A parametric study highlights the importance\nof maintaining a volume ratio less than 1 of ingested to modeled neck volume to\nprevent the creation of false-momentum.",
            "author": [
                "Howard Ho",
                "Ebenezer Essel",
                "Pierre Sullivan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10072v1",
                "http://arxiv.org/pdf/2311.10072v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10065v2",
            "title": "Visual Environment Assessment for Safe Autonomous Quadrotor Landing",
            "updated": "2023-11-17T01:59:10Z",
            "published": "2023-11-16T18:02:10Z",
            "summary": "Autonomous identification and evaluation of safe landing zones are of\nparamount importance for ensuring the safety and effectiveness of aerial robots\nin the event of system failures, low battery, or the successful completion of\nspecific tasks. In this paper, we present a novel approach for detection and\nassessment of potential landing sites for safe quadrotor landing. Our solution\nefficiently integrates 2D and 3D environmental information, eliminating the\nneed for external aids such as GPS and computationally intensive elevation\nmaps. The proposed pipeline combines semantic data derived from a Neural\nNetwork (NN), to extract environmental features, with geometric data obtained\nfrom a disparity map, to extract critical geometric attributes such as slope,\nflatness, and roughness. We define several cost metrics based on these\nattributes to evaluate safety, stability, and suitability of regions in the\nenvironments and identify the most suitable landing area. Our approach runs in\nreal-time on quadrotors equipped with limited computational capabilities.\nExperimental results conducted in diverse environments demonstrate that the\nproposed method can effectively assess and identify suitable landing areas,\nenabling the safe and autonomous landing of a quadrotor.",
            "author": [
                "Mattia Secchiero",
                "Nishanth Bobbili",
                "Yang Zhou",
                "Giuseppe Loianno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10065v2",
                "http://arxiv.org/pdf/2311.10065v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10064v1",
            "title": "Analyzing Deviations of Dyadic Lines in Fast Hough Transform",
            "updated": "2023-11-16T18:00:38Z",
            "published": "2023-11-16T18:00:38Z",
            "summary": "Fast Hough transform is a widely used algorithm in pattern recognition. The\nalgorithm relies on approximating lines using a specific discrete line model\ncalled dyadic lines. The worst-case deviation of a dyadic line from the ideal\nline it used to construct grows as $O(log(n))$, where $n$ is the linear size of\nthe image. But few lines actually reach the worst-case bound. The present paper\naddresses a statistical analysis of the deviation of a dyadic line from its\nideal counterpart. Specifically, our findings show that the mean deviation is\nzero, and the variance grows as $O(log(n))$. As $n$ increases, the distribution\nof these (suitably normalized) deviations converges towards a normal\ndistribution with zero mean and a small variance. This limiting result makes an\nessential use of ergodic theory.",
            "author": [
                "Gleb Smirnov",
                "Simon Karpenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10064v1",
                "http://arxiv.org/pdf/2311.10064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10063v2",
            "title": "FENDL: A library for fusion research and applications",
            "updated": "2023-11-17T10:35:43Z",
            "published": "2023-11-16T18:00:18Z",
            "summary": "The Fusion Evaluated Nuclear Data Library (FENDL) is a comprehensive and\nvalidated collection of nuclear cross section data coordinated by the\nInternational Atomic Energy Agency (IAEA) Nuclear Data Section (NDS). FENDL\nassembles the best nuclear data for fusion applications selected from available\nnuclear data libraries and has been under development for decades. FENDL\ncontains sub-libraries for incident neutron, proton, and deuteron cross\nsections including general purpose and activation files used for particle\ntransport and nuclide inventory calculations.\n  We describe the history, selection of evaluations for the various\nsub-libraries (neutron, proton, deuteron) with the focus on transport and\nreactor dosimetry applications, the processing of the nuclear data for\napplication codes, and the development of the TENDL-2017 library which is the\ncurrently recommended activation library for FENDL. We briefly describe the\nIAEA IRDFF library as the recommended library for dosimetry fusion\napplications. We also present work on validation of the neutron sub-library\nusing a variety of fusion relevant computational and experimental benchmarks. A\nvariety of cross section libraries are used for the validation work including\nFENDL-2.1, FENDL-3.1d, FENDL-3.2, ENDF/B-VIII.0, and JEFF-3.2 with the emphasis\non the FENDL libraries. The results of the experimental validation showed that\nthe performance of FENDL-3.2b is at least as good and in most cases better than\nFENDL-2.1.\n  Future work will consider improved evaluations developed by the International\nNuclear Data Evaluation Network (INDEN). Additional work will be needed to\ninvestigate differences in gas production in structural materials. Covariance\nmatrices need to be updated to support the development of fusion technology.\nAdditional validation work for high-energy neutrons, protons and deuterons, and\nthe activation library will be needed.",
            "author": [
                "G. Schnabel",
                "D. L. Aldama",
                "T. Bohm",
                "U. Fischer",
                "S. Kunieda",
                "A. Trkov",
                "C. Konno",
                "R. Capote",
                "A. J. Koning",
                "S. Breidokaite",
                "T. Eade",
                "M. Fabbri",
                "D. Flammini",
                "L. Isolan",
                "I. Kodeli",
                "M. Ko\u0161\u0165\u00e1l",
                "S. Kwon",
                "D. Laghi",
                "D. Leichtle",
                "S. Nakayama",
                "M. Ohta",
                "L. W. Packer",
                "Y. Qiu",
                "S. Sato",
                "M. Sawan",
                "M. Schulc",
                "G. Stankunas",
                "M. Sumini",
                "A. Valentine",
                "R. Villari",
                "A. \u017dohar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10063v2",
                "http://arxiv.org/pdf/2311.10063v2"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "cs.DL",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10057v3",
            "title": "The Song Describer Dataset: a Corpus of Audio Captions for\n  Music-and-Language Evaluation",
            "updated": "2023-11-22T21:22:11Z",
            "published": "2023-11-16T17:52:21Z",
            "summary": "We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of\nhigh-quality audio-caption pairs, designed for the evaluation of\nmusic-and-language models. The dataset consists of 1.1k human-written natural\nlanguage descriptions of 706 music recordings, all publicly accessible and\nreleased under Creative Common licenses. To showcase the use of our dataset, we\nbenchmark popular models on three key music-and-language tasks (music\ncaptioning, text-to-music generation and music-language retrieval). Our\nexperiments highlight the importance of cross-dataset evaluation and offer\ninsights into how researchers can use SDD to gain a broader understanding of\nmodel performance.",
            "author": [
                "Ilaria Manco",
                "Benno Weck",
                "SeungHeon Doh",
                "Minz Won",
                "Yixiao Zhang",
                "Dmitry Bogdanov",
                "Yusong Wu",
                "Ke Chen",
                "Philip Tovstogan",
                "Emmanouil Benetos",
                "Elio Quinton",
                "Gy\u00f6rgy Fazekas",
                "Juhan Nam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10057v3",
                "http://arxiv.org/pdf/2311.10057v3"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10054v1",
            "title": "Is \"A Helpful Assistant\" the Best Role for Large Language Models? A\n  Systematic Evaluation of Social Roles in System Prompts",
            "updated": "2023-11-16T17:48:55Z",
            "published": "2023-11-16T17:48:55Z",
            "summary": "Prompting serves as the major way humans interact with Large Language Models\n(LLM). Commercial AI systems commonly define the role of the LLM in system\nprompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of the\ndefault system prompt. But is \"a helpful assistant\" the best role for LLMs? In\nthis study, we present a systematic evaluation of how social roles in system\nprompts affect model performance. We curate a list of 162 roles covering 6\ntypes of interpersonal relationships and 8 types of occupations. Through\nextensive analysis of 3 popular LLMs and 2457 questions, we show that adding\ninterpersonal roles in prompts consistently improves the models' performance\nover a range of questions. Moreover, while we find that using gender-neutral\nroles and specifying the role as the audience leads to better performances,\npredicting which role leads to the best performance remains a challenging task,\nand that frequency, similarity, and perplexity do not fully explain the effect\nof social roles on model performances. Our results can help inform the design\nof system prompts for AI systems. Code and data are available at\nhttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.",
            "author": [
                "Mingqian Zheng",
                "Jiaxin Pei",
                "David Jurgens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10054v1",
                "http://arxiv.org/pdf/2311.10054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10050v1",
            "title": "Graph models for Cybersecurity -- A Survey",
            "updated": "2023-11-16T17:45:49Z",
            "published": "2023-11-16T17:45:49Z",
            "summary": "Graph models are helpful means of analyzing computer networks as well as\ncomplex system architectures for security. In this paper we evaluate the\ncurrent state of research for representing and analysing cyber-attack using\ngraph models, i.e. attack graph (AG) formalisms. We propose a taxonomy on\nattack graph formalisms, based on 70 models, which we analysed with respect to\ntheir \\textit{graph semantic}, involved agents and analysis features.\nAdditionally, we adress which formalisms allow for automatic attack graph\ngeneration from raw or processes data inputs. Our taxonomy is especially\ndesigned to help users and applied researchers identify a suitable AG model for\ntheir needs. A summary of the individual AG formalisms is provided as\nsupplementary material.",
            "author": [
                "Jasmin Wachter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10050v1",
                "http://arxiv.org/pdf/2311.10050v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10048v1",
            "title": "Linear-scaling local natural orbital CCSD(T) approach for open-shell\n  systems: algorithm, benchmarks, and large-scale applications",
            "updated": "2023-11-16T17:44:33Z",
            "published": "2023-11-16T17:44:33Z",
            "summary": "The extension of the highly-optimized local natural orbital (LNO) CCSD(T)\nmethod is presented for high-spin open-shell molecules. The techniques enabling\nthe outstanding efficiency of the closed-shell LNO-CCSD(T) variant are adopted,\nincluding the iteration- and redundancy-free MP2 and (T) formulations, as well\nas the integral-direct, memory- and disk use economic, and OpenMP-parallel\nalgorithms. For large molecules, the efficiency of our open-shell LNO-CCSD(T)\nmethod approaches that of its closed-shell parent method due to a novel\napproximation for higher-order long-range spin-polarization effects. The\naccuracy of open-shell LNO-CCSD(T) is extensively tested for radicals and\nreactions thereof, ionization processes, as well as spin-state splittings and\ntransition-metal compounds. At the size range, where the canonical CCSD(T)\nreference is accessible (up to 20-30 atoms) the average open-shell LNO-CCSD(T)\ncorrelation energies are found to be 99.9-99.95% accurate, which translates\ninto average absolute deviations of a few tenth of a kcal/mol in the\ninvestigated energy differences already with the default settings. This enables\nthe accurate modeling of large systems with complex electronic structure, as\nillustrated on open-shell organic radicals and transition metal complexes of up\nto 179 atoms, as well as on challenging biochemical systems, including up to\n601 atoms and 11,000 basis functions. While the protein models involve\ndifficulties for local approximations, such as the spin states of a bounded\niron ion or an extremely delocalized singly occupied orbital, the corresponding\nsingle-node LNO-CCSD(T) computations were feasible in a matter of days with 10s\nto a 100 GB of memory use. Therefore, the new LNO-CCSD(T) implementation\nenables highly-accurate computations for open-shell systems of unprecedented\nsize and complexity with widely accessible hardware.",
            "author": [
                "P. Bern\u00e1t Szab\u00f3",
                "J\u00f3zsef Cs\u00f3ka",
                "Mih\u00e1ly K\u00e1llay",
                "P\u00e9ter R. Nagy"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acs.jctc.3c00881",
                "http://arxiv.org/abs/2311.10048v1",
                "http://arxiv.org/pdf/2311.10048v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10047v1",
            "title": "Frozen Set Design for Precoded Polar Codes",
            "updated": "2023-11-16T17:43:13Z",
            "published": "2023-11-16T17:43:13Z",
            "summary": "This paper focuses on the frozen set design for precoded polar codes decoded\nby the successive cancellation list (SCL) algorithm. We propose a novel frozen\nset design method, whose computational complexity is low due to the use of\nanalytical bounds and constrained frozen set structure. We derive new bounds\nbased on the recently published complexity analysis of SCL with near\nmaximum-likelihood (ML) performance. To predict the ML performance, we employ\nthe state-of-the-art bounds relying on the code weight distribution. The bounds\nand constrained frozen set structure are incorporated into the genetic\nalgorithm to generate optimized frozen sets with low complexity. Our simulation\nresults show that the constructed precoded polar codes of length 512 have a\nsuperior frame error rate (FER) performance compared to the state-of-the-art\ncodes under SCL decoding with various list sizes.",
            "author": [
                "Vera Miloslavskaya",
                "Yonghui Li",
                "Branka Vucetic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10047v1",
                "http://arxiv.org/pdf/2311.10047v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT",
                "94B60",
                "E.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10046v1",
            "title": "Computation of invariant densities for continued fraction algorithms",
            "updated": "2023-11-16T17:42:05Z",
            "published": "2023-11-16T17:42:05Z",
            "summary": "We introduce the notion of matrices graph, defining continued fraction\nalgorithms where the past and the future are almost independent. We provide an\nalgorithm to convert more general algorithms into matrices graphs. We present\nan algorithm that computes exact invariant densities of certain continued\nfraction algorithms, including classical ones and some of their extensions. For\nfinite extensions of the classical additive algorithm with two coordinates, we\nprovide a more precise algorithm that decides whether the invariant density is\ncomposed of rational fractions and computes it. For any finite set of quadratic\nnumbers, we construct a continued fraction algorithm whose invariant density\nare rational fractions containing the quadratic numbers.",
            "author": [
                "Paul Mercat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10046v1",
                "http://arxiv.org/pdf/2311.10046v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "28D05, 37A05, 37E99"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10042v1",
            "title": "Depth Insight -- Contribution of Different Features to Indoor\n  Single-image Depth Estimation",
            "updated": "2023-11-16T17:38:21Z",
            "published": "2023-11-16T17:38:21Z",
            "summary": "Depth estimation from a single image is a challenging problem in computer\nvision because binocular disparity or motion information is absent. Whereas\nimpressive performances have been reported in this area recently using\nend-to-end trained deep neural architectures, as to what cues in the images\nthat are being exploited by these black box systems is hard to know. To this\nend, in this work, we quantify the relative contributions of the known cues of\ndepth in a monocular depth estimation setting using an indoor scene data set.\nOur work uses feature extraction techniques to relate the single features of\nshape, texture, colour and saturation, taken in isolation, to predict depth. We\nfind that the shape of objects extracted by edge detection substantially\ncontributes more than others in the indoor setting considered, while the other\nfeatures also have contributions in varying degrees. These insights will help\noptimise depth estimation models, boosting their accuracy and robustness. They\npromise to broaden the practical applications of vision-based depth estimation.\nThe project code is attached to the supplementary material and will be\npublished on GitHub.",
            "author": [
                "Yihong Wu",
                "Yuwen Heng",
                "Mahesan Niranjan",
                "Hansung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10042v1",
                "http://arxiv.org/pdf/2311.10042v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10040v1",
            "title": "A characterization of efficiently compilable constraint languages",
            "updated": "2023-11-16T17:37:13Z",
            "published": "2023-11-16T17:37:13Z",
            "summary": "A central task in knowledge compilation is to compile a CNF-SAT instance into\na succinct representation format that allows efficient operations such as\ntesting satisfiability, counting, or enumerating all solutions. Useful\nrepresentation formats studied in this area range from ordered binary decision\ndiagrams (OBDDs) to circuits in decomposable negation normal form (DNNFs).\n  While it is known that there exist CNF formulas that require exponential size\nrepresentations, the situation is less well studied for other types of\nconstraints than Boolean disjunctive clauses. The constraint satisfaction\nproblem (CSP) is a powerful framework that generalizes CNF-SAT by allowing\narbitrary sets of constraints over any finite domain. The main goal of our work\nis to understand for which type of constraints (also called the constraint\nlanguage) it is possible to efficiently compute representations of polynomial\nsize. We answer this question completely and prove two tight characterizations\nof efficiently compilable constraint languages, depending on whether target\nformat is structured.\n  We first identify the combinatorial property of ``strong blockwise\ndecomposability'' and show that if a constraint language has this property, we\ncan compute DNNF representations of linear size. For all other constraint\nlanguages we construct families of CSP-instances that provably require DNNFs of\nexponential size. For a subclass of ``strong uniformly blockwise decomposable''\nconstraint languages we obtain a similar dichotomy for structured DNNFs. In\nfact, strong (uniform) blockwise decomposability even allows efficient\ncompilation into multi-valued analogs of OBDDs and FBDDs, respectively. Thus,\nwe get complete characterizations for all knowledge compilation classes between\nO(B)DDs and DNNFs.",
            "author": [
                "Christoph Berkholz",
                "Stefan Mengel",
                "Hermann Wilhelm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10040v1",
                "http://arxiv.org/pdf/2311.10040v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10039v1",
            "title": "Software Dependability Measurement at the Age Of 36",
            "updated": "2023-11-16T17:36:28Z",
            "published": "2023-11-16T17:36:28Z",
            "summary": "Thirty-six years after the first edition of IEEE standard 982.1, Measures of\nthe Software Aspects of Dependability, the third edition focuses on the\nmeasurement of in-service software dependability. This article explains how\nthis new point of view evolved and shaped the third edition's guidance for\nsoftware dependability measurement.",
            "author": [
                "Robert V. Binder"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MC.2023.3327668",
                "http://arxiv.org/abs/2311.10039v1",
                "http://arxiv.org/pdf/2311.10039v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CE",
                "cs.CR",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10036v2",
            "title": "Dynamic CBCT Imaging using Prior Model-Free Spatiotemporal Implicit\n  Neural Representation (PMF-STINR)",
            "updated": "2023-12-04T15:59:47Z",
            "published": "2023-11-16T17:34:32Z",
            "summary": "Dynamic cone-beam computed tomography (CBCT) can capture\nhigh-spatial-resolution, time-varying images for motion monitoring, patient\nsetup, and adaptive planning of radiotherapy. However, dynamic CBCT\nreconstruction is an extremely ill-posed spatiotemporal inverse problem, as\neach CBCT volume in the dynamic sequence is only captured by one or a few X-ray\nprojections. We developed a machine learning-based technique, prior-model-free\nspatiotemporal implicit neural representation (PMF-STINR), to reconstruct\ndynamic CBCTs from sequentially acquired X-ray projections. PMF-STINR employs a\njoint image reconstruction and registration approach to address the\nunder-sampling challenge. Specifically, PMF-STINR uses spatial implicit neural\nrepresentation to reconstruct a reference CBCT volume, and it applies temporal\nINR to represent the intra-scan dynamic motion with respect to the reference\nCBCT to yield dynamic CBCTs. PMF-STINR couples the temporal INR with a\nlearning-based B-spline motion model to capture time-varying deformable motion\nduring the reconstruction. Compared with previous methods, the spatial INR, the\ntemporal INR, and the B-spline model of PMF-STINR are all learned on the fly\nduring reconstruction in a one-shot fashion, without using any patient-specific\nprior knowledge or motion sorting/binning. PMF-STINR was evaluated via digital\nphantom simulations, physical phantom measurements, and a multi-institutional\npatient dataset featuring various imaging protocols (half-fan/full-fan, full\nsampling/sparse sampling, different energy and mAs settings, etc.). The results\nshowed that the one-shot learning-based PMF-STINR can accurately and robustly\nreconstruct dynamic CBCTs and capture highly irregular motion with high\ntemporal (~0.1s) resolution and sub-millimeter accuracy. It can be a promising\ntool for motion management by offering richer motion information than\ntraditional 4D-CBCTs.",
            "author": [
                "Hua-Chieh Shao",
                "Mengke Tielige",
                "Tinsu Pan",
                "You Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10036v2",
                "http://arxiv.org/pdf/2311.10036v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10034v1",
            "title": "Match and Locate: low-frequency monocular odometry based on deep feature\n  matching",
            "updated": "2023-11-16T17:32:58Z",
            "published": "2023-11-16T17:32:58Z",
            "summary": "Accurate and robust pose estimation plays a crucial role in many robotic\nsystems. Popular algorithms for pose estimation typically rely on high-fidelity\nand high-frequency signals from various sensors. Inclusion of these sensors\nmakes the system less affordable and much more complicated. In this work we\nintroduce a novel approach for the robotic odometry which only requires a\nsingle camera and, importantly, can produce reliable estimates given even\nextremely low-frequency signal of around one frame per second. The approach is\nbased on matching image features between the consecutive frames of the video\nstream using deep feature matching models. The resulting coarse estimate is\nthen adjusted by a convolutional neural network, which is also responsible for\nestimating the scale of the transition, otherwise irretrievable using only the\nfeature matching information. We evaluate the performance of the approach in\nthe AISG-SLA Visual Localisation Challenge and find that while being\ncomputationally efficient and easy to implement our method shows competitive\nresults with only around $3^{\\circ}$ of orientation estimation error and $2m$\nof translation estimation error taking the third place in the challenge.",
            "author": [
                "Stepan Konev",
                "Yuriy Biktairov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10034v1",
                "http://arxiv.org/pdf/2311.10034v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10025v1",
            "title": "A Novel Neural Network-Based Federated Learning System for Imbalanced\n  and Non-IID Data",
            "updated": "2023-11-16T17:14:07Z",
            "published": "2023-11-16T17:14:07Z",
            "summary": "With the growth of machine learning techniques, privacy of data of users has\nbecome a major concern. Most of the machine learning algorithms rely heavily on\nlarge amount of data which may be collected from various sources. Collecting\nthese data yet maintaining privacy policies has become one of the most\nchallenging tasks for the researchers. To combat this issue, researchers have\nintroduced federated learning, where a prediction model is learnt by ensuring\nthe privacy of data of clients data. However, the prevalent federated learning\nalgorithms possess an accuracy and efficiency trade-off, especially for non-IID\ndata. In this research, we propose a centralized, neural network-based\nfederated learning system. The centralized algorithm incorporates micro-level\nparallel processing inspired by the traditional mini-batch algorithm where the\nclient devices and the server handle the forward and backward propagation\nrespectively. We also devise a semi-centralized version of our proposed\nalgorithm. This algorithm takes advantage of edge computing for minimizing the\nload from the central server, where clients handle both the forward and\nbackward propagation while sacrificing the overall train time to some extent.\nWe evaluate our proposed systems on five well-known benchmark datasets and\nachieve satisfactory performance in a reasonable time across various data\ndistribution settings as compared to some existing benchmark algorithms.",
            "author": [
                "Mahfuzur Rahman Chowdhury",
                "Muhammad Ibrahim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10025v1",
                "http://arxiv.org/pdf/2311.10025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10018v1",
            "title": "On the Overconfidence Problem in Semantic 3D Mapping",
            "updated": "2023-11-16T17:02:34Z",
            "published": "2023-11-16T17:02:34Z",
            "summary": "Semantic 3D mapping, the process of fusing depth and image segmentation\ninformation between multiple views to build 3D maps annotated with object\nclasses in real-time, is a recent topic of interest. This paper highlights the\nfusion overconfidence problem, in which conventional mapping methods assign\nhigh confidence to the entire map even when they are incorrect, leading to\nmiscalibrated outputs. Several methods to improve uncertainty calibration at\ndifferent stages in the fusion pipeline are presented and compared on the\nScanNet dataset. We show that the most widely used Bayesian fusion strategy is\namong the worst calibrated, and propose a learned pipeline that combines fusion\nand calibration, GLFS, which achieves simultaneously higher accuracy and 3D map\ncalibration while retaining real-time capability. We further illustrate the\nimportance of map calibration on a downstream task by showing that\nincorporating proper semantic fusion on a modular ObjectNav agent improves its\nsuccess rates. Our code will be provided on Github for reproducibility upon\nacceptance.",
            "author": [
                "Joao Marcos Correia Marques",
                "Albert Zhai",
                "Shenlong Wang",
                "Kris Hauser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10018v1",
                "http://arxiv.org/pdf/2311.10018v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO",
                "I.2.9; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10127v1",
            "title": "Learning interactions to boost human creativity with bandits and GPT-4",
            "updated": "2023-11-16T16:53:17Z",
            "published": "2023-11-16T16:53:17Z",
            "summary": "This paper considers how interactions with AI algorithms can boost human\ncreative thought. We employ a psychological task that demonstrates limits on\nhuman creativity, namely semantic feature generation: given a concept name,\nrespondents must list as many of its features as possible. Human participants\ntypically produce only a fraction of the features they know before getting\n\"stuck.\" In experiments with humans and with a language AI (GPT-4) we contrast\nbehavior in the standard task versus a variant in which participants can ask\nfor algorithmically-generated hints. Algorithm choice is administered by a\nmulti-armed bandit whose reward indicates whether the hint helped generating\nmore features. Humans and the AI show similar benefits from hints, and\nremarkably, bandits learning from AI responses prefer the same prompting\nstrategy as those learning from human behavior. The results suggest that\nstrategies for boosting human creativity via computer interactions can be\nlearned by bandits run on groups of simulated participants.",
            "author": [
                "Ara Vartanian",
                "Xiaoxi Sun",
                "Yun-Shiuan Chuang",
                "Siddharth Suresh",
                "Xiaojin Zhu",
                "Timothy T. Rogers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10127v1",
                "http://arxiv.org/pdf/2311.10127v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10011v1",
            "title": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot\n  Class-Agnostic Counting",
            "updated": "2023-11-16T16:50:56Z",
            "published": "2023-11-16T16:50:56Z",
            "summary": "The class-agnostic counting (CAC) task has recently been proposed to solve\nthe problem of counting all objects of an arbitrary class with several\nexemplars given in the input image. To address this challenging task, existing\nleading methods all resort to density map regression, which renders them\nimpractical for downstream tasks that require object locations and restricts\ntheir ability to well explore the scale information of exemplars for\nsupervision. To address the limitations, we propose a novel localization-based\nCAC approach, termed Scale-modulated Query and Localization Network (SQLNet).\nIt fully explores the scales of exemplars in both the query and localization\nstages and achieves effective counting by accurately locating each object and\npredicting its approximate size. Specifically, during the query stage, rich\ndiscriminative representations of the target class are acquired by the\nHierarchical Exemplars Collaborative Enhancement (HECE) module from the few\nexemplars through multi-scale exemplar cooperation with equifrequent size\nprompt embedding. These representations are then fed into the Exemplars-Unified\nQuery Correlation (EUQC) module to interact with the query features in a\nunified manner and produce the correlated query tensor. In the localization\nstage, the Scale-aware Multi-head Localization (SAML) module utilizes the query\ntensor to predict the confidence, location, and size of each potential object.\nMoreover, a scale-aware localization loss is introduced, which exploits\nflexible location associations and exemplar scales for supervision to optimize\nthe model performance. Extensive experiments demonstrate that SQLNet\noutperforms state-of-the-art methods on popular CAC benchmarks, achieving\nexcellent performance not only in counting accuracy but also in localization\nand bounding box generation. Our codes will be available at\nhttps://github.com/HCPLab-SYSU/SQLNet",
            "author": [
                "Hefeng Wu",
                "Yandong Chen",
                "Lingbo Liu",
                "Tianshui Chen",
                "Keze Wang",
                "Liang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10011v1",
                "http://arxiv.org/pdf/2311.10011v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10007v1",
            "title": "Dynamic Clustering of Active Rings",
            "updated": "2023-11-16T16:43:10Z",
            "published": "2023-11-16T16:43:10Z",
            "summary": "A collection of rings made of active Brownian particles (ABPs) for different\npacking fractions and activities is investigated using computer simulations. We\nshow that active rings display an emergent dynamic clustering instead of the\nconventional motility-induced phase separation (MIPS) as in the case of\ncollection of ABPs. Surprisingly, increasing packing fraction of rings exhibits\na non-monotonicity in the dynamics due to the formation of a large number of\nsmall clusters. The conformational fluctuations of the polymers suppress the\nusual MIPS exhibited by ABPs. Our findings demonstrate how the motion of a\ncollection of rings is influenced by the interplay of activity, topology, and\nconnectivity.",
            "author": [
                "Ligesh Theeyancheri",
                "Subhasish Chaki",
                "Tapomoy Bhattacharjee",
                "Rajarshi Chakrabarti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10007v1",
                "http://arxiv.org/pdf/2311.10007v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10004v1",
            "title": "Finite-temperature vibronic spectra from the split-operator thermofield\n  coherence dynamics",
            "updated": "2023-11-16T16:33:36Z",
            "published": "2023-11-16T16:33:36Z",
            "summary": "The inclusion of temperature effects is important to properly simulate and\ninterpret experimentally observed vibrationally resolved electronic spectra. We\npresent a numerically exact approach for evaluating these spectra at finite\ntemperature using the thermofield coherence dynamics. In this method, which\navoids implementing an algorithm for solving the von Neumann equation for the\ncoherence, the thermal vibrational ensemble is first mapped to a pure-state\nwavepacket in an augmented space, and this wavepacket is then propagated by\nsolving the standard, zero-temperature Schr\\\"{o}dinger equation with the\nsplit-operator Fourier method. We show that the finite-temperature spectra\nobtained with the thermofield coherence dynamics in a Morse potential agree\nexactly with those computed by Boltzmann-averaging the spectra of individual\nvibrational levels. Because the split-operator thermofield dynamics on a full\ntensor-product grid is restricted to low-dimensional systems, we briefly\ndiscuss how the accessible dimensionality can be increased by various\ntechniques developed for the zero-temperature split-operator Fourier method.",
            "author": [
                "Zhan Tong Zhang",
                "Ji\u0159\u00ed Van\u00ed\u010dek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10004v1",
                "http://arxiv.org/pdf/2311.10004v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10002v1",
            "title": "Straggler-resilient Federated Learning: Tackling Computation\n  Heterogeneity with Layer-wise Partial Model Training in Mobile Edge Network",
            "updated": "2023-11-16T16:30:04Z",
            "published": "2023-11-16T16:30:04Z",
            "summary": "Federated Learning (FL) enables many resource-limited devices to train a\nmodel collaboratively without data sharing. However, many existing works focus\non model-homogeneous FL, where the global and local models are the same size,\nignoring the inherently heterogeneous computational capabilities of different\ndevices and restricting resource-constrained devices from contributing to FL.\nIn this paper, we consider model-heterogeneous FL and propose Federated Partial\nModel Training (FedPMT), where devices with smaller computational capabilities\nwork on partial models (subsets of the global model) and contribute to the\nglobal model. Different from Dropout-based partial model generation, which\nremoves neurons in hidden layers at random, model training in FedPMT is\nachieved from the back-propagation perspective. As such, all devices in FedPMT\nprioritize the most crucial parts of the global model. Theoretical analysis\nshows that the proposed partial model training design has a similar convergence\nrate to the widely adopted Federated Averaging (FedAvg) algorithm,\n$\\mathcal{O}(1/T)$, with the sub-optimality gap enlarged by a constant factor\nrelated to the model splitting design in FedPMT. Empirical results show that\nFedPMT significantly outperforms the existing benchmark FedDrop. Meanwhile,\ncompared to the popular model-homogeneous benchmark, FedAvg, FedPMT reaches the\nlearning target in a shorter completion time, thus achieving a better trade-off\nbetween learning accuracy and completion time.",
            "author": [
                "Hongda Wu",
                "Ping Wang",
                "C V Aswartha Narayana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10002v1",
                "http://arxiv.org/pdf/2311.10002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10001v1",
            "title": "Fast return-level estimates for flood insurance via an improved Bennett\n  inequality for random variables with differing upper bounds",
            "updated": "2023-11-16T16:29:56Z",
            "published": "2023-11-16T16:29:56Z",
            "summary": "The k-year return levels of insurance losses due to flooding can be estimated\nby simulating and then summing a large number of independent losses for each of\na large number of hypothetical years of flood events, and replicating this a\nlarge number of times. This leads to repeated realisations of the total losses\nover each year in a long sequence of years, from which return levels and their\nuncertainty can be estimated; the procedure, however, is highly computationally\nintensive. We develop and use a new, Bennett-like concentration inequality in a\nprocedure that provides conservative but relatively accurate estimates of\nreturn levels at a fraction of the computational cost. Bennett's inequality\nprovides concentration bounds on deviations of a sum of independent random\nvariables from its expectation; it accounts for the different variances of each\nof the variables but uses only a single, uniform upper bound on their support.\nMotivated by the variability in the total insured value of insurance risks\nwithin a portfolio, we consider the case where the bounds on the support can\nvary by an order of magnitude or more, and obtain tractable concentration\nbounds. Simulation studies and application to a representative portfolio\ndemonstrate the substantial improvement of our bounds over those obtained\nthrough Bennett's inequality. We then develop an importance sampling procedure\nthat repeatedly samples the loss for each year from the distribution implied by\nthe concentration inequality, leading to conservative estimates of the return\nlevels and their uncertainty.",
            "author": [
                "Anna Maria Barlow",
                "Chris Sherlock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10001v1",
                "http://arxiv.org/pdf/2311.10001v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09999v1",
            "title": "TransFusion -- A Transparency-Based Diffusion Model for Anomaly\n  Detection",
            "updated": "2023-11-16T16:23:11Z",
            "published": "2023-11-16T16:23:11Z",
            "summary": "Surface anomaly detection is a vital component in manufacturing inspection.\nReconstructive anomaly detection methods restore the normal appearance of an\nobject, ideally modifying only the anomalous regions. Due to the limitations of\ncommonly used reconstruction architectures, the produced reconstructions are\noften poor and either still contain anomalies or lack details in anomaly-free\nregions. Recent reconstructive methods adopt diffusion models, however with the\nstandard diffusion process the problems are not adequately addressed. We\npropose a novel transparency-based diffusion process, where the transparency of\nanomalous regions is progressively increased, restoring their normal appearance\naccurately and maintaining the appearance of anomaly-free regions without loss\nof detail. We propose TRANSparency DifFUSION (TransFusion), a discriminative\nanomaly detection method that implements the proposed diffusion process,\nenabling accurate downstream anomaly detection. TransFusion achieves\nstate-of-the-art performance on both the VisA and the MVTec AD datasets, with\nan image-level AUROC of 98.5% and 99.2%, respectively.",
            "author": [
                "Matic Fu\u010dka",
                "Vitjan Zavrtanik",
                "Danijel Sko\u010daj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09999v1",
                "http://arxiv.org/pdf/2311.09999v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09998v1",
            "title": "DeepEMD: A Transformer-based Fast Estimation of the Earth Mover's\n  Distance",
            "updated": "2023-11-16T16:14:58Z",
            "published": "2023-11-16T16:14:58Z",
            "summary": "The Earth Mover's Distance (EMD) is the measure of choice between point\nclouds. However the computational cost to compute it makes it prohibitive as a\ntraining loss, and the standard approach is to use a surrogate such as the\nChamfer distance. We propose an attention-based model to compute an accurate\napproximation of the EMD that can be used as a training loss for generative\nmodels. To get the necessary accurate estimation of the gradients we train our\nmodel to explicitly compute the matching between point clouds instead of EMD\nitself. We cast this new objective as the estimation of an attention matrix\nthat approximates the ground truth matching matrix. Experiments show that this\nmodel provides an accurate estimate of the EMD and its gradient with a wall\nclock speed-up of more than two orders of magnitude with respect to the exact\nHungarian matching algorithm and one order of magnitude with respect to the\nstandard approximate Sinkhorn algorithm, allowing in particular to train a\npoint cloud VAE with the EMD itself. Extensive evaluation show the remarkable\nbehaviour of this model when operating out-of-distribution, a key requirement\nfor a distance surrogate. Finally, the model generalizes very well to point\nclouds during inference several times larger than during training.",
            "author": [
                "Atul Kumar Sinha",
                "Francois Fleuret"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09998v1",
                "http://arxiv.org/pdf/2311.09998v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09996v1",
            "title": "Tailoring hot-carrier distributions of plasmonic nanostructures through\n  surface alloying",
            "updated": "2023-11-16T16:13:58Z",
            "published": "2023-11-16T16:13:58Z",
            "summary": "Alloyed metal nanoparticles are a promising platform for plasmonically\nenabled hot-carrier generation, which can be used to drive photochemical\nreactions. Although the non-plasmonic component in these systems has been\ninvestigated for its potential to enhance catalytic activity, its capacity to\naffect the photochemical process favorably has been underexplored by\ncomparison. Here, we study the impact of surface alloy species and\nconcentration on hot-carrier generation in Ag nanoparticles. By\nfirst-principles simulations, we photoexcite the localized surface plasmon,\nallow it to dephase, and calculate spatially and energetically resolved\nhot-carrier distributions. We show that the presence of non-noble species in\nthe topmost surface layer drastically enhances hot-hole generation at the\nsurface at the expense of hot-hole generation in the bulk, due to the\nadditional d-type states that are introduced to the surface. The energy of the\ngenerated holes can be tuned by choice of the alloyant, with systematic trends\nacross the d-band block. Already low surface alloy concentrations have a large\nimpact, with a saturation of the enhancement effect typically close to 75% of a\nmonolayer. Hot-electron generation at the surface is hindered slightly by\nalloying but here an judicious choice of the alloy composition allows one to\nstrike a balance between hot electrons and holes. In this context, it is also\nimportant to consider that increasing the alloy concentration broadens the\nlocalized surface plasmon resonance, and thus decreases hot-carrier generation\noverall. Our work underscores the promise of utilizing multicomponent\nnanoparticles to achieve enhanced control over plasmonic catalysis, and\nprovides guidelines for how hot-carrier distributions can be tailored by\ndesigning the electronic structure of the surface through alloying.",
            "author": [
                "Jakub Fojt",
                "Tuomas P. Rossi",
                "Priyank V. Kumar",
                "Paul Erhart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09996v1",
                "http://arxiv.org/pdf/2311.09996v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09995v1",
            "title": "Realistic Runtime Analysis for Quantum Simplex Computation",
            "updated": "2023-11-16T16:11:44Z",
            "published": "2023-11-16T16:11:44Z",
            "summary": "In recent years, strong expectations have been raised for the possible power\nof quantum computing for solving difficult optimization problems, based on\ntheoretical, asymptotic worst-case bounds. Can we expect this to have\nconsequences for Linear and Integer Programming when solving instances of\npractically relevant size, a fundamental goal of Mathematical Programming,\nOperations Research and Algorithm Engineering? Answering this question faces a\ncrucial impediment: The lack of sufficiently large quantum platforms prevents\nperforming real-world tests for comparison with classical methods.\n  In this paper, we present a quantum analog for classical runtime analysis\nwhen solving real-world instances of important optimization problems. To this\nend, we measure the expected practical performance of quantum computers by\nanalyzing the expected gate complexity of a quantum algorithm. The lack of\npractical quantum platforms for experimental comparison is addressed by hybrid\nbenchmarking, in which the algorithm is performed on a classical system,\nlogging the expected cost of the various subroutines that are employed by the\nquantum versions. In particular, we provide an analysis of quantum methods for\nLinear Programming, for which recent work has provided asymptotic speedup\nthrough quantum subroutines for the Simplex method. We show that a practical\nquantum advantage for realistic problem sizes would require quantum gate\noperation times that are considerably below current physical limitations.",
            "author": [
                "Sabrina Ammann",
                "Maximilian Hess",
                "Debora Ramacciotti",
                "S\u00e1ndor P. Fekete",
                "Paulina L. A. Goedicke",
                "David Gross",
                "Andreea Lefterovici",
                "Tobias J. Osborne",
                "Michael Perk",
                "Antonio Rotundo",
                "S. E. Skelton",
                "Sebastian Stiller",
                "Timo de Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09995v1",
                "http://arxiv.org/pdf/2311.09995v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09993v1",
            "title": "Generative AI for Hate Speech Detection: Evaluation and Findings",
            "updated": "2023-11-16T16:09:43Z",
            "published": "2023-11-16T16:09:43Z",
            "summary": "Automatic hate speech detection using deep neural models is hampered by the\nscarcity of labeled datasets, leading to poor generalization. To mitigate this\nproblem, generative AI has been utilized to generate large amounts of synthetic\nhate speech sequences from available labeled examples, leveraging the generated\ndata in finetuning large pre-trained language models (LLMs). In this chapter,\nwe provide a review of relevant methods, experimental setups and evaluation of\nthis approach. In addition to general LLMs, such as BERT, RoBERTa and ALBERT,\nwe apply and evaluate the impact of train set augmentation with generated data\nusing LLMs that have been already adapted for hate detection, including\nRoBERTa-Toxicity, HateBERT, HateXplain, ToxDect, and ToxiGen. An empirical\nstudy corroborates our previous findings, showing that this approach improves\nhate speech generalization, boosting recall performance across data\ndistributions. In addition, we explore and compare the performance of the\nfinetuned LLMs with zero-shot hate detection using a GPT-3.5 model. Our results\ndemonstrate that while better generalization is achieved using the GPT-3.5\nmodel, it achieves mediocre recall and low precision on most datasets. It is an\nopen question whether the sensitivity of models such as GPT-3.5, and onward,\ncan be improved using similar techniques of text generation.",
            "author": [
                "Sagi Pendzel",
                "Tomer Wullach",
                "Amir Adler",
                "Einat Minkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09993v1",
                "http://arxiv.org/pdf/2311.09993v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09989v1",
            "title": "Xputer: Bridging Data Gaps with NMF, XGBoost, and a Streamlined GUI\n  Experience",
            "updated": "2023-11-16T16:07:19Z",
            "published": "2023-11-16T16:07:19Z",
            "summary": "The rapid proliferation of data across diverse fields has accentuated the\nimportance of accurate imputation for missing values. This task is crucial for\nensuring data integrity and deriving meaningful insights. In response to this\nchallenge, we present Xputer, a novel imputation tool that adeptly integrates\nNon-negative Matrix Factorization (NMF) with the predictive strengths of\nXGBoost. One of Xputer's standout features is its versatility: it supports zero\nimputation, enables hyperparameter optimization through Optuna, and allows\nusers to define the number of iterations. For enhanced user experience and\naccessibility, we have equipped Xputer with an intuitive Graphical User\nInterface (GUI) ensuring ease of handling, even for those less familiar with\ncomputational tools. In performance benchmarks, Xputer not only rivals the\ncomputational speed of established tools such as IterativeImputer but also\noften outperforms them in terms of imputation accuracy. Furthermore, Xputer\nautonomously handles a diverse spectrum of data types, including categorical,\ncontinuous, and Boolean, eliminating the need for prior preprocessing. Given\nits blend of performance, flexibility, and user-friendly design, Xputer emerges\nas a state-of-the-art solution in the realm of data imputation.",
            "author": [
                "Saleena Younus",
                "Lars R\u00f6nnstrand",
                "Julhash U. Kazi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09989v1",
                "http://arxiv.org/pdf/2311.09989v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09988v1",
            "title": "Computing defining ideals of space spectral curves for algebro-geometric\n  third order ODOs",
            "updated": "2023-11-16T16:06:56Z",
            "published": "2023-11-16T16:06:56Z",
            "summary": "Commuting pairs of ordinary differential operators (ODOs) have been related\nto plane algebraic curves since the work of Burchnall and Chaundy a century\nago. We introduce now the concept of Burchnall-Chaundy (BC) ideal of a\ncommuting pair, as the ideal of all constant coefficient bivariate polynomials\nsatisfied by the pair. We prove this prime ideal to be equal to the radical of\na differential elimination ideal and the defining ideal of a plane algebraic\ncurve, the spectral curve of a commuting pair.\n  The ODOs of this work have coefficients in an arbitrary differential field\nwith field of constants algebraically closed and of characteristic zero.\nMotivated by the extension of the recently introduced Picard-Vessiot theory for\nspectral problems $L(y)=\\lambda y$, where $\\lambda$ is an algebraic parameter,\nwe also define the BC ideal of an algebro-geometric third order operator $L$.\nThis allows a constructive proof of a famous theorem by I. Schur, establishing\nan isomorphism between the centralizer of $L$ and the coordinate ring of a\nspace algebraic curve, that we define as the spectral curve of $L$ and whose\ndefining ideal is the BC ideal of $L$. We provide the first explicit example of\na non-planar spectral curve. We compute a set of generators of the defining\nideal of this curve by means of differential resultants and define a new\ncoefficient field determined by the spectral curve, to effectively compute an\nintrinsic right factor of $L-\\lambda$.",
            "author": [
                "Sonia L. Rueda",
                "Maria-Angeles Zurro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09988v1",
                "http://arxiv.org/pdf/2311.09988v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.CA",
                "13N10, 13P15, 12H05",
                "I.1.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09987v1",
            "title": "Deficiency indices for singular magnetic Schr\u00f6dinger operators",
            "updated": "2023-11-16T16:06:14Z",
            "published": "2023-11-16T16:06:14Z",
            "summary": "We show that the deficiency indices of magnetic Schr\\\"odinger operators with\nseveral local singularities can be computed in terms of the deficiency indices\nof operators carrying just one singularity each. We discuss some applications\nto physically relevant operators.",
            "author": [
                "Michele Correggi",
                "Davide Fermi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09987v1",
                "http://arxiv.org/pdf/2311.09987v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.MP",
                "quant-ph",
                "35J10, 35P05, 47B25, 81Q10, 81Q70"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10784v1",
            "title": "ExFake: Towards an Explainable Fake News Detection Based on Content and\n  Social Context Information",
            "updated": "2023-11-16T15:57:58Z",
            "published": "2023-11-16T15:57:58Z",
            "summary": "ExFake is an explainable fake news detection system based on content and\ncontext-level information. It is concerned with the veracity analysis of online\nposts based on their content, social context (i.e., online users' credibility\nand historical behaviour), and data coming from trusted entities such as\nfact-checking websites and named entities. Unlike state-of-the-art systems, an\nExplainable AI (XAI) assistant is also adopted to help online social networks\n(OSN) users develop good reflexes when faced with any doubted information that\nspreads on social networks. The trustworthiness of OSN users is also addressed\nby assigning a credibility score to OSN users, as OSN users are one of the main\nculprits for spreading fake news. Experimental analysis on a real-world dataset\ndemonstrates that ExFake significantly outperforms other baseline methods for\nfake news detection.",
            "author": [
                "Sabrine Amri",
                "Henri-Cedric Mputu Boleilanga",
                "Esma A\u00efmeur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10784v1",
                "http://arxiv.org/pdf/2311.10784v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09979v1",
            "title": "Unambiguity and Fewness for Nonuniform Families of Polynomial-Size\n  Nondeterministic Finite Automata",
            "updated": "2023-11-16T15:52:24Z",
            "published": "2023-11-16T15:52:24Z",
            "summary": "Nonuniform families of polynomial-size finite automata, which are series of\nindexed finite automata having polynomially many inner states, are used in the\npast literature to solve nonuniform families of promise decision problems.\nAmong such nonuniform families of finite automata, we focus our attention, in\nparticular, on the variants of nondeterministic finite automata, which have at\nmost \"one\" (unambiguous), \"polynomially many\" (few) accepting computation\npaths, or unambiguous/few computation paths leading to each fixed\nconfiguration. When such machines are limited to make only one-way head moves,\nwe can prove with no unproven hardness assumptions that some of these variants\nare different in computational power from each other. As for two-way machines\nrestricted to instances of polynomially-bounded length, families of two-way\npolynomial-size nondeterministic finite automata are equivalent in power to\nfamilies of polynomial-size unambiguous finite automata.",
            "author": [
                "Tomoyuki Yamakami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09979v1",
                "http://arxiv.org/pdf/2311.09979v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.CC",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09978v1",
            "title": "Gauging spacetime inversions in quantum gravity",
            "updated": "2023-11-16T15:51:11Z",
            "published": "2023-11-16T15:51:11Z",
            "summary": "Spacetime inversion symmetries such as parity and time reversal play a\ncentral role in physics, but they are usually treated as global symmetries. In\nquantum gravity there are no global symmetries, so any spacetime inversion\nsymmetries must be gauge symmetries. In particular this includes\n$\\mathcal{CRT}$ symmetry (in even dimensions usually combined with a rotation\nto become $\\mathcal{CPT}$), which in quantum field theory is always a symmetry\nand seems likely to be a symmetry of quantum gravity as well. In this article\nwe discuss what it means to gauge a spacetime inversion symmetry, and we\nexplain some of the more unusual consequences of doing this. In particular we\nargue that the gauging of $\\mathcal{CRT}$ is automatically implemented by the\nsum over topologies in the Euclidean gravity path integral, that in a closed\nuniverse the Hilbert space of quantum gravity must be a real vector space, and\nthat in Lorentzian signature manifolds which are not time-orientable must be\nincluded as valid configurations of the theory. In particular we give an\nexample of an asymptotically-AdS time-unorientable geometry which must be\nincluded to reproduce computable results in the dual CFT.",
            "author": [
                "Daniel Harlow",
                "Tokiro Numasawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09978v1",
                "http://arxiv.org/pdf/2311.09978v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09974v1",
            "title": "From Pretext to Purpose: Batch-Adaptive Self-Supervised Learning",
            "updated": "2023-11-16T15:47:49Z",
            "published": "2023-11-16T15:47:49Z",
            "summary": "In recent years, self-supervised contrastive learning has emerged as a\ndistinguished paradigm in the artificial intelligence landscape. It facilitates\nunsupervised feature learning through contrastive delineations at the instance\nlevel. However, crafting an effective self-supervised paradigm remains a\npivotal challenge within this field. This paper delves into two crucial factors\nimpacting self-supervised contrastive learning-bach size and pretext tasks, and\nfrom a data processing standpoint, proposes an adaptive technique of batch\nfusion. The proposed method, via dimensionality reduction and reconstruction of\nbatch data, enables formerly isolated individual data to partake in intra-batch\ncommunication through the Embedding Layer. Moreover, it adaptively amplifies\nthe self-supervised feature encoding capability as the training progresses. We\nconducted a linear classification test of this method based on the classic\ncontrastive learning framework on ImageNet-1k. The empirical findings\nillustrate that our approach achieves state-of-the-art performance under\nequitable comparisons. Benefiting from its \"plug-and-play\" characteristics, we\nfurther explored other contrastive learning methods. On the ImageNet-100,\ncompared to the original performance, the top1 has seen a maximum increase of\n1.25%. We suggest that the proposed method may contribute to the advancement of\ndata-driven self-supervised learning research, bringing a fresh perspective to\nthis community.",
            "author": [
                "Jiansong Zhang",
                "Peizhong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09974v1",
                "http://arxiv.org/pdf/2311.09974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09969v2",
            "title": "Examining bias perpetuation in academic search engines: an algorithm\n  audit of Google and Semantic Scholar",
            "updated": "2023-11-21T09:49:25Z",
            "published": "2023-11-16T15:43:31Z",
            "summary": "Researchers rely on academic web search engines to find scientific sources,\nbut search engine mechanisms may selectively present content that aligns with\nbiases embedded in the queries. This study examines whether confirmation-biased\nqueries prompted into Google Scholar and Semantic Scholar will yield skewed\nresults. Six queries (topics across health and technology domains such as\n\"vaccines\" or \"internet use\") were analyzed for disparities in search results.\nWe confirm that biased queries (targeting \"benefits\" or \"risks\") affect search\nresults in line with the bias, with technology-related queries displaying more\nsignificant disparities. Overall, Semantic Scholar exhibited fewer disparities\nthan Google Scholar. Topics rated as more polarizing did not consistently show\nmore skewed results. Academic search results that perpetuate confirmation bias\nhave strong implications for both researchers and citizens searching for\nevidence. More research is needed to explore how scientific inquiry and\nacademic search engines interact.",
            "author": [
                "Celina Kacperski",
                "Mona Bielig",
                "Mykola Makhortykh",
                "Maryna Sydorova",
                "Roberto Ulloa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09969v2",
                "http://arxiv.org/pdf/2311.09969v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09967v1",
            "title": "Scalable Sequential Optimization Under Observability Don't Cares",
            "updated": "2023-11-16T15:41:00Z",
            "published": "2023-11-16T15:41:00Z",
            "summary": "Sequential logic synthesis can provide better Power-Performance-Area (PPA)\nthan combinational logic synthesis since it explores a larger solution space.\nAs the gate cost in advanced technologies keeps rising, sequential logic\nsynthesis provides a powerful alternative that is gaining momentum in the EDA\ncommunity. In this work, we present a new scalable algorithm for\ndon't-care-based sequential logic synthesis. Our new approach is based on\nsequential k-step induction and can apply both redundancy removal and\nresubstitution transformations under Sequential Observability Don't Cares\n(SODCs). Using SODC-based optimizations with induction is a challenging problem\ndue to dependencies and alignment of don't cares among the base case and the\ninductive case. We propose a new approach utilizing the full power of SODCs\nwithout limiting the solution space. Our algorithm is implemented as part of an\nindustrial tool and achieves 6.9% average area improvement after technology\nmapping when compared to state-of-the-art sequential synthesis methods.\nMoreover, all the new sequential optimizations can be verified using\nstate-of-the-art sequential verification tools.",
            "author": [
                "Dewmini Sudara Marakkalage",
                "Eleonora Testa",
                "Walter Lau Neto",
                "Alan Mishchenko",
                "Giovanni De Micheli",
                "Luca Amar\u00f9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09967v1",
                "http://arxiv.org/pdf/2311.09967v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09966v1",
            "title": "The divergence-free velocity formulation of the consistent Navier-Stokes\n  Cahn-Hilliard model with non-matching densities, divergence-conforming\n  discretization, and benchmarks",
            "updated": "2023-11-16T15:39:19Z",
            "published": "2023-11-16T15:39:19Z",
            "summary": "The prototypical diffuse-interface model that describes multi-component flows\nis the Navier-Stokes Cahn-Hilliard model (NSCH). Over the last decades many\nNSCH models have appeared that claim to describe the same physical phenomena,\nyet are distinct from one another. In a recent article [M.F.P. ten Eikelder,\nK.G. van der Zee, I. Akkerman, and D. Schillinger, Math. Mod. Meth. Appl. S.\n33, pp 175-221, 2023.] we have established a unified framework of virtually all\nNSCH models. The framework reveals that there is only a single consistent NSCH\nmodel that naturally emanates from the underlying mixture theory. In the\ncurrent article we present, verify and validate this novel consistent NSCH\nmodel by means of numerical simulation. To this purpose we discretize a\ndivergence-free velocity formulation of the NSCH model using\ndivergence-conforming isogeometric spaces. We compare computations of our\nconsistent model to results of existing models from literature. The predictive\ncapability of the numerical methodology is demonstrated via three-dimensional\ncomputations of a rising bubble and the contraction of a liquid filament that\ncompare well with experimental data.",
            "author": [
                "M. ten Eikelder",
                "D. Schillinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09966v1",
                "http://arxiv.org/pdf/2311.09966v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math.NA",
                "65M60, 65M12, 76T99, 35Q30, 35R35, 76D45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09965v1",
            "title": "SurgPLAN: Surgical Phase Localization Network for Phase Recognition",
            "updated": "2023-11-16T15:39:01Z",
            "published": "2023-11-16T15:39:01Z",
            "summary": "Surgical phase recognition is crucial to providing surgery understanding in\nsmart operating rooms. Despite great progress in automatic surgical phase\nrecognition, most existing methods are still restricted by two problems. First,\nthese methods cannot capture discriminative visual features for each frame and\nmotion information with simple 2D networks. Second, the frame-by-frame\nrecognition paradigm degrades the performance due to unstable predictions\nwithin each phase, termed as phase shaking. To address these two challenges, we\npropose a Surgical Phase LocAlization Network, named SurgPLAN, to facilitate a\nmore accurate and stable surgical phase recognition with the principle of\ntemporal detection. Specifically, we first devise a Pyramid SlowFast (PSF)\narchitecture to serve as the visual backbone to capture multi-scale spatial and\ntemporal features by two branches with different frame sampling rates.\nMoreover, we propose a Temporal Phase Localization (TPL) module to generate the\nphase prediction based on temporal region proposals, which ensures accurate and\nconsistent predictions within each surgical phase. Extensive experiments\nconfirm the significant advantages of our SurgPLAN over frame-by-frame\napproaches in terms of both accuracy and stability.",
            "author": [
                "Xingjian Luo",
                "You Pang",
                "Zhen Chen",
                "Jinlin Wu",
                "Zongmin Zhang",
                "Zhen Lei",
                "Hongbin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09965v1",
                "http://arxiv.org/pdf/2311.09965v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09958v1",
            "title": "VertDetect: Fully End-to-End 3D Vertebral Instance Segmentation Model",
            "updated": "2023-11-16T15:29:21Z",
            "published": "2023-11-16T15:29:21Z",
            "summary": "Vertebral detection and segmentation are critical steps for treatment\nplanning in spine surgery and radiation therapy. Accurate identification and\nsegmentation are complicated in imaging that does not include the full spine,\nin cases with variations in anatomy (T13 and/or L6 vertebrae), and in the\npresence of fracture or hardware. This paper proposes VertDetect, a fully\nautomated end-to-end 3D vertebral instance segmentation Convolutional Neural\nNetwork (CNN) model to predict vertebral level labels and segmentations for all\nvertebrae present in a CT scan. The utilization of a shared CNN backbone\nprovides the detection and segmentation branches of the network with feature\nmaps containing both spinal and vertebral level information. A Graph\nConvolutional Network (GCN) layer is used to improve vertebral labelling by\nusing the known structure of the spine. This model achieved a Dice Similarity\nCoefficient (DSC) of 0.883 (95% CI, 0.843-0.906) and 0.882 (95% CI,\n0.835-0.909) in the VerSe 2019 and 0.868 (95\\% CI, 0.834-0.890) and 0.869 (95\\%\nCI, 0.832-0.891) in the VerSe 2020 public and hidden test sets, respectively.\nThis model achieved state-of-the-art performance for an end-to-end\narchitecture, whose design facilitates the extraction of features that can be\nsubsequently used for downstream tasks.",
            "author": [
                "Geoff Klein",
                "Michael Hardisty",
                "Cari Whyne",
                "Anne L. Martel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09958v1",
                "http://arxiv.org/pdf/2311.09958v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09952v1",
            "title": "Score-based generative models learn manifold-like structures with\n  constrained mixing",
            "updated": "2023-11-16T15:15:15Z",
            "published": "2023-11-16T15:15:15Z",
            "summary": "How do score-based generative models (SBMs) learn the data distribution\nsupported on a low-dimensional manifold? We investigate the score model of a\ntrained SBM through its linear approximations and subspaces spanned by local\nfeature vectors. During diffusion as the noise decreases, the local\ndimensionality increases and becomes more varied between different sample\nsequences. Importantly, we find that the learned vector field mixes samples by\na non-conservative field within the manifold, although it denoises with normal\nprojections as if there is an energy function in off-manifold directions. At\neach noise level, the subspace spanned by the local features overlap with an\neffective density function. These observations suggest that SBMs can flexibly\nmix samples with the learned score field while carefully maintaining a\nmanifold-like structure of the data distribution.",
            "author": [
                "Li Kevin Wenliang",
                "Ben Moran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09952v1",
                "http://arxiv.org/pdf/2311.09952v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09948v1",
            "title": "Hijacking Large Language Models via Adversarial In-Context Learning",
            "updated": "2023-11-16T15:01:48Z",
            "published": "2023-11-16T15:01:48Z",
            "summary": "In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMs\nfor specific tasks by utilizing labeled examples as demonstrations in the\nprecondition prompts. Despite its promising performance, ICL suffers from\ninstability with the choice and arrangement of examples. Additionally, crafted\nadversarial attacks pose a notable threat to the robustness of ICL. However,\nexisting attacks are either easy to detect, rely on external models, or lack\nspecificity towards ICL. To address these issues, this work introduces a novel\ntransferable attack for ICL, aiming to hijack LLMs to generate the targeted\nresponse. The proposed LLM hijacking attack leverages a gradient-based prompt\nsearch method to learn and append imperceptible adversarial suffixes to the\nin-context demonstrations. Extensive experimental results on various tasks and\ndatasets demonstrate the effectiveness of our LLM hijacking attack, resulting\nin a distracted attention towards adversarial tokens, consequently leading to\nthe targeted unwanted outputs.",
            "author": [
                "Yao Qiang",
                "Xiangyu Zhou",
                "Dongxiao Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09948v1",
                "http://arxiv.org/pdf/2311.09948v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09945v1",
            "title": "An Attention-Based Denoising Framework for Personality Detection in\n  Social Media Texts",
            "updated": "2023-11-16T14:56:09Z",
            "published": "2023-11-16T14:56:09Z",
            "summary": "In social media networks, users produce a large amount of text content\nanytime, providing researchers with a valuable approach to digging for\npersonality-related information. Personality detection based on user-generated\ntexts is a universal method that can be used to build user portraits. The\npresence of noise in social media texts hinders personality detection. However,\nprevious studies have not fully addressed this challenge. Inspired by the\nscanning reading technique, we propose an attention-based information\nextraction mechanism (AIEM) for long texts, which is applied to quickly locate\nvaluable pieces of information, and focus more attention on the deep semantics\nof key pieces. Then, we provide a novel attention-based denoising framework\n(ADF) for personality detection tasks and achieve state-of-the-art performance\non two commonly used datasets. Notably, we obtain an average accuracy\nimprovement of 10.2% on the gold standard Twitter-Myers-Briggs Type Indicator\n(Twitter-MBTI) dataset. We made our code publicly available on GitHub. We shed\nlight on how AIEM works to magnify personality-related signals.",
            "author": [
                "Qirui Tang",
                "Wenkang Jiang",
                "Yihua Du",
                "Lei Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09945v1",
                "http://arxiv.org/pdf/2311.09945v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09944v1",
            "title": "A Physics-Informed Neural Network approach for compartmental\n  epidemiological models",
            "updated": "2023-11-16T14:54:28Z",
            "published": "2023-11-16T14:54:28Z",
            "summary": "Compartmental models provide simple and efficient tools to analyze the\nrelevant transmission processes during an outbreak, to produce short-term\nforecasts or transmission scenarios, and to assess the impact of vaccination\ncampaigns. However, their calibration is not straightforward, since many\nfactors contribute to the rapid change of the transmission dynamics during an\nepidemic. For example, there might be changes in the individual awareness, the\nimposition of non-pharmacological interventions and the emergence of new\nvariants. As a consequence, model parameters such as the transmission rate are\ndoomed to change in time, making their assessment more challenging. Here, we\npropose to use Physics-Informed Neural Networks (PINNs) to track the temporal\nchanges in the model parameters and provide an estimate of the model state\nvariables. PINNs recently gained attention in many engineering applications\nthanks to their ability to consider both the information from data (typically\nuncertain) and the governing equations of the system. The ability of PINNs to\nidentify unknown model parameters makes them particularly suitable to solve\nill-posed inverse problems, such as those arising in the application of\nepidemiological models. Here, we develop a reduced-split approach for the\nimplementation of PINNs to estimate the temporal changes in the state variables\nand transmission rate of an epidemic based on the SIR model equation and\ninfectious data. The main idea is to split the training first on the\nepidemiological data, and then on the residual of the system equations. The\nproposed method is applied to five synthetic test cases and two real scenarios\nreproducing the first months of the COVID-19 Italian pandemic. Our results show\nthat the split implementation of PINNs outperforms the standard approach in\nterms of accuracy (up to one order of magnitude) and computational times (speed\nup of 20%).",
            "author": [
                "Caterina Millevoi",
                "Damiano Pasetto",
                "Massimiliano Ferronato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09944v1",
                "http://arxiv.org/pdf/2311.09944v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09942v1",
            "title": "Harnessing Transformers: A Leap Forward in Lung Cancer Image Detection",
            "updated": "2023-11-16T14:50:42Z",
            "published": "2023-11-16T14:50:42Z",
            "summary": "This paper discusses the role of Transfer Learning (TL) and transformers in\ncancer detection based on image analysis. With the enormous evolution of cancer\npatients, the identification of cancer cells in a patient's body has emerged as\na trend in the field of Artificial Intelligence (AI). This process involves\nanalyzing medical images, such as Computed Tomography (CT) scans and Magnetic\nResonance Imaging (MRIs), to identify abnormal growths that may help in cancer\ndetection. Many techniques and methods have been realized to improve the\nquality and performance of cancer classification and detection, such as TL,\nwhich allows the transfer of knowledge from one task to another with the same\ntask or domain. TL englobes many methods, particularly those used in image\nanalysis, such as transformers and Convolutional Neural Network (CNN) models\ntrained on the ImageNet dataset. This paper analyzes and criticizes each method\nof TL based on image analysis and compares the results of each method, showing\nthat transformers have achieved the best results with an accuracy of 97.41% for\ncolon cancer detection and 94.71% for Histopathological Lung cancer. Future\ndirections for cancer detection based on image analysis are also discussed.",
            "author": [
                "Amine Bechar",
                "Youssef Elmir",
                "Rafik Medjoudj",
                "Yassine Himeur",
                "Abbes Amira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09942v1",
                "http://arxiv.org/pdf/2311.09942v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09939v1",
            "title": "RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection",
            "updated": "2023-11-16T14:43:45Z",
            "published": "2023-11-16T14:43:45Z",
            "summary": "Online misinformation is often multimodal in nature, i.e., it is caused by\nmisleading associations between texts and accompanying images. To support the\nfact-checking process, researchers have been recently developing automatic\nmultimodal methods that gather and analyze external information, evidence,\nrelated to the image-text pairs under examination. However, prior works assumed\nall collected evidence to be relevant. In this study, we introduce a \"Relevant\nEvidence Detection\" (RED) module to discern whether each piece of evidence is\nrelevant, to support or refute the claim. Specifically, we develop the\n\"Relevant Evidence Detection Directed Transformer\" (RED-DOT) and explore\nmultiple architectural variants (e.g., single or dual-stage) and mechanisms\n(e.g., \"guided attention\"). Extensive ablation and comparative experiments\ndemonstrate that RED-DOT achieves significant improvements over the\nstate-of-the-art on the VERITE benchmark by up to 28.5%. Furthermore, our\nevidence re-ranking and element-wise modality fusion led to RED-DOT achieving\ncompetitive and even improved performance on NewsCLIPings+, without the need\nfor numerous evidence or multiple backbone encoders. Finally, our qualitative\nanalysis demonstrates that the proposed \"guided attention\" module has the\npotential to enhance the architecture's interpretability. We release our code\nat: https://github.com/stevejpapad/relevant-evidence-detection",
            "author": [
                "Stefanos-Iordanis Papadopoulos",
                "Christos Koutlis",
                "Symeon Papadopoulos",
                "Panagiotis C. Petrantonakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09939v1",
                "http://arxiv.org/pdf/2311.09939v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09938v1",
            "title": "Confronting electroweak MSSM through one-loop renormalized\n  neutralino-Higgs interactions for dark matter direct detection and muon\n  $(g-2)$",
            "updated": "2023-11-16T14:41:57Z",
            "published": "2023-11-16T14:41:57Z",
            "summary": "We compute the next-to-leading order (NLO) corrections to the vertices where\na pair of the lightest neutralino couples to CP-even (light or heavy) Higgs\nscalars. In particular, the lightest neutralino is assumed to be a dominantly\nBino-like mixed state, composed of Bino and Higgsino or Bino, Wino, and\nHiggsino. After computing all the three-point functions in the electroweak\nMSSM, we detail the contributions from the counterterms that arise in\nrenormalizing these vertices in one-loop order. The amendment of the\nrenormalized vertices impacts the spin-independent direct detection\ncross-sections of the scattering of nucleons with dark matter. We perform a\ncomprehensive numerical scan over the parameter space where all the points\nsatisfy the present B-physics constraints and accommodate the muon's anomalous\nmagnetic moment. Finally, we exemplify a few benchmark points, which indulge\nthe present searches of supersymmetric particles. After including the\nrenormalized one-loop vertices, the spin-independent DM-nucleon cross-sections\nmay be enhanced up to $20\\%$ compared to its tree-level results. Finally, with\nthe NLO cross-section, we use the recent LUX-ZEPLIN (LZ) results on the\nneutralino-nucleon scattering to display the relative rise in the lowest\nallowed band of the Higgsino mass parameter in the $M_1-\\mu$ plane of the\nelectroweak MSSM.",
            "author": [
                "Subhadip Bisal",
                "Arindam Chatterjee",
                "Debottam Das",
                "Syed Adil Pasha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09938v1",
                "http://arxiv.org/pdf/2311.09938v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09935v1",
            "title": "Semi-parametric Benchmark Dose Analysis with Monotone Additive Models",
            "updated": "2023-11-16T14:40:41Z",
            "published": "2023-11-16T14:40:41Z",
            "summary": "Benchmark dose analysis aims to estimate the level of exposure to a toxin\nthat results in a clinically-significant adverse outcome and quantifies\nuncertainty using the lower limit of a confidence interval for this level. We\ndevelop a novel framework for benchmark dose analysis based on monotone\nadditive dose-response models. We first introduce a flexible approach for\nfitting monotone additive models via penalized B-splines and\nLaplace-approximate marginal likelihood. A reflective Newton method is then\ndeveloped that employs de Boor's algorithm for computing splines and their\nderivatives for efficient estimation of the benchmark dose. Finally, we develop\nand assess three approaches for calculating benchmark dose lower limits: a\nnaive one based on asymptotic normality of the estimator, one based on an\napproximate pivot, and one using a Bayesian parametric bootstrap. The latter\napproaches improve upon the naive method in terms of accuracy and are\nguaranteed to return a positive lower limit; the approach based on an\napproximate pivot is typically an order of magnitude faster than the bootstrap,\nalthough they are both practically feasible to compute. We apply the new\nmethods to make inferences about the level of prenatal alcohol exposure\nassociated with clinically significant cognitive defects in children using data\nfrom an NIH-funded longitudinal study. Software to reproduce the results in\nthis paper is available at https://github.com/awstringer1/bmd-paper-code.",
            "author": [
                "Alex Stringer",
                "Tugba Akkaya Hocagil",
                "Richard Cook",
                "Louise Ryan",
                "Sandra W. Jacobson",
                "Joseph L. Jacobson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09935v1",
                "http://arxiv.org/pdf/2311.09935v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09934v1",
            "title": "Echo Chambers within the Russo-Ukrainian War: The Role of Bipartisan\n  Users",
            "updated": "2023-11-16T14:39:37Z",
            "published": "2023-11-16T14:39:37Z",
            "summary": "The ongoing Russia-Ukraine war has been extensively discussed on social\nmedia. One commonly observed problem in such discussions is the emergence of\necho chambers, where users are rarely exposed to opinions outside their\nworldview. Prior literature on this topic has assumed that such users hold a\nsingle consistent view. However, recent work has revealed that complex topics\n(such as the war) often trigger bipartisanship among certain people. With this\nin mind, we study the presence of echo chambers on Twitter related to the\nRusso-Ukrainian war. We measure their presence and identify an important subset\nof bipartisan users who vary their opinions during the invasion. We explore the\nrole they play in the communications graph and identify features that\ndistinguish them from remaining users. We conclude by discussing their\nimportance and how they can improve the quality of discourse surrounding the\nwar.",
            "author": [
                "Peixian Zhang",
                "Ehsan-Ul Haq",
                "Yiming Zhu",
                "Pan Hui",
                "Gareth Tyson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09934v1",
                "http://arxiv.org/pdf/2311.09934v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09933v2",
            "title": "Heuristic Learning for Co-Design Scheme of Optimal Sequential Attack",
            "updated": "2023-11-17T02:40:49Z",
            "published": "2023-11-16T14:39:08Z",
            "summary": "This paper considers a novel co-design problem of the optimal\n\\textit{sequential} attack, whose attack strategy changes with the time series,\nand in which the \\textit{sequential} attack selection strategy and\n\\textit{sequential} attack signal are simultaneously designed. Different from\nthe existing attack design works that separately focus on attack subsets or\nattack signals, the joint design of the attack strategy poses a huge challenge\ndue to the deep coupling relation between the \\textit{sequential} attack\nselection strategy and \\textit{sequential} attack signal. In this manuscript,\nwe decompose the sequential co-design problem into two equivalent sub-problems.\nSpecifically, we first derive an analytical closed-form expression between the\noptimal attack signal and the sequential attack selection strategy.\nFurthermore, we prove the finite-time inverse convergence of the critical\nparameters in the injected optimal attack signal by discrete-time Lyapunov\nanalysis, which enables the efficient off-line design of the attack signal and\nsaves computing resources. Finally, we exploit its relationship to design a\nheuristic two-stage learning-based joint attack algorithm (HTL-JA), which can\naccelerate realization of the attack target compared to the one-stage\nproximal-policy-optimization-based (PPO) algorithm. Extensive simulations are\nconducted to show the effectiveness of the injected optimal sequential attack.",
            "author": [
                "Xiaoyu Luo",
                "Haoxuan Pan",
                "Chongrong Fang",
                "Chengcheng Zhao",
                "Peng Cheng",
                "Jianping He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09933v2",
                "http://arxiv.org/pdf/2311.09933v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09932v1",
            "title": "The Communication GSC System with Energy Harvesting Nodes aided by\n  Opportunistic Routing",
            "updated": "2023-11-16T14:36:41Z",
            "published": "2023-11-16T14:36:41Z",
            "summary": "In this paper, a cooperative communication network based on energy-harvesting\n(EH) decode-and-forward (DF) relays is proposed. For relay nodes, there is\nharvest-storage-use (HSU) structure in this system. And energy can be obtained\nfrom the surrounding environment through energy buffering. In order to improve\nthe performance of the communication system, the opportunistic routing\nalgorithm and the generalized selection combining (GSC) algorithm are adopted\nin this communication system. In addition, from discrete-time continuous-state\nspace Markov chain model (DCSMC), a theoretical expression of the energy\nlimiting distribution stored in infinite buffers is derived. Through using the\nprobability distribution and state transition matrix, the theoretical\nexpressions of system outage probability, throughput and time cost of per\npacket are obtained. Through the simulation verification, the theoretical\nresults are in good agreement with the simulation results.",
            "author": [
                "Hanyu Liu",
                "Lei Teng",
                "Wannian An",
                "Xiaoqi Qin",
                "Chen Dong",
                "Xiaodong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09932v1",
                "http://arxiv.org/pdf/2311.09932v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09929v1",
            "title": "Mutating etcd Towards Edge Suitability",
            "updated": "2023-11-16T14:31:16Z",
            "published": "2023-11-16T14:31:16Z",
            "summary": "In the edge environment servers are no longer being co-located away from\nclients, instead they are being co-located with clients away from other\nservers, focusing on reliable and performant operation. Orchestration\nplatforms, such as Kubernetes, are a key system being transitioned to the edge\nbut they remain unsuited to the environment, stemming primarily from their\ncritical key-value stores. In this work we derive requirements from the edge\nenvironment showing that, fundamentally, the design of distributed key-value\ndatastores, such as etcd, is unsuited to meet them. Using these requirements,\nwe explore the design space for distributed key-value datastores and implement\ntwo successive mutations of etcd for different points: mergeable-etcd and\ndismerge, trading linearizability for causal consistency based on CRDTs.\nmergeable-etcd retains the linear revision history but encounters inherent\nshortcomings, whilst dismerge embraces the causal model. Both stores are\nlocal-first, maintaining reliable performance under network partitions and\nvariability, drastically surpassing etcd's performance, whilst maintaining\ncompetitive performance in reliable settings.",
            "author": [
                "Andrew Jeffery",
                "Heidi Howard",
                "Richard Mortier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09929v1",
                "http://arxiv.org/pdf/2311.09929v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09922v1",
            "title": "Fast multiplication by two's complement addition of numbers represented\n  as a set of polynomial radix 2 indexes, stored as an integer list for\n  massively parallel computation",
            "updated": "2023-11-16T14:21:13Z",
            "published": "2023-11-16T14:21:13Z",
            "summary": "We demonstrate a multiplication method based on numbers represented as set of\npolynomial radix 2 indices stored as an integer list. The 'polynomial integer\nindex multiplication' method is a set of algorithms implemented in python code.\nWe demonstrate the method to be faster than both the Number Theoretic Transform\n(NTT) and Karatsuba for multiplication within a certain bit range. Also\nimplemented in python code for comparison purposes with the polynomial radix 2\ninteger method. We demonstrate that it is possible to express any integer or\nreal number as a list of integer indices, representing a finite series in base\ntwo. The finite series of integer index representation of a number can then be\nstored and distributed across multiple CPUs / GPUs. We show that operations of\naddition and multiplication can be applied as two's complement additions\noperating on the index integer representations and can be fully distributed\nacross a given CPU / GPU architecture. We demonstrate fully distributed\narithmetic operations such that the 'polynomial integer index multiplication'\nmethod overcomes the current limitation of parallel multiplication methods. Ie,\nthe need to share common core memory and common disk for the calculation of\nresults and intermediate results.",
            "author": [
                "Mark Stocks"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09922v1",
                "http://arxiv.org/pdf/2311.09922v1"
            ],
            "primary_category": "cs.MS",
            "category": [
                "cs.MS",
                "cs.DC",
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10782v1",
            "title": "A BERT based Ensemble Approach for Sentiment Classification of Customer\n  Reviews and its Application to Nudge Marketing in e-Commerce",
            "updated": "2023-11-16T14:18:24Z",
            "published": "2023-11-16T14:18:24Z",
            "summary": "According to the literature, Product reviews are an important source of\ninformation for customers to support their buying decision. Product reviews\nimprove customer trust and loyalty. Reviews help customers in understanding\nwhat other customers think about a particular product and helps in driving\npurchase decisions. Therefore, for an e-commerce platform it is important to\nunderstand the sentiments in customer reviews to understand their products and\nservices, and it also allows them to potentially create positive consumer\ninteraction as well as long lasting relationships. Reviews also provide\ninnovative ways to market the products for an ecommerce company. One such\napproach is Nudge Marketing. Nudge marketing is a subtle way for an ecommerce\ncompany to help their customers make better decisions without hesitation.",
            "author": [
                "Sayan Putatunda",
                "Anwesha Bhowmik",
                "Girish Thiruvenkadam",
                "Rahul Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10782v1",
                "http://arxiv.org/pdf/2311.10782v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09919v1",
            "title": "DSR-Diff: Depth Map Super-Resolution with Diffusion Model",
            "updated": "2023-11-16T14:18:10Z",
            "published": "2023-11-16T14:18:10Z",
            "summary": "Color-guided depth map super-resolution (CDSR) improve the spatial resolution\nof a low-quality depth map with the corresponding high-quality color map,\nbenefiting various applications such as 3D reconstruction, virtual reality, and\naugmented reality. While conventional CDSR methods typically rely on\nconvolutional neural networks or transformers, diffusion models (DMs) have\ndemonstrated notable effectiveness in high-level vision tasks. In this work, we\npresent a novel CDSR paradigm that utilizes a diffusion model within the latent\nspace to generate guidance for depth map super-resolution. The proposed method\ncomprises a guidance generation network (GGN), a depth map super-resolution\nnetwork (DSRN), and a guidance recovery network (GRN). The GGN is specifically\ndesigned to generate the guidance while managing its compactness. Additionally,\nwe integrate a simple but effective feature fusion module and a\ntransformer-style feature extraction module into the DSRN, enabling it to\nleverage guided priors in the extraction, fusion, and reconstruction of\nmulti-model images. Taking into account both accuracy and efficiency, our\nproposed method has shown superior performance in extensive experiments when\ncompared to state-of-the-art methods. Our codes will be made available at\nhttps://github.com/shiyuan7/DSR-Diff.",
            "author": [
                "Yuan Shi",
                "Bin Xia",
                "Rui Zhu",
                "Qingmin Liao",
                "Wenming Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09919v1",
                "http://arxiv.org/pdf/2311.09919v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09918v1",
            "title": "Proceedings of the 18th International Workshop on Logical Frameworks and\n  Meta-Languages: Theory and Practice",
            "updated": "2023-11-16T14:16:51Z",
            "published": "2023-11-16T14:16:51Z",
            "summary": "Logical frameworks and meta-languages form a common substrate for\nrepresenting, implementing and reasoning about a wide variety of deductive\nsystems of interest in logic and computer science. Their design, implementation\nand their use in reasoning tasks, ranging from the correctness of software to\nthe properties of formal systems, have been the focus of considerable research\nover the last two decades. This workshop brings together designers,\nimplementors and practitioners to discuss various aspects impinging on the\nstructure and utility of logical frameworks, including the treatment of\nvariable binding, inductive and co-inductive reasoning techniques and the\nexpressiveness and lucidity of the reasoning process.",
            "author": [
                "Alberto Ciaffaglione",
                "Carlos Olarte"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.396",
                "http://arxiv.org/abs/2311.09918v1",
                "http://arxiv.org/pdf/2311.09918v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09913v1",
            "title": "Visualizing acoustic levitation using COMSOL Multiphysics",
            "updated": "2023-11-16T14:09:01Z",
            "published": "2023-11-16T14:09:01Z",
            "summary": "We present a new virtual laboratory developed with COMSOL Multiphysics for\nthe simulation of an acoustic levitator. Our computer application simulates the\nacoustic pressure field and its interaction with a set of particles. Students\ncan interact with the system by having the possibility of changing the\nfrequency and distance parameters between transducers in real-time. We have\nalso developed and shared for free use the 3D printing design files for the\nconstruction of necessary components for the acoustic levitator and the\ninstructions for its experimental implementation. The experimental results,\nalong with the virtual laboratory, provide the students with useful tools to\nunderstand and interpret the acoustic phenomenon involved.",
            "author": [
                "Francisco M. Mu\u00f1oz-P\u00e9rez",
                "Juan C. Castro-Palacio",
                "Marcos H. Gim\u00e9nez",
                "Juan A. Monsoriu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09913v1",
                "http://arxiv.org/pdf/2311.09913v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14713v2",
            "title": "The Rise of the AI Co-Pilot: Lessons for Design from Aviation and Beyond",
            "updated": "2023-11-29T16:52:34Z",
            "published": "2023-11-16T13:58:15Z",
            "summary": "The fast pace of advances in AI promises to revolutionize various aspects of\nknowledge work, extending its influence to daily life and professional fields\nalike. We advocate for a paradigm where AI is seen as a collaborative co-pilot,\nworking under human guidance rather than as a mere tool. Drawing from relevant\nresearch and literature in the disciplines of Human-Computer Interaction and\nHuman Factors Engineering, we highlight the criticality of maintaining human\noversight in AI interactions. Reflecting on lessons from aviation, we address\nthe dangers of over-relying on automation, such as diminished human vigilance\nand skill erosion. Our paper proposes a design approach that emphasizes active\nhuman engagement, control, and skill enhancement in the AI partnership, aiming\nto foster a harmonious, effective, and empowering human-AI relationship. We\nparticularly call out the critical need to design AI interaction capabilities\nand software applications to enable and celebrate the primacy of human agency.\nThis calls for designs for human-AI partnership that cede ultimate control and\nresponsibility to the human user as pilot, with the AI co-pilot acting in a\nwell-defined supporting role.",
            "author": [
                "Abigail Sellen",
                "Eric Horvitz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14713v2",
                "http://arxiv.org/pdf/2311.14713v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09904v1",
            "title": "Capacitated Network Bargaining Games: Stability and Structure",
            "updated": "2023-11-16T13:56:14Z",
            "published": "2023-11-16T13:56:14Z",
            "summary": "Capacitated network bargaining games are popular combinatorial games that\ninvolve the structure of matchings in graphs. We show that it is always\npossible to stabilize unweighted instances of this problem (that is, ensure\nthat they admit a stable outcome) via capacity-reduction and edge-removal\noperations, without decreasing the total value that the players can get.\n  Furthermore, for general weighted instances, we show that computing a minimum\namount of vertex-capacity to reduce to make an instance stable is a\npolynomial-time solvable problem. We then exploit this to give approximation\nresults for the NP-hard problem of stabilizing a graph via edge-removal\noperations.\n  Our work extends and generalizes previous results in the literature that\ndealt with an uncapacitated version of the problem, using several new\narguments. In particular, while previous results mainly used combinatorial\ntechniques, we here rely on polyhedral arguments and, more specifically, on the\nnotion of circuits of a polytope.",
            "author": [
                "Laura Sanit\u00e0",
                "Lucy Verberk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09904v1",
                "http://arxiv.org/pdf/2311.09904v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO",
                "05C57",
                "G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09902v1",
            "title": "Selection of Distinct Morphologies to Divide & Conquer Gigapixel\n  Pathology Images",
            "updated": "2023-11-16T13:54:38Z",
            "published": "2023-11-16T13:54:38Z",
            "summary": "Whole slide images (WSIs) are massive digital pathology files illustrating\nintricate tissue structures. Selecting a small, representative subset of\npatches from each WSI is essential yet challenging. Therefore, following the\n\"Divide & Conquer\" approach becomes essential to facilitate WSI analysis\nincluding the classification and the WSI matching in computational pathology.\nTo this end, we propose a novel method termed \"Selection of Distinct\nMorphologies\" (SDM) to choose a subset of WSI patches. The aim is to encompass\nall inherent morphological variations within a given WSI while simultaneously\nminimizing the number of selected patches to represent these variations,\nensuring a compact yet comprehensive set of patches. This systematically\ncurated patch set forms what we term a \"montage\". We assess the\nrepresentativeness of the SDM montage across various public and private\nhistopathology datasets. This is conducted by using the leave-one-out WSI\nsearch and matching evaluation method, comparing it with the state-of-the-art\nYottixel's mosaic. SDM demonstrates remarkable efficacy across all datasets\nduring its evaluation. Furthermore, SDM eliminates the necessity for empirical\nparameterization, a crucial aspect of Yottixel's mosaic, by inherently\noptimizing the selection process to capture the distinct morphological features\nwithin the WSI.",
            "author": [
                "Abubakr Shafique",
                "Saghir Alfasly",
                "Areej Alsaafin",
                "Peyman Nejat",
                "Jibran A. Khan",
                "H. R. Tizhoosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09902v1",
                "http://arxiv.org/pdf/2311.09902v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09895v1",
            "title": "Measurement Free Approach towards Dynamic Construction of a Shallow\n  Depth Ansatz for Molecular Energetics in Noisy Quantum Computers",
            "updated": "2023-11-16T13:45:33Z",
            "published": "2023-11-16T13:45:33Z",
            "summary": "Recent advances in quantum information and quantum science have inspired the\ndevelopment of various compact dynamic structured ansatze that are expected to\nbe realizable in the Noisy Intermediate-Scale Quantum (NISQ) devices. However,\nsuch ansatze construction strategies hitherto developed involve considerable\npre-circuit measurements, and thus they deviate significantly in NISQ platform\nfrom their ideal structures. It is thus imperative that the usage of quantum\nresources must be minimized while retaining the expressivity and dynamical\nstructure of the ansatz that can tailor itself depending on the degree of\nstrong correlation. We propose a novel ansatz construction strategy based on\nthe \\textit{ab-initio} many-body perturbation theory that requires \\textit{no}\npre-circuit measurement and thus it remains structurally unaffected by any\nhardware noise. The accuracy and quantum complexity associated with the ansatz\nare solely dictated by a pre-defined perturbative order as desired and hence\nare tunable. Furthermore, the underlying perturbative structure of the ansatz\nconstruction pipeline enables us to decompose any high-rank excitation that\nappears in higher perturbative orders into various low-rank operators, and thus\nkeeps the execution gate-depth to its minimum. With a number of challenging\napplications on strongly correlated system, we demonstrate that our ansatz\nperforms significantly better, both in terms of accuracy, parameter count and\ncircuit depth, in comparison to the allied unitary coupled cluster based\nansatze.",
            "author": [
                "Dipanjali Halder",
                "Dibyendu Mondal",
                "Rahul Maitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09895v1",
                "http://arxiv.org/pdf/2311.09895v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09889v2",
            "title": "Language Generation from Human Brain Activities",
            "updated": "2023-11-19T15:23:17Z",
            "published": "2023-11-16T13:37:21Z",
            "summary": "Generating human language through non-invasive brain-computer interfaces\n(BCIs) has the potential to unlock many applications, such as serving disabled\npatients and improving communication. Currently, however, generating language\nvia BCIs has been previously successful only within a classification setup for\nselecting pre-generated sentence continuation candidates with the most likely\ncortical semantic representation. Inspired by recent research that revealed\nassociations between the brain and the large computational language models, we\npropose a generative language BCI that utilizes the capacity of a large\nlanguage model (LLM) jointly with a semantic brain decoder to directly generate\nlanguage from functional magnetic resonance imaging (fMRI) input. The proposed\nmodel can generate coherent language sequences aligned with the semantic\ncontent of visual or auditory language stimuli perceived, without prior\nknowledge of any pre-generated candidates. We compare the language generated\nfrom the presented model with a random control, pre-generated language\nselection approach, and a standard LLM, which generates common coherent text\nsolely based on the next word likelihood according to statistical language\ntraining data. The proposed model is found to generate language that is more\naligned with semantic stimulus in response to which brain input is sampled. Our\nfindings demonstrate the potential and feasibility of employing BCIs in direct\nlanguage generation.",
            "author": [
                "Ziyi Ye",
                "Qingyao Ai",
                "Yiqun Liu",
                "Min Zhang",
                "Christina Lioma",
                "Tuukka Ruotsalo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09889v2",
                "http://arxiv.org/pdf/2311.09889v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09887v1",
            "title": "LIO-EKF: High Frequency LiDAR-Inertial Odometry using Extended Kalman\n  Filters",
            "updated": "2023-11-16T13:28:19Z",
            "published": "2023-11-16T13:28:19Z",
            "summary": "Odometry estimation is a key element for every autonomous system requiring\nnavigation in an unknown environment. In modern mobile robots, 3D\nLiDAR-inertial systems are often used for this task. By fusing LiDAR scans and\nIMU measurements, these systems can reduce the accumulated drift caused by\nsequentially registering individual LiDAR scans and provide a robust pose\nestimate. Although effective, LiDAR-inertial odometry systems require proper\nparameter tuning to be deployed. In this paper, we propose LIO-EKF, a\ntightly-coupled LiDAR-inertial odometry system based on point-to-point\nregistration and the classical extended Kalman filter scheme. We propose an\nadaptive data association that considers the relative pose uncertainty, the map\ndiscretization errors, and the LiDAR noise. In this way, we can substantially\nreduce the parameters to tune for a given type of environment. The experimental\nevaluation suggests that the proposed system performs on par with the\nstate-of-the-art LiDAR-inertial odometry pipelines, but is significantly faster\nin computing the odometry.",
            "author": [
                "Yibin Wu",
                "Tiziano Guadagnino",
                "Louis Wiesmann",
                "Lasse Klingbeil",
                "Cyrill Stachniss",
                "Heiner Kuhlmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09887v1",
                "http://arxiv.org/pdf/2311.09887v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09881v1",
            "title": "The Software Genome Project: Venture to the Genomic Pathways of Open\n  Source Software and Its Applications",
            "updated": "2023-11-16T13:18:24Z",
            "published": "2023-11-16T13:18:24Z",
            "summary": "With the boom in modern software development, open-source software has become\nan integral part of various industries, driving progress in computer science.\nHowever, the immense complexity and diversity of the open-source ecosystem also\npose a series of challenges, including issues of quality, security, management,\nmaintenance, compliance, and sustainability. Existing open-source governance\napproaches, while excelling in community building and collaboration, still face\nshortcomings in decentralized management, security, and maintenance. To address\nthese challenges, inspired by the Human Genome Project, we treat the software\nsource code as software DNA and propose the \\textbf{Software Genome Project},\nwhich is geared towards the secure monitoring and exploitation of open-source\nsoftware. By identifying and labeling integrated and classified code features\nat a fine-grained level, and effectively identifying safeguards for functional\nimplementations and non-functional requirements at different levels of\ngranularity, Software Genome Project builds a complete set of software genome\nmaps to help developers and managers gain a deeper understanding of software\ncomplexity and diversity. By dissecting and summarizing functional and\nundesirable genes, Software Genome Project helps facilitate targeted software\nremediation and optimization, provides valuable insight and understanding of\nthe entire software ecosystem, and supports critical development tasks such as\ntechnology selection and open source governance. This project is expected to\ndrive the evolution of software development towards more efficient, reliable,\nand sustainable software solutions.",
            "author": [
                "Yueming Wu",
                "Chengwei Liu",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09881v1",
                "http://arxiv.org/pdf/2311.09881v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09875v1",
            "title": "Unbiased and Multilevel Methods for a Class of Diffusions Partially\n  Observed via Marked Point Processes",
            "updated": "2023-11-16T13:09:44Z",
            "published": "2023-11-16T13:09:44Z",
            "summary": "In this article we consider the filtering problem associated to partially\nobserved diffusions, with observations following a marked point process. In the\nmodel, the data form a point process with observation times that have its\nintensity driven by a diffusion, with the associated marks also depending upon\nthe diffusion process. We assume that one must resort to time-discretizing the\ndiffusion process and develop particle and multilevel particle filters to\nrecursively approximate the filter. In particular, we prove that our multilevel\nparticle filter can achieve a mean square error (MSE) of\n$\\mathcal{O}(\\epsilon^2)$ ($\\epsilon>0$ and arbitrary) with a cost of\n$\\mathcal{O}(\\epsilon^{-2.5})$ versus using a particle filter which has a cost\nof $\\mathcal{O}(\\epsilon^{-3})$ to achieve the same MSE. We then show how this\nmethodology can be extended to give unbiased (that is with no\ntime-discretization error) estimators of the filter, which are proved to have\nfinite variance and with high-probability have finite cost. Finally, we extend\nour methodology to the problem of online static-parameter estimation.",
            "author": [
                "Miguel Alvarez",
                "Ajay Jasra",
                "Hamza Ruzayqat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09875v1",
                "http://arxiv.org/pdf/2311.09875v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "cs.NA",
                "math.NA",
                "stat.ME",
                "60G55, 60G35, 62M20, 62F30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10126v1",
            "title": "I&S-ViT: An Inclusive & Stable Method for Pushing the Limit of\n  Post-Training ViTs Quantization",
            "updated": "2023-11-16T13:07:47Z",
            "published": "2023-11-16T13:07:47Z",
            "summary": "Albeit the scalable performance of vision transformers (ViTs), the dense\ncomputational costs (training & inference) undermine their position in\nindustrial applications. Post-training quantization (PTQ), tuning ViTs with a\ntiny dataset and running in a low-bit format, well addresses the cost issue but\nunluckily bears more performance drops in lower-bit cases. In this paper, we\nintroduce I&S-ViT, a novel method that regulates the PTQ of ViTs in an\ninclusive and stable fashion. I&S-ViT first identifies two issues in the PTQ of\nViTs: (1) Quantization inefficiency in the prevalent log2 quantizer for\npost-Softmax activations; (2) Rugged and magnified loss landscape in\ncoarse-grained quantization granularity for post-LayerNorm activations. Then,\nI&S-ViT addresses these issues by introducing: (1) A novel shift-uniform-log2\nquantizer (SULQ) that incorporates a shift mechanism followed by uniform\nquantization to achieve both an inclusive domain representation and accurate\ndistribution approximation; (2) A three-stage smooth optimization strategy\n(SOS) that amalgamates the strengths of channel-wise and layer-wise\nquantization to enable stable learning. Comprehensive evaluations across\ndiverse vision tasks validate I&S-ViT' superiority over existing PTQ of ViTs\nmethods, particularly in low-bit scenarios. For instance, I&S-ViT elevates the\nperformance of 3-bit ViT-B by an impressive 50.68%.",
            "author": [
                "Yunshan Zhong",
                "Jiawei Hu",
                "Mingbao Lin",
                "Mengzhao Chen",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10126v1",
                "http://arxiv.org/pdf/2311.10126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09874v1",
            "title": "Experimental virtual distillation of entanglement and coherence",
            "updated": "2023-11-16T13:03:34Z",
            "published": "2023-11-16T13:03:34Z",
            "summary": "Noise is in general inevitable and detrimental to practical and useful\nquantum communication and computation. Under the resource theory framework,\nresource distillation serves as a generic tool to overcome the effect of noise.\nYet, conventional resource distillation protocols generally require operations\non multi-copies of resource states, and strong limitations exist that restrict\ntheir practical utilities. Recently, by relaxing the setting of resource\ndistillation to only approximating the measurement statistics instead of the\nquantum state, a resource-frugal protocol, virtual resource distillation, is\nproposed, which allows more effective distillation of noisy resources. Here, we\nreport its experimental implementation on a four-qubit photonic quantum system\nfor the distillation of quantum coherence (up to dimension 4) and bipartite\nentanglement. We show the virtual distillation of the maximal superposed state\nof dimension four from the state of dimension two, an impossible task in\nconventional coherence distillation. Furthermore, we demonstrate the virtual\ndistillation of entanglement with operations acting only on a single copy of\nthe noisy EPR pair and showcase the quantum teleportation task using the\nvirtually distilled EPR pair with a significantly improved fidelity of the\nteleported state. These results illustrate the feasibility of the virtual\nresource distillation method and pave the way for accurate manipulation of\nquantum resources with noisy quantum hardware.",
            "author": [
                "Ting Zhang",
                "Yukun Zhang",
                "Lu Liu",
                "Xiao-Xu Fang",
                "Qian-Xi Zhang",
                "Xiao Yuan",
                "He Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09874v1",
                "http://arxiv.org/pdf/2311.09874v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10125v1",
            "title": "UnifiedVisionGPT: Streamlining Vision-Oriented AI through Generalized\n  Multimodal Framework",
            "updated": "2023-11-16T13:01:25Z",
            "published": "2023-11-16T13:01:25Z",
            "summary": "In the current landscape of artificial intelligence, foundation models serve\nas the bedrock for advancements in both language and vision domains. OpenAI\nGPT-4 has emerged as the pinnacle in large language models (LLMs), while the\ncomputer vision (CV) domain boasts a plethora of state-of-the-art (SOTA) models\nsuch as Meta's SAM and DINO, and YOLOS. However, the financial and\ncomputational burdens of training new models from scratch remain a significant\nbarrier to progress. In response to this challenge, we introduce\nUnifiedVisionGPT, a novel framework designed to consolidate and automate the\nintegration of SOTA vision models, thereby facilitating the development of\nvision-oriented AI. UnifiedVisionGPT distinguishes itself through four key\nfeatures: (1) provides a versatile multimodal framework adaptable to a wide\nrange of applications, building upon the strengths of multimodal foundation\nmodels; (2) seamlessly integrates various SOTA vision models to create a\ncomprehensive multimodal platform, capitalizing on the best components of each\nmodel; (3) prioritizes vision-oriented AI, ensuring a more rapid progression in\nthe CV domain compared to the current trajectory of LLMs; and (4) introduces\nautomation in the selection of SOTA vision models, generating optimal results\nbased on diverse multimodal inputs such as text prompts and images. This paper\noutlines the architecture and capabilities of UnifiedVisionGPT, demonstrating\nits potential to revolutionize the field of computer vision through enhanced\nefficiency, versatility, generalization, and performance. Our implementation,\nalong with the unified multimodal framework and comprehensive dataset, is made\npublicly available at https://github.com/LHBuilder/SA-Segment-Anything.",
            "author": [
                "Chris Kelly",
                "Luhui Hu",
                "Cindy Yang",
                "Yu Tian",
                "Deshun Yang",
                "Bang Yang",
                "Zaoshan Huang",
                "Zihao Li",
                "Yuexian Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10125v1",
                "http://arxiv.org/pdf/2311.10125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09870v2",
            "title": "Five-Parton Scattering in QCD at Two Loops",
            "updated": "2023-11-30T15:06:13Z",
            "published": "2023-11-16T12:56:55Z",
            "summary": "We compute all helicity amplitudes for the scattering of five partons in\ntwo-loop QCD in all the relevant flavor configurations, retaining all\ncontributing color structures. We employ tensor projection to obtain helicity\namplitudes in the 't Hooft-Veltman scheme starting from a set of primitive\namplitudes. Our analytic results are expressed in terms of massless pentagon\nfunctions, and are easy to evaluate numerically. These amplitudes provide\nimportant input to investigations of collinear-factorization breaking and to\nstudies of the multi-Regge kinematics regime.",
            "author": [
                "Bakul Agarwal",
                "Federico Buccioni",
                "Federica Devoto",
                "Giulio Gambuti",
                "Andreas von Manteuffel",
                "Lorenzo Tancredi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09870v2",
                "http://arxiv.org/pdf/2311.09870v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09866v1",
            "title": "A numerical method for solving elliptic equations on real closed\n  algebraic curves and surfaces",
            "updated": "2023-11-16T12:52:17Z",
            "published": "2023-11-16T12:52:17Z",
            "summary": "There are many numerical methods for solving partial different equations\n(PDEs) on manifolds such as classical implicit, finite difference, finite\nelement, and isogeometric analysis methods which aim at improving the\ninteroperability between finite element method and computer aided design (CAD)\nsoftware. However, these approaches have difficulty when the domain has\nsingularities since the solution at the singularity may be multivalued. This\npaper develops a novel numerical approach to solve elliptic PDEs on real,\nclosed, connected, orientable, and almost smooth algebraic curves and surfaces.\nOur method integrates numerical algebraic geometry, differential geometry, and\na finite difference scheme which is demonstrated on several examples.",
            "author": [
                "Wenrui Hao",
                "Jonathan D. Hauenstein",
                "Margaret H. Regan",
                "Tingting Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09866v1",
                "http://arxiv.org/pdf/2311.09866v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09862v1",
            "title": "Which Modality should I use -- Text, Motif, or Image? : Understanding\n  Graphs with Large Language Models",
            "updated": "2023-11-16T12:45:41Z",
            "published": "2023-11-16T12:45:41Z",
            "summary": "Large language models (LLMs) are revolutionizing various fields by leveraging\nlarge text corpora for context-aware intelligence. Due to the context size,\nhowever, encoding an entire graph with LLMs is fundamentally limited. This\npaper explores how to better integrate graph data with LLMs and presents a\nnovel approach using various encoding modalities (e.g., text, image, and motif)\nand approximation of global connectivity of a graph using different prompting\nmethods to enhance LLMs' effectiveness in handling complex graph structures.\nThe study also introduces GraphTMI, a new benchmark for evaluating LLMs in\ngraph structure analysis, focusing on factors such as homophily, motif\npresence, and graph difficulty. Key findings reveal that image modality,\nsupported by advanced vision-language models like GPT-4V, is more effective\nthan text in managing token limits while retaining critical information. The\nresearch also examines the influence of different factors on each encoding\nmodality's performance. This study highlights the current limitations and\ncharts future directions for LLMs in graph understanding and reasoning tasks.",
            "author": [
                "Debarati Das",
                "Ishaan Gupta",
                "Jaideep Srivastava",
                "Dongyeop Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09862v1",
                "http://arxiv.org/pdf/2311.09862v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09861v2",
            "title": "PsyBench: a balanced and in-depth Psychological Chinese Evaluation\n  Benchmark for Foundation Models",
            "updated": "2023-11-17T03:17:05Z",
            "published": "2023-11-16T12:43:18Z",
            "summary": "As Large Language Models (LLMs) are becoming prevalent in various fields,\nthere is an urgent need for improved NLP benchmarks that encompass all the\nnecessary knowledge of individual discipline. Many contemporary benchmarks for\nfoundational models emphasize a broad range of subjects but often fall short in\npresenting all the critical subjects and encompassing necessary professional\nknowledge of them. This shortfall has led to skewed results, given that LLMs\nexhibit varying performance across different subjects and knowledge areas. To\naddress this issue, we present psybench, the first comprehensive Chinese\nevaluation suite that covers all the necessary knowledge required for graduate\nentrance exams. psybench offers a deep evaluation of a model's strengths and\nweaknesses in psychology through multiple-choice questions. Our findings show\nsignificant differences in performance across different sections of a subject,\nhighlighting the risk of skewed results when the knowledge in test sets is not\nbalanced. Notably, only the ChatGPT model reaches an average accuracy above\n$70\\%$, indicating that there is still plenty of room for improvement. We\nexpect that psybench will help to conduct thorough evaluations of base models'\nstrengths and weaknesses and assist in practical application in the field of\npsychology.",
            "author": [
                "Junlei Zhang",
                "Hongliang He",
                "Nirui Song",
                "Shuyuan He",
                "Shuai Zhang",
                "Huachuan Qiu",
                "Anqi Li",
                "Lizhi Ma",
                "Zhenzhong Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09861v2",
                "http://arxiv.org/pdf/2311.09861v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09860v1",
            "title": "GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity\n  Extraction Focused on Machine Learning Models and Datasets",
            "updated": "2023-11-16T12:43:02Z",
            "published": "2023-11-16T12:43:02Z",
            "summary": "Named Entity Recognition (NER) models play a crucial role in various NLP\ntasks, including information extraction (IE) and text understanding. In\nacademic writing, references to machine learning models and datasets are\nfundamental components of various computer science publications and necessitate\naccurate models for identification. Despite the advancements in NER, existing\nground truth datasets do not treat fine-grained types like ML model and model\narchitecture as separate entity types, and consequently, baseline models cannot\nrecognize them as such. In this paper, we release a corpus of 100 manually\nannotated full-text scientific publications and a first baseline model for 10\nentity types centered around ML models and datasets. In order to provide a\nnuanced understanding of how ML models and datasets are mentioned and utilized,\nour dataset also contains annotations for informal mentions like \"our\nBERT-based model\" or \"an image CNN\". You can find the ground truth dataset and\ncode to replicate model training at https://data.gesis.org/gsap/gsap-ner.",
            "author": [
                "Wolfgang Otto",
                "Matth\u00e4us Zloch",
                "Lu Gan",
                "Saurav Karmakar",
                "Stefan Dietze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09860v1",
                "http://arxiv.org/pdf/2311.09860v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09858v1",
            "title": "Polynomially Over-Parameterized Convolutional Neural Networks Contain\n  Structured Strong Winning Lottery Tickets",
            "updated": "2023-11-16T12:38:45Z",
            "published": "2023-11-16T12:38:45Z",
            "summary": "The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialised\nneural networks likely contain subnetworks that perform well without any\ntraining. Although unstructured pruning has been extensively studied in this\ncontext, its structured counterpart, which can deliver significant\ncomputational and memory efficiency gains, has been largely unexplored. One of\nthe main reasons for this gap is the limitations of the underlying mathematical\ntools used in formal analyses of the SLTH. In this paper, we overcome these\nlimitations: we leverage recent advances in the multidimensional generalisation\nof the Random Subset-Sum Problem and obtain a variant that admits the\nstochastic dependencies that arise when addressing structured pruning in the\nSLTH. We apply this result to prove, for a wide class of random Convolutional\nNeural Networks, the existence of structured subnetworks that can approximate\nany sufficiently smaller network.\n  This result provides the first sub-exponential bound around the SLTH for\nstructured pruning, opening up new avenues for further research on the\nhypothesis and contributing to the understanding of the role of\nover-parameterization in deep learning.",
            "author": [
                "Arthur da Cunha",
                "Francesco d'Amore",
                "Emanuele Natale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09858v1",
                "http://arxiv.org/pdf/2311.09858v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09856v1",
            "title": "Contribution Evaluation in Federated Learning: Examining Current\n  Approaches",
            "updated": "2023-11-16T12:32:44Z",
            "published": "2023-11-16T12:32:44Z",
            "summary": "Federated Learning (FL) has seen increasing interest in cases where entities\nwant to collaboratively train models while maintaining privacy and governance\nover their data. In FL, clients with private and potentially heterogeneous data\nand compute resources come together to train a common model without raw data\never leaving their locale. Instead, the participants contribute by sharing\nlocal model updates, which, naturally, differ in quality. Quantitatively\nevaluating the worth of these contributions is termed the Contribution\nEvaluation (CE) problem. We review current CE approaches from the underlying\nmathematical framework to efficiently calculate a fair value for each client.\nFurthermore, we benchmark some of the most promising state-of-the-art\napproaches, along with a new one we introduce, on MNIST and CIFAR-10, to\nshowcase their differences. Designing a fair and efficient CE method, while a\nsmall part of the overall FL system design, is tantamount to the mainstream\nadoption of FL.",
            "author": [
                "Vasilis Siomos",
                "Jonathan Passerat-Palmbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09856v1",
                "http://arxiv.org/pdf/2311.09856v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00793v1",
            "title": "Variants of Tagged Sentential Decision Diagrams",
            "updated": "2023-11-16T12:29:25Z",
            "published": "2023-11-16T12:29:25Z",
            "summary": "A recently proposed canonical form of Boolean functions, namely tagged\nsentential decision diagrams (TSDDs), exploits both the standard and\nzero-suppressed trimming rules. The standard ones minimize the size of\nsentential decision diagrams (SDDs) while the zero-suppressed trimming rules\nhave the same objective as the standard ones but for zero-suppressed sentential\ndecision diagrams (ZSDDs). The original TSDDs, which we call zero-suppressed\nTSDDs (ZTSDDs), firstly fully utilize the zero-suppressed trimming rules, and\nthen the standard ones. In this paper, we present a variant of TSDDs which we\ncall standard TSDDs (STSDDs) by reversing the order of trimming rules. We then\nprove the canonicity of STSDDs and present the algorithms for binary operations\non TSDDs. In addition, we offer two kinds of implementations of STSDDs and\nZTSDDs and acquire three variations of the original TSDDs. Experimental\nevaluations demonstrate that the four versions of TSDDs have the size advantage\nover SDDs and ZSDDs.",
            "author": [
                "Deyuan Zhong",
                "Mingwei Zhang",
                "Quanlong Guan",
                "Liangda Fang",
                "Zhaorong Lai",
                "Yong Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00793v1",
                "http://arxiv.org/pdf/2312.00793v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09850v1",
            "title": "Semantic-Relay-Aided Text Transmission: Placement Optimization and\n  Bandwidth Allocation",
            "updated": "2023-11-16T12:23:49Z",
            "published": "2023-11-16T12:23:49Z",
            "summary": "Semantic communication has emerged as a promising technology to break the\nShannon limit by extracting the meaning of source data and sending relevant\nsemantic information only. However, some mobile devices may have limited\ncomputation and storage resources, which renders it difficult to deploy and\nimplement the resource-demanding deep learning based semantic encoder/decoder.\nTo tackle this challenge, we propose in this paper a new semantic relay\n(SemRelay), which is equipped with a semantic receiver for assisting text\ntransmission from a resource-abundant base station (BS) to a\nresource-constrained mobile device. Specifically, the SemRelay first decodes\nthe semantic information sent by the BS (with a semantic transmitter) and then\nforwards it to the user by adopting conventional bit transmission, hence\neffectively improving the text transmission efficiency. We formulate an\noptimization problem to maximize the achievable (effective) bit rate by jointly\ndesigning the SemRelay placement and bandwidth allocation. Although this\nproblem is non-convex and generally difficult to solve, we propose an efficient\npenalty-based algorithm to obtain a high-quality suboptimal solution. Numerical\nresults show the close-to-optimal performance of the proposed algorithm as well\nas significant rate performance gain of the proposed SemRelay over conventional\ndecode-and-forward relay.",
            "author": [
                "Tianyu Liu",
                "Changsheng You",
                "Zeyang Hu",
                "Chenyu Wu",
                "Yi Gong",
                "Kaibin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09850v1",
                "http://arxiv.org/pdf/2311.09850v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09849v1",
            "title": "Rusty Detection Using Image Processing For Maintenance Of Stations",
            "updated": "2023-11-16T12:21:54Z",
            "published": "2023-11-16T12:21:54Z",
            "summary": "This study addresses the challenge of accurately seg-menting rusted areas on\npainted construction surfaces. A method leveraging digital image processing is\nexplored to calculate the percentage of rust present on painted coatings. The\nproposed segmentation approach is based on the HSV color model. To equalize\nluminosity and mitigate the influence of illumination, a fundamental model of\nsingle-scale Retinex is applied specifically to the saturation component.\n  Subsequently, the image undergoes further processing, involv-ing manual color\nfiltering. This step is crucial for refining the identification of rusted\nregions. To enhance precision and filter out noise, the pixel areas selected\nthrough color filtering are subjected to the DBScan algorithm. This multi-step\nprocess aims to achieve a robust segmentation of rusted areas on painted\nconstruction surfaces, providing a valuable contribution to the field of\ncorrosion detection and analysis.",
            "author": [
                "Dao Duy Tung",
                "Ho Xuan Hung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09849v1",
                "http://arxiv.org/pdf/2311.09849v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09847v1",
            "title": "Overcoming Data Scarcity in Biomedical Imaging with a Foundational\n  Multi-Task Model",
            "updated": "2023-11-16T12:20:25Z",
            "published": "2023-11-16T12:20:25Z",
            "summary": "Foundational models, pretrained on a large scale, have demonstrated\nsubstantial success across non-medical domains. However, training these models\ntypically requires large, comprehensive datasets, which contrasts with the\nsmaller and more heterogeneous datasets common in biomedical imaging. Here, we\npropose a multi-task learning strategy that decouples the number of training\ntasks from memory requirements. We trained a Universal bioMedical PreTrained\nmodel (UMedPT) on a multi-task database including tomographic, microscopic, and\nX-ray images, with various labelling strategies such as classification,\nsegmentation, and object detection. The UMedPT foundational model outperformed\nImageNet pretraining and the previous state-of-the-art models. For tasks\nrelated to the pretraining database, it maintained its performance with only 1%\nof the original training data and without fine-tuning. For out-of-domain tasks\nit required not more than 50% of the original training data. In an external\nindependent validation imaging features extracted using UMedPT proved to be a\nnew standard for cross-center transferability.",
            "author": [
                "Raphael Sch\u00e4fer",
                "Till Nicke",
                "Henning H\u00f6fener",
                "Annkristin Lange",
                "Dorit Merhof",
                "Friedrich Feuerhake",
                "Volkmar Schulz",
                "Johannes Lotz",
                "Fabian Kiessling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09847v1",
                "http://arxiv.org/pdf/2311.09847v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09846v1",
            "title": "GroupMixer: Patch-based Group Convolutional Neural Network for Breast\n  Cancer Detection from Histopathological Images",
            "updated": "2023-11-16T12:19:48Z",
            "published": "2023-11-16T12:19:48Z",
            "summary": "Diagnosis of breast cancer malignancy at the early stages is a crucial step\nfor controlling its side effects. Histopathological analysis provides a unique\nopportunity for malignant breast cancer detection. However, such a task would\nbe tedious and time-consuming for the histopathologists. Deep Neural Networks\nenable us to learn informative features directly from raw histopathological\nimages without manual feature extraction. Although Convolutional Neural\nNetworks (CNNs) have been the dominant architectures in the computer vision\nrealm, Transformer-based architectures have shown promising results in\ndifferent computer vision tasks. Although harnessing the capability of\nTransformer-based architectures for medical image analysis seems interesting,\nthese architectures are large, have a significant number of trainable\nparameters, and require large datasets to be trained on, which are usually rare\nin the medical domain. It has been claimed and empirically proved that at least\npart of the superior performance of Transformer-based architectures in Computer\nVision domain originates from patch embedding operation. In this paper, we\nborrowed the previously introduced idea of integrating a fully Convolutional\nNeural Network architecture with Patch Embedding operation and presented an\nefficient CNN architecture for breast cancer malignancy detection from\nhistopathological images. Despite the number of parameters that is\nsignificantly smaller than other methods, the accuracy performance metrics\nachieved 97.65%, 98.92%, 99.21%, and 98.01% for 40x, 100x, 200x, and 400x\nmagnifications respectively. We took a step forward and modified the\narchitecture using Group Convolution and Channel Shuffling ideas and reduced\nthe number of trainable parameters even more with a negligible decline in\nperformance and achieved 95.42%, 98.16%, 96.05%, and 97.92% accuracy for the\nmentioned magnifications respectively.",
            "author": [
                "Ardavan Modarres",
                "Erfan Ebrahim Esfahani",
                "Mahsa Bahrami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09846v1",
                "http://arxiv.org/pdf/2311.09846v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09843v1",
            "title": "A guide to numerical dispersion curve calculations: explanation,\n  interpretation and basic Matlab code",
            "updated": "2023-11-16T12:14:08Z",
            "published": "2023-11-16T12:14:08Z",
            "summary": "Dispersion curves or band diagrams play a crucial role in examining,\nanalyzing and designing wave propagation in periodic structures. Despite their\nubiquity and current research interest, introductory papers and reference\nscripting tailored to novel researchers in the field are lacking. This paper\naims to address this gap, by presenting a comprehensive educational resource\nfor researchers starting in the field of periodic structures and more\nspecifically on the study of dispersion curves. The objective is twofold. A\nfirst objective is to give a detailed explanation of dispersion curves, with\ngraphical illustrations. Secondly, a documented Matlab code is provided to\ncompute dispersion curves of 3D structures with 2D periodicity using the\nso-called inverse approach. The dispersion curves are obtained with numerical\nsimulations using the finite element method. The code is written for elastic\nwave propagation and orthogonal periodicity directions, but can be extended to\nother types of linear wave propagation, non-orthogonal periodicity directions\nor 1D and 3D periodicity. The aim of this code is to serve as a starting point\nfor novice researchers in the field, to facilitate their understanding of\ndifferent aspects of dispersion curves and serve as a stepping stone in their\nfuture research.",
            "author": [
                "Vanessa Cool",
                "Elke Deckers",
                "Lucas Van Belle",
                "Claus Claeys"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09843v1",
                "http://arxiv.org/pdf/2311.09843v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09841v1",
            "title": "Leveraging LLMs in Scholarly Knowledge Graph Question Answering",
            "updated": "2023-11-16T12:13:49Z",
            "published": "2023-11-16T12:13:49Z",
            "summary": "This paper presents a scholarly Knowledge Graph Question Answering (KGQA)\nthat answers bibliographic natural language questions by leveraging a large\nlanguage model (LLM) in a few-shot manner. The model initially identifies the\ntop-n similar training questions related to a given test question via a\nBERT-based sentence encoder and retrieves their corresponding SPARQL. Using the\ntop-n similar question-SPARQL pairs as an example and the test question creates\na prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs\nthe SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and\nreturns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of\nthe Scholarly-QALD-23 challenge benchmarks.",
            "author": [
                "Tilahun Abedissa Taffa",
                "Ricardo Usbeck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09841v1",
                "http://arxiv.org/pdf/2311.09841v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09838v1",
            "title": "Bayesian Inference of Reproduction Number from Epidemiological and\n  Genetic Data Using Particle MCMC",
            "updated": "2023-11-16T12:09:32Z",
            "published": "2023-11-16T12:09:32Z",
            "summary": "Inference of the reproduction number through time is of vital importance\nduring an epidemic outbreak. Typically, epidemiologists tackle this using\nobserved prevalence or incidence data. However, prevalence and incidence data\nalone is often noisy or partial. Models can also have identifiability issues\nwith determining whether a large amount of a small epidemic or a small amount\nof a large epidemic has been observed. Sequencing data however is becoming more\nabundant, so approaches which can incorporate genetic data are an active area\nof research. We propose using particle MCMC methods to infer the time-varying\nreproduction number from a combination of prevalence data reported at a set of\ndiscrete times and a dated phylogeny reconstructed from sequences. We validate\nour approach on simulated epidemics with a variety of scenarios. We then apply\nthe method to a real data set of HIV-1 in North Carolina, USA, between 1957 and\n2019.",
            "author": [
                "Alicia Gill",
                "Jere Koskela",
                "Xavier Didelot",
                "Richard G. Everitt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09838v1",
                "http://arxiv.org/pdf/2311.09838v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "q-bio.GN",
                "q-bio.PE",
                "stat.AP",
                "stat.CO",
                "62P10, 65C05, 92D10, 92D30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09836v1",
            "title": "PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization",
            "updated": "2023-11-16T12:05:23Z",
            "published": "2023-11-16T12:05:23Z",
            "summary": "We investigate pre-training techniques for abstractive multi-document\nsummarization (MDS), which is much less studied than summarizing single\ndocuments. Though recent work has demonstrated the effectiveness of\nhighlighting information salience for pre-training strategy design, it\nstruggles to generate abstractive and reflective summaries, which are critical\nproperties for MDS. To this end, we present PELMS, a pre-trained model that\nuses objectives based on semantic coherence heuristics and faithfulness\nconstraints with un-labeled multi-document inputs, to promote the generation of\nconcise, fluent, and faithful summaries. To support the training of PELMS, we\ncompile MultiPT, a multi-document pre-training corpus containing over 93\nmillion documents to form more than 3 million unlabeled topic-centric document\nclusters, covering diverse genres such as product reviews, news, and general\nknowledge. We perform extensive evaluation of PELMS in low-shot settings on a\nwide range of MDS datasets. Our approach consistently outperforms competitive\ncomparisons with respect to overall informativeness, abstractiveness,\ncoherence, and faithfulness.",
            "author": [
                "Joseph J. Peper",
                "Wenzhao Qiu",
                "Lu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09836v1",
                "http://arxiv.org/pdf/2311.09836v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09835v1",
            "title": "ML-Bench: Large Language Models Leverage Open-source Libraries for\n  Machine Learning Tasks",
            "updated": "2023-11-16T12:03:21Z",
            "published": "2023-11-16T12:03:21Z",
            "summary": "Large language models have shown promising performance in code generation\nbenchmarks. However, a considerable divide exists between these benchmark\nachievements and their practical applicability, primarily attributed to\nreal-world programming's reliance on pre-existing libraries. Instead of\nevaluating LLMs to code from scratch, this work aims to propose a new\nevaluation setup where LLMs use open-source libraries to finish machine\nlearning tasks. Therefore, we propose ML-Bench, an expansive benchmark\ndeveloped to assess the effectiveness of LLMs in leveraging existing functions\nin open-source libraries. Consisting of 10044 samples spanning 130 tasks over\n14 notable machine learning GitHub repositories. In this setting, given a\nspecific machine learning task instruction and the accompanying README in a\ncodebase, an LLM is tasked to generate code to accomplish the task. This\nnecessitates the comprehension of long and language-code interleaved documents,\nas well as the understanding of complex cross-file code structures, introducing\nnew challenges. Notably, while GPT-4 exhibits remarkable improvement over other\nLLMs, it manages to accomplish only 39.73\\% of the tasks, leaving a huge space\nfor improvement. We address these challenges by proposing ML-Agent, designed to\neffectively navigate the codebase, locate documentation, retrieve code, and\ngenerate executable code. Empirical results demonstrate that ML-Agent, built\nupon GPT-4, results in further improvements. Code, data, and models are\navailable at \\url{https://ml-bench.github.io/}.",
            "author": [
                "Yuliang Liu",
                "Xiangru Tang",
                "Zefan Cai",
                "Junjie Lu",
                "Yichi Zhang",
                "Yanjun Shao",
                "Zexuan Deng",
                "Helan Hu",
                "Zengxian Yang",
                "Kaikai An",
                "Ruijun Huang",
                "Shuzheng Si",
                "Sheng Chen",
                "Haozhe Zhao",
                "Zhengliang Li",
                "Liang Chen",
                "Yiming Zong",
                "Yan Wang",
                "Tianyu Liu",
                "Zhiwei Jiang",
                "Baobao Chang",
                "Yujia Qin",
                "Wangchunshu Zhou",
                "Yilun Zhao",
                "Arman Cohan",
                "Mark Gerstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09835v1",
                "http://arxiv.org/pdf/2311.09835v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09834v1",
            "title": "Overview of the HASOC Subtrack at FIRE 2023: Identification of Tokens\n  Contributing to Explicit Hate in English by Span Detection",
            "updated": "2023-11-16T12:01:19Z",
            "published": "2023-11-16T12:01:19Z",
            "summary": "As hate speech continues to proliferate on the web, it is becoming\nincreasingly important to develop computational methods to mitigate it.\nReactively, using black-box models to identify hateful content can perplex\nusers as to why their posts were automatically flagged as hateful. On the other\nhand, proactive mitigation can be achieved by suggesting rephrasing before a\npost is made public. However, both mitigation techniques require information\nabout which part of a post contains the hateful aspect, i.e., what spans within\na text are responsible for conveying hate. Better detection of such spans can\nsignificantly reduce explicitly hateful content on the web. To further\ncontribute to this research area, we organized HateNorm at HASOC-FIRE 2023,\nfocusing on explicit span detection in English Tweets. A total of 12 teams\nparticipated in the competition, with the highest macro-F1 observed at 0.58.",
            "author": [
                "Sarah Masud",
                "Mohammad Aflah Khan",
                "Md. Shad Akhtar",
                "Tanmoy Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09834v1",
                "http://arxiv.org/pdf/2311.09834v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09832v1",
            "title": "X-Mark: Towards Lossless Watermarking Through Lexical Redundancy",
            "updated": "2023-11-16T11:58:31Z",
            "published": "2023-11-16T11:58:31Z",
            "summary": "Text watermarking has emerged as an important technique for detecting\nmachine-generated text. However, existing methods can severely degrade text\nquality due to arbitrary vocabulary partitioning, which disrupts the language\nmodel's expressiveness and impedes textual coherence. To mitigate this, we\nintroduce XMark, a novel approach that capitalizes on text redundancy within\nthe lexical space. Specifically, XMark incorporates a mutually exclusive rule\nfor synonyms during the language model decoding process, thereby integrating\nprior knowledge into vocabulary partitioning and preserving the capabilities of\nlanguage generation. We present theoretical analyses and empirical evidence\ndemonstrating that XMark substantially enhances text generation fluency while\nmaintaining watermark detectability. Furthermore, we investigate watermarking's\nimpact on the emergent abilities of large language models, including zero-shot\nand few-shot knowledge recall, logical reasoning, and instruction following.\nOur comprehensive experiments confirm that XMark consistently outperforms\nexisting methods in retaining these crucial capabilities of LLMs.",
            "author": [
                "Liang Chen",
                "Yatao Bian",
                "Yang Deng",
                "Shuaiyi Li",
                "Bingzhe Wu",
                "Peilin Zhao",
                "Kam-fai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09832v1",
                "http://arxiv.org/pdf/2311.09832v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09830v1",
            "title": "AutoPlanBench: : Automatically generating benchmarks for LLM planners\n  from PDDL",
            "updated": "2023-11-16T11:55:27Z",
            "published": "2023-11-16T11:55:27Z",
            "summary": "LLMs are being increasingly used for planning-style tasks, but their\ncapabilities for planning and reasoning are poorly understood. We present a\nnovel method for automatically converting planning benchmarks written in PDDL\ninto textual descriptions and offer a benchmark dataset created with our\nmethod. We show that while the best LLM planners do well on many planning\ntasks, others remain out of reach of current methods.",
            "author": [
                "Katharina Stein",
                "Alexander Koller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09830v1",
                "http://arxiv.org/pdf/2311.09830v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09829v1",
            "title": "FollowEval: A Multi-Dimensional Benchmark for Assessing the\n  Instruction-Following Capability of Large Language Models",
            "updated": "2023-11-16T11:53:31Z",
            "published": "2023-11-16T11:53:31Z",
            "summary": "The effective assessment of the instruction-following ability of large\nlanguage models (LLMs) is of paramount importance. A model that cannot adhere\nto human instructions might be not able to provide reliable and helpful\nresponses. In pursuit of this goal, various benchmarks have been constructed to\nevaluate the instruction-following capacity of these models. However, these\nbenchmarks are limited to a single language and are constructed using automated\napproaches, which restricts their applicability and the quality of the test\nexamples they contain. To bridge this gap, we introduce the FollowEval\nbenchmark in this paper. This benchmark is composed of instances in both\nEnglish and Chinese, and all test examples are crafted by human experts.\nFurthermore, the FollowEval benchmark is designed to assess LLMs across five\ncritical dimensions of instruction following: string manipulation, commonsense\nreasoning, logical reasoning, spatial reasoning, and response constraints. To\nenhance the complexity and present a sufficient challenge, each test example is\ndesigned to evaluate more than one dimension. We have evaluated various LLMs\nusing the FollowEval benchmark and found that their performance significantly\nlags behind that of humans. This highlights the considerable room for\nimprovement in the instruction-following ability of these models.",
            "author": [
                "Yimin Jing",
                "Renren Jin",
                "Jiahao Hu",
                "Huishi Qiu",
                "Xiaohua Wang",
                "Peng Wang",
                "Deyi Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09829v1",
                "http://arxiv.org/pdf/2311.09829v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09828v1",
            "title": "AfriMTE and AfriCOMET: Empowering COMET to Embrace Under-resourced\n  African Languages",
            "updated": "2023-11-16T11:52:52Z",
            "published": "2023-11-16T11:52:52Z",
            "summary": "Despite the progress we have recorded in scaling multilingual machine\ntranslation (MT) models and evaluation data to several under-resourced African\nlanguages, it is difficult to measure accurately the progress we have made on\nthese languages because evaluation is often performed on n-gram matching\nmetrics like BLEU that often have worse correlation with human judgments.\nEmbedding-based metrics such as COMET correlate better; however, lack of\nevaluation data with human ratings for under-resourced languages, complexity of\nannotation guidelines like Multidimensional Quality Metrics (MQM), and limited\nlanguage coverage of multilingual encoders have hampered their applicability to\nAfrican languages. In this paper, we address these challenges by creating\nhigh-quality human evaluation data with a simplified MQM guideline for\nerror-span annotation and direct assessment (DA) scoring for 13 typologically\ndiverse African languages. Furthermore, we develop AfriCOMET, a COMET\nevaluation metric for African languages by leveraging DA training data from\nhigh-resource languages and African-centric multilingual encoder\n(AfroXLM-Roberta) to create the state-of-the-art evaluation metric for African\nlanguages MT with respect to Spearman-rank correlation with human judgments\n(+0.406).",
            "author": [
                "Jiayi Wang",
                "David Ifeoluwa Adelani",
                "Sweta Agrawal",
                "Ricardo Rei",
                "Eleftheria Briakou",
                "Marine Carpuat",
                "Marek Masiak",
                "Xuanli He",
                "Sofia Bourhim",
                "Andiswa Bukula",
                "Muhidin Mohamed",
                "Temitayo Olatoye",
                "Hamam Mokayede",
                "Christine Mwase",
                "Wangui Kimotho",
                "Foutse Yuehgoh",
                "Anuoluwapo Aremu",
                "Jessica Ojo",
                "Shamsuddeen Hassan Muhammad",
                "Salomey Osei",
                "Abdul-Hakeem Omotayo",
                "Chiamaka Chukwuneke",
                "Perez Ogayo",
                "Oumaima Hourrane",
                "Salma El Anigri",
                "Lolwethu Ndolela",
                "Thabiso Mangwana",
                "Shafie Abdi Mohamed",
                "Ayinde Hassan",
                "Oluwabusayo Olufunke Awoyomi",
                "Lama Alkhaled",
                "Sana Al-Azzawi",
                "Naome A. Etori",
                "Millicent Ochieng",
                "Clemencia Siro",
                "Samuel Njoroge",
                "Eric Muchiri",
                "Wangari Kimotho",
                "Lyse Naomi Wamba Momo",
                "Daud Abolade",
                "Simbiat Ajao",
                "Tosin Adewumi",
                "Iyanuoluwa Shode",
                "Ricky Macharm",
                "Ruqayya Nasir Iro",
                "Saheed S. Abdullahi",
                "Stephen E. Moore",
                "Bernard Opoku",
                "Zainab Akinjobi",
                "Abeeb Afolabi",
                "Nnaemeka Obiefuna",
                "Onyekachi Raphael Ogbu",
                "Sam Brian",
                "Verrah Akinyi Otiende",
                "Chinedu Emmanuel Mbonu",
                "Sakayo Toadoum Sari",
                "Pontus Stenetorp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09828v1",
                "http://arxiv.org/pdf/2311.09828v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09827v1",
            "title": "Cognitive Overload: Jailbreaking Large Language Models with Overloaded\n  Logical Thinking",
            "updated": "2023-11-16T11:52:22Z",
            "published": "2023-11-16T11:52:22Z",
            "summary": "While large language models (LLMs) have demonstrated increasing power, they\nhave also given rise to a wide range of harmful behaviors. As representatives,\njailbreak attacks can provoke harmful or unethical responses from LLMs, even\nafter safety alignment. In this paper, we investigate a novel category of\njailbreak attacks specifically designed to target the cognitive structure and\nprocesses of LLMs. Specifically, we analyze the safety vulnerability of LLMs in\nthe face of (1) multilingual cognitive overload, (2) veiled expression, and (3)\neffect-to-cause reasoning. Different from previous jailbreak attacks, our\nproposed cognitive overload is a black-box attack with no need for knowledge of\nmodel architecture or access to model weights. Experiments conducted on\nAdvBench and MasterKey reveal that various LLMs, including both popular\nopen-source model Llama 2 and the proprietary model ChatGPT, can be compromised\nthrough cognitive overload. Motivated by cognitive psychology work on managing\ncognitive load, we further investigate defending cognitive overload attack from\ntwo perspectives. Empirical studies show that our cognitive overload from three\nperspectives can jailbreak all studied LLMs successfully, while existing\ndefense strategies can hardly mitigate the caused malicious uses effectively.",
            "author": [
                "Nan Xu",
                "Fei Wang",
                "Ben Zhou",
                "Bang Zheng Li",
                "Chaowei Xiao",
                "Muhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09827v1",
                "http://arxiv.org/pdf/2311.09827v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09825v1",
            "title": "Human Still Wins over LLM: An Empirical Study of Active Learning on\n  Domain-Specific Annotation Tasks",
            "updated": "2023-11-16T11:51:13Z",
            "published": "2023-11-16T11:51:13Z",
            "summary": "Large Language Models (LLMs) have demonstrated considerable advances, and\nseveral claims have been made about their exceeding human performance. However,\nin real-world tasks, domain knowledge is often required. Low-resource learning\nmethods like Active Learning (AL) have been proposed to tackle the cost of\ndomain expert annotation, raising this question: Can LLMs surpass compact\nmodels trained with expert annotations in domain-specific tasks? In this work,\nwe conduct an empirical experiment on four datasets from three different\ndomains comparing SOTA LLMs with small models trained on expert annotations\nwith AL. We found that small models can outperform GPT-3.5 with a few hundreds\nof labeled data, and they achieve higher or similar performance with GPT-4\ndespite that they are hundreds time smaller. Based on these findings, we posit\nthat LLM predictions can be used as a warmup method in real-world applications\nand human experts remain indispensable in tasks involving data annotation\ndriven by domain-specific knowledge.",
            "author": [
                "Yuxuan Lu",
                "Bingsheng Yao",
                "Shao Zhang",
                "Yun Wang",
                "Peng Zhang",
                "Tun Lu",
                "Toby Jia-Jun Li",
                "Dakuo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09825v1",
                "http://arxiv.org/pdf/2311.09825v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09822v1",
            "title": "MAM-E: Mammographic synthetic image generation with diffusion models",
            "updated": "2023-11-16T11:49:49Z",
            "published": "2023-11-16T11:49:49Z",
            "summary": "Generative models are used as an alternative data augmentation technique to\nalleviate the data scarcity problem faced in the medical imaging field.\nDiffusion models have gathered special attention due to their innovative\ngeneration approach, the high quality of the generated images and their\nrelatively less complex training process compared with Generative Adversarial\nNetworks. Still, the implementation of such models in the medical domain\nremains at early stages. In this work, we propose exploring the use of\ndiffusion models for the generation of high quality full-field digital\nmammograms using state-of-the-art conditional diffusion pipelines.\nAdditionally, we propose using stable diffusion models for the inpainting of\nsynthetic lesions on healthy mammograms. We introduce MAM-E, a pipeline of\ngenerative models for high quality mammography synthesis controlled by a text\nprompt and capable of generating synthetic lesions on specific regions of the\nbreast. Finally, we provide quantitative and qualitative assessment of the\ngenerated images and easy-to-use graphical user interfaces for mammography\nsynthesis.",
            "author": [
                "Ricardo Montoya-del-Angel",
                "Karla Sam-Millan",
                "Joan C Vilanova",
                "Robert Mart\u00ed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09822v1",
                "http://arxiv.org/pdf/2311.09822v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09821v1",
            "title": "Towards Robust Temporal Reasoning of Large Language Models via a\n  Multi-Hop QA Dataset and Pseudo-Instruction Tuning",
            "updated": "2023-11-16T11:49:29Z",
            "published": "2023-11-16T11:49:29Z",
            "summary": "Knowledge in the real world is being updated constantly. However, it is\ncostly to frequently update large language models (LLMs). Therefore, it is\ncrucial for LLMs to understand the concept of temporal knowledge. However,\nprior works on temporal question answering did not emphasize multi-answer and\nmulti-hop types of temporal reasoning. In this paper, we propose a complex\ntemporal question-answering (QA) dataset Complex-TR that focuses on\nmulti-answer and multi-hop temporal reasoning. Besides, we also propose a novel\ndata augmentation strategy to improve the complex temporal reasoning capability\nand robustness of LLMs. We conducted experiments on multiple temporal QA\ndatasets. Experimental results show that our method is able to improve LLMs'\nperformance on temporal QA benchmarks by significant margins.",
            "author": [
                "Qingyu Tan",
                "Hwee Tou Ng",
                "Lidong Bing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09821v1",
                "http://arxiv.org/pdf/2311.09821v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09819v1",
            "title": "PWISeg: Point-based Weakly-supervised Instance Segmentation for Surgical\n  Instruments",
            "updated": "2023-11-16T11:48:29Z",
            "published": "2023-11-16T11:48:29Z",
            "summary": "In surgical procedures, correct instrument counting is essential. Instance\nsegmentation is a location method that locates not only an object's bounding\nbox but also each pixel's specific details. However, obtaining mask-level\nannotations is labor-intensive in instance segmentation. To address this issue,\nwe propose a novel yet effective weakly-supervised surgical instrument instance\nsegmentation approach, named Point-based Weakly-supervised Instance\nSegmentation (PWISeg). PWISeg adopts an FCN-based architecture with\npoint-to-box and point-to-mask branches to model the relationships between\nfeature points and bounding boxes, as well as feature points and segmentation\nmasks on FPN, accomplishing instrument detection and segmentation jointly in a\nsingle model. Since mask level annotations are hard to available in the real\nworld, for point-to-mask training, we introduce an unsupervised projection\nloss, utilizing the projected relation between predicted masks and bboxes as\nsupervision signal. On the other hand, we annotate a few pixels as the key\npixel for each instrument. Based on this, we further propose a key pixel\nassociation loss and a key pixel distribution loss, driving the point-to-mask\nbranch to generate more accurate segmentation predictions. To comprehensively\nevaluate this task, we unveil a novel surgical instrument dataset with manual\nannotations, setting up a benchmark for further research. Our comprehensive\nresearch trial validated the superior performance of our PWISeg. The results\nshow that the accuracy of surgical instrument segmentation is improved,\nsurpassing most methods of instance segmentation via weakly supervised bounding\nboxes. This improvement is consistently observed in our proposed dataset and\nwhen applied to the public HOSPI-Tools dataset.",
            "author": [
                "Zhen Sun",
                "Huan Xu",
                "Jinlin Wu",
                "Zhen Chen",
                "Zhen Lei",
                "Hongbin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09819v1",
                "http://arxiv.org/pdf/2311.09819v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09818v1",
            "title": "SUQL: Conversational Search over Structured and Unstructured Data with\n  Large Language Models",
            "updated": "2023-11-16T11:48:17Z",
            "published": "2023-11-16T11:48:17Z",
            "summary": "Many knowledge sources consist of both structured information such as\nrelational databases as well as unstructured free text. Building a\nconversational interface to such data sources is challenging.\n  This paper introduces SUQL, Structured and Unstructured Query Language, the\nfirst formal executable representation that naturally covers compositions of\nstructured and unstructured data queries. Specifically, it augments SQL with\nseveral free-text primitives to form a precise, succinct, and expressive\nrepresentation. This paper also presents a conversational search agent based on\nlarge language models, including a few-shot contextual semantic parser for\nSUQL.\n  To validate our approach, we introduce a dataset consisting of crowdsourced\nquestions and conversations about real restaurants. Over 51% of the questions\nin the dataset require both structured and unstructured data, suggesting that\nit is a common phenomenon. We show that our few-shot conversational agent based\non SUQL finds an entity satisfying all user requirements 89.3% of the time,\ncompared to just 65.0% for a strong and commonly used baseline.",
            "author": [
                "Shicheng Liu",
                "Jialiang Xu",
                "Wesley Tjangnaka",
                "Sina J. Semnani",
                "Chen Jie Yu",
                "Gui D\u00e1vid",
                "Monica S. Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09818v1",
                "http://arxiv.org/pdf/2311.09818v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10537v1",
            "title": "MedAgents: Large Language Models as Collaborators for Zero-shot Medical\n  Reasoning",
            "updated": "2023-11-16T11:47:58Z",
            "published": "2023-11-16T11:47:58Z",
            "summary": "Large Language Models (LLMs), despite their remarkable progress across\nvarious general domains, encounter significant barriers in medicine and\nhealthcare. This field faces unique challenges such as domain-specific\nterminologies and the reasoning over specialized knowledge. To address these\nobstinate issues, we propose a novel Multi-disciplinary Collaboration (MC)\nframework for the medical domain that leverages role-playing LLM-based agents\nwho participate in a collaborative multi-round discussion, thereby enhancing\nLLM proficiency and reasoning capabilities. This training-free and\ninterpretable framework encompasses five critical steps: gathering domain\nexperts, proposing individual analyses, summarising these analyses into a\nreport, iterating over discussions until a consensus is reached, and ultimately\nmaking a decision. Our work particularly focuses on the zero-shot scenario, our\nresults on nine data sets (MedQA, MedMCQA, PubMedQA, and six subtasks from\nMMLU) establish that our proposed MC framework excels at mining and harnessing\nthe medical expertise in LLMs, as well as extending its reasoning abilities.\nBased on these outcomes, we further conduct a human evaluation to pinpoint and\ncategorize common errors within our method, as well as ablation studies aimed\nat understanding the impact of various factors on overall performance. Our code\ncan be found at \\url{https://github.com/gersteinlab/MedAgents}.",
            "author": [
                "Xiangru Tang",
                "Anni Zou",
                "Zhuosheng Zhang",
                "Yilun Zhao",
                "Xingyao Zhang",
                "Arman Cohan",
                "Mark Gerstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10537v1",
                "http://arxiv.org/pdf/2311.10537v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09817v1",
            "title": "Neural-Logic Human-Object Interaction Detection",
            "updated": "2023-11-16T11:47:53Z",
            "published": "2023-11-16T11:47:53Z",
            "summary": "The interaction decoder utilized in prevalent Transformer-based HOI detectors\ntypically accepts pre-composed human-object pairs as inputs. Though achieving\nremarkable performance, such paradigm lacks feasibility and cannot explore\nnovel combinations over entities during decoding. We present L OGIC HOI, a new\nHOI detector that leverages neural-logic reasoning and Transformer to infer\nfeasible interactions between entities. Specifically, we modify the\nself-attention mechanism in vanilla Transformer, enabling it to reason over the\n<human, action, object> triplet and constitute novel interactions. Meanwhile,\nsuch reasoning process is guided by two crucial properties for understanding\nHOI: affordances (the potential actions an object can facilitate) and proxemics\n(the spatial relations between humans and objects). We formulate these two\nproperties in first-order logic and ground them into continuous space to\nconstrain the learning process of our approach, leading to improved performance\nand zero-shot generalization capabilities. We evaluate L OGIC HOI on V-COCO and\nHICO-DET under both normal and zero-shot setups, achieving significant\nimprovements over existing methods.",
            "author": [
                "Liulei Li",
                "Jianan Wei",
                "Wenguan Wang",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09817v1",
                "http://arxiv.org/pdf/2311.09817v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09816v1",
            "title": "Performance Trade-offs of Watermarking Large Language Models",
            "updated": "2023-11-16T11:44:58Z",
            "published": "2023-11-16T11:44:58Z",
            "summary": "Amidst growing concerns of large language models (LLMs) being misused for\ngenerating misinformation or completing homework assignments, watermarking has\nemerged as an effective solution for distinguishing human-written and\nLLM-generated text. A prominent watermarking strategy is to embed a signal into\ngenerated text by upsampling a (pseudorandomly-chosen) subset of tokens at\nevery generation step. Although this signal is imperceptible to a human reader,\nit is detectable through statistical testing. However, implanting such signals\nalters the model's output distribution and can have unintended effects when\nwatermarked LLMs are used for downstream applications. In this work, we\nevaluate the performance of watermarked LLMs on a diverse suite of tasks,\nincluding text classification, textual entailment, reasoning, question\nanswering, translation, summarization, and language modeling. We find that\nwatermarking has negligible impact on the performance of tasks posed as k-class\nclassification problems in the average case. However, the accuracy can plummet\nto that of a random classifier for some scenarios (that occur with\nnon-negligible probability). Tasks that are cast as multiple-choice questions\nand short-form generation are surprisingly unaffected by watermarking. For\nlong-form generation tasks, including summarization and translation, we see a\ndrop of 15-20% in the performance due to watermarking. Our findings highlight\nthe trade-offs that users should be cognizant of when using watermarked models,\nand point to cases where future research could improve existing trade-offs.",
            "author": [
                "Anirudh Ajith",
                "Sameer Singh",
                "Danish Pruthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09816v1",
                "http://arxiv.org/pdf/2311.09816v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09814v1",
            "title": "Stacked Intelligent Metasurface-Aided MIMO Transceiver Design",
            "updated": "2023-11-16T11:39:52Z",
            "published": "2023-11-16T11:39:52Z",
            "summary": "Next-generation wireless networks are expected to utilize the limited radio\nfrequency (RF) resources more efficiently with the aid of intelligent\ntransceivers. To this end, we propose a promising transceiver architecture\nrelying on stacked intelligent metasurfaces (SIM). An SIM is constructed by\nstacking an array of programmable metasurface layers, where each layer consists\nof a massive number of low-cost passive meta-atoms that individually manipulate\nthe electromagnetic (EM) waves. By appropriately configuring the passive\nmeta-atoms, an SIM is capable of accomplishing advanced computation and signal\nprocessing tasks, such as multiple-input multiple-output (MIMO)\nprecoding/combining, multi-user interference mitigation, and radar sensing, as\nthe EM wave propagates through the multiple layers of the metasurface, which\neffectively reduces both the RF-related energy consumption and processing\ndelay. Inspired by this, we provide an overview of the SIM-aided MIMO\ntransceiver design, which encompasses its hardware architecture and its\npotential benefits over state-of-the-art solutions. Furthermore, we discuss\npromising application scenarios and identify the open research challenges\nassociated with the design of advanced SIM architectures for next-generation\nwireless networks. Finally, numerical results are provided for quantifying the\nbenefits of wave-based signal processing in wireless systems.",
            "author": [
                "Jiancheng An",
                "Chau Yuen",
                "Chao Xu",
                "Hongbin Li",
                "Derrick Wing Kwan Ng",
                "Marco Di Renzo",
                "M\u00e9rouane Debbah",
                "Lajos Hanzo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09814v1",
                "http://arxiv.org/pdf/2311.09814v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09812v1",
            "title": "Large Language Models for Propaganda Span Annotation",
            "updated": "2023-11-16T11:37:54Z",
            "published": "2023-11-16T11:37:54Z",
            "summary": "The use of propagandistic techniques in online communication has increased in\nrecent years, aiming to manipulate online audiences. Efforts to automatically\ndetect and debunk such content have been made, addressing various modeling\nscenarios. These include determining whether the content (text, image, or\nmultimodal) (i) is propagandistic, (ii) employs one or more techniques, and\n(iii) includes techniques with identifiable spans. Significant research efforts\nhave been devoted to the first two scenarios compared to the latter. Therefore,\nin this study, we focus on the task of detecting propagandistic textual spans.\nWe investigate whether large language models such as GPT-4 can be utilized to\nperform the task of an annotator. For the experiments, we used an in-house\ndeveloped dataset consisting of annotations from multiple annotators. Our\nresults suggest that providing more information to the model as prompts\nimproves the annotation agreement and performance compared to human\nannotations. We plan to make the annotated labels from multiple annotators,\nincluding GPT-4, available for the community.",
            "author": [
                "Maram Hasanain",
                "Fatema Ahmed",
                "Firoj Alam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09812v1",
                "http://arxiv.org/pdf/2311.09812v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10123v1",
            "title": "MetaDreamer: Efficient Text-to-3D Creation With Disentangling Geometry\n  and Texture",
            "updated": "2023-11-16T11:35:10Z",
            "published": "2023-11-16T11:35:10Z",
            "summary": "Generative models for 3D object synthesis have seen significant advancements\nwith the incorporation of prior knowledge distilled from 2D diffusion models.\nNevertheless, challenges persist in the form of multi-view geometric\ninconsistencies and slow generation speeds within the existing 3D synthesis\nframeworks. This can be attributed to two factors: firstly, the deficiency of\nabundant geometric a priori knowledge in optimization, and secondly, the\nentanglement issue between geometry and texture in conventional 3D generation\nmethods.In response, we introduce MetaDreammer, a two-stage optimization\napproach that leverages rich 2D and 3D prior knowledge. In the first stage, our\nemphasis is on optimizing the geometric representation to ensure multi-view\nconsistency and accuracy of 3D objects. In the second stage, we concentrate on\nfine-tuning the geometry and optimizing the texture, thereby achieving a more\nrefined 3D object. Through leveraging 2D and 3D prior knowledge in two stages,\nrespectively, we effectively mitigate the interdependence between geometry and\ntexture. MetaDreamer establishes clear optimization objectives for each stage,\nresulting in significant time savings in the 3D generation process. Ultimately,\nMetaDreamer can generate high-quality 3D objects based on textual prompts\nwithin 20 minutes, and to the best of our knowledge, it is the most efficient\ntext-to-3D generation method. Furthermore, we introduce image control into the\nprocess, enhancing the controllability of 3D generation. Extensive empirical\nevidence confirms that our method is not only highly efficient but also\nachieves a quality level that is at the forefront of current state-of-the-art\n3D generation techniques.",
            "author": [
                "Lincong Feng",
                "Muyu Wang",
                "Maoyu Wang",
                "Kuo Xu",
                "Xiaoli Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10123v1",
                "http://arxiv.org/pdf/2311.10123v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09810v1",
            "title": "Towards Formal Fault Injection for Safety Assessment of Automated\n  Systems",
            "updated": "2023-11-16T11:34:18Z",
            "published": "2023-11-16T11:34:18Z",
            "summary": "Reasoning about safety, security, and other dependability attributes of\nautonomous systems is a challenge that needs to be addressed before the\nadoption of such systems in day-to-day life. Formal methods is a class of\nmethods that mathematically reason about a system's behavior. Thus, a\ncorrectness proof is sufficient to conclude the system's dependability.\nHowever, these methods are usually applied to abstract models of the system,\nwhich might not fully represent the actual system. Fault injection, on the\nother hand, is a testing method to evaluate the dependability of systems.\nHowever, the amount of testing required to evaluate the system is rather large\nand often a problem. This vision paper introduces formal fault injection, a\nfusion of these two techniques throughout the development lifecycle to enhance\nthe dependability of autonomous systems. We advocate for a more cohesive\napproach by identifying five areas of mutual support between formal methods and\nfault injection. By forging stronger ties between the two fields, we pave the\nway for developing safe and dependable autonomous systems. This paper delves\ninto the integration's potential and outlines future research avenues,\naddressing open challenges along the way.",
            "author": [
                "Ashfaq Farooqui",
                "Behrooz Sangchoolie"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.11",
                "http://arxiv.org/abs/2311.09810v1",
                "http://arxiv.org/pdf/2311.09810v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09809v1",
            "title": "Comparing Differentiable Logics for Learning Systems: A Research Preview",
            "updated": "2023-11-16T11:33:08Z",
            "published": "2023-11-16T11:33:08Z",
            "summary": "Extensive research on formal verification of machine learning (ML) systems\nindicates that learning from data alone often fails to capture underlying\nbackground knowledge. A variety of verifiers have been developed to ensure that\na machine-learnt model satisfies correctness and safety properties, however,\nthese verifiers typically assume a trained network with fixed weights.\nML-enabled autonomous systems are required to not only detect incorrect\npredictions, but should also possess the ability to self-correct, continuously\nimproving and adapting. A promising approach for creating ML models that\ninherently satisfy constraints is to encode background knowledge as logical\nconstraints that guide the learning process via so-called differentiable\nlogics. In this research preview, we compare and evaluate various logics from\nthe literature in weakly-supervised contexts, presenting our findings and\nhighlighting open problems for future work. Our experimental results are\nbroadly consistent with results reported previously in literature; however,\nlearning with differentiable logics introduces a new hyperparameter that is\ndifficult to tune and has significant influence on the effectiveness of the\nlogics.",
            "author": [
                "Thomas Flinkow",
                "Barak A. Pearlmutter",
                "Rosemary Monahan"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.3",
                "http://arxiv.org/abs/2311.09809v1",
                "http://arxiv.org/pdf/2311.09809v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09808v1",
            "title": "PixT3: Pixel-based Table To Text generation",
            "updated": "2023-11-16T11:32:47Z",
            "published": "2023-11-16T11:32:47Z",
            "summary": "Table-to-Text has been traditionally approached as a linear language to text\nproblem. However, visually represented tables are rich in visual information\nand serve as a concise, effective form of representing data and its\nrelationships. When using text-based approaches, after the linearization\nprocess, this information is either lost or represented in a space inefficient\nmanner. This inefficiency has remained a constant challenge for text-based\napproaches making them struggle with large tables. In this paper, we\ndemonstrate that image representation of tables are more space-efficient than\nthe typical textual linearizations, and multi-modal approaches are competitive\nin Table-to-Text tasks. We present PixT3, a multimodal table-to-text model that\noutperforms the state-of-the-art (SotA) in the ToTTo benchmark in a pure\nTable-to-Text setting while remaining competitive in controlled Table-to-Text\nscenarios. It also generalizes better in unseen datasets, outperforming ToTTo\nSotA in all generation settings. Additionally, we introduce a new intermediate\ntraining curriculum to reinforce table structural awareness, leading to\nimproved generation and overall faithfulness of the models.",
            "author": [
                "I\u00f1igo Alonso",
                "Eneko Agirre",
                "Mirella Lapata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09808v1",
                "http://arxiv.org/pdf/2311.09808v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09807v1",
            "title": "The Curious Decline of Linguistic Diversity: Training Language Models on\n  Synthetic Text",
            "updated": "2023-11-16T11:31:50Z",
            "published": "2023-11-16T11:31:50Z",
            "summary": "This study investigates the consequences of training large language models\n(LLMs) on synthetic data generated by their predecessors, an increasingly\nprevalent practice aimed at addressing the limited supply of human-generated\ntraining data. Diverging from the usual emphasis on performance metrics, we\nfocus on the impact of this training methodology on linguistic diversity,\nespecially when conducted recursively over time. To assess this, we developed a\nset of novel metrics targeting lexical, syntactic, and semantic diversity,\napplying them in recursive fine-tuning experiments across various natural\nlanguage generation tasks. Our findings reveal a marked decrease in the\ndiversity of the models' outputs through successive iterations. This trend\nunderscores the potential risks of training LLMs on predecessor-generated text,\nparticularly concerning the preservation of linguistic richness. Our study\nhighlights the need for careful consideration of the long-term effects of such\ntraining approaches on the linguistic capabilities of LLMs.",
            "author": [
                "Yanzhu Guo",
                "Guokan Shang",
                "Michalis Vazirgiannis",
                "Chlo\u00e9 Clavel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09807v1",
                "http://arxiv.org/pdf/2311.09807v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09806v2",
            "title": "EvaSurf: Efficient View-Aware Implicit Textured Surface Reconstruction\n  on Mobile Devices",
            "updated": "2023-11-18T07:30:54Z",
            "published": "2023-11-16T11:30:56Z",
            "summary": "Reconstructing real-world 3D objects has numerous applications in computer\nvision, such as virtual reality, video games, and animations. Ideally, 3D\nreconstruction methods should generate high-fidelity results with 3D\nconsistency in real-time. Traditional methods match pixels between images using\nphoto-consistency constraints or learned features, while differentiable\nrendering methods like Neural Radiance Fields (NeRF) use differentiable volume\nrendering or surface-based representation to generate high-fidelity scenes.\nHowever, these methods require excessive runtime for rendering, making them\nimpractical for daily applications. To address these challenges, we present\n$\\textbf{EvaSurf}$, an $\\textbf{E}$fficient $\\textbf{V}$iew-$\\textbf{A}$ware\nimplicit textured $\\textbf{Surf}$ace reconstruction method on mobile devices.\nIn our method, we first employ an efficient surface-based model with a\nmulti-view supervision module to ensure accurate mesh reconstruction. To enable\nhigh-fidelity rendering, we learn an implicit texture embedded with a set of\nGaussian lobes to capture view-dependent information. Furthermore, with the\nexplicit geometry and the implicit texture, we can employ a lightweight neural\nshader to reduce the expense of computation and further support real-time\nrendering on common mobile devices. Extensive experiments demonstrate that our\nmethod can reconstruct high-quality appearance and accurate mesh on both\nsynthetic and real-world datasets. Moreover, our method can be trained in just\n1-2 hours using a single GPU and run on mobile devices at over 40 FPS (Frames\nPer Second), with a final package required for rendering taking up only 40-50\nMB.",
            "author": [
                "Jingnan Gao",
                "Zhuo Chen",
                "Yichao Yan",
                "Bowen Pan",
                "Zhe Wang",
                "Jiangjing Lyu",
                "Xiaokang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09806v2",
                "http://arxiv.org/pdf/2311.09806v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09805v1",
            "title": "DocMath-Eval: Evaluating Numerical Reasoning Capabilities of LLMs in\n  Understanding Long Documents with Tabular Data",
            "updated": "2023-11-16T11:30:53Z",
            "published": "2023-11-16T11:30:53Z",
            "summary": "Recent LLMs have demonstrated remarkable performance in solving exam-like\nmath word problems. However, the degree to which these numerical reasoning\nskills are effective in real-world scenarios, particularly in expert domains,\nis still largely unexplored. This paper introduces DocMath-Eval, a\ncomprehensive benchmark specifically designed to evaluate the numerical\nreasoning and problem-solving capabilities of LLMs in the context of\nunderstanding and analyzing financial documents containing both text and\ntables. We evaluate a wide spectrum of 19 LLMs, including those specialized in\ncoding and finance. We also incorporate different prompting strategies (i.e.,\nChain-of-Thoughts and Program-of-Thoughts) to comprehensively assess the\ncapabilities and limitations of existing LLMs in DocMath-Eval. We found that,\nalthough the current best-performing system (i.e., GPT-4), can perform well on\nsimple problems such as calculating the rate of increase in a financial metric\nwithin a short document context, it significantly lags behind human experts in\nmore complex problems grounded in longer contexts. We believe DocMath-Eval can\nbe used as a valuable benchmark to evaluate LLMs' capabilities to solve\nchallenging numerical reasoning problems in expert domains. We will release the\nbenchmark and code at https://github.com/yale-nlp/DocMath-Eval.",
            "author": [
                "Yilun Zhao",
                "Yitao Long",
                "Hongjun Liu",
                "Linyong Nan",
                "Lyuhao Chen",
                "Ryo Kamoi",
                "Yixin Liu",
                "Xiangru Tang",
                "Rui Zhang",
                "Arman Cohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09805v1",
                "http://arxiv.org/pdf/2311.09805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09802v1",
            "title": "Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs",
            "updated": "2023-11-16T11:26:21Z",
            "published": "2023-11-16T11:26:21Z",
            "summary": "Though prompting LLMs with various reasoning structures produces reasoning\nproofs along with answers, these proofs are not ensured to be causal and\nreliable due to the inherent defects of LLMs. Tracking such deficiencies, we\npresent a neuro-symbolic integration method, in which a neural LLM is used to\nrepresent the knowledge of the problem while an LLM-free symbolic solver is\nadopted to do deliberative reasoning using the knowledge. Specifically, our\ncustomized meta-interpreters allow the production of reasoning proofs and\nsupport flexible search strategies. These reasoning proofs are ensured to be\ncausal and reliable because of the deterministic executing nature of the\nsymbolic solvers. Empirically, on ProofWriter, our method surpasses the CoT\nbaseline by nearly double in accuracy and more than triple in proof similarity.\nOn GSM8K, our method also shows accuracy improvements and nearly doubled proof\nsimilarity. Our code is released at https://github.com/DAMO-NLP-SG/CaRing",
            "author": [
                "Sen Yang",
                "Xin Li",
                "Leyang Cui",
                "Lidong Bing",
                "Wai Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09802v1",
                "http://arxiv.org/pdf/2311.09802v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09800v1",
            "title": "$\\textit{Dial BeInfo for Faithfulness}$: Improving Factuality of\n  Information-Seeking Dialogue via Behavioural Fine-Tuning",
            "updated": "2023-11-16T11:25:44Z",
            "published": "2023-11-16T11:25:44Z",
            "summary": "Factuality is a crucial requirement in information seeking dialogue: the\nsystem should respond to the user's queries so that the responses are\nmeaningful and aligned with the knowledge provided to the system. However, most\nmodern large language models suffer from hallucinations, that is, they generate\nresponses not supported by or contradicting the knowledge source. To mitigate\nthe issue and increase faithfulness of information-seeking dialogue systems, we\nintroduce BeInfo, a simple yet effective method that applies behavioural tuning\nto aid information-seeking dialogue. Relying on three standard datasets, we\nshow that models tuned with BeInfo} become considerably more faithful to the\nknowledge source both for datasets and domains seen during BeInfo-tuning, as\nwell as on unseen domains, when applied in a zero-shot manner. In addition, we\nshow that the models with 3B parameters (e.g., Flan-T5) tuned with BeInfo\ndemonstrate strong performance on data from real `production' conversations and\noutperform GPT4 when tuned on a limited amount of such realistic in-domain\ndialogues.",
            "author": [
                "Evgeniia Razumovskaia",
                "Ivan Vuli\u0107",
                "Pavle Markovi\u0107",
                "Tomasz Cichy",
                "Qian Zheng",
                "Tsung-Hsien Wen",
                "Pawe\u0142 Budzianowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09800v1",
                "http://arxiv.org/pdf/2311.09800v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09799v1",
            "title": "How Far Can We Extract Diverse Perspectives from Large Language Models?\n  Criteria-Based Diversity Prompting!",
            "updated": "2023-11-16T11:23:38Z",
            "published": "2023-11-16T11:23:38Z",
            "summary": "Collecting diverse human data on subjective NLP topics is costly and\nchallenging. As Large Language Models (LLMs) have developed human-like\ncapabilities, there is a recent trend in collaborative efforts between humans\nand LLMs for generating diverse data, offering potential scalable and efficient\nsolutions. However, the extent of LLMs' capability to generate diverse\nperspectives on subjective topics remains an unexplored question. In this\nstudy, we investigate LLMs' capacity for generating diverse perspectives and\nrationales on subjective topics, such as social norms and argumentative texts.\nWe formulate this problem as diversity extraction in LLMs and propose a\ncriteria-based prompting technique to ground diverse opinions and measure\nperspective diversity from the generated criteria words. Our results show that\nmeasuring semantic diversity through sentence embeddings and distance metrics\nis not enough to measure perspective diversity. To see how far we can extract\ndiverse perspectives from LLMs, or called diversity coverage, we employ a\nstep-by-step recall prompting for generating more outputs from the model in an\niterative manner. As we apply our prompting method to other tasks (hate speech\nlabeling and story continuation), indeed we find that LLMs are able to generate\ndiverse opinions according to the degree of task subjectivity.",
            "author": [
                "Shirley Anugrah Hayati",
                "Minhwa Lee",
                "Dheeraj Rajagopal",
                "Dongyeop Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09799v1",
                "http://arxiv.org/pdf/2311.09799v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09797v1",
            "title": "KnowledgeMath: Knowledge-Intensive Math Word Problem Solving in Finance\n  Domains",
            "updated": "2023-11-16T11:22:08Z",
            "published": "2023-11-16T11:22:08Z",
            "summary": "We introduce KnowledgeMath, a novel benchmark designed to evaluate LLMs'\ncapabilities in applying financial knowledge to solve complex math word\nproblems. Compared to prior works, this study features three core advancements.\nFirst, KnowledgeMath includes 1,259 problems with a hybrid of textual and\ntabular content and require college-level knowledge in the finance domain for\neffective resolution. Second, we provide expert-annotated, detailed solution\nreferences in Python program format, ensuring a high-quality benchmark for LLM\nassessment. Finally, we evaluate a wide spectrum of 14 LLMs with different\nprompting strategies like Chain-of-Thoughts and Program-of-Thoughts. The\ncurrent best-performing system (i.e., GPT-4 with Program-of-Thoughts) achieves\nonly 45.4% accuracy, leaving substantial room for improvement. While\nknowledge-augmented LLMs can improve the performance (e.g., from 23.9% to 32.0%\nfor GPT-3.5), it is still significantly lower the estimated human expert\nperformance of 94%. We believe that KnowledgeMath can facilitate future\nresearch on domain-specific knowledge retrieval and augmentation into the math\nword problem-solving process. We will release the benchmark and code at\nhttps://github.com/yale-nlp/KnowledgeMath.",
            "author": [
                "Yilun Zhao",
                "Hongjun Liu",
                "Yitao Long",
                "Rui Zhang",
                "Chen Zhao",
                "Arman Cohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09797v1",
                "http://arxiv.org/pdf/2311.09797v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09796v1",
            "title": "Interpreting User Requests in the Context of Natural Language Standing\n  Instructions",
            "updated": "2023-11-16T11:19:26Z",
            "published": "2023-11-16T11:19:26Z",
            "summary": "Users of natural language interfaces, generally powered by Large Language\nModels (LLMs),often must repeat their preferences each time they make a similar\nrequest. To alleviate this, we propose including some of a user's preferences\nand instructions in natural language -- collectively termed standing\ninstructions -- as additional context for such interfaces. For example, when a\nuser states I'm hungry, their previously expressed preference for Persian food\nwill be automatically added to the LLM prompt, so as to influence the search\nfor relevant restaurants. We develop NLSI, a language-to-program dataset\nconsisting of over 2.4K dialogues spanning 17 domains, where each dialogue is\npaired with a user profile (a set of users specific standing instructions) and\ncorresponding structured representations (API calls). A key challenge in NLSI\nis to identify which subset of the standing instructions is applicable to a\ngiven dialogue. NLSI contains diverse phenomena, from simple preferences to\ninterdependent instructions such as triggering a hotel search whenever the user\nis booking tickets to an event. We conduct experiments on NLSI using prompting\nwith large language models and various retrieval approaches, achieving a\nmaximum of 44.7% exact match on API prediction. Our results demonstrate the\nchallenges in identifying the relevant standing instructions and their\ninterpretation into API calls.",
            "author": [
                "Nikita Moghe",
                "Patrick Xia",
                "Jacob Andreas",
                "Jason Eisner",
                "Benjamin Van Durme",
                "Harsh Jhamtani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09796v1",
                "http://arxiv.org/pdf/2311.09796v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09794v1",
            "title": "On the Non-Locality of Edge Insertions",
            "updated": "2023-11-16T11:18:46Z",
            "published": "2023-11-16T11:18:46Z",
            "summary": "We challenge the idea that edge insertions are local improvement operations\nand show that the edge-insertion algorithm must sometimes insert an edge\nbetween vertices that are at the farthest combinatorial distance apart, and\nthat this edge must also cross linearly many edges of the triangulation for the\nalgorithm to escape a local optimum and return the optimal triangulation.",
            "author": [
                "Florestan Brunck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09794v1",
                "http://arxiv.org/pdf/2311.09794v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "68U05",
                "G.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09793v1",
            "title": "Fossil 2.0: Formal Certificate Synthesis for the Verification and\n  Control of Dynamical Models",
            "updated": "2023-11-16T11:18:21Z",
            "published": "2023-11-16T11:18:21Z",
            "summary": "This paper presents Fossil 2.0, a new major release of a software tool for\nthe synthesis of certificates (e.g., Lyapunov and barrier functions) for\ndynamical systems modelled as ordinary differential and difference equations.\nFossil 2.0 is much improved from its original release, including new\ninterfaces, a significantly expanded certificate portfolio, controller\nsynthesis and enhanced extensibility. We present these new features as part of\nthis tool paper. Fossil implements a counterexample-guided inductive synthesis\n(CEGIS) loop ensuring the soundness of the method. Our tool uses neural\nnetworks as templates to generate candidate functions, which are then formally\nproven by an SMT solver acting as an assertion verifier. Improvements with\nrespect to the first release include a wider range of certificates, synthesis\nof control laws, and support for discrete-time models.",
            "author": [
                "Alec Edwards",
                "Andrea Peruffo",
                "Alessandro Abate"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09793v1",
                "http://arxiv.org/pdf/2311.09793v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.LO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09791v2",
            "title": "Low-cost singular value decomposition with optimal sensor placement",
            "updated": "2023-11-17T09:33:05Z",
            "published": "2023-11-16T11:14:54Z",
            "summary": "This paper presents a new method capable of reconstructing datasets with\ngreat precision and very low computational cost using a novel variant of the\nsingular value decomposition (SVD) algorithm that has been named low-cost SVD\n(lcSVD). This algorithm allows to reconstruct a dataset from a minimum amount\nof points, that can be selected randomly, equidistantly or can be calculated\nusing the optimal sensor placement functionality that is also presented in this\npaper, which finds minimizing the reconstruction error to validate the\ncalculated sensor positions. This method also allows to find the optimal number\nof sensors, aiding users in optimizing experimental data recollection. The\nmethod is tested in a series of datasets, which vary between experimental and\nnumerical simulations, two- and three-dimensional data and laminar and\nturbulent flow, which have been used to demonstrate the capacity of this method\nbased on its high reconstruction accuracy, robustness, and computational\nresource optimization. Maximum speed-up factors of 630 and memory reduction of\n37% are found when compared to the application of standard SVD to the dataset.\nThis method will be incorporated into ModelFLOWs-app's next version release.",
            "author": [
                "Ashton Hetherington",
                "Soledad Le Clainche"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09791v2",
                "http://arxiv.org/pdf/2311.09791v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10781v1",
            "title": "Can Language Model Moderators Improve the Health of Online Discourse?",
            "updated": "2023-11-16T11:14:22Z",
            "published": "2023-11-16T11:14:22Z",
            "summary": "Human moderation of online conversation is essential to maintaining civility\nand focus in a dialogue, but is challenging to scale and harmful to moderators.\nThe inclusion of sophisticated natural language generation modules as a force\nmultiplier aid moderators is a tantalizing prospect, but adequate evaluation\napproaches have so far been elusive. In this paper, we establish a systematic\ndefinition of conversational moderation effectiveness through a\nmultidisciplinary lens that incorporates insights from social science. We then\npropose a comprehensive evaluation framework that uses this definition to asses\nmodels' moderation capabilities independently of human intervention. With our\nframework, we conduct the first known study of conversational dialogue models\nas moderators, finding that appropriately prompted models can provide specific\nand fair feedback on toxic behavior but struggle to influence users to increase\ntheir levels of respect and cooperation.",
            "author": [
                "Hyundong Cho",
                "Shuai Liu",
                "Taiwei Shi",
                "Darpan Jain",
                "Basem Rizk",
                "Yuyang Huang",
                "Zixun Lu",
                "Nuan Wen",
                "Jonathan Gratch",
                "Emilio Ferrara",
                "Jonathan May"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10781v1",
                "http://arxiv.org/pdf/2311.10781v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09790v3",
            "title": "Breaking Boundaries: Balancing Performance and Robustness in Deep\n  Wireless Traffic Forecasting",
            "updated": "2023-11-28T15:53:00Z",
            "published": "2023-11-16T11:10:38Z",
            "summary": "Balancing the trade-off between accuracy and robustness is a long-standing\nchallenge in time series forecasting. While most of existing robust algorithms\nhave achieved certain suboptimal performance on clean data, sustaining the same\nperformance level in the presence of data perturbations remains extremely hard.\nIn this paper, we study a wide array of perturbation scenarios and propose\nnovel defense mechanisms against adversarial attacks using real-world telecom\ndata. We compare our strategy against two existing adversarial training\nalgorithms under a range of maximal allowed perturbations, defined using\n$\\ell_{\\infty}$-norm, $\\in [0.1,0.4]$. Our findings reveal that our hybrid\nstrategy, which is composed of a classifier to detect adversarial examples, a\ndenoiser to eliminate noise from the perturbed data samples, and a standard\nforecaster, achieves the best performance on both clean and perturbed data. Our\noptimal model can retain up to $92.02\\%$ the performance of the original\nforecasting model in terms of Mean Squared Error (MSE) on clean data, while\nbeing more robust than the standard adversarially trained models on perturbed\ndata. Its MSE is 2.71$\\times$ and 2.51$\\times$ lower than those of comparing\nmethods on normal and perturbed data, respectively. In addition, the components\nof our models can be trained in parallel, resulting in better computational\nefficiency. Our results indicate that we can optimally balance the trade-off\nbetween the performance and robustness of forecasting models by improving the\nclassifier and denoiser, even in the presence of sophisticated and destructive\npoisoning attacks.",
            "author": [
                "Romain Ilbert",
                "Thai V. Hoang",
                "Zonghua Zhang",
                "Themis Palpanas"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3605772.3624002",
                "http://arxiv.org/abs/2311.09790v3",
                "http://arxiv.org/pdf/2311.09790v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "68T05, 62M10, 68T01",
                "I.2.6; I.2.4; K.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09789v1",
            "title": "Arrow's Impossibility Theorem: Computability in Social Choice Theory",
            "updated": "2023-11-16T11:06:13Z",
            "published": "2023-11-16T11:06:13Z",
            "summary": "Arrow's Impossibility Theorem establishes bounds on what we can require from\nvoting systems. Given satisfaction of a small collection of \"fairness\" axioms,\nit shows votes can only exist as dictatorships in which one voter determines\nall outcomes. Votes are modelled as maps from a collection of partial orders,\nthe preferences of voters, to a single verdict which is another aggregated\npartial ordering. This result is classic and has an extension called the\nPossibility Theorem that shows these dictatorships needn't exist with infinite\nvoter sets. Mihara extends this work by examining the computability of each of\nthese results. He found that the only voting systems that are in any sense\ncomputable are necessarily dictatorial, which takes away from the usefulness of\nthe Possibility Theorem.\n  In this paper we primarily survey the results of Mihara, focusing not on\napplied consequences, as much of the surrounding literature does, but going\ninto greater details on the underlying Mathematics and Computability of the\nproofs. We give detailed exposition on the methods used and introduce all\nnotation. We first see complete proofs of the classical results and a\nsufficient introduction to computability that an unfamiliar reader should be\nable to follow without prior knowledge of the field. We then expand into\nMihara's results, and using our established knowledge of computability show the\nproblems with trying to compute non-dictatorial social welfare functions. This\ninvolves introducing an extended definition of computability called pairwise\ncomputability.",
            "author": [
                "Alex Hall"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09789v1",
                "http://arxiv.org/pdf/2311.09789v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09788v1",
            "title": "Towards Proved Formal Specification and Verification of STL Operators as\n  Synchronous Observers",
            "updated": "2023-11-16T11:04:57Z",
            "published": "2023-11-16T11:04:57Z",
            "summary": "Signal Temporal Logic (STL) is a convenient formalism to express bounded\nhorizon properties of autonomous critical systems. STL extends LTL to\nreal-valued signals and associates a non-singleton bound interval to each\ntemporal operators. In this work we provide a rigorous encoding of non-nested\ndiscrete-time STL formulas into Lustre synchronous observers.\n  Our encoding provides a three-valued online semantics for the observers and\ntherefore enables both the verification of the property and the search of\ncounter-examples. A key contribution of this work is an instrumented proof of\nthe validity of the implementation. Each node is proved correct with respect to\nthe original STL semantics. All the experiments are automated with the Kind2\nmodel-checker and the Z3 SMT solver.",
            "author": [
                "C\u00e9line Bellanger",
                "Pierre-Lo\u00efc Garoche",
                "Matthieu Martel",
                "C\u00e9lia Picard"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.14",
                "http://arxiv.org/abs/2311.09788v1",
                "http://arxiv.org/pdf/2311.09788v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09786v1",
            "title": "Correct-by-Construction Control for Stochastic and Uncertain Dynamical\n  Models via Formal Abstractions",
            "updated": "2023-11-16T11:03:54Z",
            "published": "2023-11-16T11:03:54Z",
            "summary": "Automated synthesis of correct-by-construction controllers for autonomous\nsystems is crucial for their deployment in safety-critical scenarios. Such\nautonomous systems are naturally modeled as stochastic dynamical models. The\ngeneral problem is to compute a controller that provably satisfies a given\ntask, represented as a probabilistic temporal logic specification. However,\nfactors such as stochastic uncertainty, imprecisely known parameters, and\nhybrid features make this problem challenging. We have developed an abstraction\nframework that can be used to solve this problem under various modeling\nassumptions. Our approach is based on a robust finite-state abstraction of the\nstochastic dynamical model in the form of a Markov decision process with\nintervals of probabilities (iMDP). We use state-of-the-art verification\ntechniques to compute an optimal policy on the iMDP with guarantees for\nsatisfying the given specification. We then show that, by construction, we can\nrefine this policy into a feedback controller for which these guarantees carry\nover to the dynamical model. In this short paper, we survey our recent research\nin this area and highlight two challenges (related to scalability and dealing\nwith nonlinear dynamics) that we aim to address with our ongoing research.",
            "author": [
                "Thom Badings",
                "Nils Jansen",
                "Licio Romao",
                "Alessandro Abate"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.10",
                "http://arxiv.org/abs/2311.09786v1",
                "http://arxiv.org/pdf/2311.09786v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09785v1",
            "title": "Enforcing Timing Properties in Motorway Traffic",
            "updated": "2023-11-16T11:03:35Z",
            "published": "2023-11-16T11:03:35Z",
            "summary": "In previous work, we proposed a Runtime Enforcement Approach to deal with\ntiming properties in motorway traffic, which are present in form of Timed\nMulti-Lane Spatial Logic (TMLSL) formulae, a logic tailored to express both\nspatial and timing properties. Employing communication between the cars, we\nutilised a nondeterministic controller guessing which actions to execute next\nfor each car, before asking the local monitors of the cars for permission to\nexecute the announced actions. In this contribution, we consider a more\nreasonable controller that only considers sequences that satisfy its own\nproperties. This is done utilising region automata that one can generate from\nthe cars' specifications. In the approach, we also came along a minor\ndecidability result for TMLSL.",
            "author": [
                "Christopher Bischopink"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.9",
                "http://arxiv.org/abs/2311.09785v1",
                "http://arxiv.org/pdf/2311.09785v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09784v1",
            "title": "Automatic Generation of Scenarios for System-level Simulation-based\n  Verification of Autonomous Driving Systems",
            "updated": "2023-11-16T11:03:13Z",
            "published": "2023-11-16T11:03:13Z",
            "summary": "With increasing complexity of Automated Driving Systems (ADS), ensuring their\nsafety and reliability has become a critical challenge. The Verification and\nValidation (V&V) of these systems are particularly demanding when AI components\nare employed to implement perception and/or control functions. In ESA-funded\nproject VIVAS, we developed a generic framework for system-level\nsimulation-based V&V of autonomous systems. The approach is based on a\nsimulation model of the system, an abstract model that describes symbolically\nthe system behavior, and formal methods to generate scenarios and verify the\nsimulation executions. Various coverage criteria can be defined to guide the\nautomated generation of the scenarios.\n  In this paper, we describe the instantiation of the VIVAS framework for an\nADS case study. This is based on the integration of CARLA, a widely-used\ndriving simulator, and its ScenarioRunner tool, which enables the creation of\ndiverse and complex driving scenarios. This is also used in the CARLA\nAutonomous Driving Challenge to validate different ADS agents for perception\nand control based on AI, shared by the CARLA community. We describe the\ndevelopment of an abstract ADS model and the formulation of a coverage\ncriterion that focuses on the behaviors of vehicles relative to the vehicle\nwith ADS under verification. Leveraging the VIVAS framework, we generate and\nexecute various driving scenarios, thus testing the capabilities of the AI\ncomponents. The results show the effectiveness of VIVAS in automatically\ngenerating scenarios for system-level simulation-based V&V of an automated\ndriving system using CARLA and ScenarioRunner. Therefore, they highlight the\npotential of the approach as a powerful tool in the future of ADS V&V\nmethodologies.",
            "author": [
                "Srajan Goyal",
                "Alberto Griggio",
                "Jacob Kimblad",
                "Stefano Tonetta"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.8",
                "http://arxiv.org/abs/2311.09784v1",
                "http://arxiv.org/pdf/2311.09784v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09783v1",
            "title": "Investigating Data Contamination in Modern Benchmarks for Large Language\n  Models",
            "updated": "2023-11-16T11:03:04Z",
            "published": "2023-11-16T11:03:04Z",
            "summary": "Recent observations have underscored a disparity between the inflated\nbenchmark scores and the actual performance of LLMs, raising concerns about\npotential contamination of evaluation benchmarks. This issue is especially\ncritical for closed-source models and certain open-source models where training\ndata transparency is lacking. In this paper we study data contamination by\nproposing two methods tailored for both open-source and proprietary LLMs. We\nfirst introduce a retrieval-based system to explore potential overlaps between\nevaluation benchmarks and pretraining corpora. We further present a novel\ninvestigation protocol named \\textbf{T}estset \\textbf{S}lot Guessing\n(\\textit{TS-Guessing}), applicable to both open and proprietary models. This\napproach entails masking a wrong answer in a multiple-choice question and\nprompting the model to fill in the gap. Additionally, it involves obscuring an\nunlikely word in an evaluation example and asking the model to produce it. We\nfind that certain commercial LLMs could surprisingly guess the missing option\nin various test sets. Specifically, in the TruthfulQA benchmark, we find that\nLLMs exhibit notable performance improvement when provided with additional\nmetadata in the benchmark. Further, in the MMLU benchmark, ChatGPT and GPT-4\ndemonstrated an exact match rate of 52\\% and 57\\%, respectively, in guessing\nthe missing options in benchmark test data. We hope these results underscore\nthe need for more robust evaluation methodologies and benchmarks in the field.",
            "author": [
                "Chunyuan Deng",
                "Yilun Zhao",
                "Xiangru Tang",
                "Mark Gerstein",
                "Arman Cohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09783v1",
                "http://arxiv.org/pdf/2311.09783v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09782v1",
            "title": "More Samples or More Prompt Inputs? Exploring Effective In-Context\n  Sampling for LLM Few-Shot Prompt Engineering",
            "updated": "2023-11-16T11:02:49Z",
            "published": "2023-11-16T11:02:49Z",
            "summary": "While most existing works on LLM prompt-engineering focus only on how to\nselect a better set of data samples inside one single prompt input (In-Context\nLearning or ICL), why can't we design and leverage multiple prompt inputs\ntogether to further improve the LLM performance? In this work, we propose\nIn-Context Sampling (ICS), a low-resource LLM prompt-engineering technique to\nproduce the most confident prediction results by optimizing the construction of\nmultiple ICL prompt inputs. Extensive experiments with two SOTA LLMs (FlanT5-XL\nand Mistral-7B) on three NLI datasets (e-SNLI, Multi-NLI, and ANLI) illustrate\nthat ICS can consistently enhance LLM's prediction performance and confidence.\nAn ablation study suggests that a diversity-based ICS strategy may further\nimprove LLM's performance, which sheds light on a new yet promising future\nresearch direction.",
            "author": [
                "Bingsheng Yao",
                "Guiming Chen",
                "Ruishi Zou",
                "Yuxuan Lu",
                "Jiachen Li",
                "Shao Zhang",
                "Sijia Liu",
                "James Hendler",
                "Dakuo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09782v1",
                "http://arxiv.org/pdf/2311.09782v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09781v1",
            "title": "Online Reachability Analysis and Space Convexification for Autonomous\n  Racing",
            "updated": "2023-11-16T11:02:48Z",
            "published": "2023-11-16T11:02:48Z",
            "summary": "This paper presents an optimisation-based approach for an obstacle avoidance\nproblem within an autonomous vehicle racing context. Our control regime\nleverages online reachability analysis and sensor data to compute the maximal\nsafe traversable region that an agent can traverse within the environment. The\nidea is to first compute a non-convex safe region, which then can be\nconvexified via a novel coupled separating hyperplane algorithm. This derived\nsafe area is then used to formulate a nonlinear model-predictive control\nproblem that seeks to find an optimal and safe driving trajectory. We evaluate\nthe proposed approach through a series of diverse experiments and assess the\nruntime requirements of our proposed approach through an analysis of the\neffects of a set of varying optimisation objectives for generating these\ncoupled hyperplanes.",
            "author": [
                "Sergiy Bogomolov",
                "Taylor T. Johnson",
                "Diego Manzanas Lopez",
                "Patrick Musau",
                "Paulius Stankaitis"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.7",
                "http://arxiv.org/abs/2311.09781v1",
                "http://arxiv.org/pdf/2311.09781v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09780v1",
            "title": "Model Checking for Closed-Loop Robot Reactive Planning",
            "updated": "2023-11-16T11:02:29Z",
            "published": "2023-11-16T11:02:29Z",
            "summary": "In this paper, we show how model checking can be used to create multi-step\nplans for a differential drive wheeled robot so that it can avoid immediate\ndanger. Using a small, purpose built model checking algorithm in situ we\ngenerate plans in real-time in a way that reflects the egocentric reactive\nresponse of simple biological agents. Our approach is based on chaining\ntemporary control systems which are spawned to eliminate disturbances in the\nlocal environment that disrupt an autonomous agent from its preferred action\n(or resting state). The method involves a novel discretization of 2D LiDAR data\nwhich is sensitive to bounded stochastic variations in the immediate\nenvironment. We operationalise multi-step planning using invariant checking by\nforward depth-first search, using a cul-de-sac scenario as a first test case.\nOur results demonstrate that model checking can be used to plan efficient\ntrajectories for local obstacle avoidance, improving on the performance of a\nreactive agent which can only plan one step. We achieve this in near real-time\nusing no pre-computed data. While our method has limitations, we believe our\napproach shows promise as an avenue for the development of safe, reliable and\ntransparent trajectory planning in the context of autonomous vehicles.",
            "author": [
                "Christopher Chandler",
                "Bernd Porr",
                "Alice Miller",
                "Giulia Lafratta"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.6",
                "http://arxiv.org/abs/2311.09780v1",
                "http://arxiv.org/pdf/2311.09780v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09778v1",
            "title": "Certified Control for Train Sign Classification",
            "updated": "2023-11-16T11:02:10Z",
            "published": "2023-11-16T11:02:10Z",
            "summary": "There is considerable industrial interest in integrating AI techniques into\nrailway systems, notably for fully autonomous train systems. The KI-LOK\nresearch project is involved in developing new methods for certifying such\nAI-based systems. Here we explore the utility of a certified control\narchitecture for a runtime monitor that prevents false positive detection of\ntraffic signs in an AI-based perception system. The monitor uses classical\ncomputer vision algorithms to check if the signs -- detected by an AI object\ndetection model -- fit predefined specifications. We provide such\nspecifications for some critical signs and integrate a Python prototype of the\nmonitor with a popular object detection model to measure relevant performance\nmetrics on generated data. Our initial results are promising, achieving\nconsiderable precision gains with only minor recall reduction; however, further\ninvestigation into generalization possibilities will be necessary.",
            "author": [
                "Jan Ro\u00dfbach",
                "Michael Leuschel"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.5",
                "http://arxiv.org/abs/2311.09778v1",
                "http://arxiv.org/pdf/2311.09778v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10780v1",
            "title": "Extending Neural Network Verification to a Larger Family of Piece-wise\n  Linear Activation Functions",
            "updated": "2023-11-16T11:01:39Z",
            "published": "2023-11-16T11:01:39Z",
            "summary": "In this paper, we extend an available neural network verification technique\nto support a wider class of piece-wise linear activation functions.\nFurthermore, we extend the algorithms, which provide in their original form\nexact respectively over-approximative results for bounded input sets\nrepresented as start sets, to allow also unbounded input set. We implemented\nour algorithms and demonstrated their effectiveness in some case studies.",
            "author": [
                "L\u00e1szl\u00f3 Antal",
                "Hana Masara",
                "Erika \u00c1brah\u00e1m"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.4",
                "http://arxiv.org/abs/2311.10780v1",
                "http://arxiv.org/pdf/2311.10780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09777v1",
            "title": "Trust Modelling and Verification Using Event-B",
            "updated": "2023-11-16T11:01:20Z",
            "published": "2023-11-16T11:01:20Z",
            "summary": "Trust is a crucial component in collaborative multiagent systems (MAS)\ninvolving humans and autonomous AI agents. Rather than assuming trust based on\npast system behaviours, it is important to formally verify trust by modelling\nthe current state and capabilities of agents. We argue for verifying actual\ntrust relations based on agents abilities to deliver intended outcomes in\nspecific contexts. To enable reasoning about different notions of trust, we\npropose using the refinement-based formal method Event-B. Refinement allows\nprogressively introducing new aspects of trust from abstract to concrete models\nincorporating knowledge and runtime states. We demonstrate modelling three\ntrust concepts and verifying associated trust properties in MAS. The formal,\ncorrectness-by-construction approach allows to deduce guarantees about\ntrustworthy autonomy in human-AI partnerships. Overall, our contribution\nfacilitates rigorous verification of trust in multiagent systems.",
            "author": [
                "Asieh Salehi Fathabadi",
                "Vahid Yazdanpanah"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.2",
                "http://arxiv.org/abs/2311.09777v1",
                "http://arxiv.org/pdf/2311.09777v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09776v1",
            "title": "What to tell when? -- Information Provision as a Game",
            "updated": "2023-11-16T11:01:02Z",
            "published": "2023-11-16T11:01:02Z",
            "summary": "Constantly informing systems (CIS), that is technical systems that provide us\nwith information over a long period of time, face the challenge of providing us\nwith helpful information. The information base of a human model changes over\ntime but also his mood and his ability to accept information. An information\nprovision strategy should hence take such aspects into account. In this paper,\nwe describe our vision of an approach to aid the design of CIS. We envision\nusing psychological models of the human mind and emotions in an information\nprovision game. Its analysis gives comparative insights into design variants.",
            "author": [
                "Astrid Rakow",
                "Mehrnoush Hajnorouzi",
                "Akhila Bairy"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.1",
                "http://arxiv.org/abs/2311.09776v1",
                "http://arxiv.org/pdf/2311.09776v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10122v2",
            "title": "Video-LLaVA: Learning United Visual Representation by Alignment Before\n  Projection",
            "updated": "2023-11-21T14:37:30Z",
            "published": "2023-11-16T10:59:44Z",
            "summary": "The Large Vision-Language Model (LVLM) has enhanced the performance of\nvarious downstream tasks in visual-language understanding. Most existing\napproaches encode images and videos into separate feature spaces, which are\nthen fed as inputs to large language models. However, due to the lack of\nunified tokenization for images and videos, namely misalignment before\nprojection, it becomes challenging for a Large Language Model (LLM) to learn\nmulti-modal interactions from several poor projection layers. In this work, we\nunify visual representation into the language feature space to advance the\nfoundational LLM towards a unified LVLM. As a result, we establish a simple but\nrobust LVLM baseline, Video-LLaVA, which learns from a mixed dataset of images\nand videos, mutually enhancing each other. Video-LLaVA achieves superior\nperformances on a broad range of 9 image benchmarks across 5 image\nquestion-answering datasets and 4 image benchmark toolkits. Additionally, our\nVideo-LLaVA also outperforms Video-ChatGPT by 5.8%, 9.9%, 18.6%, and 10.1% on\nMSRVTT, MSVD, TGIF, and ActivityNet, respectively. Notably, extensive\nexperiments demonstrate that Video-LLaVA mutually benefits images and videos\nwithin a unified visual representation, outperforming models designed\nspecifically for images or videos. We aim for this work to provide modest\ninsights into the multi-modal inputs for the LLM.",
            "author": [
                "Bin Lin",
                "Yang Ye",
                "Bin Zhu",
                "Jiaxi Cui",
                "Munan Ning",
                "Peng Jin",
                "Li Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10122v2",
                "http://arxiv.org/pdf/2311.10122v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09774v1",
            "title": "HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs",
            "updated": "2023-11-16T10:56:24Z",
            "published": "2023-11-16T10:56:24Z",
            "summary": "Adapting a language model into a specific domain, a.k.a `domain adaption', is\na common practice when specialized knowledge, e.g. medicine, is not\nencapsulated in a general language model like Llama2. The challenge lies in the\nheterogeneity of data across the two training stages, as it varies in\nlanguages, genres, or formats. To tackle this and simplify the learning\nprotocol, we propose to transform heterogeneous data, from the both\npre-training and supervised stages, into a unified, simple input-output pair\nformat. We validate the new protocol in the domains where proprietary LLMs like\nChatGPT perform relatively poorly, such as Traditional Chinese Medicine. The\ndeveloped model, HuatuoGPT-II, has shown state-of-the-art performance in\nChinese medicine domain on a number of benchmarks, e.g. medical licensing\nexams. It even outperforms proprietary models like ChatGPT and GPT-4 in some\naspects, especially in Traditional Chinese Medicine. Expert manual evaluations\nfurther validate HuatuoGPT-II's advantages over existing LLMs. Notably,\nHuatuoGPT-II was benchmarked in a fresh Chinese National Medical Licensing\nExamination where it achieved the best performance, showcasing not only its\neffectiveness but also its generalization capabilities.",
            "author": [
                "Junying Chen",
                "Xidong Wang",
                "Anningzhe Gao",
                "Feng Jiang",
                "Shunian Chen",
                "Hongbo Zhang",
                "Dingjie Song",
                "Wenya Xie",
                "Chuyi Kong",
                "Jianquan Li",
                "Xiang Wan",
                "Haizhou Li",
                "Benyou Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09774v1",
                "http://arxiv.org/pdf/2311.09774v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09773v1",
            "title": "To be or not to be? an exploration of continuously controllable prompt\n  engineering",
            "updated": "2023-11-16T10:55:29Z",
            "published": "2023-11-16T10:55:29Z",
            "summary": "As the use of large language models becomes more widespread, techniques like\nparameter-efficient fine-tuning and other methods for controlled generation are\ngaining traction for customizing models and managing their outputs. However,\nthe challenge of precisely controlling how prompts influence these models is an\narea ripe for further investigation. In response, we introduce ControlPE\n(Continuously Controllable Prompt Engineering). ControlPE enables finer\nadjustments to prompt effects, complementing existing prompt engineering, and\neffectively controls continuous targets. This approach harnesses the power of\nLoRA (Low-Rank Adaptation) to create an effect akin to prompt weighting,\nenabling fine-tuned adjustments to the impact of prompts. Our methodology\ninvolves generating specialized datasets for prompt distillation, incorporating\nthese prompts into the LoRA model, and carefully adjusting LoRA merging weight\nto regulate the influence of prompts. This provides a dynamic and adaptable\ntool for prompt control. Through our experiments, we have validated the\npracticality and efficacy of ControlPE. It proves to be a promising solution\nfor control a variety of prompts, ranging from generating short responses\nprompts, refusal prompts to chain-of-thought prompts.",
            "author": [
                "Yuhan Sun",
                "Mukai Li",
                "Yixin Cao",
                "Kun Wang",
                "Wenxiao Wang",
                "Xingyu Zeng",
                "Rui Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09773v1",
                "http://arxiv.org/pdf/2311.09773v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09769v1",
            "title": "1953: Fermi's \"little discovery\" and the birth of the numerical\n  experiment",
            "updated": "2023-11-16T10:49:31Z",
            "published": "2023-11-16T10:49:31Z",
            "summary": "The year 1953 is pivotal for computational physics: the first application of\nthe Monte-Carlo method is published and calculations of the so-called\nFermi-Pasta-Ulam-Tsingou experiment are started. It is the beginning of the\nmassive use in the physical sciences of numerical methods implemented on\nelectronic computers and a decisive step in the development of modern nonlinear\ndynamics. This will lead to an unpredictable development during the following\n70 years. We briefly review the unfolding of these events and present some\nrecent results that show how the issues raised are still relevant today",
            "author": [
                "Stefano Lepri",
                "Roberto Livi",
                "Stefano Ruffo"
            ],
            "link": [
                "http://dx.doi.org/10.1393/gdf/i2023-10531-6",
                "http://arxiv.org/abs/2311.09769v1",
                "http://arxiv.org/pdf/2311.09769v1"
            ],
            "primary_category": "physics.hist-ph",
            "category": [
                "physics.hist-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10121v2",
            "title": "Slide-SAM: Medical SAM Meets Sliding Window",
            "updated": "2023-12-05T07:10:25Z",
            "published": "2023-11-16T10:45:46Z",
            "summary": "The Segment Anything Model (SAM) has achieved a notable success in\ntwo-dimensional image segmentation in natural images. However, the substantial\ngap between medical and natural images hinders its direct application to\nmedical image segmentation tasks. Particularly in 3D medical images, SAM\nstruggles to learn contextual relationships between slices, limiting its\npractical applicability. Moreover, applying 2D SAM to 3D images requires\nprompting the entire volume, which is time- and label-consuming. To address\nthese problems, we propose Slide-SAM, which treats a stack of three adjacent\nslices as a prediction window. It firstly takes three slices from a 3D volume\nand point- or bounding box prompts on the central slice as inputs to predict\nsegmentation masks for all three slices. Subsequently, the masks of the top and\nbottom slices are then used to generate new prompts for adjacent slices.\nFinally, step-wise prediction can be achieved by sliding the prediction window\nforward or backward through the entire volume. Our model is trained on multiple\npublic and private medical datasets and demonstrates its effectiveness through\nextensive 3D segmetnation experiments, with the help of minimal prompts. Code\nis available at \\url{https://github.com/Curli-quan/Slide-SAM}.",
            "author": [
                "Quan Quan",
                "Fenghe Tang",
                "Zikang Xu",
                "Heqin Zhu",
                "S. Kevin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10121v2",
                "http://arxiv.org/pdf/2311.10121v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09768v1",
            "title": "Utilizing dataset affinity prediction in object detection to assess\n  training data",
            "updated": "2023-11-16T10:45:32Z",
            "published": "2023-11-16T10:45:32Z",
            "summary": "Data pooling offers various advantages, such as increasing the sample size,\nimproving generalization, reducing sampling bias, and addressing data sparsity\nand quality, but it is not straightforward and may even be counterproductive.\nAssessing the effectiveness of pooling datasets in a principled manner is\nchallenging due to the difficulty in estimating the overall information content\nof individual datasets. Towards this end, we propose incorporating a data\nsource prediction module into standard object detection pipelines. The module\nruns with minimal overhead during inference time, providing additional\ninformation about the data source assigned to individual detections. We show\nthe benefits of the so-called dataset affinity score by automatically selecting\nsamples from a heterogeneous pool of vehicle datasets. The results show that\nobject detectors can be trained on a significantly sparser set of training\nsamples without losing detection accuracy.",
            "author": [
                "Stefan Becker",
                "Jens Bayer",
                "Ronny Hug",
                "Wolfgang H\u00fcbner",
                "Michael Arens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09768v1",
                "http://arxiv.org/pdf/2311.09768v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09767v1",
            "title": "New advancements, challenges and opportunities of nanophotonics for\n  neuromorphic computing: A state-of-the-art review",
            "updated": "2023-11-16T10:44:46Z",
            "published": "2023-11-16T10:44:46Z",
            "summary": "The expansion of optoelectronic devices on photonic integration platforms has\nled to significant growth in the field of photonic computing. Photonic\nintegrated circuits have facilitated the creation of ultrafast artificial\nneural networks, forming the basis for a novel category of information\nprocessing devices. Their application extends to diverse domains such as\nmedical diagnosis, language models, telecommunications, quantum computing, and\nthe metaverse, addressing the escalating demands of machine learning and\nartificial intelligence (AI). In contrast, conventional electronics faces\nchallenges in latency, crosstalk, and energy consumption. Neuromorphic\nphotonics emerges as a compelling solution, featuring sub-nanosecond latencies,\nminimal heat dissipation, and high parallelism, expanding the scope of AI and\nOptical Neural Networks. This review explores recent advances in integrated\nphotonic neuromorphic systems, focusing on materials and device engineering\nbreakthroughs needed to overcome existing challenges. Examining various\ntechnologies in AI accelerators, from traditional optics to PICs, we assess\nenergy efficiency through operations per joule and compute density in\noperations per squared millimeter per second. A comparative analysis highlights\ncrucial technical aspects, emphasizing nanophotonic components like VCSEL\nlasers, optical interconnects, nanocavity resonators, and frequency microcombs.\nThese components showcase recent breakthroughs in photonic engineering and\nmaterials science, enabling the creation of customized neuromorphic systems for\nAI tasks. Despite progress, current technologies face obstacles in achieving\nphotonic AI accelerators with computing speed and energy efficiencies reaching\nthe petaOPS range. The review explores potential future approaches in new\ndevices, fabrication, materials, scalability, and integration to enhance\ncritical performance metrics.",
            "author": [
                "Renjie Li",
                "Yuanhao Gong",
                "Hai Huang",
                "Yuze Zhou",
                "Sixuan Mao",
                "Connie Chang-Hasnain",
                "Zhaoyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09767v1",
                "http://arxiv.org/pdf/2311.09767v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09766v1",
            "title": "LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores",
            "updated": "2023-11-16T10:43:26Z",
            "published": "2023-11-16T10:43:26Z",
            "summary": "Automatic evaluation of generated textual content presents an ongoing\nchallenge within the field of NLP. Given the impressive capabilities of modern\nlanguage models (LMs) across diverse NLP tasks, there is a growing trend to\nemploy these models in creating innovative evaluation metrics for automated\nassessment of generation tasks. This paper investigates a pivotal question: Do\nlanguage model-driven evaluation metrics inherently exhibit bias favoring texts\ngenerated by the same underlying language model? Specifically, we assess\nwhether prominent LM-based evaluation metrics--namely, BARTScore, T5Score, and\nGPTScore--demonstrate a favorable bias toward their respective underlying LMs\nin the context of summarization tasks. Our findings unveil a latent bias,\nparticularly pronounced when such evaluation metrics are used in an\nreference-free manner without leveraging gold summaries. These results\nunderscore that assessments provided by generative evaluation models can be\ninfluenced by factors beyond the inherent text quality, highlighting the\nnecessity of developing more dependable evaluation protocols in the future.",
            "author": [
                "Yiqi Liu",
                "Nafise Sadat Moosavi",
                "Chenghua Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09766v1",
                "http://arxiv.org/pdf/2311.09766v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09763v1",
            "title": "Test-time Backdoor Mitigation for Black-Box Large Language Models with\n  Defensive Demonstrations",
            "updated": "2023-11-16T10:38:43Z",
            "published": "2023-11-16T10:38:43Z",
            "summary": "Existing studies in backdoor defense have predominantly focused on the\ntraining phase, overlooking the critical aspect of testing time defense. This\ngap becomes particularly pronounced in the context of Large Language Models\n(LLMs) deployed as Web Services, which typically offer only black-box access,\nrendering training-time defenses impractical. To bridge this gap, our work\nintroduces defensive demonstrations, an innovative backdoor defense strategy\nfor blackbox large language models. Our method involves identifying the task\nand retrieving task-relevant demonstrations from an uncontaminated pool. These\ndemonstrations are then combined with user queries and presented to the model\nduring testing, without requiring any modifications/tuning to the black-box\nmodel or insights into its internal mechanisms. Defensive demonstrations are\ndesigned to counteract the adverse effects of triggers, aiming to recalibrate\nand correct the behavior of poisoned models during test-time evaluations.\nExtensive experiments show that defensive demonstrations are effective in\ndefending both instance-level and instruction-level backdoor attacks, not only\nrectifying the behavior of poisoned models but also surpassing existing\nbaselines in most scenarios.",
            "author": [
                "Wenjie Mo",
                "Jiashu Xu",
                "Qin Liu",
                "Jiongxiao Wang",
                "Jun Yan",
                "Chaowei Xiao",
                "Muhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09763v1",
                "http://arxiv.org/pdf/2311.09763v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09762v1",
            "title": "Graph-Guided Reasoning for Multi-Hop Question Answering in Large\n  Language Models",
            "updated": "2023-11-16T10:36:08Z",
            "published": "2023-11-16T10:36:08Z",
            "summary": "Chain-of-Thought (CoT) prompting has boosted the multi-step reasoning\ncapabilities of Large Language Models (LLMs) by generating a series of\nrationales before the final answer. We analyze the reasoning paths generated by\nCoT and find two issues in multi-step reasoning: (i) Generating rationales\nirrelevant to the question, (ii) Unable to compose subquestions or queries for\ngenerating/retrieving all the relevant information. To address them, we propose\na graph-guided CoT prompting method, which guides the LLMs to reach the correct\nanswer with graph representation/verification steps. Specifically, we first\nleverage LLMs to construct a \"question/rationale graph\" by using knowledge\nextraction prompting given the initial question and the rationales generated in\nthe previous steps. Then, the graph verification step diagnoses the current\nrationale triplet by comparing it with the existing question/rationale graph to\nfilter out irrelevant rationales and generate follow-up questions to obtain\nrelevant information. Additionally, we generate CoT paths that exclude the\nextracted graph information to represent the context information missed from\nthe graph extraction. Our graph-guided reasoning method shows superior\nperformance compared to previous CoT prompting and the variants on multi-hop\nquestion answering benchmark datasets.",
            "author": [
                "Jinyoung Park",
                "Ameen Patel",
                "Omar Zia Khan",
                "Hyunwoo J. Kim",
                "Joo-Kyung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09762v1",
                "http://arxiv.org/pdf/2311.09762v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09761v1",
            "title": "MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and\n  Classification",
            "updated": "2023-11-16T10:35:11Z",
            "published": "2023-11-16T10:35:11Z",
            "summary": "Fallacies can be used to spread disinformation, fake news, and propaganda,\nunderlining the importance of their detection. Automated detection and\nclassification of fallacies, however, remain challenging, mainly because of the\ninnate subjectivity of the task and the need for a comprehensive, unified\napproach in existing research. Addressing these limitations, our study\nintroduces a novel taxonomy of fallacies that aligns and refines previous\nclassifications, a new annotation scheme tailored for subjective NLP tasks, and\na new evaluation method designed to handle subjectivity, adapted to precision,\nrecall, and F1-Score metrics. Using our annotation scheme, the paper introduces\nMAFALDA (Multi-level Annotated FALlacy DAtaset), a gold standard dataset.\nMAFALDA is based on examples from various previously existing fallacy datasets\nunder our unified taxonomy across three levels of granularity. We then evaluate\nseveral language models under a zero-shot learning setting using MAFALDA to\nassess their fallacy detection and classification capability. Our comprehensive\nevaluation not only benchmarks the performance of these models but also\nprovides valuable insights into their strengths and limitations in addressing\nfallacious reasoning.",
            "author": [
                "Chadi Helwe",
                "Tom Calamai",
                "Pierre-Henri Paris",
                "Chlo\u00e9 Clavel",
                "Fabian Suchanek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09761v1",
                "http://arxiv.org/pdf/2311.09761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09760v1",
            "title": "Eventually Lattice-Linear Algorithms",
            "updated": "2023-11-16T10:34:08Z",
            "published": "2023-11-16T10:34:08Z",
            "summary": "Lattice-linear systems allow nodes to execute asynchronously. We introduce\neventually lattice-linear algorithms, where lattices are induced only among the\nstates in a subset of the state space. The algorithm guarantees that the system\ntransitions to a state in one of the lattices. Then, the algorithm behaves\nlattice linearly while traversing to an optimal state through that lattice.\n  We present a lattice-linear self-stabilizing algorithm for service demand\nbased minimal dominating set (SDMDS) problem. Using this as an example, we\nelaborate the working of, and define, eventually lattice-linear algorithms.\nThen, we present eventually lattice-linear self-stabilizing algorithms for\nminimal vertex cover (\\mvc), maximal independent set (\\mis), graph colouring\n(\\gc) and 2-dominating set problems (\\tds).\n  Algorithms for SDMDS, \\mvc and \\mis converge in 1 round plus $n$ moves\n(within $2n$ moves), \\gc in $n+4m$ moves, and \\tds in 1 round plus $2n$ moves\n(within $3n$ moves). These results are an improvement over the existing\nliterature. We also present experimental results to show performance gain\ndemonstrating the benefit of lattice-linearity.",
            "author": [
                "Arya Tanmay Gupta",
                "Sandeep S Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09760v1",
                "http://arxiv.org/pdf/2311.09760v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09759v1",
            "title": "Scene Text Image Super-resolution based on Text-conditional Diffusion\n  Models",
            "updated": "2023-11-16T10:32:18Z",
            "published": "2023-11-16T10:32:18Z",
            "summary": "Scene Text Image Super-resolution (STISR) has recently achieved great success\nas a preprocessing method for scene text recognition. STISR aims to transform\nblurred and noisy low-resolution (LR) text images in real-world settings into\nclear high-resolution (HR) text images suitable for scene text recognition. In\nthis study, we leverage text-conditional diffusion models (DMs), known for\ntheir impressive text-to-image synthesis capabilities, for STISR tasks. Our\nexperimental results revealed that text-conditional DMs notably surpass\nexisting STISR methods. Especially when texts from LR text images are given as\ninput, the text-conditional DMs are able to produce superior quality\nsuper-resolution text images. Utilizing this capability, we propose a novel\nframework for synthesizing LR-HR paired text image datasets. This framework\nconsists of three specialized text-conditional DMs, each dedicated to text\nimage synthesis, super-resolution, and image degradation. These three modules\nare vital for synthesizing distinct LR and HR paired images, which are more\nsuitable for training STISR methods. Our experiments confirmed that these\nsynthesized image pairs significantly enhance the performance of STISR methods\nin the TextZoom evaluation.",
            "author": [
                "Chihiro Noguchi",
                "Shun Fukuda",
                "Masao Yamanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09759v1",
                "http://arxiv.org/pdf/2311.09759v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09758v1",
            "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue\n  State Tracking",
            "updated": "2023-11-16T10:30:55Z",
            "published": "2023-11-16T10:30:55Z",
            "summary": "Large language models (LLMs) have revolutionized the landscape of Natural\nLanguage Processing systems, but are computationally expensive. To reduce the\ncost without sacrificing performance, previous studies have explored various\napproaches to harness the potential of Small Language Models (SLMs) as\ncost-effective alternatives to their larger counterparts. Driven by findings\nthat SLMs and LLMs exhibit complementary strengths in a structured knowledge\nextraction task, this work presents a novel SLM/LLM routing framework designed\nto improve computational efficiency and enhance task performance. First,\nexemplar pools are created to represent the types of contexts where each LM\nprovides a more reliable answer, leveraging a sentence embedding fine-tuned so\nthat context similarity is close to dialogue state similarity. Then, during\ninference, the k-nearest exemplars to the testing instance are retrieved, and\nthe instance is routed according to majority vote. In dialogue state tracking\ntasks, the proposed routing framework enhances performance substantially\ncompared to relying solely on LLMs, while reducing the computational costs by\nover 50%.",
            "author": [
                "Chia-Hsuan Lee",
                "Hao Cheng",
                "Mari Ostendorf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09758v1",
                "http://arxiv.org/pdf/2311.09758v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09757v1",
            "title": "UFPS: A unified framework for partially-annotated federated segmentation\n  in heterogeneous data distribution",
            "updated": "2023-11-16T10:30:27Z",
            "published": "2023-11-16T10:30:27Z",
            "summary": "Partially supervised segmentation is a label-saving method based on datasets\nwith fractional classes labeled and intersectant. However, it is still far from\nlanding on real-world medical applications due to privacy concerns and data\nheterogeneity. As a remedy without privacy leakage, federated partially\nsupervised segmentation (FPSS) is formulated in this work. The main challenges\nfor FPSS are class heterogeneity and client drift. We propose a Unified\nFederated Partially-labeled Segmentation (UFPS) framework to segment pixels\nwithin all classes for partially-annotated datasets by training a totipotential\nglobal model without class collision. Our framework includes Unified Label\nLearning and sparsed Unified Sharpness Aware Minimization for unification of\nclass and feature space, respectively. We find that vanilla combinations for\ntraditional methods in partially supervised segmentation and federated learning\nare mainly hampered by class collision through empirical study. Our\ncomprehensive experiments on real medical datasets demonstrate better\ndeconflicting and generalization ability of UFPS compared with modified\nmethods.",
            "author": [
                "Le Jiang",
                "Li Yan Ma",
                "Tie Yong Zeng",
                "Shi Hui Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09757v1",
                "http://arxiv.org/pdf/2311.09757v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09756v1",
            "title": "FairytaleCQA: Integrating a Commonsense Knowledge Graph into Children's\n  Storybook Narratives",
            "updated": "2023-11-16T10:30:26Z",
            "published": "2023-11-16T10:30:26Z",
            "summary": "AI models (including LLM) often rely on narrative question-answering (QA)\ndatasets to provide customized QA functionalities to support downstream\nchildren education applications; however, existing datasets only include QA\npairs that are grounded within the given storybook content, but children can\nlearn more when teachers refer the storybook content to real-world knowledge\n(e.g., commonsense knowledge). We introduce the FairytaleCQA dataset, which is\nannotated by children education experts, to supplement 278 storybook narratives\nwith educationally appropriate commonsense knowledge. The dataset has 5,868 QA\npairs that not only originate from the storybook narrative but also contain the\ncommonsense knowledge grounded by an external knowledge graph (i.e.,\nConceptNet). A follow-up experiment shows that a smaller model (T5-large)\nfine-tuned with FairytaleCQA reliably outperforms much larger prompt-engineered\nLLM (e.g., GPT-4) in this new QA-pair generation task (QAG). This result\nsuggests that: 1) our dataset brings novel challenges to existing LLMs, and 2)\nhuman experts' data annotation are still critical as they have much nuanced\nknowledge that LLMs do not know in the children educational domain.",
            "author": [
                "Jiaju Chen",
                "Yuxuan Lu",
                "Shao Zhang",
                "Bingsheng Yao",
                "Yuanzhe Dong",
                "Ying Xu",
                "Yunyao Li",
                "Qianwen Wang",
                "Dakuo Wang",
                "Yuling Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09756v1",
                "http://arxiv.org/pdf/2311.09756v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09755v1",
            "title": "How Does Calibration Data Affect the Post-training Pruning and\n  Quantization of Large Language Models?",
            "updated": "2023-11-16T10:30:00Z",
            "published": "2023-11-16T10:30:00Z",
            "summary": "Pruning and quantization form the foundation of model compression for neural\nnetworks, enabling efficient inference for large language models (LLMs).\nRecently, various quantization and pruning techniques have demonstrated\nstate-of-the-art performance in a post-training setting. They rely upon\ncalibration data, a small set of unlabeled examples, to generate layer\nactivations. However, no prior work has systematically investigated how the\ncalibration data impacts the effectiveness of model compression methods. In\nthis paper, we present the first extensive empirical study on the effect of\ncalibration data upon LLM performance. We trial a variety of pruning and\nquantization methods, tasks, models, and datasets. Surprisingly, we find\nsubstantial variations in downstream task performance, contrasting existing\nwork that suggests a greater level of robustness to the calibration data.\nFinally, we make a series of recommendations for the effective use of\ncalibration data in LLM quantization and pruning.",
            "author": [
                "Miles Williams",
                "Nikolaos Aletras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09755v1",
                "http://arxiv.org/pdf/2311.09755v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09753v1",
            "title": "DIFFNAT: Improving Diffusion Image Quality Using Natural Image\n  Statistics",
            "updated": "2023-11-16T10:28:59Z",
            "published": "2023-11-16T10:28:59Z",
            "summary": "Diffusion models have advanced generative AI significantly in terms of\nediting and creating naturalistic images. However, efficiently improving\ngenerated image quality is still of paramount interest. In this context, we\npropose a generic \"naturalness\" preserving loss function, viz., kurtosis\nconcentration (KC) loss, which can be readily applied to any standard diffusion\nmodel pipeline to elevate the image quality. Our motivation stems from the\nprojected kurtosis concentration property of natural images, which states that\nnatural images have nearly constant kurtosis values across different band-pass\nversions of the image. To retain the \"naturalness\" of the generated images, we\nenforce reducing the gap between the highest and lowest kurtosis values across\nthe band-pass versions (e.g., Discrete Wavelet Transform (DWT)) of images. Note\nthat our approach does not require any additional guidance like classifier or\nclassifier-free guidance to improve the image quality. We validate the proposed\napproach for three diverse tasks, viz., (1) personalized few-shot finetuning\nusing text guidance, (2) unconditional image generation, and (3) image\nsuper-resolution. Integrating the proposed KC loss has improved the perceptual\nquality across all these tasks in terms of both FID, MUSIQ score, and user\nevaluation.",
            "author": [
                "Aniket Roy",
                "Maiterya Suin",
                "Anshul Shah",
                "Ketul Shah",
                "Jiang Liu",
                "Rama Chellappa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09753v1",
                "http://arxiv.org/pdf/2311.09753v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09748v1",
            "title": "Translation Aligned Sentence Embeddings for Turkish Language",
            "updated": "2023-11-16T10:25:22Z",
            "published": "2023-11-16T10:25:22Z",
            "summary": "Due to the limited availability of high quality datasets for training\nsentence embeddings in Turkish, we propose a training methodology and a regimen\nto develop a sentence embedding model. The central idea is simple but effective\n: is to fine-tune a pretrained encoder-decoder model in two consecutive stages,\nwhere the first stage involves aligning the embedding space with translation\npairs. Thanks to this alignment, the prowess of the main model can be better\nprojected onto the target language in a sentence embedding setting where it can\nbe fine-tuned with high accuracy in short duration with limited target language\ndataset.",
            "author": [
                "Eren Unlu",
                "Unver Ciftci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09748v1",
                "http://arxiv.org/pdf/2311.09748v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09745v1",
            "title": "Application-Centric Benchmarking of Distributed FaaS Platforms using\n  BeFaaS",
            "updated": "2023-11-16T10:19:07Z",
            "published": "2023-11-16T10:19:07Z",
            "summary": "Due to the popularity of the FaaS programming model, there is now a wide\nvariety of commercial and open-source FaaS systems. Hence, for comparison of\ndifferent FaaS systems and their configuration options, FaaS application\ndevelopers rely on FaaS benchmarking frameworks. Existing frameworks, however,\ntend to evaluate only single isolated aspects, a more holistic\napplication-centric benchmarking framework is still missing. In previous work,\nwe proposed BeFaaS, an extensible application-centric benchmarking framework\nfor FaaS environments that focuses on the evaluation of FaaS platforms through\nrealistic and typical examples of FaaS applications. In this extended paper, we\n(i) enhance our benchmarking framework with additional features for distributed\nFaaS setups, (ii) design application benchmarks reflecting typical FaaS use\ncases, and (iii) use them to run extensive experiments with commercial cloud\nFaaS platforms (AWS Lambda, Azure Functions, Google Cloud Functions) and the\ntinyFaaS edge serverless platform. BeFaaS now includes four FaaS\napplication-centric benchmarks, is extensible for additional workload profiles\nand platforms, and supports federated benchmark runs in which the benchmark\napplication is distributed over multiple FaaS systems while collecting\nfine-grained measurement results for drill-down analysis. Our experiment\nresults show that (i) network transmission is a major contributor to response\nlatency for function chains, (ii) this effect is exacerbated in hybrid\nedge-cloud deployments, (iii) the trigger delay between a published event and\nthe start of the triggered function ranges from about 100ms for AWS Lambda to\n800ms for Google Cloud Functions, and (iv) Azure Functions shows the best cold\nstart behavior for our workloads.",
            "author": [
                "Martin Grambow",
                "Tobias Pfandzelter",
                "David Bermbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09745v1",
                "http://arxiv.org/pdf/2311.09745v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09744v1",
            "title": "Redefining the Laparoscopic Spatial Sense: AI-based Intra- and\n  Postoperative Measurement from Stereoimages",
            "updated": "2023-11-16T10:19:04Z",
            "published": "2023-11-16T10:19:04Z",
            "summary": "A significant challenge in image-guided surgery is the accurate measurement\ntask of relevant structures such as vessel segments, resection margins, or\nbowel lengths. While this task is an essential component of many surgeries, it\ninvolves substantial human effort and is prone to inaccuracies. In this paper,\nwe develop a novel human-AI-based method for laparoscopic measurements\nutilizing stereo vision that has been guided by practicing surgeons. Based on a\nholistic qualitative requirements analysis, this work proposes a comprehensive\nmeasurement method, which comprises state-of-the-art machine learning\narchitectures, such as RAFT-Stereo and YOLOv8. The developed method is assessed\nin various realistic experimental evaluation environments. Our results outline\nthe potential of our method achieving high accuracies in distance measurements\nwith errors below 1 mm. Furthermore, on-surface measurements demonstrate\nrobustness when applied in challenging environments with textureless regions.\nOverall, by addressing the inherent challenges of image-guided surgery, we lay\nthe foundation for a more robust and accurate solution for intra- and\npostoperative measurements, enabling more precise, safe, and efficient surgical\nprocedures.",
            "author": [
                "Leopold M\u00fcller",
                "Patrick Hemmer",
                "Moritz Queisner",
                "Igor Sauer",
                "Simeon Allmendinger",
                "Johannes Jakubik",
                "Michael V\u00f6ssing",
                "Niklas K\u00fchl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09744v1",
                "http://arxiv.org/pdf/2311.09744v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09743v1",
            "title": "Capturing Perspectives of Crowdsourced Annotators in Subjective Learning\n  Tasks",
            "updated": "2023-11-16T10:18:32Z",
            "published": "2023-11-16T10:18:32Z",
            "summary": "In most classification models, it has been assumed to have a single ground\ntruth label for each data point. However, subjective tasks like toxicity\nclassification can lead to genuine disagreement among annotators. In these\ncases aggregating labels will result in biased labeling and, consequently,\nbiased models that can overlook minority opinions. Previous studies have shed\nlight on the pitfalls of label aggregation and have introduced a handful of\npractical approaches to tackle this issue. Recently proposed multi-annotator\nmodels, which predict labels individually per annotator, are vulnerable to\nunder-determination for annotators with small samples. This problem is\nespecially the case in crowd-sourced datasets. In this work, we propose\nAnnotator Aware Representations for Texts (AART) for subjective classification\ntasks. We will show the improvement of our method on metrics that assess the\nperformance on capturing annotators' perspectives. Additionally, our approach\ninvolves learning representations for annotators, allowing for an exploration\nof the captured annotation behaviors.",
            "author": [
                "Negar Mokhberian",
                "Myrl G. Marmarelis",
                "Frederic R. Hopp",
                "Valerio Basile",
                "Fred Morstatter",
                "Kristina Lerman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09743v1",
                "http://arxiv.org/pdf/2311.09743v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09741v1",
            "title": "What Constitutes a Faithful Summary? Preserving Author Perspectives in\n  News Summarization",
            "updated": "2023-11-16T10:14:28Z",
            "published": "2023-11-16T10:14:28Z",
            "summary": "In this work, we take a first step towards designing summarization systems\nthat are faithful to the author's opinions and perspectives. Focusing on a case\nstudy of preserving political perspectives in news summarization, we find that\nexisting approaches alter the political opinions and stances of news articles\nin more than 50% of summaries, misrepresenting the intent and perspectives of\nthe news authors. We thus propose P^3Sum, a diffusion model-based summarization\napproach controlled by political perspective classifiers. In P^3Sum, the\npolitical leaning of a generated summary is iteratively evaluated at each\ndecoding step, and any drift from the article's original stance incurs a loss\nback-propagated to the embedding layers, steering the political stance of the\nsummary at inference time. Extensive experiments on three news summarization\ndatasets demonstrate that P^3Sum outperforms state-of-the-art summarization\nsystems and large language models by up to 11.4% in terms of the success rate\nof stance preservation, with on-par performance on standard summarization\nutility metrics. These findings highlight the lacunae that even for\nstate-of-the-art models it is still challenging to preserve author perspectives\nin news summarization, while P^3Sum presents an important first step towards\nevaluating and developing summarization systems that are faithful to author\nintent and perspectives.",
            "author": [
                "Yuhan Liu",
                "Shangbin Feng",
                "Xiaochuang Han",
                "Vidhisha Balachandran",
                "Chan Young Park",
                "Sachin Kumar",
                "Yulia Tsvetkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09741v1",
                "http://arxiv.org/pdf/2311.09741v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09740v3",
            "title": "Redefining Super-Resolution: Fine-mesh PDE predictions without classical\n  simulations",
            "updated": "2023-11-27T03:09:21Z",
            "published": "2023-11-16T10:13:09Z",
            "summary": "In Computational Fluid Dynamics (CFD), coarse mesh simulations offer\ncomputational efficiency but often lack precision. Applying conventional\nsuper-resolution to these simulations poses a significant challenge due to the\nfundamental contrast between downsampling high-resolution images and\nauthentically emulating low-resolution physics. The former method conserves\nmore of the underlying physics, surpassing the usual constraints of real-world\nscenarios. We propose a novel definition of super-resolution tailored for\nPDE-based problems. Instead of simply downsampling from a high-resolution\ndataset, we use coarse-grid simulated data as our input and predict fine-grid\nsimulated outcomes. Employing a physics-infused UNet upscaling method, we\ndemonstrate its efficacy across various 2D-CFD problems such as discontinuity\ndetection in Burger's equation, Methane combustion, and fouling in Industrial\nheat exchangers. Our method enables the generation of fine-mesh solutions\nbypassing traditional simulation, ensuring considerable computational saving\nand fidelity to the original ground truth outcomes. Through diverse boundary\nconditions during training, we further establish the robustness of our method,\npaving the way for its broad applications in engineering and scientific CFD\nsolvers.",
            "author": [
                "Rajat Kumar Sarkar",
                "Ritam Majumdar",
                "Vishal Jadhav",
                "Sagar Srinivas Sakhinana",
                "Venkataramana Runkana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09740v3",
                "http://arxiv.org/pdf/2311.09740v3"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.AI",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09739v1",
            "title": "Machine Learning for Polaritonic Chemistry: Accessing chemical kinetics",
            "updated": "2023-11-16T10:08:44Z",
            "published": "2023-11-16T10:08:44Z",
            "summary": "Altering chemical reactivity and material structure in confined optical\nenvironments is on the rise, and yet, a conclusive understanding of the\nmicroscopic mechanisms remains elusive. This originates mostly from the fact\nthat accurately predicting vibrational and reactive dynamics for soluted\nensembles of realistic molecules is no small endeavor, and adding (collective)\nstrong light-matter interaction does not simplify matters. Here, we establish a\nframework based on a combination of machine learning (ML) models, trained using\ndensity-functional theory calculations, and molecular dynamics to accelerate\nsuch simulations. We then apply this approach to evaluate strong coupling,\nchanges in reaction rate constant, and their influence on enthalpy and entropy\nfor the deprotection reaction of 1-phenyl-2-trimethylsilylacetylene, which has\nbeen studied previously both experimentally and using ab initio simulations.\nWhile we find qualitative agreement with critical experimental observations,\nespecially with regard to the changes in kinetics, we also find differences in\ncomparison with previous theoretical predictions. The features for which the\nML-accelerated and ab initio simulations agree show the experimentally\nestimated kinetic behavior. Conflicting features indicate that a contribution\nof electronic polarization to the reaction process is more relevant then\ncurrently believed. Our work demonstrates the practical use of ML for\npolaritonic chemistry, discusses limitations of common approximations and paves\nthe way for a more holistic description of polaritonic chemistry.",
            "author": [
                "Christian Sch\u00e4fer",
                "Jakub Fojt",
                "Eric Lindgren",
                "Paul Erhart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09739v1",
                "http://arxiv.org/pdf/2311.09739v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.comp-ph",
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09737v1",
            "title": "Gradient-Map-Guided Adaptive Domain Generalization for Cross Modality\n  MRI Segmentation",
            "updated": "2023-11-16T10:07:27Z",
            "published": "2023-11-16T10:07:27Z",
            "summary": "Cross-modal MRI segmentation is of great value for computer-aided medical\ndiagnosis, enabling flexible data acquisition and model generalization.\nHowever, most existing methods have difficulty in handling local variations in\ndomain shift and typically require a significant amount of data for training,\nwhich hinders their usage in practice. To address these problems, we propose a\nnovel adaptive domain generalization framework, which integrates a\nlearning-free cross-domain representation based on image gradient maps and a\nclass prior-informed test-time adaptation strategy for mitigating local domain\nshift. We validate our approach on two multi-modal MRI datasets with six\ncross-modal segmentation tasks. Across all the task settings, our method\nconsistently outperforms competing approaches and shows a stable performance\neven with limited training data.",
            "author": [
                "Bingnan Li",
                "Zhitong Gao",
                "Xuming He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09737v1",
                "http://arxiv.org/pdf/2311.09737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09736v1",
            "title": "CARE: Extracting Experimental Findings From Clinical Literature",
            "updated": "2023-11-16T10:06:19Z",
            "published": "2023-11-16T10:06:19Z",
            "summary": "Extracting fine-grained experimental findings from literature can provide\nmassive utility for scientific applications. Prior work has focused on\ndeveloping annotation schemas and datasets for limited aspects of this problem,\nleading to simpler information extraction datasets which do not capture the\nreal-world complexity and nuance required for this task. Focusing on\nbiomedicine, this work presents CARE (Clinical Aggregation-oriented Result\nExtraction) -- a new IE dataset for the task of extracting clinical findings.\nWe develop a new annotation schema capturing fine-grained findings as n-ary\nrelations between entities and attributes, which includes phenomena challenging\nfor current IE systems such as discontinuous entity spans, nested relations,\nand variable arity n-ary relations. Using this schema, we collect extensive\nannotations for 700 abstracts from two sources: clinical trials and case\nreports. We also benchmark the performance of various state-of-the-art IE\nsystems on our dataset, including extractive models and generative LLMs in\nfully supervised and limited data settings. Our results demonstrate the\ndifficulty of our dataset -- even SOTA models such as GPT4 struggle,\nparticularly on relation extraction. We release our annotation schema and CARE\nto encourage further research on extracting and aggregating scientific findings\nfrom literature.",
            "author": [
                "Aakanksha Naik",
                "Bailey Kuehl",
                "Erin Bransom",
                "Doug Downey",
                "Tom Hope"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09736v1",
                "http://arxiv.org/pdf/2311.09736v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09734v1",
            "title": "Tracking the Newsworthiness of Public Documents",
            "updated": "2023-11-16T10:05:26Z",
            "published": "2023-11-16T10:05:26Z",
            "summary": "Journalists must find stories in huge amounts of textual data (e.g. leaks,\nbills, press releases) as part of their jobs: determining when and why text\nbecomes news can help us understand coverage patterns and help us build\nassistive tools. Yet, this is challenging because very few labelled links\nexist, language use between corpora is very different, and text may be covered\nfor a variety of reasons. In this work we focus on news coverage of local\npublic policy in the San Francisco Bay Area by the San Francisco Chronicle.\nFirst, we gather news articles, public policy documents and meeting recordings\nand link them using probabilistic relational modeling, which we show is a\nlow-annotation linking methodology that outperforms other retrieval-based\nbaselines. Second, we define a new task: newsworthiness prediction, to predict\nif a policy item will get covered. We show that different aspects of public\npolicy discussion yield different newsworthiness signals. Finally we perform\nhuman evaluation with expert journalists and show our systems identify policies\nthey consider newsworthy with 68% F1 and our coverage recommendations are\nhelpful with an 84% win-rate.",
            "author": [
                "Alexander Spangher",
                "Emilio Ferrara",
                "Ben Welsh",
                "Nanyun Peng",
                "Serdar Tumgoren",
                "Jonathan May"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09734v1",
                "http://arxiv.org/pdf/2311.09734v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09733v1",
            "title": "MOKA: Moral Knowledge Augmentation for Moral Event Extraction",
            "updated": "2023-11-16T10:04:49Z",
            "published": "2023-11-16T10:04:49Z",
            "summary": "News media employ moral language to create memorable stories, and readers\noften engage with the content that align with their values. Moral theories have\nbeen applied to news analysis studying moral values in isolation, while the\nintricate dynamics among participating entities in shaping moral events have\nbeen overlooked. This is mainly due to the use of obscure language to conceal\nevident ideology and values, coupled with the insufficient moral reasoning\ncapability in most existing NLP systems, where LLMs are no exception. To study\nthis phenomenon, we first annotate a new dataset, MORAL EVENTS, consisting of\n5,494 structured annotations on 474 news articles by diverse US media across\nthe political spectrum. We further propose MOKA, a moral event extraction\nframework with MOral Knowledge Augmentation, that leverages knowledge derived\nfrom moral words and moral scenarios. Experimental results show that MOKA\noutperforms competitive baselines across three moral event understanding tasks.\nFurther analyses illuminate the selective reporting of moral events by media\noutlets of different ideological leanings, suggesting the significance of\nevent-level morality analysis in news. Our datasets and codebase are available\nat https://github.com/launchnlp/MOKA.",
            "author": [
                "Xinliang Frederick Zhang",
                "Winston Wu",
                "Nick Beauchamp",
                "Lu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09733v1",
                "http://arxiv.org/pdf/2311.09733v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09732v1",
            "title": "Source Prompt: Coordinated Pre-training of Language Models on Diverse\n  Corpora from Multiple Sources",
            "updated": "2023-11-16T10:03:26Z",
            "published": "2023-11-16T10:03:26Z",
            "summary": "Pre-trained language models (PLMs) have established the new paradigm in the\nfield of NLP. For more powerful PLMs, one of the most popular and successful\nway is to continuously scale up sizes of the models and the pre-training\ncorpora. These large corpora are generally obtained by converging smaller ones\nfrom multiple sources, they are thus growing increasingly diverse. However, the\nside-effects of these colossal converged corpora remain understudied. In this\npaper, we identify the disadvantage of heterogeneous corpora from multiple\nsources for pre-training PLMs. Towards coordinated pre-training on diverse\ncorpora, we further propose source prompts (SP), which explicitly prompt the\nmodel of the data source at the pre-training and fine-tuning stages. Results of\nextensive experiments demonstrate that PLMs pre-trained with SP on diverse\ncorpora gain significant improvement in various downstream tasks.",
            "author": [
                "Yipei Xu",
                "Dakuan Lu",
                "Jiaqing Liang",
                "Xintao Wang",
                "Yipeng Geng",
                "Yingsi Xin",
                "Hengkui Wu",
                "Ken Chen",
                "ruiji zhang",
                "Yanghua Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09732v1",
                "http://arxiv.org/pdf/2311.09732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09731v1",
            "title": "Prudent Silence or Foolish Babble? Examining Large Language Models'\n  Responses to the Unknown",
            "updated": "2023-11-16T10:02:40Z",
            "published": "2023-11-16T10:02:40Z",
            "summary": "Large Language Models (LLMs) often struggle when faced with situations where\nthey lack the prerequisite knowledge to generate a sensical response. In these\ncases, models tend to fabricate and hallucinate, rather than appropriately\nsignaling uncertainty as humans would. This behavior misaligns with human\nconversational norms and presents challenges surrounding responsible and\nethical AI development. This work aims to systematically investigate LLMs'\nbehaviors in such situations. We curate an adversarial question-answering\nbenchmark containing unanswerable questions targeting information absent from\nthe LLM's training data. Concretely, these unanswerable questions contain\nnon-existent concepts or false premises. When presented with such unanswerable\nquestions, an LLM should appropriately convey uncertainty, and be able to\nchallenge the premise and refuse to generate a response. While facing\nanswerable valid questions, a model should demonstrate a positive correlation\nbetween accuracy and confidence. Using a model-agnostic unified confidence\nelicitation approach, we observe that LLMs that have gone through instruction\nfinetuning and reinforcement learning from human feedback (RLHF) perform\nsignificantly better than their counterparts that do not. Moreover, uncertainty\nexpression 1 through our elicitation method does not always stay consistent\nwith the perceived confidence of the direct response of an LLM. Our findings\ncall for further research into teaching LLMs to proactively and reliably\nexpress uncertainty.",
            "author": [
                "Genglin Liu",
                "Xingyao Wang",
                "Lifan Yuan",
                "Yangyi Chen",
                "Hao Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09731v1",
                "http://arxiv.org/pdf/2311.09731v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09730v1",
            "title": "Aligning with Whom? Large Language Models Have Gender and Racial Biases\n  in Subjective NLP Tasks",
            "updated": "2023-11-16T10:02:24Z",
            "published": "2023-11-16T10:02:24Z",
            "summary": "Human perception of language depends on personal backgrounds like gender and\nethnicity. While existing studies have shown that large language models (LLMs)\nhold values that are closer to certain societal groups, it is unclear whether\ntheir prediction behaviors on subjective NLP tasks also exhibit a similar bias.\nIn this study, leveraging the POPQUORN dataset which contains annotations of\ndiverse demographic backgrounds, we conduct a series of experiments on four\npopular LLMs to investigate their capability to understand group differences\nand potential biases in their predictions for politeness and offensiveness. We\nfind that for both tasks, model predictions are closer to the labels from White\nand female participants. We further explore prompting with the target\ndemographic labels and show that including the target demographic in the prompt\nactually worsens the model's performance. More specifically, when being\nprompted to respond from the perspective of \"Black\" and \"Asian\" individuals,\nmodels show lower performance in predicting both overall scores as well as the\nscores from corresponding groups. Our results suggest that LLMs hold gender and\nracial biases for subjective NLP tasks and that demographic-infused prompts\nalone may be insufficient to mitigate such effects. Code and data are available\nat https://github.com/Jiaxin-Pei/LLM-Group-Bias.",
            "author": [
                "Huaman Sun",
                "Jiaxin Pei",
                "Minje Choi",
                "David Jurgens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09730v1",
                "http://arxiv.org/pdf/2311.09730v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09726v1",
            "title": "MS-Former: Memory-Supported Transformer for Weakly Supervised Change\n  Detection with Patch-Level Annotations",
            "updated": "2023-11-16T09:57:29Z",
            "published": "2023-11-16T09:57:29Z",
            "summary": "Fully supervised change detection methods have achieved significant\nadvancements in performance, yet they depend severely on acquiring costly\npixel-level labels. Considering that the patch-level annotations also contain\nabundant information corresponding to both changed and unchanged objects in\nbi-temporal images, an intuitive solution is to segment the changes with\npatch-level annotations. How to capture the semantic variations associated with\nthe changed and unchanged regions from the patch-level annotations to obtain\npromising change results is the critical challenge for the weakly supervised\nchange detection task. In this paper, we propose a memory-supported transformer\n(MS-Former), a novel framework consisting of a bi-directional attention block\n(BAB) and a patch-level supervision scheme (PSS) tailored for weakly supervised\nchange detection with patch-level annotations. More specifically, the BAM\ncaptures contexts associated with the changed and unchanged regions from the\ntemporal difference features to construct informative prototypes stored in the\nmemory bank. On the other hand, the BAM extracts useful information from the\nprototypes as supplementary contexts to enhance the temporal difference\nfeatures, thereby better distinguishing changed and unchanged regions. After\nthat, the PSS guides the network learning valuable knowledge from the\npatch-level annotations, thus further elevating the performance. Experimental\nresults on three benchmark datasets demonstrate the effectiveness of our\nproposed method in the change detection task. The demo code for our work will\nbe publicly available at \\url{https://github.com/guanyuezhen/MS-Former}.",
            "author": [
                "Zhenglai Li",
                "Chang Tang",
                "Xinwang Liu",
                "Changdong Li",
                "Xianju Li",
                "Wei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09726v1",
                "http://arxiv.org/pdf/2311.09726v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09724v1",
            "title": "Outcome-supervised Verifiers for Planning in Mathematical Reasoning",
            "updated": "2023-11-16T09:56:28Z",
            "published": "2023-11-16T09:56:28Z",
            "summary": "Large language models (LLMs) often struggle with maintaining accuracy across\na sequence of intermediate reasoning steps in mathematical reasoning, leading\nto error propagation that undermines the final result. The current methodology\nto mitigate this issue primarily involves using a verifier model to assess the\ncorrectness of generated solution candidates, focusing either on the overall\nreasoning path or on an incomplete reasoning path. By rethinking this approach,\nwe argue that assessing potentials of incomplete reasoning paths could be more\nadvantageous as it guides towards correct final answers, transforming the task\ninto a \\textit{planning} problem. Our proposed verifier, the\nOutcome-supervision Value Model (OVM), employs outcome supervision for\ntraining, offering an efficient and intuitive method for \\textit{planning} by\nprioritizing steps that lead to accurate conclusions over mere per-step\ncorrectness. Furthermore, the OVM eschews the need for labor-intensive\nannotations on step-level correctness, enhancing its scalability. Our\nexperiments on two multi-step mathematical reasoning datasets, GSM8K and Game\nof 24, demonstrate the superior performance of the OVM model. Notably, in\nGSM8K, our \\textbf{OVM-7B model achieves state-of-the-art results among LLMs up\nto 13B parameters}; especially it does not utilize GPT-4 or code execution.\nThese findings offer a novel perspective on the role of outcome supervision in\ntraining verifiers for multi-step reasoning tasks and provide theoretical\njustification for its advantage in value estimation for planning.",
            "author": [
                "Fei Yu",
                "Anningzhe Gao",
                "Benyou Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09724v1",
                "http://arxiv.org/pdf/2311.09724v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09722v1",
            "title": "Comprehensive Quantum Calculation of the First Dielectric Virial\n  Coefficient of Water",
            "updated": "2023-11-16T09:55:30Z",
            "published": "2023-11-16T09:55:30Z",
            "summary": "We present a complete calculation, fully accounting for quantum effects and\nfor molecular flexibility, of the first dielectric virial coefficient of water\nand its isotopologues. The contribution of the electronic polarizability is\ncomputed from a state-of-the-art intramolecular potential and polarizability\nsurface from the literature, and its small temperature dependence is\nquantified. The dipolar polarizability is calculated in a similar manner with\nan accurate literature dipole-moment surface; it differs from the classical\nresult both due to the different molecular geometries sampled at different\ntemperatures and due to the quantization of rotation. We calculate the dipolar\ncontribution independently from spectroscopic information in the HITRAN2020\ndatabase and find that the two methods yield consistent results. The resulting\nfirst dielectric virial coefficient provides a complete description of the\ndielectric constant at low density that can be used in humidity metrology and\nas a boundary condition for new formulations for the static dielectric constant\nof water and heavy water.",
            "author": [
                "Giovanni Garberoglio",
                "Chiara Lissoni",
                "Luca Spagnoli",
                "Allan H. Harvey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09722v1",
                "http://arxiv.org/pdf/2311.09722v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09721v1",
            "title": "On Evaluating the Integration of Reasoning and Action in LLM Agents with\n  Database Question Answering",
            "updated": "2023-11-16T09:55:07Z",
            "published": "2023-11-16T09:55:07Z",
            "summary": "This study introduces a new long-form database question answering dataset\ndesigned to evaluate how Large Language Models (LLMs) interact with a SQL\ninterpreter. The task necessitates LLMs to strategically generate multiple SQL\nqueries to retrieve sufficient data from a database, to reason with the\nacquired context, and to synthesize them into a comprehensive analytical\nnarrative. Our findings highlight that this task poses great challenges even\nfor the state-of-the-art GPT-4 model. We propose and evaluate two interaction\nstrategies, and provide a fine-grained analysis of the individual stages within\nthe interaction. A key discovery is the identification of two primary\nbottlenecks hindering effective interaction: the capacity for planning and the\nability to generate multiple SQL queries. To address the challenge of\naccurately assessing answer quality, we introduce a multi-agent evaluation\nframework that simulates the academic peer-review process, enhancing the\nprecision and reliability of our evaluations. This framework allows for a more\nnuanced understanding of the strengths and limitations of current LLMs in\ncomplex retrieval and reasoning tasks.",
            "author": [
                "Linyong Nan",
                "Ellen Zhang",
                "Weijin Zou",
                "Yilun Zhao",
                "Wenfei Zhou",
                "Arman Cohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09721v1",
                "http://arxiv.org/pdf/2311.09721v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09718v1",
            "title": "You don't need a personality test to know these models are unreliable:\n  Assessing the Reliability of Large Language Models on Psychometric\n  Instruments",
            "updated": "2023-11-16T09:50:53Z",
            "published": "2023-11-16T09:50:53Z",
            "summary": "The versatility of Large Language Models (LLMs) on natural language\nunderstanding tasks has made them popular for research in social sciences. In\nparticular, to properly understand the properties and innate personas of LLMs,\nresearchers have performed studies that involve using prompts in the form of\nquestions that ask LLMs of particular opinions. In this study, we take a\ncautionary step back and examine whether the current format of prompting\nenables LLMs to provide responses in a consistent and robust manner. We first\nconstruct a dataset that contains 693 questions encompassing 39 different\ninstruments of persona measurement on 115 persona axes. Additionally, we design\na set of prompts containing minor variations and examine LLM's capabilities to\ngenerate accurate answers, as well as consistency variations to examine their\nconsistency towards simple perturbations such as switching the option order.\nOur experiments on 15 different open-source LLMs reveal that even simple\nperturbations are sufficient to significantly downgrade a model's\nquestion-answering ability, and that most LLMs have low negation consistency.\nOur results suggest that the currently widespread practice of prompting is\ninsufficient to accurately capture model perceptions, and we discuss potential\nalternatives to improve such issues.",
            "author": [
                "Bangzhao Shu",
                "Lechen Zhang",
                "Minje Choi",
                "Lavinia Dunagan",
                "Dallas Card",
                "David Jurgens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09718v1",
                "http://arxiv.org/pdf/2311.09718v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09712v1",
            "title": "Regularized Conventions: Equilibrium Computation as a Model of Pragmatic\n  Reasoning",
            "updated": "2023-11-16T09:42:36Z",
            "published": "2023-11-16T09:42:36Z",
            "summary": "We present a model of pragmatic language understanding, where utterances are\nproduced and understood by searching for regularized equilibria of signaling\ngames. In this model (which we call ReCo, for Regularized Conventions),\nspeakers and listeners search for contextually appropriate utterance--meaning\nmappings that are both close to game-theoretically optimal conventions and\nclose to a shared, ''default'' semantics. By characterizing pragmatic\ncommunication as equilibrium search, we obtain principled sampling algorithms\nand formal guarantees about the trade-off between communicative success and\nnaturalness. Across several datasets capturing real and idealized human\njudgments about pragmatic implicatures, ReCo matches or improves upon\npredictions made by best response and rational speech act models of language\nunderstanding.",
            "author": [
                "Athul Paul Jacob",
                "Gabriele Farina",
                "Jacob Andreas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09712v1",
                "http://arxiv.org/pdf/2311.09712v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09709v1",
            "title": "Large Language Model Inference with Lexical Shortlisting",
            "updated": "2023-11-16T09:35:50Z",
            "published": "2023-11-16T09:35:50Z",
            "summary": "Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.",
            "author": [
                "Nikolay Bogoychev",
                "Pinzhen Chen",
                "Barry Haddow",
                "Alexandra Birch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09709v1",
                "http://arxiv.org/pdf/2311.09709v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09708v1",
            "title": "A Self-enhancement Multitask Framework for Unsupervised Aspect Category\n  Detection",
            "updated": "2023-11-16T09:35:24Z",
            "published": "2023-11-16T09:35:24Z",
            "summary": "Our work addresses the problem of unsupervised Aspect Category Detection\nusing a small set of seed words. Recent works have focused on learning\nembedding spaces for seed words and sentences to establish similarities between\nsentences and aspects. However, aspect representations are limited by the\nquality of initial seed words, and model performances are compromised by noise.\nTo mitigate this limitation, we propose a simple framework that automatically\nenhances the quality of initial seed words and selects high-quality sentences\nfor training instead of using the entire dataset. Our main concepts are to add\na number of seed words to the initial set and to treat the task of noise\nresolution as a task of augmenting data for a low-resource task. In addition,\nwe jointly train Aspect Category Detection with Aspect Term Extraction and\nAspect Term Polarity to further enhance performance. This approach facilitates\nshared representation learning, allowing Aspect Category Detection to benefit\nfrom the additional guidance offered by other tasks. Extensive experiments\ndemonstrate that our framework surpasses strong baselines on standard datasets.",
            "author": [
                "Thi-Nhung Nguyen",
                "Hoang Ngo",
                "Kiem-Hieu Nguyen",
                "Tuan-Dung Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09708v1",
                "http://arxiv.org/pdf/2311.09708v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09707v1",
            "title": "GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization\n  in Programming Language Understanding",
            "updated": "2023-11-16T09:35:00Z",
            "published": "2023-11-16T09:35:00Z",
            "summary": "Language models can serve as a valuable tool for software developers to\nincrease productivity. Large generative models can be used for code generation\nand code completion, while smaller encoder-only models are capable of\nperforming code search tasks using natural language queries.These capabilities\nare heavily influenced by the quality and diversity of the available training\ndata. Source code datasets used for training usually focus on the most popular\nlanguages and testing is mostly conducted on the same distributions, often\noverlooking low-resource programming languages. Motivated by the NLP\ngeneralization taxonomy proposed by Hupkes et.\\,al., we propose a new benchmark\ndataset called GenCodeSearchNet (GeCS) which builds upon existing natural\nlanguage code search datasets to systemically evaluate the programming language\nunderstanding generalization capabilities of language models. As part of the\nfull dataset, we introduce a new, manually curated subset StatCodeSearch that\nfocuses on R, a popular but so far underrepresented programming language that\nis often used by researchers outside the field of computer science. For\nevaluation and comparison, we collect several baseline results using fine-tuned\nBERT-style models and GPT-style large language models in a zero-shot setting.",
            "author": [
                "Andor Diera",
                "Abdelhalim Dahou",
                "Lukas Galke",
                "Fabian Karl",
                "Florian Sihler",
                "Ansgar Scherp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09707v1",
                "http://arxiv.org/pdf/2311.09707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09705v1",
            "title": "edibble: An R package to encapsulate elements of experimental designs\n  for better planning, management and workflow",
            "updated": "2023-11-16T09:32:51Z",
            "published": "2023-11-16T09:32:51Z",
            "summary": "I present an R package called edibble that facilitates the design of\nexperiments by encapsulating elements of the experiment in a series of\ncomposable functions. This package is an interpretation of \"the grammar of\nexperimental designs\" by Tanaka (2023) in the R programming language. The main\nfeatures of the edibble package are demonstrated, illustrating how it can be\nused to create a wide array of experimental designs. The implemented system\naims to encourage cognitive thinking for holistic planning and data management\nof experiments in a streamlined workflow. This workflow can increase the\ninherent value of experimental data by reducing potential errors or noise with\ncareful preplanning, as well as, ensuring fit-for-purpose analysis of\nexperimental data.",
            "author": [
                "Emi Tanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09705v1",
                "http://arxiv.org/pdf/2311.09705v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.OT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09702v1",
            "title": "Deceiving Semantic Shortcuts on Reasoning Chains: How Far Can Models Go\n  without Hallucination?",
            "updated": "2023-11-16T09:27:36Z",
            "published": "2023-11-16T09:27:36Z",
            "summary": "Despite the recent advancement in large language models (LLMs) and their high\nperformances across numerous benchmarks, recent research has unveiled that LLMs\nsuffer from hallucinations and unfaithful reasoning. This work studies a\nspecific type of hallucination induced by semantic associations. Specifically,\nwe investigate to what extent LLMs take shortcuts from certain keyword/entity\nbiases in the prompt instead of following the correct reasoning path. To\nquantify this phenomenon, we propose a novel probing method and benchmark\ncalled EureQA. We start from questions that LLMs will answer correctly with\nutmost certainty, and mask the important entity with evidence sentence\nrecursively, asking models to find masked entities according to a chain of\nevidence before answering the question.\n  During the construction of the evidence, we purposefully replace semantic\nclues (entities) that may lead to the correct answer with distractor clues\n(evidence) that will not directly lead to the correct answer but require a\nchain-like reasoning process. We evaluate if models can follow the correct\nreasoning chain instead of short-cutting through distractor clues. We find that\nexisting LLMs lack the necessary capabilities to follow correct reasoning paths\nand resist the attempt of greedy shortcuts. We show that the distractor\nsemantic associations often lead to model hallucination, which is strong\nevidence that questions the validity of current LLM reasoning.",
            "author": [
                "Bangzheng Li",
                "Ben Zhou",
                "Fei Wang",
                "Xingyu Fu",
                "Dan Roth",
                "Muhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09702v1",
                "http://arxiv.org/pdf/2311.09702v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10119v1",
            "title": "Accommodating Missing Modalities in Time-Continuous Multimodal Emotion\n  Recognition",
            "updated": "2023-11-16T09:22:48Z",
            "published": "2023-11-16T09:22:48Z",
            "summary": "Decades of research indicate that emotion recognition is more effective when\ndrawing information from multiple modalities. But what if some modalities are\nsometimes missing? To address this problem, we propose a novel\nTransformer-based architecture for recognizing valence and arousal in a\ntime-continuous manner even with missing input modalities. We use a coupling of\ncross-attention and self-attention mechanisms to emphasize relationships\nbetween modalities during time and enhance the learning process on weak salient\ninputs. Experimental results on the Ulm-TSST dataset show that our model\nexhibits an improvement of the concordance correlation coefficient evaluation\nof 37% when predicting arousal values and 30% when predicting valence values,\ncompared to a late-fusion baseline approach.",
            "author": [
                "Juan Vazquez-Rodriguez",
                "Gr\u00e9goire Lefebvre",
                "Julien Cumin",
                "James L. Crowley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10119v1",
                "http://arxiv.org/pdf/2311.10119v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10118v1",
            "title": "Now and Future of Artificial Intelligence-based Signet Ring Cell\n  Diagnosis: A Survey",
            "updated": "2023-11-16T09:20:43Z",
            "published": "2023-11-16T09:20:43Z",
            "summary": "Since signet ring cells (SRCs) are associated with high peripheral metastasis\nrate and dismal survival, they play an important role in determining surgical\napproaches and prognosis, while they are easily missed by even experienced\npathologists. Although automatic diagnosis SRCs based on deep learning has\nreceived increasing attention to assist pathologists in improving the\ndiagnostic efficiency and accuracy, the existing works have not been\nsystematically overviewed, which hindered the evaluation of the gap between\nalgorithms and clinical applications. In this paper, we provide a survey on SRC\nanalysis driven by deep learning from 2008 to August 2023. Specifically, the\nbiological characteristics of SRCs and the challenges of automatic\nidentification are systemically summarized. Then, the representative algorithms\nare analyzed and compared via dividing them into classification, detection, and\nsegmentation. Finally, for comprehensive consideration to the performance of\nexisting methods and the requirements for clinical assistance, we discuss the\nopen issues and future trends of SRC analysis. The retrospect research will\nhelp researchers in the related fields, particularly for who without medical\nscience background not only to clearly find the outline of SRC analysis, but\nalso gain the prospect of intelligent diagnosis, resulting in accelerating the\npractice and application of intelligent algorithms.",
            "author": [
                "Zhu Meng",
                "Junhao Dong",
                "Limei Guo",
                "Fei Su",
                "Guangxi Wang",
                "Zhicheng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10118v1",
                "http://arxiv.org/pdf/2311.10118v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09699v1",
            "title": "Boltzmann's Billiard Systems: Computation of the Billiard Mapping and\n  Some Numerical Results",
            "updated": "2023-11-16T09:16:43Z",
            "published": "2023-11-16T09:16:43Z",
            "summary": "L. Boltzmann proposed a billiard model with a planar central force problem\nreflected against a line not passing through the center. He asserted that such\na system is ergodic, which thus illustrates his ergodic hypothesis. However, it\nhas been recently shown that when the underlying central force problem is the\nKepler problem then the system is actually integrable by Gallavotti-Jauslin.\nThis raises the question of whether Boltzmann's assertion holds true for some\ncentral force problems that he considered. In this paper, we present some\ngeometrical and numerical analysis on the dynamics of several of these systems.\nAs indicated by the numerics, many of these systems show chaotic dynamics and a\nsystem seems to be ergodic.",
            "author": [
                "Michael Plum",
                "Airi Takeuchi",
                "Lei Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09699v1",
                "http://arxiv.org/pdf/2311.09699v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09697v1",
            "title": "A Dynamic Computational Model of Head Sway Responses in Human Upright\n  Stance Postural Control during Support Surface Tilt",
            "updated": "2023-11-16T09:14:12Z",
            "published": "2023-11-16T09:14:12Z",
            "summary": "Human and humanoid posture control models usually rely on single or multiple\ndegrees of freedom inverted pendulum representation of upright stance\nassociated with a feedback controller. In models typically focused on the\naction between ankles, hips, and knees, the control of head position is often\nneglected, and the head is considered one with the upper body. However, two of\nthe three main contributors to the human motion sensorium reside in the head:\nthe vestibular and the visual system. As the third contributor, the\nproprioceptive system is distributed throughout the body. In human\nneurodegenerative brain diseases of motor control, like Progressive\nSupranuclear Palsy PSP and Idiopathic Parkinson's Disease IPD, clinical studies\nhave demonstrated the importance of head motion deficits. This work\nspecifically addresses the control of the head during a perturbed upright\nstance. A control model for the neck is proposed following the hypothesis of a\nmodular posture control from previous studies. Data from human experiments are\nused to fit the model and retrieve sets of parameters representative of the\nbehavior obtained in different conditions. The result of the analysis is\ntwofold: validate the model and its underlying hypothesis and provide a system\nto assess the differences in posture control that can be used to identify the\ndifferences between healthy subjects and patients with different conditions.\nImplications for clinical pathology and application in humanoid and assistive\nrobotics are discussed.",
            "author": [
                "Vittorio Lippi",
                "Christoph Maurer",
                "Stefan Kammermeier"
            ],
            "link": [
                "http://dx.doi.org/10.5220/0000168300003543",
                "http://arxiv.org/abs/2311.09697v1",
                "http://arxiv.org/pdf/2311.09697v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09696v1",
            "title": "Fumbling in Babel: An Investigation into ChatGPT's Language\n  Identification Ability",
            "updated": "2023-11-16T09:12:20Z",
            "published": "2023-11-16T09:12:20Z",
            "summary": "Recently, ChatGPT has emerged as a powerful NLP tool that can carry out\nseveral tasks. However, the range of languages ChatGPT can handle remains\nlargely a mystery. In this work, we investigate ChatGPT's language\nidentification abilities. For this purpose, we compile Babel-670, a benchmark\ncomprising $670$ languages representing $23$ language families. Languages in\nBabel-670 run the gamut between the very high-resource to the very low-resource\nand are spoken in five continents. We then study ChatGPT's (both GPT-3.5 and\nGPT-4) ability to (i) identify both language names and language codes (ii)\nunder both zero- and few-shot conditions (iii) with and without provision of\nlabel set. When compared to smaller finetuned language identification tools, we\nfind that ChatGPT lags behind. Our empirical analysis shows the reality that\nChatGPT still resides in a state of potential enhancement before it can\nsufficiently serve diverse communities.",
            "author": [
                "Wei-Rui Chen",
                "Ife Adebara",
                "Khai Duy Doan",
                "Qisheng Liao",
                "Muhammad Abdul-Mageed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09696v1",
                "http://arxiv.org/pdf/2311.09696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09694v1",
            "title": "Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness",
            "updated": "2023-11-16T09:09:32Z",
            "published": "2023-11-16T09:09:32Z",
            "summary": "Are the longstanding robustness issues in NLP resolved by today's larger and\nmore performant models? To address this question, we conduct a thorough\ninvestigation using 19 models of different sizes spanning different\narchitectural choices and pretraining objectives. We conduct evaluations using\n(a) OOD and challenge test sets, (b) CheckLists, (c) contrast sets, and (d)\nadversarial inputs. Our analysis reveals that not all OOD tests provide further\ninsight into robustness. Evaluating with CheckLists and contrast sets shows\nsignificant gaps in model performance; merely scaling models does not make them\nsufficiently robust. Finally, we point out that current approaches for\nadversarial evaluations of models are themselves problematic: they can be\neasily thwarted, and in their current forms, do not represent a sufficiently\ndeep probe of model robustness. We conclude that not only is the question of\nrobustness in NLP as yet unresolved, but even some of the approaches to measure\nrobustness need to be reassessed.",
            "author": [
                "Ashim Gupta",
                "Rishanth Rajendhran",
                "Nathan Stringham",
                "Vivek Srikumar",
                "Ana Marasovi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09694v1",
                "http://arxiv.org/pdf/2311.09694v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09693v1",
            "title": "BLT: Can Large Language Models Handle Basic Legal Text?",
            "updated": "2023-11-16T09:09:22Z",
            "published": "2023-11-16T09:09:22Z",
            "summary": "We find that the best publicly available LLMs like GPT-4 and PaLM 2 currently\nperform poorly at basic text handling required of lawyers or paralegals, such\nas looking up the text at a line of a witness deposition or at a subsection of\na contract. We introduce a benchmark to quantify this poor performance, which\ncasts into doubt LLMs' current reliability as-is for legal practice. Finetuning\nfor these tasks brings an older LLM to near-perfect performance on our test set\nand also raises performance on a related legal task. This stark result\nhighlights the need for more domain expertise in LLM training.",
            "author": [
                "Andrew Blair-Stanek",
                "Nils Holzenberger",
                "Benjamin Van Durme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09693v1",
                "http://arxiv.org/pdf/2311.09693v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.1; I.2.7; J.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09688v1",
            "title": "Sensitivity to keV-MeV dark matter from cosmic-ray scattering with\n  current and the upcoming ground-based arrays CTA and SWGO",
            "updated": "2023-11-16T09:01:29Z",
            "published": "2023-11-16T09:01:29Z",
            "summary": "A wealth of astrophysical and cosmological observational evidence shows that\nthe matter content of the universe is made of about 85$\\%$ of non-baryonic dark\nmatter. Huge experimental efforts have been deployed to look for the direct\ndetection of dark matter via their scattering on target nucleons, their\nproduction in colliders, and their indirect detection via their annihilation\nproducts. Inelastic scattering of high-energy cosmic rays off dark matter\nparticles populating the Milky Way halo would produce secondary gamma rays in\nthe final state from the decay of the neutral pions produced in such\ninteractions, providing a new avenue to probe dark matter properties. We\ncompute here the sensitivity for H.E.S.S.-like observatory, a\ncurrent-generation ground-based Cherenkov telescopes, to the expected gamma-ray\nflux from collisions of Galactic cosmic rays and dark matter in the center of\nthe Milky Way. We also derive sensitivity prospects for the upcoming Cherenkov\nTelescope Array (CTA) and Southern Wide-field Gamma-ray Observatory (SWGO). The\nexpected sensitivity allows us to probe a poorly-constrained range of dark\nmatter masses so far, ranging from keV to sub-GeV, and provide complementary\nconstraints on the dark matter-proton scattering cross section traditionally\nprobed by deep underground direct dark matter experiments.",
            "author": [
                "Igor Reis",
                "Emmanuel Moulin",
                "Aion Viana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09688v1",
                "http://arxiv.org/pdf/2311.09688v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09687v1",
            "title": "Inducing Political Bias Allows Language Models Anticipate Partisan\n  Reactions to Controversies",
            "updated": "2023-11-16T08:57:53Z",
            "published": "2023-11-16T08:57:53Z",
            "summary": "Social media platforms are rife with politically charged discussions.\nTherefore, accurately deciphering and predicting partisan biases using Large\nLanguage Models (LLMs) is increasingly critical. In this study, we address the\nchallenge of understanding political bias in digitized discourse using LLMs.\nWhile traditional approaches often rely on finetuning separate models for each\npolitical faction, our work innovates by employing a singular,\ninstruction-tuned LLM to reflect a spectrum of political ideologies. We present\na comprehensive analytical framework, consisting of Partisan Bias Divergence\nAssessment and Partisan Class Tendency Prediction, to evaluate the model's\nalignment with real-world political ideologies in terms of stances, emotions,\nand moral foundations. Our findings reveal the model's effectiveness in\ncapturing emotional and moral nuances, albeit with some challenges in stance\ndetection, highlighting the intricacies and potential for refinement in NLP\ntools for politically sensitive contexts. This research contributes\nsignificantly to the field by demonstrating the feasibility and importance of\nnuanced political understanding in LLMs, particularly for applications\nrequiring acute awareness of political bias.",
            "author": [
                "Zihao He",
                "Siyi Guo",
                "Ashwin Rao",
                "Kristina Lerman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09687v1",
                "http://arxiv.org/pdf/2311.09687v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09684v1",
            "title": "Do Physicians Know How to Prompt? The Need for Automatic Prompt\n  Optimization Help in Clinical Note Generation",
            "updated": "2023-11-16T08:54:52Z",
            "published": "2023-11-16T08:54:52Z",
            "summary": "This study examines the effect of prompt engineering on the performance of\nLarge Language Models (LLMs) in clinical note generation. We introduce an\nAutomatic Prompt Optimization (APO) framework to refine initial prompts and\ncompare the outputs of medical experts, non-medical experts, and APO-enhanced\nGPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in\nstandardizing prompt quality across clinical note sections. A human-in-the-loop\napproach shows that experts maintain content quality post-APO, with a\npreference for their own modifications, suggesting the value of expert\ncustomization. We recommend a two-phase optimization process, leveraging\nAPO-GPT4 for consistency and expert input for personalization.",
            "author": [
                "Zonghai Yao",
                "Ahmed Jaafar",
                "Beining Wang",
                "Yue Zhu",
                "Zhichao Yang",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09684v1",
                "http://arxiv.org/pdf/2311.09684v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09682v1",
            "title": "MacGyver: Are Large Language Models Creative Problem Solvers?",
            "updated": "2023-11-16T08:52:27Z",
            "published": "2023-11-16T08:52:27Z",
            "summary": "We explore the creative problem-solving capabilities of modern large language\nmodels (LLMs) in a constrained setting. The setting requires circumventing a\ncognitive bias known in psychology as ''functional fixedness'' to use familiar\nobjects in innovative or unconventional ways. To this end, we create MacGyver,\nan automatically generated dataset consisting of 1,600 real-world problems that\ndeliberately trigger functional fixedness and require thinking\n'out-of-the-box'. We then present our collection of problems to both LLMs and\nhumans to compare and contrast their problem-solving abilities. We show that\nMacGyver is challenging for both groups, but in unique and complementary ways.\nFor example, humans typically excel in solving problems that they are familiar\nwith but may struggle with tasks requiring domain-specific knowledge, leading\nto a higher variance. On the other hand, LLMs, being exposed to a variety of\nhighly specialized knowledge, attempt broader problems but are prone to\noverconfidence and propose actions that are physically infeasible or\ninefficient. We also provide a detailed error analysis of LLMs, and demonstrate\nthe potential of enhancing their problem-solving ability with novel prompting\ntechniques such as iterative step-wise reflection and divergent-convergent\nthinking. This work provides insight into the creative problem-solving\ncapabilities of humans and AI and illustrates how psychological paradigms can\nbe extended into large-scale tasks for comparing humans and machines.",
            "author": [
                "Yufei Tian",
                "Abhilasha Ravichander",
                "Lianhui Qin",
                "Ronan Le Bras",
                "Raja Marjieh",
                "Nanyun Peng",
                "Yejin Choi",
                "Thomas L. Griffiths",
                "Faeze Brahman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09682v1",
                "http://arxiv.org/pdf/2311.09682v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09680v4",
            "title": "Trustworthy Large Models in Vision: A Survey",
            "updated": "2023-12-01T15:12:06Z",
            "published": "2023-11-16T08:49:46Z",
            "summary": "The rapid progress of Large Models (LMs) has recently revolutionized various\nfields of deep learning with remarkable grades, ranging from Natural Language\nProcessing (NLP) to Computer Vision (CV). However, LMs are increasingly\nchallenged and criticized by academia and industry due to their powerful\nperformance but untrustworthy behavior, which urgently needs to be alleviated\nby reliable methods. Despite the abundance of literature on trustworthy LMs in\nNLP, a systematic survey specifically delving into the trustworthiness of LMs\nin CV remains absent. In order to mitigate this gap, we summarize four relevant\nconcerns that obstruct the trustworthy usage in vision of LMs in this survey,\nincluding 1) human misuse, 2) vulnerability, 3) inherent issue and 4)\ninterpretability. By highlighting corresponding challenge, countermeasures, and\ndiscussion in each topic, we hope this survey will facilitate readers'\nunderstanding of this field, promote alignment of LMs with human expectations\nand enable trustworthy LMs to serve as welfare rather than disaster for human\nsociety.",
            "author": [
                "Ziyan Guo",
                "Li Xu",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09680v4",
                "http://arxiv.org/pdf/2311.09680v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09677v1",
            "title": "R-Tuning: Teaching Large Language Models to Refuse Unknown Questions",
            "updated": "2023-11-16T08:45:44Z",
            "published": "2023-11-16T08:45:44Z",
            "summary": "Large language models (LLMs) have revolutionized numerous domains with their\nimpressive performance but still face their challenges. A predominant issue is\nthe propensity for these models to generate non-existent facts, a concern\ntermed hallucination. Our research is motivated by the observation that\nprevious instruction tuning methods force the model to complete a sentence no\nmatter whether the model knows the knowledge or not. When the question is out\nof the parametric knowledge, it will try to make up something and fail to\nindicate when it lacks knowledge. In this paper, we present a new approach\ncalled Refusal-Aware Instruction Tuning (R-Tuning). This approach is formalized\nby first identifying the knowledge gap between parametric knowledge and the\ninstruction tuning data. Then, we construct the refusal-aware data based on the\nknowledge intersection, to tune LLMs to refrain from responding to questions\nbeyond its parametric knowledge. Experimental results demonstrate this new\ninstruction tuning approach effectively improves a model's ability to answer\nknown questions and refrain from answering unknown questions. Furthermore, when\ntested on out-of-domain datasets, the refusal ability was found to be a\nmeta-skill that could be generalized to other tasks. Further analysis\nsurprisingly finds that learning the uncertainty during training displays a\nbetter ability to estimate uncertainty than uncertainty-based testing. Our code\nwill be released at https://github.com/shizhediao/R-Tuning.",
            "author": [
                "Hanning Zhang",
                "Shizhe Diao",
                "Yong Lin",
                "Yi R. Fung",
                "Qing Lian",
                "Xingyao Wang",
                "Yangyi Chen",
                "Heng Ji",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09677v1",
                "http://arxiv.org/pdf/2311.09677v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09675v1",
            "title": "Where Do People Tell Stories Online? Story Detection Across Online\n  Communities",
            "updated": "2023-11-16T08:42:26Z",
            "published": "2023-11-16T08:42:26Z",
            "summary": "People share stories online for a myriad of purposes, whether as a means of\nself-disclosure, processing difficult personal experiences, providing needed\ninformation or entertainment, or persuading others to share their beliefs.\nBetter understanding of online storytelling can illuminate the dynamics of\nsocial movements, sensemaking practices, persuasion strategies, and more.\nHowever, unlike other media such as books and visual content where the\nnarrative nature of the content is often overtly signaled at the document\nlevel, studying storytelling in online communities is challenging due to the\nmixture of storytelling and non-storytelling behavior, which can be\ninterspersed within documents and across diverse topics and settings. We\nintroduce a codebook and create the Storytelling in Online Communities Corpus,\nan expert-annotated dataset of 502 English-language posts and comments with\nlabeled story and event spans. Using our corpus, we train and evaluate an\nonline story detection model, which we use to investigate the role storytelling\nof in different social contexts. We identify distinctive features of online\nstorytelling, the prevalence of storytelling among different communities, and\nthe conversational patterns of storytelling.",
            "author": [
                "Maria Antoniak",
                "Joel Mire",
                "Maarten Sap",
                "Elliott Ash",
                "Andrew Piper"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09675v1",
                "http://arxiv.org/pdf/2311.09675v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09671v1",
            "title": "Robust Contrastive Learning With Theory Guarantee",
            "updated": "2023-11-16T08:39:58Z",
            "published": "2023-11-16T08:39:58Z",
            "summary": "Contrastive learning (CL) is a self-supervised training paradigm that allows\nus to extract meaningful features without any label information. A typical CL\nframework is divided into two phases, where it first tries to learn the\nfeatures from unlabelled data, and then uses those features to train a linear\nclassifier with the labeled data. While a fair amount of existing theoretical\nworks have analyzed how the unsupervised loss in the first phase can support\nthe supervised loss in the second phase, none has examined the connection\nbetween the unsupervised loss and the robust supervised loss, which can shed\nlight on how to construct an effective unsupervised loss for the first phase of\nCL. To fill this gap, our work develops rigorous theories to dissect and\nidentify which components in the unsupervised loss can help improve the robust\nsupervised loss and conduct proper experiments to verify our findings.",
            "author": [
                "Ngoc N. Tran",
                "Lam Tran",
                "Hoang Phan",
                "Anh Bui",
                "Tung Pham",
                "Toan Tran",
                "Dinh Phung",
                "Trung Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09671v1",
                "http://arxiv.org/pdf/2311.09671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09668v1",
            "title": "Improving the Generation Quality of Watermarked Large Language Models\n  via Word Importance Scoring",
            "updated": "2023-11-16T08:36:00Z",
            "published": "2023-11-16T08:36:00Z",
            "summary": "The strong general capabilities of Large Language Models (LLMs) bring\npotential ethical risks if they are unrestrictedly accessible to malicious\nusers. Token-level watermarking inserts watermarks in the generated texts by\naltering the token probability distributions with a private random number\ngenerator seeded by its prefix tokens. However, this watermarking algorithm\nalters the logits during generation, which can lead to a downgraded text\nquality if it chooses to promote tokens that are less relevant given the input.\nIn this work, we propose to improve the quality of texts generated by a\nwatermarked language model by Watermarking with Importance Scoring (WIS). At\neach generation step, we estimate the importance of the token to generate, and\nprevent it from being impacted by watermarking if it is important for the\nsemantic correctness of the output. We further propose three methods to predict\nimportance scoring, including a perturbation-based method and two model-based\nmethods. Empirical experiments show that our method can generate texts with\nbetter quality with comparable level of detection rate.",
            "author": [
                "Yuhang Li",
                "Yihan Wang",
                "Zhouxing Shi",
                "Cho-Jui Hsieh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09668v1",
                "http://arxiv.org/pdf/2311.09668v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09665v1",
            "title": "Evaluating LLM Agent Group Dynamics against Human Group Dynamics: A Case\n  Study on Wisdom of Partisan Crowds",
            "updated": "2023-11-16T08:30:15Z",
            "published": "2023-11-16T08:30:15Z",
            "summary": "This study investigates the potential of Large Language Models (LLMs) to\nsimulate human group dynamics, particularly within politically charged\ncontexts. We replicate the Wisdom of Partisan Crowds phenomenon using LLMs to\nrole-play as Democrat and Republican personas, engaging in a structured\ninteraction akin to human group study. Our approach evaluates how agents'\nresponses evolve through social influence. Our key findings indicate that LLM\nagents role-playing detailed personas and without Chain-of-Thought (CoT)\nreasoning closely align with human behaviors, while having CoT reasoning hurts\nthe alignment. However, incorporating explicit biases into agent prompts does\nnot necessarily enhance the wisdom of partisan crowds. Moreover, fine-tuning\nLLMs with human data shows promise in achieving human-like behavior but poses a\nrisk of overfitting certain behaviors. These findings show the potential and\nlimitations of using LLM agents in modeling human group phenomena.",
            "author": [
                "Yun-Shiuan Chuang",
                "Siddharth Suresh",
                "Nikunj Harlalka",
                "Agam Goyal",
                "Robert Hawkins",
                "Sijia Yang",
                "Dhavan Shah",
                "Junjie Hu",
                "Timothy T. Rogers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09665v1",
                "http://arxiv.org/pdf/2311.09665v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09661v1",
            "title": "Evolving Domain Adaptation of Pretrained Language Models for Text\n  Classification",
            "updated": "2023-11-16T08:28:00Z",
            "published": "2023-11-16T08:28:00Z",
            "summary": "Adapting pre-trained language models (PLMs) for time-series text\nclassification amidst evolving domain shifts (EDS) is critical for maintaining\naccuracy in applications like stance detection. This study benchmarks the\neffectiveness of evolving domain adaptation (EDA) strategies, notably\nself-training, domain-adversarial training, and domain-adaptive pretraining,\nwith a focus on an incremental self-training method. Our analysis across\nvarious datasets reveals that this incremental method excels at adapting PLMs\nto EDS, outperforming traditional domain adaptation techniques. These findings\nhighlight the importance of continually updating PLMs to ensure their\neffectiveness in real-world applications, paving the way for future research\ninto PLM robustness against the natural temporal evolution of language.",
            "author": [
                "Yun-Shiuan Chuang",
                "Yi Wu",
                "Dhruv Gupta",
                "Rheeya Uppaal",
                "Ananya Kumar",
                "Luhang Sun",
                "Makesh Narsimhan Sreedhar",
                "Sijia Yang",
                "Timothy T. Rogers",
                "Junjie Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09661v1",
                "http://arxiv.org/pdf/2311.09661v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09659v1",
            "title": "Enhancing Deformable Object Manipulation By Using Interactive Perception\n  and Assistive Tools",
            "updated": "2023-11-16T08:24:28Z",
            "published": "2023-11-16T08:24:28Z",
            "summary": "In the field of robotic manipulation, the proficiency of deformable object\nmanipulation lags behind human capabilities due to the inherent characteristics\nof deformable objects. These objects have infinite degrees of freedom,\nresulting in non-trivial perception and state estimation, and complex dynamics,\ncomplicating the prediction of future configurations. Although recent research\nhas focused on deformable object manipulation, most approaches rely on static\nvision and simple manipulation techniques, limiting the performance level. This\npaper proposes two solutions to enhance the performance: interactive perception\nand the use of assistive tools. The first solution posits that optimal\nperspectives exist during deformable object manipulation, facilitating easier\nstate estimation. By exploring the action-perception regularity, interactive\nperception facilitates better manipulation and perception. The second solution\nadvocates for the use of assistive tools, a hallmark of human intelligence, to\nimprove manipulation performance. For instance, a folding board can aid in\ngarment folding tasks by reducing object deformation and managing complex\ndynamics. Hence, this research aims to address the deformable object\nmanipulation problem by incorporating interactive perception and assistive\ntools to augment manipulation performance.",
            "author": [
                "Peng Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09659v1",
                "http://arxiv.org/pdf/2311.09659v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09656v1",
            "title": "Structured Chemistry Reasoning with Large Language Models",
            "updated": "2023-11-16T08:20:36Z",
            "published": "2023-11-16T08:20:36Z",
            "summary": "This paper studies the problem of solving complex chemistry problems with\nlarge language models (LLMs). Despite the extensive general knowledge in LLMs\n(such as GPT-4), they struggle with chemistry reasoning that requires faithful\ngrounded reasoning with diverse chemical knowledge and an integrative\nunderstanding of chemical interactions. We propose InstructChem, a new\nstructured reasoning approach that substantially boosts the LLMs' chemical\nreasoning capabilities. InstructChem explicitly decomposes the reasoning into\nthree critical phrases, including chemical formulae generation by LLMs that\noffers the basis for subsequent grounded reasoning, step-by-step reasoning that\nmakes multi-step derivations with the identified formulae for a preliminary\nanswer, and iterative review-and-refinement that steers LLMs to progressively\nrevise the previous phases for increasing confidence, leading to the final\nhigh-confidence answer. We conduct extensive experiments on four different\nchemistry challenges, including quantum chemistry, quantum mechanics, physical\nchemistry, and chemistry kinetics. Our approach significantly enhances GPT-4 on\nchemistry reasoning, yielding an 8% average absolute improvement and a 30% peak\nimprovement. We further use the generated reasoning by GPT-4 to fine-tune\nsmaller LMs (e.g., Vicuna) and observe strong improvement of the smaller LMs.\nThis validates our approach and enables LLMs to generate high-quality\nreasoning.",
            "author": [
                "Siru Ouyang",
                "Zhuosheng Zhang",
                "Bing Yan",
                "Xuan Liu",
                "Jiawei Han",
                "Lianhui Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09656v1",
                "http://arxiv.org/pdf/2311.09656v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09655v2",
            "title": "Multi-View Spectrogram Transformer for Respiratory Sound Classification",
            "updated": "2023-12-05T09:10:37Z",
            "published": "2023-11-16T08:17:02Z",
            "summary": "Deep neural networks have been applied to audio spectrograms for respiratory\nsound classification. Existing models often treat the spectrogram as a\nsynthetic image while overlooking its physical characteristics. In this paper,\na Multi-View Spectrogram Transformer (MVST) is proposed to embed different\nviews of time-frequency characteristics into the vision transformer.\nSpecifically, the proposed MVST splits the mel-spectrogram into different sized\npatches, representing the multi-view acoustic elements of a respiratory sound.\nThese patches and positional embeddings are then fed into transformer encoders\nto extract the attentional information among patches through a self-attention\nmechanism. Finally, a gated fusion scheme is designed to automatically weigh\nthe multi-view features to highlight the best one in a specific scenario.\nExperimental results on the ICBHI dataset demonstrate that the proposed MVST\nsignificantly outperforms state-of-the-art methods for classifying respiratory\nsounds.",
            "author": [
                "Wentao He",
                "Yuchen Yan",
                "Jianfeng Ren",
                "Ruibin Bai",
                "Xudong Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09655v2",
                "http://arxiv.org/pdf/2311.09655v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09653v1",
            "title": "Improved TokenPose with Sparsity",
            "updated": "2023-11-16T08:12:34Z",
            "published": "2023-11-16T08:12:34Z",
            "summary": "Over the past few years, the vision transformer and its various forms have\ngained significance in human pose estimation. By treating image patches as\ntokens, transformers can capture global relationships wisely, estimate the\nkeypoint tokens by leveraging the visual tokens, and recognize the posture of\nthe human body. Nevertheless, global attention is computationally demanding,\nwhich poses a challenge for scaling up transformer-based methods to\nhigh-resolution features. In this paper, we introduce sparsity in both keypoint\ntoken attention and visual token attention to improve human pose estimation.\nExperimental results on the MPII dataset demonstrate that our model has a\nhigher level of accuracy and proved the feasibility of the method, achieving\nnew state-of-the-art results. The idea can also provide references for other\ntransformer-based models.",
            "author": [
                "Anning Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09653v1",
                "http://arxiv.org/pdf/2311.09653v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09652v1",
            "title": "Event-based Motion-Robust Accurate Shape Estimation for Mixed\n  Reflectance Scenes",
            "updated": "2023-11-16T08:12:10Z",
            "published": "2023-11-16T08:12:10Z",
            "summary": "Event-based structured light systems have recently been introduced as an\nexciting alternative to conventional frame-based triangulation systems for the\n3D measurements of diffuse surfaces. Important benefits include the fast\ncapture speed and the high dynamic range provided by the event camera - albeit\nat the cost of lower data quality. So far, both low-accuracy event-based as\nwell as high-accuracy frame-based 3D imaging systems are tailored to a specific\nsurface type, such as diffuse or specular, and can not be used for a broader\nclass of object surfaces (\"mixed reflectance scenes\"). In this paper, we\npresent a novel event-based structured light system that enables fast 3D\nimaging of mixed reflectance scenes with high accuracy. On the captured events,\nwe use epipolar constraints that intrinsically enable decomposing the measured\nreflections into diffuse, two-bounce specular, and other multi-bounce\nreflections. The diffuse objects in the scene are reconstructed using\ntriangulation. Eventually, the reconstructed diffuse scene parts are used as a\n\"display\" to evaluate the specular scene parts via deflectometry. This novel\nprocedure allows us to use the entire scene as a virtual screen, using only a\nscanning laser and an event camera. The resulting system achieves fast and\nmotion-robust (14Hz) reconstructions of mixed reflectance scenes with < 500\n$\\mu$m accuracy. Moreover, we introduce a \"superfast\" capture mode (250Hz) for\nthe 3D measurement of diffuse scenes.",
            "author": [
                "Aniket Dashpute",
                "Jiazhang Wang",
                "James Taylor",
                "Oliver Cossairt",
                "Ashok Veeraraghavan",
                "Florian Willomitzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09652v1",
                "http://arxiv.org/pdf/2311.09652v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09651v1",
            "title": "\"It's not like Jarvis, but it's pretty close!\" -- Examining ChatGPT's\n  Usage among Undergraduate Students in Computer Science",
            "updated": "2023-11-16T08:10:18Z",
            "published": "2023-11-16T08:10:18Z",
            "summary": "Large language models (LLMs) such as ChatGPT and Google Bard have garnered\nsignificant attention in the academic community. Previous research has\nevaluated these LLMs for various applications such as generating programming\nexercises and solutions. However, these evaluations have predominantly been\nconducted by instructors and researchers, not considering the actual usage of\nLLMs by students. This study adopts a student-first approach to comprehensively\nunderstand how undergraduate computer science students utilize ChatGPT, a\npopular LLM, released by OpenAI. We employ a combination of student surveys and\ninterviews to obtain valuable insights into the benefits, challenges, and\nsuggested improvements related to ChatGPT. Our findings suggest that a majority\nof students (over 57%) have a convincingly positive outlook towards adopting\nChatGPT as an aid in coursework-related tasks. However, our research also\nhighlights various challenges that must be resolved for long-term acceptance of\nChatGPT amongst students. The findings from this investigation have broader\nimplications and may be applicable to other LLMs and their role in computing\neducation.",
            "author": [
                "Ishika Joshi",
                "Ritvik Budhiraja",
                "Harshal D Akolekar",
                "Jagat Sesh Challa",
                "Dhruv Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09651v1",
                "http://arxiv.org/pdf/2311.09651v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09649v1",
            "title": "ICXML: An In-Context Learning Framework for Zero-Shot Extreme\n  Multi-Label Classification",
            "updated": "2023-11-16T08:01:17Z",
            "published": "2023-11-16T08:01:17Z",
            "summary": "This paper focuses on the task of Extreme Multi-Label Classification (XMC)\nwhose goal is to predict multiple labels for each instance from an extremely\nlarge label space. While existing research has primarily focused on fully\nsupervised XMC, real-world scenarios often lack complete supervision signals,\nhighlighting the importance of zero-shot settings. Given the large label space,\nutilizing in-context learning approaches is not trivial. We address this issue\nby introducing In-Context Extreme Multilabel Learning (ICXML), a two-stage\nframework that cuts down the search space by generating a set of candidate\nlabels through incontext learning and then reranks them. Extensive experiments\nsuggest that ICXML advances the state of the art on two diverse public\nbenchmarks.",
            "author": [
                "Yaxin Zhu",
                "Hamed Zamani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09649v1",
                "http://arxiv.org/pdf/2311.09649v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09648v1",
            "title": "Event Causality Is Key to Computational Story Understanding",
            "updated": "2023-11-16T07:59:12Z",
            "published": "2023-11-16T07:59:12Z",
            "summary": "Psychological research suggests the central role of event causality in human\nstory understanding. Further, event causality has been heavily utilized in\nsymbolic story generation. However, few machine learning systems for story\nunderstanding employ event causality, partially due to the lack of reliable\nmethods for identifying open-world causal event relations. Leveraging recent\nprogress in large language models (LLMs), we present the first method for event\ncausality identification that leads to material improvements in computational\nstory understanding. We design specific prompts for extracting event causal\nrelations from GPT. Against human-annotated event causal relations in the\nGLUCOSE dataset, our technique performs on par with supervised models, while\nbeing easily generalizable to stories of different types and lengths. The\nextracted causal relations lead to 5.7\\% improvements on story quality\nevaluation and 8.7\\% on story video-text alignment. Our findings indicate\nenormous untapped potential for event causality in computational story\nunderstanding.",
            "author": [
                "Yidan Sun",
                "Qin Chao",
                "Boyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09648v1",
                "http://arxiv.org/pdf/2311.09648v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09646v1",
            "title": "Reconstructing Continuous Light Field From Single Coded Image",
            "updated": "2023-11-16T07:59:01Z",
            "published": "2023-11-16T07:59:01Z",
            "summary": "We propose a method for reconstructing a continuous light field of a target\nscene from a single observed image. Our method takes the best of two worlds:\njoint aperture-exposure coding for compressive light-field acquisition, and a\nneural radiance field (NeRF) for view synthesis. Joint aperture-exposure coding\nimplemented in a camera enables effective embedding of 3-D scene information\ninto an observed image, but in previous works, it was used only for\nreconstructing discretized light-field views. NeRF-based neural rendering\nenables high quality view synthesis of a 3-D scene from continuous viewpoints,\nbut when only a single image is given as the input, it struggles to achieve\nsatisfactory quality. Our method integrates these two techniques into an\nefficient and end-to-end trainable pipeline. Trained on a wide variety of\nscenes, our method can reconstruct continuous light fields accurately and\nefficiently without any test time optimization. To our knowledge, this is the\nfirst work to bridge two worlds: camera design for efficiently acquiring 3-D\ninformation and neural rendering.",
            "author": [
                "Yuya Ishikawa",
                "Keita Takahashi",
                "Chihiro Tsutake",
                "Toshiaki Fujii"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2023.3314340",
                "http://arxiv.org/abs/2311.09646v1",
                "http://arxiv.org/pdf/2311.09646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09642v2",
            "title": "Weakly Supervised Anomaly Detection for Chest X-Ray Image",
            "updated": "2023-11-18T16:44:24Z",
            "published": "2023-11-16T07:53:34Z",
            "summary": "Chest X-Ray (CXR) examination is a common method for assessing thoracic\ndiseases in clinical applications. While recent advances in deep learning have\nenhanced the significance of visual analysis for CXR anomaly detection, current\nmethods often miss key cues in anomaly images crucial for identifying disease\nregions, as they predominantly rely on unsupervised training with normal\nimages. This letter focuses on a more practical setup in which few-shot anomaly\nimages with only image-level labels are available during training. For this\npurpose, we propose WSCXR, a weakly supervised anomaly detection framework for\nCXR. WSCXR firstly constructs sets of normal and anomaly image features\nrespectively. It then refines the anomaly image features by eliminating normal\nregion features through anomaly feature mining, thus fully leveraging the\nscarce yet crucial features of diseased areas. Additionally, WSCXR employs a\nlinear mixing strategy to augment the anomaly features, facilitating the\ntraining of anomaly detector with few-shot anomaly images. Experiments on two\nCXR datasets demonstrate the effectiveness of our approach.",
            "author": [
                "Haoqi Ni",
                "Ximiao Zhang",
                "Min Xu",
                "Ning Lang",
                "Xiuzhuang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09642v2",
                "http://arxiv.org/pdf/2311.09642v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09641v1",
            "title": "On the Exploitability of Reinforcement Learning with Human Feedback for\n  Large Language Models",
            "updated": "2023-11-16T07:48:45Z",
            "published": "2023-11-16T07:48:45Z",
            "summary": "Reinforcement Learning with Human Feedback (RLHF) is a methodology designed\nto align Large Language Models (LLMs) with human preferences, playing an\nimportant role in LLMs alignment. Despite its advantages, RLHF relies on human\nannotators to rank the text, which can introduce potential security\nvulnerabilities if any adversarial annotator (i.e., attackers) manipulates the\nranking score by up-ranking any malicious text to steer the LLM adversarially.\nTo assess the red-teaming of RLHF against human preference data poisoning, we\npropose RankPoison, a poisoning attack method on candidates' selection of\npreference rank flipping to reach certain malicious behaviors (e.g., generating\nlonger sequences, which can increase the computational cost). With poisoned\ndataset generated by RankPoison, we can perform poisoning attacks on LLMs to\ngenerate longer tokens without hurting the original safety alignment\nperformance. Moreover, applying RankPoison, we also successfully implement a\nbackdoor attack where LLMs can generate longer answers under questions with the\ntrigger word. Our findings highlight critical security challenges in RLHF,\nunderscoring the necessity for more robust alignment methods for LLMs.",
            "author": [
                "Jiongxiao Wang",
                "Junlin Wu",
                "Muhao Chen",
                "Yevgeniy Vorobeychik",
                "Chaowei Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09641v1",
                "http://arxiv.org/pdf/2311.09641v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09639v1",
            "title": "On the Quantification of Image Reconstruction Uncertainty without\n  Training Data",
            "updated": "2023-11-16T07:46:47Z",
            "published": "2023-11-16T07:46:47Z",
            "summary": "Computational imaging plays a pivotal role in determining hidden information\nfrom sparse measurements. A robust inverse solver is crucial to fully\ncharacterize the uncertainty induced by these measurements, as it allows for\nthe estimation of the complete posterior of unrecoverable targets. This, in\nturn, facilitates a probabilistic interpretation of observational data for\ndecision-making. In this study, we propose a deep variational framework that\nleverages a deep generative model to learn an approximate posterior\ndistribution to effectively quantify image reconstruction uncertainty without\nthe need for training data. We parameterize the target posterior using a\nflow-based model and minimize their Kullback-Leibler (KL) divergence to achieve\naccurate uncertainty estimation. To bolster stability, we introduce a robust\nflow-based model with bi-directional regularization and enhance expressivity\nthrough gradient boosting. Additionally, we incorporate a space-filling design\nto achieve substantial variance reduction on both latent prior space and target\nposterior space. We validate our method on several benchmark tasks and two\nreal-world applications, namely fastMRI and black hole image reconstruction.\nOur results indicate that our method provides reliable and high-quality image\nreconstruction with robust uncertainty estimation.",
            "author": [
                "Sirui Bi",
                "Victor Fung",
                "Jiaxin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09639v1",
                "http://arxiv.org/pdf/2311.09639v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09638v1",
            "title": "Converting Non-Equilibrium Charge Density into Spin Current",
            "updated": "2023-11-16T07:46:38Z",
            "published": "2023-11-16T07:46:38Z",
            "summary": "The interconversion between charge and spin degrees of freedom is of both\nfundamental and technological relevance in spintronics. While a non-equilibrium\nspin density and a charge current are related by the well known\nRashba-Edelstein effect, here we theoretically model the generation of a\ntime-dependent spin current due to a periodic modulation of the charge density,\nfor example by a gate. By using the Boltzmann transport equation, we show that\nwhen the chemical potential is varied, a spin current is generated in the time\nscale it takes for the system to re-equilibrate in the new chemical potential.\nThe effect is ubiquitous in many systems with spin-momentum locking; we compute\nthe strength of the effect in four examples and propose a simple device scheme\nto measure the spin accumulation resulting from such time-dependent spin\ncurrents. Our findings test fundamental theoretical questions about\ncharge-to-spin conversion mechanisms and provide an all-electrical way to\ngenerate spin currents without the need for charge currents, magnetic materials\nor optical methods.",
            "author": [
                "Marc Vila",
                "Joel E. Moore"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09638v1",
                "http://arxiv.org/pdf/2311.09638v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09637v1",
            "title": "Multi-objective Quantum Annealing approach for solving flexible job shop\n  scheduling in manufacturing",
            "updated": "2023-11-16T07:45:57Z",
            "published": "2023-11-16T07:45:57Z",
            "summary": "Flexible Job Shop Scheduling (FJSSP) is a complex optimization problem\ncrucial for real-world process scheduling in manufacturing. Efficiently solving\nsuch problems is vital for maintaining competitiveness. This paper introduces\nQuantum Annealing-based solving algorithm (QASA) to address FJSSP, utilizing\nquantum annealing and classical techniques. QASA optimizes multi-criterial\nFJSSP considering makespan, total workload, and job priority concurrently. It\nemploys Hamiltonian formulation with Lagrange parameters to integrate\nconstraints and objectives, allowing objective prioritization through weight\nassignment. To manage computational complexity, large instances are decomposed\ninto subproblems, and a decision logic based on bottleneck factors is used.\nExperiments on benchmark problems show QASA, combining tabu search, simulated\nannealing, and Quantum Annealing, outperforms a classical solving algorithm\n(CSA) in solution quality (set coverage and hypervolume ratio metrics).\nComputational efficiency analysis indicates QASA achieves superior Pareto\nsolutions with a reasonable increase in computation time compared to CSA.",
            "author": [
                "Philipp Schworm",
                "Xiangquian Wu",
                "Matthias Klar",
                "Moritz Glatt",
                "Jan C. Aurich"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jmsy.2023.11.015",
                "http://arxiv.org/abs/2311.09637v1",
                "http://arxiv.org/pdf/2311.09637v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09636v1",
            "title": "Holographic torus correlators in $\\text{AdS}_3$ gravity coupled to\n  scalar field",
            "updated": "2023-11-16T07:39:40Z",
            "published": "2023-11-16T07:39:40Z",
            "summary": "This paper investigates holographic torus correlators of generic operators at\nconformal infinity and a finite cutoff within AdS$_3$ gravity coupled with a\nfree scalar field. Using a near-boundary analysis and solving the gravitational\nboundary value problem, we solve Einstein's equation and calculate mixed\ncorrelators for massless and massive coupled scalar fields. The conformal ward\nidentity on the torus has been reproduced holographically, which can be\nregarded as a consistency check. Further, recurrence relations for a specific\nclass of higher-point correlators are derived, validating AdS$_3$/CFT$_2$ with\nnon-trivial boundary topology. While the two-point scalar correlator is\naccurately computed on the thermal AdS$_3$ saddle, the higher-point correlators\nassociated with scalar and stress tensor operators are explored.",
            "author": [
                "Song He",
                "Yun-Ze Li",
                "Yunda Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09636v1",
                "http://arxiv.org/pdf/2311.09636v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09635v1",
            "title": "Evaluating In-Context Learning of Libraries for Code Generation",
            "updated": "2023-11-16T07:37:25Z",
            "published": "2023-11-16T07:37:25Z",
            "summary": "Contemporary Large Language Models (LLMs) exhibit a high degree of code\ngeneration and comprehension capability. A particularly promising area is their\nability to interpret code modules from unfamiliar libraries for solving\nuser-instructed tasks. Recent work has shown that large proprietary LLMs can\nlearn novel library usage in-context from demonstrations. These results raise\nseveral open questions: whether demonstrations of library usage is required,\nwhether smaller (and more open) models also possess such capabilities, etc. In\nthis work, we take a broader approach by systematically evaluating a diverse\narray of LLMs across three scenarios reflecting varying levels of domain\nspecialization to understand their abilities and limitations in generating code\nbased on libraries defined in-context. Our results show that even smaller\nopen-source LLMs like Llama-2 and StarCoder demonstrate an adept understanding\nof novel code libraries based on specification presented in-context. Our\nfindings further reveal that LLMs exhibit a surprisingly high proficiency in\nlearning novel library modules even when provided with just natural language\ndescriptions or raw code implementations of the functions, which are often\ncheaper to obtain than demonstrations. Overall, our results pave the way for\nharnessing LLMs in more adaptable and dynamic coding environments.",
            "author": [
                "Arkil Patel",
                "Siva Reddy",
                "Dzmitry Bahdanau",
                "Pradeep Dasigi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09635v1",
                "http://arxiv.org/pdf/2311.09635v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09634v1",
            "title": "Towards Accurate Quantum Chemical Calculations on Noisy Quantum\n  Computers",
            "updated": "2023-11-16T07:36:15Z",
            "published": "2023-11-16T07:36:15Z",
            "summary": "Variational quantum eigensolver (VQE) is a hybrid quantum-classical algorithm\ndesigned for noisy intermediate-scale quantum (NISQ) computers. It is promising\nfor quantum chemical calculations (QCC) because it can calculate the\nground-state energy of a target molecule. Although VQE has a potential to\nachieve a higher accuracy than classical approximation methods in QCC, it is\nchallenging to achieve it on current NISQ computers due to the significant\nimpact of noises. Density matrix embedding theory (DMET) is a well-known\ntechnique to divide a molecule into multiple fragments, which is available to\nmitigate the noise impact on VQE. However, our preliminary evaluation shows\nthat the naive combination of DMET and VQE does not outperform a gold standard\nclassical method.\n  In this work, we present three approaches to mitigate the noise impact for\nthe DMET+VQE combination. (1) The size of quantum circuits used by VQE is\ndecreased by reducing the number of bath orbitals which represent interactions\nbetween multiple fragments in DMET. (2) Reduced density matrices (RDMs), which\nare used to calculate a molecular energy in DMET, are calculated accurately\nbased on expectation values obtained by executing quantum circuits using a\nnoise-less quantum computer simulator. (3) The parameters of a quantum circuit\noptimized by VQE are refined with mathematical post-processing. The evaluation\nusing a noisy quantum computer simulator shows that our approaches\nsignificantly improve the accuracy of the DMET+VQE combination. Moreover, we\ndemonstrate that on a real NISQ device, the DMET+VQE combination applying our\nthree approaches achieves a higher accuracy than the gold standard classical\nmethod.",
            "author": [
                "Naoki Iijima",
                "Satoshi Imamura",
                "Mikio Morita",
                "Sho Takemori",
                "Akihiko Kasagi",
                "Yuhei Umeda",
                "Eiji Yoshida"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09634v1",
                "http://arxiv.org/pdf/2311.09634v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09633v1",
            "title": "Reconciling Radio Tomographic Imaging with Phaseless Inverse Scattering",
            "updated": "2023-11-16T07:35:28Z",
            "published": "2023-11-16T07:35:28Z",
            "summary": "Radio Tomographic Imaging (RTI) is a phaseless imaging approach that can\nprovide shape reconstruction and localization of objects using received signal\nstrength (RSS) measurements. RSS measurements can be straightforwardly obtained\nfrom wireless networks such as Wi-Fi and therefore RTI has been extensively\nresearched and accepted as a good indoor RF imaging technique. However, RTI is\nformulated on empirical models using an assumption of light-of-sight (LOS)\npropagation that does not account for intricate scattering effects. There are\ntwo main objectives of this work. The first objective is to reconcile and\ncompare the empirical RTI model with formal inverse scattering approaches to\nbetter understand why RTI is an effective RF imaging technique. The second\nobjective is to obtain straightforward enhancements to RTI, based on inverse\nscattering, to enhance its performance. The resulting enhancements can provide\nreconstructions of the shape and also material properties of the objects that\ncan aid image classification. We also provide numerical and experimental\nresults to compare RTI with the enhanced RTI for indoor imaging applications\nusing low-cost 2.4 GHz Wi-Fi transceivers. These results show that the enhanced\nRTI can outperform RTI while having similar computational complexity to RTI.",
            "author": [
                "Amartansh Dubey",
                "Zan Li",
                "Ross Murch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09633v1",
                "http://arxiv.org/pdf/2311.09633v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "eess.SP",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00029v1",
            "title": "Bergeron: Combating Adversarial Attacks through a Conscience-Based\n  Alignment Framework",
            "updated": "2023-11-16T07:31:18Z",
            "published": "2023-11-16T07:31:18Z",
            "summary": "Modern Large language models (LLMs) can still generate responses that may not\nbe aligned with human expectations or values. While many weight-based alignment\nmethods have been proposed, many of them still leave models vulnerable to\nattacks when used on their own. To help mitigate this issue, we introduce\nBergeron, a framework designed to improve the robustness of LLMs against\nadversarial attacks. Bergeron employs a two-tiered architecture. Here, a\nsecondary LLM serves as a simulated conscience that safeguards a primary LLM.\nWe do this by monitoring for and correcting potentially harmful text within\nboth the prompt inputs and the generated outputs of the primary LLM. Empirical\nevaluation shows that Bergeron can improve the alignment and robustness of\nseveral popular LLMs without costly fine-tuning. It aids both open-source and\nblack-box LLMs by complementing and reinforcing their existing alignment\ntraining.",
            "author": [
                "Matthew Pisano",
                "Peter Ly",
                "Abraham Sanders",
                "Bingsheng Yao",
                "Dakuo Wang",
                "Tomek Strzalkowski",
                "Mei Si"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00029v1",
                "http://arxiv.org/pdf/2312.00029v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09632v1",
            "title": "Online Continual Knowledge Learning for Language Models",
            "updated": "2023-11-16T07:31:03Z",
            "published": "2023-11-16T07:31:03Z",
            "summary": "Large Language Models (LLMs) serve as repositories of extensive world\nknowledge, enabling them to perform tasks such as question-answering and\nfact-checking. However, this knowledge can become obsolete as global contexts\nchange. In this paper, we introduce a novel problem in the realm of continual\nlearning: Online Continual Knowledge Learning (OCKL). This problem formulation\naims to manage the dynamic nature of world knowledge in LMs under real-time\nconstraints. We propose a new benchmark and evaluation metric designed to\nmeasure both the rate of new knowledge acquisition and the retention of\npreviously learned knowledge. Our empirical evaluation, conducted using a\nvariety of state-of-the-art methods, establishes robust base-lines for OCKL.\nOur results reveal that existing continual learning approaches are\nunfortunately insufficient for tackling the unique challenges posed by OCKL. We\nidentify key factors that influence the trade-off between knowledge acquisition\nand retention, thereby advancing our understanding of how to train LMs in a\ncontinually evolving environment.",
            "author": [
                "Yuhao Wu",
                "Tongjun Shi",
                "Karthick Sharma",
                "Chun Wei Seah",
                "Shuhao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09632v1",
                "http://arxiv.org/pdf/2311.09632v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09631v2",
            "title": "On the Pauli Spectrum of QAC0",
            "updated": "2023-11-17T17:47:21Z",
            "published": "2023-11-16T07:25:06Z",
            "summary": "The circuit class $\\mathsf{QAC}^0$ was introduced by Moore (1999) as a model\nfor constant depth quantum circuits where the gate set includes many-qubit\nToffoli gates. Proving lower bounds against such circuits is a longstanding\nchallenge in quantum circuit complexity; in particular, showing that\npolynomial-size $\\mathsf{QAC}^0$ cannot compute the parity function has\nremained an open question for over 20 years.\n  In this work, we identify a notion of the Pauli spectrum of $\\mathsf{QAC}^0$\ncircuits, which can be viewed as the quantum analogue of the Fourier spectrum\nof classical $\\mathsf{AC}^0$ circuits. We conjecture that the Pauli spectrum of\n$\\mathsf{QAC}^0$ circuits satisfies low-degree concentration, in analogy to the\nfamous Linial, Nisan, Mansour theorem on the low-degree Fourier concentration\nof $\\mathsf{AC}^0$ circuits. If true, this conjecture immediately implies that\npolynomial-size $\\mathsf{QAC}^0$ circuits cannot compute parity.\n  We prove this conjecture for the class of depth-$d$, polynomial-size\n$\\mathsf{QAC}^0$ circuits with at most $n^{O(1/d)}$ auxiliary qubits. We obtain\nnew circuit lower bounds and learning results as applications: this class of\ncircuits cannot correctly compute\n  - the $n$-bit parity function on more than $(\\frac{1}{2} +\n2^{-\\Omega(n^{1/d})})$-fraction of inputs, and\n  - the $n$-bit majority function on more than $(1 -\n1/\\mathrm{poly}(n))$-fraction of inputs.\n  Additionally we show that this class of $\\mathsf{QAC}^0$ circuits with\nlimited auxiliary qubits can be learned with quasipolynomial sample complexity,\ngiving the first learning result for $\\mathsf{QAC}^0$ circuits.\n  More broadly, our results add evidence that \"Pauli-analytic\" techniques can\nbe a powerful tool in studying quantum circuits.",
            "author": [
                "Shivam Nadimpalli",
                "Natalie Parham",
                "Francisca Vasconcelos",
                "Henry Yuen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09631v2",
                "http://arxiv.org/pdf/2311.09631v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09630v1",
            "title": "From Scroll to Misbelief: Modeling the Unobservable Susceptibility to\n  Misinformation on Social Media",
            "updated": "2023-11-16T07:22:56Z",
            "published": "2023-11-16T07:22:56Z",
            "summary": "Susceptibility to misinformation describes the extent to believe unverifiable\nclaims, which is hidden in people's mental process and infeasible to observe.\nExisting susceptibility studies heavily rely on the self-reported beliefs,\nmaking any downstream applications on susceptability hard to scale. To address\nthese limitations, in this work, we propose a computational model to infer\nusers' susceptibility levels given their activities. Since user's\nsusceptibility is a key indicator for their reposting behavior, we utilize the\nsupervision from the observable sharing behavior to infer the underlying\nsusceptibility tendency. The evaluation shows that our model yields estimations\nthat are highly aligned with human judgment on users' susceptibility level\ncomparisons. Building upon such large-scale susceptibility labeling, we further\nconduct a comprehensive analysis of how different social factors relate to\nsusceptibility. We find that political leanings and psychological factors are\nassociated with susceptibility in varying degrees.",
            "author": [
                "Yanchen Liu",
                "Mingyu Derek Ma",
                "Wenna Qin",
                "Azure Zhou",
                "Jiaao Chen",
                "Weiyan Shi",
                "Wei Wang",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09630v1",
                "http://arxiv.org/pdf/2311.09630v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09627v1",
            "title": "CRISPR: Eliminating Bias Neurons from an Instruction-following Language\n  Model",
            "updated": "2023-11-16T07:16:55Z",
            "published": "2023-11-16T07:16:55Z",
            "summary": "Large language models (LLMs) executing tasks through instruction-based\nprompts often face challenges stemming from distribution differences between\nuser instructions and training instructions. This leads to distractions and\nbiases, especially when dealing with inconsistent dynamic labels. In this\npaper, we introduces a novel bias mitigation method, CRISPR, designed to\nalleviate instruction-label biases in LLMs. CRISPR utilizes attribution methods\nto identify bias neurons influencing biased outputs and employs pruning to\neliminate the bias neurons. Experimental results demonstrate the method's\neffectiveness in mitigating biases in instruction-based prompting, enhancing\nlanguage model performance on social bias benchmarks without compromising\npre-existing knowledge. CRISPR proves highly practical, model-agnostic,\noffering flexibility in adapting to evolving social biases.",
            "author": [
                "Nakyeong Yang",
                "Taegwan Kang",
                "Kyomin Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09627v1",
                "http://arxiv.org/pdf/2311.09627v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09625v1",
            "title": "DECDM: Document Enhancement using Cycle-Consistent Diffusion Models",
            "updated": "2023-11-16T07:16:02Z",
            "published": "2023-11-16T07:16:02Z",
            "summary": "The performance of optical character recognition (OCR) heavily relies on\ndocument image quality, which is crucial for automatic document processing and\ndocument intelligence. However, most existing document enhancement methods\nrequire supervised data pairs, which raises concerns about data separation and\nprivacy protection, and makes it challenging to adapt these methods to new\ndomain pairs. To address these issues, we propose DECDM, an end-to-end\ndocument-level image translation method inspired by recent advances in\ndiffusion models. Our method overcomes the limitations of paired training by\nindependently training the source (noisy input) and target (clean output)\nmodels, making it possible to apply domain-specific diffusion models to other\npairs. DECDM trains on one dataset at a time, eliminating the need to scan both\ndatasets concurrently, and effectively preserving data privacy from the source\nor target domain. We also introduce simple data augmentation strategies to\nimprove character-glyph conservation during translation. We compare DECDM with\nstate-of-the-art methods on multiple synthetic data and benchmark datasets,\nsuch as document denoising and {\\color{black}shadow} removal, and demonstrate\nthe superiority of performance quantitatively and qualitatively.",
            "author": [
                "Jiaxin Zhang",
                "Joy Rimchala",
                "Lalla Mouatadid",
                "Kamalika Das",
                "Sricharan Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09625v1",
                "http://arxiv.org/pdf/2311.09625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09623v1",
            "title": "Apoptosis classification using attention based spatio temporal graph\n  convolution neural network",
            "updated": "2023-11-16T07:14:50Z",
            "published": "2023-11-16T07:14:50Z",
            "summary": "Accurate classification of apoptosis plays an important role in cell biology\nresearch. There are many state-of-the-art approaches which use deep CNNs to\nperform the apoptosis classification but these approaches do not account for\nthe cell interaction. Our paper proposes the Attention Graph spatio-temporal\ngraph convolutional network to classify the cell death based on the target\ncells in the video. This method considers the interaction of multiple target\ncells at each time stamp. We model the whole video sequence as a set of graphs\nand classify the target cell in the video as dead or alive. Our method\nencounters both spatial and temporal relationships.",
            "author": [
                "Akash Awasthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09623v1",
                "http://arxiv.org/pdf/2311.09623v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10779v1",
            "title": "Knowledge Plugins: Enhancing Large Language Models for Domain-Specific\n  Recommendations",
            "updated": "2023-11-16T07:09:38Z",
            "published": "2023-11-16T07:09:38Z",
            "summary": "The significant progress of large language models (LLMs) provides a promising\nopportunity to build human-like systems for various practical applications.\nHowever, when applied to specific task domains, an LLM pre-trained on a\ngeneral-purpose corpus may exhibit a deficit or inadequacy in two types of\ndomain-specific knowledge. One is a comprehensive set of domain data that is\ntypically large-scale and continuously evolving. The other is specific working\npatterns of this domain reflected in the data. The absence or inadequacy of\nsuch knowledge impacts the performance of the LLM. In this paper, we propose a\ngeneral paradigm that augments LLMs with DOmain-specific KnowledgE to enhance\ntheir performance on practical applications, namely DOKE. This paradigm relies\non a domain knowledge extractor, working in three steps: 1) preparing effective\nknowledge for the task; 2) selecting the knowledge for each specific sample;\nand 3) expressing the knowledge in an LLM-understandable way. Then, the\nextracted knowledge is incorporated through prompts, without any computational\ncost of model fine-tuning. We instantiate the general paradigm on a widespread\napplication, i.e. recommender systems, where critical item attributes and\ncollaborative filtering signals are incorporated. Experimental results\ndemonstrate that DOKE can substantially improve the performance of LLMs in\nspecific domains.",
            "author": [
                "Jing Yao",
                "Wei Xu",
                "Jianxun Lian",
                "Xiting Wang",
                "Xiaoyuan Yi",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10779v1",
                "http://arxiv.org/pdf/2311.10779v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09622v1",
            "title": "Homography Initialization and Dynamic Weighting Algorithm Based on a\n  Downward-Looking Camera and IMU",
            "updated": "2023-11-16T07:06:55Z",
            "published": "2023-11-16T07:06:55Z",
            "summary": "In recent years, the technology in visual-inertial odometry (VIO) has matured\nconsiderably and has been widely used in many applications. However, we still\nencounter challenges when applying VIO to a micro air vehicle (MAV) equipped\nwith a downward-looking camera. Specifically, VIO cannot compute the correct\ninitialization results during take-off and the cumulative drift is large when\nthe MAV is flying in the air. To overcome these problems, we propose a\nhomographybased initialization method, which utilizes the fact that the\nfeatures detected by the downward-looking camera during take-off are\napproximately on the same plane. Then we introduce the prior normal vector and\nmotion field to make states more accurate. In addition, to deal with the\ncumulative drift, a strategy for dynamically weighting visual residuals is\nproposed. Finally, we evaluate our method on the collected real-world datasets.\nThe results demonstrate that our system can be successfully initialized no\nmatter how the MAV takes off and the positioning errors are also greatly\nimproved.",
            "author": [
                "Bo Dong",
                "Yongkang Tao",
                "Deng Peng",
                "Zhigang Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09622v1",
                "http://arxiv.org/pdf/2311.09622v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09619v1",
            "title": "Take One Step at a Time to Know Incremental Utility of Demonstration: An\n  Analysis on Reranking for Few-Shot In-Context Learning",
            "updated": "2023-11-16T07:03:54Z",
            "published": "2023-11-16T07:03:54Z",
            "summary": "In-Context Learning (ICL) is an emergent capability of Large Language Models\n(LLMs). Only a few demonstrations enable LLMs to be used as blackbox for new\ntasks. Previous studies have shown that using LLMs' outputs as labels is\neffective in training models to select demonstrations. Such a label is expected\nto estimate utility of a demonstration in ICL; however, it has not been well\nunderstood how different labeling strategies affect results on target tasks.\nThis paper presents an analysis on different utility functions by focusing on\nLLMs' output probability given ground-truth output, and task-specific reward\ngiven LLMs' prediction. Unlike the previous work, we introduce a novel labeling\nmethod, incremental utility, which estimates how much incremental knowledge is\nbrought into the LLMs by a demonstration. We conduct experiments with\ninstruction-tuned LLMs on binary/multi-class classification, segmentation, and\ntranslation across Arabic, English, Finnish, Japanese, and Spanish. Our results\nshow that (1) the probability is effective when the probability values are\ndistributed across the whole value range (on the classification tasks), and (2)\nthe downstream metric is more robust when nuanced reward values are provided\nwith long outputs (on the segmentation and translation tasks). We then show\nthat the proposed incremental utility further helps ICL by contrasting how the\nLLMs perform with and without the demonstrations.",
            "author": [
                "Kazuma Hashimoto",
                "Karthik Raman",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09619v1",
                "http://arxiv.org/pdf/2311.09619v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09618v1",
            "title": "Simulating Opinion Dynamics with Networks of LLM-based Agents",
            "updated": "2023-11-16T07:01:48Z",
            "published": "2023-11-16T07:01:48Z",
            "summary": "Accurately simulating human opinion dynamics is crucial for understanding a\nvariety of societal phenomena, including polarization and the spread of\nmisinformation. However, the agent-based models (ABMs) commonly used for such\nsimulations lack fidelity to human behavior. We propose a new approach to\nsimulating opinion dynamics based on populations of Large Language Models\n(LLMs). Our findings reveal a strong inherent bias in LLM agents towards\naccurate information, leading to consensus in line with scientific reality.\nHowever, this bias limits the simulation of individuals with resistant views on\nissues like climate change. After inducing confirmation bias through prompt\nengineering, we observed opinion fragmentation in line with existing\nagent-based research. These insights highlight the promise and limitations of\nLLM agents in this domain and suggest a path forward: refining LLMs with\nreal-world discourse to better simulate the evolution of human beliefs.",
            "author": [
                "Yun-Shiuan Chuang",
                "Agam Goyal",
                "Nikunj Harlalka",
                "Siddharth Suresh",
                "Robert Hawkins",
                "Sijia Yang",
                "Dhavan Shah",
                "Junjie Hu",
                "Timothy T. Rogers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09618v1",
                "http://arxiv.org/pdf/2311.09618v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09615v1",
            "title": "On Retrieval Augmentation and the Limitations of Language Model Training",
            "updated": "2023-11-16T06:59:54Z",
            "published": "2023-11-16T06:59:54Z",
            "summary": "Augmenting a language model (LM) with $k$-nearest neighbors (kNN) retrieval\non its training data alone can decrease its perplexity, though the underlying\nreasons for this remains elusive. In this work, we first rule out one\npreviously posited possibility -- the \"softmax bottleneck.\" We further identify\nthe MLP hurdle phenomenon, where the final MLP layer in LMs may impede LM\noptimization early on. We explore memorization and generalization in language\nmodels with two new datasets, where advanced model like GPT-3.5-turbo find\ngeneralizing to irrelevant information in the training data challenging.\nHowever, incorporating kNN retrieval to vanilla GPT-2 117M can consistently\nimprove performance in this setting.",
            "author": [
                "Ting-Rui Chiang",
                "Xinyan Velocity Yu",
                "Joshua Robinson",
                "Ollie Liu",
                "Isabelle Lee",
                "Dani Yogatama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09615v1",
                "http://arxiv.org/pdf/2311.09615v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09614v1",
            "title": "Comprehensive Evaluation and Insights into the Use of Deep Neural\n  Networks to Detect and Quantify Lymphoma Lesions in PET/CT Images",
            "updated": "2023-11-16T06:58:46Z",
            "published": "2023-11-16T06:58:46Z",
            "summary": "This study performs comprehensive evaluation of four neural network\narchitectures (UNet, SegResNet, DynUNet, and SwinUNETR) for lymphoma lesion\nsegmentation from PET/CT images. These networks were trained, validated, and\ntested on a diverse, multi-institutional dataset of 611 cases. Internal testing\n(88 cases; total metabolic tumor volume (TMTV) range [0.52, 2300] ml) showed\nSegResNet as the top performer with a median Dice similarity coefficient (DSC)\nof 0.76 and median false positive volume (FPV) of 4.55 ml; all networks had a\nmedian false negative volume (FNV) of 0 ml. On the unseen external test set\n(145 cases with TMTV range: [0.10, 2480] ml), SegResNet achieved the best\nmedian DSC of 0.68 and FPV of 21.46 ml, while UNet had the best FNV of 0.41 ml.\nWe assessed reproducibility of six lesion measures, calculated their prediction\nerrors, and examined DSC performance in relation to these lesion measures,\noffering insights into segmentation accuracy and clinical relevance.\nAdditionally, we introduced three lesion detection criteria, addressing the\nclinical need for identifying lesions, counting them, and segmenting based on\nmetabolic characteristics. We also performed expert intra-observer variability\nanalysis revealing the challenges in segmenting ``easy'' vs. ``hard'' cases, to\nassist in the development of more resilient segmentation algorithms. Finally,\nwe performed inter-observer agreement assessment underscoring the importance of\na standardized ground truth segmentation protocol involving multiple expert\nannotators. Code is available at:\nhttps://github.com/microsoft/lymphoma-segmentation-dnn",
            "author": [
                "Shadab Ahamed",
                "Yixi Xu",
                "Claire Gowdy",
                "Joo H. O",
                "Ingrid Bloise",
                "Don Wilson",
                "Patrick Martineau",
                "Fran\u00e7ois B\u00e9nard",
                "Fereshteh Yousefirizi",
                "Rahul Dodhia",
                "Juan M. Lavista",
                "William B. Weeks",
                "Carlos F. Uribe",
                "Arman Rahmim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09614v1",
                "http://arxiv.org/pdf/2311.09614v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10116v1",
            "title": "Wildfire Smoke Detection with Cross Contrast Patch Embedding",
            "updated": "2023-11-16T06:53:03Z",
            "published": "2023-11-16T06:53:03Z",
            "summary": "The Transformer-based deep networks have increasingly shown significant\nadvantages over CNNs. Some existing work has applied it in the field of\nwildfire recognition or detection. However, we observed that the vanilla\nTransformer is not friendly for extracting smoke features. Because low-level\ninformation such as color, transparency and texture is very important for smoke\nrecognition, and transformer pays more attention to the semantic relevance\nbetween middle- or high-level features, and is not sensitive to the subtle\nchanges of low-level features along the space. To solve this problem, we\npropose the Cross Contrast Patch Embedding(CCPE) module based on the Swin\nTransformer, which uses the multi-scales spatial frequency contrast information\nin both vertical and horizontal directions to improve the discrimination of the\nnetwork on the underlying details. The fuzzy boundary of smoke makes the\npositive and negative label assignment for instances in a dilemma, which is\nanother challenge for wildfires detection. To solve this problem, a Separable\nNegative Sampling Mechanism(SNSM) is proposed. By using two different negative\ninstance sampling strategies on positive images and negative images\nrespectively, the problem of supervision signal confusion caused by label\ndiversity in the process of network training is alleviated. This paper also\nreleases the RealFire Test, the largest real wildfire test set so far, to\nevaluate the proposed method and promote future research. It contains 50,535\nimages from 3,649 video clips. The proposed method has been extensively tested\nand evaluated on RealFire Test dataset, and has a significant performance\nimprovement compared with the baseline detection models.",
            "author": [
                "Chong Wang",
                "Cheng Xu",
                "Adeel Akram",
                "Zhilin Shan",
                "Qixing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10116v1",
                "http://arxiv.org/pdf/2311.10116v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09613v1",
            "title": "Digital Socrates: Evaluating LLMs through explanation critiques",
            "updated": "2023-11-16T06:51:46Z",
            "published": "2023-11-16T06:51:46Z",
            "summary": "While LLMs can provide reasoned explanations along with their answers, the\nnature and quality of those explanations are still poorly understood. In\nresponse, our goal is to define a detailed way of characterizing the\nexplanation capabilities of modern models and to create a nuanced,\ninterpretable explanation evaluation tool that can generate such\ncharacterizations automatically, without relying on expensive API calls or\nhuman annotations. Our approach is to (a) define the new task of explanation\ncritiquing - identifying and categorizing any main flaw in an explanation and\nproviding suggestions to address the flaw, (b) create a sizeable,\nhuman-verified dataset for this task, and (c) train an open-source, automatic\ncritiquing model (called Digital Socrates) using this data. Through\nquantitative and qualitative analysis, we demonstrate how Digital Socrates is\nuseful for revealing insights about student models by examining their reasoning\nchains, and how it can provide high-quality, nuanced, automatic evaluation of\nthose model explanations for the first time. Digital Socrates thus fills an\nimportant gap in evaluation tools for understanding and improving the\nexplanation behavior of models.",
            "author": [
                "Yuling Gu",
                "Oyvind Tafjord",
                "Peter Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09613v1",
                "http://arxiv.org/pdf/2311.09613v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09612v1",
            "title": "Efficient End-to-End Visual Document Understanding with Rationale\n  Distillation",
            "updated": "2023-11-16T06:50:26Z",
            "published": "2023-11-16T06:50:26Z",
            "summary": "Understanding visually situated language requires recognizing text and visual\nelements, and interpreting complex layouts. State-of-the-art methods commonly\nuse specialized pre-processing tools, such as optical character recognition\n(OCR) systems, that map document image inputs to extracted information in the\nspace of textual tokens, and sometimes also employ large language models (LLMs)\nto reason in text token space. However, the gains from external tools and LLMs\ncome at the cost of increased computational and engineering complexity. In this\npaper, we ask whether small pretrained image-to-text models can learn selective\ntext or layout recognition and reasoning as an intermediate inference step in\nan end-to-end model for pixel-level visual language understanding. We\nincorporate the outputs of such OCR tools, LLMs, and larger multimodal models\nas intermediate ``rationales'' on training data, and train a small student\nmodel to predict both rationales and answers for input questions based on those\ntraining examples. A student model based on Pix2Struct (282M parameters)\nachieves consistent improvements on three visual document understanding\nbenchmarks representing infographics, scanned documents, and figures, with\nimprovements of more than 4\\% absolute over a comparable Pix2Struct model that\npredicts answers directly.",
            "author": [
                "Wang Zhu",
                "Alekh Agarwal",
                "Mandar Joshi",
                "Robin Jia",
                "Jesse Thomason",
                "Kristina Toutanova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09612v1",
                "http://arxiv.org/pdf/2311.09612v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09611v1",
            "title": "DeltaLCA: Comparative Life-Cycle Assessment for Electronics Design",
            "updated": "2023-11-16T06:45:49Z",
            "published": "2023-11-16T06:45:49Z",
            "summary": "Reducing the environmental footprint of electronics and computing devices\nrequires new tools that empower designers to make informed decisions about\nsustainability during the design process itself. This is not possible with\ncurrent tools for life cycle assessment (LCA) which require substantial domain\nexpertise and time to evaluate the numerous chips and other components that\nmake up a device. We observe first that informed decision-making does not\nrequire absolute metrics and can instead be done by comparing designs. Second,\nwe can use domain-specific heuristics to perform these comparisons. We combine\nthese insights to develop DeltaLCA, an open-source interactive design tool that\naddresses the dual challenges of automating life cycle inventory generation and\ndata availability by performing comparative analyses of electronics designs.\nUsers can upload standard design files from Electronic Design Automation (EDA)\nsoftware and the tool will guide them through determining which one has greater\ncarbon footprint. DeltaLCA leverages electronics-specific LCA datasets and\nheuristics and tries to automatically rank the two designs, prompting users to\nprovide additional information only when necessary. We show through case\nstudies DeltaLCA achieves the same result as evaluating full LCAs, and that it\naccelerates LCA comparisons from eight expert-hours to a single click for\ndevices with ~30 components, and 15 minutes for more complex devices with ~100\ncomponents.",
            "author": [
                "Zhihan Zhang",
                "Felix H\u00e4hnlein",
                "Yuxuan Mei",
                "Zachary Englhardt",
                "Shwetak Patel",
                "Adriana Schulz",
                "Vikram Iyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09611v1",
                "http://arxiv.org/pdf/2311.09611v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09610v1",
            "title": "Weak breakdown of bulk-boundary correspondence in a symmetry-protected\n  topological phase out-of-equilibrium",
            "updated": "2023-11-16T06:44:03Z",
            "published": "2023-11-16T06:44:03Z",
            "summary": "Time evolution of topological systems is an active area of interest due to\ntheir expected uses in fault tolerant quantum computing. Here, we analyze the\ndynamics of a non-interacting spinless fermion chain in its topological phase,\nwhen the system is quenched out-of-equilibrium by a Hamiltonian belonging to\nthe same symmetry class. Due to the presence of particle-hole symmetry, we find\nthat the bulk properties of the system remain intact throughout the evolution.\nHowever, the boundary properties may be drastically altered, where we see\ndelocalization of initially localized Majorana edge modes. The presence of\nlocal static disorder can be utilized to preserve exponential localization, yet\nwe still identify non-trivial dynamics in the Majorana polarization and\nLoschmidt echo. We find that, due to delocalization, the entanglement spectrum\nis no longer a good indicator of the bulk topological phase, as the system\nremains non-trivial while degeneracies in the many-body entanglement spectrum\nare lost.",
            "author": [
                "Thomas L. M. Lane",
                "Mikl\u00f3s Horv\u00e1th",
                "Kristian Patrick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09610v1",
                "http://arxiv.org/pdf/2311.09610v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.mes-hall",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09608v1",
            "title": "Deep Neural Helmholtz Operators for 3D Elastic Wave Propagation and\n  Inversion",
            "updated": "2023-11-16T06:37:47Z",
            "published": "2023-11-16T06:37:47Z",
            "summary": "Numerical simulations of seismic wave propagation in heterogeneous 3D media\nare central to investigating subsurface structures and understanding earthquake\nprocesses, yet are computationally expensive for large problems. This is\nparticularly problematic for full waveform inversion, which typically involves\nnumerous runs of the forward process. In machine learning there has been\nconsiderable recent work in the area of operator learning, with a new class of\nmodels called neural operators allowing for data-driven solutions to partial\ndifferential equations. Recent works in seismology have shown that when neural\noperators are adequately trained, they can significantly shorten the compute\ntime for wave propagation. However, the memory required for the 3D time domain\nequations may be prohibitive. In this study, we show that these limitations can\nbe overcome by solving the wave equations in the frequency domain, also known\nas the Helmholtz equations, since the solutions for a set of frequencies can be\ndetermined in parallel. The 3D Helmholtz neural operator is 40 times more\nmemory-efficient than an equivalent time-domain version. We employ a U-shaped\nneural operator for 2D and 3D elastic wave modeling, achieving two orders of\nmagnitude acceleration compared to a baseline spectral element method. The\nneural operator accurately generalizes to variable velocity structures and can\nbe evaluated on denser input meshes than used in the training simulations. We\nalso show that when solving for wavefields strictly on the surface, the\naccuracy can be significantly improved via a graph neural operator layer. In\nleveraging automatic differentiation, the proposed method can serve as an\nalternative to the adjoint-state approach for 3D full-waveform inversion,\nreducing the computation time by a factor of 350.",
            "author": [
                "Caifeng Zou",
                "Kamyar Azizzadenesheli",
                "Zachary E. Ross",
                "Robert W. Clayton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09608v1",
                "http://arxiv.org/pdf/2311.09608v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09607v1",
            "title": "Multi-Task Learning Approach for Unified Biometric Estimation from Fetal\n  Ultrasound Anomaly Scans",
            "updated": "2023-11-16T06:35:02Z",
            "published": "2023-11-16T06:35:02Z",
            "summary": "Precise estimation of fetal biometry parameters from ultrasound images is\nvital for evaluating fetal growth, monitoring health, and identifying potential\ncomplications reliably. However, the automated computerized segmentation of the\nfetal head, abdomen, and femur from ultrasound images, along with the\nsubsequent measurement of fetal biometrics, remains challenging. In this work,\nwe propose a multi-task learning approach to classify the region into head,\nabdomen and femur as well as estimate the associated parameters. We were able\nto achieve a mean absolute error (MAE) of 1.08 mm on head circumference, 1.44\nmm on abdomen circumference and 1.10 mm on femur length with a classification\naccuracy of 99.91\\% on a dataset of fetal Ultrasound images. To achieve this,\nwe leverage a weighted joint classification and segmentation loss function to\ntrain a U-Net architecture with an added classification head. The code can be\naccessed through\n\\href{https://github.com/BioMedIA-MBZUAI/Multi-Task-Learning-Approach-for-Unified-Biometric-Estimation-from-Fetal-Ultrasound-Anomaly-Scans.git}{\\texttt{Github}",
            "author": [
                "Mohammad Areeb Qazi",
                "Mohammed Talha Alam",
                "Ibrahim Almakky",
                "Werner Gerhard Diehl",
                "Leanne Bricker",
                "Mohammad Yaqub"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09607v1",
                "http://arxiv.org/pdf/2311.09607v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10778v1",
            "title": "uHD: Unary Processing for Lightweight and Dynamic Hyperdimensional\n  Computing",
            "updated": "2023-11-16T06:28:19Z",
            "published": "2023-11-16T06:28:19Z",
            "summary": "Hyperdimensional computing (HDC) is a novel computational paradigm that\noperates on long-dimensional vectors known as hypervectors. The hypervectors\nare constructed as long bit-streams and form the basic building blocks of HDC\nsystems. In HDC, hypervectors are generated from scalar values without taking\ntheir bit significance into consideration. HDC has been shown to be efficient\nand robust in various data processing applications, including computer vision\ntasks. To construct HDC models for vision applications, the current\nstate-of-the-art practice utilizes two parameters for data encoding: pixel\nintensity and pixel position. However, the intensity and position information\nembedded in high-dimensional vectors are generally not generated dynamically in\nthe HDC models. Consequently, the optimal design of hypervectors with high\nmodel accuracy requires powerful computing platforms for training. A more\nefficient approach to generating hypervectors is to create them dynamically\nduring the training phase, which results in accurate, low-cost, and highly\nperformable vectors. To this aim, we use low-discrepancy sequences to generate\nintensity hypervectors only, while avoiding position hypervectors. By doing so,\nthe multiplication step in vector encoding is eliminated, resulting in a\npower-efficient HDC system. For the first time in the literature, our proposed\napproach employs lightweight vector generators utilizing unary bit-streams for\nefficient encoding of data instead of using conventional comparator-based\ngenerators.",
            "author": [
                "Sercan Aygun",
                "Mehran Shoushtari Moghadam",
                "M. Hassan Najafi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10778v1",
                "http://arxiv.org/pdf/2311.10778v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09606v1",
            "title": "GistScore: Learning Better Representations for In-Context Example\n  Selection with Gist Bottlenecks",
            "updated": "2023-11-16T06:28:05Z",
            "published": "2023-11-16T06:28:05Z",
            "summary": "Large language models (LLMs) have the ability to perform in-context learning\n(ICL) of new tasks by conditioning on prompts comprising a few task examples.\nThis work studies the problem of selecting the best examples given a candidate\npool to improve ICL performance on given a test input. Existing approaches\neither require training with feedback from a much larger LLM or are\ncomputationally expensive. We propose a novel metric, GistScore, based on\nExample Gisting, a novel approach for training example retrievers for ICL using\nan attention bottleneck via Gisting, a recent technique for compressing task\ninstructions. To tradeoff performance with ease of use, we experiment with both\nfine-tuning gist models on each dataset and multi-task training a single model\non a large collection of datasets. On 21 diverse datasets spanning 9 tasks, we\nshow that our fine-tuned models get state-of-the-art ICL performance with 20%\nabsolute average gain over off-the-shelf retrievers and 7% over the best prior\nmethods. Our multi-task model generalizes well out-of-the-box to new task\ncategories, datasets, and prompt templates with retrieval speeds that are\nconsistently thousands of times faster than the best prior training-free\nmethod.",
            "author": [
                "Shivanshu Gupta",
                "Clemens Rosenbaum",
                "Ethan R. Elenberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09606v1",
                "http://arxiv.org/pdf/2311.09606v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09605v1",
            "title": "Measuring and Improving Attentiveness to Partial Inputs with\n  Counterfactuals",
            "updated": "2023-11-16T06:27:35Z",
            "published": "2023-11-16T06:27:35Z",
            "summary": "The inevitable appearance of spurious correlations in training datasets hurts\nthe generalization of NLP models on unseen data. Previous work has found that\ndatasets with paired inputs are prone to correlations between a specific part\nof the input (e.g., the hypothesis in NLI) and the label; consequently, models\ntrained only on those outperform chance. Are these correlations picked up by\nmodels trained on the full input data? To address this question, we propose a\nnew evaluation method, Counterfactual Attentiveness Test (CAT). CAT uses\ncounterfactuals by replacing part of the input with its counterpart from a\ndifferent example (subject to some restrictions), expecting an attentive model\nto change its prediction. Using CAT, we systematically investigate established\nsupervised and in-context learning models on ten datasets spanning four tasks:\nnatural language inference, reading comprehension, paraphrase detection, and\nvisual & language reasoning. CAT reveals that reliance on such correlations is\nmainly data-dependent. Surprisingly, we find that GPT3 becomes less attentive\nwith an increased number of demonstrations, while its accuracy on the test data\nimproves. Our results demonstrate that augmenting training or demonstration\ndata with counterfactuals is effective in improving models' attentiveness. We\nshow that models' attentiveness measured by CAT reveals different conclusions\nfrom solely measuring correlations in data.",
            "author": [
                "Yanai Elazar",
                "Bhargavi Paranjape",
                "Hao Peng",
                "Sarah Wiegreffe",
                "Khyathi Raghavi",
                "Vivek Srikumar",
                "Sameer Singh",
                "Noah A. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09605v1",
                "http://arxiv.org/pdf/2311.09605v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09603v1",
            "title": "SCORE: A framework for Self-Contradictory Reasoning Evaluation",
            "updated": "2023-11-16T06:22:17Z",
            "published": "2023-11-16T06:22:17Z",
            "summary": "Large language models (LLMs) have demonstrated impressive reasoning ability\nin various language-based tasks. Despite many proposed reasoning methods aimed\nat enhancing performance in downstream tasks, two fundamental questions\npersist: Does reasoning genuinely support predictions, and how reliable is the\nquality of reasoning? In this paper, we propose a framework \\textsc{SCORE} to\nanalyze how well LLMs can reason. Specifically, we focus on self-contradictory\nreasoning, where reasoning does not support the prediction. We find that LLMs\noften contradict themselves when performing reasoning tasks that involve\ncontextual information and commonsense. The model may miss evidence or use\nshortcuts, thereby exhibiting self-contradictory behaviors. We also employ the\nPoint-of-View (POV) method, which probes models to generate reasoning from\nmultiple perspectives, as a diagnostic tool for further analysis. We find that\nthough LLMs may appear to perform well in one-perspective settings, they fail\nto stabilize such behavior in multi-perspectives settings. Even for correct\npredictions, the reasoning may be messy and incomplete, and LLMs can easily be\nled astray from good reasoning. \\textsc{SCORE}'s results underscore the lack of\nrobustness required for trustworthy reasoning and the urgency for further\nresearch to establish best practices for a comprehensive evaluation of\nreasoning beyond accuracy-based metrics.",
            "author": [
                "Ziyi Liu",
                "Isabelle Lee",
                "Yongkang Du",
                "Soumya Sanyal",
                "Jieyu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09603v1",
                "http://arxiv.org/pdf/2311.09603v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09602v1",
            "title": "Language Models (Mostly) Do Not Consider Emotion Triggers When\n  Predicting Emotion",
            "updated": "2023-11-16T06:20:13Z",
            "published": "2023-11-16T06:20:13Z",
            "summary": "Situations and events evoke emotions in humans, but to what extent do they\ninform the prediction of emotion detection models? Prior work in emotion\ntrigger or cause identification focused on training models to recognize events\nthat trigger an emotion. Instead, this work investigates how well\nhuman-annotated emotion triggers correlate with features that models deemed\nsalient in their prediction of emotions. First, we introduce a novel dataset\nEmoTrigger, consisting of 900 social media posts sourced from three different\ndatasets; these were annotated by experts for emotion triggers with high\nagreement. Using EmoTrigger, we evaluate the ability of large language models\n(LLMs) to identify emotion triggers, and conduct a comparative analysis of the\nfeatures considered important for these tasks between LLMs and fine-tuned\nmodels. Our analysis reveals that emotion triggers are largely not considered\nsalient features for emotion prediction models, instead there is intricate\ninterplay between various features and the task of emotion detection.",
            "author": [
                "Smriti Singh",
                "Cornelia Caragea",
                "Junyi Jessy Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09602v1",
                "http://arxiv.org/pdf/2311.09602v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09600v1",
            "title": "Homology and twisted C*-algebras for self-similar actions and\n  Zappa-Sz\u00e9p products",
            "updated": "2023-11-16T06:19:18Z",
            "published": "2023-11-16T06:19:18Z",
            "summary": "We study the categorical homology of Zappa-Sz\\'ep products of small\ncategories, which include all self-similar actions. We prove that the\ncategorical homology coincides with the homology of a double complex, and so\ncan be computed via a spectral sequence involving homology groups of the\nconstituent categories. We give explicit formulae for the isomorphisms\ninvolved, and compute the homology of a class of examples that generalise\nodometers. We define the C*-algebras of self-similar groupoid actions on\nk-graphs twisted by 2-cocycles arising from this homology theory, and prove\nsome fundamental results about their structure.",
            "author": [
                "Alexander Mundey",
                "Aidan Sims"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09600v1",
                "http://arxiv.org/pdf/2311.09600v1"
            ],
            "primary_category": "math.KT",
            "category": [
                "math.KT",
                "math.OA",
                "18G15 (primary) 18A32, 46L05 (secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09599v1",
            "title": "Gradual Source Domain Expansion for Unsupervised Domain Adaptation",
            "updated": "2023-11-16T06:18:35Z",
            "published": "2023-11-16T06:18:35Z",
            "summary": "Unsupervised domain adaptation (UDA) tries to overcome the need for a large\nlabeled dataset by transferring knowledge from a source dataset, with lots of\nlabeled data, to a target dataset, that has no labeled data. Since there are no\nlabels in the target domain, early misalignment might propagate into the later\nstages and lead to an error build-up. In order to overcome this problem, we\npropose a gradual source domain expansion (GSDE) algorithm. GSDE trains the UDA\ntask several times from scratch, each time reinitializing the network weights,\nbut each time expands the source dataset with target data. In particular, the\nhighest-scoring target data of the previous run are employed as pseudo-source\nsamples with their respective pseudo-label. Using this strategy, the\npseudo-source samples induce knowledge extracted from the previous run directly\nfrom the start of the new training. This helps align the two domains better,\nespecially in the early training epochs. In this study, we first introduce a\nstrong baseline network and apply our GSDE strategy to it. We conduct\nexperiments and ablation studies on three benchmarks (Office-31, OfficeHome,\nand DomainNet) and outperform state-of-the-art methods. We further show that\nthe proposed GSDE strategy can improve the accuracy of a variety of different\nstate-of-the-art UDA approaches.",
            "author": [
                "Thomas Westfechtel",
                "Hao-Wei Yeh",
                "Dexuan Zhang",
                "Tatsuya Harada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09599v1",
                "http://arxiv.org/pdf/2311.09599v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09596v1",
            "title": "Generating Drug Repurposing Hypotheses through the Combination of\n  Disease-Specific Hypergraphs",
            "updated": "2023-11-16T06:09:14Z",
            "published": "2023-11-16T06:09:14Z",
            "summary": "The drug development pipeline for a new compound can last 10-20 years and\ncost over 10 billion. Drug repurposing offers a more time- and cost-effective\nalternative. Computational approaches based on biomedical knowledge graph\nrepresentations have recently yielded new drug repurposing hypotheses. In this\nstudy, we present a novel, disease-specific hypergraph representation learning\ntechnique to derive contextual embeddings of biological pathways of various\nlengths but that all start at any given drug and all end at the disease of\ninterest. Further, we extend this method to multi-disease hypergraphs. To\ndetermine the repurposing potential of each of the 1,522 drugs, we derive\ndrug-specific distributions of cosine similarity values and ultimately consider\nthe median for ranking. Cosine similarity values are computed between (1) all\nbiological pathways starting at the considered drug and ending at the disease\nof interest and (2) all biological pathways starting at drugs currently\nprescribed against that disease and ending at the disease of interest. We\nillustrate our approach with Alzheimer's disease (AD) and two of its risk\nfactors: hypertension (HTN) and type 2 diabetes (T2D). We compare each drug's\nrank across four hypergraph settings (single- or multi-disease): AD only, AD +\nHTN, AD + T2D, and AD + HTN + T2D. Notably, our framework led to the\nidentification of two promising drugs whose repurposing potential was\nsignificantly higher in hypergraphs combining two diseases: dapagliflozin\n(antidiabetic; moved up, from top 32$\\%$ to top 7$\\%$, across all considered\ndrugs) and debrisoquine (antihypertensive; moved up, from top 76$\\%$ to top\n23$\\%$). Our approach serves as a hypothesis generation tool, to be paired with\na validation pipeline relying on laboratory experiments and semi-automated\nparsing of the biomedical literature.",
            "author": [
                "Ayush Jain",
                "Marie Laure-Charpignon",
                "Irene Y. Chen",
                "Anthony Philippakis",
                "Ahmed Alaa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09596v1",
                "http://arxiv.org/pdf/2311.09596v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09595v1",
            "title": "Logarithmic corrections for near-extremal black holes",
            "updated": "2023-11-16T06:07:26Z",
            "published": "2023-11-16T06:07:26Z",
            "summary": "We present the computation of logarithmic corrections to near-extremal black\nhole entropy from one-loop Euclidean gravity path integral around the\nnear-horizon geometry. We extract these corrections employing a suitably\nmodified heat kernel method, where the near-extremal near-horizon geometry is\ntreated as a perturbation around the extremal near-horizon geometry. Using this\nmethod we compute the logarithmic corrections to non-rotating solutions in four\ndimensional Einstein-Maxwell and $\\mathcal{N} = 2,4,8$ supergravity theories.\nWe also discuss the limit that suitably recovers the extremal black hole\nresults.",
            "author": [
                "Nabamita Banerjee",
                "Muktajyoti Saha",
                "Suthanth Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09595v1",
                "http://arxiv.org/pdf/2311.09595v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09593v1",
            "title": "Multi-Step Dialogue Workflow Action Prediction",
            "updated": "2023-11-16T06:05:47Z",
            "published": "2023-11-16T06:05:47Z",
            "summary": "In task-oriented dialogue, a system often needs to follow a sequence of\nactions, called a workflow, that complies with a set of guidelines in order to\ncomplete a task. In this paper, we propose the novel problem of multi-step\nworkflow action prediction, in which the system predicts multiple future\nworkflow actions. Accurate prediction of multiple steps allows for multi-turn\nautomation, which can free up time to focus on more complex tasks. We propose\nthree modeling approaches that are simple to implement yet lead to more action\nautomation: 1) fine-tuning on a training dataset, 2) few-shot in-context\nlearning leveraging retrieval and large language model prompting, and 3)\nzero-shot graph traversal, which aggregates historical action sequences into a\ngraph for prediction. We show that multi-step action prediction produces\nfeatures that improve accuracy on downstream dialogue tasks like predicting\ntask success, and can increase automation of steps by 20% without requiring as\nmuch feedback from a human overseeing the system.",
            "author": [
                "Ramya Ramakrishnan",
                "Ethan Elenberg",
                "Hashan Narangodage",
                "Ryan McDonald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09593v1",
                "http://arxiv.org/pdf/2311.09593v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09592v2",
            "title": "Scalable and Adaptively Secure Any-Trust Distributed Key Generation and\n  All-hands Checkpointing",
            "updated": "2023-11-17T12:22:36Z",
            "published": "2023-11-16T06:05:01Z",
            "summary": "The classical distributed key generation protocols (DKG) are resurging due to\ntheir widespread applications in blockchain. While efforts have been made to\nimprove DKG communication, practical large scale deployments are still yet to\ncome, due to various challenges including broadcast channel scalability and\nworst-case complaint phase. In this paper, we propose a practical DKG for\nDL-based cryptosystems, with only (quasi-)linear computation/communication cost\nper participant, with the help of a public ledger, and beacon; Notably, our DKG\nonly incurs constant-size blockchain storage cost for broadcast, even in the\nface of worst-case complaints. Moreover, our protocol satisfies adaptive\nsecurity. The key to our improvements lies in delegating the most costly\noperations to an Any-Trust group. This group is randomly sampled and consists\nof a small number of individuals. The population only trusts that at least one\nmember in the group is honest, without knowing which one. Additionally, we\nintroduce an extended broadcast channel based on a blockchain and data\ndispersal network (such as IPFS), enabling reliable broadcasting of\narbitrary-size messages at the cost of constant-size blockchain storage, which\nmay be of independent interest.\n  Our DKG leads to a fully practical instantiation of Filecoin's checkpointing\nmechanism, in which all validators of a Proof-of-Stake (PoS) blockcahin\nperiodically run DKG and threshold signing to create checkpoints on Bitcoin,\nthereby enhancing the security of the PoS chain. In comparison with another\ncheckpointing approach of Babylon (Oakland, 2023), ours enjoys a significally\nsmaller monetary cost of Bitcoin transaction fees. For a PoS chain with\n$2^{12}$ validators, our cost is merely 0.6\\% of that incurred by Babylon's\napproach.",
            "author": [
                "Hanwen Feng",
                "Tiancheng Mai",
                "Qiang Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09592v2",
                "http://arxiv.org/pdf/2311.09592v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09590v1",
            "title": "MARformer: An Efficient Metal Artifact Reduction Transformer for Dental\n  CBCT Images",
            "updated": "2023-11-16T06:02:03Z",
            "published": "2023-11-16T06:02:03Z",
            "summary": "Cone Beam Computed Tomography (CBCT) plays a key role in dental diagnosis and\nsurgery. However, the metal teeth implants could bring annoying metal artifacts\nduring the CBCT imaging process, interfering diagnosis and downstream\nprocessing such as tooth segmentation. In this paper, we develop an efficient\nTransformer to perform metal artifacts reduction (MAR) from dental CBCT images.\nThe proposed MAR Transformer (MARformer) reduces computation complexity in the\nmultihead self-attention by a new Dimension-Reduced Self-Attention (DRSA)\nmodule, based on that the CBCT images have globally similar structure. A\nPatch-wise Perceptive Feed Forward Network (P2FFN) is also proposed to perceive\nlocal image information for fine-grained restoration. Experimental results on\nCBCT images with synthetic and real-world metal artifacts show that our\nMARformer is efficient and outperforms previous MAR methods and two restoration\nTransformers.",
            "author": [
                "Yuxuan Shi",
                "Jun Xu",
                "Dinggang Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09590v1",
                "http://arxiv.org/pdf/2311.09590v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10777v3",
            "title": "A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,\n  Methods, and Trends",
            "updated": "2023-12-03T05:50:36Z",
            "published": "2023-11-16T06:01:47Z",
            "summary": "Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment\nanalysis (SA) that identifies aspects and the associated opinions from a given\ntext. In the digital era, ABSA gained increasing popularity and applications in\nmining opinionated text data to obtain insights and support decisions. ABSA\nresearch employs linguistic, statistical, and machine-learning approaches and\nutilises resources such as labelled datasets, aspect and sentiment lexicons and\nontology. By its nature, ABSA is domain-dependent and can be sensitive to the\nimpact of misalignment between the resource and application domains. However,\nto our knowledge, this topic has not been explored by the existing ABSA\nliterature reviews. In this paper, we present a Systematic Literature Review\n(SLR) of ABSA studies with a focus on the research application domain, dataset\ndomain, and the research methods to examine their relationships and identify\ntrends over time. Our results suggest a number of potential systemic issues in\nthe ABSA research literature, including the predominance of the\n``product/service review'' dataset domain among the majority of studies that\ndid not have a specific research application domain, coupled with the\nprevalence of dataset-reliant methods such as supervised machine learning. This\nreview makes a number of unique contributions to the ABSA research field: 1) To\nour knowledge, it is the first SLR that links the research domain, dataset\ndomain, and research method through a systematic perspective; 2) it is one of\nthe largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191\nsearch results without time constraint; and 3) our review methodology adopted\nan innovative automatic filtering process based on PDF-mining, which enhanced\nscreening quality and reliability. Suggestions and our review limitations are\nalso discussed.",
            "author": [
                "Yan Cathy Hua",
                "Paul Denny",
                "Katerina Taskova",
                "J\u00f6rg Wicker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10777v3",
                "http://arxiv.org/pdf/2311.10777v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09589v1",
            "title": "Mortal Computation: A Foundation for Biomimetic Intelligence",
            "updated": "2023-11-16T06:00:58Z",
            "published": "2023-11-16T06:00:58Z",
            "summary": "This review motivates and synthesizes research efforts in\nneuroscience-inspired artificial intelligence and biomimetic computing in terms\nof mortal computation. Specifically, we characterize the notion of mortality by\nrecasting ideas in biophysics, cybernetics, and cognitive science in terms of a\ntheoretical foundation for sentient behavior. We frame the mortal computation\nthesis through the Markov blanket formalism and the circular causality entailed\nby inference, learning, and selection. The ensuing framework -- underwritten by\nthe free energy principle -- could prove useful for guiding the construction of\nunconventional connectionist computational systems, neuromorphic intelligence,\nand chimeric agents, including sentient organoids, which stand to revolutionize\nthe long-term future of embodied, enactive artificial intelligence and\ncognition research.",
            "author": [
                "Alexander Ororbia",
                "Karl Friston"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09589v1",
                "http://arxiv.org/pdf/2311.09589v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09585v1",
            "title": "LifeTox: Unveiling Implicit Toxicity in Life Advice",
            "updated": "2023-11-16T05:43:02Z",
            "published": "2023-11-16T05:43:02Z",
            "summary": "As large language models become increasingly integrated into daily life,\ndetecting implicit toxicity across diverse contexts is crucial. To this end, we\nintroduce LifeTox, a dataset designed for identifying implicit toxicity within\na broad range of advice-seeking scenarios. Unlike existing safety datasets,\nLifeTox comprises diverse contexts derived from personal experiences through\nopen-ended questions. Experiments demonstrate that RoBERTa fine-tuned on\nLifeTox matches or surpasses the zero-shot performance of large language models\nin toxicity classification tasks. These results underscore the efficacy of\nLifeTox in addressing the complex challenges inherent in implicit toxicity.",
            "author": [
                "Minbeom Kim",
                "Jahyun Koo",
                "Hwanhee Lee",
                "Joonsuk Park",
                "Hwaran Lee",
                "Kyomin Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09585v1",
                "http://arxiv.org/pdf/2311.09585v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09581v1",
            "title": "Enhancing Medical Text Evaluation with GPT-4",
            "updated": "2023-11-16T05:32:09Z",
            "published": "2023-11-16T05:32:09Z",
            "summary": "In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.",
            "author": [
                "Yiqing Xie",
                "Sheng Zhang",
                "Hao Cheng",
                "Zelalem Gero",
                "Cliff Wong",
                "Tristan Naumann",
                "Hoifung Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09581v1",
                "http://arxiv.org/pdf/2311.09581v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09580v1",
            "title": "MMOE: Mixture of Multimodal Interaction Experts",
            "updated": "2023-11-16T05:31:21Z",
            "published": "2023-11-16T05:31:21Z",
            "summary": "Multimodal machine learning, which studies the information and interactions\nacross various input modalities, has made significant advancements in\nunderstanding the relationship between images and descriptive text. However,\nthis is just a portion of the potential multimodal interactions seen in the\nreal world and does not include new interactions between conflicting utterances\nand gestures in predicting sarcasm, for example. Notably, the current methods\nfor capturing shared information often do not extend well to these more nuanced\ninteractions, sometimes performing as low as 50% in binary classification. In\nthis paper, we address this problem via a new approach called MMOE, which\nstands for a mixture of multimodal interaction experts. Our method\nautomatically classifies data points from unlabeled multimodal datasets by\ntheir interaction type and employs specialized models for each specific\ninteraction. Based on our experiments, this approach improves performance on\nthese challenging interactions by more than 10%, leading to an overall increase\nof 2% for tasks like sarcasm prediction. As a result, interaction\nquantification provides new insights for dataset analysis and yields simple\napproaches that obtain state-of-the-art performance.",
            "author": [
                "Haofei Yu",
                "Paul Pu Liang",
                "Ruslan Salakhutdinov",
                "Louis-Philippe Morency"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09580v1",
                "http://arxiv.org/pdf/2311.09580v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09579v1",
            "title": "Crafting In-context Examples according to LMs' Parametric Knowledge",
            "updated": "2023-11-16T05:30:07Z",
            "published": "2023-11-16T05:30:07Z",
            "summary": "In-context learning has been applied to knowledge-rich tasks such as question\nanswering. In such scenarios, in-context examples are used to trigger a\nbehaviour in the language model: namely, it should surface information stored\nin its parametric knowledge. We study the construction of in-context example\nsets, with a focus on the parametric knowledge of the model regarding\nin-context examples. We identify 'known' examples, where models can correctly\nanswer from its parametric knowledge, and 'unknown' ones. Our experiments show\nthat prompting with 'unknown' examples decreases the performance, potentially\nas it encourages hallucination rather than searching its parametric knowledge.\nConstructing an in-context example set that presents both known and unknown\ninformation performs the best across diverse settings. We perform analysis on\nthree multi-answer question answering datasets, which allows us to further\nstudy answer set ordering strategies based on the LM's knowledge about each\nanswer. Together, our study sheds lights on how to best construct in-context\nexample sets for knowledge-rich tasks.",
            "author": [
                "Yoonsang Lee",
                "Pranav Atreya",
                "Xi Ye",
                "Eunsol Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09579v1",
                "http://arxiv.org/pdf/2311.09579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09578v1",
            "title": "Tied-Lora: Enhacing parameter efficiency of LoRA with weight tying",
            "updated": "2023-11-16T05:29:39Z",
            "published": "2023-11-16T05:29:39Z",
            "summary": "We propose Tied-LoRA, a simple paradigm utilizes weight tying and selective\ntraining to further increase parameter efficiency of the Low-rank adaptation\n(LoRA) method. Our investigations include all feasible combinations parameter\ntraining/freezing in conjunction with weight tying to identify the optimal\nbalance between performance and the number of trainable parameters. Through\nexperiments covering a variety of tasks and two base language models, we\nprovide analysis revealing trade-offs between efficiency and performance. Our\nexperiments uncovered a particular Tied-LoRA configuration that stands out by\ndemonstrating comparable performance across several tasks while employing only\n13~\\% percent of parameters utilized by the standard LoRA method.",
            "author": [
                "Adithya Renduchintala",
                "Tugrul Konuk",
                "Oleksii Kuchaiev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09578v1",
                "http://arxiv.org/pdf/2311.09578v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09576v1",
            "title": "Work State-Centric AI Agents: Design, Implementation, and Management of\n  Cognitive Work Threads",
            "updated": "2023-11-16T05:21:25Z",
            "published": "2023-11-16T05:21:25Z",
            "summary": "AI agents excel in executing predefined tasks, but the dynamic management of\nwork state information during task execution remains an underexplored area. We\npropose a work state-centric AI agent model employing \"work notes\" to record\nand reflect the state throughout task execution. This paper details the model's\narchitecture, featuring worker threads for task oversight, planner modules for\ntask decomposition and planning, and executor modules for performing subtasks\nusing a ReAct-inspired thought-action loop. We provide an exhaustive work state\nrecord incorporating plans and outcomes, constituting a comprehensive work\njournal. Our results show that this model not only improves task execution\nefficiency but also lays a solid foundation for subsequent task analysis and\nauditing.",
            "author": [
                "Chen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09576v1",
                "http://arxiv.org/pdf/2311.09576v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09574v3",
            "title": "LymphoML: An interpretable artificial intelligence-based method\n  identifies morphologic features that correlate with lymphoma subtype",
            "updated": "2023-11-20T02:01:33Z",
            "published": "2023-11-16T05:17:14Z",
            "summary": "The accurate classification of lymphoma subtypes using hematoxylin and eosin\n(H&E)-stained tissue is complicated by the wide range of morphological features\nthese cancers can exhibit. We present LymphoML - an interpretable machine\nlearning method that identifies morphologic features that correlate with\nlymphoma subtypes. Our method applies steps to process H&E-stained tissue\nmicroarray cores, segment nuclei and cells, compute features encompassing\nmorphology, texture, and architecture, and train gradient-boosted models to\nmake diagnostic predictions. LymphoML's interpretable models, developed on a\nlimited volume of H&E-stained tissue, achieve non-inferior diagnostic accuracy\nto pathologists using whole-slide images and outperform black box deep-learning\non a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using\nSHapley Additive exPlanation (SHAP) analysis, we assess the impact of each\nfeature on model prediction and find that nuclear shape features are most\ndiscriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma\n(F1-score: 74.5%). Finally, we provide the first demonstration that a model\ncombining features from H&E-stained tissue with features from a standardized\npanel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a\n46-stain panel (86.1%).",
            "author": [
                "Vivek Shankar",
                "Xiaoli Yang",
                "Vrishab Krishna",
                "Brent Tan",
                "Oscar Silva",
                "Rebecca Rojansky",
                "Andrew Ng",
                "Fabiola Valvert",
                "Edward Briercheck",
                "David Weinstock",
                "Yasodha Natkunam",
                "Sebastian Fernandez-Pol",
                "Pranav Rajpurkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09574v3",
                "http://arxiv.org/pdf/2311.09574v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "I.5.1; I.5.2; I.5.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09572v1",
            "title": "A Meta Logarithmic-Sobolev Inequality for Phase-Covariant Gaussian\n  Channels",
            "updated": "2023-11-16T05:14:17Z",
            "published": "2023-11-16T05:14:17Z",
            "summary": "We introduce a meta logarithmic-Sobolev (log-Sobolev) inequality for the\nLindbladian of all single-mode phase-covariant Gaussian channels of bosonic\nquantum systems, and prove that this inequality is saturated by thermal states.\nWe show that our inequality provides a general framework to derive information\ntheoretic results regarding phase-covariant Gaussian channels. Specifically, by\nusing the optimality of thermal states, we explicitly compute the optimal\nconstant $\\alpha_p$, for $1\\leq p\\leq 2$, of the $p$-log-Sobolev inequality\nassociated to the quantum Ornstein-Uhlenbeck semigroup. These constants were\npreviously known for $p=1$ only. Our meta log-Sobolev inequality also enables\nus to provide an alternative proof for the constrained minimum output entropy\nconjecture in the single-mode case. Specifically, we show that for any\nsingle-mode phase-covariant Gaussian channel $\\Phi$, the minimum of the von\nNeumann entropy $S\\big(\\Phi(\\rho)\\big)$ over all single-mode states $\\rho$ with\na given lower bound on $S(\\rho)$, is achieved at a thermal state.",
            "author": [
                "Salman Beigi",
                "Saleh Rahimi-Keshari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09572v1",
                "http://arxiv.org/pdf/2311.09572v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09571v1",
            "title": "3D Paintbrush: Local Stylization of 3D Shapes with Cascaded Score\n  Distillation",
            "updated": "2023-11-16T05:13:44Z",
            "published": "2023-11-16T05:13:44Z",
            "summary": "In this work we develop 3D Paintbrush, a technique for automatically\ntexturing local semantic regions on meshes via text descriptions. Our method is\ndesigned to operate directly on meshes, producing texture maps which seamlessly\nintegrate into standard graphics pipelines. We opt to simultaneously produce a\nlocalization map (to specify the edit region) and a texture map which conforms\nto it. This synergistic approach improves the quality of both the localization\nand the stylization. To enhance the details and resolution of the textured\narea, we leverage multiple stages of a cascaded diffusion model to supervise\nour local editing technique with generative priors learned from images at\ndifferent resolutions. Our technique, referred to as Cascaded Score\nDistillation (CSD), simultaneously distills scores at multiple resolutions in a\ncascaded fashion, enabling control over both the granularity and global\nunderstanding of the supervision. We demonstrate the effectiveness of 3D\nPaintbrush to locally texture a variety of shapes within different semantic\nregions. Project page: https://threedle.github.io/3d-paintbrush",
            "author": [
                "Dale Decatur",
                "Itai Lang",
                "Kfir Aberman",
                "Rana Hanocka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09571v1",
                "http://arxiv.org/pdf/2311.09571v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09569v1",
            "title": "Prompt Optimisation with Random Sampling",
            "updated": "2023-11-16T05:08:33Z",
            "published": "2023-11-16T05:08:33Z",
            "summary": "Using the generative nature of a language model to generate task-relevant\nseparators has shown competitive results compared to human-curated prompts like\n\"TL;DR\". We demonstrate that even randomly chosen tokens from the vocabulary as\nseparators can achieve near-state-of-the-art performance. We analyse this\nphenomenon in detail using three different random generation strategies,\nestablishing that the language space is rich with potential good separators,\nregardless of the underlying language model size. These observations challenge\nthe common assumption that an effective prompt should be human-readable or\ntask-relevant. Experimental results show that using random separators leads to\nan average 16% relative improvement across nine text classification tasks on\nseven language models, compared to human-curated separators, and is on par with\nautomatic prompt searching methods.",
            "author": [
                "Yao Lu",
                "Jiayi Wang",
                "Sebastian Riedel",
                "Pontus Stenetorp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09569v1",
                "http://arxiv.org/pdf/2311.09569v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09567v2",
            "title": "Entangling gates on degenerate spin qubits dressed by a global field",
            "updated": "2023-12-01T00:39:33Z",
            "published": "2023-11-16T05:07:13Z",
            "summary": "Coherently dressed spins have shown promising results as building blocks for\nfuture quantum computers owing to their resilience to environmental noise and\ntheir compatibility with global control fields. This mode of operation allows\nfor more amenable qubit architecture requirements and simplifies signal routing\non the chip. However, multi-qubit operations, such as qubit addressability and\ntwo-qubit gates, are yet to be demonstrated to establish global control in\ncombination with dressed qubits as a viable path to universal quantum\ncomputing. Here we demonstrate simultaneous on-resonance driving of degenerate\nqubits using a global field while retaining addressability for qubits with\nequal Larmor frequencies. Furthermore, we implement SWAP oscillations during\non-resonance driving, constituting the demonstration of driven two-qubit gates.\nSignificantly, our findings highlight the fragility of entangling gates between\nsuperposition states and how dressing can increase the noise robustness. These\nresults represent a crucial milestone towards global control operation with\ndressed qubits. It also opens a door to interesting spin physics on degenerate\nspins.",
            "author": [
                "Ingvild Hansen",
                "Amanda E. Seedhouse",
                "Santiago Serrano",
                "Andreas Nickl",
                "MengKe Feng",
                "Jonathan Y. Huang",
                "Tuomo Tanttu",
                "Nard Dumoulin Stuyck",
                "Wee Han Lim",
                "Fay E. Hudson",
                "Kohei M. Itoh",
                "Andre Saraiva",
                "Arne Laucht",
                "Andrew S. Dzurak",
                "Chih Hwan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09567v2",
                "http://arxiv.org/pdf/2311.09567v2"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09564v1",
            "title": "LongBoX: Evaluating Transformers on Long-Sequence Clinical Tasks",
            "updated": "2023-11-16T04:57:49Z",
            "published": "2023-11-16T04:57:49Z",
            "summary": "Many large language models (LLMs) for medicine have largely been evaluated on\nshort texts, and their ability to handle longer sequences such as a complete\nelectronic health record (EHR) has not been systematically explored. Assessing\nthese models on long sequences is crucial since prior work in the general\ndomain has demonstrated performance degradation of LLMs on longer texts.\nMotivated by this, we introduce LongBoX, a collection of seven medical datasets\nin text-to-text format, designed to investigate model performance on long\nsequences. Preliminary experiments reveal that both medical LLMs (e.g., BioGPT)\nand strong general domain LLMs (e.g., FLAN-T5) struggle on this benchmark. We\nfurther evaluate two techniques designed for long-sequence handling: (i)\nlocal-global attention, and (ii) Fusion-in-Decoder (FiD). Our results\ndemonstrate mixed results with long-sequence handling - while scores on some\ndatasets increase, there is substantial room for improvement. We hope that\nLongBoX facilitates the development of more effective long-sequence techniques\nfor the medical domain. Data and source code are available at\nhttps://github.com/Mihir3009/LongBoX.",
            "author": [
                "Mihir Parmar",
                "Aakanksha Naik",
                "Himanshu Gupta",
                "Disha Agrawal",
                "Chitta Baral"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09564v1",
                "http://arxiv.org/pdf/2311.09564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09562v1",
            "title": "A Reevaluation of Event Extraction: Past, Present, and Future Challenges",
            "updated": "2023-11-16T04:43:03Z",
            "published": "2023-11-16T04:43:03Z",
            "summary": "Event extraction has attracted much attention in recent years due to its\npotential for many applications. However, recent studies observe some\nevaluation challenges, suggesting that reported scores might not reflect the\ntrue performance. In this work, we first identify and discuss these evaluation\nchallenges, including the unfair comparisons resulting from different\nassumptions about data or different data preprocessing steps, the\nincompleteness of the current evaluation framework leading to potential dataset\nbias or data split bias, and low reproducibility of prior studies. To address\nthese challenges, we propose TextEE, a standardized, fair, and reproducible\nbenchmark for event extraction. TextEE contains standardized data preprocessing\nscripts and splits for more than ten datasets across different domains. In\naddition, we aggregate and re-implement over ten event extraction approaches\npublished in recent years and conduct a comprehensive reevaluation. Finally, we\nexplore the capability of large language models in event extraction and discuss\nsome future challenges. We expect TextEE will serve as a reliable benchmark for\nevent extraction, facilitating future research in the field.",
            "author": [
                "Kuan-Hao Huang",
                "I-Hung Hsu",
                "Tanmay Parekh",
                "Zhiyu Xie",
                "Zixuan Zhang",
                "Premkumar Natarajan",
                "Kai-Wei Chang",
                "Nanyun Peng",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09562v1",
                "http://arxiv.org/pdf/2311.09562v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09559v1",
            "title": "Enchancing Semi-Supervised Learning for Extractive Summarization with an\n  LLM-based pseudolabeler",
            "updated": "2023-11-16T04:29:41Z",
            "published": "2023-11-16T04:29:41Z",
            "summary": "This work tackles the task of extractive text summarization in a limited\nlabeled data scenario using a semi-supervised approach. Specifically, we\npropose a prompt-based pseudolabel selection strategy using GPT-4. We evaluate\nour method on three text summarization datasets: TweetSumm, WikiHow, and\nArXiv/PubMed. Our experiments show that by using an LLM to evaluate and\ngenerate pseudolabels, we can improve the ROUGE-1 by 10-20\\% on the different\ndatasets, which is akin to enhancing pretrained models. We also show that such\na method needs a smaller pool of unlabeled examples to perform better.",
            "author": [
                "Gaurav Sahu",
                "Olga Vechtomova",
                "Issam H. Laradji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09559v1",
                "http://arxiv.org/pdf/2311.09559v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09558v1",
            "title": "Pachinko: Patching Interpretable QA Models through Natural Language\n  Feedback",
            "updated": "2023-11-16T04:26:32Z",
            "published": "2023-11-16T04:26:32Z",
            "summary": "Eliciting feedback from end users of NLP models can be beneficial for\nimproving models. However, how should we present model responses to users so\nthey are most amenable to be corrected from user feedback? Further, what\nproperties do users value to understand and trust responses? We answer these\nquestions by analyzing the effect of rationales generated by QA models to\nsupport their answers. We specifically consider decomposed question-answering\nmodels that first extract an intermediate rationale based on a context and a\nquestion and then use solely this rationale to answer the question. A rationale\noutlines the approach followed by the model to answer the question. Our work\nconsiders various formats of these rationales that vary according to\nwell-defined properties of interest. We sample these rationales from large\nlanguage models using few-shot prompting for two reading comprehension\ndatasets, and then perform two user studies. In the first one, we present users\nwith incorrect answers and corresponding rationales of various formats and ask\nthem to provide natural language feedback to revise the rationale. We then\nmeasure the effectiveness of this feedback in patching these rationales through\nin-context learning. The second study evaluates how well different rationale\nformats enable users to understand and trust model answers, when they are\ncorrect. We find that rationale formats significantly affect how easy it is (1)\nfor users to give feedback for rationales, and (2) for models to subsequently\nexecute this feedback. In addition to influencing critiquablity, certain\nformats significantly enhance user reported understanding and trust of model\noutputs.",
            "author": [
                "Chaitanya Malaviya",
                "Subin Lee",
                "Dan Roth",
                "Mark Yatskar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09558v1",
                "http://arxiv.org/pdf/2311.09558v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09556v1",
            "title": "Linear-scale simulations of quench dynamics",
            "updated": "2023-11-16T04:18:32Z",
            "published": "2023-11-16T04:18:32Z",
            "summary": "The accurate description and robust computational modeling of the\nnonequilibrium properties of quantum systems remain challenges in condensed\nmatter physics. In this work, we develop a linear-scale computational\nsimulation technique for the non-equilibrium dynamics of quantum quench\nsystems. In particular, we report a polynomial expansion of the Loschmidt echo\nto describe the dynamical quantum phase transitions of noninteracting quantum\nquench systems. An expansion based method allows us to efficiently compute the\nLoschmidt echo for infinitely large systems without diagonalizing the system\nHamiltonian. To demonstrate its utility, we highlight quantum quenching\ndynamics under tight-binding quasicrystals and disordered lattices in one\nspatial dimension. In addition, the role of the wave vector on the quench\ndynamics under lattice models is addressed. We observe wave vector-independent\ndynamical phase transitions in self-dual localization models.",
            "author": [
                "Niaz Ali Khan",
                "Wen Chen",
                "Munsif Jan",
                "Gao Xianlong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09556v1",
                "http://arxiv.org/pdf/2311.09556v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09552v1",
            "title": "Large Language Models are Few-Shot Training Example Generators: A Case\n  Study in Fallacy Recognition",
            "updated": "2023-11-16T04:17:47Z",
            "published": "2023-11-16T04:17:47Z",
            "summary": "Recognizing fallacies is crucial for ensuring the quality and validity of\narguments across various domains. However, computational fallacy recognition\nfaces challenges due to the diverse genres, domains, and types of fallacies\nfound in datasets. This leads to a highly multiclass, and even multi-label,\nsetup with substantial class imbalance. In this study, we aim to enhance\nexisting models for fallacy recognition by incorporating additional context and\nby leveraging large language models to generate synthetic data, thus increasing\nthe representation of the infrequent classes. We experiment with GPT3.5 to\ngenerate synthetic examples and we examine the impact of prompt settings for\nthis. Moreover, we explore zero-shot and few-shot scenarios to evaluate the\neffectiveness of using the generated examples for training smaller models\nwithin a unified fallacy recognition framework. Furthermore, we analyze the\noverlap between the synthetic data and existing fallacy datasets. Finally, we\ninvestigate the usefulness of providing supplementary context for detecting\nfallacy types that need such context, e.g., diversion fallacies. Our evaluation\nresults demonstrate consistent improvements across fallacy types, datasets, and\ngenerators.",
            "author": [
                "Tariq Alhindi",
                "Smaranda Muresan",
                "Preslav Nakov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09552v1",
                "http://arxiv.org/pdf/2311.09552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09550v1",
            "title": "A Speed Odyssey for Deployable Quantization of LLMs",
            "updated": "2023-11-16T04:11:19Z",
            "published": "2023-11-16T04:11:19Z",
            "summary": "The large language model era urges faster and less costly inference. Prior\nmodel compression works on LLMs tend to undertake a software-centric approach\nprimarily focused on the simulated quantization performance. By neglecting the\nfeasibility of deployment, these approaches are typically disabled in real\npractice. They used to drastically push down the quantization bit range for a\nreduced computation which might not be supported by the mainstream hardware, or\ninvolve sophisticated algorithms that introduce extra computation or memory\naccess overhead. We argue that pursuing a hardware-centric approach in the\nconstruction of quantization algorithms is crucial. In this regard, we are\ndriven to build our compression method on top of hardware awareness,\neliminating impractical algorithm choices while maximizing the benefit of\nhardware acceleration. Our method, OdysseyLLM, comes with a novel W4A8 kernel\nimplementation called FastGEMM and a combined recipe of quantization\nstrategies. Extensive experiments manifest the superiority of our W4A8 method\nwhich brings the actual speed boosting up to \\textbf{4$\\times$} compared to\nHugging Face FP16 inference and \\textbf{2.23$\\times$} vs. the state-of-the-art\ninference engine TensorRT-LLM in FP16, and \\textbf{1.45$\\times$} vs.\nTensorRT-LLM in INT8, yet without substantially harming the performance.",
            "author": [
                "Qingyuan Li",
                "Ran Meng",
                "Yiduo Li",
                "Bo Zhang",
                "Liang Li",
                "Yifan Lu",
                "Xiangxiang Chu",
                "Yerui Sun",
                "Yuchen Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09550v1",
                "http://arxiv.org/pdf/2311.09550v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09549v1",
            "title": "SparseAuto: An Auto-Scheduler for Sparse Tensor Computations Using\n  Recursive Loop Nest Restructuring",
            "updated": "2023-11-16T04:05:50Z",
            "published": "2023-11-16T04:05:50Z",
            "summary": "Automated code generation and performance optimizations for sparse tensor\nalgebra are cardinal since they have become essential in many real-world\napplications like quantum computing, physics, chemistry, and machine learning.\nGeneral sparse tensor algebra compilers are not always versatile enough to\ngenerate asymptotically optimal code for sparse tensor contractions. This paper\nshows how to optimize and generate asymptotically better schedules for complex\ntensor expressions using kernel fission and fusion. We present a generalized\nloop transformation to achieve loop nesting for minimized memory footprint and\nreduced asymptotic complexity.\n  Furthermore, we present an auto-scheduler that uses a partially ordered\nset-based cost model that uses both time and auxiliary memory complexities in\nits pruning stages. In addition, we highlight the use of SMT solvers in sparse\nauto-schedulers to prune the Pareto frontier of schedules to the smallest\nnumber of possible schedules with user-defined constraints available at compile\ntime. Finally, we show that our auto-scheduler can select asymptotically better\nschedules that use our compiler transformation to generate optimized code. Our\nresults show that the auto-scheduler achieves orders of magnitude speedup\ncompared to the TACO-generated code for several real-world tensor algebra\ncomputations on different real-world inputs.",
            "author": [
                "Adhitha Dias",
                "Logan Anderson",
                "Kirshanthan Sundararajah",
                "Artem Pelenitsyn",
                "Milind Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09549v1",
                "http://arxiv.org/pdf/2311.09549v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09548v1",
            "title": "Universally Optimal Information Dissemination and Shortest Paths in the\n  HYBRID Distributed Model",
            "updated": "2023-11-16T04:00:56Z",
            "published": "2023-11-16T04:00:56Z",
            "summary": "In this work we consider the HYBRID model of distributed computing,\nintroduced recently by Augustine, Hinnenthal, Kuhn, Scheideler, and Schneider\n(SODA 2020), where nodes have access to two different communication modes:\nhigh-bandwidth local communication along the edges of the graph and\nlow-bandwidth all-to-all communication, capturing the non-uniform nature of\nmodern communication networks.\n  Prior work in HYBRID has focused on showing existentially optimal algorithms,\nmeaning there exists a pathological family of instances on which no algorithm\ncan do better. This neglects the fact that such worst-case instances often do\nnot appear or can be actively avoided in practice. In this work, we focus on\nthe notion of universal optimality, first raised by Garay, Kutten, and Peleg\n(FOCS 1993). Roughly speaking, a universally optimal algorithm is one that,\ngiven any input graph, runs as fast as the best algorithm designed specifically\nfor that graph.\n  We show the first universally optimal algorithms in HYBRID. We present\nuniversally optimal solutions for fundamental information dissemination tasks,\nsuch as broadcasting and unicasting multiple messages in HYBRID. Furthermore,\nwe apply these tools to obtain universally optimal solutions for various\nshortest paths problems in HYBRID.\n  A main conceptual contribution of this work is the conception of a new graph\nparameter called neighborhood quality that captures the inherent complexity of\nmany fundamental graph problems in HYBRID.\n  We also show new existentially optimal shortest paths algorithms in HYBRID,\nwhich are utilized as key subroutines in our universally optimal algorithms and\nare of independent interest. Our new algorithms for $k$-source shortest paths\nmatch the existing $\\tilde{\\Omega}(\\sqrt{k})$ lower bound for all $k$.\nPreviously, the lower bound was only known to be tight when $k \\in\n\\tilde{\\Omega}(n^{2/3})$.",
            "author": [
                "Yi-Jun Chang",
                "Oren Hecht",
                "Dean Leitersdorf",
                "Philipp Schneider"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09548v1",
                "http://arxiv.org/pdf/2311.09548v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09543v1",
            "title": "Temporal-Aware Refinement for Video-based Human Pose and Shape Recovery",
            "updated": "2023-11-16T03:35:17Z",
            "published": "2023-11-16T03:35:17Z",
            "summary": "Though significant progress in human pose and shape recovery from monocular\nRGB images has been made in recent years, obtaining 3D human motion with high\naccuracy and temporal consistency from videos remains challenging. Existing\nvideo-based methods tend to reconstruct human motion from global image\nfeatures, which lack detailed representation capability and limit the\nreconstruction accuracy. In this paper, we propose a Temporal-Aware Refining\nNetwork (TAR), to synchronously explore temporal-aware global and local image\nfeatures for accurate pose and shape recovery. First, a global transformer\nencoder is introduced to obtain temporal global features from static feature\nsequences. Second, a bidirectional ConvGRU network takes the sequence of\nhigh-resolution feature maps as input, and outputs temporal local feature maps\nthat maintain high resolution and capture the local motion of the human body.\nFinally, a recurrent refinement module iteratively updates estimated SMPL\nparameters by leveraging both global and local temporal information to achieve\naccurate and smooth results. Extensive experiments demonstrate that our TAR\nobtains more accurate results than previous state-of-the-art methods on popular\nbenchmarks, i.e., 3DPW, MPI-INF-3DHP, and Human3.6M.",
            "author": [
                "Ming Chen",
                "Yan Zhou",
                "Weihua Jian",
                "Pengfei Wan",
                "Zhongyuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09543v1",
                "http://arxiv.org/pdf/2311.09543v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09542v1",
            "title": "Towards Pragmatic Awareness in Question Answering: A Case Study in\n  Maternal and Infant Health",
            "updated": "2023-11-16T03:33:01Z",
            "published": "2023-11-16T03:33:01Z",
            "summary": "Questions posed by information-seeking users often contain implicit false or\npotentially harmful assumptions. In a high-risk domain such as maternal and\ninfant health, a question-answering system must recognize these pragmatic\nconstraints and go beyond simply answering user questions, examining them in\ncontext to respond helpfully. To achieve this, we study pragmatic inferences\nmade when mothers ask questions about pregnancy and infant care. Some of the\ninferences in these questions evade detection by existing methods, risking the\npossibility of QA systems failing to address them which can have dangerous\nhealth and policy implications. We explore the viability of detecting\ninferences from questions using large language models and illustrate that\ninforming existing QA pipelines with pragmatic inferences produces responses\nthat can mitigate the propagation of harmful beliefs.",
            "author": [
                "Neha Srikanth",
                "Rupak Sarkar",
                "Rachel Rudinger",
                "Jordan Boyd-Graber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09542v1",
                "http://arxiv.org/pdf/2311.09542v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09540v1",
            "title": "FedFusion: Manifold Driven Federated Learning for Multi-satellite and\n  Multi-modality Fusion",
            "updated": "2023-11-16T03:29:19Z",
            "published": "2023-11-16T03:29:19Z",
            "summary": "Multi-satellite, multi-modality in-orbit fusion is a challenging task as it\nexplores the fusion representation of complex high-dimensional data under\nlimited computational resources. Deep neural networks can reveal the underlying\ndistribution of multi-modal remote sensing data, but the in-orbit fusion of\nmultimodal data is more difficult because of the limitations of different\nsensor imaging characteristics, especially when the multimodal data follows\nnon-independent identically distribution (Non-IID) distributions. To address\nthis problem while maintaining classification performance, this paper proposes\na manifold-driven multi-modality fusion framework, FedFusion, which randomly\nsamples local data on each client to jointly estimate the prominent manifold\nstructure of shallow features of each client and explicitly compresses the\nfeature matrices into a low-rank subspace through cascading and additive\napproaches, which is used as the feature input of the subsequent classifier.\nConsidering the physical space limitations of the satellite constellation, we\ndeveloped a multimodal federated learning module designed specifically for\nmanifold data in a deep latent space. This module achieves iterative updating\nof the sub-network parameters of each client through global weighted averaging,\nconstructing a framework that can represent compact representations of each\nclient. The proposed framework surpasses existing methods in terms of\nperformance on three multimodal datasets, achieving a classification average\naccuracy of 94.35$\\%$ while compressing communication costs by a factor of 4.\nFurthermore, extensive numerical evaluations of real-world satellite images\nwere conducted on the orbiting edge computing architecture based on Jetson TX2\nindustrial modules, which demonstrated that FedFusion significantly reduced\ntraining time by 48.4 minutes (15.18%) while optimizing accuracy.}",
            "author": [
                "DaiXun Li",
                "Weiying Xie",
                "Yunsong Li",
                "Leyuan Fang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TGRS.2023.3339522",
                "http://arxiv.org/abs/2311.09540v1",
                "http://arxiv.org/pdf/2311.09540v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09539v1",
            "title": "Entanglement constraint on wave-particle duality for tripartite systems",
            "updated": "2023-11-16T03:28:48Z",
            "published": "2023-11-16T03:28:48Z",
            "summary": "A global multi-partite entanglement may place a constraint on the\nwave-particle duality. We investigate this constraint relation of the global\nentanglement and the quantitative wave-particle duality in tripartite systems.\nWe perform quantum state tomography to reconstruct the reduced density matrix\nby using the OriginQ quantum computing cloud platform. As a result, we show\nthat, theoretically and experimentally, the quantitative wave-particle duality\nis indeed constrained by the global tripartite entanglement.",
            "author": [
                "Zanjia Li",
                "Yingqiu He",
                "Dong Ding",
                "Ting Gao",
                "Fengli Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09539v1",
                "http://arxiv.org/pdf/2311.09539v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09538v1",
            "title": "Reducing Privacy Risks in Online Self-Disclosures with Language Models",
            "updated": "2023-11-16T03:28:43Z",
            "published": "2023-11-16T03:28:43Z",
            "summary": "Self-disclosure, while being common and rewarding in social media\ninteraction, also poses privacy risks. In this paper, we take the initiative to\nprotect the user-side privacy associated with online self-disclosure through\nidentification and abstraction. We develop a taxonomy of 19 self-disclosure\ncategories, and curate a large corpus consisting of 4.8K annotated disclosure\nspans. We then fine-tune a language model for identification, achieving over\n75% in Token F$_1$. We further conduct a HCI user study, with 82\\% of\nparticipants viewing the model positively, highlighting its real world\napplicability. Motivated by the user feedback, we introduce the task of\nself-disclosure abstraction. We experiment with both one-span abstraction and\nthree-span abstraction settings, and explore multiple fine-tuning strategies.\nOur best model can generate diverse abstractions that moderately reduce privacy\nrisks while maintaining high utility according to human evaluation.",
            "author": [
                "Yao Dou",
                "Isadora Krsek",
                "Tarek Naous",
                "Anubha Kabra",
                "Sauvik Das",
                "Alan Ritter",
                "Wei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09538v1",
                "http://arxiv.org/pdf/2311.09538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09536v1",
            "title": "Correlation networks: Interdisciplinary approaches beyond thresholding",
            "updated": "2023-11-16T03:26:10Z",
            "published": "2023-11-16T03:26:10Z",
            "summary": "Many empirical networks originate from correlational data, arising in domains\nas diverse as psychology, neuroscience, genomics, microbiology, finance, and\nclimate science. Specialized algorithms and theory have been developed in\ndifferent application domains for working with such networks, as well as in\nstatistics, network science, and computer science, often with limited\ncommunication between practitioners in different fields. This leaves\nsignificant room for cross-pollination across disciplines. A central challenge\nis that it is not always clear how to best transform correlation matrix data\ninto networks for the application at hand, and probably the most widespread\nmethod, i.e., thresholding on the correlation value to create either unweighted\nor weighted networks, suffers from multiple problems. In this article, we\nreview various methods of constructing and analyzing correlation networks,\nranging from thresholding and its improvements to weighted networks,\nregularization, dynamic correlation networks, threshold-free approaches, and\nmore. Finally, we propose and discuss a variety of key open questions currently\nconfronting this field.",
            "author": [
                "Naoki Masuda",
                "Zachary M. Boyd",
                "Diego Garlaschelli",
                "Peter J. Mucha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09536v1",
                "http://arxiv.org/pdf/2311.09536v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09533v1",
            "title": "Effective Large Language Model Adaptation for Improved Grounding",
            "updated": "2023-11-16T03:22:25Z",
            "published": "2023-11-16T03:22:25Z",
            "summary": "Large language models (LLMs) have achieved remarkable advancements in natural\nlanguage understanding, generation, and manipulation of text-based data.\nHowever, one major issue towards their widespread deployment in the real world\nis that they can generate \"hallucinated\" answers that are not factual. Towards\nthis end, this paper focuses on improving grounding from a holistic perspective\nwith a novel framework, AGREE, Adaptation of LLMs for GRounding EnhancEment. We\nstart with the design of an iterative test-time adaptation (TTA) capability\nthat takes into account the support information generated in self-grounded\nresponses. To effectively enable this capability, we tune LLMs to ground the\nclaims in their responses to retrieved documents by providing citations. This\ntuning on top of the pre-trained LLMs requires a small amount of data that\nneeds to be constructed in a particular way to learn the grounding information,\nfor which we introduce a data construction method. Our results show that the\ntuning-based AGREE framework generates better grounded responses with more\naccurate citations compared to prompting-based approaches.",
            "author": [
                "Xi Ye",
                "Ruoxi Sun",
                "Sercan \u00d6. Arik",
                "Tomas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09533v1",
                "http://arxiv.org/pdf/2311.09533v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09529v1",
            "title": "TransCrimeNet: A Transformer-Based Model for Text-Based Crime Prediction\n  in Criminal Networks",
            "updated": "2023-11-16T03:14:58Z",
            "published": "2023-11-16T03:14:58Z",
            "summary": "This paper presents TransCrimeNet, a novel transformer-based model for\npredicting future crimes in criminal networks from textual data. Criminal\nnetwork analysis has become vital for law enforcement agencies to prevent\ncrimes. However, existing graph-based methods fail to effectively incorporate\ncrucial textual data like social media posts and interrogation transcripts that\nprovide valuable insights into planned criminal activities. To address this\nlimitation, we develop TransCrimeNet which leverages the representation\nlearning capabilities of transformer models like BERT to extract features from\nunstructured text data. These text-derived features are fused with graph\nembeddings of the criminal network for accurate prediction of future crimes.\nExtensive experiments on real-world criminal network datasets demonstrate that\nTransCrimeNet outperforms previous state-of-the-art models by 12.7\\% in F1\nscore for crime prediction. The results showcase the benefits of combining\ntextual and graph-based features for actionable insights to disrupt criminal\nenterprises.",
            "author": [
                "Chen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09529v1",
                "http://arxiv.org/pdf/2311.09529v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09528v1",
            "title": "HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM",
            "updated": "2023-11-16T03:13:29Z",
            "published": "2023-11-16T03:13:29Z",
            "summary": "Existing open-source helpfulness preference datasets do not specify what\nmakes some responses more helpful and others less so. Models trained on these\ndatasets can incidentally learn to model dataset artifacts (e.g. preferring\nlonger but unhelpful responses only due to their length). To alleviate this\nproblem, we collect HelpSteer, a multi-attribute helpfulness dataset annotated\nfor the various aspects that make responses helpful. Specifically, our\n37k-sample dataset has annotations for correctness, coherence, complexity, and\nverbosity in addition to overall helpfulness of responses. Training Llama 2 70B\nusing the HelpSteer dataset with SteerLM technique produces a model that scores\n7.54 on MT Bench, which is currently the highest score for open models that do\nnot require training data from more powerful models (e.g. GPT4). We release\nthis dataset with CC-BY-4.0 license at\nhttps://huggingface.co/datasets/nvidia/HelpSteer",
            "author": [
                "Zhilin Wang",
                "Yi Dong",
                "Jiaqi Zeng",
                "Virginia Adams",
                "Makesh Narsimhan Sreedhar",
                "Daniel Egert",
                "Olivier Delalleau",
                "Jane Polak Scowcroft",
                "Neel Kant",
                "Aidan Swope",
                "Oleksii Kuchaiev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09528v1",
                "http://arxiv.org/pdf/2311.09528v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09526v1",
            "title": "Towards Serverless Optimization with In-place Scaling",
            "updated": "2023-11-16T03:06:51Z",
            "published": "2023-11-16T03:06:51Z",
            "summary": "Serverless computing has gained popularity due to its cost efficiency, ease\nof deployment, and enhanced scalability. However, in serverless environments,\nservers are initiated only after receiving a request, leading to increased\nresponse times. This delay is commonly known as the cold start problem. In this\nstudy, we explore the in-place scaling feature released in Kubernetes v1.27 and\nexamine its impact on serverless computing. Our experimental results reveal\nimprovements in request latency, with reductions ranging from 1.16 to 18.15\ntimes across various workloads when compared to traditional cold policy.",
            "author": [
                "Vincent Hsieh",
                "Jerry Chou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09526v1",
                "http://arxiv.org/pdf/2311.09526v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09524v2",
            "title": "Mori-Zwanzig Modal Decomposition",
            "updated": "2023-11-17T02:38:42Z",
            "published": "2023-11-16T03:03:08Z",
            "summary": "We introduce the Mori-Zwanzig (MZ) Modal Decomposition (MZMD), a novel\ntechnique for performing modal analysis of large scale spatio-temporal\nstructures in complex dynamical systems, and show that it represents an\nefficient generalization of Dynamic Mode Decomposition (DMD). The MZ formalism\nprovides a mathematical framework for constructing non-Markovian reduced-order\nmodels of resolved variables from high-dimensional dynamical systems,\nincorporating the effects of unresolved dynamics through the memory kernel and\northogonal dynamics. We present a formulation and analysis of the modes and\nspectrum from MZMD and compare it to DMD when applied to a complex flow: a\nDirect Numerical Simulation (DNS) data-set of laminar-turbulent boundary-layer\ntransition flow over a flared cone at Mach 6. We show that the addition of\nmemory terms by MZMD improves the resolution of spatio-temporal structures\nwithin the transitional/turbulent regime, which contains features that arise\ndue to nonlinear mechanisms, such as the generation of the so-called \"hot\"\nstreaks on the surface of the flared cone. As a result, compared to DMD, MZMD\nimproves future state prediction accuracy, while requiring nearly the same\ncomputational cost.",
            "author": [
                "Michael Woodward",
                "Yifeng Tian",
                "Yen Ting Lin",
                "Christoph Hader",
                "Hermann Fasel",
                "Daniel Livescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09524v2",
                "http://arxiv.org/pdf/2311.09524v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09523v1",
            "title": "Data-driven estimates for light-quark-connected and\n  strange-plus-disconnected hadronic $g-2$ window quantities",
            "updated": "2023-11-16T03:01:58Z",
            "published": "2023-11-16T03:01:58Z",
            "summary": "A number of discrepancies have emerged between lattice computations and\ndata-driven dispersive evaluations of the RBC/UKQCD\nIntermediate-window-hadronic contribution to the muon anomalous magnetic\nmoment. It is therefore interesting to obtain data-driven estimates for the\nlight-quark-connected and strange-plus-disconnected components of this window\nquantity, allowing for a more detailed comparison between the lattice and\ndata-driven approaches. The aim of this paper is to provide these estimates,\nextending the analysis to several other window quantities, including two\nwindows designed to focus on the region in which the two-pion contribution is\ndominant. Clear discrepancies are observed for all light-quark-connected\ncontributions considered, while good agreement with lattice results is found\nfor strange-plus disconnected contributions to the quantities for which\ncorresponding lattice results exist. The largest of these discrepancies is that\nfor the RBC/UKQCD intermediate window, where, as previously reported, our\ndata-driven result, $a_\\mu^{W1,{\\rm lqc}}=198.9(1.1)\\times 10^{-10}$, is in\nsignificant tension with the results of 8 different recent lattice\ndeterminations. Our strategy is the same as recently employed in obtaining\ndata-driven estimates for the light-quark-connected and\nstrange-plus-disconnected components of the full leading-order hadronic vacuum\npolarization contribution to the muon anomalous magnetic moment. Updated\nversions of those earlier results are also presented, for completeness.",
            "author": [
                "Genessa Benton",
                "Diogo Boito",
                "Maarten Golterman",
                "Alex Keshavarzi",
                "Kim Maltman",
                "Santiago Peris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09523v1",
                "http://arxiv.org/pdf/2311.09523v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09522v1",
            "title": "Reversed Indexes $\\approx$ Values in Wavelet Trees",
            "updated": "2023-11-16T03:01:50Z",
            "published": "2023-11-16T03:01:50Z",
            "summary": "This work presents a discovery to advance the wisdom in a particular Succinct\nData Structure: Wavelet Tree (Grossi, Gupta, and Vitter 2003). The discovery is\nfirst made by showing the feasibility of Reversed Indexes = Values: for\nintegers within $[0,2^{N})$, there exists a Wavelet Tree that its compressed\nindexes can be equivalent to the Leibniz Binary system (Leibniz 1703), with\nonly the bit reversal. Then we show how to strengthen the discovery by\ngeneralizing it into Reversed Indexes $\\approx$ Values, by applying a longest\ncommon subsequence in bits and its patterns. Finally, we conjuncture potential\nimplications of the above ideas by discussing its benefits, and modifications\nto the RAM model.\n  The discovery reveals that: (1) the usability of Succinct Data Structure can\nbe significantly expanded, by enabling Computation Directly on Compression; and\n(2) near-optimal lossless compression can still yield close connections with\nthe Leibniz Binary System (Leibniz 1703), which breeds polymorphic\nfunctionalities within a single piece of the information. This work also\nprovides an initial analysis of the benefits from the method (and potentially\nother extensions), and suggests potential modifications.",
            "author": [
                "Xiangjun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09522v1",
                "http://arxiv.org/pdf/2311.09522v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09521v1",
            "title": "AMRFact: Enhancing Summarization Factuality Evaluation with AMR-driven\n  Training Data Generation",
            "updated": "2023-11-16T02:56:29Z",
            "published": "2023-11-16T02:56:29Z",
            "summary": "Ensuring factual consistency is crucial in various natural language\nprocessing tasks, particularly in abstractive summarization, where preserving\nthe integrity of information is paramount. Prior entailment-based approaches\noften generate factually inconsistent summaries and then train a classifier on\nthe generated data. However, summaries produced by these approaches are either\nof low coherence or lack error-type coverage. To address these issues, we\npropose AMRFact, a novel framework that generates factually inconsistent\nsummaries using Abstract Meaning Representation (AMR). Our approach parses\nfactually correct summaries into AMR graphs and injects controlled factual\ninconsistencies to create negative examples, allowing for coherent factually\ninconsistent summaries to be generated with high error-type coverage.\nAdditionally, we present a data selection module NegFilter based on natural\nlanguage inference and BARTScore to ensure the quality of the generated\nnegative samples. Experimental results demonstrate that our approach\nsignificantly outperforms previous systems on the AggreFact-SOTA dataset,\nshowcasing its efficacy in assessing factuality in abstractive summarization.",
            "author": [
                "Haoyi Qiu",
                "Kung-Hsiang Huang",
                "Jingnong Qu",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09521v1",
                "http://arxiv.org/pdf/2311.09521v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09520v1",
            "title": "MDFL: Multi-domain Diffusion-driven Feature Learning",
            "updated": "2023-11-16T02:55:21Z",
            "published": "2023-11-16T02:55:21Z",
            "summary": "High-dimensional images, known for their rich semantic information, are\nwidely applied in remote sensing and other fields. The spatial information in\nthese images reflects the object's texture features, while the spectral\ninformation reveals the potential spectral representations across different\nbands. Currently, the understanding of high-dimensional images remains limited\nto a single-domain perspective with performance degradation. Motivated by the\nmasking texture effect observed in the human visual system, we present a\nmulti-domain diffusion-driven feature learning network (MDFL) , a scheme to\nredefine the effective information domain that the model really focuses on.\nThis method employs diffusion-based posterior sampling to explicitly consider\njoint information interactions between the high-dimensional manifold structures\nin the spectral, spatial, and frequency domains, thereby eliminating the\ninfluence of masking texture effects in visual models. Additionally, we\nintroduce a feature reuse mechanism to gather deep and raw features of\nhigh-dimensional data. We demonstrate that MDFL significantly improves the\nfeature extraction performance of high-dimensional data, thereby providing a\npowerful aid for revealing the intrinsic patterns and structures of such data.\nThe experimental results on three multi-modal remote sensing datasets show that\nMDFL reaches an average overall accuracy of 98.25%, outperforming various\nstate-of-the-art baseline schemes. The code will be released, contributing to\nthe computer vision community.",
            "author": [
                "Daixun Li",
                "Weiying Xie",
                "Jiaqing Zhang",
                "Yunsong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09520v1",
                "http://arxiv.org/pdf/2311.09520v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09519v1",
            "title": "Leveraging Code to Improve In-context Learning for Semantic Parsing",
            "updated": "2023-11-16T02:50:06Z",
            "published": "2023-11-16T02:50:06Z",
            "summary": "In-context learning (ICL) is an appealing approach for semantic parsing due\nto its few-shot nature and improved generalization. However, learning to parse\nto rare domain-specific languages (DSLs) from just a few demonstrations is\nchallenging, limiting the performance of even the most capable LLMs. In this\nwork, we improve the effectiveness of ICL for semantic parsing by (1) using\ngeneral-purpose programming languages such as Python instead of DSLs, and (2)\naugmenting prompts with a structured domain description that includes, e.g.,\nthe available classes and functions. We show that both these changes\nsignificantly improve accuracy across three popular datasets. Combined, they\nlead to dramatic improvements (e.g. 7.9% to 66.5% on SMCalFlow compositional\nsplit), nearly closing the performance gap between easier i.i.d.\\ and harder\ncompositional splits when used with a strong model, and reducing the need for a\nlarge number of demonstrations. We find that the resemblance of the target\nparse language to general-purpose code is a more important factor than the\nlanguage's popularity in pre-training corpora. Our findings provide an improved\nmethodology for building semantic parsers in the modern context of ICL with\nLLMs.",
            "author": [
                "Ben Bogin",
                "Shivanshu Gupta",
                "Peter Clark",
                "Ashish Sabharwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09519v1",
                "http://arxiv.org/pdf/2311.09519v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09518v1",
            "title": "From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer\n  Multiple-choice Questions for Programming Classes in Higher Education",
            "updated": "2023-11-16T02:46:15Z",
            "published": "2023-11-16T02:46:15Z",
            "summary": "We explore the evolving efficacy of three generative pre-trained transformer\n(GPT) models in generating answers for multiple-choice questions (MCQ) from\nintroductory and intermediate Python programming courses in higher education.\nWe focus on the differences in capabilities of the models prior to the release\nof ChatGPT (Nov '22), at the time of the release, and today (i.e., Aug '23).\nRecent studies have established that the abilities of the OpenAI's GPT models\nto handle assessments originally designed for humans keep increasing as the\nnewer more capable models are released. However, the qualitative differences in\nthe capabilities and limitations of these models to reason about and/or analyze\nprogramming MCQs have been under-explored. We evaluated three OpenAI's GPT\nmodels on formative and summative MCQ assessments from three Python courses\n(530 questions) focusing on the qualitative differences in the evolving\nefficacy of the subsequent models. This study provides further evidence and\ninsight into the trajectory of the current developments where there already\nexists a technology that can be utilized by students to collect passing scores,\nwith no effort whatsoever, on what today counts as viable programming knowledge\nand skills assessments. This study could be leveraged by educators and\ninstitutions to better understand the recent technological developments in\norder to adapt the design of programming assessments as well as to fuel the\nnecessary discussions into how assessments in future programming classes should\nbe updated.",
            "author": [
                "Jaromir Savelka",
                "Arav Agarwal",
                "Christopher Bogart",
                "Majd Sakr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09518v1",
                "http://arxiv.org/pdf/2311.09518v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09517v1",
            "title": "GEE! Grammar Error Explanation with Large Language Models",
            "updated": "2023-11-16T02:45:47Z",
            "published": "2023-11-16T02:45:47Z",
            "summary": "Grammatical error correction tools are effective at correcting grammatical\nerrors in users' input sentences but do not provide users with \\textit{natural\nlanguage} explanations about their errors. Such explanations are essential for\nhelping users learn the language by gaining a deeper understanding of its\ngrammatical rules (DeKeyser, 2003; Ellis et al., 2006). To address this gap, we\npropose the task of grammar error explanation, where a system needs to provide\none-sentence explanations for each grammatical error in a pair of erroneous and\ncorrected sentences. We analyze the capability of GPT-4 in grammar error\nexplanation, and find that it only produces explanations for 60.2% of the\nerrors using one-shot prompting. To improve upon this performance, we develop a\ntwo-step pipeline that leverages fine-tuned and prompted large language models\nto perform structured atomic token edit extraction, followed by prompting GPT-4\nto generate explanations. We evaluate our pipeline on German and Chinese\ngrammar error correction data sampled from language learners with a wide range\nof proficiency levels. Human evaluation reveals that our pipeline produces\n93.9% and 98.0% correct explanations for German and Chinese data, respectively.\nTo encourage further research in this area, we will open-source our data and\ncode.",
            "author": [
                "Yixiao Song",
                "Kalpesh Krishna",
                "Rajesh Bhatt",
                "Kevin Gimpel",
                "Mohit Iyyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09517v1",
                "http://arxiv.org/pdf/2311.09517v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09516v1",
            "title": "Real-Time Adaptive Neural Network on FPGA: Enhancing Adaptability\n  through Dynamic Classifier Selection",
            "updated": "2023-11-16T02:44:45Z",
            "published": "2023-11-16T02:44:45Z",
            "summary": "This research studies an adaptive neural network with a Dynamic Classifier\nSelection framework on Field-Programmable Gate Arrays (FPGAs). The evaluations\nare conducted across three different datasets. By adjusting parameters, the\narchitecture surpasses all models in the ensemble set in accuracy and shows an\nimprovement of up to 8% compared to a singular neural network implementation.\nThe research also emphasizes considerable resource savings of up to 109.28%,\nachieved via partial reconfiguration rather than a traditional fixed approach.\nSuch improved efficiency suggests that the architecture is ideal for settings\nlimited by computational capacity, like in edge computing scenarios. The\ncollected data highlights the architecture's two main benefits: high\nperformance and real-world application, signifying a notable input to\nFPGA-based ensemble learning methods.",
            "author": [
                "Achraf El Bouazzaoui",
                "Abdelkader Hadjoudja",
                "Omar Mouhib"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09516v1",
                "http://arxiv.org/pdf/2311.09516v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09513v1",
            "title": "Sequencing Matters: A Generate-Retrieve-Generate Model for Building\n  Conversational Agents",
            "updated": "2023-11-16T02:37:58Z",
            "published": "2023-11-16T02:37:58Z",
            "summary": "This paper contains what the Georgetown InfoSense group has done in regard to\nsolving the challenges presented by TREC iKAT 2023. Our submitted runs\noutperform the median runs by a significant margin, exhibiting superior\nperformance in nDCG across various cut numbers and in overall success rate. Our\napproach uses a Generate-Retrieve-Generate method, which we've found to greatly\noutpace Retrieve-Then-Generate approaches for the purposes of iKAT. Our\nsolution involves the use of Large Language Models (LLMs) for initial answers,\nanswer grounding by BM25, passage quality filtering by logistic regression, and\nanswer generation by LLMs again. We leverage several purpose-built Language\nModels, including BERT, Chat-based, and text-to-transfer-based models, for text\nunderstanding, classification, generation, and summarization. The official\nresults of the TREC evaluation contradict our initial self-evaluation, which\nmay suggest that a decrease in the reliance on our retrieval and classification\nmethods is better. Nonetheless, our findings suggest that the sequence of\ninvolving these different components matters, where we see an essentiality of\nusing LLMs before using search engines.",
            "author": [
                "Quinn Patwardhan",
                "Grace Hui Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09513v1",
                "http://arxiv.org/pdf/2311.09513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09512v1",
            "title": "Covers of fractal interpolation surfaces with finite families of\n  octahedrons",
            "updated": "2023-11-16T02:34:16Z",
            "published": "2023-11-16T02:34:16Z",
            "summary": "In our previous work, On the localization of Hutchinson-Barnsley fractals,\nChaos Solitons Fractals, 173 (2023), 113-674, we presented a method for finding\na finite family of closed balls whose union contains the attractor of a given\niterated function system. In this paper, for the particular framework of\nfractal interpolation surfaces, we provide an improved version of it. This\napproach is more efficient, from the computational point of view, as it is\nbased on finding the maximum of certain sets, in contrast to the previous\nmethod which uses a sorting algorithm.",
            "author": [
                "Bogdan Anghelina",
                "Radu Miculescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09512v1",
                "http://arxiv.org/pdf/2311.09512v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "28A80, 41A05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09511v2",
            "title": "Identifying Systems with Symmetries using Equivariant Autoregressive\n  Reservoir Computers",
            "updated": "2023-11-28T22:59:41Z",
            "published": "2023-11-16T02:32:26Z",
            "summary": "The investigation reported in this document focuses on identifying systems\nwith symmetries using equivariant autoregressive reservoir computers. General\nresults in structured matrix approximation theory are presented, exploring a\ntwo-fold approach. Firstly, a comprehensive examination of generic\nsymmetry-preserving nonlinear time delay embedding is conducted. This involves\nanalyzing time series data sampled from an equivariant system under study.\nSecondly, sparse least-squares methods are applied to discern approximate\nrepresentations of the output coupling matrices. These matrices play a pivotal\nrole in determining the nonlinear autoregressive representation of an\nequivariant system. The structural characteristics of these matrices are\ndictated by the set of symmetries inherent in the system. The document outlines\nprototypical algorithms derived from the described techniques, offering insight\ninto their practical applications. Emphasis is placed on their effectiveness in\nthe identification and predictive simulation of equivariant nonlinear systems,\nregardless of whether such systems exhibit chaotic behavior.",
            "author": [
                "Fredy Vides",
                "Idelfonso B. R. Nogueira",
                "Lendy Banegas",
                "Evelyn Flores"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09511v2",
                "http://arxiv.org/pdf/2311.09511v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09510v1",
            "title": "One Size Does Not Fit All: Customizing Open-Domain Procedures",
            "updated": "2023-11-16T02:25:36Z",
            "published": "2023-11-16T02:25:36Z",
            "summary": "How-to procedures, such as how to plant a garden, are ubiquitous. But one\nsize does not fit all - humans often need to customize these procedural plans\naccording to their specific needs, e.g., planting a garden without pesticides.\nWhile LLMs can fluently generate generic procedures, we present the first study\non how well LLMs can customize open-domain procedures. We introduce\nCustomPlans, a probe dataset of customization hints that encodes diverse user\nneeds for open-domain How-to procedures. Using LLMs as CustomizationAgent and\nExecutionAgent in different settings, we establish their abilities to perform\nopen-domain procedure customization. Human evaluation shows that using these\nagents in a Sequential setting is the best, but they are good enough only ~51%\nof the time. Error analysis shows that LLMs do not sufficiently address user\ncustomization needs in their generated procedures.",
            "author": [
                "Yash Kumar Lal",
                "Li Zhang",
                "Faeze Brahman",
                "Bodhisattwa Prasad Majumder",
                "Peter Clark",
                "Niket Tandon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09510v1",
                "http://arxiv.org/pdf/2311.09510v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09509v1",
            "title": "Heterogeneity and Low-Frequency Vibrations in Bidisperse Sphere Packings",
            "updated": "2023-11-16T02:18:56Z",
            "published": "2023-11-16T02:18:56Z",
            "summary": "In the jamming transition of monodisperse packings, spatial heterogeneity is\nirrelevant as the transition is described by mean-field theories. Here, we show\nthat this situation drastically changes if the particle-size dispersity is\nlarge enough. We use computer simulations to study the structural and\nvibrational properties of bidisperse sphere packings with a large size ratio.\nNear the critical point, the small particles tend to form clusters, leading to\nthe emergence of large-scale structural heterogeneity. Concomitantly, the\nlow-frequency vibrations are significantly enhanced compared to those in\nmonodisperse packings, and their density of states follows a linear law with\nthe frequency. We numerically and theoretically demonstrate that these\nbehaviors of the structural heterogeneity and the low-frequency vibrations are\nintimately connected. The present work suggests that the nature of\nheterogeneous packings is markedly different from that of homogeneous packings.",
            "author": [
                "Yusuke Hara",
                "Hideyuki Mizuno",
                "Atsushi Ikeda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09509v1",
                "http://arxiv.org/pdf/2311.09509v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09507v1",
            "title": "An optimization framework for analyzing nonlinear stability due to\n  sparse finite-amplitude perturbations",
            "updated": "2023-11-16T02:07:15Z",
            "published": "2023-11-16T02:07:15Z",
            "summary": "Recent works have established the utility of sparsity-promoting norms for\nextracting spatially-localized instability mechanisms in fluid flows, with\npossible implications for flow control. However, these prior works have focused\non linear dynamics of infinitesimal perturbations about a given baseflow. In\nthis paper, we propose an optimization framework for computing sparse\nfinite-amplitude perturbations that maximize transient growth in nonlinear\nsystems. A variational approach is used to derive the first-order necessary\nconditions for optimality, which form the basis of our iterative direct-adjoint\nlooping numerical solution algorithm. When applied to a reduced-order model of\na sinusoidal shear flow at $Re=20$, our framework identifies that energy\ninjection into a single vortical mode yields comparable energy amplification as\nthe non-sparse optimal solution with energy distributed across all modes.\nEnergy injection into three additional modes results in an identical transient\ngrowth as the non-sparse case. Subsequent analysis of the dynamic response of\nthe flow establishes that these sparse optimal perturbations trigger many of\nthe same nonlinear modal interactions that give rise to transient growth when\nall modes are perturbed in an optimal manner. It is also observed that as\nperturbation amplitude is increased, the maximum transient growth is achieved\nat an earlier time. Our results highlight the power of the proposed\noptimization framework for revealing dominant nonlinear modal interactions and\nsparse perturbation mechanisms for transient growth and instability in fluid\nflows. We anticipate the approach will be a useful tool in guiding the design\nof flow control strategies in the future.",
            "author": [
                "A. Leonid Heide",
                "Maziar S. Hemati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09507v1",
                "http://arxiv.org/pdf/2311.09507v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09505v1",
            "title": "SegMix: A Simple Structure-Aware Data Augmentation Method",
            "updated": "2023-11-16T02:05:15Z",
            "published": "2023-11-16T02:05:15Z",
            "summary": "Interpolation-based Data Augmentation (DA) methods (Mixup) linearly\ninterpolate the inputs and labels of two or more training examples. Mixup has\nmore recently been adapted to the field of Natural Language Processing (NLP),\nmainly for sequence labeling tasks. However, such a simple adoption yields\nmixed or unstable improvements over the baseline models. We argue that the\ndirect-adoption methods do not account for structures in NLP tasks. To this\nend, we propose SegMix, a collection of interpolation-based DA algorithms that\ncan adapt to task-specific structures. SegMix poses fewer constraints on data\nstructures, is robust to various hyperparameter settings, applies to more task\nsettings, and adds little computational overhead. In the algorithm's core, we\napply interpolation methods on task-specific meaningful segments, in contrast\nto applying them on sequences as in prior work. We find SegMix to be a flexible\nframework that combines rule-based DA methods with interpolation-based methods,\ncreating interesting mixtures of DA techniques. We show that SegMix\nconsistently improves performance over strong baseline models in Named Entity\nRecognition (NER) and Relation Extraction (RE) tasks, especially under\ndata-scarce settings. Furthermore, this method is easy to implement and adds\nnegligible training overhead.",
            "author": [
                "Yuxin Pei",
                "Pushkar Bhuse",
                "Zhengzhong Liu",
                "Eric Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09505v1",
                "http://arxiv.org/pdf/2311.09505v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09503v1",
            "title": "NLTS Hamiltonians and Strongly-Explicit SoS Lower Bounds from Low-Rate\n  Quantum LDPC Codes",
            "updated": "2023-11-16T01:58:00Z",
            "published": "2023-11-16T01:58:00Z",
            "summary": "Recent constructions of the first asymptotically good quantum LDPC (qLDPC)\ncodes led to two breakthroughs in complexity theory: the NLTS (No Low-Energy\nTrivial States) theorem (Anshu, Breuckmann, and Nirkhe, STOC'23), and explicit\nlower bounds against a linear number of levels of the Sum-of-Squares (SoS)\nhierarchy (Hopkins and Lin, FOCS'22).\n  In this work, we obtain improvements to both of these results using qLDPC\ncodes of low rate:\n  - Whereas Anshu et al. only obtained NLTS Hamiltonians from qLDPC codes of\nlinear dimension, we show the stronger result that qLDPC codes of arbitrarily\nsmall positive dimension yield NLTS Hamiltonians.\n  - The SoS lower bounds of Hopkins and Lin are only weakly explicit because\nthey require running Gaussian elimination to find a nontrivial codeword, which\ntakes polynomial time. We resolve this shortcoming by introducing a new method\nof planting a strongly explicit nontrivial codeword in linear-distance qLDPC\ncodes, which in turn yields strongly explicit SoS lower bounds.\n  Our \"planted\" qLDPC codes may be of independent interest, as they provide a\nnew way of ensuring a qLDPC code has positive dimension without resorting to\nparity check counting, and therefore provide more flexibility in the code\nconstruction.",
            "author": [
                "Louis Golowich",
                "Tali Kaufman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09503v1",
                "http://arxiv.org/pdf/2311.09503v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09502v1",
            "title": "SQATIN: Supervised Instruction Tuning Meets Question Answering for\n  Improved Dialogue NLU",
            "updated": "2023-11-16T01:57:00Z",
            "published": "2023-11-16T01:57:00Z",
            "summary": "Task-oriented dialogue (ToD) systems help users execute well-defined tasks\nacross a variety of domains (e.g., $\\textit{flight booking}$ or $\\textit{food\nordering}$), with their Natural Language Understanding (NLU) components being\ndedicated to the analysis of user utterances, predicting users' intents\n($\\textit{Intent Detection}$, ID) and extracting values for informational slots\n($\\textit{Value Extraction}$, VE). In most domains, labelled NLU data is\nscarce, making sample-efficient learning -- enabled with effective transfer\nparadigms -- paramount. In this work, we introduce SQATIN, a new framework for\ndialog NLU based on (i) instruction tuning and (ii) question-answering-based\nformulation of ID and VE tasks. According to the evaluation on established NLU\nbenchmarks, SQATIN sets the new state of the art in dialogue NLU, substantially\nsurpassing the performance of current models based on standard fine-tuning\nobjectives in both in-domain training and cross-domain transfer. SQATIN yields\nparticularly large performance gains in cross-domain transfer, owing to the\nfact that our QA-based instruction tuning leverages similarities between\nnatural language descriptions of classes (i.e., slots and intents) across\ndomains.",
            "author": [
                "Evgeniia Razumovskaia",
                "Goran Glava\u0161",
                "Anna Korhonen",
                "Ivan Vuli\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09502v1",
                "http://arxiv.org/pdf/2311.09502v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09500v2",
            "title": "Pseudo-keypoint RKHS Learning for Self-supervised 6DoF Pose Estimation",
            "updated": "2023-11-18T04:09:28Z",
            "published": "2023-11-16T01:52:24Z",
            "summary": "This paper addresses the simulation-to-real domain gap in 6DoF PE, and\nproposes a novel self-supervised keypoint radial voting-based 6DoF PE\nframework, effectively narrowing this gap using a learnable kernel in RKHS. We\nformulate this domain gap as a distance in high-dimensional feature space,\ndistinct from previous iterative matching methods. We propose an adapter\nnetwork, which evolves the network parameters from the source domain, which has\nbeen massively trained on synthetic data with synthetic poses, to the target\ndomain, which is trained on real data. Importantly, the real data training only\nuses pseudo-poses estimated by pseudo-keypoints, and thereby requires no real\ngroundtruth data annotations. RKHSPose achieves state-of-the-art performance on\nthree commonly used 6DoF PE datasets including LINEMOD (+4.2%), Occlusion\nLINEMOD (+2%), and YCB-Video (+3%). It also compares favorably to fully\nsupervised methods on all six applicable BOP core datasets, achieving within\n-10.8% to -0.3% of the top fully supervised results.",
            "author": [
                "Yangzheng Wu",
                "Michael Greenspan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09500v2",
                "http://arxiv.org/pdf/2311.09500v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09499v1",
            "title": "Center Focusing Network for Real-Time LiDAR Panoptic Segmentation",
            "updated": "2023-11-16T01:52:11Z",
            "published": "2023-11-16T01:52:11Z",
            "summary": "LiDAR panoptic segmentation facilitates an autonomous vehicle to\ncomprehensively understand the surrounding objects and scenes and is required\nto run in real time. The recent proposal-free methods accelerate the algorithm,\nbut their effectiveness and efficiency are still limited owing to the\ndifficulty of modeling non-existent instance centers and the costly\ncenter-based clustering modules. To achieve accurate and real-time LiDAR\npanoptic segmentation, a novel center focusing network (CFNet) is introduced.\nSpecifically, the center focusing feature encoding (CFFE) is proposed to\nexplicitly understand the relationships between the original LiDAR points and\nvirtual instance centers by shifting the LiDAR points and filling in the center\npoints. Moreover, to leverage the redundantly detected centers, a fast center\ndeduplication module (CDM) is proposed to select only one center for each\ninstance. Experiments on the SemanticKITTI and nuScenes panoptic segmentation\nbenchmarks demonstrate that our CFNet outperforms all existing methods by a\nlarge margin and is 1.6 times faster than the most efficient method. The code\nis available at https://github.com/GangZhang842/CFNet.",
            "author": [
                "Xiaoyan Li",
                "Gang Zhang",
                "Boyue Wang",
                "Yongli Hu",
                "Baocai Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09499v1",
                "http://arxiv.org/pdf/2311.09499v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09497v1",
            "title": "Peer Reviews of Peer Reviews: A Randomized Controlled Trial and Other\n  Experiments",
            "updated": "2023-11-16T01:40:07Z",
            "published": "2023-11-16T01:40:07Z",
            "summary": "Is it possible to reliably evaluate the quality of peer reviews? We study\nthis question driven by two primary motivations -- incentivizing high-quality\nreviewing using assessed quality of reviews and measuring changes to review\nquality in experiments. We conduct a large scale study at the NeurIPS 2022\nconference, a top-tier conference in machine learning, in which we invited\n(meta)-reviewers and authors to evaluate reviews given to submitted papers.\nFirst, we conduct a RCT to examine bias due to the length of reviews. We\ngenerate elongated versions of reviews by adding substantial amounts of\nnon-informative content. Participants in the control group evaluate the\noriginal reviews, whereas participants in the experimental group evaluate the\nartificially lengthened versions. We find that lengthened reviews are scored\n(statistically significantly) higher quality than the original reviews.\nAdditionally, in analysis of observational data we find that authors are\npositively biased towards reviews recommending acceptance of their own papers,\neven after controlling for confounders of review length, quality, and different\nnumbers of papers per author. We also measure disagreement rates between\nmultiple evaluations of the same review of 28%-32%, which is comparable to that\nof paper reviewers at NeurIPS. Further, we assess the amount of miscalibration\nof evaluators of reviews using a linear model of quality scores and find that\nit is similar to estimates of miscalibration of paper reviewers at NeurIPS.\nFinally, we estimate the amount of variability in subjective opinions around\nhow to map individual criteria to overall scores of review quality and find\nthat it is roughly the same as that in the review of papers. Our results\nsuggest that the various problems that exist in reviews of papers --\ninconsistency, bias towards irrelevant factors, miscalibration, subjectivity --\nalso arise in reviewing of reviews.",
            "author": [
                "Alexander Goldberg",
                "Ivan Stelmakh",
                "Kyunghyun Cho",
                "Alice Oh",
                "Alekh Agarwal",
                "Danielle Belgrave",
                "Nihar B. Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09497v1",
                "http://arxiv.org/pdf/2311.09497v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10776v2",
            "title": "Towards an Automatic AI Agent for Reaction Condition Recommendation in\n  Chemical Synthesis",
            "updated": "2023-11-28T02:21:40Z",
            "published": "2023-11-16T01:21:33Z",
            "summary": "Artificial intelligence (AI) for reaction condition optimization has become\nan important topic in the pharmaceutical industry, given that a data-driven AI\nmodel can assist drug discovery and accelerate reaction design. However,\nexisting AI models lack the chemical insights and real-time knowledge\nacquisition abilities of experienced human chemists. This paper proposes a\nLarge Language Model (LLM) empowered AI agent to bridge this gap. We put forth\na novel three-phase paradigm and applied advanced intelligence-enhancement\nmethods like in-context learning and multi-LLM debate so that the AI agent can\nborrow human insight and update its knowledge by searching the latest chemical\nliterature. Additionally, we introduce a novel Coarse-label Contrastive\nLearning (CCL) based chemical fingerprint that greatly enhances the agent's\nperformance in optimizing the reaction condition. With the above efforts, the\nproposed AI agent can autonomously generate the optimal reaction condition\nrecommendation without any human interaction. Further, the agent is highly\nprofessional in terms of chemical reactions. It demonstrates close-to-human\nperformance and strong generalization capability in both dry-lab and wet-lab\nexperiments. As the first attempt in the chemical AI agent, this work goes a\nstep further in the field of \"AI for chemistry\" and opens up new possibilities\nfor computer-aided synthesis planning.",
            "author": [
                "Kexin Chen",
                "Junyou Li",
                "Kunyi Wang",
                "Yuyang Du",
                "Jiahui Yu",
                "Jiamin Lu",
                "Lanqing Li",
                "Jiezhong Qiu",
                "Qun Fang",
                "Pheng Ann Heng",
                "Guangyong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10776v2",
                "http://arxiv.org/pdf/2311.10776v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09489v1",
            "title": "MirrorNet: A TEE-Friendly Framework for Secure On-device DNN Inference",
            "updated": "2023-11-16T01:21:19Z",
            "published": "2023-11-16T01:21:19Z",
            "summary": "Deep neural network (DNN) models have become prevalent in edge devices for\nreal-time inference. However, they are vulnerable to model extraction attacks\nand require protection. Existing defense approaches either fail to fully\nsafeguard model confidentiality or result in significant latency issues. To\novercome these challenges, this paper presents MirrorNet, which leverages\nTrusted Execution Environment (TEE) to enable secure on-device DNN inference.\nIt generates a TEE-friendly implementation for any given DNN model to protect\nthe model confidentiality, while meeting the stringent computation and storage\nconstraints of TEE. The framework consists of two key components: the backbone\nmodel (BackboneNet), which is stored in the normal world but achieves lower\ninference accuracy, and the Companion Partial Monitor (CPM), a lightweight\nmirrored branch stored in the secure world, preserving model confidentiality.\nDuring inference, the CPM monitors the intermediate results from the\nBackboneNet and rectifies the classification output to achieve higher accuracy.\nTo enhance flexibility, MirrorNet incorporates two modules: the CPM Strategy\nGenerator, which generates various protection strategies, and the Performance\nEmulator, which estimates the performance of each strategy and selects the most\noptimal one. Extensive experiments demonstrate the effectiveness of MirrorNet\nin providing security guarantees while maintaining low computation latency,\nmaking MirrorNet a practical and promising solution for secure on-device DNN\ninference. For the evaluation, MirrorNet can achieve a 18.6% accuracy gap\nbetween authenticated and illegal use, while only introducing 0.99% hardware\noverhead.",
            "author": [
                "Ziyu Liu",
                "Yukui Luo",
                "Shijin Duan",
                "Tong Zhou",
                "Xiaolin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09489v1",
                "http://arxiv.org/pdf/2311.09489v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09486v1",
            "title": "The impact of effective participation in stopping misinformation: an\n  approach based on Branching Process",
            "updated": "2023-11-16T01:14:18Z",
            "published": "2023-11-16T01:14:18Z",
            "summary": "The emergence of research focused to understand the spreading and impact of\ndisinformation is increasing year over year. Most times, the purpose of those\nwho start the spreading of information intentionally false and designed to\ncause harm is in catalyzing its fast transformation into misinformation, which\nis the false content shared by people who do not realize it is false or\nmisleading. Our interest is in discussing the role of people who decide to\nadopt an active role in stopping the propagation of an information when they\nrealize that it is false. For this, we formulate two simple probabilistic\nmodels to compare misinformation spreading in the possible scenarios for which\nthere is a passive or an active environment of aware individuals. With aware\nindividuals we mean those individuals who realize that a given information is\nfalse or misleading. In the passive environment we assume that if one of an\naware individual is exposed to the misinformation then he/she will not spread\nit. In the active environment we assume that if one of an aware individual is\nexposed to the misinformation then he/she will not spread it but also he/she\nwill stop the propagation to other individuals from the individual who\ncontacted him/her. We appeal to the theory of branching processes to analyse\npropagation in both scenarios and we discuss the role and the impact of\neffective participation in stopping misinformation. We show that the\npropagation reduces drastically provided we assume an active environment, and\nwe obtain theoretical and computational results to measure such a reduction,\nwhich in turns depends on the proportion of aware individuals and the number of\npotential contacts of each individual which is assumed to be random.",
            "author": [
                "Luz Marina Gomez",
                "Valdivino V. Junior",
                "Pablo M. Rodriguez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09486v1",
                "http://arxiv.org/pdf/2311.09486v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09482v1",
            "title": "Robust Conformal Prediction for STL Runtime Verification under\n  Distribution Shift",
            "updated": "2023-11-16T00:54:34Z",
            "published": "2023-11-16T00:54:34Z",
            "summary": "Cyber-physical systems (CPS) designed in simulators behave differently in the\nreal-world. Once they are deployed in the real-world, we would hence like to\npredict system failures during runtime. We propose robust predictive runtime\nverification (RPRV) algorithms under signal temporal logic (STL) tasks for\ngeneral stochastic CPS. The RPRV problem faces several challenges: (1) there\nmay not be sufficient data of the behavior of the deployed CPS, (2) predictive\nmodels are based on a distribution over system trajectories encountered during\nthe design phase, i.e., there may be a distribution shift during deployment. To\naddress these challenges, we assume to know an upper bound on the statistical\ndistance (in terms of an f-divergence) between the distributions at deployment\nand design time, and we utilize techniques based on robust conformal\nprediction. Motivated by our results in [1], we construct an accurate and an\ninterpretable RPRV algorithm. We use a trajectory prediction model to estimate\nthe system behavior at runtime and robust conformal prediction to obtain\nprobabilistic guarantees by accounting for distribution shifts. We precisely\nquantify the relationship between calibration data, desired confidence, and\npermissible distribution shift. To the best of our knowledge, these are the\nfirst statistically valid algorithms under distribution shift in this setting.\nWe empirically validate our algorithms on a Franka manipulator within the\nNVIDIA Isaac sim environment.",
            "author": [
                "Yiqi Zhao",
                "Bardh Hoxha",
                "Georgios Fainekos",
                "Jyotirmoy V. Deshmukh",
                "Lars Lindemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09482v1",
                "http://arxiv.org/pdf/2311.09482v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LO",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09481v1",
            "title": "Personalized Jargon Identification for Enhanced Interdisciplinary\n  Communication",
            "updated": "2023-11-16T00:51:25Z",
            "published": "2023-11-16T00:51:25Z",
            "summary": "Scientific jargon can impede researchers when they read materials from other\ndomains. Current methods of jargon identification mainly use corpus-level\nfamiliarity indicators (e.g., Simple Wikipedia represents plain language).\nHowever, researchers' familiarity of a term can vary greatly based on their own\nbackground. We collect a dataset of over 10K term familiarity annotations from\n11 computer science researchers for terms drawn from 100 paper abstracts.\nAnalysis of this data reveals that jargon familiarity and information needs\nvary widely across annotators, even within the same sub-domain (e.g., NLP). We\ninvestigate features representing individual, sub-domain, and domain knowledge\nto predict individual jargon familiarity. We compare supervised and\nprompt-based approaches, finding that prompt-based methods including personal\npublications yields the highest accuracy, though zero-shot prompting provides a\nstrong baseline. This research offers insight into features and methods to\nintegrate personal data into scientific jargon identification.",
            "author": [
                "Yue Guo",
                "Joseph Chee Chang",
                "Maria Antoniak",
                "Erin Bransom",
                "Trevor Cohen",
                "Lucy Lu Wang",
                "Tal August"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09481v1",
                "http://arxiv.org/pdf/2311.09481v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09480v1",
            "title": "Show Your Work with Confidence: Confidence Bands for Tuning Curves",
            "updated": "2023-11-16T00:50:37Z",
            "published": "2023-11-16T00:50:37Z",
            "summary": "The choice of hyperparameters greatly impacts performance in natural language\nprocessing. Often, it is hard to tell if a method is better than another or\njust better tuned. Tuning curves fix this ambiguity by accounting for tuning\neffort. Specifically, they plot validation performance as a function of the\nnumber of hyperparameter choices tried so far. While several estimators exist\nfor these curves, it is common to use point estimates, which we show fail\nsilently and give contradictory results when given too little data.\n  Beyond point estimates, confidence bands are necessary to rigorously\nestablish the relationship between different approaches. We present the first\nmethod to construct valid confidence bands for tuning curves. The bands are\nexact, simultaneous, and distribution-free, thus they provide a robust basis\nfor comparing methods.\n  Empirical analysis shows that while bootstrap confidence bands, which serve\nas a baseline, fail to approximate their target confidence, ours achieve it\nexactly. We validate our design with ablations, analyze the effect of sample\nsize, and provide guidance on comparing models with our method. To promote\nconfident comparisons in future work, we release a library implementing the\nmethod at https://github.com/nalourie/opda .",
            "author": [
                "Nicholas Lourie",
                "Kyunghyun Cho",
                "He He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09480v1",
                "http://arxiv.org/pdf/2311.09480v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09476v1",
            "title": "ARES: An Automated Evaluation Framework for Retrieval-Augmented\n  Generation Systems",
            "updated": "2023-11-16T00:39:39Z",
            "published": "2023-11-16T00:39:39Z",
            "summary": "Evaluating retrieval-augmented generation (RAG) systems traditionally relies\non hand annotations for input queries, passages to retrieve, and responses to\ngenerate. We introduce ARES, an Automated RAG Evaluation System, for evaluating\nRAG systems along the dimensions of context relevance, answer faithfulness, and\nanswer relevance. Using synthetic training data, ARES finetunes lightweight LM\njudges to assess the quality of individual RAG components. To mitigate\npotential prediction errors, ARES utilizes a small set of human-annotated\ndatapoints for prediction-powered inference (PPI). Across six different\nknowledge-intensive tasks in KILT and SuperGLUE, ARES accurately evaluates RAG\nsystems while using a few hundred human annotations during evaluation.\nFurthermore, ARES judges remain effective across domain shifts, proving\naccurate even after changing the type of queries and/or documents used in the\nevaluated RAG systems. We make our datasets and code for replication and\ndeployment available at https://github.com/stanford-futuredata/ARES.",
            "author": [
                "Jon Saad-Falcon",
                "Omar Khattab",
                "Christopher Potts",
                "Matei Zaharia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09476v1",
                "http://arxiv.org/pdf/2311.09476v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09473v1",
            "title": "JAB: Joint Adversarial Prompting and Belief Augmentation",
            "updated": "2023-11-16T00:35:54Z",
            "published": "2023-11-16T00:35:54Z",
            "summary": "With the recent surge of language models in different applications, attention\nto safety and robustness of these models has gained significant importance.\nHere we introduce a joint framework in which we simultaneously probe and\nimprove the robustness of a black-box target model via adversarial prompting\nand belief augmentation using iterative feedback loops. This framework utilizes\nan automated red teaming approach to probe the target model, along with a\nbelief augmenter to generate instructions for the target model to improve its\nrobustness to those adversarial probes. Importantly, the adversarial model and\nthe belief generator leverage the feedback from past interactions to improve\nthe effectiveness of the adversarial prompts and beliefs, respectively. In our\nexperiments, we demonstrate that such a framework can reduce toxic content\ngeneration both in dynamic cases where an adversary directly interacts with a\ntarget model and static cases where we use a static benchmark dataset to\nevaluate our model.",
            "author": [
                "Ninareh Mehrabi",
                "Palash Goyal",
                "Anil Ramakrishna",
                "Jwala Dhamala",
                "Shalini Ghosh",
                "Richard Zemel",
                "Kai-Wei Chang",
                "Aram Galstyan",
                "Rahul Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09473v1",
                "http://arxiv.org/pdf/2311.09473v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09471v1",
            "title": "Simulation Based Inference of BNS Kilonova Properties: A Case Study with\n  AT2017gfo",
            "updated": "2023-11-16T00:24:28Z",
            "published": "2023-11-16T00:24:28Z",
            "summary": "Kilonovae are a class of astronomical transients observed as counterparts to\nmergers of compact binary systems, such as a binary neutron star (BNS) or black\nhole-neutron star (BHNS) inspirals. They serve as probes for heavy-element\nnucleosynthesis in astrophysical environments, while together with\ngravitational wave emission constraining the distance to the merger itself,\nthey can place constraints on the Hubble constant. Obtaining the physical\nparameters (e.g. ejecta mass, velocity, composition) of a kilonova from\nobservations is a complex inverse problem, usually tackled by sampling-based\ninference methods such as Markov-chain Monte Carlo (MCMC) or nested sampling\ntechniques. These methods often rely on computing approximate likelihoods,\nsince a full simulation of compact object mergers involve expensive\ncomputations such as integrals, the calculation of likelihood of the observed\ndata given parameters can become intractable, rendering the likelihood-based\ninference approaches inapplicable. We propose here to use Simulation-based\nInference (SBI) techniques to infer the physical parameters of BNS kilonovae\nfrom their spectra, using simulations produced with KilonovaNet. Our model uses\nAmortized Neural Posterior Estimation (ANPE) together with an embedding neural\nnetwork to accurately predict posterior distributions from simulated spectra.\nWe further test our model with real observations from AT2017gfo, the only\nkilonova with multi-messenger data, and show that our estimates agree with\nprevious likelihood-based approaches.",
            "author": [
                "Phelipe A. Darc",
                "Clecio R. Bom",
                "Bernardo M. O. Fraga",
                "Charlie D. Kilpatrick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09471v1",
                "http://arxiv.org/pdf/2311.09471v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09469v1",
            "title": "Clarify When Necessary: Resolving Ambiguity Through Interaction with LMs",
            "updated": "2023-11-16T00:18:50Z",
            "published": "2023-11-16T00:18:50Z",
            "summary": "Resolving ambiguities through interaction is a hallmark of natural language,\nand modeling this behavior is a core challenge in crafting AI assistants. In\nthis work, we study such behavior in LMs by proposing a task-agnostic framework\nfor resolving ambiguity by asking users clarifying questions. Our framework\nbreaks down this objective into three subtasks: (1) determining when\nclarification is needed, (2) determining what clarifying question to ask, and\n(3) responding accurately with the new information gathered through\nclarification. We evaluate systems across three NLP applications: question\nanswering, machine translation and natural language inference. For the first\nsubtask, we present a novel uncertainty estimation approach, intent-sim, that\ndetermines the utility of querying for clarification by estimating the entropy\nover user intents. Our method consistently outperforms existing uncertainty\nestimation approaches at identifying predictions that will benefit from\nclarification. When only allowed to ask for clarification on 10% of examples,\nour system is able to double the performance gains over randomly selecting\nexamples to clarify. Furthermore, we find that intent-sim is robust,\ndemonstrating improvements across a wide range of NLP tasks and LMs. Together,\nour work lays foundation for studying clarifying interactions with LMs.",
            "author": [
                "Michael J. Q. Zhang",
                "Eunsol Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09469v1",
                "http://arxiv.org/pdf/2311.09469v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09468v1",
            "title": "Carbon Dioxide Emission Minimized Virtual Machine (VM) Placement in\n  Cloud-Fog Network Architecture",
            "updated": "2023-11-16T00:16:35Z",
            "published": "2023-11-16T00:16:35Z",
            "summary": "Cloud computing has provided economies of scale, savings, and efficiency for\nboth individual consumers and enterprises. Its key advantage is its ability to\nhandle increasing amounts of data and provide functionality that gives users\nthe ability to scale their computing resources, including processing, data\nstorage, and networking capabilities. Virtual Machines (VM), enabled via\nvirtualization technology, allow cloud service providers to deliver their\nservices to users. This, however, results in increasing carbon dioxide\nemissions from increased energy use. This paper introduces a Mixed-Integer\nLinear Programming (MILP) model that investigates the VM placement, focusing on\nthe British Telecom (BT) network topology, in a cloud-fog network architecture\nwhen renewable energy sources are introduced in the fog layer located near\ntraffic-producing sources. VMs can be placed on nodes hosted on the core,\nmetro, and access (fog) layers. We first investigate the effect of varying\ntraffic on IP over WDM power consumption in the backbone network and the number\nof optical carrier signals to serve the traffic over a period of time. We later\nextend the model to consider the CO2-minimized optimal virtual machine\nplacement given the sporadic traffic quantity, and the consideration of solar\nrenewable energy sources placed in data centers located in the access (fog)\nlayer throughout the day, imposed on the VM and the minimum workload\nrequirement of the VM to maintain a service level agreement (SLA).",
            "author": [
                "Tarek Bessalah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09468v1",
                "http://arxiv.org/pdf/2311.09468v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09467v1",
            "title": "Think While You Write: Hypothesis Verification Promotes Faithful\n  Knowledge-to-Text Generation",
            "updated": "2023-11-16T00:13:19Z",
            "published": "2023-11-16T00:13:19Z",
            "summary": "Neural knowledge-to-text generation models often struggle to faithfully\ngenerate descriptions for the input facts: they may produce hallucinations that\ncontradict the given facts, or describe facts not present in the input. To\nreduce hallucinations, we propose a novel decoding method, TWEAK (Think While\nEffectively Articulating Knowledge). TWEAK treats the generated sequences at\neach decoding step and its future sequences as hypotheses, and ranks each\ngeneration candidate based on how well their corresponding hypotheses support\nthe input facts using a Hypothesis Verification Model (HVM). We first\ndemonstrate the effectiveness of TWEAK by using a Natural Language Inference\n(NLI) model as the HVM and report improved faithfulness with minimal impact on\nthe quality. We then replace the NLI model with our task-specific HVM trained\nwith a first-of-a-kind dataset, FATE (Fact-Aligned Textual Entailment), which\npairs input facts with their faithful and hallucinated descriptions with the\nhallucinated spans marked. The new HVM improves the faithfulness and the\nquality further and runs faster. Overall the best TWEAK variants improve on\naverage 2.22/7.17 points on faithfulness measured by FactKB over WebNLG and\nTekGen/GenWiki, respectively, with only 0.14/0.32 points degradation on quality\nmeasured by BERTScore over the same datasets. Since TWEAK is a decoding-only\napproach, it can be integrated with any neural generative model without\nretraining.",
            "author": [
                "Yifu Qiu",
                "Varun Embar",
                "Shay B. Cohen",
                "Benjamin Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09467v1",
                "http://arxiv.org/pdf/2311.09467v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09466v1",
            "title": "Soft Matching Distance: A metric on neural representations that captures\n  single-neuron tuning",
            "updated": "2023-11-16T00:13:00Z",
            "published": "2023-11-16T00:13:00Z",
            "summary": "Common measures of neural representational (dis)similarity are designed to be\ninsensitive to rotations and reflections of the neural activation space.\nMotivated by the premise that the tuning of individual units may be important,\nthere has been recent interest in developing stricter notions of\nrepresentational (dis)similarity that require neurons to be individually\nmatched across networks. When two networks have the same size (i.e. same number\nof neurons), a distance metric can be formulated by optimizing over neuron\nindex permutations to maximize tuning curve alignment. However, it is not clear\nhow to generalize this metric to measure distances between networks with\ndifferent sizes. Here, we leverage a connection to optimal transport theory to\nderive a natural generalization based on \"soft\" permutations. The resulting\nmetric is symmetric, satisfies the triangle inequality, and can be interpreted\nas a Wasserstein distance between two empirical distributions. Further, our\nproposed metric avoids counter-intuitive outcomes suffered by alternative\napproaches, and captures complementary geometric insights into neural\nrepresentations that are entirely missed by rotation-invariant metrics.",
            "author": [
                "Meenakshi Khosla",
                "Alex H. Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09466v1",
                "http://arxiv.org/pdf/2311.09466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09465v2",
            "title": "A new stabilized time-spectral finite element solver for fast simulation\n  of blood flow",
            "updated": "2023-11-17T03:00:08Z",
            "published": "2023-11-16T00:09:59Z",
            "summary": "The increasing application of cardiorespiratory simulations for diagnosis and\nsurgical planning necessitates the development of computational methods\nsignificantly faster than the current technology. To achieve this objective, we\nleverage the time-periodic nature of these flows by discretizing equations in\nthe frequency domain instead of the time domain. This approach markedly reduces\nthe size of the discrete problem and, consequently, the simulation cost. With\nthis motivation, we introduce a finite element method for simulating\ntime-periodic flows that are physically stable. The proposed time-spectral\nmethod is formulated by augmenting the baseline Galerkin's method with a\nleast-squares penalty term. This penalty term is weighted by a\npositive-definite stabilization tensor, computed by solving an eigenvalue\nproblem that involves the contraction of the velocity convolution matrix with\nthe element metric tensor. The outcome is a formally stable residual-based\nmethod that emulates the standard time method when simulating steady flows.\nConsequently, it preserves the appealing properties of the standard method,\nincluding stability in strong convection and the convenient use of equal-order\ninterpolation functions for velocity and pressure, among other benefits. This\nmethod is tested on a patient-specific Fontan model at nominal Reynolds and\nWomersley numbers of 500 and 10, respectively, demonstrating its ability to\nreplicate conventional time simulation results using as few as 7 modes at 11%\nof the computational cost. Owing to its higher local-to-processor computation\ndensity, the proposed method also exhibits improved parallel scalability,\nthereby enabling efficient utilization of computational resources for the rapid\nsimulation of time-critical applications.",
            "author": [
                "Mahdi Esmaily",
                "Dongjie Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09465v2",
                "http://arxiv.org/pdf/2311.09465v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00027v1",
            "title": "Stealthy and Persistent Unalignment on Large Language Models via\n  Backdoor Injections",
            "updated": "2023-11-15T23:52:05Z",
            "published": "2023-11-15T23:52:05Z",
            "summary": "Recent developments in Large Language Models (LLMs) have manifested\nsignificant advancements. To facilitate safeguards against malicious\nexploitation, a body of research has concentrated on aligning LLMs with human\npreferences and inhibiting their generation of inappropriate content.\nUnfortunately, such alignments are often vulnerable: fine-tuning with a minimal\namount of harmful data can easily unalign the target LLM. While being\neffective, such fine-tuning-based unalignment approaches also have their own\nlimitations: (1) non-stealthiness, after fine-tuning, safety audits or\nred-teaming can easily expose the potential weaknesses of the unaligned models,\nthereby precluding their release/use. (2) non-persistence, the unaligned LLMs\ncan be easily repaired through re-alignment, i.e., fine-tuning again with\naligned data points. In this work, we show that it is possible to conduct\nstealthy and persistent unalignment on large language models via backdoor\ninjections. We also provide a novel understanding on the relationship between\nthe backdoor persistence and the activation pattern and further provide\nguidelines for potential trigger design. Through extensive experiments, we\ndemonstrate that our proposed stealthy and persistent unalignment can\nsuccessfully pass the safety evaluation while maintaining strong persistence\nagainst re-alignment defense.",
            "author": [
                "Yuanpu Cao",
                "Bochuan Cao",
                "Jinghui Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00027v1",
                "http://arxiv.org/pdf/2312.00027v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10775v1",
            "title": "ToolTalk: Evaluating Tool-Usage in a Conversational Setting",
            "updated": "2023-11-15T23:50:31Z",
            "published": "2023-11-15T23:50:31Z",
            "summary": "Large language models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users. Many\nrecent works seek to augment LLM-based assistants with external tools so they\ncan access private or up-to-date information and carry out actions on behalf of\nusers. To better measure the performance of these assistants, this paper\nintroduces ToolTalk, a benchmark consisting of complex user intents requiring\nmulti-step tool usage specified through dialogue. ToolTalk contains 28 tools\ngrouped into 7 plugins, and includes a complete simulated implementation of\neach tool, allowing for fully automated evaluation of assistants that rely on\nexecution feedback. ToolTalk also emphasizes tools that externally affect the\nworld rather than only tools for referencing or searching information. We\nevaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and\n50% respectively. Our analysis of the errors reveals three major categories and\nsuggests some future directions for improvement. We release ToolTalk at\nhttps://github.com/microsoft/ToolTalk.",
            "author": [
                "Nicholas Farn",
                "Richard Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10775v1",
                "http://arxiv.org/pdf/2311.10775v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09460v1",
            "title": "Near-Optimal Streaming Ellipsoidal Rounding for General Convex Polytopes",
            "updated": "2023-11-15T23:49:18Z",
            "published": "2023-11-15T23:49:18Z",
            "summary": "We give near-optimal algorithms for computing an ellipsoidal rounding of a\nconvex polytope whose vertices are given in a stream. The approximation factor\nis linear in the dimension (as in John's theorem) and only loses an excess\nlogarithmic factor in the aspect ratio of the polytope. Our algorithms are\nnearly optimal in two senses: first, their runtimes nearly match those of the\nmost efficient known algorithms for the offline version of the problem. Second,\ntheir approximation factors nearly match a lower bound we show against a\nnatural class of geometric streaming algorithms. In contrast to existing works\nin the streaming setting that compute ellipsoidal roundings only for centrally\nsymmetric convex polytopes, our algorithms apply to general convex polytopes.\nWe also show how to use our algorithms to construct coresets from a stream of\npoints that approximately preserve both the ellipsoidal rounding and the convex\nhull of the original set of points.",
            "author": [
                "Yury Makarychev",
                "Naren Sarayu Manoj",
                "Max Ovsiankin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09460v1",
                "http://arxiv.org/pdf/2311.09460v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09458v1",
            "title": "Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of\n  Lexical Overlap in Train and Test Reference Summaries",
            "updated": "2023-11-15T23:47:53Z",
            "published": "2023-11-15T23:47:53Z",
            "summary": "Ideal summarization models should generalize to novel summary-worthy content\nwithout remembering reference training summaries by rote. However, a single\naverage performance score on the entire test set is inadequate in determining\nsuch model competencies. We propose a fine-grained evaluation protocol by\npartitioning a test set based on the lexical similarity of reference test\nsummaries with training summaries. We observe up to a 5x (1.2x) difference in\nROUGE-2 (entity recall) scores between the subsets with the lowest and highest\nsimilarity. Next, we show that such training repetitions also make a model\nvulnerable to rote learning, reproducing data artifacts such as factual errors,\nespecially when reference test summaries are lexically close to training\nsummaries. Consequently, we propose to limit lexical repetitions in training\nsummaries during both supervised fine-tuning and likelihood calibration stages\nto improve the performance on novel test cases while retaining average\nperformance. Our automatic and human evaluations on novel test subsets and\nrecent news articles show that limiting lexical repetitions in training\nsummaries can prevent rote learning and improve generalization.",
            "author": [
                "Prafulla Kumar Choubey",
                "Alexander R. Fabbri",
                "Caiming Xiong",
                "Chien-Sheng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09458v1",
                "http://arxiv.org/pdf/2311.09458v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09452v1",
            "title": "Close the Gates to an Inhuman Future: How and why we should choose to\n  not develop superhuman general-purpose artificial intelligence",
            "updated": "2023-11-15T23:41:12Z",
            "published": "2023-11-15T23:41:12Z",
            "summary": "In the coming years, humanity may irreversibly cross a threshold by creating\nsuperhuman general-purpose artificial intelligence. This would present many\nunprecedented risks and is likely to be uncontrollable in several ways. We can\nchoose not to do so, starting by instituting hard limits on the computation\nthat can be used to train and run neural networks. With these limits in place,\nAI research and industry can work on making AI that humans can understand and\ncontrol, and from which we can reap enormous benefit.",
            "author": [
                "Anthony Aguirre"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09452v1",
                "http://arxiv.org/pdf/2311.09452v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10774v1",
            "title": "MMC: Advancing Multimodal Chart Understanding with Large-scale\n  Instruction Tuning",
            "updated": "2023-11-15T23:36:42Z",
            "published": "2023-11-15T23:36:42Z",
            "summary": "With the rapid development of large language models (LLMs) and their\nintegration into large multimodal models (LMMs), there has been impressive\nprogress in zero-shot completion of user-oriented vision-language tasks.\nHowever, a gap remains in the domain of chart image understanding due to the\ndistinct abstract components in charts. To address this, we introduce a\nlarge-scale MultiModal Chart Instruction (MMC-Instruction) dataset comprising\n600k instances supporting diverse tasks and chart types. Leveraging this data,\nwe develop MultiModal Chart Assistant (MMCA), an LMM that achieves\nstate-of-the-art performance on existing chart QA benchmarks. Recognizing the\nneed for a comprehensive evaluation of LMM chart understanding, we also propose\na MultiModal Chart Benchmark (MMC-Benchmark), a comprehensive human-annotated\nbenchmark with 9 distinct tasks evaluating reasoning capabilities over charts.\nExtensive experiments on MMC-Benchmark reveal the limitations of existing LMMs\non correctly interpreting charts, even for the most recent GPT-4V model. Our\nwork provides an instruction-tuning methodology and benchmark to advance\nmultimodal understanding of charts.",
            "author": [
                "Fuxiao Liu",
                "Xiaoyang Wang",
                "Wenlin Yao",
                "Jianshu Chen",
                "Kaiqiang Song",
                "Sangwoo Cho",
                "Yaser Yacoob",
                "Dong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10774v1",
                "http://arxiv.org/pdf/2311.10774v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09447v1",
            "title": "How Trustworthy are Open-Source LLMs? An Assessment under Malicious\n  Demonstrations Shows their Vulnerabilities",
            "updated": "2023-11-15T23:33:07Z",
            "published": "2023-11-15T23:33:07Z",
            "summary": "The rapid progress in open-source Large Language Models (LLMs) is\nsignificantly driving AI development forward. However, there is still a limited\nunderstanding of their trustworthiness. Deploying these models at scale without\nsufficient trustworthiness can pose significant risks, highlighting the need to\nuncover these issues promptly. In this work, we conduct an assessment of\nopen-source LLMs on trustworthiness, scrutinizing them across eight different\naspects including toxicity, stereotypes, ethics, hallucination, fairness,\nsycophancy, privacy, and robustness against adversarial demonstrations. We\npropose an enhanced Chain of Utterances-based (CoU) prompting strategy by\nincorporating meticulously crafted malicious demonstrations for trustworthiness\nattack. Our extensive experiments encompass recent and representative series of\nopen-source LLMs, including Vicuna, MPT, Falcon, Mistral, and Llama 2. The\nempirical outcomes underscore the efficacy of our attack strategy across\ndiverse aspects. More interestingly, our result analysis reveals that models\nwith superior performance in general NLP tasks do not always have greater\ntrustworthiness; in fact, larger models can be more vulnerable to attacks.\nAdditionally, models that have undergone instruction tuning, focusing on\ninstruction following, tend to be more susceptible, although fine-tuning LLMs\nfor safety alignment proves effective in mitigating adversarial trustworthiness\nattacks.",
            "author": [
                "Lingbo Mo",
                "Boshi Wang",
                "Muhao Chen",
                "Huan Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09447v1",
                "http://arxiv.org/pdf/2311.09447v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09445v1",
            "title": "A Software-Hardware Co-Optimized Toolkit for Deep Reinforcement Learning\n  on Heterogeneous Platforms",
            "updated": "2023-11-15T23:31:18Z",
            "published": "2023-11-15T23:31:18Z",
            "summary": "Deep Reinforcement Learning (DRL) is vital in various AI applications. DRL\nalgorithms comprise diverse compute kernels, which may not be simultaneously\noptimized using a homogeneous architecture. However, even with available\nheterogeneous architectures, optimizing DRL performance remains a challenge due\nto the complexity of hardware and programming models employed in modern data\ncenters. To address this, we introduce PEARL, a toolkit for composing parallel\nDRL systems on heterogeneous platforms consisting of general-purpose processors\n(CPUs) and accelerators (GPUs, FPGAs). Our innovations include: 1. A general\ntraining protocol agnostic of the underlying hardware, enabling portable\nimplementations across various processors and accelerators. 2. Incorporation of\nDRL-specific scheduling optimizations within the protocol, facilitating\nparallelized training and enhancing the overall system performance. 3.\nHigh-level API for productive development using the toolkit. 4. Automatic\noptimization of DRL task-to-device assignments through performance estimation,\nsupporting various optimization metrics including throughput and power\nefficiency.\n  We showcase our toolkit through experimentation with two widely used DRL\nalgorithms, DQN and DDPG, on two diverse heterogeneous platforms. The generated\nimplementations outperform state-of-the-art libraries for CPU-GPU platforms by\nthroughput improvements of up to 2.1$\\times$ and power efficiency improvements\nof up to 3.4$\\times$.",
            "author": [
                "Yuan Meng",
                "Michael Kinsner",
                "Deshanand Singh",
                "Mahesh A Iyer",
                "Viktor Prasanna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09445v1",
                "http://arxiv.org/pdf/2311.09445v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09443v1",
            "title": "Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset",
            "updated": "2023-11-15T23:27:19Z",
            "published": "2023-11-15T23:27:19Z",
            "summary": "Using novel approaches to dataset development, the Biasly dataset captures\nthe nuance and subtlety of misogyny in ways that are unique within the\nliterature. Built in collaboration with multi-disciplinary experts and\nannotators themselves, the dataset contains annotations of movie subtitles,\ncapturing colloquial expressions of misogyny in North American film. The\ndataset can be used for a range of NLP tasks, including classification,\nseverity score regression, and text generation for rewrites. In this paper, we\ndiscuss the methodology used, analyze the annotations obtained, and provide\nbaselines using common NLP algorithms in the context of misogyny detection and\nmitigation. We hope this work will promote AI for social good in NLP for bias\ndetection, explanation, and removal.",
            "author": [
                "Brooklyn Sheppard",
                "Anna Richter",
                "Allison Cohen",
                "Elizabeth Allyn Smith",
                "Tamara Kneese",
                "Carolyne Pelletier",
                "Ioana Baldini",
                "Yue Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09443v1",
                "http://arxiv.org/pdf/2311.09443v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09441v1",
            "title": "Exploring the Privacy-Energy Consumption Tradeoff for Split Federated\n  Learning",
            "updated": "2023-11-15T23:23:42Z",
            "published": "2023-11-15T23:23:42Z",
            "summary": "Split Federated Learning (SFL) has recently emerged as a promising\ndistributed learning technology, leveraging the strengths of both federated\nlearning and split learning. It emphasizes the advantages of rapid convergence\nwhile addressing privacy concerns. As a result, this innovation has received\nsignificant attention from both industry and academia. However, since the model\nis split at a specific layer, known as a cut layer, into both client-side and\nserver-side models for the SFL, the choice of the cut layer in SFL can have a\nsubstantial impact on the energy consumption of clients and their privacy, as\nit influences the training burden and the output of the client-side models.\nMoreover, the design challenge of determining the cut layer is highly\nintricate, primarily due to the inherent heterogeneity in the computing and\nnetworking capabilities of clients. In this article, we provide a comprehensive\noverview of the SFL process and conduct a thorough analysis of energy\nconsumption and privacy. This analysis takes into account the influence of\nvarious system parameters on the cut layer selection strategy. Additionally, we\nprovide an illustrative example of the cut layer selection, aiming to minimize\nthe risk of clients from reconstructing the raw data at the server while\nsustaining energy consumption within the required energy budget, which involve\ntrade-offs. Finally, we address open challenges in this field including their\napplications to 6G technology. These directions represent promising avenues for\nfuture research and development.",
            "author": [
                "Joohyung Lee",
                "Mohamed Seif",
                "Jungchan Cho",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09441v1",
                "http://arxiv.org/pdf/2311.09441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09440v1",
            "title": "On the Relevance of Blockchain Evaluations on Bare Metal",
            "updated": "2023-11-15T23:23:35Z",
            "published": "2023-11-15T23:23:35Z",
            "summary": "In this paper, we present the first bare metal comparison of modern\nblockchains, including Algorand, Avalanche, Diem, Ethereum, Quorum and Solana.\nThis evaluation was conducted with the recent Diablo benchmark suite, a\nframework to evaluate the performance of different blockchains on the same\nground. By tuning network delays in our controlled environment we were able to\nreproduce performance trends obtained in geo-distributed settings, hence\ndemonstrating the relevance of bare metal evaluations to better understand\nblockchain performance.",
            "author": [
                "Andrei Lebedev",
                "Vincent Gramoli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09440v1",
                "http://arxiv.org/pdf/2311.09440v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09438v1",
            "title": "Labeled Interactive Topic Models",
            "updated": "2023-11-15T23:18:01Z",
            "published": "2023-11-15T23:18:01Z",
            "summary": "Topic models help users understand large document collections; however, topic\nmodels do not always find the ``right'' topics. While classical probabilistic\nand anchor-based topic models have interactive variants to guide models toward\nbetter topics, such interactions are not available for neural topic models such\nas the embedded topic model (\\abr{etm}). We correct this lacuna by adding an\nintuitive interaction to neural topic models: users can label a topic with a\nword, and topics are updated so that the topic words are close to the label.\nThis allows a user to refine topics based on their information need. While,\ninteractivity is intuitive for \\abr{etm}, we extend this framework to work with\nother neural topic models as well. We develop an interactive interface which\nallows users to interact and relabel topic models as they see fit. We evaluate\nour method through a human study, where users can relabel topics to find\nrelevant documents. Using our method, user labeling improves document rank\nscores, helping to find more relevant documents to a given query when compared\nto no user labeling.",
            "author": [
                "Kyle Seelman",
                "Mozhi Zhang",
                "Jordan Boyd-Graber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09438v1",
                "http://arxiv.org/pdf/2311.09438v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.HC",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09437v1",
            "title": "Entangleware Sequencer: A Control Platform for Atomic Physics\n  Experiments",
            "updated": "2023-11-15T23:14:43Z",
            "published": "2023-11-15T23:14:43Z",
            "summary": "Experimental quantum physics and computing platforms rely on sophisticated\ncomputer control and timing systems that must be deterministic. An exemplar is\nthe sequence used to create a Bose-Einstein condensate at the University of\nIllinois, which involves 46,812 analog and digital transitions over 100 seconds\nwith 20 ns timing precision and nanosecond timing drift. We present a control\nand sequencing platform, using industry-standard National Instruments hardware\nto generate the necessary digital and analog signals, that achieves this level\nof performance. The system uses a master 10 MHz reference clock that is\nconditioned to the Global Positioning Satellite constellation and leverages\nlow-phase-noise clock distribution hardware for timing stability. A\nPython-based user front-end provides a flexible language to describe\nexperimental procedures and easy-to-implement version control. A library of\nuseful peripheral hardware that can be purchased as low-cost evaluation boards\nprovides enhanced capabilities. We provide a GitHub repository containing\nexample python sequences and libraries for peripheral devices as a resource for\nthe community.",
            "author": [
                "N. Kowalski",
                "N. Fredman",
                "J. Zirbel",
                "B. DeMarco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09437v1",
                "http://arxiv.org/pdf/2311.09437v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09433v2",
            "title": "Backdoor Activation Attack: Attack Large Language Models using\n  Activation Steering for Safety-Alignment",
            "updated": "2023-11-24T16:22:41Z",
            "published": "2023-11-15T23:07:40Z",
            "summary": "To ensure AI safety, instruction-tuned Large Language Models (LLMs) are\nspecifically trained to ensure alignment, which refers to making models behave\nin accordance with human intentions. While these models have demonstrated\ncommendable results on various safety benchmarks, the vulnerability of their\nsafety alignment has not been extensively studied. This is particularly\ntroubling given the potential harm that LLMs can inflict. Existing attack\nmethods on LLMs often rely on poisoned training data or the injection of\nmalicious prompts. These approaches compromise the stealthiness and\ngeneralizability of the attacks, making them susceptible to detection.\nAdditionally, these models often demand substantial computational resources for\nimplementation, making them less practical for real-world applications.\nInspired by recent success in modifying model behavior through steering vectors\nwithout the need for optimization, and drawing on its effectiveness in\nred-teaming LLMs, we conducted experiments employing activation steering to\ntarget four key aspects of LLMs: truthfulness, toxicity, bias, and harmfulness\n- across a varied set of attack settings. To establish a universal attack\nstrategy applicable to diverse target alignments without depending on manual\nanalysis, we automatically select the intervention layer based on contrastive\nlayer search. Our experiment results show that activation attacks are highly\neffective and add little or no overhead to attack efficiency. Additionally, we\ndiscuss potential countermeasures against such activation attacks. Our code and\ndata are available at https://github.com/wang2226/Backdoor-Activation-Attack\nWarning: this paper contains content that can be offensive or upsetting.",
            "author": [
                "Haoran Wang",
                "Kai Shu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09433v2",
                "http://arxiv.org/pdf/2311.09433v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09431v1",
            "title": "Striped Attention: Faster Ring Attention for Causal Transformers",
            "updated": "2023-11-15T23:01:02Z",
            "published": "2023-11-15T23:01:02Z",
            "summary": "To help address the growing demand for ever-longer sequence lengths in\ntransformer models, Liu et al. recently proposed Ring Attention, an exact\nattention algorithm capable of overcoming per-device memory bottle- necks by\ndistributing self-attention across multiple devices. In this paper, we study\nthe performance characteristics of Ring Attention in the important special case\nof causal transformer models, and identify a key workload imbal- ance due to\ntriangular structure of causal attention computations. We propose a simple\nextension to Ring Attention, which we call Striped Attention to fix this\nimbalance. Instead of devices having contiguous subsequences, each device has a\nsubset of tokens distributed uniformly throughout the sequence, which we\ndemonstrate leads to more even workloads. In experiments running Striped\nAttention on A100 GPUs and TPUv4s, we are able to achieve up to 1.45x\nend-to-end throughput improvements over the original Ring Attention algorithm\non causal transformer training at a sequence length of 256k. Furthermore, on 16\nTPUv4 chips, we were able to achieve 1.65x speedups at sequence lengths of\n786k. We release the code for our experiments as open source",
            "author": [
                "William Brandon",
                "Aniruddha Nrusimha",
                "Kevin Qian",
                "Zachary Ankner",
                "Tian Jin",
                "Zhiye Song",
                "Jonathan Ragan-Kelley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09431v1",
                "http://arxiv.org/pdf/2311.09431v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09428v2",
            "title": "Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language\n  Models",
            "updated": "2023-12-05T20:36:23Z",
            "published": "2023-11-15T22:57:13Z",
            "summary": "This work investigates the potential of undermining both fairness and\ndetection performance in abusive language detection. In a dynamic and complex\ndigital world, it is crucial to investigate the vulnerabilities of these\ndetection models to adversarial fairness attacks to improve their fairness\nrobustness. We propose a simple yet effective framework FABLE that leverages\nbackdoor attacks as they allow targeted control over the fairness and detection\nperformance. FABLE explores three types of trigger designs (i.e., rare,\nartificial, and natural triggers) and novel sampling strategies. Specifically,\nthe adversary can inject triggers into samples in the minority group with the\nfavored outcome (i.e., \"non-abusive\") and flip their labels to the unfavored\noutcome, i.e., \"abusive\". Experiments on benchmark datasets demonstrate the\neffectiveness of FABLE attacking fairness and utility in abusive language\ndetection.",
            "author": [
                "Yueqing Liang",
                "Lu Cheng",
                "Ali Payani",
                "Kai Shu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09428v2",
                "http://arxiv.org/pdf/2311.09428v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09426v1",
            "title": "Linear-Cost Vecchia Approximation of Multivariate Normal Probabilities",
            "updated": "2023-11-15T22:52:56Z",
            "published": "2023-11-15T22:52:56Z",
            "summary": "Multivariate normal (MVN) probabilities arise in myriad applications, but\nthey are analytically intractable and need to be evaluated via\nMonte-Carlo-based numerical integration. For the state-of-the-art minimax\nexponential tilting (MET) method, we show that the complexity of each of its\ncomponents can be greatly reduced through an integrand parameterization that\nutilizes the sparse inverse Cholesky factor produced by the Vecchia\napproximation, whose approximation error is often negligible relative to the\nMonte-Carlo error. Based on this idea, we derive algorithms that can estimate\nMVN probabilities and sample from truncated MVN distributions in linear time\n(and that are easily parallelizable) at the same convergence or acceptance rate\nas MET, whose complexity is cubic in the dimension of the MVN probability. We\nshowcase the advantages of our methods relative to existing approaches using\nseveral simulated examples. We also analyze a groundwater-contamination dataset\nwith over twenty thousand censored measurements to demonstrate the scalability\nof our method for partially censored Gaussian-process models.",
            "author": [
                "Jian Cao",
                "Matthias Katzfuss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09426v1",
                "http://arxiv.org/pdf/2311.09426v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09425v1",
            "title": "Robust and conservative dynamical low-rank methods for the Vlasov\n  equation via a novel macro-micro decomposition",
            "updated": "2023-11-15T22:52:07Z",
            "published": "2023-11-15T22:52:07Z",
            "summary": "Dynamical low-rank (DLR) approximation has gained interest in recent years as\na viable solution to the curse of dimensionality in the numerical solution of\nkinetic equations including the Boltzmann and Vlasov equations. These methods\ninclude the projector-splitting and Basis-update & Galerkin DLR integrators,\nand have shown promise at greatly improving the computational efficiency of\nkinetic solutions. However, this often comes at the cost of conservation of\ncharge, current and energy. In this work we show how a novel macro-micro\ndecomposition may be used to separate the distribution function into two\ncomponents, one of which carries the conserved quantities, and the other of\nwhich is orthogonal to them. We apply DLR approximation to the latter, and\nthereby achieve a clean and extensible approach to a conservative DLR scheme\nwhich retains the computational advantages of the base scheme. Moreover, our\ndecomposition is compatible with the projector-splitting integrator, and can\ntherefore access second-order accuracy in time via a Strang splitting scheme.\nWe describe a first-order integrator which can exactly conserve charge and\neither current or energy, as well as a second-order accurate integrator which\nexactly conserves charge and energy. To highlight the flexibility of the\nproposed macro-micro decomposition, we implement a pair of velocity space\ndiscretizations, and verify the claimed accuracy and conservation properties on\na suite of plasma benchmark problems.",
            "author": [
                "Jack Coughlin",
                "Jingwei Hu",
                "Uri Shumlak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09425v1",
                "http://arxiv.org/pdf/2311.09425v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "physics.comp-ph",
                "35Q61, 35Q83, 65M06, 65M70"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09424v1",
            "title": "Predicting Spine Geometry and Scoliosis from DXA Scans",
            "updated": "2023-11-15T22:49:08Z",
            "published": "2023-11-15T22:49:08Z",
            "summary": "Our objective in this paper is to estimate spine curvature in DXA scans. To\nthis end we first train a neural network to predict the middle spine curve in\nthe scan, and then use an integral-based method to determine the curvature\nalong the spine curve. We use the curvature to compare to the standard angle\nscoliosis measure obtained using the DXA Scoliosis Method (DSM). The\nperformance improves over the prior work of Jamaludin et al. 2018. We show that\nthe maximum curvature can be used as a scoring function for ordering the\nseverity of spinal deformation.",
            "author": [
                "Amir Jamaludin",
                "Timor Kadir",
                "Emma Clark",
                "Andrew Zisserman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09424v1",
                "http://arxiv.org/pdf/2311.09424v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09422v1",
            "title": "Predicting generalization performance with correctness discriminators",
            "updated": "2023-11-15T22:43:42Z",
            "published": "2023-11-15T22:43:42Z",
            "summary": "The ability to predict an NLP model's accuracy on unseen, potentially\nout-of-distribution data is a prerequisite for trustworthiness. We present a\nnovel model that establishes upper and lower bounds on the accuracy, without\nrequiring gold labels for the unseen data. We achieve this by training a\ndiscriminator which predicts whether the output of a given sequence-to-sequence\nmodel is correct or not. We show across a variety of tagging, parsing, and\nsemantic parsing tasks that the gold accuracy is reliably between the predicted\nupper and lower bounds, and that these bounds are remarkably close together.",
            "author": [
                "Yuekun Yao",
                "Alexander Koller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09422v1",
                "http://arxiv.org/pdf/2311.09422v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09413v1",
            "title": "Leveraging machine learning to enhance climate models: a review",
            "updated": "2023-11-15T22:30:32Z",
            "published": "2023-11-15T22:30:32Z",
            "summary": "Recent achievements in machine learning (Ml) have had a significant impact on\nvarious fields, including climate science. Climate modeling is very important\nand plays a crucial role in shaping the decisions of governments and\nindividuals in mitigating the impact of climate change. Climate change poses a\nserious threat to humanity, however, current climate models are limited by\ncomputational costs, uncertainties, and biases, affecting their prediction\naccuracy. The vast amount of climate data generated by satellites, radars, and\nearth system models (ESMS) poses a significant challenge. ML techniques can be\neffectively employed to analyze this data and extract valuable insights that\naid in our understanding of the earth climate. This review paper focuses on how\nml has been utilized in the last 5 years to boost the current state-of-the-art\nclimate models. We invite the ml community to join in the global effort to\naccurately model the earth climate by collaborating with other fields to\nleverage ml as a powerful tool in this endeavor.",
            "author": [
                "Ahmed Elsayed",
                "Shrouk Wally",
                "Islam Alkabbany",
                "Asem Ali",
                "Aly Farag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09413v1",
                "http://arxiv.org/pdf/2311.09413v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09411v1",
            "title": "Heteroskedasticity as a Signature of Association for Age-Related Genes",
            "updated": "2023-11-15T22:26:32Z",
            "published": "2023-11-15T22:26:32Z",
            "summary": "Human aging is a process controlled by both genetics and environment. Many\nstudies have been conducted to identify a subset of genes related to aging from\nthe human genome. Biologists implicitly categorize age-related genes into genes\nthat cause aging and genes that are influenced by aging, which resulted in both\ncausal inference and inference of associations studies. While inference of\nassociation is better explored, causal inference and computational causal\ninference, remains less explored. In this work, we are primarily motivated to\ntackle the problem of identifying genes associated with aging, while having a\nbrief look into genes with probable causal relations, both from a computational\nperspective. Specifically, we form a set of hypotheses and accordingly,\nintroduce a data-tailored framework for inference. First we perform linear\nmodeling on the expression values of age-related genes, and then examine the\npresence of heteroskedastic properties in the residual of the model. We\nevaluate this framework and our results suggest that, 1) presence of\nheteroskedasticity in these residuals is a potential signature of association\nfor age-related genes, and 2) consistent heteroskedasticity along the human\nlife span could imply some sort of causality. To our knowledge, along with\nidentifying age-associated genes, this is the first work to propose a framework\nfor computational causal inference on age-related genes, using a dataset of\nhuman dermal fibroblast gene expression data. Hence the results of our simple,\nyet effective approach can be used not only to assess future age-related genes,\nbut also as a possible criterion to select new associative or potential causal\ngenes with respect to aging.",
            "author": [
                "Salman Mohamadi",
                "Donald A. Adjeroh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09411v1",
                "http://arxiv.org/pdf/2311.09411v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09410v1",
            "title": "When Large Language Models contradict humans? Large Language Models'\n  Sycophantic Behaviour",
            "updated": "2023-11-15T22:18:33Z",
            "published": "2023-11-15T22:18:33Z",
            "summary": "Large Language Models (LLMs) have been demonstrating the ability to solve\ncomplex tasks by delivering answers that are positively evaluated by humans due\nin part to the intensive use of human feedback that refines responses. However,\nthe suggestibility transmitted through human feedback increases the inclination\nto produce responses that correspond to the user's beliefs or misleading\nprompts as opposed to true facts, a behaviour known as sycophancy. This\nphenomenon decreases the bias, robustness, and, consequently, their\nreliability.\n  In this paper, we shed light on the suggestibility of LLMs to sycophantic\nbehaviour, demonstrating these tendencies via human-influenced prompts over\ndifferent tasks. Our investigation reveals that LLMs show sycophantic\ntendencies when responding to queries involving subjective opinions and\nstatements that should elicit a contrary response based on facts, demonstrating\na lack of robustness.",
            "author": [
                "Leonardo Ranaldi",
                "Giulia Pucci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09410v1",
                "http://arxiv.org/pdf/2311.09410v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09406v1",
            "title": "Alternatives to the Scaled Dot Product for Attention in the Transformer\n  Neural Network Architecture",
            "updated": "2023-11-15T22:10:42Z",
            "published": "2023-11-15T22:10:42Z",
            "summary": "The transformer neural network architecture uses a form of attention in which\nthe dot product of query and key is divided by the square root of the key\ndimension before applying softmax. This scaling of the dot product is designed\nto avoid the absolute value of the dot products becoming so large that applying\nsoftmax leads to vanishing gradients. In this paper, we propose some\nalternative scalings, including dividing the dot product instead by the sum of\nthe key lengths before applying softmax. We use simulated keys and queries to\nshow that in many situations this appears to be more effective at avoiding\nregions where applying softmax leads to vanishing gradients.",
            "author": [
                "James Bernhard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09406v1",
                "http://arxiv.org/pdf/2311.09406v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.NE",
                "I.2.0; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09404v1",
            "title": "To Translate or Not to Translate: A Systematic Investigation of\n  Translation-Based Cross-Lingual Transfer to Low-Resource Languages",
            "updated": "2023-11-15T22:03:28Z",
            "published": "2023-11-15T22:03:28Z",
            "summary": "Perfect machine translation (MT) would render cross-lingual transfer (XLT) by\nmeans of multilingual language models (LMs) superfluous. Given, on one hand,\nthe large body of work on improving XLT with multilingual LMs and, on the other\nhand, recent advances in massively multilingual MT, in this work, we\nsystematically evaluate existing and propose new translation-based XLT\napproaches for transfer to low-resource languages. We show that all\ntranslation-based approaches dramatically outperform zero-shot XLT with\nmultilingual LMs, rendering the approach that combines the round-trip\ntranslation of the source-language training data with the translation of the\ntarget-language test instances the most effective. We next show that one can\nobtain further empirical gains by adding reliable translations to other\nhigh-resource languages to the training data. Moreover, we propose an effective\ntranslation-based XLT strategy even for languages not supported by the MT\nsystem. Finally, we show that model selection for XLT based on target-language\nvalidation data obtained with MT outperforms model selection based on the\nsource-language data. We hope that our findings encourage adoption of more\nrobust translation-based baselines in XLT research.",
            "author": [
                "Benedikt Ebing",
                "Goran Glava\u0161"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09404v1",
                "http://arxiv.org/pdf/2311.09404v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09402v1",
            "title": "Synthetically Enhanced: Unveiling Synthetic Data's Potential in Medical\n  Imaging Research",
            "updated": "2023-11-15T21:58:01Z",
            "published": "2023-11-15T21:58:01Z",
            "summary": "Chest X-rays (CXR) are the most common medical imaging study and are used to\ndiagnose multiple medical conditions. This study examines the impact of\nsynthetic data supplementation, using diffusion models, on the performance of\ndeep learning (DL) classifiers for CXR analysis. We employed three datasets:\nCheXpert, MIMIC-CXR, and Emory Chest X-ray, training conditional denoising\ndiffusion probabilistic models (DDPMs) to generate synthetic frontal\nradiographs. Our approach ensured that synthetic images mirrored the\ndemographic and pathological traits of the original data. Evaluating the\nclassifiers' performance on internal and external datasets revealed that\nsynthetic data supplementation enhances model accuracy, particularly in\ndetecting less prevalent pathologies. Furthermore, models trained on synthetic\ndata alone approached the performance of those trained on real data. This\nsuggests that synthetic data can potentially compensate for real data shortages\nin training robust DL models. However, despite promising outcomes, the\nsuperiority of real data persists.",
            "author": [
                "Bardia Khosravi",
                "Frank Li",
                "Theo Dapamede",
                "Pouria Rouzrokh",
                "Cooper U. Gamble",
                "Hari M. Trivedi",
                "Cody C. Wyles",
                "Andrew B. Sellergren",
                "Saptarshi Purkayastha",
                "Bradley J. Erickson",
                "Judy W. Gichoya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09402v1",
                "http://arxiv.org/pdf/2311.09402v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09401v1",
            "title": "MoCo-Transfer: Investigating out-of-distribution contrastive learning\n  for limited-data domains",
            "updated": "2023-11-15T21:56:47Z",
            "published": "2023-11-15T21:56:47Z",
            "summary": "Medical imaging data is often siloed within hospitals, limiting the amount of\ndata available for specialized model development. With limited in-domain data,\none might hope to leverage larger datasets from related domains. In this paper,\nwe analyze the benefit of transferring self-supervised contrastive\nrepresentations from moment contrast (MoCo) pretraining on out-of-distribution\ndata to settings with limited data. We consider two X-ray datasets which image\ndifferent parts of the body, and compare transferring from each other to\ntransferring from ImageNet. We find that depending on quantity of labeled and\nunlabeled data, contrastive pretraining on larger out-of-distribution datasets\ncan perform nearly as well or better than MoCo pretraining in-domain, and\npretraining on related domains leads to higher performance than if one were to\nuse the ImageNet pretrained weights. Finally, we provide a preliminary way of\nquantifying similarity between datasets.",
            "author": [
                "Yuwen Chen",
                "Helen Zhou",
                "Zachary C. Lipton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09401v1",
                "http://arxiv.org/pdf/2311.09401v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09398v1",
            "title": "Photonic quantum computing on thin-film lithium niobate: Part I Design\n  of an efficient heralded single photon source co-integrated with\n  superconducting detectors",
            "updated": "2023-11-15T21:51:12Z",
            "published": "2023-11-15T21:51:12Z",
            "summary": "Photonic quantum computers are currently one of the primary candidates for\nfault-tolerant quantum computation. At the heart of the photonic quantum\ncomputation lies the strict requirement for suitable quantum sources e.g. high\npurity, high brightness single photon sources. To build a practical quantum\ncomputer, thousands to millions of such sources are required. In this article,\nwe theoretically propose a unique single-photon source design on a thin-film\nlithium niobate (TFLN) platform co-integrated with superconducting nanowire\nsingle-photon detectors. We show that with a judicial design of single photon\nsource using thin film periodically poled lithium waveguides (PPLN),\nback-illuminated grating couplers (GCs) and directly bonded or integrated\ncavity coupled superconducting nanowire single-photon detectors (SNSPDs) can\nlead to a simple but practical high efficiency heralded single-photon source\nusing the current fabrication technology. Such a device will eliminate the\nrequirement of out coupling of the generated photons and can lead to a fully\nintegrated solution. The proposed design can be useful for fusion-based quantum\ncomputation and for multiplexed single photon sources and also for efficient\non-chip generation and detection of squeezed light.",
            "author": [
                "A. Sayem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09398v1",
                "http://arxiv.org/pdf/2311.09398v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09395v1",
            "title": "SmoQyDQMC.jl: A flexible implementation of determinant quantum Monte\n  Carlo for Hubbard and electron-phonon interactions",
            "updated": "2023-11-15T21:43:22Z",
            "published": "2023-11-15T21:43:22Z",
            "summary": "We introduce the SmoQyDQMC.jl package, a Julia implementation of the\ndeterminant quantum Monte Carlo algorithm. SmoQyDQMC.jl supports generalized\ntight-binding Hamiltonians with on-site Hubbard and generalized electron-phonon\ninteractions, including non-linear $e$-ph coupling and anharmonic lattice\npotentials. Our implementations use hybrid Monte Carlo methods with exact\nforces for sampling the phonon fields, enabling efficient simulation of\nlow-energy phonon branches, including acoustic phonons. The SmoQyDQMC.jl\npackage also uses a flexible scripting interface, allowing users to adapt it to\ndifferent workflows and interface with other software packages in the Julia\necosystem. The code for this package can be downloaded from our GitHub\nrepository at https://github.com/SmoQySuite/SmoQyDQMC.jl or installed using the\nJulia package manager. The online documentation, including examples, can be\nobtained from our document page at\nhttps://smoqysuite.github.io/SmoQyDQMC.jl/stable/.",
            "author": [
                "Benjamin Cohen-Stead",
                "Sohan Malkaruge Costa",
                "James Neuhaus",
                "Andy Tanjaroon Ly",
                "Yutan Zhang",
                "Richard Scalettar",
                "Kipton Barros",
                "Steven Johnston"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09395v1",
                "http://arxiv.org/pdf/2311.09395v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.stat-mech",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09393v1",
            "title": "Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic\n  Oblivious Computation",
            "updated": "2023-11-15T21:39:30Z",
            "published": "2023-11-15T21:39:30Z",
            "summary": "Secure multiparty computation (MPC) techniques enable multiple parties to\ncompute joint functions over their private data without sharing that data to\nother parties, typically by employing powerful cryptographic protocols to\nprotect individual's data. One challenge when writing such functions is that\nmost MPC languages force users to intermix programmatic and privacy concerns in\na single application, making it difficult to change or audit a program's\nunderlying privacy policy. Existing policy-agnostic MPC languages rely on\nrun-time / dynamic enforcement to decouple privacy requirements from program\nlogic. Unfortunately, the resulting overhead makes it difficult to scale MPC\napplications that manipulate structured data. This work proposes to eliminate\nthis overhead by instead transforming programs to semantically equivalent\nversions that statically enforce user-provided privacy policies. We have\nimplemented this approach in a new MPC language, called Taypsi; our\nexperimental evaluation demonstrates that the resulting system features\nconsiderable performance improvements on a variety of MPC applications\ninvolving structured data and complex privacy polices.",
            "author": [
                "Qianchuan Ye",
                "Benjamin Delaware"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09393v1",
                "http://arxiv.org/pdf/2311.09393v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09390v1",
            "title": "LEEETs-Dial: Linguistic Entrainment in End-to-End Task-oriented Dialogue\n  systems",
            "updated": "2023-11-15T21:35:25Z",
            "published": "2023-11-15T21:35:25Z",
            "summary": "Linguistic entrainment, or alignment, represents a phenomenon where\nlinguistic patterns employed by conversational participants converge to one\nanother. While alignment has been shown to produce a more natural user\nexperience, most dialogue systems do not have any provisions for it. In this\nwork, we introduce methods for achieving dialogue alignment in a GPT-2-based\nend-to-end dialogue system through the utilization of shared vocabulary. We\nexperiment with training instance weighting, alignment-specific loss, and\nadditional conditioning to generate responses that align with the user. By\ncomparing different entrainment techniques on the MultiWOZ dataset, we\ndemonstrate that all three approaches produce significantly better-aligned\nresults than the baseline, as confirmed by both automated and manual evaluation\nmetrics.",
            "author": [
                "Nalin Kumar",
                "Ond\u0159ej Du\u0161ek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09390v1",
                "http://arxiv.org/pdf/2311.09390v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09389v1",
            "title": "Neural machine translation for automated feedback on children's\n  early-stage writing",
            "updated": "2023-11-15T21:32:44Z",
            "published": "2023-11-15T21:32:44Z",
            "summary": "In this work, we address the problem of assessing and constructing feedback\nfor early-stage writing automatically using machine learning. Early-stage\nwriting is typically vastly different from conventional writing due to phonetic\nspelling and lack of proper grammar, punctuation, spacing etc. Consequently,\nearly-stage writing is highly non-trivial to analyze using common linguistic\nmetrics. We propose to use sequence-to-sequence models for \"translating\"\nearly-stage writing by students into \"conventional\" writing, which allows the\ntranslated text to be analyzed using linguistic metrics. Furthermore, we\npropose a novel robust likelihood to mitigate the effect of noise in the\ndataset. We investigate the proposed methods using a set of numerical\nexperiments and demonstrate that the conventional text can be predicted with\nhigh accuracy.",
            "author": [
                "Jonas Vestergaard Jensen",
                "Mikkel Jordahn",
                "Michael Riis Andersen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09389v1",
                "http://arxiv.org/pdf/2311.09389v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09387v2",
            "title": "Banach-Tarski Embeddings and Transformers",
            "updated": "2023-11-21T18:31:57Z",
            "published": "2023-11-15T21:30:26Z",
            "summary": "We introduce a new construction of embeddings of arbitrary recursive data\nstructures into high dimensional vectors. These embeddings provide an\ninterpretable model for the latent state vectors of transformers. We\ndemonstrate that these embeddings can be decoded to the original data structure\nwhen the embedding dimension is sufficiently large. This decoding algorithm has\na natural implementation as a transformer. We also show that these embedding\nvectors can be manipulated directly to perform computations on the underlying\ndata without decoding. As an example we present an algorithm that constructs\nthe embedded parse tree of an embedded token sequence using only vector\noperations in embedding space.",
            "author": [
                "Joshua Maher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09387v2",
                "http://arxiv.org/pdf/2311.09387v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10112v1",
            "title": "Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large\n  Language Models",
            "updated": "2023-11-15T21:25:15Z",
            "published": "2023-11-15T21:25:15Z",
            "summary": "In recent years, modeling evolving knowledge over temporal knowledge graphs\n(TKGs) has become a heated topic. Various methods have been proposed to\nforecast links on TKGs. Most of them are embedding-based, where hidden\nrepresentations are learned to represent knowledge graph (KG) entities and\nrelations based on the observed graph contexts. Although these methods show\nstrong performance on traditional TKG forecasting (TKGF) benchmarks, they\nnaturally face a strong challenge when they are asked to model the unseen\nzero-shot relations that has no prior graph context. In this paper, we try to\nmitigate this problem as follows. We first input the text descriptions of KG\nrelations into large language models (LLMs) for generating relation\nrepresentations, and then introduce them into embedding-based TKGF methods.\nLLM-empowered representations can capture the semantic information in the\nrelation descriptions. This makes the relations, whether seen or unseen, with\nsimilar semantic meanings stay close in the embedding space, enabling TKGF\nmodels to recognize zero-shot relations even without any observed graph\ncontext. Experimental results show that our approach helps TKGF models to\nachieve much better performance in forecasting the facts with previously unseen\nrelations, while still maintaining their ability in link forecasting regarding\nseen relations.",
            "author": [
                "Zifeng Ding",
                "Heling Cai",
                "Jingpei Wu",
                "Yunpu Ma",
                "Ruotong Liao",
                "Bo Xiong",
                "Volker Tresp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10112v1",
                "http://arxiv.org/pdf/2311.10112v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09383v1",
            "title": "Long-form Question Answering: An Iterative Planning-Retrieval-Generation\n  Approach",
            "updated": "2023-11-15T21:22:27Z",
            "published": "2023-11-15T21:22:27Z",
            "summary": "Long-form question answering (LFQA) poses a challenge as it involves\ngenerating detailed answers in the form of paragraphs, which go beyond simple\nyes/no responses or short factual answers. While existing QA models excel in\nquestions with concise answers, LFQA requires handling multiple topics and\ntheir intricate relationships, demanding comprehensive explanations. Previous\nattempts at LFQA focused on generating long-form answers by utilizing relevant\ncontexts from a corpus, relying solely on the question itself. However, they\noverlooked the possibility that the question alone might not provide sufficient\ninformation to identify the relevant contexts. Additionally, generating\ndetailed long-form answers often entails aggregating knowledge from diverse\nsources. To address these limitations, we propose an LFQA model with iterative\nPlanning, Retrieval, and Generation. This iterative process continues until a\ncomplete answer is generated for the given question. From an extensive\nexperiment on both an open domain and a technical domain QA dataset, we find\nthat our model outperforms the state-of-the-art models on various textual and\nfactual metrics for the LFQA task.",
            "author": [
                "Pritom Saha Akash",
                "Kashob Kumar Roy",
                "Lucian Popa",
                "Kevin Chen-Chuan Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09383v1",
                "http://arxiv.org/pdf/2311.09383v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09382v1",
            "title": "Non-conservation and conservation for different formulations of moist\n  potential vorticity",
            "updated": "2023-11-15T21:21:22Z",
            "published": "2023-11-15T21:21:22Z",
            "summary": "Potential vorticity (PV) is one of the most important quantities in\natmospheric science. The PV of each fluid parcel is known to be conserved in\nthe case of a dry atmosphere. However, a parcel's PV is not conserved if clouds\nor phase changes of water occur. Recently, PV conservation laws were derived\nfor a cloudy atmosphere, where each parcel's PV is not conserved but\nparcel-integrated PV is conserved, for integrals over certain volumes that move\nwith the flow. Hence a variety of different statements are now possible for\nmoist PV conservation and non-conservation, and in comparison to the case of a\ndry atmosphere, the situation for moist PV is more complex. Here, in light of\nthis complexity, several different definitions of moist PV are compared for a\ncloudy atmosphere. Numerical simulations are shown for a rising thermal, both\nbefore and after the formation of a cloud. These simulations include the first\ncomputational illustration of the parcel-integrated, moist PV conservation\nlaws. The comparisons, both theoretical and numerical, serve to clarify and\nhighlight the different statements of conservation and non-conservation that\narise for different definitions of moist PV.",
            "author": [
                "Parvathi Kooloth",
                "Leslie M. Smith",
                "Samuel N. Stechmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09382v1",
                "http://arxiv.org/pdf/2311.09382v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09380v1",
            "title": "Noncommutative invariants of dihedral groups",
            "updated": "2023-11-15T21:14:03Z",
            "published": "2023-11-15T21:14:03Z",
            "summary": "We consider the 2-generated free metabelian associative and Lie algebras over\nthe complex field and the invariants of the dihedral groups of finite order\nacting on these algebras. In the associative case we find a finite set of\ngenerators of the algebra of invariants. In the Lie case, when the algebra of\ninvariants is not finitely generated, we give a minimal system of generators of\nthe invariants in the commutator ideal as a module of the algebra of the\ninvariants in the polynomial algebra in two variables. In both associative and\nLie cases we compute the Hilbert series of the algebras of invariants.",
            "author": [
                "Vesselin Drensky",
                "Boyan Kostadinov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09380v1",
                "http://arxiv.org/pdf/2311.09380v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA",
                "math.CO",
                "math.GR",
                "16R10, 17B01, 05A15, 15A72, 16R40, 16W22, 17B30, 20D10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09379v1",
            "title": "A Characteristic Mapping Method for Vlasov-Poisson with Extreme\n  Resolution Properties",
            "updated": "2023-11-15T21:13:16Z",
            "published": "2023-11-15T21:13:16Z",
            "summary": "We propose an efficient semi-Lagrangian characteristic mapping method for\nsolving the one+one-dimensional Vlasov-Poisson equations with high precision on\na coarse grid. The flow map is evolved numerically and exponential resolution\nin linear time is obtained. Global third-order convergence in space and time is\nshown and conservation properties are assessed. For benchmarking, we consider\nlinear and nonlinear Landau damping and the two-stream instability. We compare\nthe results with a Fourier pseudo-spectral method. The extreme fine-scale\nresolution features are illustrated showing the method's capabilities to\nefficiently treat filamentation in fusion plasma simulations.",
            "author": [
                "Philipp Krah",
                "Xi-Yuan Yin",
                "Julius Bergmann",
                "Jean-Christophe Nave",
                "Kai Schneider"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09379v1",
                "http://arxiv.org/pdf/2311.09379v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "physics.comp-ph",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09378v1",
            "title": "What Predicts Interpersonal Affect? Preliminary Analyses from\n  Retrospective Evaluations",
            "updated": "2023-11-15T21:11:24Z",
            "published": "2023-11-15T21:11:24Z",
            "summary": "While the field of affective computing has contributed to greatly improving\nthe seamlessness of human-robot interactions, the focus has primarily been on\nthe emotional processing of the self, rather than the perception of the other.\nTo address this gap, in a user study with 30 participant dyads, we collected\nthe users' retrospective ratings of the interpersonal perception of the other\ninteractant, after a short interaction. We made use of CORAE, a novel web-based\nopen-source tool for COntinuous Retrospective Affect Evaluation. In this work,\nwe analyze how these interpersonal ratings correlate with different aspects of\nthe interaction, namely personality traits, participation balance, and\nsentiment analysis. Notably, we discovered that conversational imbalance has a\nsignificant effect on the retrospective ratings, among other findings. By\nemploying these analyses and methodologies, we lay the groundwork for enhanced\nhuman-robot interactions, wherein affect is understood as a highly dynamic and\ncontext-dependent outcome of interaction history.",
            "author": [
                "Maria Teresa Parreira",
                "Michael J. Sack",
                "Malte Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09378v1",
                "http://arxiv.org/pdf/2311.09378v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09376v1",
            "title": "DISTA: Denoising Spiking Transformer with intrinsic plasticity and\n  spatiotemporal attention",
            "updated": "2023-11-15T21:09:08Z",
            "published": "2023-11-15T21:09:08Z",
            "summary": "Among the array of neural network architectures, the Vision Transformer (ViT)\nstands out as a prominent choice, acclaimed for its exceptional expressiveness\nand consistent high performance in various vision applications. Recently, the\nemerging Spiking ViT approach has endeavored to harness spiking neurons, paving\nthe way for a more brain-inspired transformer architecture that thrives in\nultra-low power operations on dedicated neuromorphic hardware. Nevertheless,\nthis approach remains confined to spatial self-attention and doesn't fully\nunlock the potential of spiking neural networks. We introduce DISTA, a\nDenoising Spiking Transformer with Intrinsic Plasticity and SpatioTemporal\nAttention, designed to maximize the spatiotemporal computational prowess of\nspiking neurons, particularly for vision applications. DISTA explores two types\nof spatiotemporal attentions: intrinsic neuron-level attention and\nnetwork-level attention with explicit memory. Additionally, DISTA incorporates\nan efficient nonlinear denoising mechanism to quell the noise inherent in\ncomputed spatiotemporal attention maps, thereby resulting in further\nperformance gains. Our DISTA transformer undergoes joint training involving\nsynaptic plasticity (i.e., weight tuning) and intrinsic plasticity (i.e.,\nmembrane time constant tuning) and delivers state-of-the-art performances\nacross several static image and dynamic neuromorphic datasets. With only 6 time\nsteps, DISTA achieves remarkable top-1 accuracy on CIFAR10 (96.26%) and\nCIFAR100 (79.15%), as well as 79.1% on CIFAR10-DVS using 10 time steps.",
            "author": [
                "Boxun Xu",
                "Hejia Geng",
                "Yuxuan Yin",
                "Peng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09376v1",
                "http://arxiv.org/pdf/2311.09376v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09375v1",
            "title": "HypOp: Distributed Constrained Combinatorial Optimization leveraging\n  Hypergraph Neural Networks",
            "updated": "2023-11-15T21:06:49Z",
            "published": "2023-11-15T21:06:49Z",
            "summary": "Scalable addressing of high dimensional constrained combinatorial\noptimization problems is a challenge that arises in several science and\nengineering disciplines. Recent work introduced novel application of graph\nneural networks for solving polynomial-cost unconstrained combinatorial\noptimization problems. This paper proposes a new framework, called HypOp, which\ngreatly advances the state of the art for solving combinatorial optimization\nproblems in several aspects: (i) it generalizes the prior results to\nconstrained optimization problems with an arbitrary cost function; (ii) it\nbroadens the application to higher dimensional problems by leveraging a\nhypergraph neural network structure; (iii) it enables scalability to much\nlarger problems by introducing a new distributed and parallel architecture for\nhypergraph neural network training; (iv) it demonstrates generalizability to\nother problem formulations by knowledge transfer from the learned experience of\naddressing one set of cost/constraints to another set for the same hypergraph;\n(v) it significantly boosts the solution accuracy compared with the prior art\nby suggesting a fine-tuning step using simulated annealing; (vi) HypOp shows a\nremarkable progress on benchmark examples, with run times improved by up to\nfivefold using a combination of fine-tuning and distributed training\ntechniques. The framework allows addressing a novel set of scientific problems\nincluding hypergraph MaxCut problem, satisfiability problems (3SAT), and\nresource allocation. We showcase the application of HypOp in scientific\ndiscovery by solving a hypergraph MaxCut problem on the NDC drug-substance\nhypergraph. Through extensive experimentation on a variety of combinatorial\noptimization problems, HypOp demonstrates superiority over existing\nunsupervised learning-based solvers and generic optimization methods.",
            "author": [
                "Nasimeh Heydaribeni",
                "Xinrui Zhan",
                "Ruisi Zhang",
                "Tina Eliassi-Rad",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09375v1",
                "http://arxiv.org/pdf/2311.09375v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09374v1",
            "title": "On computability of equilibrium states",
            "updated": "2023-11-15T21:05:15Z",
            "published": "2023-11-15T21:05:15Z",
            "summary": "Equilibrium states are natural dynamical analogues of Gibbs measures in\nthermodynamic formalism. The paper is devoted to the study of their\ncomputability. We show that the unique equilibrium state associated to a pair\nof a computable, topologically exact, distance-expanding, open transformation\n$T\\colon X\\rightarrow X$ and a computable H\\\"older continuous potential\n$\\varphi\\colon X\\rightarrow\\mathbb{R}$ is always computable. Furthermore, the\nequilibrium state of a computable hyperbolic rational map restricted to its\nJulia set with respect to its geometric potential is computable. On the other\nhand, we introduce a mechanism to provide many examples with non-unique\nequilibrium states for each potential in a dense subset of the space of\ncontinuous potentials, which should be of interest independent of Computable\nAnalysis. We also construct some computable dynamical systems whose equilibrium\nstates are all non-computable.",
            "author": [
                "Ilia Binder",
                "Qiandu He",
                "Zhiqiang Li",
                "Yiwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09374v1",
                "http://arxiv.org/pdf/2311.09374v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.LO",
                "Primary: 03D78, Secondary: 37D35, 37D20, 37F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09370v1",
            "title": "On correlation bounds against polynomials",
            "updated": "2023-11-15T21:00:23Z",
            "published": "2023-11-15T21:00:23Z",
            "summary": "We study the fundamental challenge of exhibiting explicit functions that have\nsmall correlation with low-degree polynomials over $\\mathbb{F}_{2}$. Our main\ncontributions include:\n  1. In STOC 2020, CHHLZ introduced a new technique to prove correlation\nbounds. Using their technique they established new correlation bounds for\nlow-degree polynomials. They conjectured that their technique generalizes to\nhigher degree polynomials as well. We give a counterexample to their\nconjecture, in fact ruling out weaker parameters and showing what they prove is\nessentially the best possible.\n  2. We propose a new approach for proving correlation bounds with the central\n\"mod functions\", consisting of two steps: (I) the polynomials that maximize\ncorrelation are symmetric and (II) symmetric polynomials have small\ncorrelation. Contrary to related results in the literature, we conjecture that\n(I) is true. We argue this approach is not affected by existing \"barrier\nresults\".\n  3. We prove our conjecture for quadratic polynomials. Specifically, we\ndetermine the maximum possible correlation between quadratic polynomials modulo\n2 and the functions $(x_{1},\\dots,x_{n})\\to z^{\\sum x_{i}}$ for any $z$ on the\ncomplex unit circle; and show that it is achieved by symmetric polynomials. To\nobtain our results we develop a new proof technique: we express correlation in\nterms of directional derivatives and analyze it by slowly restricting the\ndirection.\n  4. We make partial progress on the conjecture for cubic polynomials, in\nparticular proving tight correlation bounds for cubic polynomials whose\ndegree-3 part is symmetric.",
            "author": [
                "Peter Ivanov",
                "Liam Pavlovic",
                "Emanuele Viola"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09370v1",
                "http://arxiv.org/pdf/2311.09370v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09369v1",
            "title": "Time-dependent Probabilistic Generative Models for Disease Progression",
            "updated": "2023-11-15T21:00:00Z",
            "published": "2023-11-15T21:00:00Z",
            "summary": "Electronic health records contain valuable information for monitoring\npatients' health trajectories over time. Disease progression models have been\ndeveloped to understand the underlying patterns and dynamics of diseases using\nthese data as sequences. However, analyzing temporal data from EHRs is\nchallenging due to the variability and irregularities present in medical\nrecords. We propose a Markovian generative model of treatments developed to (i)\nmodel the irregular time intervals between medical events; (ii) classify\ntreatments into subtypes based on the patient sequence of medical events and\nthe time intervals between them; and (iii) segment treatments into subsequences\nof disease progression patterns. We assume that sequences have an associated\nstructure of latent variables: a latent class representing the different\nsubtypes of treatments; and a set of latent stages indicating the phase of\nprogression of the treatments. We use the Expectation-Maximization algorithm to\nlearn the model, which is efficiently solved with a dynamic programming-based\nmethod. Various parametric models have been employed to model the time\nintervals between medical events during the learning process, including the\ngeometric, exponential, and Weibull distributions. The results demonstrate the\neffectiveness of our model in recovering the underlying model from data and\naccurately modeling the irregular time intervals between medical actions.",
            "author": [
                "Onintze Zaballa",
                "Aritz P\u00e9rez",
                "Elisa G\u00f3mez-Inhiesto",
                "Teresa Acaiturri-Ayesta",
                "Jose A. Lozano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09369v1",
                "http://arxiv.org/pdf/2311.09369v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09367v1",
            "title": "A Survey on Online User Aggression: Content Detection and Behavioural\n  Analysis on Social Media Platforms",
            "updated": "2023-11-15T20:59:13Z",
            "published": "2023-11-15T20:59:13Z",
            "summary": "The rise of social media platforms has led to an increase in cyber-aggressive\nbehavior, encompassing a broad spectrum of hostile behavior, including\ncyberbullying, online harassment, and the dissemination of offensive and hate\nspeech. These behaviors have been associated with significant societal\nconsequences, ranging from online anonymity to real-world outcomes such as\ndepression, suicidal tendencies, and, in some instances, offline violence.\nRecognizing the societal risks associated with unchecked aggressive content,\nthis paper delves into the field of Aggression Content Detection and Behavioral\nAnalysis of Aggressive Users, aiming to bridge the gap between disparate\nstudies. In this paper, we analyzed the diversity of definitions and proposed a\nunified cyber-aggression definition. We examine the comprehensive process of\nAggression Content Detection, spanning from dataset creation, feature selection\nand extraction, and detection algorithm development. Further, we review studies\non Behavioral Analysis of Aggression that explore the influencing factors,\nconsequences, and patterns associated with cyber-aggressive behavior. This\nsystematic literature review is a cross-examination of content detection and\nbehavioral analysis in the realm of cyber-aggression. The integrated\ninvestigation reveals the effectiveness of incorporating sociological insights\ninto computational techniques for preventing cyber-aggressive behavior.\nFinally, the paper concludes by identifying research gaps and encouraging\nfurther progress in the unified domain of socio-computational aggressive\nbehavior analysis.",
            "author": [
                "Swapnil Mane",
                "Suman Kundu",
                "Rajesh Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09367v1",
                "http://arxiv.org/pdf/2311.09367v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09366v1",
            "title": "LOKE: Linked Open Knowledge Extraction for Automated Knowledge Graph\n  Construction",
            "updated": "2023-11-15T20:57:44Z",
            "published": "2023-11-15T20:57:44Z",
            "summary": "While the potential of Open Information Extraction (Open IE) for Knowledge\nGraph Construction (KGC) may seem promising, we find that the alignment of Open\nIE extraction results with existing knowledge graphs to be inadequate. The\nadvent of Large Language Models (LLMs), especially the commercially available\nOpenAI models, have reset expectations for what is possible with deep learning\nmodels and have created a new field called prompt engineering. We investigate\nthe use of GPT models and prompt engineering for knowledge graph construction\nwith the Wikidata knowledge graph to address a similar problem to Open IE,\nwhich we call Open Knowledge Extraction (OKE) using an approach we call the\nLinked Open Knowledge Extractor (LOKE, pronounced like \"Loki\"). We consider the\nentity linking task essential to construction of real world knowledge graphs.\nWe merge the CaRB benchmark scoring approach with data from the TekGen dataset\nfor the LOKE task. We then show that a well engineered prompt, paired with a\nnaive entity linking approach (which we call LOKE-GPT), outperforms AllenAI's\nOpenIE 4 implementation on the OKE task, although it over-generates triples\ncompared to the reference set due to overall triple scarcity in the TekGen set.\nThrough an analysis of entity linkability in the CaRB dataset, as well as\noutputs from OpenIE 4 and LOKE-GPT, we see that LOKE-GPT and the \"silver\"\nTekGen triples show that the task is significantly different in content from\nOIE, if not structure. Through this analysis and a qualitative analysis of\nsentence extractions via all methods, we found that LOKE-GPT extractions are of\nhigh utility for the KGC task and suitable for use in semi-automated extraction\nsettings.",
            "author": [
                "Jamie McCusker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09366v1",
                "http://arxiv.org/pdf/2311.09366v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09363v1",
            "title": "Investigating the Emergent Audio Classification Ability of ASR\n  Foundation Models",
            "updated": "2023-11-15T20:52:56Z",
            "published": "2023-11-15T20:52:56Z",
            "summary": "Text and vision foundation models can perform many tasks in a zero-shot\nsetting, a desirable property that enables these systems to be applied in\ngeneral and low-resource settings. However, there has been significantly less\nwork on the zero-shot abilities of ASR foundation models, with these systems\ntypically fine-tuned to specific tasks or constrained to applications that\nmatch their training criterion and data annotation. In this work we investigate\nthe ability of Whisper and MMS, ASR foundation models trained primarily for\nspeech recognition, to perform zero-shot audio classification. We use simple\ntemplate-based text prompts at the decoder and use the resulting decoding\nprobabilities to generate zero-shot predictions. Without training the model on\nextra data or adding any new parameters, we demonstrate that Whisper shows\npromising zero-shot classification performance on a range of 8\naudio-classification datasets, outperforming existing state-of-the-art\nzero-shot baseline's accuracy by an average of 9%. One important step to unlock\nthe emergent ability is debiasing, where a simple unsupervised reweighting\nmethod of the class probabilities yields consistent significant performance\ngains. We further show that performance increases with model size, implying\nthat as ASR foundation models scale up, they may exhibit improved zero-shot\nperformance.",
            "author": [
                "Rao Ma",
                "Adian Liusie",
                "Mark J. F. Gales",
                "Kate M. Knill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09363v1",
                "http://arxiv.org/pdf/2311.09363v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09361v1",
            "title": "RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination\n  Prior",
            "updated": "2023-11-15T20:48:26Z",
            "published": "2023-11-15T20:48:26Z",
            "summary": "Inverse rendering is an ill-posed problem. Previous work has sought to\nresolve this by focussing on priors for object or scene shape or appearance. In\nthis work, we instead focus on a prior for natural illuminations. Current\nmethods rely on spherical harmonic lighting or other generic representations\nand, at best, a simplistic prior on the parameters. This results in limitations\nfor the inverse setting in terms of the expressivity of the illumination\nconditions, especially when taking specular reflections into account. We\npropose a conditional neural field representation based on a variational\nauto-decoder and a transformer decoder. We extend Vector Neurons to build\nequivariance directly into our architecture, and leveraging insights from depth\nestimation through a scale-invariant loss function, we enable the accurate\nrepresentation of High Dynamic Range (HDR) images. The result is a compact,\nrotation-equivariant HDR neural illumination model capable of capturing\ncomplex, high-frequency features in natural environment maps. Training our\nmodel on a curated dataset of 1.6K HDR environment maps of natural scenes, we\ncompare it against traditional representations, demonstrate its applicability\nfor an inverse rendering task and show environment map completion from partial\nobservations. We share our PyTorch implementation, dataset and trained models\nat https://github.com/JADGardner/ns_reni",
            "author": [
                "James A. D. Gardner",
                "Bernhard Egger",
                "William A. P. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09361v1",
                "http://arxiv.org/pdf/2311.09361v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09359v1",
            "title": "Local Computation Algorithms for Maximum Matching: New Lower Bounds",
            "updated": "2023-11-15T20:43:46Z",
            "published": "2023-11-15T20:43:46Z",
            "summary": "We study local computation algorithms (LCA) for maximum matching. An LCA does\nnot return its output entirely, but reveals parts of it upon query. For\nmatchings, each query is a vertex $v$; the LCA should return whether $v$ is\nmatched -- and if so to which neighbor -- while spending a small time per\nquery.\n  In this paper, we prove that any LCA that computes a matching that is at most\nan additive of $\\epsilon n$ smaller than the maximum matching in $n$-vertex\ngraphs of maximum degree $\\Delta$ must take at least\n$\\Delta^{\\Omega(1/\\varepsilon)}$ time. This comes close to the existing upper\nbounds that take $(\\Delta/\\epsilon)^{O(1/\\epsilon^2)} polylog(n)$ time.\n  In terms of sublinear time algorithms, our techniques imply that any\nalgorithm that estimates the size of maximum matching up to an additive error\nof $\\epsilon n$ must take $\\Delta^{\\Omega(1/\\epsilon)}$ time. This negatively\nresolves a decade old open problem of the area (see Open Problem 39 of\nsublinear.info) on whether such estimates can be achieved in\n$poly(\\Delta/\\epsilon)$ time.",
            "author": [
                "Soheil Behnezhad",
                "Mohammad Roghani",
                "Aviad Rubinstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09359v1",
                "http://arxiv.org/pdf/2311.09359v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09358v1",
            "title": "Empirical evaluation of Uncertainty Quantification in\n  Retrieval-Augmented Language Models for Science",
            "updated": "2023-11-15T20:42:11Z",
            "published": "2023-11-15T20:42:11Z",
            "summary": "Large language models (LLMs) have shown remarkable achievements in natural\nlanguage processing tasks, producing high-quality outputs. However, LLMs still\nexhibit limitations, including the generation of factually incorrect\ninformation. In safety-critical applications, it is important to assess the\nconfidence of LLM-generated content to make informed decisions. Retrieval\nAugmented Language Models (RALMs) is relatively a new area of research in NLP.\nRALMs offer potential benefits for scientific NLP tasks, as retrieved\ndocuments, can serve as evidence to support model-generated content. This\ninclusion of evidence enhances trustworthiness, as users can verify and explore\nthe retrieved documents to validate model outputs. Quantifying uncertainty in\nRALM generations further improves trustworthiness, with retrieved text and\nconfidence scores contributing to a comprehensive and reliable model for\nscientific applications. However, there is limited to no research on UQ for\nRALMs, particularly in scientific contexts. This study aims to address this gap\nby conducting a comprehensive evaluation of UQ in RALMs, focusing on scientific\ntasks. This research investigates how uncertainty scores vary when scientific\nknowledge is incorporated as pretraining and retrieval data and explores the\nrelationship between uncertainty scores and the accuracy of model-generated\noutputs. We observe that an existing RALM finetuned with scientific knowledge\nas the retrieval data tends to be more confident in generating predictions\ncompared to the model pretrained only with scientific knowledge. We also found\nthat RALMs are overconfident in their predictions, making inaccurate\npredictions more confidently than accurate ones. Scientific knowledge provided\neither as pretraining or retrieval corpus does not help alleviate this issue.\nWe released our code, data and dashboards at https://github.com/pnnl/EXPERT2.",
            "author": [
                "Sridevi Wagle",
                "Sai Munikoti",
                "Anurag Acharya",
                "Sara Smith",
                "Sameera Horawalavithana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09358v1",
                "http://arxiv.org/pdf/2311.09358v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09356v1",
            "title": "LePaRD: A Large-Scale Dataset of Judges Citing Precedents",
            "updated": "2023-11-15T20:33:27Z",
            "published": "2023-11-15T20:33:27Z",
            "summary": "We present the Legal Passage Retrieval Dataset LePaRD. LePaRD is a massive\ncollection of U.S. federal judicial citations to precedent in context. The\ndataset aims to facilitate work on legal passage prediction, a challenging\npractice-oriented legal retrieval and reasoning task. Legal passage prediction\nseeks to predict relevant passages from precedential court decisions given the\ncontext of a legal argument. We extensively evaluate various retrieval\napproaches on LePaRD, and find that classification appears to work best.\nHowever, we note that legal precedent prediction is a difficult task, and there\nremains significant room for improvement. We hope that by publishing LePaRD, we\nwill encourage others to engage with a legal NLP task that promises to help\nexpand access to justice by reducing the burden associated with legal research.\nA subset of the LePaRD dataset is freely available and the whole dataset will\nbe released upon publication.",
            "author": [
                "Robert Mahari",
                "Dominik Stammbach",
                "Elliott Ash",
                "Alex `Sandy' Pentland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09356v1",
                "http://arxiv.org/pdf/2311.09356v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11925v1",
            "title": "Quantum Computing Standards & Accounting Information Systems",
            "updated": "2023-11-15T20:32:27Z",
            "published": "2023-11-15T20:32:27Z",
            "summary": "This research investigates the potential implications of quantum technology\non accounting information systems, and business overall. This endeavor focuses\non the vulnerabilities of quantum computers and the emergence of\nquantum-resistant encryption algorithms. This paper critically analyzes quantum\nstandards and their transformative effects on the efficiency, expediency, and\nsecurity of commerce. By comparing the differences, similarities, and\nlimitations of quantum standards, the research presents a collection of best\npractices and adaptation methods to fortify organizations against cyber threats\nin the quantum era. The study provides a guide to understanding and navigating\nthe interplay between quantum technology and standard-setting organizations,\nenabling organizations to safeguard the integrity of their practices and adapt\nproactively to the challenges ushered in by the advent of quantum supremacy.\nThis endeavor also contributes to research by painting the standard-setting\necosystem and noting its intricate processes. The findings include the\nidentification of organizations involved with quantum standards, as well as\nobserved distinctions, similarities, and limitations between American and\nEuropean standards.",
            "author": [
                "Maksym Lazirko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11925v1",
                "http://arxiv.org/pdf/2311.11925v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.ET",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09355v1",
            "title": "Privacy Threats in Stable Diffusion Models",
            "updated": "2023-11-15T20:31:40Z",
            "published": "2023-11-15T20:31:40Z",
            "summary": "This paper introduces a novel approach to membership inference attacks (MIA)\ntargeting stable diffusion computer vision models, specifically focusing on the\nhighly sophisticated Stable Diffusion V2 by StabilityAI. MIAs aim to extract\nsensitive information about a model's training data, posing significant privacy\nconcerns. Despite its advancements in image synthesis, our research reveals\nprivacy vulnerabilities in the stable diffusion models' outputs. Exploiting\nthis information, we devise a black-box MIA that only needs to query the victim\nmodel repeatedly. Our methodology involves observing the output of a stable\ndiffusion model at different generative epochs and training a classification\nmodel to distinguish when a series of intermediates originated from a training\nsample or not. We propose numerous ways to measure the membership features and\ndiscuss what works best. The attack's efficacy is assessed using the ROC AUC\nmethod, demonstrating a 60\\% success rate in inferring membership information.\nThis paper contributes to the growing body of research on privacy and security\nin machine learning, highlighting the need for robust defenses against MIAs.\nOur findings prompt a reevaluation of the privacy implications of stable\ndiffusion models, urging practitioners and developers to implement enhanced\nsecurity measures to safeguard against such attacks.",
            "author": [
                "Thomas Cilloni",
                "Charles Fleming",
                "Charles Walter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09355v1",
                "http://arxiv.org/pdf/2311.09355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09350v1",
            "title": "Generalizable Imitation Learning Through Pre-Trained Representations",
            "updated": "2023-11-15T20:15:51Z",
            "published": "2023-11-15T20:15:51Z",
            "summary": "In this paper we leverage self-supervised vision transformer models and their\nemergent semantic abilities to improve the generalization abilities of\nimitation learning policies. We introduce BC-ViT, an imitation learning\nalgorithm that leverages rich DINO pre-trained Visual Transformer (ViT)\npatch-level embeddings to obtain better generalization when learning through\ndemonstrations. Our learner sees the world by clustering appearance features\ninto semantic concepts, forming stable keypoints that generalize across a wide\nrange of appearance variations and object types. We show that this\nrepresentation enables generalized behaviour by evaluating imitation learning\nacross a diverse dataset of object manipulation tasks. Our method, data and\nevaluation approach are made available to facilitate further study of\ngeneralization in Imitation Learners.",
            "author": [
                "Wei-Di Chang",
                "Francois Hogan",
                "David Meger",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09350v1",
                "http://arxiv.org/pdf/2311.09350v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09348v1",
            "title": "Analysis of Research Trends in Computer Science: A Network Approach",
            "updated": "2023-11-15T20:10:57Z",
            "published": "2023-11-15T20:10:57Z",
            "summary": "Nowadays, computer science (CS) has emerged as a dominant force in numerous\nresearch areas both within and beyond its own discipline. However, despite its\nsignificant impact on scholarly space, only a limited number of studies have\nbeen conducted to analyze the research trends and relationships within computer\nscience. In this study, we collected information on fields and subfields from\nover 2,000 research articles published in the 2022 proceedings of the top\nAssociation for Computing Machinery (ACM) conferences spanning various research\nfields. Through a network approach, we investigated the interconnections\nbetween CS fields and subfields to evaluate their interdisciplinarity and\nmultidisciplinarity. Our findings indicate that computing methodologies and\nprivacy and security stand out as the most interdisciplinary fields, while\nhuman-centered computing exhibits the highest frequency among the papers.\nFurthermore, we discovered that machine learning emerges as the most\ninterdisciplinary and multidisciplinary subfield within computer science. These\nresults offer valuable insights for universities seeking to foster\ninterdisciplinary research opportunities for their students.",
            "author": [
                "Ghazal Kalhor",
                "Behnam Bahrak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09348v1",
                "http://arxiv.org/pdf/2311.09348v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09346v1",
            "title": "Nothing Stands Still: A Spatiotemporal Benchmark on 3D Point Cloud\n  Registration Under Large Geometric and Temporal Change",
            "updated": "2023-11-15T20:09:29Z",
            "published": "2023-11-15T20:09:29Z",
            "summary": "Building 3D geometric maps of man-made spaces is a well-established and\nactive field that is fundamental to computer vision and robotics. However,\nconsidering the evolving nature of built environments, it is essential to\nquestion the capabilities of current mapping efforts in handling temporal\nchanges. In addition, spatiotemporal mapping holds significant potential for\nachieving sustainability and circularity goals. Existing mapping approaches\nfocus on small changes, such as object relocation or self-driving car\noperation; in all cases where the main structure of the scene remains fixed.\nConsequently, these approaches fail to address more radical changes in the\nstructure of the built environment, such as geometry and topology. To this end,\nwe introduce the Nothing Stands Still (NSS) benchmark, which focuses on the\nspatiotemporal registration of 3D scenes undergoing large spatial and temporal\nchange, ultimately creating one coherent spatiotemporal map. Specifically, the\nbenchmark involves registering two or more partial 3D point clouds (fragments)\nfrom the same scene but captured from different spatiotemporal views. In\naddition to the standard pairwise registration, we assess the multi-way\nregistration of multiple fragments that belong to any temporal stage. As part\nof NSS, we introduce a dataset of 3D point clouds recurrently captured in\nlarge-scale building indoor environments that are under construction or\nrenovation. The NSS benchmark presents three scenarios of increasing\ndifficulty, to quantify the generalization ability of point cloud registration\nmethods over space (within one building and across buildings) and time. We\nconduct extensive evaluations of state-of-the-art methods on NSS. The results\ndemonstrate the necessity for novel methods specifically designed to handle\nlarge spatiotemporal changes. The homepage of our benchmark is at\nhttp://nothing-stands-still.com.",
            "author": [
                "Tao Sun",
                "Yan Hao",
                "Shengyu Huang",
                "Silvio Savarese",
                "Konrad Schindler",
                "Marc Pollefeys",
                "Iro Armeni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09346v1",
                "http://arxiv.org/pdf/2311.09346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09344v1",
            "title": "Language and Task Arithmetic with Parameter-Efficient Layers for\n  Zero-Shot Summarization",
            "updated": "2023-11-15T20:04:58Z",
            "published": "2023-11-15T20:04:58Z",
            "summary": "Parameter-efficient fine-tuning (PEFT) using labeled task data can\nsignificantly improve the performance of large language models (LLMs) on the\ndownstream task. However, there are 7000 languages in the world and many of\nthese languages lack labeled data for real-world language generation tasks. In\nthis paper, we propose to improve zero-shot cross-lingual transfer by composing\nlanguage or task specialized parameters. Our method composes language and task\nPEFT modules via element-wise arithmetic operations to leverage unlabeled data\nand English labeled data. We extend our approach to cases where labeled data\nfrom more languages is available and propose to arithmetically compose PEFT\nmodules trained on languages related to the target. Empirical results on\nsummarization demonstrate that our method is an effective strategy that obtains\nconsistent gains using minimal training of PEFT modules.",
            "author": [
                "Alexandra Chronopoulou",
                "Jonas Pfeiffer",
                "Joshua Maynez",
                "Xinyi Wang",
                "Sebastian Ruder",
                "Priyanka Agrawal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09344v1",
                "http://arxiv.org/pdf/2311.09344v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09343v1",
            "title": "Well-being in isolation: Exploring artistic immersive virtual\n  environments in a simulated lunar habitat to alleviate asthenia symptoms",
            "updated": "2023-11-15T20:04:00Z",
            "published": "2023-11-15T20:04:00Z",
            "summary": "Revived interest in lunar and planetary exploration is heralding a new era\nfor human spaceflight, characterized by frequent strain on astronaut's mental\nwell-being, which stems from increased exposure to isolated, confined, and\nextreme (ICE) conditions. Whilst Immersive Virtual Reality (IVR) has been\nemployed to facilitate self-help interventions to mitigate challenges caused by\nisolated environments in several domains, its applicability in support of\nfuture space expeditions remains largely unexplored. To address this\nlimitation, we administered the use of distinct IVR environments to crew\nmembers (n=5) partaking in a simulated lunar habitat study. Utilizing a\nBayesian approach to scrutinize small group data, we discovered a significant\nrelationship between IVR usage and a reduction in perceived stress-related\nsymptoms, particularly those associated with asthenia (syndrome often linked to\nchronic fatigue and weakness; a condition characterized by feelings of energy\ndepletion or exhaustion that can be amplified in ICE conditions). The\nreductions were most prominent with the use of interactive virtual\nenvironments. The 'Aesthetic Realities' - virtual environments conceived as art\nexhibits - received exceptional praise from our participants. These\nenvironments mark a fascinating convergence of art and science, holding promise\nto mitigate effects related to isolation in spaceflight training and beyond.",
            "author": [
                "Grzegorz Pochwatko",
                "Wieslaw Kopec",
                "Justyna Swidrak",
                "Anna Jaskulska",
                "Kinga H. Skorupska",
                "Barbara Karpowicz",
                "Rafa\u0142 Mas\u0142yk",
                "Maciej Grzeszczuk",
                "Steven Barnes",
                "Paulina Borkiewicz",
                "Pawe\u0142 Kobyli\u0144ski",
                "Micha\u0142 Pabi\u015b-Orzeszyna",
                "Robert Balas",
                "Jagoda Lazarek",
                "Florian Dufresne",
                "Leonie Bensch",
                "Tommy Nilsson"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ISMAR59233.2023.00033",
                "http://arxiv.org/abs/2311.09343v1",
                "http://arxiv.org/pdf/2311.09343v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY",
                "93B51, 97M50",
                "H.1.2; I.3.8; J.4; J.m; K.8.2; J.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09338v1",
            "title": "Challenges for Predictive Modeling with Neural Network Techniques using\n  Error-Prone Dietary Intake Data",
            "updated": "2023-11-15T19:54:14Z",
            "published": "2023-11-15T19:54:14Z",
            "summary": "Dietary intake data are routinely drawn upon to explore diet-health\nrelationships. However, these data are often subject to measurement error,\ndistorting the true relationships. Beyond measurement error, there are likely\ncomplex synergistic and sometimes antagonistic interactions between different\ndietary components, complicating the relationships between diet and health\noutcomes. Flexible models are required to capture the nuance that these complex\ninteractions introduce. This complexity makes research on diet-health\nrelationships an appealing candidate for the application of machine learning\ntechniques, and in particular, neural networks. Neural networks are\ncomputational models that are able to capture highly complex, nonlinear\nrelationships so long as sufficient data are available. While these models have\nbeen applied in many domains, the impacts of measurement error on the\nperformance of predictive modeling has not been systematically investigated.\nHowever, dietary intake data are typically collected using self-report methods\nand are prone to large amounts of measurement error. In this work, we\ndemonstrate the ways in which measurement error erodes the performance of\nneural networks, and illustrate the care that is required for leveraging these\nmodels in the presence of error. We demonstrate the role that sample size and\nreplicate measurements play on model performance, indicate a motivation for the\ninvestigation of transformations to additivity, and illustrate the caution\nrequired to prevent model overfitting. While the past performance of neural\nnetworks across various domains make them an attractive candidate for examining\ndiet-health relationships, our work demonstrates that substantial care and\nfurther methodological development are both required to observe increased\npredictive performance when applying these techniques, compared to more\ntraditional statistical procedures.",
            "author": [
                "Dylan Spicker",
                "Amir Nazemi",
                "Joy Hutchinson",
                "Paul Fieguth",
                "Sharon I. Kirkpatrick",
                "Michael Wallace",
                "Kevin W. Dodd"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09338v1",
                "http://arxiv.org/pdf/2311.09338v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09336v1",
            "title": "Pinpoint, Not Criticize: Refining Large Language Models via Fine-Grained\n  Actionable Feedback",
            "updated": "2023-11-15T19:52:11Z",
            "published": "2023-11-15T19:52:11Z",
            "summary": "Recent improvements in text generation have leveraged human feedback to\nimprove the quality of the generated output. However, human feedback is not\nalways available, especially during inference. In this work, we propose an\ninference time optimization method FITO to use fine-grained actionable feedback\nin the form of error type, error location and severity level that are predicted\nby a learned error pinpoint model for iterative refinement. FITO starts with an\ninitial output, then iteratively incorporates the feedback via a refinement\nmodel that generates an improved output conditioned on the feedback. Given the\nuncertainty of consistent refined samples at iterative steps, we formulate\niterative refinement into a local search problem and develop a simulated\nannealing based algorithm that balances exploration of the search space and\noptimization for output quality. We conduct experiments on three text\ngeneration tasks, including machine translation, long-form question answering\n(QA) and topical summarization. We observe 0.8 and 0.7 MetricX gain on\nChinese-English and English-German translation, 4.5 and 1.8 ROUGE-L gain at\nlong form QA and topic summarization respectively, with a single iteration of\nrefinement. With our simulated annealing algorithm, we see further quality\nimprovements, including up to 1.7 MetricX improvements over the baseline\napproach.",
            "author": [
                "Wenda Xu",
                "Daniel Deutsch",
                "Mara Finkelstein",
                "Juraj Juraska",
                "Biao Zhang",
                "Zhongtao Liu",
                "William Yang Wang",
                "Lei Li",
                "Markus Freitag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09336v1",
                "http://arxiv.org/pdf/2311.09336v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10111v1",
            "title": "VideoCon: Robust Video-Language Alignment via Contrast Captions",
            "updated": "2023-11-15T19:51:57Z",
            "published": "2023-11-15T19:51:57Z",
            "summary": "Despite being (pre)trained on a massive amount of data, state-of-the-art\nvideo-language alignment models are not robust to semantically-plausible\ncontrastive changes in the video captions. Our work addresses this by\nidentifying a broad spectrum of contrast misalignments, such as replacing\nentities, actions, and flipping event order, which alignment models should be\nrobust against. To this end, we introduce the VideoCon, a video-language\nalignment dataset constructed by a large language model that generates\nplausible contrast video captions and explanations for differences between\noriginal and contrast video captions. Then, a generative video-language model\nis finetuned with VideoCon to assess video-language entailment and generate\nexplanations. Our VideoCon-based alignment model significantly outperforms\ncurrent models. It exhibits a 12-point increase in AUC for the video-language\nalignment task on human-generated contrast captions. Finally, our model sets\nnew state of the art zero-shot performance in temporally-extensive\nvideo-language tasks such as text-to-video retrieval (SSv2-Temporal) and video\nquestion answering (ATP-Hard). Moreover, our model shows superior performance\non novel videos and human-crafted captions and explanations. Our code and data\nare available at https://github.com/Hritikbansal/videocon.",
            "author": [
                "Hritik Bansal",
                "Yonatan Bitton",
                "Idan Szpektor",
                "Kai-Wei Chang",
                "Aditya Grover"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10111v1",
                "http://arxiv.org/pdf/2311.10111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09335v1",
            "title": "Lighter, yet More Faithful: Investigating Hallucinations in Pruned Large\n  Language Models for Abstractive Summarization",
            "updated": "2023-11-15T19:49:24Z",
            "published": "2023-11-15T19:49:24Z",
            "summary": "Despite their remarkable performance on abstractive summarization, large\nlanguage models (LLMs) face two significant challenges: their considerable size\nand tendency to hallucinate. Hallucinations are concerning because they erode\nthe reliability of LLMs and raise safety issues. Pruning is a technique that\nreduces model size by removing redundant weights to create sparse models that\nenable more efficient inference. Pruned models yield comparable performance to\ntheir counterpart full-sized models, making them ideal alternatives when\noperating on a limited budget. However, the effect that pruning has upon\nhallucinations in abstractive summarization with LLMs has yet to be explored.\nIn this paper, we provide an extensive empirical study on the hallucinations\nproduced by pruned models across three standard summarization tasks, two\npruning approaches, three instruction-tuned LLMs, and three hallucination\nevaluation metrics. Surprisingly, we find that pruned LLMs hallucinate less\ncompared to their full-sized counterparts. Our follow-up analysis suggests that\npruned models tend to depend more on the source input and less on their\nparametric knowledge from pre-training for generation. This greater dependency\non the source input leads to a higher lexical overlap between generated content\nand the source input, which can be a reason for the reduction in\nhallucinations.",
            "author": [
                "George Chrysostomou",
                "Zhixue Zhao",
                "Miles Williams",
                "Nikolaos Aletras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09335v1",
                "http://arxiv.org/pdf/2311.09335v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09334v1",
            "title": "Lattice Hamiltonian for Adjoint QCD$_2$",
            "updated": "2023-11-15T19:48:23Z",
            "published": "2023-11-15T19:48:23Z",
            "summary": "We introduce a Hamiltonian lattice model for the $(1+1)$-dimensional\n$\\text{SU}(N_c)$ gauge theory coupled to one adjoint Majorana fermion of mass\n$m$. The discretization of the continuum theory uses staggered Majorana\nfermions. We analyze the symmetries of the lattice model and find lattice\nanalogs of the anomalies of the corresponding continuum theory. An important\nrole is played by the lattice translation by one lattice site, which in the\ncontinuum limit involves a discrete axial transformation. On a lattice with\nperiodic boundary conditions, the Hilbert space breaks up into sectors labeled\nby the $N_c$-ality $p=0, \\ldots N_c-1$. Our symmetry analysis implies various\nexact degeneracies in the spectrum of the lattice model. In particular, it\nshows that, for $m=0$ and even $N_c$, the sectors $p$ and $p'$ are degenerate\nif $|p-p'| = N_c/2$. In the $N_c = 2$ case, we explicitly construct the action\nof the Hamiltonian on a basis of gauge-invariant states, and we perform both a\nstrong coupling expansion and exact diagonalization for lattices of up to $12$\nlattice sites. Upon extrapolation of these results, we find good agreement with\nthe spectrum computed previously using discretized light-cone quantization. One\nof our new results is the first numerical calculation of the fermion bilinear\ncondensate.",
            "author": [
                "Ross Dempsey",
                "Igor R. Klebanov",
                "Silviu S. Pufu",
                "Benjamin T. S\u00f8gaard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09334v1",
                "http://arxiv.org/pdf/2311.09334v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.str-el",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16168v1",
            "title": "Inexpensive High Fidelity Melt Pool Models in Additive Manufacturing\n  Using Generative Deep Diffusion",
            "updated": "2023-11-15T19:37:20Z",
            "published": "2023-11-15T19:37:20Z",
            "summary": "Defects in laser powder bed fusion (L-PBF) parts often result from the\nmeso-scale dynamics of the molten alloy near the laser, known as the melt pool.\nFor instance, the melt pool can directly contribute to the formation of\nundesirable porosity, residual stress, and surface roughness in the final part.\nExperimental in-situ monitoring of the three-dimensional melt pool physical\nfields is challenging, due to the short length and time scales involved in the\nprocess. Multi-physics simulation methods can describe the three-dimensional\ndynamics of the melt pool, but are computationally expensive at the mesh\nrefinement required for accurate predictions of complex effects, such as the\nformation of keyhole porosity. Therefore, in this work, we develop a generative\ndeep learning model based on the probabilistic diffusion framework to map\nlow-fidelity, coarse-grained simulation information to the high-fidelity\ncounterpart. By doing so, we bypass the computational expense of conducting\nmultiple high-fidelity simulations for analysis by instead upscaling\nlightweight coarse mesh simulations. Specifically, we implement a 2-D diffusion\nmodel to spatially upscale cross-sections of the coarsely simulated melt pool\nto their high-fidelity equivalent. We demonstrate the preservation of key\nmetrics of the melting process between the ground truth simulation data and the\ndiffusion model output, such as the temperature field, the melt pool dimensions\nand the variability of the keyhole vapor cavity. Specifically, we predict the\nmelt pool depth within 3 $\\mu m$ based on low-fidelity input data 4$\\times$\ncoarser than the high-fidelity simulations, reducing analysis time by two\norders of magnitude.",
            "author": [
                "Francis Ogoke",
                "Quanliang Liu",
                "Olabode Ajenifujah",
                "Alexander Myers",
                "Guadalupe Quirarte",
                "Jack Beuth",
                "Jonathan Malen",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16168v1",
                "http://arxiv.org/pdf/2311.16168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09326v1",
            "title": "Superposition States on Different Axes of the Bloch Sphere for\n  Cost-Effective Circuits Realization on IBM Quantum Computers",
            "updated": "2023-11-15T19:34:21Z",
            "published": "2023-11-15T19:34:21Z",
            "summary": "A proposed method for preparing the superposition states of qubits using\ndifferent axes of the Bloch sphere. This method utilizes the Y-axis of the\nBloch sphere using IBM native (square root of X) gates, instead of utilizing\nthe X-axis of the Bloch sphere using IBM non-native Hadamard gates, for\ntranspiling cost-effective quantum circuits on IBM quantum computers. In this\npaper, our presented method ensures that the final transpiled quantum circuits\nalways have a lower quantum cost than that of the transpiled quantum circuits\nusing the Hadamard gates.",
            "author": [
                "A. Al-Bayaty",
                "M. Perkowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09326v1",
                "http://arxiv.org/pdf/2311.09326v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09325v1",
            "title": "Improving fit to human reading times via temperature-scaled surprisal",
            "updated": "2023-11-15T19:34:06Z",
            "published": "2023-11-15T19:34:06Z",
            "summary": "Past studies have provided broad support for that words with lower\npredictability (i.e., higher surprisal) require more time for comprehension by\nusing large language models (LLMs) to simulate humans' cognitive load. In\ngeneral, these studies have implicitly assumed that the probability scores from\nLLMs are accurate, ignoring the discrepancies between human cognition and LLMs\nfrom this standpoint. Inspired by the concept of probability calibration, we\nare the first work to focus on the probability distribution for human reading\nsimulation. We propose to use temperature-scaled surprisal, a surprisal\ncalculated by shaped probability, to be the predictor of human reading times.\nOur results across three corpora consistently revealed that such a surprisal\ncan drastically improve the prediction of reading times. Setting the\ntemperature to be approximately 2.5 across all models and datasets can yield up\nto an 89% of increase in delta log-likelihood in our setting. We also propose a\ncalibration metric to quantify the possible human-likeness bias. Further\nanalysis was done and provided insights into this phenomenon.",
            "author": [
                "Tong Liu",
                "Iza \u0160krjanec",
                "Vera Demberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09325v1",
                "http://arxiv.org/pdf/2311.09325v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09319v1",
            "title": "Spoken Word2Vec: A Perspective And Some Techniques",
            "updated": "2023-11-15T19:25:29Z",
            "published": "2023-11-15T19:25:29Z",
            "summary": "Text word embeddings that encode distributional semantic features work by\nmodeling contextual similarities of frequently occurring words. Acoustic word\nembeddings, on the other hand, typically encode low-level phonetic\nsimilarities. Semantic embeddings for spoken words have been previously\nexplored using similar algorithms to Word2Vec, but the resulting vectors still\nmainly encoded phonetic rather than semantic features. In this paper, we\nexamine the assumptions and architectures used in previous works and show\nexperimentally how Word2Vec algorithms fail to encode distributional semantics\nwhen the input units are acoustically correlated. In addition, previous works\nrelied on the simplifying assumptions of perfect word segmentation and\nclustering by word type. Given these conditions, a trivial solution identical\nto text-based embeddings has been overlooked. We follow this simpler path using\nautomatic word type clustering and examine the effects on the resulting\nembeddings, highlighting the true challenges in this task.",
            "author": [
                "Mohammad Amaan Sayeed",
                "Hanan Aldarmaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09319v1",
                "http://arxiv.org/pdf/2311.09319v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10771v1",
            "title": "Automatic Restoration of Diacritics for Speech Data Sets",
            "updated": "2023-11-15T19:24:54Z",
            "published": "2023-11-15T19:24:54Z",
            "summary": "Automatic text-based diacritic restoration models generally have high\ndiacritic error rates when applied to speech transcripts as a result of domain\nand style shifts in spoken language. In this work, we explore the possibility\nof improving the performance of automatic diacritic restoration when applied to\nspeech data by utilizing the parallel spoken utterances. In particular, we use\nthe pre-trained Whisper ASR model fine-tuned on relatively small amounts of\ndiacritized Arabic speech data to produce rough diacritized transcripts for the\nspeech utterances, which we then use as an additional input for a\ntransformer-based diacritic restoration model. The proposed model consistently\nimprove diacritic restoration performance compared to an equivalent text-only\nmodel, with at least 5\\% absolute reduction in diacritic error rate within the\nsame domain and on two out-of-domain test sets. Our results underscore the\ninadequacy of current text-based diacritic restoration models for speech data\nsets and provide a new baseline for speech-based diacritic restoration.",
            "author": [
                "Sara Shatnawi",
                "Sawsan Alqahtani",
                "Hanan Aldarmaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10771v1",
                "http://arxiv.org/pdf/2311.10771v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09308v1",
            "title": "Divergences between Language Models and Human Brains",
            "updated": "2023-11-15T19:02:40Z",
            "published": "2023-11-15T19:02:40Z",
            "summary": "Do machines and humans process language in similar ways? A recent line of\nresearch has hinted in the affirmative, demonstrating that human brain signals\ncan be effectively predicted using the internal representations of language\nmodels (LMs). This is thought to reflect shared computational principles\nbetween LMs and human language processing. However, there are also clear\ndifferences in how LMs and humans acquire and use language, even if the final\ntask they are performing is the same. Despite this, there is little work\nexploring systematic differences between human and machine language processing\nusing brain data. To address this question, we examine the differences between\nLM representations and the human brain's responses to language, specifically by\nexamining a dataset of Magnetoencephalography (MEG) responses to a written\nnarrative. In doing so we identify three phenomena that, in prior work, LMs\nhave been found to not capture well: emotional understanding, figurative\nlanguage processing, and physical commonsense. By fine-tuning LMs on datasets\nrelated to these phenomena, we observe that fine-tuned LMs show improved\nalignment with human brain responses across these tasks. Our study implies that\nthe observed divergences between LMs and human brains may stem from LMs'\ninadequate representation of these specific types of knowledge.",
            "author": [
                "Yuchen Zhou",
                "Emmy Liu",
                "Graham Neubig",
                "Leila Wehbe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09308v1",
                "http://arxiv.org/pdf/2311.09308v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09305v1",
            "title": "Accurate and Honest Approximation of Correlated Qubit Noise",
            "updated": "2023-11-15T19:00:34Z",
            "published": "2023-11-15T19:00:34Z",
            "summary": "Accurate modeling of noise in realistic quantum processors is critical for\nconstructing fault-tolerant quantum computers. While a full simulation of\nactual noisy quantum circuits provides information about correlated noise among\nall qubits and is therefore accurate, it is, however, computationally expensive\nas it requires resources that grow exponentially with the number of qubits. In\nthis paper, we propose an efficient systematic construction of approximate\nnoise channels, where their accuracy can be enhanced by incorporating noise\ncomponents with higher qubit-qubit correlation degree. To formulate such\napproximate channels, we first present a method, dubbed the cluster expansion\napproach, to decompose the Lindbladian generator of an actual Markovian noise\nchannel into components based on interqubit correlation degree. We then\ngenerate a $k$-th order approximate noise channel by truncating the cluster\nexpansion and incorporating noise components with correlations up to the $k$-th\ndegree. We require that the approximate noise channels must be accurate and\nalso \"honest\", i.e., the actual errors are not underestimated in our physical\nmodels. As an example application, we apply our method to model noise in a\nthree-qubit quantum processor that stabilizes a [[2,0,0]] codeword, which is\none of the four Bell states. We find that, for realistic noise strength typical\nfor fixed-frequency superconducting qubits coupled via always-on static\ninteractions, correlated noise beyond two-qubit correlation can significantly\naffect the code simulation accuracy. Since our approach provides a systematic\nnoise characterization, it enables the potential for accurate, honest and\nscalable approximation to simulate large numbers of qubits from full modeling\nor experimental characterizations of small enough quantum subsystems, which are\nefficient but still retain essential noise features of the entire device.",
            "author": [
                "F. Setiawan",
                "Alexander V. Gramolin",
                "Elisha S. Matekole",
                "Hari Krovi",
                "Jacob M. Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09305v1",
                "http://arxiv.org/pdf/2311.09305v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09298v1",
            "title": "Scattering phase shifts from a quantum computer",
            "updated": "2023-11-15T19:00:05Z",
            "published": "2023-11-15T19:00:05Z",
            "summary": "We calculate two-body scattering phase shifts on a quantum computer using a\nleading order short-range effective field theory Hamiltonian. The algorithm\ncombines the variational quantum eigensolver and the quantum subspace\nexpansion. As an example, we consider scattering in the deuteron $^3$S$_1$\npartial wave. We calculate scattering phase shifts with a quantum simulator and\non real hardware. We also study how noise impacts these calculations and\ndiscuss noise mitigation required to extend our work to larger quantum\nprocessing units. With current hardware, up to five superconducting qubits can\nproduce acceptable results, and larger calculations will require a significant\nnoise reduction.",
            "author": [
                "Sanket Sharma",
                "Thomas Papenbrock",
                "Lucas Platter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09298v1",
                "http://arxiv.org/pdf/2311.09298v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09299v1",
            "title": "Magnetic field breakout from white dwarf crystallization dynamos",
            "updated": "2023-11-15T19:00:05Z",
            "published": "2023-11-15T19:00:05Z",
            "summary": "A convective dynamo operating during the crystallization of white dwarfs is\none of the promising channels to produce their observed strong magnetic fields.\nAlthough the magnitude of the fields generated by crystallization dynamos is\nuncertain, their timing may serve as an orthogonal test of this channel's\ncontribution. The carbon-oxygen cores of $M\\approx 0.5-1.0\\,{\\rm M}_\\odot$\nwhite dwarfs begin to crystallize at an age $t_{\\rm cryst}\\propto M^{-5/3}$,\nbut the magnetic field is initially trapped in the convection zone - deep\ninside the CO core. Only once a mass of $m_{\\rm cryst}$ has crystallized, the\nconvection zone approaches the white dwarf's helium layer, such that the\nmagnetic diffusion time through the envelope shortens sufficiently for the\nfield to break out to the surface, where it can be observed. This breakout time\nis longer than $t_{\\rm cryst}$ by a few Gyr, scaling as $t_{\\rm break}\\propto\nt_{\\rm cryst}f^{-1/2}$, where $f\\equiv 1-m_{\\rm cryst}/M$ depends on the white\ndwarf's initial C/O profile before crystallization. The first appearance of\nstrong magnetic fields $B\\gtrsim 1\\textrm{ MG}$ in volume-limited samples\napproximately coincides with our numerically computed $t_{\\rm break}(M)$ -\npotentially signalling crystallization dynamos as a dominant magnetization\nchannel. However, some observed magnetic white dwarfs are slightly younger,\nchallenging this scenario. The dependence of the breakout process on the white\ndwarf's C/O profile implies that magnetism may probe the CO phase diagram, as\nwell as uncertainties during the core helium burning phase in the white dwarf's\nprogenitor, such as the $^{12}{\\rm C}(\\alpha,\\gamma)^{16}{\\rm O}$ nuclear\nreaction.",
            "author": [
                "Daniel Blatman",
                "Sivan Ginzburg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09299v1",
                "http://arxiv.org/pdf/2311.09299v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09292v1",
            "title": "Full range spectral correlations and their spectral form factors in\n  chaotic and integrable models",
            "updated": "2023-11-15T19:00:01Z",
            "published": "2023-11-15T19:00:01Z",
            "summary": "Quantum chaotic systems are characterized by energy correlations in their\nspectral statistics, usually probed by the distribution of nearest-neighbor\nlevel spacings. Some signatures of chaos, like the spectral form factor (SFF),\ntake all the correlations into account, while others sample only short-range or\nlong-range correlations. Here, we characterize correlations between\neigenenergies at all possible spectral distances. Specifically, we study the\ndistribution of $k$-th neighbor level spacings ($k$nLS) and compute its\nassociated $k$-th neighbor spectral form factor ($k$nSFF). This leads to two\nnew full-range signatures of quantum chaos, the variance of the $k$nLS\ndistribution and the minimum value of the $k$nSFF, which quantitatively\ncharacterize correlations between pairs of eigenenergies with any number of\nlevels $k$ between them. We find exact and approximate expressions for these\nsignatures in the three Gaussian ensembles of random matrix theory (GOE, GUE\nand GSE) and in integrable systems with completely uncorrelated spectra (the\nPoisson ensemble). We illustrate our findings in a XXZ spin chain with\ndisorder, which interpolates between chaotic and integrable behavior. Our\nrefined measures of chaos allow us to probe deviations from Poissonian and\nRandom Matrix behavior in realistic systems. This illustrates how the measures\nwe introduce bring a new light into studying many-body quantum systems, which\nlie in-between the fully chaotic or fully integrable models.",
            "author": [
                "Ruth Shir",
                "Pablo Martinez-Azcona",
                "Aur\u00e9lia Chenu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09292v1",
                "http://arxiv.org/pdf/2311.09292v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech",
                "hep-th",
                "math-ph",
                "math.MP",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09221v1",
            "title": "Single-Image 3D Human Digitization with Shape-Guided Diffusion",
            "updated": "2023-11-15T18:59:56Z",
            "published": "2023-11-15T18:59:56Z",
            "summary": "We present an approach to generate a 360-degree view of a person with a\nconsistent, high-resolution appearance from a single input image. NeRF and its\nvariants typically require videos or images from different viewpoints. Most\nexisting approaches taking monocular input either rely on ground-truth 3D scans\nfor supervision or lack 3D consistency. While recent 3D generative models show\npromise of 3D consistent human digitization, these approaches do not generalize\nwell to diverse clothing appearances, and the results lack photorealism. Unlike\nexisting work, we utilize high-capacity 2D diffusion models pretrained for\ngeneral image synthesis tasks as an appearance prior of clothed humans. To\nachieve better 3D consistency while retaining the input identity, we\nprogressively synthesize multiple views of the human in the input image by\ninpainting missing regions with shape-guided diffusion conditioned on\nsilhouette and surface normal. We then fuse these synthesized multi-view images\nvia inverse rendering to obtain a fully textured high-resolution 3D mesh of the\ngiven person. Experiments show that our approach outperforms prior methods and\nachieves photorealistic 360-degree synthesis of a wide range of clothed humans\nwith complex textures from a single image.",
            "author": [
                "Badour AlBahar",
                "Shunsuke Saito",
                "Hung-Yu Tseng",
                "Changil Kim",
                "Johannes Kopf",
                "Jia-Bin Huang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618153",
                "http://arxiv.org/abs/2311.09221v1",
                "http://arxiv.org/pdf/2311.09221v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09278v1",
            "title": "Symbol-LLM: Towards Foundational Symbol-centric Interface For Large\n  Language Models",
            "updated": "2023-11-15T18:59:56Z",
            "published": "2023-11-15T18:59:56Z",
            "summary": "Large Language Models (LLMs) have greatly propelled the progress in natural\nlanguage(NL)-centric tasks based on NL interface. However, the NL form is not\nenough for world knowledge. Current works focus on this question by injecting\nspecific symbolic knowledge into LLM, which ignore two critical challenges: the\ninterrelations between various symbols and the balance between symbolic-centric\nand NL-centric capabilities. In this work, we tackle these challenges from both\na data and framework perspective and introduce Symbol-LLM series models. First,\nwe collect 34 symbolic tasks, covering ~20 different forms, which are unified\nto capture symbol interrelations. Then, a two-stage tuning framework succeeds\nin injecting symbolic knowledge without loss of the generality ability.\nExtensive experiments on both symbol- and NL-centric tasks demonstrate the\nbalanced and superior performances of Symbol-LLM series models.",
            "author": [
                "Fangzhi Xu",
                "Zhiyong Wu",
                "Qiushi Sun",
                "Siyu Ren",
                "Fei Yuan",
                "Shuai Yuan",
                "Qika Lin",
                "Yu Qiao",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09278v1",
                "http://arxiv.org/pdf/2311.09278v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09217v1",
            "title": "DMV3D: Denoising Multi-View Diffusion using 3D Large Reconstruction\n  Model",
            "updated": "2023-11-15T18:58:41Z",
            "published": "2023-11-15T18:58:41Z",
            "summary": "We propose \\textbf{DMV3D}, a novel 3D generation approach that uses a\ntransformer-based 3D large reconstruction model to denoise multi-view\ndiffusion. Our reconstruction model incorporates a triplane NeRF representation\nand can denoise noisy multi-view images via NeRF reconstruction and rendering,\nachieving single-stage 3D generation in $\\sim$30s on single A100 GPU. We train\n\\textbf{DMV3D} on large-scale multi-view image datasets of highly diverse\nobjects using only image reconstruction losses, without accessing 3D assets. We\ndemonstrate state-of-the-art results for the single-image reconstruction\nproblem where probabilistic modeling of unseen object parts is required for\ngenerating diverse reconstructions with sharp textures. We also show\nhigh-quality text-to-3D generation results outperforming previous 3D diffusion\nmodels. Our project website is at: https://justimyhxu.github.io/projects/dmv3d/ .",
            "author": [
                "Yinghao Xu",
                "Hao Tan",
                "Fujun Luan",
                "Sai Bi",
                "Peng Wang",
                "Jiahao Li",
                "Zifan Shi",
                "Kalyan Sunkavalli",
                "Gordon Wetzstein",
                "Zexiang Xu",
                "Kai Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09217v1",
                "http://arxiv.org/pdf/2311.09217v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09216v1",
            "title": "Assessing Translation capabilities of Large Language Models involving\n  English and Indian Languages",
            "updated": "2023-11-15T18:58:19Z",
            "published": "2023-11-15T18:58:19Z",
            "summary": "Generative Large Language Models (LLMs) have achieved remarkable advancements\nin various NLP tasks. In this work, our aim is to explore the multilingual\ncapabilities of large language models by using machine translation as a task\ninvolving English and 22 Indian languages. We first investigate the translation\ncapabilities of raw large language models, followed by exploring the in-context\nlearning capabilities of the same raw models. We fine-tune these large language\nmodels using parameter efficient fine-tuning methods such as LoRA and\nadditionally with full fine-tuning. Through our study, we have identified the\nbest performing large language model for the translation task involving LLMs,\nwhich is based on LLaMA.\n  Our results demonstrate significant progress, with average BLEU scores of\n13.42, 15.93, 12.13, 12.30, and 12.07, as well as CHRF scores of 43.98, 46.99,\n42.55, 42.42, and 45.39, respectively, using 2-stage fine-tuned LLaMA-13b for\nEnglish to Indian languages on IN22 (conversational), IN22 (general),\nflores200-dev, flores200-devtest, and newstest2019 testsets. Similarly, for\nIndian languages to English, we achieved average BLEU scores of 14.03, 16.65,\n16.17, 15.35 and 12.55 along with chrF scores of 36.71, 40.44, 40.26, 39.51,\nand 36.20, respectively, using fine-tuned LLaMA-13b on IN22 (conversational),\nIN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets.\nOverall, our findings highlight the potential and strength of large language\nmodels for machine translation capabilities, including for languages that are\ncurrently underrepresented in LLMs.",
            "author": [
                "Vandan Mujadia",
                "Ashok Urlana",
                "Yash Bhaskar",
                "Penumalla Aditya Pavani",
                "Kukkapalli Shravya",
                "Parameswari Krishnamurthy",
                "Dipti Misra Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09216v1",
                "http://arxiv.org/pdf/2311.09216v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09215v1",
            "title": "ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy",
            "updated": "2023-11-15T18:56:51Z",
            "published": "2023-11-15T18:56:51Z",
            "summary": "Modern computer vision offers a great variety of models to practitioners, and\nselecting a model from multiple options for specific applications can be\nchallenging. Conventionally, competing model architectures and training\nprotocols are compared by their classification accuracy on ImageNet. However,\nthis single metric does not fully capture performance nuances critical for\nspecialized tasks. In this work, we conduct an in-depth comparative analysis of\nmodel behaviors beyond ImageNet accuracy, for both ConvNet and Vision\nTransformer architectures, each across supervised and CLIP training paradigms.\nAlthough our selected models have similar ImageNet accuracies and compute\nrequirements, we find that they differ in many other aspects: types of\nmistakes, output calibration, transferability, and feature invariance, among\nothers. This diversity in model characteristics, not captured by traditional\nmetrics, highlights the need for more nuanced analysis when choosing among\ndifferent models. Our code is available at\nhttps://github.com/kirill-vish/Beyond-INet.",
            "author": [
                "Kirill Vishniakov",
                "Zhiqiang Shen",
                "Zhuang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09215v1",
                "http://arxiv.org/pdf/2311.09215v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09214v1",
            "title": "Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive\n  Thinking from Large Language Models",
            "updated": "2023-11-15T18:56:23Z",
            "published": "2023-11-15T18:56:23Z",
            "summary": "Large language models (LLMs) have achieved remarkable advancements in the\nfield of natural language processing. However, the sheer scale and\ncomputational demands of these models present formidable challenges when\nconsidering their practical deployment in resource-constrained contexts. While\ntechniques such as chain-of-thought (CoT) distillation have displayed promise\nin distilling LLMs into small language models (SLMs), there is a risk that\ndistilled SLMs may still carry over flawed reasoning or hallucinations\ninherited from their LLM counterparts. To address these issues, we propose a\ntwofold methodology: First, we introduce a novel method for distilling the\nself-evaluation capability inherent in LLMs into SLMs, which aims to mitigate\nthe adverse effects of erroneous reasoning and reduce hallucinations. Second,\nwe advocate for a comprehensive distillation process that incorporates multiple\ndistinct chain-of-thought and self-evaluation paradigms and ensures a more\nholistic and robust knowledge transfer into SLMs. Experiments on three NLP\nbenchmarks demonstrate that our method significantly improves the performance\nof distilled SLMs and sheds light on the path towards developing smaller models\nclosely aligned with human cognition.",
            "author": [
                "Weize Liu",
                "Guocong Li",
                "Kai Zhang",
                "Bang Du",
                "Qiyuan Chen",
                "Xuming Hu",
                "Hongxia Xu",
                "Jintai Chen",
                "Jian Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09214v1",
                "http://arxiv.org/pdf/2311.09214v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09213v1",
            "title": "GRIM: GRaph-based Interactive narrative visualization for gaMes",
            "updated": "2023-11-15T18:55:45Z",
            "published": "2023-11-15T18:55:45Z",
            "summary": "Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The\nnarratives of these may take years to write and typically involve a large\ncreative team. In this work, we demonstrate the potential of large generative\ntext models to assist this process. \\textbf{GRIM}, a prototype\n\\textbf{GR}aph-based \\textbf{I}nteractive narrative visualization system for\nga\\textbf{M}es, generates a rich narrative graph with branching storylines that\nmatch a high-level narrative description and constraints provided by the\ndesigner. Game designers can interactively edit the graph by automatically\ngenerating new sub-graphs that fit the edits within the original narrative and\nconstraints. We illustrate the use of \\textbf{GRIM} in conjunction with GPT-4,\ngenerating branching narratives for four well-known stories with different\ncontextual constraints.",
            "author": [
                "Jorge Leandro",
                "Sudha Rao",
                "Michael Xu",
                "Weijia Xu",
                "Nebosja Jojic",
                "Chris Brockett",
                "Bill Dolan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09213v1",
                "http://arxiv.org/pdf/2311.09213v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09212v1",
            "title": "Controllable Text Summarization: Unraveling Challenges, Approaches, and\n  Prospects -- A Survey",
            "updated": "2023-11-15T18:55:43Z",
            "published": "2023-11-15T18:55:43Z",
            "summary": "Generic text summarization approaches often fail to address the specific\nintent and needs of individual users. Recently, scholarly attention has turned\nto the development of summarization methods that are more closely tailored and\ncontrolled to align with specific objectives and user needs. While a growing\ncorpus of research is devoted towards a more controllable summarization, there\nis no comprehensive survey available that thoroughly explores the diverse\ncontrollable aspects or attributes employed in this context, delves into the\nassociated challenges, and investigates the existing solutions. In this survey,\nwe formalize the Controllable Text Summarization (CTS) task, categorize\ncontrollable aspects according to their shared characteristics and objectives,\nand present a thorough examination of existing methods and datasets within each\ncategory. Moreover, based on our findings, we uncover limitations and research\ngaps, while also delving into potential solutions and future directions for\nCTS.",
            "author": [
                "Ashok Urlana",
                "Pruthwik Mishra",
                "Tathagato Roy",
                "Rahul Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09212v1",
                "http://arxiv.org/pdf/2311.09212v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09211v2",
            "title": "Digitally reproducing the artistic style of XVI century artist Antonio\n  Campelo in Alegoria Prudencia",
            "updated": "2023-11-24T17:03:52Z",
            "published": "2023-11-15T18:55:14Z",
            "summary": "In this work, the artistic style of the sixteenth century Portuguese artist\nAnt\\'onio Campelo in Alegoria \\`a Prud\\^encia is analyzed in order to create a\ncomputational tool that allows one to transform any 3D digital sculpture model\ninto an image that resembles the modeled style. From this analysis the problem\nis divided into two parts: detection and drawing of contour lines and the\nshading of the scene. Several techniques from Non Photorealistic Rendering\n(NPR) and from Photorealistic Rendering that can resolve the problem are\npresented and, based on this study, a possible solution is presented. Each\nmodeled rendering component is then analyzed using image based methods against\nthe proposed artistic style and parameters are adjusted for a closer match. In\nthe final stage a group of people was asked to answer a questionnaire where the\nsimilarity between the renderings of different objects and the original style\nwas classified according to their personal opinion. One of our findings is that\nalthough the source 3D objects cannot be readily found for a direct comparison,\nnor can the paper medium with centuries old damage be the same, the comparison\nof sub -parts of both images of the same topology was still possible validating\nour method and discarding other styles from the comparison.",
            "author": [
                "Joao Fradinho Oliveira",
                "Joao Madeiras Pereira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09211v2",
                "http://arxiv.org/pdf/2311.09211v2"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09210v1",
            "title": "Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language\n  Models",
            "updated": "2023-11-15T18:54:53Z",
            "published": "2023-11-15T18:54:53Z",
            "summary": "Retrieval-augmented language models (RALMs) represent a substantial\nadvancement in the capabilities of large language models, notably in reducing\nfactual hallucination by leveraging external knowledge sources. However, the\nreliability of the retrieved information is not always guaranteed. The\nretrieval of irrelevant data can lead to misguided responses, and potentially\ncausing the model to overlook its inherent knowledge, even when it possesses\nadequate information to address the query. Moreover, standard RALMs often\nstruggle to assess whether they possess adequate knowledge, both intrinsic and\nretrieved, to provide an accurate answer. In situations where knowledge is\nlacking, these systems should ideally respond with \"unknown\" when the answer is\nunattainable. In response to these challenges, we introduces Chain-of-Noting\n(CoN), a novel approach aimed at improving the robustness of RALMs in facing\nnoisy, irrelevant documents and in handling unknown scenarios. The core idea of\nCoN is to generate sequential reading notes for retrieved documents, enabling a\nthorough evaluation of their relevance to the given question and integrating\nthis information to formulate the final answer. We employed ChatGPT to create\ntraining data for CoN, which was subsequently trained on an LLaMa-2 7B model.\nOur experiments across four open-domain QA benchmarks show that RALMs equipped\nwith CoN significantly outperform standard RALMs. Notably, CoN achieves an\naverage improvement of +7.9 in EM score given entirely noisy retrieved\ndocuments and +10.5 in rejection rates for real-time questions that fall\noutside the pre-training knowledge scope.",
            "author": [
                "Wenhao Yu",
                "Hongming Zhang",
                "Xiaoman Pan",
                "Kaixin Ma",
                "Hongwei Wang",
                "Dong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09210v1",
                "http://arxiv.org/pdf/2311.09210v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09277v1",
            "title": "Contrastive Chain-of-Thought Prompting",
            "updated": "2023-11-15T18:54:01Z",
            "published": "2023-11-15T18:54:01Z",
            "summary": "Despite the success of chain of thought in enhancing language model\nreasoning, the underlying process remains less well understood. Although\nlogically sound reasoning appears inherently crucial for chain of thought,\nprior studies surprisingly reveal minimal impact when using invalid\ndemonstrations instead. Furthermore, the conventional chain of thought does not\ninform language models on what mistakes to avoid, which potentially leads to\nmore errors. Hence, inspired by how humans can learn from both positive and\nnegative examples, we propose contrastive chain of thought to enhance language\nmodel reasoning. Compared to the conventional chain of thought, our approach\nprovides both valid and invalid reasoning demonstrations, to guide the model to\nreason step-by-step while reducing reasoning mistakes. To improve\ngeneralization, we introduce an automatic method to construct contrastive\ndemonstrations. Our experiments on reasoning benchmarks demonstrate that\ncontrastive chain of thought can serve as a general enhancement of\nchain-of-thought prompting.",
            "author": [
                "Yew Ken Chia",
                "Guizhen Chen",
                "Luu Anh Tuan",
                "Soujanya Poria",
                "Lidong Bing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09277v1",
                "http://arxiv.org/pdf/2311.09277v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09276v1",
            "title": "Leveraging Citizen Science for Flood Extent Detection using Machine\n  Learning Benchmark Dataset",
            "updated": "2023-11-15T18:49:29Z",
            "published": "2023-11-15T18:49:29Z",
            "summary": "Accurate detection of inundated water extents during flooding events is\ncrucial in emergency response decisions and aids in recovery efforts. Satellite\nRemote Sensing data provides a global framework for detecting flooding extents.\nSpecifically, Sentinel-1 C-Band Synthetic Aperture Radar (SAR) imagery has\nproven to be useful in detecting water bodies due to low backscatter of water\nfeatures in both co-polarized and cross-polarized SAR imagery. However,\nincreased backscatter can be observed in certain flooded regions such as\npresence of infrastructure and trees - rendering simple methods such as pixel\nintensity thresholding and time-series differencing inadequate. Machine\nLearning techniques has been leveraged to precisely capture flood extents in\nflooded areas with bumps in backscatter but needs high amounts of labelled data\nto work desirably. Hence, we created a labeled known water body extent and\nflooded area extents during known flooding events covering about 36,000 sq.\nkilometers of regions within mainland U.S and Bangladesh. Further, We also\nleveraged citizen science by open-sourcing the dataset and hosting an open\ncompetition based on the dataset to rapidly prototype flood extent detection\nusing community generated models. In this paper we present the information\nabout the dataset, the data processing pipeline, a baseline model and the\ndetails about the competition, along with discussion on winning approaches. We\nbelieve the dataset adds to already existing datasets based on Sentinel-1C SAR\ndata and leads to more robust modeling of flood extents. We also hope the\nresults from the competition pushes the research in flood extent detection\nfurther.",
            "author": [
                "Muthukumaran Ramasubramanian",
                "Iksha Gurung",
                "Shubhankar Gahlot",
                "Ronny H\u00e4nsch",
                "Andrew L. Molthan",
                "Manil Maskey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09276v1",
                "http://arxiv.org/pdf/2311.09276v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09206v1",
            "title": "TableLlama: Towards Open Large Generalist Models for Tables",
            "updated": "2023-11-15T18:47:52Z",
            "published": "2023-11-15T18:47:52Z",
            "summary": "Semi-structured tables are ubiquitous. There has been a variety of tasks that\naim to automatically interpret, augment, and query tables. Current methods\noften require pretraining on tables or special model architecture design, are\nrestricted to specific table types, or have simplifying assumptions about\ntables and tasks. This paper makes the first step towards developing\nopen-source large language models (LLMs) as generalists for a diversity of\ntable-based tasks. Towards that end, we construct TableInstruct, a new dataset\nwith a variety of realistic tables and tasks, for instruction tuning and\nevaluating LLMs. We further develop the first open-source generalist model for\ntables, TableLlama, by fine-tuning Llama 2 (7B) with LongLoRA to address the\nlong context challenge. We experiment under both in-domain setting and\nout-of-domain setting. On 7 out of 8 in-domain tasks, TableLlama achieves\ncomparable or better performance than the SOTA for each task, despite the\nlatter often has task-specific design. On 6 out-of-domain datasets, it achieves\n6-48 absolute point gains compared with the base model, showing that training\non TableInstruct enhances the model's generalizability. We will open-source our\ndataset and trained model to boost future work on developing open generalist\nmodels for tables.",
            "author": [
                "Tianshu Zhang",
                "Xiang Yue",
                "Yifei Li",
                "Huan Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09206v1",
                "http://arxiv.org/pdf/2311.09206v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09205v1",
            "title": "When Is Multilinguality a Curse? Language Modeling for 250 High- and\n  Low-Resource Languages",
            "updated": "2023-11-15T18:47:42Z",
            "published": "2023-11-15T18:47:42Z",
            "summary": "Multilingual language models are widely used to extend NLP systems to\nlow-resource languages. However, concrete evidence for the effects of\nmultilinguality on language modeling performance in individual languages\nremains scarce. Here, we pre-train over 10,000 monolingual and multilingual\nlanguage models for over 250 languages, including multiple language families\nthat are under-studied in NLP. We assess how language modeling performance in\neach language varies as a function of (1) monolingual dataset size, (2) added\nmultilingual dataset size, (3) linguistic similarity of the added languages,\nand (4) model size (up to 45M parameters). We find that in moderation, adding\nmultilingual data improves low-resource language modeling performance, similar\nto increasing low-resource dataset sizes by up to 33%. Improvements depend on\nthe syntactic similarity of the added multilingual data, with marginal\nadditional effects of vocabulary overlap. However, high-resource languages\nconsistently perform worse in multilingual pre-training scenarios. As dataset\nsizes increase, adding multilingual data begins to hurt performance for both\nlow-resource and high-resource languages, likely due to limited model capacity\n(the \"curse of multilinguality\"). These results suggest that massively\nmultilingual pre-training may not be optimal for any languages involved, but\nthat more targeted models can significantly improve performance.",
            "author": [
                "Tyler A. Chang",
                "Catherine Arnett",
                "Zhuowen Tu",
                "Benjamin K. Bergen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09205v1",
                "http://arxiv.org/pdf/2311.09205v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09204v1",
            "title": "Fusion-Eval: Integrating Evaluators with LLMs",
            "updated": "2023-11-15T18:46:56Z",
            "published": "2023-11-15T18:46:56Z",
            "summary": "Evaluating Large Language Models (LLMs) is a complex task, especially\nconsidering the intricacies of natural language understanding and the\nexpectations for high-level reasoning. Traditional evaluations typically lean\non human-based, model-based, or automatic-metrics-based paradigms, each with\nits own advantages and shortcomings. We introduce \"Fusion-Eval\", a system that\nemploys LLMs not solely for direct evaluations, but to skillfully integrate\ninsights from diverse evaluators. This gives Fusion-Eval flexibility, enabling\nit to work effectively across diverse tasks and make optimal use of multiple\nreferences. In testing on the SummEval dataset, Fusion-Eval achieved a Spearman\ncorrelation of 0.96, outperforming other evaluators. The success of Fusion-Eval\nunderscores the potential of LLMs to produce evaluations that closely align\nhuman perspectives, setting a new standard in the field of LLM evaluation.",
            "author": [
                "Lei Shu",
                "Nevan Wichers",
                "Liangchen Luo",
                "Yun Zhu",
                "Yinxiao Liu",
                "Jindong Chen",
                "Lei Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09204v1",
                "http://arxiv.org/pdf/2311.09204v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09199v1",
            "title": "Second cohomology space of $\\frak {sl}(2)$ acting on the space of\n  $n$-ary differential operators on $\\mathbb{R}$",
            "updated": "2023-11-15T18:43:13Z",
            "published": "2023-11-15T18:43:13Z",
            "summary": "We consider the spaces $\\mathcal{F}_\\mu$ of polynomial $\\mu$-densities on the\nline as $\\mathfrak{sl}(2)$-modules and then we compute the cohomological spaces\n$\\mathrm{H}^2_\\mathrm{diff}(\\mathfrak{sl}(2),\n\\mathcal{D}_{\\bar{\\lambda},\\mu})$, where $\\mu\\in \\mathbb{R}$,\n$\\bar{\\lambda}=(\\lambda_1,\\dots,\\lambda_n)\n  \\in\\mathbb{R}^n$ and $\\mathcal{D}_{\\bar{\\lambda},\\mu}$ is the space of\n$n$-ary differential operators from\n$\\mathcal{F}_{\\lambda_1}\\otimes\\cdots\\otimes\n  \\mathcal{F}_{\\lambda_n}$ to $\\mathcal{F}_\\mu$.",
            "author": [
                "Mabrouk Ben Ammar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09199v1",
                "http://arxiv.org/pdf/2311.09199v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10770v2",
            "title": "Exponentially Faster Language Modelling",
            "updated": "2023-11-21T06:59:59Z",
            "published": "2023-11-15T18:42:50Z",
            "summary": "Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.",
            "author": [
                "Peter Belcak",
                "Roger Wattenhofer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10770v2",
                "http://arxiv.org/pdf/2311.10770v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09198v1",
            "title": "Never Lost in the Middle: Improving Large Language Models via Attention\n  Strengthening Question Answering",
            "updated": "2023-11-15T18:42:44Z",
            "published": "2023-11-15T18:42:44Z",
            "summary": "While large language models (LLMs) are equipped with longer text input\ncapabilities than before, they are struggling to seek correct information in\nlong contexts. The \"lost in the middle\" problem challenges most LLMs, referring\nto the dramatic decline in accuracy when correct information is located in the\nmiddle. To overcome this crucial issue, this paper proposes to enhance the\ninformation searching and reflection ability of LLMs in long contexts via\nspecially designed tasks called Attention Strengthening Multi-doc QA (ASM QA).\nFollowing these tasks, our model excels in focusing more precisely on the\ndesired information. Experimental results show substantial improvement in\nMulti-doc QA and other benchmarks, superior to state-of-the-art models by 13.7%\nabsolute gain in shuffled settings, by 21.5% in passage retrieval task. We\nrelease our model, Ziya-Reader to promote related research in the community.",
            "author": [
                "Junqing He",
                "Kunhao Pan",
                "Xiaoqun Dong",
                "Zhuoyang Song",
                "Yibo Liu",
                "Yuxin Liang",
                "Hao Wang",
                "Qianguo Sun",
                "Songxin Zhang",
                "Zejian Xie",
                "Jiaxing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09198v1",
                "http://arxiv.org/pdf/2311.09198v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09194v1",
            "title": "Structural Priming Demonstrates Abstract Grammatical Representations in\n  Multilingual Language Models",
            "updated": "2023-11-15T18:39:56Z",
            "published": "2023-11-15T18:39:56Z",
            "summary": "Abstract grammatical knowledge - of parts of speech and grammatical patterns\n- is key to the capacity for linguistic generalization in humans. But how\nabstract is grammatical knowledge in large language models? In the human\nliterature, compelling evidence for grammatical abstraction comes from\nstructural priming. A sentence that shares the same grammatical structure as a\npreceding sentence is processed and produced more readily. Because confounds\nexist when using stimuli in a single language, evidence of abstraction is even\nmore compelling from crosslingual structural priming, where use of a syntactic\nstructure in one language primes an analogous structure in another language. We\nmeasure crosslingual structural priming in large language models, comparing\nmodel behavior to human experimental results from eight crosslingual\nexperiments covering six languages, and four monolingual structural priming\nexperiments in three non-English languages. We find evidence for abstract\nmonolingual and crosslingual grammatical representations in the models that\nfunction similarly to those found in humans. These results demonstrate that\ngrammatical representations in multilingual language models are not only\nsimilar across languages, but they can causally influence text produced in\ndifferent languages.",
            "author": [
                "James A. Michaelov",
                "Catherine Arnett",
                "Tyler A. Chang",
                "Benjamin K. Bergen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09194v1",
                "http://arxiv.org/pdf/2311.09194v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09193v1",
            "title": "The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task",
            "updated": "2023-11-15T18:39:21Z",
            "published": "2023-11-15T18:39:21Z",
            "summary": "The study explores the effectiveness of the Chain-of-Thought approach, known\nfor its proficiency in language tasks by breaking them down into sub-tasks and\nintermediate steps, in improving vision-language tasks that demand\nsophisticated perception and reasoning. We present the \"Description then\nDecision\" strategy, which is inspired by how humans process signals. This\nstrategy significantly improves probing task performance by 50%, establishing\nthe groundwork for future research on reasoning paradigms in complex\nvision-language tasks.",
            "author": [
                "Yifan Wu",
                "Pengchuan Zhang",
                "Wenhan Xiong",
                "Barlas Oguz",
                "James C. Gee",
                "Yixin Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09193v1",
                "http://arxiv.org/pdf/2311.09193v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09191v1",
            "title": "Domain Aligned CLIP for Few-shot Classification",
            "updated": "2023-11-15T18:34:26Z",
            "published": "2023-11-15T18:34:26Z",
            "summary": "Large vision-language representation learning models like CLIP have\ndemonstrated impressive performance for zero-shot transfer to downstream tasks\nwhile largely benefiting from inter-modal (image-text) alignment via\ncontrastive objectives. This downstream performance can further be enhanced by\nfull-scale fine-tuning which is often compute intensive, requires large\nlabelled data, and can reduce out-of-distribution (OOD) robustness.\nFurthermore, sole reliance on inter-modal alignment might overlook the rich\ninformation embedded within each individual modality. In this work, we\nintroduce a sample-efficient domain adaptation strategy for CLIP, termed Domain\nAligned CLIP (DAC), which improves both intra-modal (image-image) and\ninter-modal alignment on target distributions without fine-tuning the main\nmodel. For intra-modal alignment, we introduce a lightweight adapter that is\nspecifically trained with an intra-modal contrastive objective. To improve\ninter-modal alignment, we introduce a simple framework to modulate the\nprecomputed class text embeddings. The proposed few-shot fine-tuning framework\nis computationally efficient, robust to distribution shifts, and does not alter\nCLIP's parameters. We study the effectiveness of DAC by benchmarking on 11\nwidely used image classification tasks with consistent improvements in 16-shot\nclassification upon strong baselines by about 2.3% and demonstrate competitive\nperformance on 4 OOD robustness benchmarks.",
            "author": [
                "Muhammad Waleed Gondal",
                "Jochen Gast",
                "Inigo Alonso Ruiz",
                "Richard Droste",
                "Tommaso Macri",
                "Suren Kumar",
                "Luitpold Staudigl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09191v1",
                "http://arxiv.org/pdf/2311.09191v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09190v1",
            "title": "On the Computation of the Gaussian Rate-Distortion-Perception Function",
            "updated": "2023-11-15T18:34:03Z",
            "published": "2023-11-15T18:34:03Z",
            "summary": "In this paper, we study the computation of the rate-distortion-perception\nfunction (RDPF) for a multivariate Gaussian source under mean squared error\n(MSE) distortion and, respectively, Kullback-Leibler divergence, geometric\nJensen-Shannon divergence, squared Hellinger distance, and squared\nWasserstein-2 distance perception metrics. To this end, we first characterize\nthe analytical bounds of the scalar Gaussian RDPF for the aforementioned\ndivergence functions, also providing the RDPF-achieving forward \"test-channel\"\nrealization. Focusing on the multivariate case, we establish that, for\ntensorizable distortion and perception metrics, the optimal solution resides on\nthe vector space spanned by the eigenvector of the source covariance matrix.\nConsequently, the multivariate optimization problem can be expressed as a\nfunction of the scalar Gaussian RDPFs of the source marginals, constrained by\nglobal distortion and perception levels. Leveraging this characterization, we\ndesign an alternating minimization scheme based on the block nonlinear\nGauss-Seidel method, which optimally solves the problem while identifying the\nGaussian RDPF-achieving realization. Furthermore, the associated algorithmic\nembodiment is provided, as well as the convergence and the rate of convergence\ncharacterization. Lastly, for the \"perfect realism\" regime, the analytical\nsolution for the multivariate Gaussian RDPF is obtained. We corroborate our\nresults with numerical simulations and draw connections to existing results.",
            "author": [
                "Giuseppe Serra",
                "Photios A. Stavrou",
                "Marios Kountouris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09190v1",
                "http://arxiv.org/pdf/2311.09190v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CV",
                "cs.LG",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09189v1",
            "title": "PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for\n  Mental Health",
            "updated": "2023-11-15T18:32:27Z",
            "published": "2023-11-15T18:32:27Z",
            "summary": "Recently, there has been a growing interest in utilizing large language\nmodels (LLMs) in mental health research, with studies showcasing their\nremarkable capabilities, such as disease detection. However, there is currently\na lack of a comprehensive benchmark for evaluating the capability of LLMs in\nthis domain. Therefore, we address this gap by introducing the first\ncomprehensive benchmark tailored to the unique characteristics of the mental\nhealth domain. This benchmark encompasses a total of six sub-tasks, covering\nthree dimensions, to systematically assess the capabilities of LLMs in the\nrealm of mental health. We have designed corresponding concise prompts for each\nsub-task. And we comprehensively evaluate a total of eight advanced LLMs using\nour benchmark. Experiment results not only demonstrate significant room for\nimprovement in current LLMs concerning mental health but also unveil potential\ndirections for future model optimization.",
            "author": [
                "Haoan Jin",
                "Siyuan Chen",
                "Mengyue Wu",
                "Kenny Q. Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09189v1",
                "http://arxiv.org/pdf/2311.09189v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09188v1",
            "title": "Towards Verifiable Text Generation with Symbolic References",
            "updated": "2023-11-15T18:28:29Z",
            "published": "2023-11-15T18:28:29Z",
            "summary": "Large language models (LLMs) have demonstrated an impressive ability to\nsynthesize plausible and fluent text. However they remain vulnerable to\nhallucinations, and thus their outputs generally require manual human\nverification for high-stakes applications, which can be time-consuming and\ndifficult. This paper proposes symbolically grounded generation (SymGen) as a\nsimple approach for enabling easier validation of an LLM's output. SymGen\nprompts an LLM to interleave its regular output text with explicit symbolic\nreferences to fields present in some conditioning data (e.g., a table in JSON\nformat). The references can be used to display the provenance of different\nspans of text in the generation, reducing the effort required for manual\nverification. Across data-to-text and question answering experiments, we find\nthat LLMs are able to directly output text that makes use of symbolic\nreferences while maintaining fluency and accuracy.",
            "author": [
                "Lucas Torroba Hennigen",
                "Shannon Shen",
                "Aniruddha Nrusimha",
                "Bernhard Gapp",
                "David Sontag",
                "Yoon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09188v1",
                "http://arxiv.org/pdf/2311.09188v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09184v1",
            "title": "Benchmarking Generation and Evaluation Capabilities of Large Language\n  Models for Instruction Controllable Summarization",
            "updated": "2023-11-15T18:25:26Z",
            "published": "2023-11-15T18:25:26Z",
            "summary": "While large language models (LLMs) already achieve strong performance on\nstandard generic summarization benchmarks, their performance on more complex\nsummarization task settings is less studied. Therefore, we benchmark LLMs on\ninstruction controllable text summarization, where the model input consists of\nboth a source article and a natural language requirement for the desired\nsummary characteristics. To this end, we curate an evaluation-only dataset for\nthis task setting and conduct human evaluation on 5 LLM-based summarization\nsystems. We then benchmark LLM-based automatic evaluation for this task with 4\ndifferent evaluation protocols and 11 LLMs, resulting in 40 evaluation methods\nin total. Our study reveals that instruction controllable text summarization\nremains a challenging task for LLMs, since (1) all LLMs evaluated still make\nfactual and other types of errors in their summaries; (2) all LLM-based\nevaluation methods cannot achieve a strong alignment with human annotators when\njudging the quality of candidate summaries; (3) different LLMs show large\nperformance gaps in summary generation and evaluation. We make our collected\nbenchmark, InstruSum, publicly available to facilitate future research in this\ndirection.",
            "author": [
                "Yixin Liu",
                "Alexander R. Fabbri",
                "Jiawen Chen",
                "Yilun Zhao",
                "Simeng Han",
                "Shafiq Joty",
                "Pengfei Liu",
                "Dragomir Radev",
                "Chien-Sheng Wu",
                "Arman Cohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09184v1",
                "http://arxiv.org/pdf/2311.09184v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09182v1",
            "title": "ContraDoc: Understanding Self-Contradictions in Documents with Large\n  Language Models",
            "updated": "2023-11-15T18:23:17Z",
            "published": "2023-11-15T18:23:17Z",
            "summary": "In recent times, large language models (LLMs) have shown impressive\nperformance on various document-level tasks such as document classification,\nsummarization, and question-answering. However, research on understanding their\ncapabilities on the task of self-contradictions in long documents has been very\nlimited. In this work, we introduce ContraDoc, the first human-annotated\ndataset to study self-contradictions in long documents across multiple domains,\nvarying document lengths, self-contradictions types, and scope. We then analyze\nthe current capabilities of four state-of-the-art open-source and commercially\navailable LLMs: GPT3.5, GPT4, PaLM2, and LLaMAv2 on this dataset. While GPT4\nperforms the best and can outperform humans on this task, we find that it is\nstill unreliable and struggles with self-contradictions that require more\nnuance and context. We release the dataset and all the code associated with the\nexperiments.",
            "author": [
                "Jierui Li",
                "Vipul Raheja",
                "Dhruv Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09182v1",
                "http://arxiv.org/pdf/2311.09182v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09180v1",
            "title": "PEARL: Personalizing Large Language Model Writing Assistants with\n  Generation-Calibrated Retrievers",
            "updated": "2023-11-15T18:19:58Z",
            "published": "2023-11-15T18:19:58Z",
            "summary": "Powerful large language models have facilitated the development of writing\nassistants that promise to significantly improve the quality and efficiency of\ncomposition and communication. However, a barrier to effective assistance is\nthe lack of personalization in LLM outputs to the author's communication style\nand specialized knowledge. In this paper, we address this challenge by\nproposing PEARL, a retrieval-augmented LLM writing assistant personalized with\na generation-calibrated retriever. Our retriever is trained to select historic\nuser-authored documents for prompt augmentation, such that they are likely to\nbest personalize LLM generations for a user request. We propose two key\nnovelties for training our retriever: 1) A training data selection method that\nidentifies user requests likely to benefit from personalization and documents\nthat provide that benefit; and 2) A scale-calibrating KL-divergence objective\nthat ensures that our retriever closely tracks the benefit of a document for\npersonalized generation. We demonstrate the effectiveness of PEARL in\ngenerating personalized workplace social media posts and Reddit comments.\nFinally, we showcase the potential of a generation-calibrated retriever to\ndouble as a performance predictor and further improve low-quality generations\nvia LLM chaining.",
            "author": [
                "Sheshera Mysore",
                "Zhuoran Lu",
                "Mengting Wan",
                "Longqi Yang",
                "Steve Menezes",
                "Tina Baghaee",
                "Emmanuel Barajas Gonzalez",
                "Jennifer Neville",
                "Tara Safavi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09180v1",
                "http://arxiv.org/pdf/2311.09180v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10768v1",
            "title": "Memory Augmented Language Models through Mixture of Word Experts",
            "updated": "2023-11-15T18:19:56Z",
            "published": "2023-11-15T18:19:56Z",
            "summary": "Scaling up the number of parameters of language models has proven to be an\neffective approach to improve performance. For dense models, increasing model\nsize proportionally increases the model's computation footprint. In this work,\nwe seek to aggressively decouple learning capacity and FLOPs through\nMixture-of-Experts (MoE) style models with large knowledge-rich vocabulary\nbased routing functions and experts. Our proposed approach, dubbed Mixture of\nWord Experts (MoWE), can be seen as a memory augmented model, where a large set\nof word-specific experts play the role of a sparse memory. We demonstrate that\nMoWE performs significantly better than the T5 family of models with similar\nnumber of FLOPs in a variety of NLP tasks. Additionally, MoWE outperforms\nregular MoE models on knowledge intensive tasks and has similar performance to\nmore complex memory augmented approaches that often require to invoke custom\nmechanisms to search the sparse memory.",
            "author": [
                "Cicero Nogueira dos Santos",
                "James Lee-Thorp",
                "Isaac Noble",
                "Chung-Ching Chang",
                "David Uthus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10768v1",
                "http://arxiv.org/pdf/2311.10768v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09179v1",
            "title": "SiRA: Sparse Mixture of Low Rank Adaptation",
            "updated": "2023-11-15T18:15:37Z",
            "published": "2023-11-15T18:15:37Z",
            "summary": "Parameter Efficient Tuning has been an prominent approach to adapt the Large\nLanguage Model to downstream tasks. Most previous works considers adding the\ndense trainable parameters, where all parameters are used to adapt certain\ntask. We found this less effective empirically using the example of LoRA that\nintroducing more trainable parameters does not help. Motivated by this we\ninvestigate the importance of leveraging \"sparse\" computation and propose SiRA:\nsparse mixture of low rank adaption. SiRA leverages the Sparse Mixture of\nExpert(SMoE) to boost the performance of LoRA. Specifically it enforces the top\n$k$ experts routing with a capacity limit restricting the maximum number of\ntokens each expert can process. We propose a novel and simple expert dropout on\ntop of gating network to reduce the over-fitting issue. Through extensive\nexperiments, we verify SiRA performs better than LoRA and other mixture of\nexpert approaches across different single tasks and multitask settings.",
            "author": [
                "Yun Zhu",
                "Nevan Wichers",
                "Chu-Cheng Lin",
                "Xinyi Wang",
                "Tianlong Chen",
                "Lei Shu",
                "Han Lu",
                "Canoee Liu",
                "Liangchen Luo",
                "Jindong Chen",
                "Lei Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09179v1",
                "http://arxiv.org/pdf/2311.09179v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09178v3",
            "title": "RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution",
            "updated": "2023-11-24T11:47:25Z",
            "published": "2023-11-15T18:15:30Z",
            "summary": "Recently, video super resolution (VSR) has become a very impactful task in\nthe area of Computer Vision due to its various applications. In this paper, we\npropose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) for\nVSR in an attempt to generate temporally coherent solutions while preserving\nspatial details. RBPGAN integrates two state-of-the-art models to get the best\nin both worlds without compromising the accuracy of produced video. The\ngenerator of the model is inspired by RBPN system, while the discriminator is\ninspired by TecoGAN. We also utilize Ping-Pong loss to increase temporal\nconsistency over time. Our contribution together results in a model that\noutperforms earlier work in terms of temporally consistent details, as we will\ndemonstrate qualitatively and quantitatively using different datasets.",
            "author": [
                "Marwah Sulaiman",
                "Zahraa Shehabeldin",
                "Israa Fahmy",
                "Mohammed Barakat",
                "Mohammed El-Naggar",
                "Dareen Hussein",
                "Moustafa Youssef",
                "Hesham Eraqi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09178v3",
                "http://arxiv.org/pdf/2311.09178v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09174v2",
            "title": "AbsPyramid: Benchmarking the Abstraction Ability of Language Models with\n  a Unified Entailment Graph",
            "updated": "2023-11-16T08:20:19Z",
            "published": "2023-11-15T18:11:23Z",
            "summary": "Cognitive research indicates that abstraction ability is essential in human\nintelligence, which remains under-explored in language models. In this paper,\nwe present AbsPyramid, a unified entailment graph of 221K textual descriptions\nof abstraction knowledge. While existing resources only touch nouns or verbs\nwithin simplified events or specific domains, AbsPyramid collects abstract\nknowledge for three components of diverse events to comprehensively evaluate\nthe abstraction ability of language models in the open domain. Experimental\nresults demonstrate that current LLMs face challenges comprehending abstraction\nknowledge in zero-shot and few-shot settings. By training on our rich\nabstraction knowledge, we find LLMs can acquire basic abstraction abilities and\ngeneralize to unseen events. In the meantime, we empirically show that our\nbenchmark is comprehensive to enhance LLMs across two previous abstraction\ntasks.",
            "author": [
                "Zhaowei Wang",
                "Haochen Shi",
                "Weiqi Wang",
                "Tianqing Fang",
                "Hongming Zhang",
                "Sehyun Choi",
                "Xin Liu",
                "Yangqiu Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09174v2",
                "http://arxiv.org/pdf/2311.09174v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09173v1",
            "title": "Design Theory for Societal Digital Transformation: The Case of Digital\n  Global Health",
            "updated": "2023-11-15T18:11:16Z",
            "published": "2023-11-15T18:11:16Z",
            "summary": "With societal challenges, including but not limited to human development,\nequity, social justice, and climate change, societal-level digital\ntransformation (SDT) is of imminent relevance and theoretical interest. While\nbuilding on local-level efforts, societal-level transformation is a nonlinear\nextension of the local level. Unfortunately, academic discourse on digital\ntransformation has largely left SDT unaccounted for. Drawing on more than 25\nyears of intensive, interventionist research engagement with the digital\ntransformation of public healthcare information management and delivery in more\nthan 80 countries in the Global South, we contribute to theorizing SDT in the\nform of a design theory consisting of six interconnected design principles.\nThese design principles articulate the interplay and tensions of accommodating\nover time increased diversity and flexibility in digital solutions, while\nsimultaneously connecting local, national, and regional/ global efforts.",
            "author": [
                "Jorn Braa",
                "Sundeep Sahay",
                "Eric Monteiro"
            ],
            "link": [
                "http://dx.doi.org/0.17705/1jais.00816",
                "http://arxiv.org/abs/2311.09173v1",
                "http://arxiv.org/pdf/2311.09173v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09168v1",
            "title": "Generalized Neighbor Search using Commodity Hardware Acceleration",
            "updated": "2023-11-15T18:06:25Z",
            "published": "2023-11-15T18:06:25Z",
            "summary": "Tree-based Nearest Neighbor Search (NNS) is hard to parallelize on GPUs.\nHowever, newer Nvidia GPUs are equipped with Ray Tracing (RT) cores that can\nbuild a spatial tree called Bounding Volume Hierarchy (BVH) to accelerate\ngraphics rendering. Recent work proposed using RT cores to implement NNS, but\nthey all have a hardware-imposed constraint on the type of distance metric,\nwhich is the Euclidean distance. We propose and implement two approaches for\ngeneralized distance computations: filter-refine, and monotone transformation,\neach of which allows non-euclidean nearest neighbor queries to be performed in\nterms of Euclidean distances. We find that our reductions improve the time\ntaken to perform distance computations during the search, thereby improving the\noverall performance of the NNS.",
            "author": [
                "Durga Mandarapu",
                "Vani Nagarajan",
                "Milind Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09168v1",
                "http://arxiv.org/pdf/2311.09168v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09164v2",
            "title": "Hybrid Quantum Cryptography from Communication Complexity",
            "updated": "2023-11-27T09:16:44Z",
            "published": "2023-11-15T18:03:15Z",
            "summary": "We introduce an explicit construction for a key distribution protocol in the\nQuantum Computational Timelock (QCT) security model, where one assumes that\ncomputationally secure encryption may only be broken after a time much longer\nthan the coherence time of available quantum memories.\n  Taking advantage of the QCT assumptions, we build a key distribution protocol\ncalled HM-QCT from the Hidden Matching problem for which there exists an\nexponential gap in one-way communication complexity between classical and\nquantum strategies.\n  We establish that the security of HM-QCT against arbitrary i.i.d. attacks can\nbe reduced to the difficulty of solving the underlying Hidden Matching problem\nwith classical information. Legitimate users, on the other hand, can use\nquantum communication, which gives them the possibility of sending multiple\ncopies of the same quantum state while retaining an information advantage. This\nleads to an everlasting secure key distribution scheme over $n$ bosonic modes.\nSuch a level of security is unattainable with purely classical techniques.\nRemarkably, the scheme remains secure with up to $\\mathcal{O}\\big(\n\\frac{\\sqrt{n}}{\\log(n)}\\big)$ input photons for each channel use, extending\nthe functionalities and potentially outperforming QKD rates by several orders\nof magnitudes.",
            "author": [
                "Francesco Mazzoncini",
                "Balthazar Bauer",
                "Peter Brown",
                "Romain All\u00e9aume"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09164v2",
                "http://arxiv.org/pdf/2311.09164v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09158v1",
            "title": "Differential Rotation in Compact Objects with Hyperons and Delta Isobars",
            "updated": "2023-11-15T17:56:36Z",
            "published": "2023-11-15T17:56:36Z",
            "summary": "Neutron stars may experience differential rotation on short, dynamical\ntimescales following extreme astrophysical events like binary neutron star\nmergers. In this work, the masses and radii of differentially rotating neutron\nstar models are computed. We employ a set of equations of states for dense\nhypernuclear and $\\Delta$-admixed-hypernuclear matter obtained within the\nframework of CDF theory in the relativistic Hartree-Fock (RHF) approximation.\nResults are shown for varying meson-$\\Delta$ couplings, or equivalently the\n$\\Delta$-potential in nuclear matter. A comparison of our results with those\nobtained for non-rotating stars shows that the maximum mass difference between\ndifferentially rotating and static stars is independent of the underlying\nparticle composition of the star. We further find that the decrease in the\nradii and increase in the maximum masses of stellar models when\n$\\Delta$-isobars are added to hyperonuclear matter (as initially observed for\nstatic and uniformly rotating stars) persist also in the case of differentially\nrotating neutron stars.",
            "author": [
                "Delaney Farrell",
                "Fridolin Weber",
                "Jia Jie Li",
                "Armen Sedrakian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09158v1",
                "http://arxiv.org/pdf/2311.09158v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09156v1",
            "title": "Radiative Asymptotic Symmetries of 3D Einstein-Maxwell Theory",
            "updated": "2023-11-15T17:55:20Z",
            "published": "2023-11-15T17:55:20Z",
            "summary": "We study the null asymptotic structure of Einstein-Maxwell theory in\nthree-dimensional (3D) spacetimes. Although devoid of bulk gravitational\ndegrees of freedom, the system admits a massless photon and can therefore\naccommodate electromagnetic radiation. We derive fall-off conditions for the\nMaxwell field that contain both Coulombic and radiative modes with\nnon-vanishing news. The latter produces non-integrability and fluxes in the\nasymptotic surface charges, and gives rise to a non-trivial 3D Bondi mass loss\nformula. The resulting solution space is thus analogous to a dimensional\nreduction of 4D pure gravity, with the role of gravitational radiation played\nby its electromagnetic cousin. We use this simplified setup to investigate\nchoices of charge brackets in detail, and compute in particular the recently\nintroduced Koszul bracket. When the latter is applied to Wald-Zoupas charges,\nwhich are conserved in the absence of news, it leads to the field-dependent\ncentral extension found earlier in [arXiv:1503.00856]. We also consider\n(Anti-)de Sitter asymptotics to further exhibit the analogy between this model\nand 4D gravity with leaky boundary conditions.",
            "author": [
                "Jorrit Bosma",
                "Marc Geiller",
                "Sucheta Majumdar",
                "Blagoje Oblak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09156v1",
                "http://arxiv.org/pdf/2311.09156v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09154v1",
            "title": "CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models",
            "updated": "2023-11-15T17:50:30Z",
            "published": "2023-11-15T17:50:30Z",
            "summary": "We are currently in an era of fierce competition among various large language\nmodels (LLMs) continuously pushing the boundaries of benchmark performance.\nHowever, genuinely assessing the capabilities of these LLMs has become a\nchallenging and critical issue due to potential data contamination, and it\nwastes dozens of time and effort for researchers and engineers to download and\ntry those contaminated models. To save our precious time, we propose a novel\nand useful method, Clean-Eval, which mitigates the issue of data contamination\nand evaluates the LLMs in a cleaner manner. Clean-Eval employs an LLM to\nparaphrase and back-translate the contaminated data into a candidate set,\ngenerating expressions with the same meaning but in different surface forms. A\nsemantic detector is then used to filter the generated low-quality samples to\nnarrow down this candidate set. The best candidate is finally selected from\nthis set based on the BLEURT score. According to human assessment, this best\ncandidate is semantically similar to the original contamination data but\nexpressed differently. All candidates can form a new benchmark to evaluate the\nmodel. Our experiments illustrate that Clean-Eval substantially restores the\nactual evaluation results on contaminated LLMs under both few-shot learning and\nfine-tuning scenarios.",
            "author": [
                "Wenhong Zhu",
                "Hongkun Hao",
                "Zhiwei He",
                "Yunze Song",
                "Yumeng Zhang",
                "Hanxu Hu",
                "Yiran Wei",
                "Rui Wang",
                "Hongyuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09154v1",
                "http://arxiv.org/pdf/2311.09154v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09149v1",
            "title": "Temporal Knowledge Question Answering via Abstract Reasoning Induction",
            "updated": "2023-11-15T17:46:39Z",
            "published": "2023-11-15T17:46:39Z",
            "summary": "In this paper, we tackle the significant challenge of temporal knowledge\nreasoning in Large Language Models (LLMs), an area where such models frequently\nencounter difficulties. These difficulties often result in the generation of\nmisleading or incorrect information, primarily due to their limited capacity to\nprocess evolving factual knowledge and complex temporal logic. In response, we\npropose a novel, constructivism-based approach that advocates for a paradigm\nshift in LLM learning towards an active, ongoing process of knowledge synthesis\nand customization. At the heart of our proposal is the Abstract Reasoning\nInduction ARI framework, which divides temporal reasoning into two distinct\nphases: Knowledge-agnostic and Knowledge-based. This division aims to reduce\ninstances of hallucinations and improve LLMs' capacity for integrating abstract\nmethodologies derived from historical data. Our approach achieves remarkable\nimprovements, with relative gains of 29.7\\% and 9.27\\% on two temporal QA\ndatasets, underscoring its efficacy in advancing temporal reasoning in LLMs.\nThe code will be released at https://github.com/czy1999/ARI.",
            "author": [
                "Ziyang Chen",
                "Dongfang Li",
                "Xiang Zhao",
                "Baotian Hu",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09149v1",
                "http://arxiv.org/pdf/2311.09149v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09148v1",
            "title": "Predicting risk/reward ratio in financial markets for asset management\n  using machine learning",
            "updated": "2023-11-15T17:45:02Z",
            "published": "2023-11-15T17:45:02Z",
            "summary": "Financial market forecasting remains a formidable challenge despite the surge\nin computational capabilities and machine learning advancements. While numerous\nstudies have underscored the precision of computer-generated market\npredictions, many of these forecasts fail to yield profitable trading outcomes.\nThis discrepancy often arises from the unpredictable nature of profit and loss\nratios in the event of successful and unsuccessful predictions. In this study,\nwe introduce a novel algorithm specifically designed for forecasting the profit\nand loss outcomes of trading activities. This is further augmented by an\ninnovative approach for integrating these forecasts with previous predictions\nof market trends. This approach is designed for algorithmic trading, enabling\ntraders to assess the profitability of each trade and calibrate the optimal\ntrade size. Our findings indicate that this method significantly improves the\nperformance of traditional trading strategies as well as algorithmic trading\nsystems, offering a promising avenue for enhancing trading decisions.",
            "author": [
                "Reza Yarbakhsh",
                "Mahdieh Soleymani Baghshah",
                "Hamidreza Karimaghaie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09148v1",
                "http://arxiv.org/pdf/2311.09148v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "q-fin.RM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09144v1",
            "title": "Grounding or Guesswork? Large Language Models are Presumptive Grounders",
            "updated": "2023-11-15T17:40:27Z",
            "published": "2023-11-15T17:40:27Z",
            "summary": "Effective conversation requires common ground: a shared understanding between\nthe participants. Common ground, however, does not emerge spontaneously in\nconversation. Speakers and listeners work together to both identify and\nconstruct a shared basis while avoiding misunderstanding. To accomplish\ngrounding, humans rely on a range of dialogue acts, like clarification (What do\nyou mean?) and acknowledgment (I understand.). In domains like teaching and\nemotional support, carefully constructing grounding prevents misunderstanding.\nHowever, it is unclear whether large language models (LLMs) leverage these\ndialogue acts in constructing common ground. To this end, we curate a set of\ngrounding acts and propose corresponding metrics that quantify attempted\ngrounding. We study whether LLMs use these grounding acts, simulating them\ntaking turns from several dialogue datasets, and comparing the results to\nhumans. We find that current LLMs are presumptive grounders, biased towards\nassuming common ground without using grounding acts. To understand the roots of\nthis behavior, we examine the role of instruction tuning and reinforcement\nlearning with human feedback (RLHF), finding that RLHF leads to less grounding.\nAltogether, our work highlights the need for more research investigating\ngrounding in human-AI interaction.",
            "author": [
                "Omar Shaikh",
                "Kristina Gligori\u0107",
                "Ashna Khetan",
                "Matthias Gerstgrasser",
                "Diyi Yang",
                "Dan Jurafsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09144v1",
                "http://arxiv.org/pdf/2311.09144v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09142v1",
            "title": "Machine-learning parameter tracking with partial state observation",
            "updated": "2023-11-15T17:39:25Z",
            "published": "2023-11-15T17:39:25Z",
            "summary": "Complex and nonlinear dynamical systems often involve parameters that change\nwith time, accurate tracking of which is essential to tasks such as state\nestimation, prediction, and control. Existing machine-learning methods require\nfull state observation of the underlying system and tacitly assume adiabatic\nchanges in the parameter. Formulating an inverse problem and exploiting\nreservoir computing, we develop a model-free and fully data-driven framework to\naccurately track time-varying parameters from partial state observation in real\ntime. In particular, with training data from a subset of the dynamical\nvariables of the system for a small number of known parameter values, the\nframework is able to accurately predict the parameter variations in time. Low-\nand high-dimensional, Markovian and non-Markovian nonlinear dynamical systems\nare used to demonstrate the power of the machine-learning based\nparameter-tracking framework. Pertinent issues affecting the tracking\nperformance are addressed.",
            "author": [
                "Zheng-Meng Zhai",
                "Mohammadamin Moradi",
                "Bryan Glaz",
                "Mulugeta Haile",
                "Ying-Cheng Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09142v1",
                "http://arxiv.org/pdf/2311.09142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DS",
                "nlin.CD",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09136v1",
            "title": "RRescue: Ranking LLM Responses to Enhance Reasoning Over Context",
            "updated": "2023-11-15T17:27:14Z",
            "published": "2023-11-15T17:27:14Z",
            "summary": "Effectively using a given context is paramount for large language models. A\ncontext window can include task specifications, retrieved documents, previous\nconversations, and even model self-reflections, functioning similarly to\nepisodic memory. While efforts are being made to expand the context window,\nstudies indicate that LLMs do not use their context optimally for response\ngeneration. In this paper, we present a novel approach to optimize LLMs using\nranking metrics, which teaches LLMs to rank a collection of\ncontextually-grounded candidate responses. Rather than a traditional full\nordering, we advocate for a partial ordering. This is because achieving\nconsensus on the perfect order for system responses can be challenging. Our\npartial ordering is more robust, less sensitive to noise, and can be acquired\nthrough human labelers, heuristic functions, or model distillation. We test our\nsystem's improved contextual understanding using the latest benchmarks,\nincluding a new multi-document question answering dataset. We conduct ablation\nstudies to understand crucial factors, such as how to gather candidate\nresponses, determine their most suitable order, and balance supervised\nfine-tuning with ranking metrics. Our approach, named RRescue, suggests a\npromising avenue for enhancing LLMs' contextual understanding via response\nranking.",
            "author": [
                "Yikun Wang",
                "Rui Zheng",
                "Haoming Li",
                "Qi Zhang",
                "Tao Gui",
                "Fei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09136v1",
                "http://arxiv.org/pdf/2311.09136v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09132v1",
            "title": "Aligning Neural Machine Translation Models: Human Feedback in Training\n  and Inference",
            "updated": "2023-11-15T17:21:58Z",
            "published": "2023-11-15T17:21:58Z",
            "summary": "Reinforcement learning from human feedback (RLHF) is a recent technique to\nimprove the quality of the text generated by a language model, making it closer\nto what humans would generate. A core ingredient in RLHF's success in aligning\nand improving large language models (LLMs) is its reward model, trained using\nhuman feedback on model outputs. In machine translation (MT), where metrics\ntrained from human annotations can readily be used as reward models, recent\nmethods using minimum Bayes risk decoding and reranking have succeeded in\nimproving the final quality of translation. In this study, we comprehensively\nexplore and compare techniques for integrating quality metrics as reward models\ninto the MT pipeline. This includes using the reward model for data filtering,\nduring the training phase through RL, and at inference time by employing\nreranking techniques, and we assess the effects of combining these in a unified\napproach. Our experimental results, conducted across multiple translation\ntasks, underscore the crucial role of effective data filtering, based on\nestimated quality, in harnessing the full potential of RL in enhancing MT\nquality. Furthermore, our findings demonstrate the effectiveness of combining\nRL training with reranking techniques, showcasing substantial improvements in\ntranslation quality.",
            "author": [
                "Miguel Moura Ramos",
                "Patrick Fernandes",
                "Ant\u00f3nio Farinhas",
                "Andr\u00e9 F. T. Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09132v1",
                "http://arxiv.org/pdf/2311.09132v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09130v1",
            "title": "Social Meme-ing: Measuring Linguistic Variation in Memes",
            "updated": "2023-11-15T17:20:20Z",
            "published": "2023-11-15T17:20:20Z",
            "summary": "Much work in the space of NLP has used computational methods to explore\nsociolinguistic variation in text. In this paper, we argue that memes, as\nmultimodal forms of language comprised of visual templates and text, also\nexhibit meaningful social variation. We construct a computational pipeline to\ncluster individual instances of memes into templates and semantic variables,\ntaking advantage of their multimodal structure in doing so. We apply this\nmethod to a large collection of meme images from Reddit and make available the\nresulting \\textsc{SemanticMemes} dataset of 3.8M images clustered by their\nsemantic function. We use these clusters to analyze linguistic variation in\nmemes, discovering not only that socially meaningful variation in meme usage\nexists between subreddits, but that patterns of meme innovation and\nacculturation within these communities align with previous findings on written\nlanguage.",
            "author": [
                "Naitian Zhou",
                "David Jurgens",
                "David Bamman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09130v1",
                "http://arxiv.org/pdf/2311.09130v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09128v1",
            "title": "Fast Detection of Phase Transitions with Multi-Task\n  Learning-by-Confusion",
            "updated": "2023-11-15T17:17:49Z",
            "published": "2023-11-15T17:17:49Z",
            "summary": "Machine learning has been successfully used to study phase transitions. One\nof the most popular approaches to identifying critical points from data without\nprior knowledge of the underlying phases is the learning-by-confusion scheme.\nAs input, it requires system samples drawn from a grid of the parameter whose\nchange is associated with potential phase transitions. Up to now, the scheme\nrequired training a distinct binary classifier for each possible splitting of\nthe grid into two sides, resulting in a computational cost that scales linearly\nwith the number of grid points. In this work, we propose and showcase an\nalternative implementation that only requires the training of a single\nmulti-class classifier. Ideally, such multi-task learning eliminates the\nscaling with respect to the number of grid points. In applications to the Ising\nmodel and an image dataset generated with Stable Diffusion, we find significant\nspeedups that closely correspond to the ideal case, with only minor deviations.",
            "author": [
                "Julian Arnold",
                "Frank Sch\u00e4fer",
                "Niels L\u00f6rch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09128v1",
                "http://arxiv.org/pdf/2311.09128v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09122v1",
            "title": "Universal NER: A Gold-Standard Multilingual Named Entity Recognition\n  Benchmark",
            "updated": "2023-11-15T17:09:54Z",
            "published": "2023-11-15T17:09:54Z",
            "summary": "We introduce Universal NER (UNER), an open, community-driven project to\ndevelop gold-standard NER benchmarks in many languages. The overarching goal of\nUNER is to provide high-quality, cross-lingually consistent annotations to\nfacilitate and standardize multilingual NER research. UNER v1 contains 18\ndatasets annotated with named entities in a cross-lingual consistent schema\nacross 12 diverse languages. In this paper, we detail the dataset creation and\ncomposition of UNER; we also provide initial modeling baselines on both\nin-language and cross-lingual learning settings. We release the data, code, and\nfitted models to the public.",
            "author": [
                "Stephen Mayhew",
                "Terra Blevins",
                "Shuheng Liu",
                "Marek \u0160uppa",
                "Hila Gonen",
                "Joseph Marvin Imperial",
                "B\u00f6rje F. Karlsson",
                "Peiqin Lin",
                "Nikola Ljube\u0161i\u0107",
                "LJ Miranda",
                "Barbara Plank",
                "Arij Riabi",
                "Yuval Pinter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09122v1",
                "http://arxiv.org/pdf/2311.09122v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09118v1",
            "title": "WildlifeDatasets: An open-source toolkit for animal re-identification",
            "updated": "2023-11-15T17:08:09Z",
            "published": "2023-11-15T17:08:09Z",
            "summary": "In this paper, we present WildlifeDatasets\n(https://github.com/WildlifeDatasets/wildlife-datasets) - an open-source\ntoolkit intended primarily for ecologists and computer-vision /\nmachine-learning researchers. The WildlifeDatasets is written in Python, allows\nstraightforward access to publicly available wildlife datasets, and provides a\nwide variety of methods for dataset pre-processing, performance analysis, and\nmodel fine-tuning. We showcase the toolkit in various scenarios and baseline\nexperiments, including, to the best of our knowledge, the most comprehensive\nexperimental comparison of datasets and methods for wildlife re-identification,\nincluding both local descriptors and deep learning approaches. Furthermore, we\nprovide the first-ever foundation model for individual re-identification within\na wide range of species - MegaDescriptor - that provides state-of-the-art\nperformance on animal re-identification datasets and outperforms other\npre-trained models such as CLIP and DINOv2 by a significant margin. To make the\nmodel available to the general public and to allow easy integration with any\nexisting wildlife monitoring applications, we provide multiple MegaDescriptor\nflavors (i.e., Small, Medium, and Large) through the HuggingFace hub\n(https://huggingface.co/BVRA).",
            "author": [
                "Vojt\u011bch \u010cerm\u00e1k",
                "Lukas Picek",
                "Luk\u00e1\u0161 Adam",
                "Kostas Papafitsoros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09118v1",
                "http://arxiv.org/pdf/2311.09118v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09117v1",
            "title": "R-Spin: Efficient Speaker and Noise-invariant Representation Learning\n  with Acoustic Pieces",
            "updated": "2023-11-15T17:07:44Z",
            "published": "2023-11-15T17:07:44Z",
            "summary": "This paper introduces Robust Spin (R-Spin), a data-efficient self-supervised\nfine-tuning framework for speaker and noise-invariant speech representations by\nlearning discrete acoustic units with speaker-invariant clustering (Spin).\nR-Spin resolves Spin's issues and enhances content representations by learning\nto predict acoustic pieces. R-Spin offers a 12X reduction in computational\nresources compared to previous state-of-the-art methods while outperforming\nthem in severely distorted speech scenarios. This paper provides detailed\nanalyses to show how discrete units contribute to speech encoder training and\nimproving robustness in diverse acoustic environments.",
            "author": [
                "Heng-Jui Chang",
                "James Glass"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09117v1",
                "http://arxiv.org/pdf/2311.09117v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09114v1",
            "title": "Ever: Mitigating Hallucination in Large Language Models through\n  Real-Time Verification and Rectification",
            "updated": "2023-11-15T17:04:56Z",
            "published": "2023-11-15T17:04:56Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\ngenerating fluent text. However, they often encounter the challenge of\ngenerating inaccurate or hallucinated content. This issue is common in both\nnon-retrieval-based generation and retrieval-augmented generation approaches,\nand existing post-hoc rectification methods may not address the accumulated\nhallucination errors that may be caused by the \"snowballing\" issue, especially\nin reasoning tasks. To tackle these challenges, we introduce a novel approach\ncalled Real-time Verification and Rectification (Ever). Instead of waiting\nuntil the end of the generation process to rectify hallucinations, Ever employs\na real-time, step-wise generation and hallucination rectification strategy. The\nprimary objective is to detect and rectify hallucinations as they occur during\nthe text generation process. When compared to both retrieval-based and\nnon-retrieval-based baselines, Ever demonstrates a significant improvement in\ngenerating trustworthy and factually accurate text across a diverse range of\ntasks, including short-form QA, biography generation, and multi-hop reasoning.",
            "author": [
                "Haoqiang Kang",
                "Juntong Ni",
                "Huaxiu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09114v1",
                "http://arxiv.org/pdf/2311.09114v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09109v1",
            "title": "Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge\n  Graph Completion?",
            "updated": "2023-11-15T16:56:49Z",
            "published": "2023-11-15T16:56:49Z",
            "summary": "Knowledge graphs (KGs) consist of links that describe relationships between\nentities. Due to the difficulty of manually enumerating all relationships\nbetween entities, automatically completing them is essential for KGs. Knowledge\nGraph Completion (KGC) is a task that infers unseen relationships between\nentities in a KG. Traditional embedding-based KGC methods, such as RESCAL,\nTransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc., infer missing links using\nonly the knowledge from training data. In contrast, the recent Pre-trained\nLanguage Model (PLM)-based KGC utilizes knowledge obtained during pre-training.\nTherefore, PLM-based KGC can estimate missing links between entities by reusing\nmemorized knowledge from pre-training without inference. This approach is\nproblematic because building KGC models aims to infer unseen links between\nentities. However, conventional evaluations in KGC do not consider inference\nand memorization abilities separately. Thus, a PLM-based KGC method, which\nachieves high performance in current KGC evaluations, may be ineffective in\npractical applications. To address this issue, we analyze whether PLM-based KGC\nmethods make inferences or merely access memorized knowledge. For this purpose,\nwe propose a method for constructing synthetic datasets specified in this\nanalysis and conclude that PLMs acquire the inference abilities required for\nKGC through pre-training, even though the performance improvements mostly come\nfrom textual information of entities and relations.",
            "author": [
                "Yusuke Sakai",
                "Hidetaka Kamigaito",
                "Katsuhiko Hayashi",
                "Taro Watanabe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09109v1",
                "http://arxiv.org/pdf/2311.09109v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09106v1",
            "title": "\"We Demand Justice!\": Towards Grounding Political Text in Social Context",
            "updated": "2023-11-15T16:53:35Z",
            "published": "2023-11-15T16:53:35Z",
            "summary": "Social media discourse from US politicians frequently consists of 'seemingly\nsimilar language used by opposing sides of the political spectrum'. But often,\nit translates to starkly contrasting real-world actions. For instance, \"We need\nto keep our students safe from mass shootings\" may signal either \"arming\nteachers to stop the shooter\" or \"banning guns to reduce mass shootings\"\ndepending on who says it and their political stance on the issue. In this\npaper, we define and characterize the context that is required to fully\nunderstand such ambiguous statements in a computational setting and ground them\nin real-world entities, actions, and attitudes. To that end, we propose two\nchallenging datasets that require an understanding of the real-world context of\nthe text to be solved effectively. We benchmark these datasets against\nbaselines built upon large pre-trained models such as BERT, RoBERTa, GPT-3,\netc. Additionally, we develop and benchmark more structured baselines building\nupon existing 'Discourse Contextualization Framework' and 'Political Actor\nRepresentation' models. We perform analysis of the datasets and baseline\npredictions to obtain further insights into the pragmatic language\nunderstanding challenges posed by the proposed social grounding tasks.",
            "author": [
                "Rajkumar Pujari",
                "Chengfei Wu",
                "Dan Goldwasser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09106v1",
                "http://arxiv.org/pdf/2311.09106v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09105v1",
            "title": "MAVEN-Arg: Completing the Puzzle of All-in-One Event Understanding\n  Dataset with Event Argument Annotation",
            "updated": "2023-11-15T16:52:14Z",
            "published": "2023-11-15T16:52:14Z",
            "summary": "Understanding events in texts is a core objective of natural language\nunderstanding, which requires detecting event occurrences, extracting event\narguments, and analyzing inter-event relationships. However, due to the\nannotation challenges brought by task complexity, a large-scale dataset\ncovering the full process of event understanding has long been absent. In this\npaper, we introduce MAVEN-Arg, which augments MAVEN datasets with event\nargument annotations, making the first all-in-one dataset supporting event\ndetection, event argument extraction (EAE), and event relation extraction. As\nan EAE benchmark, MAVEN-Arg offers three main advantages: (1) a comprehensive\nschema covering 162 event types and 612 argument roles, all with expert-written\ndefinitions and examples; (2) a large data scale, containing 98,591 events and\n290,613 arguments obtained with laborious human annotation; (3) the exhaustive\nannotation supporting all task variants of EAE, which annotates both entity and\nnon-entity event arguments in document level. Experiments indicate that\nMAVEN-Arg is quite challenging for both fine-tuned EAE models and proprietary\nlarge language models (LLMs). Furthermore, to demonstrate the benefits of an\nall-in-one dataset, we preliminarily explore a potential application, future\nevent prediction, with LLMs. MAVEN-Arg and our code can be obtained from\nhttps://github.com/THU-KEG/MAVEN-Argument.",
            "author": [
                "Xiaozhi Wang",
                "Hao Peng",
                "Yong Guan",
                "Kaisheng Zeng",
                "Jianhui Chen",
                "Lei Hou",
                "Xu Han",
                "Yankai Lin",
                "Zhiyuan Liu",
                "Ruobing Xie",
                "Jie Zhou",
                "Juanzi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09105v1",
                "http://arxiv.org/pdf/2311.09105v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09104v1",
            "title": "Cross-view and Cross-pose Completion for 3D Human Understanding",
            "updated": "2023-11-15T16:51:18Z",
            "published": "2023-11-15T16:51:18Z",
            "summary": "Human perception and understanding is a major domain of computer vision\nwhich, like many other vision subdomains recently, stands to gain from the use\nof large models pre-trained on large datasets. We hypothesize that the most\ncommon pre-training strategy of relying on general purpose, object-centric\nimage datasets such as ImageNet, is limited by an important domain shift. On\nthe other hand, collecting domain specific ground truth such as 2D or 3D labels\ndoes not scale well. Therefore, we propose a pre-training approach based on\nself-supervised learning that works on human-centric data using only images.\nOur method uses pairs of images of humans: the first is partially masked and\nthe model is trained to reconstruct the masked parts given the visible ones and\na second image. It relies on both stereoscopic (cross-view) pairs, and temporal\n(cross-pose) pairs taken from videos, in order to learn priors about 3D as well\nas human motion. We pre-train a model for body-centric tasks and one for\nhand-centric tasks. With a generic transformer architecture, these models\noutperform existing self-supervised pre-training methods on a wide set of\nhuman-centric downstream tasks, and obtain state-of-the-art performance for\ninstance when fine-tuning for model-based and model-free human mesh recovery.",
            "author": [
                "Matthieu Armando",
                "Salma Galaaoui",
                "Fabien Baradel",
                "Thomas Lucas",
                "Vincent Leroy",
                "Romain Br\u00e9gier",
                "Philippe Weinzaepfel",
                "Gr\u00e9gory Rogez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09104v1",
                "http://arxiv.org/pdf/2311.09104v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09103v1",
            "title": "Guided Scale Space Radon Transform for linear structures detection",
            "updated": "2023-11-15T16:50:01Z",
            "published": "2023-11-15T16:50:01Z",
            "summary": "Using integral transforms to the end of lines detection in images with\ncomplex background, makes the detection a hard task needing additional\nprocessing to manage the detection. As an integral transform, the Scale Space\nRadon Transform (SSRT) suffers from such drawbacks, even with its great\nabilities for thick lines detection. In this work, we propose a method to\naddress this issue for automatic detection of thick linear structures in gray\nscale and binary images using the SSRT, whatever the image background content.\nThis method involves the calculated Hessian orientations of the investigated\nimage while computing its SSRT, in such a way that linear structures are\nemphasized in the SSRT space. As a consequence, the subsequent maxima detection\nin the SSRT space is done on a modified transform space freed from unwanted\nparts and, consequently, from irrelevant peaks that usually drown the peaks\nrepresenting lines. Besides, highlighting the linear structure in the SSRT\nspace permitting, thus, to efficiently detect lines of different thickness in\nsynthetic and real images, the experiments show also the method robustness\nagainst noise and complex background.",
            "author": [
                "Aicha Baya Goumeidane",
                "Djemel Ziou",
                "Nafaa Nacereddine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09103v1",
                "http://arxiv.org/pdf/2311.09103v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09101v1",
            "title": "Towards A Unified View of Answer Calibration for Multi-Step Reasoning",
            "updated": "2023-11-15T16:47:57Z",
            "published": "2023-11-15T16:47:57Z",
            "summary": "Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have\nbroadened the scope for improving multi-step reasoning capabilities. Usually,\nanswer calibration strategies such as step-level or path-level calibration play\na vital role in multi-step reasoning. While effective, there remains a\nsignificant gap in our understanding of the key factors that drive their\nsuccess. In this paper, we break down the design of recent answer calibration\nstrategies and present a unified view which establishes connections between\nthem. We then conduct a thorough evaluation on these strategies from a unified\nview, systematically scrutinizing step-level and path-level answer calibration\nacross multiple paths. Our study holds the potential to illuminate key insights\nfor optimizing multi-step reasoning with answer calibration.",
            "author": [
                "Shumin Deng",
                "Ningyu Zhang",
                "Nay Oo",
                "Bryan Hooi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09101v1",
                "http://arxiv.org/pdf/2311.09101v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09096v1",
            "title": "Defending Large Language Models Against Jailbreaking Attacks Through\n  Goal Prioritization",
            "updated": "2023-11-15T16:42:29Z",
            "published": "2023-11-15T16:42:29Z",
            "summary": "Large Language Models (LLMs) continue to advance in their capabilities, yet\nthis progress is accompanied by a growing array of safety risks. While\nsignificant attention has been dedicated to exploiting weaknesses in LLMs\nthrough jailbreaking attacks, there remains a paucity of exploration into\ndefending against these attacks. We point out a pivotal factor contributing to\nthe success of jailbreaks: the inherent conflict between the goals of being\nhelpful and ensuring safety. To counter jailbreaking attacks, we propose to\nintegrate goal prioritization at both training and inference stages.\nImplementing goal prioritization during inference substantially diminishes the\nAttack Success Rate (ASR) of jailbreaking attacks, reducing it from 66.4% to\n2.0% for ChatGPT and from 68.2% to 19.4% for Vicuna-33B, without compromising\ngeneral performance. Furthermore, integrating the concept of goal\nprioritization into the training phase reduces the ASR from 71.0% to 6.6% for\nLLama2-13B. Remarkably, even in scenarios where no jailbreaking samples are\nincluded during training, our approach slashes the ASR by half, decreasing it\nfrom 71.0% to 34.0%. Additionally, our findings reveal that while stronger LLMs\nface greater safety risks, they also possess a greater capacity to be steered\ntowards defending against such attacks. We hope our work could contribute to\nthe comprehension of jailbreaking attacks and defenses, and shed light on the\nrelationship between LLMs' capability and safety. Our code will be available at\n\\url{https://github.com/thu-coai/JailbreakDefense_GoalPriority}.",
            "author": [
                "Zhexin Zhang",
                "Junxiao Yang",
                "Pei Ke",
                "Minlie Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09096v1",
                "http://arxiv.org/pdf/2311.09096v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09093v2",
            "title": "Applications of Computer Vision in Autonomous Vehicles: Methods,\n  Challenges and Future Directions",
            "updated": "2023-11-16T04:12:51Z",
            "published": "2023-11-15T16:41:18Z",
            "summary": "Autonomous vehicle refers to a vehicle capable of perceiving its surrounding\nenvironment and driving with little or no human driver input. The perception\nsystem is a fundamental component which enables the autonomous vehicle to\ncollect data and extract relevant information from the environment to drive\nsafely. Benefit from the recent advances in computer vision, the perception\ntask can be achieved by using sensors, such as camera, LiDAR, radar, and\nultrasonic sensor. This paper reviews publications on computer vision and\nautonomous driving that are published during the last ten years. In particular,\nwe first investigate the development of autonomous driving systems and\nsummarize these systems that are developed by the major automotive\nmanufacturers from different countries. Second, we investigate the sensors and\nbenchmark data sets that are commonly utilized for autonomous driving. Then, a\ncomprehensive overview of computer vision applications for autonomous driving\nsuch as depth estimation, object detection, lane detection, and traffic sign\nrecognition are discussed. Additionally, we review public opinions and concerns\non autonomous vehicles. Based on the discussion, we analyze the current\ntechnological challenges that autonomous vehicles meet with. Finally, we\npresent our insights and point out some promising directions for future\nresearch. This paper will help the reader to understand autonomous vehicles\nfrom the perspectives of academia and industry.",
            "author": [
                "Xingshuai Dong",
                "Massimiliano L. Cappuccio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09093v2",
                "http://arxiv.org/pdf/2311.09093v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09090v1",
            "title": "Social Bias Probing: Fairness Benchmarking for Language Models",
            "updated": "2023-11-15T16:35:59Z",
            "published": "2023-11-15T16:35:59Z",
            "summary": "Large language models have been shown to encode a variety of social biases,\nwhich carries the risk of downstream harms. While the impact of these biases\nhas been recognized, prior methods for bias evaluation have been limited to\nbinary association tests on small datasets, offering a constrained view of the\nnature of societal biases within language models. In this paper, we propose an\noriginal framework for probing language models for societal biases. We collect\na probing dataset to analyze language models' general associations, as well as\nalong the axes of societal categories, identities, and stereotypes. To this\nend, we leverage a novel perplexity-based fairness score. We curate a\nlarge-scale benchmarking dataset addressing drawbacks and limitations of\nexisting fairness collections, expanding to a variety of different identities\nand stereotypes. When comparing our methodology with prior work, we demonstrate\nthat biases within language models are more nuanced than previously\nacknowledged. In agreement with recent findings, we find that larger model\nvariants exhibit a higher degree of bias. Moreover, we expose how identities\nexpressing different religions lead to the most pronounced disparate treatments\nacross all models.",
            "author": [
                "Marta Marchiori Manerba",
                "Karolina Sta\u0144czak",
                "Riccardo Guidotti",
                "Isabelle Augenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09090v1",
                "http://arxiv.org/pdf/2311.09090v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09089v1",
            "title": "On the mass and wind luminosity of young Galactic open clusters in Gaia\n  DR2",
            "updated": "2023-11-15T16:34:12Z",
            "published": "2023-11-15T16:34:12Z",
            "summary": "Context. Star clusters constitute a relevant part of the stellar population\nin our Galaxy. The feedback processes they exert on the interstellar medium\nimpact multiple physical processes, from the chemical to the dynamical\nevolution of the Galaxy. In addition, young and massive stellar clusters might\nact as efficient particle accelerators, possibly contributing to the production\nof cosmic rays. Aims. We aim at evaluating the wind luminosity driven by the\nyoung (< 30 Myr) Galactic open stellar clusters observed by the Gaia space\nmission, which is crucial to determine the energy channeled into accelerated\nparticles. Methods. To this extent, we develop a method relying on the number,\nmagnitude and line-of-sight extinction of the stars observed per cluster.\nAssuming that the stellar mass function follows a Kroupa mass distribution, and\naccounting for the maximum stellar mass allowed by both the parent cluster age\nand mass, we conservatively estimate the mass and wind luminosity of 387 local\nclusters within the second data release of Gaia. Results. We compare the\nresults of our computation with recent estimations of young cluster masses.\nWith respect to these, we provide a sample three times more abundant,\nparticularly above a few thousand solar masses, which is of the utmost\nrelevance for predicting the gamma-ray emission resulting from the interaction\nof accelerated particles. In fact, the cluster wind luminosity distribution we\nobtain is found to extend up to 3 x 10^38 erg/s, a promising feature in terms\nof potential particle acceleration scenarios.",
            "author": [
                "Silvia Celli",
                "Andreas Specovius",
                "Stefano Menchiari",
                "Alison Mitchell",
                "Giovanni Morlino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09089v1",
                "http://arxiv.org/pdf/2311.09089v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09086v1",
            "title": "The Uli Dataset: An Exercise in Experience Led Annotation of oGBV",
            "updated": "2023-11-15T16:30:44Z",
            "published": "2023-11-15T16:30:44Z",
            "summary": "Online gender based violence has grown concomitantly with adoption of the\ninternet and social media. Its effects are worse in the Global majority where\nmany users use social media in languages other than English. The scale and\nvolume of conversations on the internet has necessitated the need for automated\ndetection of hate speech, and more specifically gendered abuse. There is,\nhowever, a lack of language specific and contextual data to build such\nautomated tools. In this paper we present a dataset on gendered abuse in three\nlanguages- Hindi, Tamil and Indian English. The dataset comprises of tweets\nannotated along three questions pertaining to the experience of gender abuse,\nby experts who identify as women or a member of the LGBTQIA community in South\nAsia. Through this dataset we demonstrate a participatory approach to creating\ndatasets that drive AI systems.",
            "author": [
                "Arnav Arora",
                "Maha Jinadoss",
                "Cheshta Arora",
                "Denny George",
                "Brindaalakshmi",
                "Haseena Dawood Khan",
                "Kirti Rawat",
                "Div",
                "Ritash",
                "Seema Mathur",
                "Shivani Yadav",
                "Shehla Rashid Shora",
                "Rie Raut",
                "Sumit Pawar",
                "Apurva Paithane",
                "Sonia",
                "Vivek",
                "Dharini Priscilla",
                "Khairunnisha",
                "Grace Banu",
                "Ambika Tandon",
                "Rishav Thakker",
                "Rahul Dev Korra",
                "Aatman Vaidya",
                "Tarunima Prabhakar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09086v1",
                "http://arxiv.org/pdf/2311.09086v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09084v1",
            "title": "Contrastive Transformer Learning with Proximity Data Generation for\n  Text-Based Person Search",
            "updated": "2023-11-15T16:26:49Z",
            "published": "2023-11-15T16:26:49Z",
            "summary": "Given a descriptive text query, text-based person search (TBPS) aims to\nretrieve the best-matched target person from an image gallery. Such a\ncross-modal retrieval task is quite challenging due to significant modality\ngap, fine-grained differences and insufficiency of annotated data. To better\nalign the two modalities, most existing works focus on introducing\nsophisticated network structures and auxiliary tasks, which are complex and\nhard to implement. In this paper, we propose a simple yet effective dual\nTransformer model for text-based person search. By exploiting a hardness-aware\ncontrastive learning strategy, our model achieves state-of-the-art performance\nwithout any special design for local feature alignment or side information.\nMoreover, we propose a proximity data generation (PDG) module to automatically\nproduce more diverse data for cross-modal training. The PDG module first\nintroduces an automatic generation algorithm based on a text-to-image diffusion\nmodel, which generates new text-image pair samples in the proximity space of\noriginal ones. Then it combines approximate text generation and feature-level\nmixup during training to further strengthen the data diversity. The PDG module\ncan largely guarantee the reasonability of the generated samples that are\ndirectly used for training without any human inspection for noise rejection. It\nimproves the performance of our model significantly, providing a feasible\nsolution to the data insufficiency problem faced by such fine-grained\nvisual-linguistic tasks. Extensive experiments on two popular datasets of the\nTBPS task (i.e., CUHK-PEDES and ICFG-PEDES) show that the proposed approach\noutperforms state-of-the-art approaches evidently, e.g., improving by 3.88%,\n4.02%, 2.92% in terms of Top1, Top5, Top10 on CUHK-PEDES. The codes will be\navailable at https://github.com/HCPLab-SYSU/PersonSearch-CTLG",
            "author": [
                "Hefeng Wu",
                "Weifeng Chen",
                "Zhibin Liu",
                "Tianshui Chen",
                "Zhiguang Chen",
                "Liang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09084v1",
                "http://arxiv.org/pdf/2311.09084v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09077v1",
            "title": "Spiking NeRF: Representing the Real-World Geometry by a Discontinuous\n  Representation",
            "updated": "2023-11-15T16:19:13Z",
            "published": "2023-11-15T16:19:13Z",
            "summary": "A crucial reason for the success of existing NeRF-based methods is to build a\nneural density field for the geometry representation via multiple perceptron\nlayers (MLPs). MLPs are continuous functions, however, real geometry or density\nfield is frequently discontinuous at the interface between the air and the\nsurface. Such a contrary brings the problem of unfaithful geometry\nrepresentation. To this end, this paper proposes spiking NeRF, which leverages\nspiking neuron and a hybrid Artificial Neural Network (ANN)-Spiking Neural\nNetwork (SNN) framework to build a discontinuous density field for faithful\ngeometry representation. Specifically, we first demonstrate the reason why\ncontinuous density fields will bring inaccuracy. Then, we propose to use the\nspiking neurons to build a discontinuous density field. We conduct\ncomprehensive analysis for the problem of existing spiking neuron models and\nthen provide the numerical relationship between the parameter of spiking neuron\nand the theoretical accuracy of geometry, Based on this, we propose a bounded\nspiking neuron to build the discontinuous density field. Our results achieve\nSOTA performance. Our code and data will be released to the public.",
            "author": [
                "Zhanfeng Liao",
                "Qian Zheng",
                "Yan Liu",
                "Gang Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09077v1",
                "http://arxiv.org/pdf/2311.09077v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09075v1",
            "title": "Self-stabilizing Byzantine Multivalued Consensus",
            "updated": "2023-11-15T16:18:17Z",
            "published": "2023-11-15T16:18:17Z",
            "summary": "Consensus, abstracting a myriad of problems in which processes have to agree\non a single value, is one of the most celebrated problems of fault-tolerant\ndistributed computing. Consensus applications include fundamental services for\nthe environments of the Cloud and Blockchain, and in such challenging\nenvironments, malicious behaviors are often modeled as adversarial Byzantine\nfaults.\n  At OPODIS 2010, Mostefaoui and Raynal (in short MR) presented a\nByzantine-tolerant solution to consensus in which the decided value cannot be a\nvalue proposed only by Byzantine processes. MR has optimal resilience coping\nwith up to t < n/3 Byzantine nodes over n processes. MR provides this\nmultivalued consensus object (which accepts proposals taken from a finite set\nof values) assuming the availability of a single Binary consensus object (which\naccepts proposals taken from the set {0,1}).\n  This work, which focuses on multivalued consensus, aims at the design of an\neven more robust solution than MR. Our proposal expands MR's fault-model with\nself-stabilization, a vigorous notion of fault-tolerance. In addition to\ntolerating Byzantine, self-stabilizing systems can automatically recover after\nthe occurrence of arbitrary transient-faults. These faults represent any\nviolation of the assumptions according to which the system was designed to\noperate (provided that the algorithm code remains intact).\n  To the best of our knowledge, we propose the first self-stabilizing solution\nfor intrusion-tolerant multivalued consensus for asynchronous message-passing\nsystems prone to Byzantine failures. Our solution has a O(t) stabilization time\nfrom arbitrary transient faults.",
            "author": [
                "Romaric Duvignau",
                "Michel Raynal",
                "Elad Michael Schiller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09075v1",
                "http://arxiv.org/pdf/2311.09075v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09071v1",
            "title": "How Multilingual is Multilingual LLM?",
            "updated": "2023-11-15T16:13:14Z",
            "published": "2023-11-15T16:13:14Z",
            "summary": "Large Language Models (LLMs), trained predominantly on extensive English\ndata, often exhibit limitations when applied to other languages. Current\nresearch is primarily focused on enhancing the multilingual capabilities of\nthese models by employing various tuning strategies. Despite their\neffectiveness in certain languages, the understanding of the multilingual\nabilities of LLMs remains incomplete. This study endeavors to evaluate the\nmultilingual capacity of LLMs by conducting an exhaustive analysis across 101\nlanguages, and classifies languages with similar characteristics into four\ndistinct quadrants. By delving into each quadrant, we shed light on the\nrationale behind their categorization and offer actionable guidelines for\ntuning these languages. Extensive experiments reveal that existing LLMs possess\nmultilingual capabilities that surpass our expectations, and we can\nsignificantly improve the multilingual performance of LLMs by focusing on these\ndistinct attributes present in each quadrant.",
            "author": [
                "Fei Yuan",
                "Shuai Yuan",
                "Zhiyong Wu",
                "Lei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09071v1",
                "http://arxiv.org/pdf/2311.09071v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09069v1",
            "title": "How Well Do Large Language Models Truly Ground?",
            "updated": "2023-11-15T16:11:27Z",
            "published": "2023-11-15T16:11:27Z",
            "summary": "Reliance on the inherent knowledge of Large Language Models (LLMs) can cause\nissues such as hallucinations, lack of control, and difficulties in integrating\nvariable knowledge. To mitigate this, LLMs can be probed to generate responses\nby grounding on external context, often given as input (knowledge-augmented\nmodels). Yet, previous research is often confined to a narrow view of the term\n\"grounding\", often only focusing on whether the response contains the correct\nanswer or not, which does not ensure the reliability of the entire response. To\naddress this limitation, we introduce a strict definition of grounding: a model\nis considered truly grounded when its responses (1) fully utilize necessary\nknowledge from the provided context, and (2) don't exceed the knowledge within\nthe contexts. We introduce a new dataset and a grounding metric to assess this\nnew definition and perform experiments across 13 LLMs of different sizes and\ntraining methods to provide insights into the factors that influence grounding\nperformance. Our findings contribute to a better understanding of how to\nimprove grounding capabilities and suggest an area of improvement toward more\nreliable and controllable LLM applications.",
            "author": [
                "Hyunji Lee",
                "Sejune Joo",
                "Chaeeun Kim",
                "Joel Jang",
                "Doyoung Kim",
                "Kyoung-Woon On",
                "Minjoon Seo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09069v1",
                "http://arxiv.org/pdf/2311.09069v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09067v1",
            "title": "Geometry of first nonempty Terracini loci",
            "updated": "2023-11-15T16:10:23Z",
            "published": "2023-11-15T16:10:23Z",
            "summary": "After a few results on curves, we characterize the smallest nonempty\nTerracini loci of Veronese and Segre-Veronese varieties. For del Pezzo\nsurfaces, we give a full description of the Terracini loci. Moreover, we\npresent an algorithm to explicitly compute the Terracini loci of a given\nvariety.",
            "author": [
                "Francesco Galuppi",
                "Pierpaola Santarsiero",
                "Douglas A. Torrance",
                "Ettore Teixeira Turatti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09067v1",
                "http://arxiv.org/pdf/2311.09067v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09066v1",
            "title": "Identifying Self-Disclosures of Use, Misuse and Addiction in\n  Community-based Social Media Posts",
            "updated": "2023-11-15T16:05:55Z",
            "published": "2023-11-15T16:05:55Z",
            "summary": "In the last decade, the United States has lost more than 500,000 people from\nan overdose involving prescription and illicit opioids\n(https://www.cdc.gov/drugoverdose/epidemic/index.html) making it a national\npublic health emergency (USDHHS, 2017). To more effectively prevent\nunintentional opioid overdoses, medical practitioners require robust and timely\ntools that can effectively identify at-risk patients. Community-based social\nmedia platforms such as Reddit allow self-disclosure for users to discuss\notherwise sensitive drug-related behaviors, often acting as indicators for\nopioid use disorder. Towards this, we present a moderate size corpus of 2500\nopioid-related posts from various subreddits spanning 6 different phases of\nopioid use: Medical Use, Misuse, Addiction, Recovery, Relapse, Not Using. For\nevery post, we annotate span-level extractive explanations and crucially study\ntheir role both in annotation quality and model development. We evaluate\nseveral state-of-the-art models in a supervised, few-shot, or zero-shot\nsetting. Experimental results and error analysis show that identifying the\nphases of opioid use disorder is highly contextual and challenging. However, we\nfind that using explanations during modeling leads to a significant boost in\nclassification accuracy demonstrating their beneficial role in a high-stakes\ndomain such as studying the opioid use disorder continuum. The dataset will be\nmade available for research on Github in the formal version.",
            "author": [
                "Chenghao Yang",
                "Tuhin Chakrabarty",
                "Karli R Hochstatter",
                "Melissa N Slavin",
                "Nabila El-Bassel",
                "Smaranda Muresan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09066v1",
                "http://arxiv.org/pdf/2311.09066v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09064v1",
            "title": "Imagine the Unseen World: A Benchmark for Systematic Generalization in\n  Visual World Models",
            "updated": "2023-11-15T16:02:13Z",
            "published": "2023-11-15T16:02:13Z",
            "summary": "Systematic compositionality, or the ability to adapt to novel situations by\ncreating a mental model of the world using reusable pieces of knowledge,\nremains a significant challenge in machine learning. While there has been\nconsiderable progress in the language domain, efforts towards systematic visual\nimagination, or envisioning the dynamical implications of a visual observation,\nare in their infancy. We introduce the Systematic Visual Imagination Benchmark\n(SVIB), the first benchmark designed to address this problem head-on. SVIB\noffers a novel framework for a minimal world modeling problem, where models are\nevaluated based on their ability to generate one-step image-to-image\ntransformations under a latent world dynamics. The framework provides benefits\nsuch as the possibility to jointly optimize for systematic perception and\nimagination, a range of difficulty levels, and the ability to control the\nfraction of possible factor combinations used during training. We provide a\ncomprehensive evaluation of various baseline models on SVIB, offering insight\ninto the current state-of-the-art in systematic visual imagination. We hope\nthat this benchmark will help advance visual systematic compositionality.",
            "author": [
                "Yeongbin Kim",
                "Gautam Singh",
                "Junyeong Park",
                "Caglar Gulcehre",
                "Sungjin Ahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09064v1",
                "http://arxiv.org/pdf/2311.09064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09063v1",
            "title": "Rotational spectroscopic characterisation of the [D2,C,S] system: an\n  update from the laboratory and theory",
            "updated": "2023-11-15T15:57:34Z",
            "published": "2023-11-15T15:57:34Z",
            "summary": "The synergy between high-resolution rotational spectroscopy and\nquantum-chemical calculations is essential for exploring future detection of\nmolecules, especially when spectroscopy parameters are not available yet. By\nusing highly correlated ab initio quartic force fields (QFFs) from explicitly\ncorrelated coupled cluster theory, a complete set of rotational constants and\ncentrifugal distortion constants for D$_2$CS and cis/trans-DCSD isomers have\nbeen produced. Comparing our new ab initio results for D$_2$CS with new\nrotational spectroscopy laboratory data for the same species, the accuracy of\nthe computed B and C rotational constants is within 0.1% while the A constant\nis only slightly higher. Additionally, quantum chemical vibrational frequencies\nare also provided, and these spectral reference data and new experimental\nrotational lines will provide additional references for potential observation\nof these deuterated sulfur species with either ground-based radio telescopes or\nspace-based infrared observatories.",
            "author": [
                "Natalia Inostroza-Pino",
                "Valerio Lattanzi",
                "C. Zachary Palmer",
                "Ryan C. Fortenberry",
                "Diego Mardones",
                "Paola Caselli",
                "Oko E. Godwin",
                "Timothy J. Lee"
            ],
            "link": [
                "http://dx.doi.org/10.1080/00268976.2023.2280762",
                "http://arxiv.org/abs/2311.09063v1",
                "http://arxiv.org/pdf/2311.09063v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "physics.atom-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09061v1",
            "title": "Automatic cable harness layout routing in a customizable 3D environment",
            "updated": "2023-11-15T15:53:25Z",
            "published": "2023-11-15T15:53:25Z",
            "summary": "Designing cable harnesses can be time-consuming and complex due to many\ndesign and manufacturing aspects and rules. Automating the design process can\nhelp to fulfil these rules, speed up the process, and optimize the design. To\naccommodate this, we formulate a harness routing optimization problem to\nminimize cable lengths, maximize bundling by rewarding shared paths, and\noptimize the cables' spatial location with respect to case-specific information\nof the routing environment, e.g., zones to avoid. A deterministic and\ncomputationally effective cable harness routing algorithm has been developed to\nsolve the routing problem and is used to generate a set of cable harness\ntopology candidates and approximate the Pareto front. Our approach was tested\nagainst a stochastic and an exact solver and our routing algorithm generated\nobjective function values better than the stochastic approach and close to the\nexact solver. Our algorithm was able to find solutions, some of them being\nproven to be near-optimal, for three industrial-sized 3D cases within\nreasonable time (in magnitude of seconds to minutes) and the computation times\nwere comparable to those of the stochastic approach.",
            "author": [
                "T. Karlsson",
                "E. \u00c5blad",
                "T. Hermansson",
                "J. S. Carlson",
                "G. Tenf\u00e4lt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09061v1",
                "http://arxiv.org/pdf/2311.09061v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "90C27",
                "G.2.1; J.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09060v1",
            "title": "Do Localization Methods Actually Localize Memorized Data in LLMs?",
            "updated": "2023-11-15T15:52:40Z",
            "published": "2023-11-15T15:52:40Z",
            "summary": "Large language models (LLMs) can memorize many pretrained sequences verbatim.\nThis paper studies if we can locate a small set of neurons in LLMs responsible\nfor memorizing a given sequence. While the concept of localization is often\nmentioned in prior work, methods for localization have never been\nsystematically and directly evaluated; we address this with two benchmarking\napproaches. In our INJ Benchmark, we actively inject a piece of new information\ninto a small subset of LLM weights and measure whether localization methods can\nidentify these \"ground truth\" weights. In the DEL Benchmark, we study\nlocalization of pretrained data that LLMs have already memorized; while this\nsetting lacks ground truth, we can still evaluate localization by measuring\nwhether dropping out located neurons erases a memorized sequence from the\nmodel. We evaluate five localization methods on our two benchmarks, and both\nshow similar rankings. All methods exhibit promising localization ability,\nespecially for pruning-based methods, though the neurons they identify are not\nnecessarily specific to a single memorized sequence.",
            "author": [
                "Ting-Yun Chang",
                "Jesse Thomason",
                "Robin Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09060v1",
                "http://arxiv.org/pdf/2311.09060v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09058v2",
            "title": "Constrained Parameter Regularization",
            "updated": "2023-12-06T14:20:53Z",
            "published": "2023-11-15T15:50:34Z",
            "summary": "Regularization is a critical component in deep learning training, with weight\ndecay being a commonly used approach. It applies a constant penalty coefficient\nuniformly across all parameters. This may be unnecessarily restrictive for some\nparameters, while insufficiently restricting others. To dynamically adjust\npenalty coefficients for different parameter groups, we present constrained\nparameter regularization (CPR) as an alternative to traditional weight decay.\nInstead of applying a single constant penalty to all parameters, we enforce an\nupper bound on a statistical measure (e.g., the L$_2$-norm) of parameter\ngroups. Consequently, learning becomes a constraint optimization problem, which\nwe address by an adaptation of the augmented Lagrangian method. CPR only\nrequires two hyperparameters and incurs no measurable runtime overhead.\nAdditionally, we propose a simple but efficient mechanism to adapt the upper\nbounds during the optimization. We provide empirical evidence of CPR's efficacy\nin experiments on the \"grokking\" phenomenon, computer vision, and language\nmodeling tasks. Our results demonstrate that CPR counteracts the effects of\ngrokking and consistently matches or outperforms traditional weight decay.",
            "author": [
                "J\u00f6rg K. H. Franke",
                "Michael Hefenbrock",
                "Gregor Koehler",
                "Frank Hutter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09058v2",
                "http://arxiv.org/pdf/2311.09058v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09055v1",
            "title": "Electronic structure in a transition metal dipnictide TaAs2",
            "updated": "2023-11-15T15:48:14Z",
            "published": "2023-11-15T15:48:14Z",
            "summary": "The family of transition metal dipnictides (TMDs) has been of theoretical and\nexperimental interest because this family hosts topological states and\nextremely large magnetoresistance (MR). Recently, TaAs2, a member of this\nfamily, has been predicted to support a topological crystalline insulating\nstate. Here, by using high resolution. Angle resolved photoemission\nspectroscopy (ARPES), we reveal both closed and open pockets in the metallic\nFermi surface and linearly dispersive bands on the (201) surface, along with\nthe presence of extreme MR observed from magneto-transport measurements. A\ncomparison of the ARPES results with first-principles computations show that\nthe linearly dispersive bands on the measured surface of TaAs2 are trivial bulk\nbands. The absence of symmetry-protected surface state on the (201) surface\nindicates its topologically dark nature. The presence of open Fermi surface\nfeatures suggests that the open orbit fermiology could contribute to the\nextremely large MR of TaAs.",
            "author": [
                "Sabin Regmi",
                "Cheng-Yi Huang",
                "Mojammel A. Khan",
                "Baokai Wang",
                "Anup Pradhan Sakhya",
                "M. Mofazzel Hosen",
                "Jesse Thompson",
                "Bahadur Singh",
                "Jonathan D. Denlinger",
                "Masahiro Ishigami",
                "J. F. Mitchell",
                "Dariusz Kaczorowski",
                "Arun Bansil",
                "Madhab Neupane"
            ],
            "link": [
                "http://dx.doi.org/10.1088/1361-648X/ad04fc",
                "http://arxiv.org/abs/2311.09055v1",
                "http://arxiv.org/pdf/2311.09055v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09053v1",
            "title": "Assessing Knowledge Editing in Language Models via Relation Perspective",
            "updated": "2023-11-15T15:44:42Z",
            "published": "2023-11-15T15:44:42Z",
            "summary": "Knowledge Editing (KE) for modifying factual knowledge in Large Language\nModels (LLMs) has been receiving increasing attention. However, existing\nknowledge editing methods are entity-centric, and it is unclear whether this\napproach is suitable for a relation-centric perspective. To address this gap,\nthis paper constructs a new benchmark named RaKE, which focuses on Relation\nbased Knowledge Editing. In this paper, we establish a suite of innovative\nmetrics for evaluation and conduct comprehensive experiments involving various\nknowledge editing baselines. We notice that existing knowledge editing methods\nexhibit the potential difficulty in their ability to edit relations. Therefore,\nwe further explore the role of relations in factual triplets within the\ntransformer. Our research results confirm that knowledge related to relations\nis not only stored in the FFN network but also in the attention layers. This\nprovides experimental support for future relation-based knowledge editing\nmethods.",
            "author": [
                "Yifan Wei",
                "Xiaoyan Yu",
                "Huanhuan Ma",
                "Fangyu Lei",
                "Yixuan Weng",
                "Ran Song",
                "Kang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09053v1",
                "http://arxiv.org/pdf/2311.09053v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09050v1",
            "title": "Improving Zero-shot Visual Question Answering via Large Language Models\n  with Reasoning Question Prompts",
            "updated": "2023-11-15T15:40:46Z",
            "published": "2023-11-15T15:40:46Z",
            "summary": "Zero-shot Visual Question Answering (VQA) is a prominent vision-language task\nthat examines both the visual and textual understanding capability of systems\nin the absence of training data. Recently, by converting the images into\ncaptions, information across multi-modalities is bridged and Large Language\nModels (LLMs) can apply their strong zero-shot generalization capability to\nunseen questions. To design ideal prompts for solving VQA via LLMs, several\nstudies have explored different strategies to select or generate\nquestion-answer pairs as the exemplar prompts, which guide LLMs to answer the\ncurrent questions effectively. However, they totally ignore the role of\nquestion prompts. The original questions in VQA tasks usually encounter\nellipses and ambiguity which require intermediate reasoning. To this end, we\npresent Reasoning Question Prompts for VQA tasks, which can further activate\nthe potential of LLMs in zero-shot scenarios. Specifically, for each question,\nwe first generate self-contained questions as reasoning question prompts via an\nunsupervised question edition module considering sentence fluency, semantic\nintegrity and syntactic invariance. Each reasoning question prompt clearly\nindicates the intent of the original question. This results in a set of\ncandidate answers. Then, the candidate answers associated with their confidence\nscores acting as answer heuristics are fed into LLMs and produce the final\nanswer. We evaluate reasoning question prompts on three VQA challenges,\nexperimental results demonstrate that they can significantly improve the\nresults of LLMs on zero-shot setting and outperform existing state-of-the-art\nzero-shot methods on three out of four data sets. Our source code is publicly\nreleased at \\url{https://github.com/ECNU-DASE-NLP/RQP}.",
            "author": [
                "Yunshi Lan",
                "Xiang Li",
                "Xin Liu",
                "Yang Li",
                "Wei Qin",
                "Weining Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09050v1",
                "http://arxiv.org/pdf/2311.09050v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09048v1",
            "title": "GRASP: A novel benchmark for evaluating language GRounding And Situated\n  Physics understanding in multimodal language models",
            "updated": "2023-11-15T15:38:28Z",
            "published": "2023-11-15T15:38:28Z",
            "summary": "This paper presents GRASP, a novel benchmark to evaluate the language\ngrounding and physical understanding capabilities of video-based multimodal\nlarge language models (LLMs). This evaluation is accomplished via a two-tier\napproach leveraging Unity simulations. The initial level tests for language\ngrounding by assessing a model's ability to relate simple textual descriptions\nwith visual information. The second level evaluates the model's understanding\nof 'Intuitive Physics' principles, such as object permanence and continuity. In\naddition to releasing the benchmark, we use it to evaluate several\nstate-of-the-art multimodal LLMs. Our evaluation reveals significant\nshortcomings in current models' language grounding and intuitive physics. These\nidentified limitations underline the importance of benchmarks like GRASP to\nmonitor the progress of future models in developing these competencies.",
            "author": [
                "Serwan Jassim",
                "Mario Holubar",
                "Annika Richter",
                "Cornelius Wolff",
                "Xenia Ohmer",
                "Elia Bruni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09048v1",
                "http://arxiv.org/pdf/2311.09048v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09040v1",
            "title": "Modeling Health Video Consumption Behaviors on Social Media: Activities,\n  Challenges, and Characteristics",
            "updated": "2023-11-15T15:31:53Z",
            "published": "2023-11-15T15:31:53Z",
            "summary": "Many people now watch health videos, such as diet, exercise, mental health,\nCOVID-19, and chronic disease videos, on social media. Most existing studies\nfocused on video creators, leaving the motivations and practices of viewers\nunderexplored. We interviewed 18 participants, surveyed 121 respondents, and\nderived a model characterizing consumers' video consumption practices on social\nmedia. The practices include five main activities: deciding to watch videos\ndriven by various motivations, accessing videos on social media through a\nsocio-technical ecosystem, watching videos to meet informational, emotional,\nand entertainment needs, evaluating the credibility and interestingness of\nvideos, and using videos to achieve health goals. The five activities do not\nnecessarily proceed in a linear fashion; rather, their arrangement is\nsituational, depending on individuals' motivations and their social and\ntechnological environments. We further identified challenges that consumers\nface while consuming health videos on social media and discussed design\nimplications and directions for future research.",
            "author": [
                "Jiaying Liu",
                "Yan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09040v1",
                "http://arxiv.org/pdf/2311.09040v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09033v1",
            "title": "MELA: Multilingual Evaluation of Linguistic Acceptability",
            "updated": "2023-11-15T15:25:28Z",
            "published": "2023-11-15T15:25:28Z",
            "summary": "Recent benchmarks for Large Language Models (LLMs) have mostly focused on\napplication-driven tasks such as complex reasoning and code generation, and\nthis has led to a scarcity in purely linguistic evaluation of LLMs. Against\nthis background, we introduce Multilingual Evaluation of Linguistic\nAcceptability -- MELA, the first multilingual benchmark on linguistic\nacceptability with 48K samples covering 10 languages from a diverse set of\nlanguage families. We establish baselines of commonly used LLMs along with\nsupervised models, and conduct cross-lingual transfer and multi-task learning\nexperiments with XLM-R. In pursuit of multilingual interpretability, we analyze\nthe weights of fine-tuned XLM-R to explore the possibility of identifying\ntransfer difficulty between languages. Our results show that ChatGPT benefits\nmuch from in-context examples but still lags behind fine-tuned XLM-R, while the\nperformance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting.\nCross-lingual and multi-task learning experiments show that unlike semantic\ntasks, in-language training data is crucial in acceptability judgements.\nResults in layerwise probing indicate that the upper layers of XLM-R become a\ntask-specific but language-agnostic region for multilingual acceptability\njudgment. We also introduce the concept of conflicting weight, which could be a\npotential indicator for the difficulty of cross-lingual transfer between\nlanguages. Our data will be available at https://github.com/sjtu-compling/MELA.",
            "author": [
                "Ziyin Zhang",
                "Yikang Liu",
                "Weifang Huang",
                "Junyu Mao",
                "Rui Wang",
                "Hai Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09033v1",
                "http://arxiv.org/pdf/2311.09033v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09029v1",
            "title": "Self-Annotated 3D Geometric Learning for Smeared Points Removal",
            "updated": "2023-11-15T15:20:24Z",
            "published": "2023-11-15T15:20:24Z",
            "summary": "There has been significant progress in improving the accuracy and quality of\nconsumer-level dense depth sensors. Nevertheless, there remains a common depth\npixel artifact which we call smeared points. These are points not on any 3D\nsurface and typically occur as interpolations between foreground and background\nobjects. As they cause fictitious surfaces, these points have the potential to\nharm applications dependent on the depth maps. Statistical outlier removal\nmethods fare poorly in removing these points as they tend also to remove actual\nsurface points. Trained network-based point removal faces difficulty in\nobtaining sufficient annotated data. To address this, we propose a fully\nself-annotated method to train a smeared point removal classifier. Our approach\nrelies on gathering 3D geometric evidence from multiple perspectives to\nautomatically detect and annotate smeared points and valid points. To validate\nthe effectiveness of our method, we present a new benchmark dataset: the Real\nAzure-Kinect dataset. Experimental results and ablation studies show that our\nmethod outperforms traditional filters and other self-annotated methods. Our\nwork is publicly available at\nhttps://github.com/wangmiaowei/wacv2024_smearedremover.git.",
            "author": [
                "Miaowei Wang",
                "Daniel Morris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09029v1",
                "http://arxiv.org/pdf/2311.09029v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09024v1",
            "title": "Fast Certification of Vision-Language Models Using Incremental\n  Randomized Smoothing",
            "updated": "2023-11-15T15:14:16Z",
            "published": "2023-11-15T15:14:16Z",
            "summary": "A key benefit of deep vision-language models such as CLIP is that they enable\nzero-shot open vocabulary classification; the user has the ability to define\nnovel class labels via natural language prompts at inference time. However,\nwhile CLIP-based zero-shot classifiers have demonstrated competitive\nperformance across a range of domain shifts, they remain highly vulnerable to\nadversarial attacks. Therefore, ensuring the robustness of such models is\ncrucial for their reliable deployment in the wild.\n  In this work, we introduce Open Vocabulary Certification (OVC), a fast\ncertification method designed for open-vocabulary models like CLIP via\nrandomized smoothing techniques. Given a base \"training\" set of prompts and\ntheir corresponding certified CLIP classifiers, OVC relies on the observation\nthat a classifier with a novel prompt can be viewed as a perturbed version of\nnearby classifiers in the base training set. Therefore, OVC can rapidly certify\nthe novel classifier using a variation of incremental randomized smoothing. By\nusing a caching trick, we achieve approximately two orders of magnitude\nacceleration in the certification process for novel prompts. To achieve further\n(heuristic) speedups, OVC approximates the embedding space at a given input\nusing a multivariate normal distribution bypassing the need for sampling via\nforward passes through the vision backbone. We demonstrate the effectiveness of\nOVC on through experimental evaluation using multiple vision-language backbones\non the CIFAR-10 and ImageNet test datasets.",
            "author": [
                "A K Nirala",
                "A Joshi",
                "C Hegde",
                "S Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09024v1",
                "http://arxiv.org/pdf/2311.09024v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09022v1",
            "title": "Exploring the Potential of Large Language Models in Computational\n  Argumentation",
            "updated": "2023-11-15T15:12:15Z",
            "published": "2023-11-15T15:12:15Z",
            "summary": "Computational argumentation has become an essential tool in various fields,\nincluding artificial intelligence, law, and public policy. It is an emerging\nresearch field in natural language processing (NLP) that attracts increasing\nattention. Research on computational argumentation mainly involves two types of\ntasks: argument mining and argument generation. As large language models (LLMs)\nhave demonstrated strong abilities in understanding context and generating\nnatural language, it is worthwhile to evaluate the performance of LLMs on\nvarious computational argumentation tasks. This work aims to embark on an\nassessment of LLMs, such as ChatGPT, Flan models and LLaMA2 models, under\nzero-shot and few-shot settings within the realm of computational\nargumentation. We organize existing tasks into 6 main classes and standardise\nthe format of 14 open-sourced datasets. In addition, we present a new benchmark\ndataset on counter speech generation, that aims to holistically evaluate the\nend-to-end performance of LLMs on argument mining and argument generation.\nExtensive experiments show that LLMs exhibit commendable performance across\nmost of these datasets, demonstrating their capabilities in the field of\nargumentation. We also highlight the limitations in evaluating computational\nargumentation and provide suggestions for future research directions in this\nfield.",
            "author": [
                "Guizhen Chen",
                "Liying Cheng",
                "Luu Anh Tuan",
                "Lidong Bing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09022v1",
                "http://arxiv.org/pdf/2311.09022v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09016v1",
            "title": "The Chromatic Number of Kneser Hypergraphs via Consensus Division",
            "updated": "2023-11-15T15:00:05Z",
            "published": "2023-11-15T15:00:05Z",
            "summary": "We show that the Consensus Division theorem implies lower bounds on the\nchromatic number of Kneser hypergraphs, offering a novel proof for a result of\nAlon, Frankl, and Lov\\'{a}sz (Trans. Amer. Math. Soc., 1986) and for its\ngeneralization by Kriz (Trans. Amer. Math. Soc., 1992). Our approach is applied\nto study the computational complexity of the total search problem Kneser$^p$,\nwhich given a succinct representation of a coloring of a $p$-uniform Kneser\nhypergraph with fewer colors than its chromatic number, asks to find a\nmonochromatic hyperedge. We prove that for every prime $p$, the Kneser$^p$\nproblem with an extended access to the input coloring is efficiently reducible\nto a quite weak approximation of the Consensus Division problem with $p$\nshares. In particular, for $p=2$, the problem is efficiently reducible to any\nnon-trivial approximation of the Consensus Halving problem on normalized\nmonotone functions. We further show that for every prime $p$, the Kneser$^p$\nproblem lies in the complexity class $\\mathsf{PPA}$-$p$. As an application, we\nestablish limitations on the complexity of the Kneser$^p$ problem, restricted\nto colorings with a bounded number of colors.",
            "author": [
                "Ishay Haviv"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09016v1",
                "http://arxiv.org/pdf/2311.09016v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DM",
                "math.AT",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09011v1",
            "title": "Algorithmic Cheap Talk",
            "updated": "2023-11-15T14:53:22Z",
            "published": "2023-11-15T14:53:22Z",
            "summary": "The literature on strategic communication originated with the influential\ncheap talk model, which precedes the Bayesian persuasion model by three\ndecades. This model describes an interaction between two agents: sender and\nreceiver. The sender knows some state of the world which the receiver does not\nknow, and tries to influence the receiver's action by communicating a cheap\ntalk message to the receiver.\n  This paper initiates the algorithmic study of cheap talk in a finite\nenvironment (i.e., a finite number of states and receiver's possible actions).\nWe first prove that approximating the sender-optimal or the welfare-maximizing\ncheap talk equilibrium up to a certain additive constant or multiplicative\nfactor is NP-hard. Fortunately, we identify three naturally-restricted cases\nthat admit efficient algorithms for finding a sender-optimal equilibrium. These\ninclude a state-independent sender's utility structure, a constant number of\nstates or a receiver having only two actions.",
            "author": [
                "Yakov Babichenko",
                "Inbal Talgam-Cohen",
                "Haifeng Xu",
                "Konstantin Zabarnyi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09011v1",
                "http://arxiv.org/pdf/2311.09011v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "91A68 (Primary) 91A27 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09008v1",
            "title": "End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and\n  Future Directions",
            "updated": "2023-11-15T14:50:16Z",
            "published": "2023-11-15T14:50:16Z",
            "summary": "End-to-end task-oriented dialogue (EToD) can directly generate responses in\nan end-to-end fashion without modular training, which attracts escalating\npopularity. The advancement of deep neural networks, especially the successful\nuse of large pre-trained models, has further led to significant progress in\nEToD research in recent years. In this paper, we present a thorough review and\nprovide a unified perspective to summarize existing approaches as well as\nrecent trends to advance the development of EToD research. The contributions of\nthis paper can be summarized: (1) \\textbf{\\textit{First survey}}: to our\nknowledge, we take the first step to present a thorough survey of this research\nfield; (2) \\textbf{\\textit{New taxonomy}}: we first introduce a unified\nperspective for EToD, including (i) \\textit{Modularly EToD} and (ii)\n\\textit{Fully EToD}; (3) \\textbf{\\textit{New Frontiers}}: we discuss some\npotential frontier areas as well as the corresponding challenges, hoping to\nspur breakthrough research in EToD field; (4) \\textbf{\\textit{Abundant\nresources}}: we build a public website\\footnote{We collect the related papers,\nbaseline projects, and leaderboards for the community at\n\\url{https://etods.net/}.}, where EToD researchers could directly access the\nrecent progress. We hope this work can serve as a thorough reference for the\nEToD research community.",
            "author": [
                "Libo Qin",
                "Wenbo Pan",
                "Qiguang Chen",
                "Lizi Liao",
                "Zhou Yu",
                "Yue Zhang",
                "Wanxiang Che",
                "Min Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09008v1",
                "http://arxiv.org/pdf/2311.09008v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09006v1",
            "title": "Data Similarity is Not Enough to Explain Language Model Performance",
            "updated": "2023-11-15T14:48:08Z",
            "published": "2023-11-15T14:48:08Z",
            "summary": "Large language models achieve high performance on many but not all downstream\ntasks. The interaction between pretraining data and task data is commonly\nassumed to determine this variance: a task with data that is more similar to a\nmodel's pretraining data is assumed to be easier for that model. We test\nwhether distributional and example-specific similarity measures (embedding-,\ntoken- and model-based) correlate with language model performance through a\nlarge-scale comparison of the Pile and C4 pretraining datasets with downstream\nbenchmarks. Similarity correlates with performance for multilingual datasets,\nbut in other benchmarks, we surprisingly find that similarity metrics are not\ncorrelated with accuracy or even each other. This suggests that the\nrelationship between pretraining data and downstream tasks is more complex than\noften assumed.",
            "author": [
                "Gregory Yauney",
                "Emily Reif",
                "David Mimno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09006v1",
                "http://arxiv.org/pdf/2311.09006v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09004v1",
            "title": "Incremental Object-Based Novelty Detection with Feedback Loop",
            "updated": "2023-11-15T14:46:20Z",
            "published": "2023-11-15T14:46:20Z",
            "summary": "Object-based Novelty Detection (ND) aims to identify unknown objects that do\nnot belong to classes seen during training by an object detection model. The\ntask is particularly crucial in real-world applications, as it allows to avoid\npotentially harmful behaviours, e.g. as in the case of object detection models\nadopted in a self-driving car or in an autonomous robot. Traditional approaches\nto ND focus on one time offline post processing of the pretrained object\ndetection output, leaving no possibility to improve the model robustness after\ntraining and discarding the abundant amount of out-of-distribution data\nencountered during deployment.\n  In this work, we propose a novel framework for object-based ND, assuming that\nhuman feedback can be requested on the predicted output and later incorporated\nto refine the ND model without negatively affecting the main object detection\nperformance. This refinement operation is repeated whenever new feedback is\navailable. To tackle this new formulation of the problem for object detection,\nwe propose a lightweight ND module attached on top of a pre-trained object\ndetection model, which is incrementally updated through a feedback loop. We\nalso propose a new benchmark to evaluate methods on this new setting and test\nextensively our ND approach against baselines, showing increased robustness and\na successful incorporation of the received feedback.",
            "author": [
                "Simone Caldarella",
                "Elisa Ricci",
                "Rahaf Aljundi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09004v1",
                "http://arxiv.org/pdf/2311.09004v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09002v1",
            "title": "Parallel Quantum Hough Transform",
            "updated": "2023-11-15T14:42:51Z",
            "published": "2023-11-15T14:42:51Z",
            "summary": "Few of the known quantum algorithms can be reliably executed on a quantum\ncomputer. Therefore, as an extension, we propose a Parallel Quantum Hough\ntransform (PQHT) algorithm that we execute on a quantum computer. We give its\nimplementation and discuss the results obtained. The PQHT algorithm is\nconceptually divided into a parallel rotation stage consisting of a set of\nconnected programmable $\\texttt{RZ}$ rotation gates, with adjustable node\nconnections of coincidence detectors realized with quantum logic gates. The\nmodules were developed using IBM Quantum Composer and tested using the IBM QASM\nsimulator. Finally, the modules were programmed using the Python package Qiskit\nand the jobs were sent to distributed IBM Q System One quantum computers. The\nsuccessful run results on Fraunhofer Q System One in Ehningen will be presented\nas a proof of concept for the PQHT algorithm.",
            "author": [
                "Frank Klefenz",
                "Nico Wittrock",
                "Frank Feldhoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09002v1",
                "http://arxiv.org/pdf/2311.09002v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "quant-ph",
                "ACM-class: I.5.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09000v2",
            "title": "Factcheck-GPT: End-to-End Fine-Grained Document-Level Fact-Checking and\n  Correction of LLM Output",
            "updated": "2023-11-16T04:15:22Z",
            "published": "2023-11-15T14:41:57Z",
            "summary": "The increased use of large language models (LLMs) across a variety of\nreal-world applications calls for mechanisms to verify the factual accuracy of\ntheir outputs. In this work, we present a holistic end-to-end solution for\nannotating the factuality of LLM-generated responses, which encompasses a\nmulti-stage annotation scheme designed to yield detailed labels concerning the\nverifiability and factual inconsistencies found in LLM outputs. We design and\nbuild an annotation tool to speed up the labelling procedure and ease the\nworkload of raters. It allows flexible incorporation of automatic results in\nany stage, e.g. automatically-retrieved evidence. We further construct an\nopen-domain document-level factuality benchmark in three-level granularity:\nclaim, sentence and document. Preliminary experiments show that FacTool,\nFactScore and Perplexity.ai are struggling to identify false claims with the\nbest F1=0.53. Annotation tool, benchmark and code are available at\nhttps://github.com/yuxiaw/Factcheck-GPT.",
            "author": [
                "Yuxia Wang",
                "Revanth Gangi Reddy",
                "Zain Muhammad Mujahid",
                "Arnav Arora",
                "Aleksandr Rubashevskii",
                "Jiahui Geng",
                "Osama Mohammed Afzal",
                "Liangming Pan",
                "Nadav Borenstein",
                "Aditya Pillai",
                "Isabelle Augenstein",
                "Iryna Gurevych",
                "Preslav Nakov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09000v2",
                "http://arxiv.org/pdf/2311.09000v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08995v1",
            "title": "Simple but Effective Unsupervised Classification for Specified Domain\n  Images: A Case Study on Fungi Images",
            "updated": "2023-11-15T14:33:22Z",
            "published": "2023-11-15T14:33:22Z",
            "summary": "High-quality labeled datasets are essential for deep learning. Traditional\nmanual annotation methods are not only costly and inefficient but also pose\nchallenges in specialized domains where expert knowledge is needed.\nSelf-supervised methods, despite leveraging unlabeled data for feature\nextraction, still require hundreds or thousands of labeled instances to guide\nthe model for effective specialized image classification. Current unsupervised\nlearning methods offer automatic classification without prior annotation but\noften compromise on accuracy. As a result, efficiently procuring high-quality\nlabeled datasets remains a pressing challenge for specialized domain images\ndevoid of annotated data. Addressing this, an unsupervised classification\nmethod with three key ideas is introduced: 1) dual-step feature dimensionality\nreduction using a pre-trained model and manifold learning, 2) a voting\nmechanism from multiple clustering algorithms, and 3) post-hoc instead of prior\nmanual annotation. This approach outperforms supervised methods in\nclassification accuracy, as demonstrated with fungal image data, achieving\n94.1% and 96.7% on public and private datasets respectively. The proposed\nunsupervised classification method reduces dependency on pre-annotated\ndatasets, enabling a closed-loop for data classification. The simplicity and\nease of use of this method will also bring convenience to researchers in\nvarious fields in building datasets, promoting AI applications for images in\nspecialized domains.",
            "author": [
                "Zhaocong liu",
                "Fa Zhang",
                "Lin Cheng",
                "Huanxi Deng",
                "Xiaoyan Yang",
                "Zhenyu Zhang",
                "Chichun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08995v1",
                "http://arxiv.org/pdf/2311.08995v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08993v1",
            "title": "When does In-context Learning Fall Short and Why? A Study on\n  Specification-Heavy Tasks",
            "updated": "2023-11-15T14:26:30Z",
            "published": "2023-11-15T14:26:30Z",
            "summary": "In-context learning (ICL) has become the default method for using large\nlanguage models (LLMs), making the exploration of its limitations and\nunderstanding the underlying causes crucial. In this paper, we find that ICL\nfalls short of handling specification-heavy tasks, which are tasks with\ncomplicated and extensive task specifications, requiring several hours for\nordinary humans to master, such as traditional information extraction tasks.\nThe performance of ICL on these tasks mostly cannot reach half of the\nstate-of-the-art results. To explore the reasons behind this failure, we\nconduct comprehensive experiments on 18 specification-heavy tasks with various\nLLMs and identify three primary reasons: inability to specifically understand\ncontext, misalignment in task schema comprehension with humans, and inadequate\nlong-text understanding ability. Furthermore, we demonstrate that through\nfine-tuning, LLMs can achieve decent performance on these tasks, indicating\nthat the failure of ICL is not an inherent flaw of LLMs, but rather a drawback\nof existing alignment methods that renders LLMs incapable of handling\ncomplicated specification-heavy tasks via ICL. To substantiate this, we perform\ndedicated instruction tuning on LLMs for these tasks and observe a notable\nimprovement. We hope the analyses in this paper could facilitate advancements\nin alignment methods enabling LLMs to meet more sophisticated human demands.",
            "author": [
                "Hao Peng",
                "Xiaozhi Wang",
                "Jianhui Chen",
                "Weikai Li",
                "Yunjia Qi",
                "Zimu Wang",
                "Zhili Wu",
                "Kaisheng Zeng",
                "Bin Xu",
                "Lei Hou",
                "Juanzi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08993v1",
                "http://arxiv.org/pdf/2311.08993v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08990v1",
            "title": "sQUlearn $\\unicode{x2013}$ A Python Library for Quantum Machine Learning",
            "updated": "2023-11-15T14:22:53Z",
            "published": "2023-11-15T14:22:53Z",
            "summary": "sQUlearn introduces a user-friendly, NISQ-ready Python library for quantum\nmachine learning (QML), designed for seamless integration with classical\nmachine learning tools like scikit-learn. The library's dual-layer architecture\nserves both QML researchers and practitioners, enabling efficient prototyping,\nexperimentation, and pipelining. sQUlearn provides a comprehensive toolset that\nincludes both quantum kernel methods and quantum neural networks, along with\nfeatures like customizable data encoding strategies, automated execution\nhandling, and specialized kernel regularization techniques. By focusing on\nNISQ-compatibility and end-to-end automation, sQUlearn aims to bridge the gap\nbetween current quantum computing capabilities and practical machine learning\napplications.",
            "author": [
                "David A. Kreplin",
                "Moritz Willmann",
                "Jan Schnabel",
                "Frederic Rapp",
                "Marco Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08990v1",
                "http://arxiv.org/pdf/2311.08990v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08988v1",
            "title": "Counting Small Induced Subgraphs with Edge-monotone Properties",
            "updated": "2023-11-15T14:22:08Z",
            "published": "2023-11-15T14:22:08Z",
            "summary": "We study the parameterized complexity of #IndSub($\\Phi$), where given a graph\n$G$ and an integer $k$, the task is to count the number of induced subgraphs on\n$k$ vertices that satisfy the graph property $\\Phi$. Focke and Roth [STOC 2022]\ncompletely characterized the complexity for each $\\Phi$ that is a hereditary\nproperty (that is, closed under vertex deletions): #IndSub($\\Phi$) is\n#W[1]-hard except in the degenerate cases when every graph satisfies $\\Phi$ or\nonly finitely many graphs satisfy $\\Phi$. We complement this result with a\nclassification for each $\\Phi$ that is edge monotone (that is, closed under\nedge deletions): #IndSub($\\Phi$) is #W[1]-hard except in the degenerate case\nwhen there are only finitely many integers $k$ such that $\\Phi$ is nontrivial\non $k$-vertex graphs. Our result generalizes earlier results for specific\nproperties $\\Phi$ that are related to the connectivity or density of the graph.\n  Further, we extend the #W[1]-hardness result by a lower bound which shows\nthat #IndSub($\\Phi$) cannot be solved in time $f(k) \\cdot |V(G)|^{o(\\sqrt{\\log\nk/\\log\\log k})}$ for any function $f$, unless the Exponential-Time Hypothesis\n(ETH) fails. For many natural properties, we obtain even a tight bound $f(k)\n\\cdot |V(G)|^{o(k)}$; for example, this is the case for every property $\\Phi$\nthat is nontrivial on $k$-vertex graphs for each $k$ greater than some $k_0$.",
            "author": [
                "Simon D\u00f6ring",
                "D\u00e1niel Marx",
                "Philip Wellnitz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08988v1",
                "http://arxiv.org/pdf/2311.08988v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08987v1",
            "title": "Proceedings Fifth International Workshop on Formal Methods for\n  Autonomous Systems",
            "updated": "2023-11-15T14:20:56Z",
            "published": "2023-11-15T14:20:56Z",
            "summary": "This EPTCS volume contains the proceedings for the Fifth International\nWorkshop on Formal Methods for Autonomous Systems (FMAS 2023), which was held\non the 15th and 16th of November 2023. FMAS 2023 was co-located with 18th\nInternational Conference on integrated Formal Methods (iFM) (iFM'22), organised\nby Leiden Institute of Advanced Computer Science of Leiden University. The\nworkshop itself was held at Scheltema Leiden, a renovated 19th Century blanket\nfactory alongside the canal.\n  FMAS 2023 received 25 submissions. We received 11 regular papers, 3\nexperience reports, 6 research previews, and 5 vision papers. The researchers\nwho submitted papers to FMAS 2023 were from institutions in: Australia, Canada,\nColombia, France, Germany, Ireland, Italy, the Netherlands, Sweden, the United\nKingdom, and the United States of America. Increasing our number of submissions\nfor the third year in a row is an encouraging sign that FMAS has established\nitself as a reputable publication venue for research on the formal modelling\nand verification of autonomous systems. After each paper was reviewed by three\nmembers of our Programme Committee we accepted a total of 15 papers: 8 long\npapers and 7 short papers.",
            "author": [
                "Marie Farrell",
                "Matt Luckcuck",
                "Mario Gleirscher",
                "Maike Schwammberger"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395",
                "http://arxiv.org/abs/2311.08987v1",
                "http://arxiv.org/pdf/2311.08987v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08984v1",
            "title": "Local strain enhanced switching of magnetic tunnel junctions for energy\n  efficient computing",
            "updated": "2023-11-15T14:18:49Z",
            "published": "2023-11-15T14:18:49Z",
            "summary": "Strain-controlled modulation of the magnetic switching behavior in magnetic\ntunnel junctions (MTJs) could provide the energy efficiency needed to\naccelerate the use of MTJs in memory, logic, and neuromorphic computing, as\nwell as an additional way to tune MTJ properties for these applications.\nState-of-the-art CoFeB-MgO based MTJs still require too high voltages to alter\ntheir magnetic switching behavior with strain. In this study, we demonstrate\nstrain-enhanced field switching of nanoscale MTJs through electric field\ncontrol via voltage applied across local gates. The results show that\nrecord-low voltage down to 200 mV can be used to control the switching field of\nthe MTJ through enhancing the magnetic anisotropy, and that tunnel\nmagnetoresistance is linearly enhanced with voltage through straining the\ncrystal structure of the tunnel barrier. These findings underscore the\npotential of electric field manipulation and strain engineering as effective\nstrategies for tailoring the properties and functionality of nanoscale MTJs.",
            "author": [
                "Suyogya Karki",
                "Jaesuk Kwon",
                "Joe Davies",
                "Raisa Fabiha",
                "Vivian Rogers",
                "Thomas Leonard",
                "Supriyo Bandyopadhyay",
                "Jean Anne C. Incorvia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08984v1",
                "http://arxiv.org/pdf/2311.08984v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08983v1",
            "title": "Edge Accelerated Robot Navigation with Hierarchical Motion Planning",
            "updated": "2023-11-15T14:16:42Z",
            "published": "2023-11-15T14:16:42Z",
            "summary": "Low-cost autonomous robots suffer from limited onboard computing power,\nresulting in excessive computation time when navigating in cluttered\nenvironments. This paper presents Edge Accelerated Robot Navigation, or EARN\nfor short, to achieve real-time collision avoidance by adopting hierarchical\nmotion planning (HMP). In contrast to existing local or edge motion planning\nsolutions that ignore the interdependency between low-level motion planning and\nhigh-level resource allocation, EARN adopts model predictive switching (MPS)\nthat maximizes the expected switching gain w.r.t. robot states and actions\nunder computation and communication resource constraints. As such, each robot\ncan dynamically switch between a point-mass motion planner executed locally to\nguarantee safety (e.g., path-following) and a full-shape motion planner\nexecuted non-locally to guarantee efficiency (e.g., overtaking). The crux to\nEARN is a two-time scale integrated decision-planning algorithm based on\nbilevel mixed-integer optimization, and a fast conditional collision avoidance\nalgorithm based on penalty dual decomposition. We validate the performance of\nEARN in indoor simulation, outdoor simulation, and real-world environments.\nExperiments show that EARN achieves significantly smaller navigation time and\ncollision ratios than state-of-the-art navigation approaches.",
            "author": [
                "Guoliang Li",
                "Ruihua Han",
                "Shuai Wang",
                "Fei Gao",
                "Yonina C. Eldar",
                "Chengzhong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08983v1",
                "http://arxiv.org/pdf/2311.08983v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08982v1",
            "title": "SentAlign: Accurate and Scalable Sentence Alignment",
            "updated": "2023-11-15T14:15:41Z",
            "published": "2023-11-15T14:15:41Z",
            "summary": "We present SentAlign, an accurate sentence alignment tool designed to handle\nvery large parallel document pairs. Given user-defined parameters, the\nalignment algorithm evaluates all possible alignment paths in fairly large\ndocuments of thousands of sentences and uses a divide-and-conquer approach to\nalign documents containing tens of thousands of sentences. The scoring function\nis based on LaBSE bilingual sentence representations. SentAlign outperforms\nfive other sentence alignment tools when evaluated on two different evaluation\nsets, German-French and English-Icelandic, and on a downstream machine\ntranslation task.",
            "author": [
                "Stein\u00fe\u00f3r Steingr\u00edmsson",
                "Hrafn Loftsson",
                "Andy Way"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08982v1",
                "http://arxiv.org/pdf/2311.08982v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08981v1",
            "title": "Speculative Contrastive Decoding",
            "updated": "2023-11-15T14:15:30Z",
            "published": "2023-11-15T14:15:30Z",
            "summary": "Large language models (LLMs) have shown extraordinary performance in various\nlanguage tasks, but high computational requirements hinder their widespread\ndeployment. Speculative decoding, which uses amateur models to predict the\ngeneration of expert models, has been proposed as a way to accelerate LLM\ninference. However, speculative decoding focuses on acceleration instead of\nmaking the best use of the token distribution from amateur models. We proposed\nSpeculative Contrastive Decoding (SCD), an accelerated decoding method\nleveraging the natural contrast between expert and amateur models in\nspeculative decoding. Comprehensive evaluations on four benchmarks show that\nSCD can achieve similar acceleration factors as speculative decoding while\nfurther improving the generation quality as the contrastive decoding. The\nanalysis of token probabilities further demonstrates the compatibility between\nspeculative and contrastive decoding. Overall, SCD provides an effective\napproach to enhance the decoding quality of LLMs while saving computational\nresources.",
            "author": [
                "Hongyi Yuan",
                "Keming Lu",
                "Fei Huang",
                "Zheng Yuan",
                "Chang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08981v1",
                "http://arxiv.org/pdf/2311.08981v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08979v1",
            "title": "A Multimodal Dataset of 21,412 Recorded Nights for Sleep and Respiratory\n  Research",
            "updated": "2023-11-15T14:14:26Z",
            "published": "2023-11-15T14:14:26Z",
            "summary": "This study introduces a novel, rich dataset obtained from home sleep apnea\ntests using the FDA-approved WatchPAT-300 device, collected from 7,077\nparticipants over 21,412 nights. The dataset comprises three levels of sleep\ndata: raw multi-channel time-series from sensors, annotated sleep events, and\ncomputed summary statistics, which include 447 features related to sleep\narchitecture, sleep apnea, and heart rate variability (HRV). We present\nreference values for Apnea/Hypopnea Index (AHI), sleep efficiency, Wake After\nSleep Onset (WASO), and HRV sample entropy, stratified by age and sex.\nMoreover, we demonstrate that the dataset improves the predictive capability\nfor various health related traits, including body composition, bone density,\nblood sugar levels and cardiovascular health. These results illustrate the\ndataset's potential to advance sleep research, personalized healthcare, and\nmachine learning applications in biomedicine.",
            "author": [
                "Alon Diament",
                "Maria Gorodetski",
                "Adam Jankelow",
                "Ayya Keshet",
                "Tal Shor",
                "Daphna Weissglas-Volkov",
                "Hagai Rossman",
                "Eran Segal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08979v1",
                "http://arxiv.org/pdf/2311.08979v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09272v1",
            "title": "Linear time Evidence Accumulation Clustering with KMeans",
            "updated": "2023-11-15T14:12:59Z",
            "published": "2023-11-15T14:12:59Z",
            "summary": "Among ensemble clustering methods, Evidence Accumulation Clustering is one of\nthe simplest technics. In this approach, a co-association (CA) matrix\nrepresenting the co-clustering frequency is built and then clustered to extract\nconsensus clusters. Compared to other approaches, this one is simple as there\nis no need to find matches between clusters obtained from two different\npartitionings. Nevertheless, this method suffers from computational issues, as\nit requires to compute and store a matrix of size n x n, where n is the number\nof items. Due to the quadratic cost, this approach is reserved for small\ndatasets. This work describes a trick which mimic the behavior of average\nlinkage clustering. We found a way of computing efficiently the density of a\npartitioning, reducing the cost from a quadratic to linear complexity.\nAdditionally, we proved that the k-means maximizes naturally the density. We\nperformed experiments on several benchmark datasets where we compared the\nk-means and the bisecting version to other state-of-the-art consensus\nalgorithms. The k-means results are comparable to the best state of the art in\nterms of NMI while keeping the computational cost low. Additionally, the\nk-means led to the best results in terms of density. These results provide\nevidence that consensus clustering can be solved with simple algorithms.",
            "author": [
                "Ga\u00eblle Candel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09272v1",
                "http://arxiv.org/pdf/2311.09272v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T20",
                "I.2.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08978v1",
            "title": "Probability of Collision of satellites and space debris for short-term\n  encounters: Rederivation and fast-to-compute upper and lower bounds",
            "updated": "2023-11-15T14:12:55Z",
            "published": "2023-11-15T14:12:55Z",
            "summary": "The proliferation of space debris in LEO has become a major concern for the\nspace industry. With the growing interest in space exploration, the prediction\nof potential collisions between objects in orbit has become a crucial issue. It\nis estimated that, in orbit, there are millions of fragments a few millimeters\nin size and thousands of inoperative satellites and discarded rocket stages.\nGiven the high speeds that these fragments can reach, even fragments a few\nmillimeters in size can cause fractures in a satellite's hull or put a serious\ncrack in the window of a space shuttle. The conventional method proposed by\nAkella and Alfriend in 2000 remains widely used to estimate the probability of\ncollision in short-term encounters. Given the small period of time, it is\nassumed that, during the encounter: (1) trajectories are represented by\nstraight lines with constant velocity; (2) there is no velocity uncertainty and\nthe position exhibits a stationary distribution throughout the encounter; and\n(3) position uncertainties are independent and represented by Gaussian\ndistributions. This study introduces a novel derivation based on first\nprinciples that naturally allows for tight and fast upper and lower bounds for\nthe probability of collision. We tested implementations of both probability and\nbound computations with the original and our formulation on a real CDM dataset\nused in ESA's Collision Avoidance Challenge. Our approach reduces the\ncalculation of the probability to two one-dimensional integrals and has the\npotential to significantly reduce the processing time compared to the\ntraditional method, from 80% to nearly real-time.",
            "author": [
                "Ricardo Ferreira",
                "Cl\u00e1udia Soares",
                "Marta Guimar\u00e3es"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08978v1",
                "http://arxiv.org/pdf/2311.08978v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08972v2",
            "title": "Unsupervised approaches based on optimal transport and convex analysis\n  for inverse problems in imaging",
            "updated": "2023-11-29T09:57:06Z",
            "published": "2023-11-15T14:04:37Z",
            "summary": "Unsupervised deep learning approaches have recently become one of the crucial\nresearch areas in imaging owing to their ability to learn expressive and\npowerful reconstruction operators even when paired high-quality training data\nis scarcely available. In this chapter, we review theoretically principled\nunsupervised learning schemes for solving imaging inverse problems, with a\nparticular focus on methods rooted in optimal transport and convex analysis. We\nbegin by reviewing the optimal transport-based unsupervised approaches such as\nthe cycle-consistency-based models and learned adversarial regularization\nmethods, which have clear probabilistic interpretations. Subsequently, we give\nan overview of a recent line of works on provably convergent learned\noptimization algorithms applied to accelerate the solution of imaging inverse\nproblems, alongside their dedicated unsupervised training schemes. We also\nsurvey a number of provably convergent plug-and-play algorithms (based on\ngradient-step deep denoisers), which are among the most important and widely\napplied unsupervised approaches for imaging problems. At the end of this\nsurvey, we provide an overview of a few related unsupervised learning\nframeworks that complement our focused schemes. Together with a detailed\nsurvey, we provide an overview of the key mathematical results that underlie\nthe methods reviewed in the chapter to keep our discussion self-contained.",
            "author": [
                "Marcello Carioni",
                "Subhadip Mukherjee",
                "Hong Ye Tan",
                "Junqi Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08972v2",
                "http://arxiv.org/pdf/2311.08972v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08968v1",
            "title": "Identifying Linear Relational Concepts in Large Language Models",
            "updated": "2023-11-15T14:01:41Z",
            "published": "2023-11-15T14:01:41Z",
            "summary": "Transformer language models (LMs) have been shown to represent concepts as\ndirections in the latent space of hidden activations. However, for any given\nhuman-interpretable concept, how can we find its direction in the latent space?\nWe present a technique called linear relational concepts (LRC) for finding\nconcept directions corresponding to human-interpretable concepts at a given\nhidden layer in a transformer LM by first modeling the relation between subject\nand object as a linear relational embedding (LRE). While the LRE work was\nmainly presented as an exercise in understanding model representations, we find\nthat inverting the LRE while using earlier object layers results in a powerful\ntechnique to find concept directions that both work well as a classifier and\ncausally influence model outputs.",
            "author": [
                "David Chanin",
                "Anthony Hunter",
                "Oana-Maria Camburu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08968v1",
                "http://arxiv.org/pdf/2311.08968v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08966v1",
            "title": "Improving Large-scale Deep Biasing with Phoneme Features and Text-only\n  Data in Streaming Transducer",
            "updated": "2023-11-15T13:53:28Z",
            "published": "2023-11-15T13:53:28Z",
            "summary": "Deep biasing for the Transducer can improve the recognition performance of\nrare words or contextual entities, which is essential in practical\napplications, especially for streaming Automatic Speech Recognition (ASR).\nHowever, deep biasing with large-scale rare words remains challenging, as the\nperformance drops significantly when more distractors exist and there are words\nwith similar grapheme sequences in the bias list. In this paper, we combine the\nphoneme and textual information of rare words in Transducers to distinguish\nwords with similar pronunciation or spelling. Moreover, the introduction of\ntraining with text-only data containing more rare words benefits large-scale\ndeep biasing. The experiments on the LibriSpeech corpus demonstrate that the\nproposed method achieves state-of-the-art performance on rare word error rate\nfor different scales and levels of bias lists.",
            "author": [
                "Jin Qiu",
                "Lu Huang",
                "Boyu Li",
                "Jun Zhang",
                "Lu Lu",
                "Zejun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08966v1",
                "http://arxiv.org/pdf/2311.08966v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08965v1",
            "title": "Variational manifolds for ground states and scarred dynamics of\n  blockade-constrained spin models on two and three dimensional lattices",
            "updated": "2023-11-15T13:52:21Z",
            "published": "2023-11-15T13:52:21Z",
            "summary": "We introduce a variational manifold of simple tensor network states for the\nstudy of a family of constrained models that describe spin-1/2 systems as\nrealized by Rydberg atom arrays. Our manifold permits analytical calculation\nvia perturbative expansion of one- and two-point functions in arbitrary spatial\ndimensions and allows for efficient computation of the matrix elements required\nfor variational energy minimization and variational time evolution in up to\nthree dimensions. We apply this framework to the PXP model on the hypercubic\nlattice in 1D, 2D, and 3D, and show that, in each case, it exhibits quantum\nphase transitions breaking the sub-lattice symmetry in equilibrium, and hosts\nquantum many body scars out of equilibrium. We demonstrate that our variational\nansatz qualitatively captures all these phenomena and predicts key quantities\nwith an accuracy that increases with the dimensionality of the lattice, and\nconclude that our method can be interpreted as a generalization of mean-field\ntheory to constrained spin models.",
            "author": [
                "Joey Li",
                "Giuliano Giudici",
                "Hannes Pichler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08965v1",
                "http://arxiv.org/pdf/2311.08965v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08962v3",
            "title": "Constraints on Density Dependent MIT Bag Model Parameters for Quark and\n  Hybrid Stars",
            "updated": "2023-11-22T03:20:10Z",
            "published": "2023-11-15T13:51:32Z",
            "summary": "We compute the equation of state (EoS) of strange quark stars (SQSs) with the\nMIT Bag model using density dependent bag pressure, characterized by a Gaussian\ndistribution function. The bag pressure's density dependence is controlled by\nthree key parameters namely the asymptotic value ($B_{as}$), $\\Delta B(=B_0 -\nB_{as})$, and $\\beta$. We explore various parameter combinations ($B_{as}$,\n$\\Delta B$, $\\beta$) that adhere to the Bodmer-Witten conjecture, a criterion\nfor the stability of SQSs. Our primary aim is to analyze the effects of these\nparameter variations on the structural properties of SQSs. However we find that\nnone of the combinations can satisfy the NICER data for PSR J0030+0451 and the\nconstraint on tidal deformability from GW170817. So it can be emphasized that\nthis model cannot describe reasonable SQS configurations. We also extend our\nwork to calculate structural properties of hybrid stars (HSs). With the density\ndependent bag model (DDBM), these astrophysical constraints are fulfilled by\nthe HSs configurations within a very restricted range of the three parameters.\nThe present work is the first to constrain the parameters of DDBM for both SQS\nand HSs using the recent astrophysical constraints on tidal deformabiity from\nGW170817 and that on mass-radius relationship from NICER data.",
            "author": [
                "Soumen Podder",
                "Suman Pal",
                "Debashree Sen",
                "Gargi Chaudhuri"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.nuclphysa.2023.122796",
                "http://arxiv.org/abs/2311.08962v3",
                "http://arxiv.org/pdf/2311.08962v3"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08961v1",
            "title": "DBJoules: An Energy Measurement Tool for Database Management Systems",
            "updated": "2023-11-15T13:51:28Z",
            "published": "2023-11-15T13:51:28Z",
            "summary": "In the rapidly evolving landscape of modern data-driven technologies,\nsoftware relies on large datasets and constant data center operations using\nvarious database systems to support computation-intensive tasks. As energy\nconsumption in software systems becomes a growing concern, selecting the right\ndatabase from energy-efficiency perspective is also critical. To address this,\nwe introduce \\textbf{\\textit{DBJoules}}, a tool that measures the energy\nconsumption of activities in database systems. \\textit{DBJoules} supports\nenergy measurement of CRUD operations for four popular databases. Through\nevaluations on two widely-used datasets, we identify disparities of 7\\% to 38\\%\nin the energy consumption of these databases. Hence, the goal is to raise\ndeveloper awareness about the effect of running queries in different databases\nfrom an energy consumption perspective, enabling them to select appropriate\ndatabase for sustainable usage. The tool's demonstration is available at\n\\url{https://youtu.be/D1MTZum0jok} and related artifacts at\n\\url{https://rishalab.github.io/DBJoules/}.",
            "author": [
                "Hemasri Sai Lella",
                "Kurra Manasa",
                "Rajrupa Chattaraj",
                "Sridhar Chimalakonda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08961v1",
                "http://arxiv.org/pdf/2311.08961v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08957v1",
            "title": "I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in\n  Social Robots",
            "updated": "2023-11-15T13:47:00Z",
            "published": "2023-11-15T13:47:00Z",
            "summary": "In the rapidly evolving landscape of human-computer interaction, the\nintegration of vision capabilities into conversational agents stands as a\ncrucial advancement. This paper presents an initial implementation of a\ndialogue manager that leverages the latest progress in Large Language Models\n(e.g., GPT-4, IDEFICS) to enhance the traditional text-based prompts with\nreal-time visual input. LLMs are used to interpret both textual prompts and\nvisual stimuli, creating a more contextually aware conversational agent. The\nsystem's prompt engineering, incorporating dialogue with summarisation of the\nimages, ensures a balance between context preservation and computational\nefficiency. Six interactions with a Furhat robot powered by this system are\nreported, illustrating and discussing the results obtained. By implementing\nthis vision-enabled dialogue system, the paper envisions a future where\nconversational agents seamlessly blend textual and visual modalities, enabling\nricher, more context-aware dialogues.",
            "author": [
                "Giulio Antonio Abbo",
                "Tony Belpaeme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08957v1",
                "http://arxiv.org/pdf/2311.08957v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08955v1",
            "title": "A Spectral Diffusion Prior for Hyperspectral Image Super-Resolution",
            "updated": "2023-11-15T13:40:58Z",
            "published": "2023-11-15T13:40:58Z",
            "summary": "Fusion-based hyperspectral image (HSI) super-resolution aims to produce a\nhigh-spatial-resolution HSI by fusing a low-spatial-resolution HSI and a\nhigh-spatial-resolution multispectral image. Such a HSI super-resolution\nprocess can be modeled as an inverse problem, where the prior knowledge is\nessential for obtaining the desired solution. Motivated by the success of\ndiffusion models, we propose a novel spectral diffusion prior for fusion-based\nHSI super-resolution. Specifically, we first investigate the spectrum\ngeneration problem and design a spectral diffusion model to model the spectral\ndata distribution. Then, in the framework of maximum a posteriori, we keep the\ntransition information between every two neighboring states during the reverse\ngenerative process, and thereby embed the knowledge of trained spectral\ndiffusion model into the fusion problem in the form of a regularization term.\nAt last, we treat each generation step of the final optimization problem as its\nsubproblem, and employ the Adam to solve these subproblems in a reverse\nsequence. Experimental results conducted on both synthetic and real datasets\ndemonstrate the effectiveness of the proposed approach. The code of the\nproposed approach will be available on https://github.com/liuofficial/SDP.",
            "author": [
                "Jianjun Liu",
                "Zebin Wu",
                "Liang Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08955v1",
                "http://arxiv.org/pdf/2311.08955v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08949v1",
            "title": "Automated Volume Corrected Mitotic Index Calculation Through\n  Annotation-Free Deep Learning using Immunohistochemistry as Reference\n  Standard",
            "updated": "2023-11-15T13:35:40Z",
            "published": "2023-11-15T13:35:40Z",
            "summary": "The volume-corrected mitotic index (M/V-Index) was shown to provide\nprognostic value in invasive breast carcinomas. However, despite its prognostic\nsignificance, it is not established as the standard method for assessing\naggressive biological behaviour, due to the high additional workload associated\nwith determining the epithelial proportion. In this work, we show that using a\ndeep learning pipeline solely trained with an annotation-free,\nimmunohistochemistry-based approach, provides accurate estimations of\nepithelial segmentation in canine breast carcinomas. We compare our automatic\nframework with the manually annotated M/V-Index in a study with three\nboard-certified pathologists. Our results indicate that the deep learning-based\npipeline shows expert-level performance, while providing time efficiency and\nreproducibility.",
            "author": [
                "Jonas Ammeling",
                "Moritz Hecker",
                "Jonathan Ganz",
                "Taryn A. Donovan",
                "Christof A. Bertram",
                "Katharina Breininger",
                "Marc Aubreville"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08949v1",
                "http://arxiv.org/pdf/2311.08949v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08945v1",
            "title": "A Single-Loop Algorithm for Decentralized Bilevel Optimization",
            "updated": "2023-11-15T13:29:49Z",
            "published": "2023-11-15T13:29:49Z",
            "summary": "Bilevel optimization has received more and more attention recently due to its\nwide applications in machine learning. In this paper, we consider bilevel\noptimization in decentralized networks. In particular, we propose a novel\nsingle-loop algorithm for solving decentralized bilevel optimization with\nstrongly convex lower level problem. Our algorithm is fully single-loop and\ndoes not require heavy matrix-vector multiplications when approximating the\nhypergradient. Moreover, unlike existing methods for decentralized bilevel\noptimization and federated bilevel optimization, our algorithm does not require\nany gradient heterogeneity assumption. Our analysis shows that the proposed\nalgorithm achieves the best known convergence rate for bilevel optimization\nalgorithms.",
            "author": [
                "Youran Dong",
                "Shiqian Ma",
                "Junfeng Yang",
                "Chao Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08945v1",
                "http://arxiv.org/pdf/2311.08945v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02985v1",
            "title": "FocalPose++: Focal Length and Object Pose Estimation via Render and\n  Compare",
            "updated": "2023-11-15T13:28:02Z",
            "published": "2023-11-15T13:28:02Z",
            "summary": "We introduce FocalPose++, a neural render-and-compare method for jointly\nestimating the camera-object 6D pose and camera focal length given a single RGB\ninput image depicting a known object. The contributions of this work are\nthreefold. First, we derive a focal length update rule that extends an existing\nstate-of-the-art render-and-compare 6D pose estimator to address the joint\nestimation task. Second, we investigate several different loss functions for\njointly estimating the object pose and focal length. We find that a combination\nof direct focal length regression with a reprojection loss disentangling the\ncontribution of translation, rotation, and focal length leads to improved\nresults. Third, we explore the effect of different synthetic training data on\nthe performance of our method. Specifically, we investigate different\ndistributions used for sampling object's 6D pose and camera's focal length when\nrendering the synthetic images, and show that parametric distribution fitted on\nreal training data works the best. We show results on three challenging\nbenchmark datasets that depict known 3D models in uncontrolled settings. We\ndemonstrate that our focal length and 6D pose estimates have lower error than\nthe existing state-of-the-art methods.",
            "author": [
                "Martin C\u00edfka",
                "Georgy Ponimatkin",
                "Yann Labb\u00e9",
                "Bryan Russell",
                "Mathieu Aubry",
                "Vladimir Petrik",
                "Josef Sivic"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02985v1",
                "http://arxiv.org/pdf/2312.02985v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08943v1",
            "title": "Safety, Trust, and Ethics Considerations for Human-AI Teaming in\n  Aerospace Control",
            "updated": "2023-11-15T13:27:32Z",
            "published": "2023-11-15T13:27:32Z",
            "summary": "Designing a safe, trusted, and ethical AI may be practically impossible;\nhowever, designing AI with safe, trusted, and ethical use in mind is possible\nand necessary in safety and mission-critical domains like aerospace. Safe,\ntrusted, and ethical use of AI are often used interchangeably; however, a\nsystem can be safely used but not trusted or ethical, have a trusted use that\nis not safe or ethical, and have an ethical use that is not safe or trusted.\nThis manuscript serves as a primer to illuminate the nuanced differences\nbetween these concepts, with a specific focus on applications of Human-AI\nteaming in aerospace system control, where humans may be in, on, or\nout-of-the-loop of decision-making.",
            "author": [
                "Kerianne L. Hobbs",
                "Bernard Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08943v1",
                "http://arxiv.org/pdf/2311.08943v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08941v1",
            "title": "Reasoning over Description Logic-based Contexts with Transformers",
            "updated": "2023-11-15T13:23:24Z",
            "published": "2023-11-15T13:23:24Z",
            "summary": "One way that the current state of the art measures the reasoning ability of\ntransformer-based models is by evaluating accuracy in downstream tasks like\nlogical question answering or proof generation over synthetic contexts\nexpressed in natural language. However, most of the contexts used are in\npractice very simple; in most cases, they are generated from short first-order\nlogic sentences with only a few logical operators and quantifiers. In this\nwork, we seek to answer the question how well a transformer-based model will\nperform reasoning over expressive contexts. For this purpose, we construct a\nsynthetic natural language question-answering dataset, generated by description\nlogic knowledge bases. For the generation of the knowledge bases, we use the\nexpressive language $\\mathcal{ALCQ}$. The resulting dataset contains 384K\nexamples, and increases in two dimensions: i) reasoning depth, and ii) length\nof sentences. We show that the performance of our DeBERTa-based model,\nDELTA$_M$, is marginally affected when the reasoning depth is increased and it\nis not affected at all when the length of the sentences is increasing. We also\nevaluate the generalization ability of the model on reasoning depths unseen at\ntraining, both increasing and decreasing, revealing interesting insights into\nthe model's adaptive generalization abilities.",
            "author": [
                "Angelos Poulis",
                "Eleni Tsalapati",
                "Manolis Koubarakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08941v1",
                "http://arxiv.org/pdf/2311.08941v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08936v2",
            "title": "Confident Naturalness Explanation (CNE): A Framework to Explain and\n  Assess Patterns Forming Naturalness",
            "updated": "2023-11-22T14:25:55Z",
            "published": "2023-11-15T13:19:02Z",
            "summary": "Protected natural areas are regions that have been minimally affected by\nhuman activities such as urbanization, agriculture, and other human\ninterventions. To better understand and map the naturalness of these areas,\nmachine learning models can be used to analyze satellite imagery. Specifically,\nexplainable machine learning methods show promise in uncovering patterns that\ncontribute to the concept of naturalness within these protected environments.\nAdditionally, addressing the uncertainty inherent in machine learning models is\ncrucial for a comprehensive understanding of this concept. However, existing\napproaches have limitations. They either fail to provide explanations that are\nboth valid and objective or struggle to offer a quantitative metric that\naccurately measures the contribution of specific patterns to naturalness, along\nwith the associated confidence. In this paper, we propose a novel framework\ncalled the Confident Naturalness Explanation (CNE) framework. This framework\ncombines explainable machine learning and uncertainty quantification to assess\nand explain naturalness. We introduce a new quantitative metric that describes\nthe confident contribution of patterns to the concept of naturalness.\nFurthermore, we generate an uncertainty-aware segmentation mask for each input\nsample, highlighting areas where the model lacks knowledge. To demonstrate the\neffectiveness of our framework, we apply it to a study site in Fennoscandia\nusing two open-source satellite datasets.",
            "author": [
                "Ahmed Emam",
                "Mohamed Farag",
                "Ribana Roscher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08936v2",
                "http://arxiv.org/pdf/2311.08936v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08934v1",
            "title": "Combining Shamir & Additive Secret Sharing to Improve Efficiency of SMC\n  Primitives Against Malicious Adversaries",
            "updated": "2023-11-15T13:15:55Z",
            "published": "2023-11-15T13:15:55Z",
            "summary": "Secure multi-party computation provides a wide array of protocols for\nmutually distrustful parties be able to securely evaluate functions of private\ninputs. Within recent years, many such protocols have been proposed\nrepresenting a plethora of strategies to securely and efficiently handle such\ncomputation. These protocols have become increasingly efficient, but their\nperformance still is impractical in many settings. We propose new approaches to\nsome of these problems which are either more efficient than previous works\nwithin the same security models or offer better security guarantees with\ncomparable efficiency. The goals of this research are to improve efficiency and\nsecurity of secure multi-party protocols and explore the application of such\napproaches to novel threat scenarios. Some of the novel optimizations employed\nare dynamically switching domains of shared secrets, asymmetric computations,\nand advantageous functional transformations, among others. Specifically, this\nwork presents a novel combination of Shamir and Additive secret sharing to be\nused in parallel which allows for the transformation of efficient protocols\nsecure against passive adversaries to be secure against active adversaries.\nFrom this set of primitives we propose the construction of a comparison\nprotocol which can be implemented under that approach with a complexity which\nis more efficient than other recent works for common domains of interest.\nFinally, we present a system which addresses a critical security threat for the\nprotection and obfuscation of information which may be of high consequence.",
            "author": [
                "Kenneth Goss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08934v1",
                "http://arxiv.org/pdf/2311.08934v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08931v1",
            "title": "Structural-Based Uncertainty in Deep Learning Across Anatomical Scales:\n  Analysis in White Matter Lesion Segmentation",
            "updated": "2023-11-15T13:04:57Z",
            "published": "2023-11-15T13:04:57Z",
            "summary": "This paper explores uncertainty quantification (UQ) as an indicator of the\ntrustworthiness of automated deep-learning (DL) tools in the context of white\nmatter lesion (WML) segmentation from magnetic resonance imaging (MRI) scans of\nmultiple sclerosis (MS) patients. Our study focuses on two principal aspects of\nuncertainty in structured output segmentation tasks. Firstly, we postulate that\na good uncertainty measure should indicate predictions likely to be incorrect\nwith high uncertainty values. Second, we investigate the merit of quantifying\nuncertainty at different anatomical scales (voxel, lesion, or patient). We\nhypothesize that uncertainty at each scale is related to specific types of\nerrors. Our study aims to confirm this relationship by conducting separate\nanalyses for in-domain and out-of-domain settings. Our primary methodological\ncontributions are (i) the development of novel measures for quantifying\nuncertainty at lesion and patient scales, derived from structural prediction\ndiscrepancies, and (ii) the extension of an error retention curve analysis\nframework to facilitate the evaluation of UQ performance at both lesion and\npatient scales. The results from a multi-centric MRI dataset of 172 patients\ndemonstrate that our proposed measures more effectively capture model errors at\nthe lesion and patient scales compared to measures that average voxel-scale\nuncertainty values. We provide the UQ protocols code at\nhttps://github.com/Medical-Image-Analysis-Laboratory/MS_WML_uncs.",
            "author": [
                "Nataliia Molchanova",
                "Vatsal Raina",
                "Andrey Malinin",
                "Francesco La Rosa",
                "Adrien Depeursinge",
                "Mark Gales",
                "Cristina Granziera",
                "Henning Muller",
                "Mara Graziani",
                "Meritxell Bach Cuadra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08931v1",
                "http://arxiv.org/pdf/2311.08931v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08927v1",
            "title": "Introducing CHAD -- An ADM1 Solver for Direct Linking to Lagrangian CFD\n  Software",
            "updated": "2023-11-15T12:57:23Z",
            "published": "2023-11-15T12:57:23Z",
            "summary": "Standard methods for modeling anaerobic digestion processes assume\nhomogeneous conditions inside the tank and thus suffer from the negligence of\nhydrodynamics. In this work, we present the software toolbox Coupled\nHydrodynamics and Anaerobic Digestion (CHAD), a novel parallelized solver that\nis capable of utilizing CFD results as the basis for Anaerobic digestion model\nNo.1 (ADMno1) simulations. CHAD uses a particle-based Lagrangian CFD solver\ni.e., DualSPHysics (DSPH) as input and provides for a parallelized, C++ code\nimplementation of the standard ADMno1. This paper demonstrates a conceptual and\nnumerical verification of the toolbox and outlines the future pathway to\nenhance the approach.",
            "author": [
                "Prashant Kumar",
                "Zhenghao Yan",
                "Soroush Dabiri",
                "Nikolaus Rauch",
                "Wolfgang Rauch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08927v1",
                "http://arxiv.org/pdf/2311.08927v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "physics.flu-dyn",
                "I.6.5; G.1.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08923v1",
            "title": "Leveraging Activation Maximization and Generative Adversarial Training\n  to Recognize and Explain Patterns in Natural Areas in Satellite Imagery",
            "updated": "2023-11-15T12:55:19Z",
            "published": "2023-11-15T12:55:19Z",
            "summary": "Natural protected areas are vital for biodiversity, climate change\nmitigation, and supporting ecological processes. Despite their significance,\ncomprehensive mapping is hindered by a lack of understanding of their\ncharacteristics and a missing land cover class definition. This paper aims to\nadvance the explanation of the designating patterns forming protected and wild\nareas. To this end, we propose a novel framework that uses activation\nmaximization and a generative adversarial model. With this, we aim to generate\nsatellite images that, in combination with domain knowledge, are capable of\noffering complete and valid explanations for the spatial and spectral patterns\nthat define the natural authenticity of these regions. Our proposed framework\nproduces more precise attribution maps pinpointing the designating patterns\nforming the natural authenticity of protected areas. Our approach fosters our\nunderstanding of the ecological integrity of the protected natural areas and\nmay contribute to future monitoring and preservation efforts.",
            "author": [
                "Ahmed Emam",
                "Timo T. Stomberg",
                "Ribana Roscher"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LGRS.2023.3335473",
                "http://arxiv.org/abs/2311.08923v1",
                "http://arxiv.org/pdf/2311.08923v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08921v1",
            "title": "Self-Improving for Zero-Shot Named Entity Recognition with Large\n  Language Models",
            "updated": "2023-11-15T12:47:52Z",
            "published": "2023-11-15T12:47:52Z",
            "summary": "Exploring the application of powerful large language models (LLMs) on the\nfundamental named entity recognition (NER) task has drawn much attention\nrecently. This work aims to investigate the possibilities of pushing the\nboundary of zero-shot NER with LLM via a training-free self-improving strategy.\nWe propose a self-improving framework, which utilize an unlabeled corpus to\nstimulate the self-learning ability of LLMs on NER. First, we use LLM to make\npredictions on the unlabeled corpus and obtain the self-annotated data. Second,\nwe explore various strategies to select reliable samples from the\nself-annotated dataset as demonstrations, considering the similarity, diversity\nand reliability of demonstrations. Finally, we conduct inference for the test\nquery via in-context learning with the selected self-annotated demonstrations.\nThrough comprehensive experimental analysis, our study yielded the following\nfindings: (1) The self-improving framework further pushes the boundary of\nzero-shot NER with LLMs, and achieves an obvious performance improvement; (2)\nIterative self-improving or naively increasing the size of unlabeled corpus\ndoes not guarantee improvements; (3) There might still be space for improvement\nvia more advanced strategy for reliable entity selection.",
            "author": [
                "Tingyu Xie",
                "Qi Li",
                "Yan Zhang",
                "Zuozhu Liu",
                "Hongwei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08921v1",
                "http://arxiv.org/pdf/2311.08921v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08912v1",
            "title": "Concave Toric Domains in Stark-type Mechanical Systems",
            "updated": "2023-11-15T12:36:06Z",
            "published": "2023-11-15T12:36:06Z",
            "summary": "It has been shown in [Frauenfelder, 2023] that the bounded component of the\nenergy surface of the planer Stark problem after the Levi-Civita transformation\nare concave toric domains. In this paper, we present a different approach on\nthe problem of determining concave toric domains in a family of integrable\nnatural mechanical problems in the plane based on the computation of\naction-variables. We give criteria on the potentials for the bounded components\nof the energy hypersurfaces to be concave toric domains and apply these\ncriteria to a class of problems.",
            "author": [
                "Airi Takeuchi",
                "Lei Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08912v1",
                "http://arxiv.org/pdf/2311.08912v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08911v1",
            "title": "Connection Incentives in Cost Sharing Mechanisms with Budgets",
            "updated": "2023-11-15T12:34:19Z",
            "published": "2023-11-15T12:34:19Z",
            "summary": "In a cost sharing problem on a weighted undirected graph, all other nodes\nwant to connect to the source node for some service. Each edge has a cost\ndenoted by a weight and all the connected nodes should share the total cost for\nthe connectivity. The goal of the existing solutions (e.g. folk solution and\ncycle-complete solution) is to design cost sharing rules with nice properties,\ne.g. budget balance and cost monotonicity. However, they did not consider the\ncases that each non-source node has a budget which is the maximum it can pay\nfor its cost share and may cut its adjacent edges to reduce its cost share. In\nthis paper, we design two cost sharing mechanisms taking into account the\nnodes' budgets and incentivizing all nodes to report all their adjacent edges\nso that we can minimize the total cost for the connectivity.",
            "author": [
                "Tianyi Zhang",
                "Dengji Zhao",
                "Junyu Zhang",
                "Sizhe Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08911v1",
                "http://arxiv.org/pdf/2311.08911v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08910v1",
            "title": "Progressive Feedback-Enhanced Transformer for Image Forgery Localization",
            "updated": "2023-11-15T12:31:43Z",
            "published": "2023-11-15T12:31:43Z",
            "summary": "Blind detection of the forged regions in digital images is an effective\nauthentication means to counter the malicious use of local image editing\ntechniques. Existing encoder-decoder forensic networks overlook the fact that\ndetecting complex and subtle tampered regions typically requires more feedback\ninformation. In this paper, we propose a Progressive FeedbACk-enhanced\nTransformer (ProFact) network to achieve coarse-to-fine image forgery\nlocalization. Specifically, the coarse localization map generated by an initial\nbranch network is adaptively fed back to the early transformer encoder layers\nfor enhancing the representation of positive features while suppressing\ninterference factors. The cascaded transformer network, combined with a\ncontextual spatial pyramid module, is designed to refine discriminative\nforensic features for improving the forgery localization accuracy and\nreliability. Furthermore, we present an effective strategy to automatically\ngenerate large-scale forged image samples close to real-world forensic\nscenarios, especially in realistic and coherent processing. Leveraging on such\nsamples, a progressive and cost-effective two-stage training protocol is\napplied to the ProFact network. The extensive experimental results on nine\npublic forensic datasets show that our proposed localizer greatly outperforms\nthe state-of-the-art on the generalization ability and robustness of image\nforgery localization. Code will be publicly available at\nhttps://github.com/multimediaFor/ProFact.",
            "author": [
                "Haochen Zhu",
                "Gang Cao",
                "Xianglin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08910v1",
                "http://arxiv.org/pdf/2311.08910v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08909v1",
            "title": "DLAS: An Exploration and Assessment of the Deep Learning Acceleration\n  Stack",
            "updated": "2023-11-15T12:26:31Z",
            "published": "2023-11-15T12:26:31Z",
            "summary": "Deep Neural Networks (DNNs) are extremely computationally demanding, which\npresents a large barrier to their deployment on resource-constrained devices.\nSince such devices are where many emerging deep learning applications lie\n(e.g., drones, vision-based medical technology), significant bodies of work\nfrom both the machine learning and systems communities have attempted to\nprovide optimizations to accelerate DNNs. To help unify these two perspectives,\nin this paper we combine machine learning and systems techniques within the\nDeep Learning Acceleration Stack (DLAS), and demonstrate how these layers can\nbe tightly dependent on each other with an across-stack perturbation study. We\nevaluate the impact on accuracy and inference time when varying different\nparameters of DLAS across two datasets, seven popular DNN architectures, four\nDNN compression techniques, three algorithmic primitives with sparse and dense\nvariants, untuned and auto-scheduled code generation, and four hardware\nplatforms. Our evaluation highlights how perturbations across DLAS parameters\ncan cause significant variation and across-stack interactions. The highest\nlevel observation from our evaluation is that the model size, accuracy, and\ninference time are not guaranteed to be correlated. Overall we make 13 key\nobservations, including that speedups provided by compression techniques are\nvery hardware dependent, and that compiler auto-tuning can significantly alter\nwhat the best algorithm to use for a given configuration is. With DLAS, we aim\nto provide a reference framework to aid machine learning and systems\npractitioners in reasoning about the context in which their respective DNN\nacceleration solutions exist in. With our evaluation strongly motivating the\nneed for co-design, we believe that DLAS can be a valuable concept for\nexploring the next generation of co-designed accelerated deep learning\nsolutions.",
            "author": [
                "Perry Gibson",
                "Jos\u00e9 Cano",
                "Elliot J. Crowley",
                "Amos Storkey",
                "Michael O'Boyle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08909v1",
                "http://arxiv.org/pdf/2311.08909v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08908v1",
            "title": "Robust Brain MRI Image Classification with SIBOW-SVM",
            "updated": "2023-11-15T12:26:24Z",
            "published": "2023-11-15T12:26:24Z",
            "summary": "The majority of primary Central Nervous System (CNS) tumors in the brain are\namong the most aggressive diseases affecting humans. Early detection of brain\ntumor types, whether benign or malignant, glial or non-glial, is critical for\ncancer prevention and treatment, ultimately improving human life expectancy.\nMagnetic Resonance Imaging (MRI) stands as the most effective technique to\ndetect brain tumors by generating comprehensive brain images through scans.\nHowever, human examination can be error-prone and inefficient due to the\ncomplexity, size, and location variability of brain tumors. Recently, automated\nclassification techniques using machine learning (ML) methods, such as\nConvolutional Neural Network (CNN), have demonstrated significantly higher\naccuracy than manual screening, while maintaining low computational costs.\nNonetheless, deep learning-based image classification methods, including CNN,\nface challenges in estimating class probabilities without proper model\ncalibration. In this paper, we propose a novel brain tumor image classification\nmethod, called SIBOW-SVM, which integrates the Bag-of-Features (BoF) model with\nSIFT feature extraction and weighted Support Vector Machines (wSVMs). This new\napproach effectively captures hidden image features, enabling the\ndifferentiation of various tumor types and accurate label predictions.\nAdditionally, the SIBOW-SVM is able to estimate the probabilities of images\nbelonging to each class, thereby providing high-confidence classification\ndecisions. We have also developed scalable and parallelable algorithms to\nfacilitate the practical implementation of SIBOW-SVM for massive images. As a\nbenchmark, we apply the SIBOW-SVM to a public data set of brain tumor MRI\nimages containing four classes: glioma, meningioma, pituitary, and normal. Our\nresults show that the new method outperforms state-of-the-art methods,\nincluding CNN.",
            "author": [
                "Liyun Zeng",
                "Hao Helen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08908v1",
                "http://arxiv.org/pdf/2311.08908v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08904v1",
            "title": "Energy-Efficient Design of Satellite-Terrestrial Computing in 6G\n  Wireless Networks",
            "updated": "2023-11-15T12:21:25Z",
            "published": "2023-11-15T12:21:25Z",
            "summary": "In this paper, we investigate the issue of satellite-terrestrial computing in\nthe sixth generation (6G) wireless networks, where multiple terrestrial base\nstations (BSs) and low earth orbit (LEO) satellites collaboratively provide\nedge computing services to ground user equipments (GUEs) and space user\nequipments (SUEs) over the world. In particular, we design a complete process\nof satellite-terrestrial computing in terms of communication and computing\naccording to the characteristics of 6G wireless networks. In order to minimize\nthe weighted total energy consumption while ensuring delay requirements of\ncomputing tasks, an energy-efficient satellite-terrestrial computing algorithm\nis put forward by jointly optimizing offloading selection, beamforming design\nand resource allocation. Finally, both theoretical analysis and simulation\nresults confirm fast convergence and superior performance of the proposed\nalgorithm for satellite-terrestrial computing in 6G wireless networks.",
            "author": [
                "Qi Wang",
                "Xiaoming Chen",
                "Qiao Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08904v1",
                "http://arxiv.org/pdf/2311.08904v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08903v1",
            "title": "Cost Sharing under Private Costs and Connection Control on Directed\n  Acyclic Graphs",
            "updated": "2023-11-15T12:19:52Z",
            "published": "2023-11-15T12:19:52Z",
            "summary": "We consider a cost sharing problem on a weighted directed acyclic graph (DAG)\nwith a source node to which all the other nodes want to connect. The cost\n(weight) of each edge is private information reported by multiple contractors,\nand among them, only one contractor is selected as the builder. All the nodes\nexcept for the source need to share the total cost of the used edges. However,\nthey may block others' connections to the source by strategically cutting their\noutgoing edges to reduce their cost share, which may increase the total cost of\nconnectivity. To minimize the total cost of connectivity, we design a cost\nsharing mechanism to incentivize each node to offer all its outgoing edges and\neach contractor to report all the edges' weights truthfully, and show the\nproperties of the proposed mechanism. In addition, our mechanism outperforms\nthe two benchmark mechanisms.",
            "author": [
                "Tianyi Zhang",
                "Dengji Zhao",
                "Junyu Zhang",
                "Sizhe Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08903v1",
                "http://arxiv.org/pdf/2311.08903v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09270v1",
            "title": "FedCode: Communication-Efficient Federated Learning via Transferring\n  Codebooks",
            "updated": "2023-11-15T12:06:32Z",
            "published": "2023-11-15T12:06:32Z",
            "summary": "Federated Learning (FL) is a distributed machine learning paradigm that\nenables learning models from decentralized local data. While FL offers\nappealing properties for clients' data privacy, it imposes high communication\nburdens for exchanging model weights between a server and the clients. Existing\napproaches rely on model compression techniques, such as pruning and weight\nclustering to tackle this. However, transmitting the entire set of weight\nupdates at each federated round, even in a compressed format, limits the\npotential for a substantial reduction in communication volume. We propose\nFedCode where clients transmit only codebooks, i.e., the cluster centers of\nupdated model weight values. To ensure a smooth learning curve and proper\ncalibration of clusters between the server and the clients, FedCode\nperiodically transfers model weights after multiple rounds of solely\ncommunicating codebooks. This results in a significant reduction in\ncommunication volume between clients and the server in both directions, without\nimposing significant computational overhead on the clients or leading to major\nperformance degradation of the models. We evaluate the effectiveness of FedCode\nusing various publicly available datasets with ResNet-20 and MobileNet backbone\nmodel architectures. Our evaluations demonstrate a 12.2-fold data transmission\nreduction on average while maintaining a comparable model performance with an\naverage accuracy loss of 1.3% compared to FedAvg. Further validation of FedCode\nperformance under non-IID data distributions showcased an average accuracy loss\nof 2.0% compared to FedAvg while achieving approximately a 12.7-fold data\ntransmission reduction.",
            "author": [
                "Saeed Khalilian",
                "Vasileios Tsouvalas",
                "Tanir Ozcelebi",
                "Nirvana Meratnia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09270v1",
                "http://arxiv.org/pdf/2311.09270v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09269v1",
            "title": "NormNet: Scale Normalization for 6D Pose Estimation in Stacked Scenarios",
            "updated": "2023-11-15T12:02:57Z",
            "published": "2023-11-15T12:02:57Z",
            "summary": "Existing Object Pose Estimation (OPE) methods for stacked scenarios are not\nrobust to changes in object scale. This paper proposes a new 6DoF OPE network\n(NormNet) for different scale objects in stacked scenarios. Specifically, each\nobject's scale is first learned with point-wise regression. Then, all objects\nin the stacked scenario are normalized into the same scale through semantic\nsegmentation and affine transformation. Finally, they are fed into a shared\npose estimator to recover their 6D poses. In addition, we introduce a new\nSim-to-Real transfer pipeline, combining style transfer and domain\nrandomization. This improves the NormNet's performance on real data even if we\nonly train it on synthetic data. Extensive experiments demonstrate that the\nproposed method achieves state-of-the-art performance on public benchmarks and\nthe MultiScale dataset we constructed. The real-world experiments show that our\nmethod can robustly estimate the 6D pose of objects at different scales.",
            "author": [
                "En-Te Lin",
                "Wei-Jie Lv",
                "Ding-Tao Huang",
                "Long Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09269v1",
                "http://arxiv.org/pdf/2311.09269v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08896v1",
            "title": "HELLaMA: LLaMA-based Table to Text Generation by Highlighting the\n  Important Evidence",
            "updated": "2023-11-15T12:02:52Z",
            "published": "2023-11-15T12:02:52Z",
            "summary": "Large models have demonstrated significant progress across various domains,\nparticularly in tasks related to text generation. In the domain of Table to\nText, many Large Language Model (LLM)-based methods currently resort to\nmodifying prompts to invoke public APIs, incurring potential costs and\ninformation leaks. With the advent of open-source large models, fine-tuning\nLLMs has become feasible. In this study, we conducted parameter-efficient\nfine-tuning on the LLaMA2 model. Distinguishing itself from previous\nfine-tuning-based table-to-text methods, our approach involves injecting\nreasoning information into the input by emphasizing table-specific row data.\nOur model consists of two modules: 1) a table reasoner that identifies relevant\nrow evidence, and 2) a table summarizer that generates sentences based on the\nhighlighted table. To facilitate this, we propose a search strategy to\nconstruct reasoning labels for training the table reasoner. On both the FetaQA\nand QTSumm datasets, our approach achieved state-of-the-art results.\nAdditionally, we observed that highlighting input tables significantly enhances\nthe model's performance and provides valuable interpretability.",
            "author": [
                "Junyi Bian",
                "Xiaolei Qin",
                "Wuhe Zou",
                "Mengzuo Huang",
                "Weidong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08896v1",
                "http://arxiv.org/pdf/2311.08896v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08894v1",
            "title": "Combining Transfer Learning with In-context Learning using Blackbox LLMs\n  for Zero-shot Knowledge Base Question Answering",
            "updated": "2023-11-15T11:56:56Z",
            "published": "2023-11-15T11:56:56Z",
            "summary": "We address the zero-shot transfer learning setting for the knowledge base\nquestion answering (KBQA) problem, where a large volume of labeled training\ndata is available for the source domain, but no such labeled examples are\navailable for the target domain. Transfer learning for KBQA makes use of large\nvolumes of unlabeled data in the target in addition to the labeled data in the\nsource. More recently, few-shot in-context learning using Black-box Large\nLanguage Models (BLLMs) has been adapted for KBQA without considering any\nsource domain data. In this work, we show how to meaningfully combine these two\nparadigms for KBQA so that their benefits add up. Specifically, we preserve the\ntwo stage retrieve-then-generate pipeline of supervised KBQA and introduce\ninteraction between in-context learning using BLLMs and transfer learning from\nthe source for both stages. In addition, we propose execution-guided\nself-refinement using BLLMs, decoupled from the transfer setting. With the help\nof experiments using benchmark datasets GrailQA as the source and WebQSP as the\ntarget, we show that the proposed combination brings significant improvements\nto both stages and also outperforms by a large margin state-of-the-art\nsupervised KBQA models trained on the source. We also show that in the\nin-domain setting, the proposed BLLM augmentation significantly outperforms\nstate-of-the-art supervised models, when the volume of labeled data is limited,\nand also outperforms these marginally even when using the entire large training\ndataset.",
            "author": [
                "Mayur Patidar",
                "Avinash Singh",
                "Riya Sawhney",
                "Indrajit Bhattacharya",
                "Mausam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08894v1",
                "http://arxiv.org/pdf/2311.08894v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08891v1",
            "title": "AdapterShadow: Adapting Segment Anything Model for Shadow Detection",
            "updated": "2023-11-15T11:51:10Z",
            "published": "2023-11-15T11:51:10Z",
            "summary": "Segment anything model (SAM) has shown its spectacular performance in\nsegmenting universal objects, especially when elaborate prompts are provided.\nHowever, the drawback of SAM is twofold. On the first hand, it fails to segment\nspecific targets, e.g., shadow images or lesions in medical images. On the\nother hand, manually specifying prompts is extremely time-consuming. To\novercome the problems, we propose AdapterShadow, which adapts SAM model for\nshadow detection. To adapt SAM for shadow images, trainable adapters are\ninserted into the frozen image encoder of SAM, since the training of the full\nSAM model is both time and memory consuming. Moreover, we introduce a novel\ngrid sampling method to generate dense point prompts, which helps to\nautomatically segment shadows without any manual interventions. Extensive\nexperiments are conducted on four widely used benchmark datasets to demonstrate\nthe superior performance of our proposed method. Codes will are publicly\navailable at https://github.com/LeipingJie/AdapterShadow.",
            "author": [
                "Leiping Jie",
                "Hui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08891v1",
                "http://arxiv.org/pdf/2311.08891v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08890v1",
            "title": "Large Language Models are legal but they are not: Making the case for a\n  powerful LegalLLM",
            "updated": "2023-11-15T11:50:10Z",
            "published": "2023-11-15T11:50:10Z",
            "summary": "Realizing the recent advances in Natural Language Processing (NLP) to the\nlegal sector poses challenging problems such as extremely long sequence\nlengths, specialized vocabulary that is usually only understood by legal\nprofessionals, and high amounts of data imbalance. The recent surge of Large\nLanguage Models (LLMs) has begun to provide new opportunities to apply NLP in\nthe legal domain due to their ability to handle lengthy, complex sequences.\nMoreover, the emergence of domain-specific LLMs has displayed extremely\npromising results on various tasks. In this study, we aim to quantify how\ngeneral LLMs perform in comparison to legal-domain models (be it an LLM or\notherwise). Specifically, we compare the zero-shot performance of three\ngeneral-purpose LLMs (ChatGPT-20b, LLaMA-2-70b, and Falcon-180b) on the LEDGAR\nsubset of the LexGLUE benchmark for contract provision classification. Although\nthe LLMs were not explicitly trained on legal data, we observe that they are\nstill able to classify the theme correctly in most cases. However, we find that\ntheir mic-F1/mac-F1 performance is up to 19.2/26.8\\% lesser than smaller models\nfine-tuned on the legal domain, thus underscoring the need for more powerful\nlegal-domain LLMs.",
            "author": [
                "Thanmay Jayakumar",
                "Fauzan Farooqui",
                "Luqman Farooqui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08890v1",
                "http://arxiv.org/pdf/2311.08890v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08886v1",
            "title": "CLIMB: Curriculum Learning for Infant-inspired Model Building",
            "updated": "2023-11-15T11:48:16Z",
            "published": "2023-11-15T11:48:16Z",
            "summary": "We describe our team's contribution to the STRICT-SMALL track of the BabyLM\nChallenge. The challenge requires training a language model from scratch using\nonly a relatively small training dataset of ten million words. We experiment\nwith three variants of cognitively-motivated curriculum learning and analyze\ntheir effect on the performance of the model on linguistic evaluation tasks. In\nthe vocabulary curriculum, we analyze methods for constraining the vocabulary\nin the early stages of training to simulate cognitively more plausible learning\ncurves. In the data curriculum experiments, we vary the order of the training\ninstances based on i) infant-inspired expectations and ii) the learning\nbehavior of the model. In the objective curriculum, we explore different\nvariations of combining the conventional masked language modeling task with a\nmore coarse-grained word class prediction task to reinforce linguistic\ngeneralization capabilities. Our results did not yield consistent improvements\nover our own non-curriculum learning baseline across a range of linguistic\nbenchmarks; however, we do find marginal gains on select tasks. Our analysis\nhighlights key takeaways for specific combinations of tasks and settings which\nbenefit from our proposed curricula. We moreover determine that careful\nselection of model architecture, and training hyper-parameters yield\nsubstantial improvements over the default baselines provided by the BabyLM\nchallenge.",
            "author": [
                "Richard Diehl Martinez",
                "Zebulon Goriely",
                "Hope McGovern",
                "Christopher Davis",
                "Andrew Caines",
                "Paula Buttery",
                "Lisa Beinborn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08886v1",
                "http://arxiv.org/pdf/2311.08886v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08884v1",
            "title": "CREPE Notes: A new method for segmenting pitch contours into discrete\n  notes",
            "updated": "2023-11-15T11:43:48Z",
            "published": "2023-11-15T11:43:48Z",
            "summary": "Tracking the fundamental frequency (f0) of a monophonic instrumental\nperformance is effectively a solved problem with several solutions achieving\n99% accuracy. However, the related task of automatic music transcription\nrequires a further processing step to segment an f0 contour into discrete\nnotes. This sub-task of note segmentation is necessary to enable a range of\napplications including musicological analysis and symbolic music generation.\nBuilding on CREPE, a state-of-the-art monophonic pitch tracking solution based\non a simple neural network, we propose a simple and effective method for\npost-processing CREPE's output to achieve monophonic note segmentation. The\nproposed method demonstrates state-of-the-art results on two challenging\ndatasets of monophonic instrumental music. Our approach also gives a 97%\nreduction in the total number of parameters used when compared with other deep\nlearning based methods.",
            "author": [
                "Xavier Riley",
                "Simon Dixon"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.8136568",
                "http://arxiv.org/abs/2311.08884v1",
                "http://arxiv.org/pdf/2311.08884v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08883v1",
            "title": "Enabling Large Language Models to Learn from Rules",
            "updated": "2023-11-15T11:42:41Z",
            "published": "2023-11-15T11:42:41Z",
            "summary": "Large language models (LLMs) have shown incredible performance in completing\nvarious real-world tasks. The current knowledge learning paradigm of LLMs is\nmainly based on learning from examples, in which LLMs learn the internal rule\nimplicitly from a certain number of supervised examples. However, the learning\nparadigm may not well learn those complicated rules, especially when the\ntraining examples are limited. We are inspired that humans can learn the new\ntasks or knowledge in another way by learning from rules. That is, humans can\ngrasp the new tasks or knowledge quickly and generalize well given only a\ndetailed rule and a few optional examples. Therefore, in this paper, we aim to\nexplore the feasibility of this new learning paradigm, which encodes the\nrule-based knowledge into LLMs. We propose rule distillation, which first uses\nthe strong in-context abilities of LLMs to extract the knowledge from the\ntextual rules and then explicitly encode the knowledge into LLMs' parameters by\nlearning from the above in-context signals produced inside the model. Our\nexperiments show that making LLMs learn from rules by our method is much more\nefficient than example-based learning in both the sample size and\ngeneralization ability.",
            "author": [
                "Wenkai Yang",
                "Yankai Lin",
                "Jie Zhou",
                "Jirong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08883v1",
                "http://arxiv.org/pdf/2311.08883v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08882v1",
            "title": "Identification of Causal Influences in Quantum Processes",
            "updated": "2023-11-15T11:41:18Z",
            "published": "2023-11-15T11:41:18Z",
            "summary": "Though the topic of causal inference is typically considered in the context\nof classical statistical models, recent years have seen great interest in\nextending causal inference techniques to quantum and generalized theories.\nCausal identification is a type of causal inference problem concerned with\nrecovering from observational data and qualitative assumptions the causal\nmechanisms generating the data, and hence the effects of hypothetical\ninterventions. A major obstacle to a theory of causal identification in the\nquantum setting is the question of what should play the role of \"observational\ndata,\" as any means of extracting data at a certain locus will almost certainly\ndisturb the system. Hence, one might think a priori that quantum measurements\nare already too much like interventions, so that the problem of causal\nidentification trivializes. This is not the case. Fixing a limited class of\nquantum instruments (namely the class of all projective measurements) to play\nthe role of \"observations,\" we note that as in the classical setting, there\nexist scenarios for which causal identification is not possible. We then\npresent sufficient conditions for quantum causal identification, starting with\na quantum analogue of the well-known \"front-door criterion\" and finishing with\na broader class of scenarios for which the effect of a single intervention is\nidentifiable. These results emerge from generalizing the process-theoretic\naccount of classical causal inference due to Jacobs, Kissinger, and Zanasi\nbeyond the setting of Markov categories, and thereby treating the classical and\nquantum problems uniformly.",
            "author": [
                "Isaac Friend",
                "Aleks Kissinger"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.394.7",
                "http://arxiv.org/abs/2311.08882v1",
                "http://arxiv.org/pdf/2311.08882v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08881v1",
            "title": "Reducing 2-QuBit Gate Count for ZX-Calculus based Quantum Circuit\n  Optimization",
            "updated": "2023-11-15T11:40:03Z",
            "published": "2023-11-15T11:40:03Z",
            "summary": "In the near term, programming quantum computers will remain severely limited\nby low quantum volumes. Therefore, it is desirable to implement quantum\ncircuits with the fewest resources possible. For the common Clifford+T\ncircuits, most research is focused on reducing the number of T gates, since\nthey are an order of magnitude more expensive than Clifford gates in quantum\nerror corrected encoding schemes. However, this optimization sometimes leads to\nmore 2-qubit gates, which, even though they are less expensive in terms of\nfault-tolerance, contribute significantly to the overall circuit cost.\nApproaches based on the ZX-calculus have recently gained some popularity in the\nfield, but reduction of 2-qubit gates is not their focus. In this work, we\npresent an alternative for improving 2-qubit gate count of a quantum circuit\nwith the ZX-calculus by using heuristics in ZX-diagram simplification. Our\napproach maintains the good reduction of the T gate count provided by other\nstrategies based on ZX-calculus, thus serving as an extension for other\noptimization algorithms. Our results show that combining the available\nZX-calculus-based optimizations with our algorithms can reduce the number of\n2-qubit gates by as much as 40% compared to current approaches using\nZX-calculus. Additionally, we improve the results of the best currently\navailable optimization technique of Nam et. al for some circuits by up to 15%.",
            "author": [
                "Korbinian Staudacher",
                "Tobias Guggemos",
                "Sophia Grundner-Culemann",
                "Wolfgang Gehrke"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.394.3",
                "http://arxiv.org/abs/2311.08881v1",
                "http://arxiv.org/pdf/2311.08881v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10767v1",
            "title": "Optimizing IaC Configurations: a Case Study Using Nature-inspired\n  Computing",
            "updated": "2023-11-15T11:28:00Z",
            "published": "2023-11-15T11:28:00Z",
            "summary": "In the last years, one of the fields of artificial intelligence that has been\ninvestigated the most is nature-inspired computing. The research done on this\nspecific topic showcases the interest that sparks in researchers and\npractitioners, who put their focus on this paradigm because of the adaptability\nand ability of nature-inspired algorithms to reach high-quality outcomes on a\nwide range of problems. In fact, this kind of methods has been successfully\napplied to solve real-world problems in heterogeneous fields such as medicine,\ntransportation, industry, or software engineering. Our main objective with this\npaper is to describe a tool based on nature-inspired computing for solving a\nspecific software engineering problem. The problem faced consists of optimizing\nInfrastructure as Code deployment configurations. For this reason, the name of\nthe system is IaC Optimizer Platform. A prototypical version of the IOP was\ndescribed in previous works, in which the functionality of this platform was\nintroduced. With this paper, we take a step forward by describing the final\nrelease of the IOP, highlighting its main contribution regarding the current\nstate-of-the-art, and justifying the decisions made on its implementation.\nAlso, we contextualize the IOP within the complete platform in which it is\nembedded, describing how a user can benefit from its use. To do that, we also\npresent and solve a real-world use case.",
            "author": [
                "Eneko Osaba",
                "Gorka Benguria",
                "Jesus L. Lobo",
                "Josu Diaz-de-Arcaya",
                "Juncal Alonso",
                "I\u00f1aki Etxaniz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10767v1",
                "http://arxiv.org/pdf/2311.10767v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08877v1",
            "title": "Llamas Know What GPTs Don't Show: Surrogate Models for Confidence\n  Estimation",
            "updated": "2023-11-15T11:27:44Z",
            "published": "2023-11-15T11:27:44Z",
            "summary": "To maintain user trust, large language models (LLMs) should signal low\nconfidence on examples where they are incorrect, instead of misleading the\nuser. The standard approach of estimating confidence is to use the softmax\nprobabilities of these models, but as of November 2023, state-of-the-art LLMs\nsuch as GPT-4 and Claude-v1.3 do not provide access to these probabilities. We\nfirst study eliciting confidence linguistically -- asking an LLM for its\nconfidence in its answer -- which performs reasonably (80.5% AUC on GPT-4\naveraged across 12 question-answering datasets -- 7% above a random baseline)\nbut leaves room for improvement. We then explore using a surrogate confidence\nmodel -- using a model where we do have probabilities to evaluate the original\nmodel's confidence in a given question. Surprisingly, even though these\nprobabilities come from a different and often weaker model, this method leads\nto higher AUC than linguistic confidences on 9 out of 12 datasets. Our best\nmethod composing linguistic confidences and surrogate model probabilities gives\nstate-of-the-art confidence estimates on all 12 datasets (84.6% average AUC on\nGPT-4).",
            "author": [
                "Vaishnavi Shrivastava",
                "Percy Liang",
                "Ananya Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08877v1",
                "http://arxiv.org/pdf/2311.08877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08870v2",
            "title": "One-Shot Federated Learning with Classifier-Guided Diffusion Models",
            "updated": "2023-11-16T15:43:52Z",
            "published": "2023-11-15T11:11:25Z",
            "summary": "One-shot federated learning (OSFL) has gained attention in recent years due\nto its low communication cost. However, most of the existing methods require\nauxiliary datasets or training generators, which hinders their practicality in\nreal-world scenarios. In this paper, we explore the novel opportunities that\ndiffusion models bring to OSFL and propose FedCADO, utilizing guidance from\nclient classifiers to generate data that complies with clients' distributions\nand subsequently training the aggregated model on the server. Specifically, our\nmethod involves targeted optimizations in two aspects. On one hand, we\nconditionally edit the randomly sampled initial noises, embedding them with\nspecified semantics and distributions, resulting in a significant improvement\nin both the quality and stability of generation. On the other hand, we employ\nthe BN statistics from the classifiers to provide detailed guidance during\ngeneration. These tailored optimizations enable us to limitlessly generate\ndatasets, which closely resemble the distribution and quality of the original\nclient dataset. Our method effectively handles the heterogeneous client models\nand the problems of non-IID features or labels. In terms of privacy protection,\nour method avoids training any generator or transferring any auxiliary\ninformation on clients, eliminating any additional privacy leakage risks.\nLeveraging the extensive knowledge stored in the pre-trained diffusion model,\nthe synthetic datasets can assist us in surpassing the knowledge limitations of\nthe client samples, resulting in aggregation models that even outperform the\nperformance ceiling of centralized training in some cases, which is\nconvincingly demonstrated in the sufficient quantification and visualization\nexperiments conducted on three large-scale multi-domain image datasets.",
            "author": [
                "Mingzhao Yang",
                "Shangchao Su",
                "Bin Li",
                "Xiangyang Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08870v2",
                "http://arxiv.org/pdf/2311.08870v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08867v1",
            "title": "Gigahertz-rate-switchable wavefront shaping through integration of\n  metasurfaces with photonic integrated circuit",
            "updated": "2023-11-15T11:02:12Z",
            "published": "2023-11-15T11:02:12Z",
            "summary": "Achieving spatiotemporal control of light at high-speeds presents immense\npossibilities for various applications in communication, computation,\nmetrology, and sensing. The integration of subwavelength metasurfaces and\noptical waveguides offers a promising approach to manipulate light across\nmultiple degrees of freedom at high-speed in compact photonic integrated\ncircuit (PICs) devices. Here, we demonstrate a gigahertz-rate-switchable\nwavefront shaping by integrating metasurface, lithium niobite on insulator\n(LNOI) photonic waveguide and electrodes within a PIC device. As proofs of\nconcept, we showcase the generation of a focus beam with reconfigurable\narbitrary polarizations, switchable focusing with lateral focal positions and\nfocal length, orbital angular momentum light beams (OAMs) as well as Bessel\nbeams. Our measurements indicate modulation speeds of up to gigahertz rate.\nThis integrated platform offers a versatile and efficient means of controlling\nlight field at high-speed within a compact system, paving the way for potential\napplications in optical communication, computation, sensing, and imaging.",
            "author": [
                "Haozong Zhong",
                "Yong Zheng",
                "Jiacheng Sun",
                "Zhizhang Wang",
                "b Rongbo Wu",
                "Ling-en Zhang",
                "Youting Liang",
                "Qinyi Hua",
                "Minghao Ning",
                "Jitao Ji",
                "Bin Fang",
                "Lin Li",
                "Tao Li",
                "Ya Cheng",
                "Shining Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08867v1",
                "http://arxiv.org/pdf/2311.08867v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08863v1",
            "title": "Toulouse Hyperspectral Data Set: a benchmark data set to assess\n  semi-supervised spectral representation learning and pixel-wise\n  classification techniques",
            "updated": "2023-11-15T10:49:15Z",
            "published": "2023-11-15T10:49:15Z",
            "summary": "Airborne hyperspectral images can be used to map the land cover in large\nurban areas, thanks to their very high spatial and spectral resolutions on a\nwide spectral domain. While the spectral dimension of hyperspectral images is\nhighly informative of the chemical composition of the land surface, the use of\nstate-of-the-art machine learning algorithms to map the land cover has been\ndramatically limited by the availability of training data. To cope with the\nscarcity of annotations, semi-supervised and self-supervised techniques have\nlately raised a lot of interest in the community. Yet, the publicly available\nhyperspectral data sets commonly used to benchmark machine learning models are\nnot totally suited to evaluate their generalization performances due to one or\nseveral of the following properties: a limited geographical coverage (which\ndoes not reflect the spectral diversity in metropolitan areas), a small number\nof land cover classes and a lack of appropriate standard train / test splits\nfor semi-supervised and self-supervised learning. Therefore, we release in this\npaper the Toulouse Hyperspectral Data Set that stands out from other data sets\nin the above-mentioned respects in order to meet key issues in spectral\nrepresentation learning and classification over large-scale hyperspectral\nimages with very few labeled pixels. Besides, we discuss and experiment the\nself-supervised task of Masked Autoencoders and establish a baseline for\npixel-wise classification based on a conventional autoencoder combined with a\nRandom Forest classifier achieving 82% overall accuracy and 74% F1 score. The\nToulouse Hyperspectral Data Set and our code are publicly available at\nhttps://www.toulouse-hyperspectral-data-set.com and\nhttps://www.github.com/Romain3Ch216/tlse-experiments, respectively.",
            "author": [
                "Romain Thoreau",
                "Laurent Risser",
                "V\u00e9ronique Achard",
                "B\u00e9atrice Berthelot",
                "Xavier Briottet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08863v1",
                "http://arxiv.org/pdf/2311.08863v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08862v1",
            "title": "Verification of a Rust Implementation of Knuth's Dancing Links using\n  ACL2",
            "updated": "2023-11-15T10:48:48Z",
            "published": "2023-11-15T10:48:48Z",
            "summary": "Dancing Links connotes an optimization to a circular doubly-linked list data\nstructure implementation which provides for fast list element removal and\nrestoration. The Dancing Links optimization is used primarily in fast\nalgorithms to find exact covers, and has been popularized by Knuth in Volume 4B\nof his seminal series The Art of Computer Programming. We describe an\nimplementation of the Dancing Links optimization in the Rust programming\nlanguage, as well as its formal verification using the ACL2 theorem prover.\nRust has garnered significant endorsement in the past few years as a modern,\nmemory-safe successor to C/C++ at companies such as Amazon, Google, and\nMicrosoft, and is being integrated into both the Linux and Windows operating\nsystem kernels. Our interest in Rust stems from its potential as a\nhardware/software co-assurance language, with application to critical systems.\nWe have crafted a Rust subset, inspired by Russinoff's Restricted Algorithmic C\n(RAC), which we have imaginatively named Restricted Algorithmic Rust, or RAR.\nIn previous work, we described our initial implementation of a RAR toolchain,\nwherein we simply transpile the RAR source into RAC. By so doing, we leverage a\nnumber of existing hardware/software co-assurance tools with a minimum\ninvestment of time and effort. In this paper, we describe the RAR Rust subset,\ndescribe our improved prototype RAR toolchain, and detail the design and\nverification of a circular doubly-linked list data structure employing the\nDancing Links optimization in RAR, with full proofs of functional correctness\naccomplished using the ACL2 theorem prover.",
            "author": [
                "David S. Hardin"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.13",
                "http://arxiv.org/abs/2311.08862v1",
                "http://arxiv.org/pdf/2311.08862v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.DS",
                "cs.PL",
                "F.3.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08861v1",
            "title": "ACL2 Proofs of Nonlinear Inequalities with Imandra",
            "updated": "2023-11-15T10:48:30Z",
            "published": "2023-11-15T10:48:30Z",
            "summary": "We present a proof-producing integration of ACL2 and Imandra for proving\nnonlinear inequalities. This leverages a new Imandra interface exposing its\nnonlinear decision procedures. The reasoning takes place over the reals, but\nthe proofs produced are valid over the rationals and may be run in both ACL2\nand ACL2(r). The ACL2 proofs Imandra constructs are extracted from\nPositivstellensatz refutations, a real algebraic analogue of the\nNullstellensatz, and are found using convex optimization.",
            "author": [
                "Grant Passmore"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.12",
                "http://arxiv.org/abs/2311.08861v1",
                "http://arxiv.org/pdf/2311.08861v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08860v1",
            "title": "Proving Calculational Proofs Correct",
            "updated": "2023-11-15T10:48:11Z",
            "published": "2023-11-15T10:48:11Z",
            "summary": "Teaching proofs is a crucial component of any undergraduate-level program\nthat covers formal reasoning. We have developed a calculational reasoning\nformat and refined it over several years of teaching a freshman-level course,\n\"Logic and Computation\", to thousands of undergraduate students. In our\ncompanion paper, we presented our calculational proof format, gave an overview\nof the calculational proof checker (CPC) tool that we developed to help users\nwrite and validate proofs, described some of the technical and implementation\ndetails of CPC and provided several publicly available proofs written using our\nformat. In this paper, we dive deeper into the implementation details of CPC,\nhighlighting how proof validation works, which helps us argue that our proof\nchecking process is sound.",
            "author": [
                "Andrew T. Walter",
                "Ankit Kumar",
                "Panagiotis Manolios"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.11",
                "http://arxiv.org/abs/2311.08860v1",
                "http://arxiv.org/pdf/2311.08860v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "D.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08859v1",
            "title": "Verification of GossipSub in ACL2s",
            "updated": "2023-11-15T10:47:48Z",
            "published": "2023-11-15T10:47:48Z",
            "summary": "GossipSub is a popular new peer-to-peer network protocol designed to\ndisseminate messages quickly and efficiently by allowing peers to forward the\nfull content of messages only to a dynamically selected subset of their\nneighboring peers (mesh neighbors) while gossiping about messages they have\nseen with the rest. Peers decide which of their neighbors to graft or prune\nfrom their mesh locally and periodically using a score for each neighbor.\nScores are calculated using a score function that depends on mesh-specific\nparameters, weights and counters relating to a peer's performance in the\nnetwork. Since a GossipSub network's performance ultimately depends on the\nperformance of its peers, an important question arises: Is the score\ncalculation mechanism effective in weeding out non-performing or even\nintentionally misbehaving peers from meshes? We answered this question in the\nnegative in our companion paper by reasoning about GossipSub using our formal,\nofficial and executable ACL2s model. Based on our findings, we synthesized and\nsimulated attacks against GossipSub which were confirmed by the developers of\nGossipSub, FileCoin, and Eth2.0, and publicly disclosed in MITRE\nCVE-2022-47547. In this paper, we present a detailed description of our model.\nWe discuss design decisions, security properties of GossipSub, reasoning about\nthe security properties in context of our model, attack generation and lessons\nwe learnt when writing it.",
            "author": [
                "Ankit Kumar",
                "Max von Hippel",
                "Panagiotis Manolios",
                "Cristina Nita-Rotaru"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.10",
                "http://arxiv.org/abs/2311.08859v1",
                "http://arxiv.org/pdf/2311.08859v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CY",
                "cs.DC",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08858v1",
            "title": "Formal Verification of Zero-Knowledge Circuits",
            "updated": "2023-11-15T10:47:28Z",
            "published": "2023-11-15T10:47:28Z",
            "summary": "Zero-knowledge circuits are sets of equality constraints over arithmetic\nexpressions interpreted in a prime field; they are used to encode computations\nin cryptographic zero-knowledge proofs. We make the following contributions to\nthe problem of ensuring that a circuit correctly encodes a computation: a\nformal framework for circuit correctness; an ACL2 library for prime fields; an\nACL2 model of the existing R1CS (Rank-1 Constraint Systems) formalism to\nrepresent circuits, along with ACL2 and Axe tools to verify circuits of this\nform; a novel PFCS (Prime Field Constraint Systems) formalism to represent\nhierarchically structured circuits, along with an ACL2 model of it and ACL2\ntools to verify circuits of this form in a compositional and scalable way;\nverification of circuits, ranging from simple to complex; and discovery of bugs\nand optimizations in existing zero-knowledge systems.",
            "author": [
                "Alessandro Coglio",
                "Eric McCarthy",
                "Eric W. Smith"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.9",
                "http://arxiv.org/abs/2311.08858v1",
                "http://arxiv.org/pdf/2311.08858v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CR",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08857v1",
            "title": "Using Counterexample Generation and Theory Exploration to Suggest\n  Missing Hypotheses",
            "updated": "2023-11-15T10:47:13Z",
            "published": "2023-11-15T10:47:13Z",
            "summary": "Newcomers to ACL2 are sometimes surprised that ACL2 rejects formulas that\nthey believe should be theorems, such as (REVERSE (REVERSE X)) = X. Experienced\nACL2 users will recognize that the theorem only holds for intended values of X,\nand given ACL2's total logic, there are many counterexamples for which this\nformula is simply not true. Counterexample generation (cgen) is a technique\nthat helps by giving the user a number of counterexamples (and also witnesses)\nto the formula, e.g., letting the user know that the intended theorem is false\nwhen X is equal to 10. In this paper we describe a tool called DrLA that goes\nfurther by suggesting additional hypotheses that will make the theorem true. In\nthis case, for example, DrLA may suggest that X needs to be either a TRUE-LIST\nor a STRING. The suggestions are discovered using the ideas of theory\nexploration and subsumption from automated theorem proving.",
            "author": [
                "Ruben Gamboa",
                "Panagiotis Manolios",
                "Eric Smith",
                "Kyle Thompson"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.8",
                "http://arxiv.org/abs/2311.08857v1",
                "http://arxiv.org/pdf/2311.08857v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08856v1",
            "title": "Advances in ACL2 Proof Debugging Tools",
            "updated": "2023-11-15T10:46:55Z",
            "published": "2023-11-15T10:46:55Z",
            "summary": "The experience of an ACL2 user generally includes many failed proof attempts.\nA key to successful use of the ACL2 prover is the effective use of tools to\ndebug those failures. We focus on changes made after ACL2 Version 8.5: the\nimproved break-rewrite utility and the new utility, with-brr-data.",
            "author": [
                "Matt Kaufmann",
                "J Strother Moore"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.7",
                "http://arxiv.org/abs/2311.08856v1",
                "http://arxiv.org/pdf/2311.08856v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08855v1",
            "title": "A Case Study in Analytic Protocol Analysis in ACL2",
            "updated": "2023-11-15T10:46:33Z",
            "published": "2023-11-15T10:46:33Z",
            "summary": "When verifying computer systems we sometimes want to study their asymptotic\nbehaviors, i.e., how they behave in the long run. In such cases, we need real\nanalysis, the area of mathematics that deals with limits and the foundations of\ncalculus. In a prior work, we used real analysis in ACL2s to study the\nasymptotic behavior of the RTO computation, commonly used in congestion control\nalgorithms across the Internet. One key component in our RTO computation\nanalysis was proving in ACL2s that for all alpha in [0, 1), the limit as n\napproaches infinity of alpha raised to n is zero. Whereas the most obvious\nproof strategy involves the logarithm, whose codomain includes irrationals, by\ndefault ACL2 only supports rationals, which forced us to take a non-standard\napproach. In this paper, we explore different approaches to proving the above\nresult in ACL2(r) and ACL2s, from the perspective of a relatively new user to\neach. We also contextualize the theorem by showing how it allowed us to prove\nimportant asymptotic properties of the RTO computation. Finally, we discuss\ntradeoffs between the various proof strategies and directions for future\nresearch.",
            "author": [
                "Max von Hippel",
                "Panagiotis Manolios",
                "Kenneth L. McMillan",
                "Cristina Nita-Rotaru",
                "Lenore Zuck"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393.6",
                "http://arxiv.org/abs/2311.08855v1",
                "http://arxiv.org/pdf/2311.08855v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.MS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08852v1",
            "title": "Real-Time Performance of Industrial IoT Communication Technologies: A\n  Review",
            "updated": "2023-11-15T10:43:43Z",
            "published": "2023-11-15T10:43:43Z",
            "summary": "With the growing need for automation and the ongoing merge of OT and IT,\nindustrial networks have to transport a high amount of heterogeneous data with\nmixed criticality such as control traffic, sensor data, and configuration\nmessages. Current advances in IT technologies furthermore enable a new set of\nautomation scenarios under the roof of Industry 4.0 and IIoT where industrial\nnetworks now have to meet new requirements in flexibility and reliability. The\nnecessary real-time guarantees will place significant demands on the networks.\nIn this paper, we identify IIoT use cases and infer real-time requirements\nalong several axes before bridging the gap between real-time network\ntechnologies and the identified scenarios. We review real-time networking\ntechnologies and present peer-reviewed works from the past 5 years for\nindustrial environments. We investigate how these can be applied to\ncontrollers, systems, and embedded devices. Finally, we discuss open challenges\nfor real-time communication technologies to enable the identified scenarios.\nThe review shows academic interest in the field of real-time communication\ntechnologies but also highlights a lack of a fixed set of standards important\nfor trust in safety and reliability, especially where wireless technologies are\nconcerned.",
            "author": [
                "Ilja Behnke",
                "Henrik Austad"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JIOT.2023.3332507",
                "http://arxiv.org/abs/2311.08852v1",
                "http://arxiv.org/pdf/2311.08852v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC",
                "C.2.5; C.2; C.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08851v1",
            "title": "Data Augmentations in Deep Weight Spaces",
            "updated": "2023-11-15T10:43:13Z",
            "published": "2023-11-15T10:43:13Z",
            "summary": "Learning in weight spaces, where neural networks process the weights of other\ndeep neural networks, has emerged as a promising research direction with\napplications in various fields, from analyzing and editing neural fields and\nimplicit neural representations, to network pruning and quantization. Recent\nworks designed architectures for effective learning in that space, which takes\ninto account its unique, permutation-equivariant, structure. Unfortunately, so\nfar these architectures suffer from severe overfitting and were shown to\nbenefit from large datasets. This poses a significant challenge because\ngenerating data for this learning setup is laborious and time-consuming since\neach data sample is a full set of network weights that has to be trained. In\nthis paper, we address this difficulty by investigating data augmentations for\nweight spaces, a set of techniques that enable generating new data examples on\nthe fly without having to train additional input weight space elements. We\nfirst review several recently proposed data augmentation schemes %that were\nproposed recently and divide them into categories. We then introduce a novel\naugmentation scheme based on the Mixup method. We evaluate the performance of\nthese techniques on existing benchmarks as well as new benchmarks we generate,\nwhich can be valuable for future studies.",
            "author": [
                "Aviv Shamsian",
                "David W. Zhang",
                "Aviv Navon",
                "Yan Zhang",
                "Miltiadis Kofinas",
                "Idan Achituve",
                "Riccardo Valperga",
                "Gertjan J. Burghouts",
                "Efstratios Gavves",
                "Cees G. M. Snoek",
                "Ethan Fetaya",
                "Gal Chechik",
                "Haggai Maron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08851v1",
                "http://arxiv.org/pdf/2311.08851v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08850v1",
            "title": "Controlling the Output of a Generative Model by Latent Feature Vector\n  Shifting",
            "updated": "2023-11-15T10:42:06Z",
            "published": "2023-11-15T10:42:06Z",
            "summary": "State-of-the-art generative models (e.g. StyleGAN3 \\cite{karras2021alias})\noften generate photorealistic images based on vectors sampled from their latent\nspace. However, the ability to control the output is limited. Here we present\nour novel method for latent vector shifting for controlled output image\nmodification utilizing semantic features of the generated images. In our\napproach we use a pre-trained model of StyleGAN3 that generates images of\nrealistic human faces in relatively high resolution. We complement the\ngenerative model with a convolutional neural network classifier, namely\nResNet34, trained to classify the generated images with binary facial features\nfrom the CelebA dataset. Our latent feature shifter is a neural network model\nwith a task to shift the latent vectors of a generative model into a specified\nfeature direction. We have trained latent feature shifter for multiple facial\nfeatures, and outperformed our baseline method in the number of generated\nimages with the desired feature. To train our latent feature shifter neural\nnetwork, we have designed a dataset of pairs of latent vectors with and without\na certain feature. Based on the evaluation, we conclude that our latent feature\nshifter approach was successful in the controlled generation of the StyleGAN3\ngenerator.",
            "author": [
                "R\u00f3bert Belanec",
                "Peter Lacko",
                "Krist\u00edna Malinovsk\u00e1"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DISA59116.2023.10308936",
                "http://arxiv.org/abs/2311.08850v1",
                "http://arxiv.org/pdf/2311.08850v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08849v1",
            "title": "OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient\n  Large-scale Multilingual Continued Pretraining",
            "updated": "2023-11-15T10:40:45Z",
            "published": "2023-11-15T10:40:45Z",
            "summary": "Pretraining multilingual language models from scratch requires considerable\ncomputational resources and substantial training data. Therefore, a more\nefficient method is to adapt existing pretrained language models (PLMs) to new\nlanguages via vocabulary extension and continued pretraining. However, this\nmethod usually randomly initializes the embeddings of new subwords and\nintroduces substantially more embedding parameters to the language model, thus\nweakening the efficiency. To address these issues, we propose a novel\nframework: \\textbf{O}ne \\textbf{F}or \\textbf{A}ll (\\textbf{\\textsc{Ofa}}),\nwhich wisely initializes the embeddings of unseen subwords from target\nlanguages and thus can adapt a PLM to multiple languages efficiently and\neffectively. \\textsc{Ofa} takes advantage of external well-aligned multilingual\nword embeddings and injects the alignment knowledge into the new embeddings. In\naddition, \\textsc{Ofa} applies matrix factorization and replaces the cumbersome\nembeddings with two lower-dimensional matrices, which significantly reduces the\nnumber of parameters while not sacrificing the performance. Through extensive\nexperiments, we show models initialized by \\textsc{Ofa} are efficient and\noutperform several baselines. \\textsc{Ofa} not only accelerates the convergence\nof continued pretraining, which is friendly to a limited computation budget,\nbut also improves the zero-shot crosslingual transfer on a wide range of\ndownstream tasks. We make our code and models publicly available.",
            "author": [
                "Yihong Liu",
                "Peiqin Lin",
                "Mingyang Wang",
                "Hinrich Sch\u00fctze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08849v1",
                "http://arxiv.org/pdf/2311.08849v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08847v1",
            "title": "Robust discrete-time super-hedging strategies under AIP condition and\n  under price uncertainty",
            "updated": "2023-11-15T10:38:06Z",
            "published": "2023-11-15T10:38:06Z",
            "summary": "We solve the problem of super-hedging European or Asian options for\ndiscrete-time financial market models where executable prices are uncertain.\nThe risky asset prices are not described by single-valued processes but\nmeasurable selections of random sets that allows to consider a large variety of\nmodels including bid-ask models with order books, but also models with a delay\nin the execution of the orders. We provide a numerical procedure to compute the\ninfimum price under a weak no-arbitrage condition, the so-called AIP condition,\nunder which the prices of the non negative European options are non negative.\nThis condition is weaker than the existence of a risk-neutral martingale\nmeasure but it is sufficient to numerically solve the super-hedging problem. We\nillustrate our method by a numerical example.",
            "author": [
                "Meriam El Mansour",
                "Emmanuel Lepinette"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08847v1",
                "http://arxiv.org/pdf/2311.08847v1"
            ],
            "primary_category": "q-fin.PR",
            "category": [
                "q-fin.PR",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08844v1",
            "title": "Violet: A Vision-Language Model for Arabic Image Captioning with Gemini\n  Decoder",
            "updated": "2023-11-15T10:34:14Z",
            "published": "2023-11-15T10:34:14Z",
            "summary": "Although image captioning has a vast array of applications, it has not\nreached its full potential in languages other than English. Arabic, for\ninstance, although the native language of more than 400 million people, remains\nlargely underrepresented in this area. This is due to the lack of labeled data\nand powerful Arabic generative models. We alleviate this issue by presenting a\nnovel vision-language model dedicated to Arabic, dubbed \\textit{Violet}. Our\nmodel is based on a vision encoder and a Gemini text decoder that maintains\ngeneration fluency while allowing fusion between the vision and language\ncomponents. To train our model, we introduce a new method for automatically\nacquiring data from available English datasets. We also manually prepare a new\ndataset for evaluation. \\textit{Violet} performs sizeably better than our\nbaselines on all of our evaluation datasets. For example, it reaches a CIDEr\nscore of $61.2$ on our manually annotated dataset and achieves an improvement\nof $13$ points on Flickr8k.",
            "author": [
                "Abdelrahman Mohamed",
                "Fakhraddin Alwajih",
                "El Moatez Billah Nagoudi",
                "Alcides Alcoba Inciarte",
                "Muhammad Abdul-Mageed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08844v1",
                "http://arxiv.org/pdf/2311.08844v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08843v3",
            "title": "Personalized Video Relighting With an At-Home Light Stage",
            "updated": "2023-12-05T02:46:37Z",
            "published": "2023-11-15T10:33:20Z",
            "summary": "In this paper, we develop a personalized video relighting algorithm that\nproduces high-quality and temporally consistent relit videos under any pose,\nexpression, and lighting condition in real-time. Existing relighting algorithms\ntypically rely either on publicly available synthetic data, which yields poor\nrelighting results, or instead on light stage data which is difficult to\nobtain. We show that by just capturing video of a user watching YouTube videos\non a monitor we can train a personalized algorithm capable of performing\nhigh-quality relighting under any condition. Our key contribution is a novel\nneural relighting architecture that effectively separates the intrinsic\nappearance features - the geometry and reflectance of the face - from the\nsource lighting and then combines them with the target lighting to generate a\nrelit image. This neural network architecture enables smoothing of intrinsic\nappearance features leading to temporally stable video relighting. Both\nqualitative and quantitative evaluations show that our architecture improves\nportrait image relighting quality and temporal consistency over\nstate-of-the-art approaches on both casually captured `Light Stage at Your\nDesk' (LSYD) and light-stage-captured `One Light At a Time' (OLAT) datasets.",
            "author": [
                "Jun Myeong Choi",
                "Max Christman",
                "Roni Sengupta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08843v3",
                "http://arxiv.org/pdf/2311.08843v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10766v1",
            "title": "Value FULCRA: Mapping Large Language Models to the Multidimensional\n  Spectrum of Basic Human Values",
            "updated": "2023-11-15T10:29:28Z",
            "published": "2023-11-15T10:29:28Z",
            "summary": "The rapid advancement of Large Language Models (LLMs) has attracted much\nattention to value alignment for their responsible development. However, how to\ndefine values in this context remains a largely unexplored question. Existing\nwork mainly follows the Helpful, Honest, Harmless principle and specifies\nvalues as risk criteria formulated in the AI community, e.g., fairness and\nprivacy protection, suffering from poor clarity, adaptability and transparency.\nInspired by basic values in humanity and social science across cultures, this\nwork proposes a novel basic value alignment paradigm and introduces a value\nspace spanned by basic value dimensions. All LLMs' behaviors can be mapped into\nthe space by identifying the underlying values, possessing the potential to\naddress the three challenges. To foster future research, we apply the\nrepresentative Schwartz's Theory of Basic Values as an initialized example and\nconstruct FULCRA, a dataset consisting of 5k (LLM output, value vector) pairs.\nOur extensive analysis of FULCRA reveals the underlying relation between basic\nvalues and LLMs' behaviors, demonstrating that our approach not only covers\nexisting mainstream risks but also anticipates possibly unidentified ones.\nAdditionally, we present an initial implementation of the basic value\nevaluation and alignment, paving the way for future research in this line.",
            "author": [
                "Jing Yao",
                "Xiaoyuan Yi",
                "Xiting Wang",
                "Yifan Gong",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10766v1",
                "http://arxiv.org/pdf/2311.10766v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10765v1",
            "title": "Enhancing Machine Translation through Advanced In-Context Learning: A\n  Methodological Strategy for GPT-4 Improvement",
            "updated": "2023-11-15T10:28:28Z",
            "published": "2023-11-15T10:28:28Z",
            "summary": "The challenge of improving translation accuracy in GPT-4 is being addressed\nby harnessing a method known as in-context learning. This paper introduces a\nstrategic approach to utilize in-context learning specifically for machine\ntranslation, aiming to significantly boost accuracy. The crux of this method\nlies in the judicious selection of demonstrations that are most effective for\nin-context learning. By selecting these examples carefully, GPT-4 can utilize\nthem to achieve remarkably accurate machine translations, eliminating the need\nfor task-specific fine-tuning. This technique is anchored in the semantic\nsimilarities between the user's prompt and the chosen dataset. Sentences from\nthis dataset, carefully picked for their relevance and clarity, serve as potent\ndemonstrations for in-context learning. This approach not only enhances\ntranslation accuracy but also enriches the understanding of nuanced linguistic\nstructures. It represents a significant step forward in machine learning,\nleveraging the inherent capabilities of GPT-4 to provide translations that are\nnot only accurate but also contextually rich and linguistically sophisticated.\nThis method demonstrates the potential of in-context learning in overcoming\nlanguage barriers, opening new avenues for cross-cultural communication and\nglobal collaboration.",
            "author": [
                "Yufeng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10765v1",
                "http://arxiv.org/pdf/2311.10765v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14711v1",
            "title": "Towards Publicly Accountable Frontier LLMs: Building an External\n  Scrutiny Ecosystem under the ASPIRE Framework",
            "updated": "2023-11-15T10:25:41Z",
            "published": "2023-11-15T10:25:41Z",
            "summary": "With the increasing integration of frontier large language models (LLMs) into\nsociety and the economy, decisions related to their training, deployment, and\nuse have far-reaching implications. These decisions should not be left solely\nin the hands of frontier LLM developers. LLM users, civil society and\npolicymakers need trustworthy sources of information to steer such decisions\nfor the better. Involving outside actors in the evaluation of these systems -\nwhat we term 'external scrutiny' - via red-teaming, auditing, and external\nresearcher access, offers a solution. Though there are encouraging signs of\nincreasing external scrutiny of frontier LLMs, its success is not assured. In\nthis paper, we survey six requirements for effective external scrutiny of\nfrontier AI systems and organize them under the ASPIRE framework: Access,\nSearching attitude, Proportionality to the risks, Independence, Resources, and\nExpertise. We then illustrate how external scrutiny might function throughout\nthe AI lifecycle and offer recommendations to policymakers.",
            "author": [
                "Markus Anderljung",
                "Everett Thornton Smith",
                "Joe O'Brien",
                "Lisa Soder",
                "Benjamin Bucknall",
                "Emma Bluemke",
                "Jonas Schuett",
                "Robert Trager",
                "Lacey Strahm",
                "Rumman Chowdhury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14711v1",
                "http://arxiv.org/pdf/2311.14711v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08838v1",
            "title": "Disinformation Capabilities of Large Language Models",
            "updated": "2023-11-15T10:25:30Z",
            "published": "2023-11-15T10:25:30Z",
            "summary": "Automated disinformation generation is often listed as one of the risks of\nlarge language models (LLMs). The theoretical ability to flood the information\nspace with disinformation content might have dramatic consequences for\ndemocratic societies around the world. This paper presents a comprehensive\nstudy of the disinformation capabilities of the current generation of LLMs to\ngenerate false news articles in English language. In our study, we evaluated\nthe capabilities of 10 LLMs using 20 disinformation narratives. We evaluated\nseveral aspects of the LLMs: how well they are at generating news articles, how\nstrongly they tend to agree or disagree with the disinformation narratives, how\noften they generate safety warnings, etc. We also evaluated the abilities of\ndetection models to detect these articles as LLM-generated. We conclude that\nLLMs are able to generate convincing news articles that agree with dangerous\ndisinformation narratives.",
            "author": [
                "Ivan Vykopal",
                "Mat\u00fa\u0161 Pikuliak",
                "Ivan Srba",
                "Robert Moro",
                "Dominik Macko",
                "Maria Bielikova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08838v1",
                "http://arxiv.org/pdf/2311.08838v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08836v1",
            "title": "Evaluating Gender Bias in the Translation of Gender-Neutral Languages\n  into English",
            "updated": "2023-11-15T10:25:14Z",
            "published": "2023-11-15T10:25:14Z",
            "summary": "Machine Translation (MT) continues to improve in quality and adoption, yet\nthe inadvertent perpetuation of gender bias remains a significant concern.\nDespite numerous studies into gender bias in translations from gender-neutral\nlanguages such as Turkish into more strongly gendered languages like English,\nthere are no benchmarks for evaluating this phenomenon or for assessing\nmitigation strategies. To address this gap, we introduce GATE X-E, an extension\nto the GATE (Rarrick et al., 2023) corpus, that consists of human translations\nfrom Turkish, Hungarian, Finnish, and Persian into English. Each translation is\naccompanied by feminine, masculine, and neutral variants for each possible\ngender interpretation. The dataset, which contains between 1250 and 1850\ninstances for each of the four language pairs, features natural sentences with\na wide range of sentence lengths and domains, challenging translation rewriters\non various linguistic phenomena. Additionally, we present an English gender\nrewriting solution built on GPT-3.5 Turbo and use GATE X-E to evaluate it. We\nopen source our contributions to encourage further research on gender\ndebiasing.",
            "author": [
                "Spencer Rarrick",
                "Ranjita Naik",
                "Sundar Poudel",
                "Vishal Chowdhary"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08836v1",
                "http://arxiv.org/pdf/2311.08836v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08835v2",
            "title": "Correlation-guided Query-Dependency Calibration in Video Representation\n  Learning for Temporal Grounding",
            "updated": "2023-11-18T15:51:20Z",
            "published": "2023-11-15T10:22:35Z",
            "summary": "Recent endeavors in video temporal grounding enforce strong cross-modal\ninteractions through attention mechanisms to overcome the modality gap between\nvideo and text query. However, previous works treat all video clips equally\nregardless of their semantic relevance with the text query in attention\nmodules. In this paper, our goal is to provide clues for query-associated video\nclips within the crossmodal encoding process. With our Correlation-Guided\nDetection Transformer~(CG-DETR), we explore the appropriate clip-wise degree of\ncross-modal interactions and how to exploit such degrees for prediction. First,\nwe design an adaptive cross-attention layer with dummy tokens. Dummy tokens\nconditioned by text query take a portion of the attention weights, preventing\nirrelevant video clips from being represented by the text query. Yet, not all\nword tokens equally inherit the text query's correlation to video clips. Thus,\nwe further guide the cross-attention map by inferring the fine-grained\ncorrelation between video clips and words. We enable this by learning a joint\nembedding space for high-level concepts, i.e., moment and sentence level, and\ninferring the clip-word correlation. Lastly, we use a moment-adaptive saliency\ndetector to exploit each video clip's degrees of text engagement. We validate\nthe superiority of CG-DETR with the state-of-the-art results on various\nbenchmarks for both moment retrieval and highlight detection. Codes are\navailable at https://github.com/wjun0830/CGDETR.",
            "author": [
                "WonJun Moon",
                "Sangeek Hyun",
                "SuBeen Lee",
                "Jae-Pil Heo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08835v2",
                "http://arxiv.org/pdf/2311.08835v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08834v1",
            "title": "A* search algorithm for an optimal investment problem in vehicle-sharing\n  systems",
            "updated": "2023-11-15T10:22:34Z",
            "published": "2023-11-15T10:22:34Z",
            "summary": "We study an optimal investment problem that arises in the context of the\nvehicle-sharing system. Given a set of locations to build stations, we need to\ndetermine i) the sequence of stations to be built and the number of vehicles to\nacquire in order to obtain the target state where all stations are built, and\nii) the number of vehicles to acquire and their allocation in order to maximize\nthe total profit returned by operating the system when some or all stations are\nopen. The profitability associated with operating open stations, measured over\na specific time period, is represented as a linear optimization problem applied\nto a collection of open stations. With operating capital, the owner of the\nsystem can open new stations. This property introduces a set-dependent aspect\nto the duration required for opening a new station, and the optimal investment\nproblem can be viewed as a variant of the Traveling Salesman Problem (TSP) with\nset-dependent cost. We propose an A* search algorithm to address this\nparticular variant of the TSP. Computational experiments highlight the benefits\nof the proposed algorithm in comparison to the widely recognized Dijkstra\nalgorithm and propose future research to explore new possibilities and\napplications for both exact and approximate A* algorithms.",
            "author": [
                "Ba Luat Le",
                "Layla Martin",
                "Emrah Demir",
                "Duc Minh Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08834v1",
                "http://arxiv.org/pdf/2311.08834v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08826v2",
            "title": "Multi-stage Euler-Maruyama methods for backward stochastic differential\n  equations driven by continuous-time Markov chains",
            "updated": "2023-11-22T20:15:13Z",
            "published": "2023-11-15T10:00:00Z",
            "summary": "Numerical methods for computing the solutions of Markov backward stochastic\ndifferential equations (BSDEs) driven by continuous-time Markov chains (CTMCs)\nare explored. The main contributions of this paper are as follows: (1) we\nobserve that Euler-Maruyama temporal discretization methods for solving Markov\nBSDEs driven by CTMCs are equivalent to exponential integrators for solving the\nassociated systems of ordinary differential equations (ODEs); (2) we introduce\nmulti-stage Euler-Maruyama methods for effectively solving \"stiff\" Markov BSDEs\ndriven by CTMCs; these BSDEs typically arise from the spatial discretization of\nMarkov BSDEs driven by Brownian motion; (3) we propose a multilevel spatial\ndiscretization method on sparse grids that efficiently approximates\nhigh-dimensional Markov BSDEs driven by Brownian motion with a combination of\nmultiple Markov BSDEs driven by CTMCs on grids with different resolutions. We\nalso illustrate the effectiveness of the presented methods with a number of\nnumerical experiments in which we treat nonlinear BSDEs arising from option\npricing problems in finance.",
            "author": [
                "Akihiro Kaneko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08826v2",
                "http://arxiv.org/pdf/2311.08826v2"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.NA",
                "math.NA",
                "q-fin.MF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08821v1",
            "title": "Thermal Finite Element Modeling and Simulation of a Squirrel-Cage\n  Induction Machine",
            "updated": "2023-11-15T09:51:20Z",
            "published": "2023-11-15T09:51:20Z",
            "summary": "Finite element models of electrical machines allow insights in electrothermal\nstresses which endanger the insulation system of the machine. This paper\npresents a thermal finite element model of a 3.7 kW squirrel-cage induction\nmachine. The model resolves the conductors and the surrounding insulation\nmaterials in the stator slots. A set of transient thermal scenarios is defined\nand measured in the machine laboratory. These data are used to assess the\nfinite element model.",
            "author": [
                "Christian Bergfried",
                "Yvonne Sp\u00e4ck-Leigsnering",
                "Roland Seebacher",
                "Heinrich Eickhoff",
                "Annette Muetze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08821v1",
                "http://arxiv.org/pdf/2311.08821v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08819v1",
            "title": "Frequency Domain-based Dataset Distillation",
            "updated": "2023-11-15T09:46:30Z",
            "published": "2023-11-15T09:46:30Z",
            "summary": "This paper presents FreD, a novel parameterization method for dataset\ndistillation, which utilizes the frequency domain to distill a small-sized\nsynthetic dataset from a large-sized original dataset. Unlike conventional\napproaches that focus on the spatial domain, FreD employs frequency-based\ntransforms to optimize the frequency representations of each data instance. By\nleveraging the concentration of spatial domain information on specific\nfrequency components, FreD intelligently selects a subset of frequency\ndimensions for optimization, leading to a significant reduction in the required\nbudget for synthesizing an instance. Through the selection of frequency\ndimensions based on the explained variance, FreD demonstrates both theoretical\nand empirical evidence of its ability to operate efficiently within a limited\nbudget, while better preserving the information of the original dataset\ncompared to conventional parameterization methods. Furthermore, based on the\northogonal compatibility of FreD with existing methods, we confirm that FreD\nconsistently improves the performances of existing distillation methods over\nthe evaluation scenarios with different benchmark datasets. We release the code\nat https://github.com/sdh0818/FreD.",
            "author": [
                "Donghyeok Shin",
                "Seungjae Shin",
                "Il-Chul Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08819v1",
                "http://arxiv.org/pdf/2311.08819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08817v1",
            "title": "MAP's not dead yet: Uncovering true language model modes by conditioning\n  away degeneracy",
            "updated": "2023-11-15T09:38:53Z",
            "published": "2023-11-15T09:38:53Z",
            "summary": "It has been widely observed that exact or approximate MAP (mode-seeking)\ndecoding from natural language generation (NLG) models consistently leads to\ndegenerate outputs (Stahlberg and Byrne, 2019, Holtzman et al., 2019). This has\ngenerally been attributed to either a fundamental inadequacy of modes in models\nor weaknesses in language modeling. Contrastingly in this work, we emphasize\nthat degenerate modes can even occur in the absence of any model error, due to\ncontamination of the training data. Specifically, we show that mixing even a\ntiny amount of low-entropy noise with a population text distribution can cause\nthe data distribution's mode to become degenerate, implying that any models\ntrained on it will be as well. As the unconditional mode of NLG models will\noften be degenerate, we therefore propose to apply MAP decoding to the model's\ndistribution conditional on avoiding specific degeneracies. Using exact-search,\nwe empirically verify that the length-conditional modes of machine translation\nmodels and language models are indeed more fluent and topical than their\nunconditional modes. For the first time, we also share many examples of exact\nmodal sequences from these models, and from several variants of the LLaMA-7B\nmodel. Notably, the modes of the LLaMA models are still degenerate, showing\nthat improvements in modeling have not fixed this issue. Because of the cost of\nexact mode finding algorithms, we develop an approximate mode finding approach,\nACBS, which finds sequences that are both high-likelihood and high-quality. We\napply this approach to LLaMA-7B, a model which was not trained for instruction\nfollowing, and find that we are able to elicit reasonable outputs without any\nfinetuning.",
            "author": [
                "Davis Yoshida",
                "Kartik Goyal",
                "Kevin Gimpel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08817v1",
                "http://arxiv.org/pdf/2311.08817v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08816v1",
            "title": "Target-oriented Domain Adaptation for Infrared Image Super-Resolution",
            "updated": "2023-11-15T09:35:07Z",
            "published": "2023-11-15T09:35:07Z",
            "summary": "Recent efforts have explored leveraging visible light images to enrich\ntexture details in infrared (IR) super-resolution. However, this direct\nadaptation approach often becomes a double-edged sword, as it improves texture\nat the cost of introducing noise and blurring artifacts. To address these\nchallenges, we propose the Target-oriented Domain Adaptation SRGAN (DASRGAN),\nan innovative framework specifically engineered for robust IR super-resolution\nmodel adaptation. DASRGAN operates on the synergy of two key components: 1)\nTexture-Oriented Adaptation (TOA) to refine texture details meticulously, and\n2) Noise-Oriented Adaptation (NOA), dedicated to minimizing noise transfer.\nSpecifically, TOA uniquely integrates a specialized discriminator,\nincorporating a prior extraction branch, and employs a Sobel-guided adversarial\nloss to align texture distributions effectively. Concurrently, NOA utilizes a\nnoise adversarial loss to distinctly separate the generative and Gaussian noise\npattern distributions during adversarial training. Our extensive experiments\nconfirm DASRGAN's superiority. Comparative analyses against leading methods\nacross multiple benchmarks and upsampling factors reveal that DASRGAN sets new\nstate-of-the-art performance standards. Code are available at\n\\url{https://github.com/yongsongH/DASRGAN}.",
            "author": [
                "Yongsong Huang",
                "Tomo Miyazaki",
                "Xiaofeng Liu",
                "Yafei Dong",
                "Shinichiro Omachi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08816v1",
                "http://arxiv.org/pdf/2311.08816v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08815v1",
            "title": "Self-Supervised Disentanglement by Leveraging Structure in Data\n  Augmentations",
            "updated": "2023-11-15T09:34:08Z",
            "published": "2023-11-15T09:34:08Z",
            "summary": "Self-supervised representation learning often uses data augmentations to\ninduce some invariance to \"style\" attributes of the data. However, with\ndownstream tasks generally unknown at training time, it is difficult to deduce\na priori which attributes of the data are indeed \"style\" and can be safely\ndiscarded. To address this, we introduce a more principled approach that seeks\nto disentangle style features rather than discard them. The key idea is to add\nmultiple style embedding spaces where: (i) each is invariant to all-but-one\naugmentation; and (ii) joint entropy is maximized. We formalize our structured\ndata-augmentation procedure from a causal latent-variable-model perspective,\nand prove identifiability of both content and (multiple blocks of) style\nvariables. We empirically demonstrate the benefits of our approach on synthetic\ndatasets and then present promising but limited results on ImageNet.",
            "author": [
                "Cian Eastwood",
                "Julius von K\u00fcgelgen",
                "Linus Ericsson",
                "Diane Bouchacourt",
                "Pascal Vincent",
                "Bernhard Sch\u00f6lkopf",
                "Mark Ibrahim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08815v1",
                "http://arxiv.org/pdf/2311.08815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08813v1",
            "title": "Comments on \"Dynamic Consensus Committee-Based for Secure Data Sharing\n  With Authorized Multi-Receiver Searchable Encryption\"",
            "updated": "2023-11-15T09:32:55Z",
            "published": "2023-11-15T09:32:55Z",
            "summary": "Recently, Yang et al. introduced an efficient searchable encryption scheme\ntitled \"Dynamic Consensus Committee-Based for Secure Data Sharing With\nAuthorized Multi-Receiver Searchable Encryption (DCC-SE),\" published in IEEE\nTransactions on Information Forensics and Security (DOI:\n10.1109/TIFS.2023.3305183). According to the authors, DCC-SE meets various\nsecurity requirements, especially the keyword trapdoor indistinguishability\nagainst chosen keyword attacks (KT-IND-CKA). In this letter, however, we reveal\na significant vulnerability of DCC-SE: any users involved in the system can\nexecute attacks against KT-IND-CKA security. This flaw potentially results in\nthe unintended disclosure of sensitive keyword information related to the\ndocuments. We present a detailed cryptanalysis on DCC-SE. In addition, to\naddress this vulnerability, we discuss the root cause and identify a flaw in\nthe security proof of DCC-SE. Subsequently, we provide a solution that\neffectively addresses this concern without significantly increasing\ncomputational overhead.",
            "author": [
                "Zi-Yuan Liu",
                "Raylin Tso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08813v1",
                "http://arxiv.org/pdf/2311.08813v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08812v1",
            "title": "Optimal subsampling algorithm for the marginal model with large\n  longitudinal data",
            "updated": "2023-11-15T09:31:08Z",
            "published": "2023-11-15T09:31:08Z",
            "summary": "Big data is ubiquitous in practices, and it has also led to heavy computation\nburden. To reduce the calculation cost and ensure the effectiveness of\nparameter estimators, an optimal subset sampling method is proposed to estimate\nthe parameters in marginal models with massive longitudinal data. The optimal\nsubsampling probabilities are derived, and the corresponding asymptotic\nproperties are established to ensure the consistency and asymptotic normality\nof the estimator. Extensive simulation studies are carried out to evaluate the\nperformance of the proposed method for continuous, binary and count data and\nwith four different working correlation matrices. A depression data is used to\nillustrate the proposed method.",
            "author": [
                "Haohui Han",
                "Liya Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08812v1",
                "http://arxiv.org/pdf/2311.08812v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08811v1",
            "title": "Correlation-aware active learning for surgery video segmentation",
            "updated": "2023-11-15T09:30:52Z",
            "published": "2023-11-15T09:30:52Z",
            "summary": "Semantic segmentation is a complex task that relies heavily on large amounts\nof annotated image data. However, annotating such data can be time-consuming\nand resource-intensive, especially in the medical domain. Active Learning (AL)\nis a popular approach that can help to reduce this burden by iteratively\nselecting images for annotation to improve the model performance. In the case\nof video data, it is important to consider the model uncertainty and the\ntemporal nature of the sequences when selecting images for annotation. This\nwork proposes a novel AL strategy for surgery video segmentation, \\COALSamp{},\nCOrrelation-aWare Active Learning. Our approach involves projecting images into\na latent space that has been fine-tuned using contrastive learning and then\nselecting a fixed number of representative images from local clusters of video\nframes. We demonstrate the effectiveness of this approach on two video datasets\nof surgical instruments and three real-world video datasets. The datasets and\ncode will be made publicly available upon receiving necessary approvals.",
            "author": [
                "Fei Wu",
                "Pablo Marquez-Neila",
                "Mingyi Zheng",
                "Hedyeh Rafii-Tari",
                "Raphael Sznitman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08811v1",
                "http://arxiv.org/pdf/2311.08811v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08806v1",
            "title": "SparseSpikformer: A Co-Design Framework for Token and Weight Pruning in\n  Spiking Transformer",
            "updated": "2023-11-15T09:22:52Z",
            "published": "2023-11-15T09:22:52Z",
            "summary": "As the third-generation neural network, the Spiking Neural Network (SNN) has\nthe advantages of low power consumption and high energy efficiency, making it\nsuitable for implementation on edge devices. More recently, the most advanced\nSNN, Spikformer, combines the self-attention module from Transformer with SNN\nto achieve remarkable performance. However, it adopts larger channel dimensions\nin MLP layers, leading to an increased number of redundant model parameters. To\neffectively decrease the computational complexity and weight parameters of the\nmodel, we explore the Lottery Ticket Hypothesis (LTH) and discover a very\nsparse ($\\ge$90%) subnetwork that achieves comparable performance to the\noriginal network. Furthermore, we also design a lightweight token selector\nmodule, which can remove unimportant background information from images based\non the average spike firing rate of neurons, selecting only essential\nforeground image tokens to participate in attention calculation. Based on that,\nwe present SparseSpikformer, a co-design framework aimed at achieving sparsity\nin Spikformer through token and weight pruning techniques. Experimental results\ndemonstrate that our framework can significantly reduce 90% model parameters\nand cut down Giga Floating-Point Operations (GFLOPs) by 20% while maintaining\nthe accuracy of the original model.",
            "author": [
                "Yue Liu",
                "Shanlin Xiao",
                "Bo Li",
                "Zhiyi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08806v1",
                "http://arxiv.org/pdf/2311.08806v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08805v1",
            "title": "Strength-dependent Transition of Graphite Under Shock Condition Resolved\n  by First Principles",
            "updated": "2023-11-15T09:22:09Z",
            "published": "2023-11-15T09:22:09Z",
            "summary": "The shock strength dependent formation of diamond represents one of the most\nintriguing questions in graphite research. Using ab initio DFT-trained carbon\nGNN model, we observe a strength-dependent graphite transition under shock. The\npoor sliding caused by scarce sliding time under high-strength shock forms\nhexagonal diamond with an orientation of (001)G//(100)HD+[010]G//[010]HD; under\nlow-strength shock, cubic diamond forms after enough sliding time, unveiling\nthe strength-dependent graphite transition. We provide computational evidence\nof the strength-dependent graphite transition from first principles, clarifying\nthe long-term shock-induced hexagonal formation and structural\nstrength-dependent trend source.",
            "author": [
                "Gu-Wen Chen",
                "Liang Xu",
                "Yao-Ming Li",
                "Zhi-Pan Liu",
                "Sheng-Cai Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08805v1",
                "http://arxiv.org/pdf/2311.08805v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08803v1",
            "title": "StrategyLLM: Large Language Models as Strategy Generators, Executors,\n  Optimizers, and Evaluators for Problem Solving",
            "updated": "2023-11-15T09:18:09Z",
            "published": "2023-11-15T09:18:09Z",
            "summary": "Most existing chain-of-thought (CoT) prompting methods suffer from the issues\nof generalizability and consistency, as they often rely on instance-specific\nsolutions that may not be applicable to other cases and lack task-level\nconsistency in their reasoning steps. To address these limitations, we propose\na comprehensive framework, StrategyLLM, harnessing the capabilities of LLMs to\ntackle various tasks. The framework improves generalizability by formulating\ngeneral problem-solving strategies and enhances consistency by producing\nconsistent solutions using these strategies. StrategyLLM employs four LLM-based\nagents: strategy generator, executor, optimizer, and evaluator, working\ntogether to generate, evaluate, and select promising strategies for a given\ntask automatically. The experimental results demonstrate that StrategyLLM\noutperforms the competitive baseline CoT-SC that requires human-annotated\nsolutions on 13 datasets across 4 challenging tasks without human involvement,\nincluding math reasoning (39.2% $\\rightarrow$ 43.3%), commonsense reasoning\n(70.3% $\\rightarrow$ 72.5%), algorithmic reasoning (51.7% $\\rightarrow$ 62.0%),\nand symbolic reasoning (30.0% $\\rightarrow$ 79.2%).",
            "author": [
                "Chang Gao",
                "Haiyun Jiang",
                "Deng Cai",
                "Shuming Shi",
                "Wai Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08803v1",
                "http://arxiv.org/pdf/2311.08803v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08799v1",
            "title": "EyeLS: Shadow-Guided Instrument Landing System for Intraocular Target\n  Approaching in Robotic Eye Surgery",
            "updated": "2023-11-15T09:11:37Z",
            "published": "2023-11-15T09:11:37Z",
            "summary": "Robotic ophthalmic surgery is an emerging technology to facilitate\nhigh-precision interventions such as retina penetration in subretinal injection\nand removal of floating tissues in retinal detachment depending on the input\nimaging modalities such as microscopy and intraoperative OCT (iOCT). Although\niOCT is explored to locate the needle tip within its range-limited ROI, it is\nstill difficult to coordinate iOCT's motion with the needle, especially at the\ninitial target-approaching stage. Meanwhile, due to 2D perspective projection\nand thus the loss of depth information, current image-based methods cannot\neffectively estimate the needle tip's trajectory towards both retinal and\nfloating targets. To address this limitation, we propose to use the shadow\npositions of the target and the instrument tip to estimate their relative depth\nposition and accordingly optimize the instrument tip's insertion trajectory\nuntil the tip approaches targets within iOCT's scanning area. Our method\nsucceeds target approaching on a retina model, and achieves an average depth\nerror of 0.0127 mm and 0.3473 mm for floating and retinal targets respectively\nin the surgical simulator without damaging the retina.",
            "author": [
                "Junjie Yang",
                "Zhihao Zhao",
                "Siyuan Shen",
                "Daniel Zapp",
                "Mathias Maier",
                "Kai Huang",
                "Nassir Navab",
                "M. Ali Nasseri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08799v1",
                "http://arxiv.org/pdf/2311.08799v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08793v1",
            "title": "German FinBERT: A German Pre-trained Language Model",
            "updated": "2023-11-15T09:07:29Z",
            "published": "2023-11-15T09:07:29Z",
            "summary": "This study presents German FinBERT, a novel pre-trained German language model\ntailored for financial textual data. The model is trained through a\ncomprehensive pre-training process, leveraging a substantial corpus comprising\nfinancial reports, ad-hoc announcements and news related to German companies.\nThe corpus size is comparable to the data sets commonly used for training\nstandard BERT models. I evaluate the performance of German FinBERT on\ndownstream tasks, specifically sentiment prediction, topic recognition and\nquestion answering against generic German language models. My results\ndemonstrate improved performance on finance-specific data, indicating the\nefficacy of German FinBERT in capturing domain-specific nuances. The presented\nfindings suggest that German FinBERT holds promise as a valuable tool for\nfinancial text analysis, potentially benefiting various applications in the\nfinancial domain.",
            "author": [
                "Moritz Scherrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08793v1",
                "http://arxiv.org/pdf/2311.08793v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08792v1",
            "title": "Matroids in OSCAR",
            "updated": "2023-11-15T09:07:08Z",
            "published": "2023-11-15T09:07:08Z",
            "summary": "OSCAR is an innovative new computer algebra system which combines and extends\nthe power of its four cornerstone systems - GAP (group theory), Singular\n(algebra and algebraic geometry), Polymake (polyhedral geometry), and Antic\n(number theory). Here, we present parts of the module handeling matroids in\nOSCAR, which will appear as a chapter of the upcoming OSCAR book. A matroid is\na fundamental and actively studied object in combinatorics. Matroids generalize\nlinear dependency in vector spaces as well as many aspects of graph theory.\nMoreover, matroids form a cornerstone of tropical geometry and a deep link\nbetween algebraic geometry and combinatorics. Our focus lies in particular on\ncomputing the realization space and the Chow ring of a matroid.",
            "author": [
                "Daniel Corey",
                "Lukas K\u00fchne",
                "Benjamin Schr\u00f6ter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08792v1",
                "http://arxiv.org/pdf/2311.08792v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG",
                "05-04 (05-02, 05E14)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08791v1",
            "title": "A Direct Approach for Solving Cloud Computing Task Assignment with Soft\n  Deadlines",
            "updated": "2023-11-15T09:06:44Z",
            "published": "2023-11-15T09:06:44Z",
            "summary": "Job scheduling in cloud computing environments is a critical yet complex\nproblem. Cloud computing user job requirements are highly dynamic and\nuncertain, while cloud computing resources are heterogeneous and constrained.\nThis paper studies the online resource allocation problem for elastic computing\njobs with soft deadlines in cloud computing environments. The main\ncontributions include: 1) Integer linear programming modeling is used to design\nan auction time scheduling framework with three key modules - resource\nallocation, evaluation, and operation, which can dynamically allocate resources\nin closed loops. 2) Methods such as time-based single resource utilization\nevaluation and weighted average evaluation are proposed to evaluate resource\nusage efficiency. 3) Soft acceptance protocols are introduced to achieve\nelastic online resource allocation. 4) The time complexity of the proposed\nalgorithms is analyzed and proven to be polynomial time, demonstrating\nefficiency. 5) Modular design makes the framework extensible. This paper\nprovides a structured cloud computing auction framework as a reference for\nbuilding practical cloud resource management systems. Future work may explore\nmore complex models of random arrival and multi-dimensional resource\nconstraints, evaluate algorithm performance on real cloud workloads, and\nfurther enhance system robustness, efficiency and fairness.",
            "author": [
                "Guang Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08791v1",
                "http://arxiv.org/pdf/2311.08791v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14710v1",
            "title": "Neuroscience inspired scientific machine learning (Part-2): Variable\n  spiking wavelet neural operator",
            "updated": "2023-11-15T09:02:01Z",
            "published": "2023-11-15T09:02:01Z",
            "summary": "We propose, in this paper, a Variable Spiking Wavelet Neural Operator\n(VS-WNO), which aims to bridge the gap between theoretical and practical\nimplementation of Artificial Intelligence (AI) algorithms for mechanics\napplications. With recent developments like the introduction of neural\noperators, AI's potential for being used in mechanics applications has\nincreased significantly. However, AI's immense energy and resource requirements\nare a hurdle in its practical field use case. The proposed VS-WNO is based on\nthe principles of spiking neural networks, which have shown promise in reducing\nthe energy requirements of the neural networks. This makes possible the use of\nsuch algorithms in edge computing. The proposed VS-WNO utilizes variable\nspiking neurons, which promote sparse communication, thus conserving energy,\nand its use is further supported by its ability to tackle regression tasks,\noften faced in the field of mechanics. Various examples dealing with partial\ndifferential equations, like Burger's equation, Allen Cahn's equation, and\nDarcy's equation, have been shown. Comparisons have been shown against wavelet\nneural operator utilizing leaky integrate and fire neurons (direct and encoded\ninputs) and vanilla wavelet neural operator utilizing artificial neurons. The\nresults produced illustrate the ability of the proposed VS-WNO to converge to\nground truth while promoting sparse communication.",
            "author": [
                "Shailesh Garg",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14710v1",
                "http://arxiv.org/pdf/2311.14710v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08788v1",
            "title": "X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented\n  Instruction Tuning with Auxiliary Evaluation Aspects",
            "updated": "2023-11-15T09:01:55Z",
            "published": "2023-11-15T09:01:55Z",
            "summary": "Natural Language Generation (NLG) typically involves evaluating the generated\ntext in various aspects (e.g., consistency and naturalness) to obtain a\ncomprehensive assessment. However, multi-aspect evaluation remains challenging\nas it may require the evaluator to generalize to any given evaluation aspect\neven if it's absent during training. In this paper, we introduce X-Eval, a\ntwo-stage instruction tuning framework to evaluate the text in both seen and\nunseen aspects customized by end users. X-Eval consists of two learning stages:\nthe vanilla instruction tuning stage that improves the model's ability to\nfollow evaluation instructions, and an enhanced instruction tuning stage that\nexploits the connections between fine-grained evaluation aspects to better\nassess text quality. To support the training of X-Eval, we collect\nAspectInstruct, the first instruction tuning dataset tailored for multi-aspect\nNLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance\ntask diversity, we devise an augmentation strategy that converts human rating\nannotations into diverse forms of NLG evaluation tasks, including scoring,\ncomparison, ranking, and Boolean question answering. Extensive experiments\nacross three essential categories of NLG tasks: dialogue generation,\nsummarization, and data-to-text coupled with 21 aspects in meta-evaluation,\ndemonstrate that our X-Eval enables even a lightweight language model to\nachieve a comparable if not higher correlation with human judgments compared to\nthe state-of-the-art NLG evaluators, such as GPT-4.",
            "author": [
                "Minqian Liu",
                "Ying Shen",
                "Zhiyang Xu",
                "Yixin Cao",
                "Eunah Cho",
                "Vaibhav Kumar",
                "Reza Ghanadan",
                "Lifu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08788v1",
                "http://arxiv.org/pdf/2311.08788v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09267v1",
            "title": "Neuroscience inspired scientific machine learning (Part-1): Variable\n  spiking neuron for regression",
            "updated": "2023-11-15T08:59:06Z",
            "published": "2023-11-15T08:59:06Z",
            "summary": "Redundant information transfer in a neural network can increase the\ncomplexity of the deep learning model, thus increasing its power consumption.\nWe introduce in this paper a novel spiking neuron, termed Variable Spiking\nNeuron (VSN), which can reduce the redundant firing using lessons from\nbiological neuron inspired Leaky Integrate and Fire Spiking Neurons (LIF-SN).\nThe proposed VSN blends LIF-SN and artificial neurons. It garners the advantage\nof intermittent firing from the LIF-SN and utilizes the advantage of continuous\nactivation from the artificial neuron. This property of the proposed VSN makes\nit suitable for regression tasks, which is a weak point for the vanilla spiking\nneurons, all while keeping the energy budget low. The proposed VSN is tested\nagainst both classification and regression tasks. The results produced advocate\nfavorably towards the efficacy of the proposed spiking neuron, particularly for\nregression tasks.",
            "author": [
                "Shailesh Garg",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09267v1",
                "http://arxiv.org/pdf/2311.09267v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08787v1",
            "title": "Polygonal Cone Control Barrier Functions (PolyC2BF) for safe navigation\n  in cluttered environments",
            "updated": "2023-11-15T08:59:05Z",
            "published": "2023-11-15T08:59:05Z",
            "summary": "In fields such as mining, search and rescue, and archaeological exploration,\nensuring real-time, collision-free navigation of robots in confined, cluttered\nenvironments is imperative. Despite the value of established path planning\nalgorithms, they often face challenges in convergence rates and handling\ndynamic infeasibilities. Alternative techniques like collision cones struggle\nto accurately represent complex obstacle geometries. This paper introduces a\nnovel category of control barrier functions, known as Polygonal Cone Control\nBarrier Function (PolyC2BF), which addresses overestimation and computational\ncomplexity issues. The proposed PolyC2BF, formulated as a Quadratic Programming\n(QP) problem, proves effective in facilitating collision-free movement of\nmultiple robots in complex environments. The efficacy of this approach is\nfurther demonstrated through PyBullet simulations on quadruped (unicycle\nmodel), and crazyflie 2.1 (quadrotor model) in cluttered environments.",
            "author": [
                "Manan Tayal",
                "Shishir Kolathaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08787v1",
                "http://arxiv.org/pdf/2311.08787v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08786v1",
            "title": "HFORD: High-Fidelity and Occlusion-Robust De-identification for Face\n  Privacy Protection",
            "updated": "2023-11-15T08:59:02Z",
            "published": "2023-11-15T08:59:02Z",
            "summary": "With the popularity of smart devices and the development of computer vision\ntechnology, concerns about face privacy protection are growing. The face\nde-identification technique is a practical way to solve the identity protection\nproblem. The existing facial de-identification methods have revealed several\nproblems, including the impact on the realism of anonymized results when faced\nwith occlusions and the inability to maintain identity-irrelevant details in\nanonymized results. We present a High-Fidelity and Occlusion-Robust\nDe-identification (HFORD) method to deal with these issues. This approach can\ndisentangle identities and attributes while preserving image-specific details\nsuch as background, facial features (e.g., wrinkles), and lighting, even in\noccluded scenes. To disentangle the latent codes in the GAN inversion space, we\nintroduce an Identity Disentanglement Module (IDM). This module selects the\nlatent codes that are closely related to the identity. It further separates the\nlatent codes into identity-related codes and attribute-related codes, enabling\nthe network to preserve attributes while only modifying the identity. To ensure\nthe preservation of image details and enhance the network's robustness to\nocclusions, we propose an Attribute Retention Module (ARM). This module\nadaptively preserves identity-irrelevant details and facial occlusions and\nblends them into the generated results in a modulated manner. Extensive\nexperiments show that our method has higher quality, better detail fidelity,\nand stronger occlusion robustness than other face de-identification methods.",
            "author": [
                "Dongxin Chen",
                "Mingrui Zhu",
                "Nannan Wang",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08786v1",
                "http://arxiv.org/pdf/2311.08786v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08782v1",
            "title": "Language Semantic Graph Guided Data-Efficient Learning",
            "updated": "2023-11-15T08:54:57Z",
            "published": "2023-11-15T08:54:57Z",
            "summary": "Developing generalizable models that can effectively learn from limited data\nand with minimal reliance on human supervision is a significant objective\nwithin the machine learning community, particularly in the era of deep neural\nnetworks. Therefore, to achieve data-efficient learning, researchers typically\nexplore approaches that can leverage more related or unlabeled data without\nnecessitating additional manual labeling efforts, such as Semi-Supervised\nLearning (SSL), Transfer Learning (TL), and Data Augmentation (DA). SSL\nleverages unlabeled data in the training process, while TL enables the transfer\nof expertise from related data distributions. DA broadens the dataset by\nsynthesizing new data from existing examples. However, the significance of\nadditional knowledge contained within labels has been largely overlooked in\nresearch. In this paper, we propose a novel perspective on data efficiency that\ninvolves exploiting the semantic information contained in the labels of the\navailable data. Specifically, we introduce a Language Semantic Graph (LSG)\nwhich is constructed from labels manifest as natural language descriptions.\nUpon this graph, an auxiliary graph neural network is trained to extract\nhigh-level semantic relations and then used to guide the training of the\nprimary model, enabling more adequate utilization of label knowledge. Across\nimage, video, and audio modalities, we utilize the LSG method in both TL and\nSSL scenarios and illustrate its versatility in significantly enhancing\nperformance compared to other data-efficient learning approaches. Additionally,\nour in-depth analysis shows that the LSG method also expedites the training\nprocess.",
            "author": [
                "Wenxuan Ma",
                "Shuang Li",
                "Lincan Cai",
                "Jingxuan Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08782v1",
                "http://arxiv.org/pdf/2311.08782v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08776v1",
            "title": "Context Adaptive Cooperation",
            "updated": "2023-11-15T08:44:44Z",
            "published": "2023-11-15T08:44:44Z",
            "summary": "Reliable broadcast and consensus are the two pillars that support a lot of\nnon-trivial fault-tolerant distributed middleware and fault-tolerant\ndistributed systems. While they have close definitions, they strongly differ in\nthe underlying assumptions needed to implement each of them. Reliable broadcast\ncan be implemented in asynchronous systems in the presence of crash or\nByzantine failures while Consensus cannot. This key difference stems from the\nfact that consensus involves synchronization between multiple processes that\nconcurrently propose values, while reliable broadcast simply involves\ndelivering a message from a predefined sender. This paper strikes a balance\nbetween these two agreement abstractions in the presence of Byzantine failures.\nIt proposes CAC, a novel agreement abstraction that enables multiple processes\nto broadcast messages simultaneously, while guaranteeing that (despite\npotential conflicts, asynchrony, and Byzantine behaviors) the non-faulty\nprocesses will agree on messages deliveries. We show that this novel\nabstraction can enable more efficient algorithms for a variety of applications\n(such as money transfer where several people can share a same account). This is\nobtained by focusing the need for synchronization only on the processes that\nactually need to synchronize.",
            "author": [
                "Timoth\u00e9 Albouy",
                "Davide Frey",
                "Mathieu Gestin",
                "Michel Raynal",
                "Fran\u00e7ois Ta\u00efani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08776v1",
                "http://arxiv.org/pdf/2311.08776v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "68W15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08774v2",
            "title": "Two-stage Joint Transductive and Inductive learning for Nuclei\n  Segmentation",
            "updated": "2023-11-17T19:26:53Z",
            "published": "2023-11-15T08:37:11Z",
            "summary": "AI-assisted nuclei segmentation in histopathological images is a crucial task\nin the diagnosis and treatment of cancer diseases. It decreases the time\nrequired to manually screen microscopic tissue images and can resolve the\nconflict between pathologists during diagnosis. Deep Learning has proven useful\nin such a task. However, lack of labeled data is a significant barrier for deep\nlearning-based approaches. In this study, we propose a novel approach to nuclei\nsegmentation that leverages the available labelled and unlabelled data. The\nproposed method combines the strengths of both transductive and inductive\nlearning, which have been previously attempted separately, into a single\nframework. Inductive learning aims at approximating the general function and\ngeneralizing to unseen test data, while transductive learning has the potential\nof leveraging the unlabelled test data to improve the classification. To the\nbest of our knowledge, this is the first study to propose such a hybrid\napproach for medical image segmentation. Moreover, we propose a novel two-stage\ntransductive inference scheme. We evaluate our approach on MoNuSeg benchmark to\ndemonstrate the efficacy and potential of our method.",
            "author": [
                "Hesham Ali",
                "Idriss Tondji",
                "Mennatullah Siam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08774v2",
                "http://arxiv.org/pdf/2311.08774v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09266v1",
            "title": "Adversarially Robust Spiking Neural Networks Through Conversion",
            "updated": "2023-11-15T08:33:46Z",
            "published": "2023-11-15T08:33:46Z",
            "summary": "Spiking neural networks (SNNs) provide an energy-efficient alternative to a\nvariety of artificial neural network (ANN) based AI applications. As the\nprogress in neuromorphic computing with SNNs expands their use in applications,\nthe problem of adversarial robustness of SNNs becomes more pronounced. To the\ncontrary of the widely explored end-to-end adversarial training based\nsolutions, we address the limited progress in scalable robust SNN training\nmethods by proposing an adversarially robust ANN-to-SNN conversion algorithm.\nOur method provides an efficient approach to embrace various computationally\ndemanding robust learning objectives that have been proposed for ANNs. During a\npost-conversion robust finetuning phase, our method adversarially optimizes\nboth layer-wise firing thresholds and synaptic connectivity weights of the SNN\nto maintain transferred robustness gains from the pre-trained ANN. We perform\nexperimental evaluations in numerous adaptive adversarial settings that account\nfor the spike-based operation dynamics of SNNs, and show that our approach\nyields a scalable state-of-the-art solution for adversarially robust deep SNNs\nwith low-latency.",
            "author": [
                "Ozan \u00d6zdenizci",
                "Robert Legenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09266v1",
                "http://arxiv.org/pdf/2311.09266v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08769v1",
            "title": "adF: A Novel System for Measuring Web Fingerprinting through Ads",
            "updated": "2023-11-15T08:30:50Z",
            "published": "2023-11-15T08:30:50Z",
            "summary": "This paper introduces adF, a novel system for analyzing the vulnerability of\ndifferent devices, Operating Systems (OSes), and browsers to web\nfingerprinting. adF performs its measurements from code inserted in ads. We\nhave used our system in several ad campaigns that delivered 5,40 million ad\nimpressions. The collected data enable us to assess the vulnerability of\ncurrent desktop and mobile devices to web fingerprinting. Based on our results,\nwe estimate that 64% of desktop devices and 40% of mobile devices can be\nuniquely fingerprinted with our web fingerprinting system. However, the\nresilience to web fingerprinting varies significantly across browsers and\ndevice types, with Chrome on desktops being the most vulnerable configuration.",
            "author": [
                "Miguel A. Bermejo-Agueda",
                "Patricia Callejo",
                "Rub\u00e9n Cuevas",
                "\u00c1ngel Cuevas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08769v1",
                "http://arxiv.org/pdf/2311.08769v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09265v1",
            "title": "FastBlend: a Powerful Model-Free Toolkit Making Video Stylization Easier",
            "updated": "2023-11-15T08:28:28Z",
            "published": "2023-11-15T08:28:28Z",
            "summary": "With the emergence of diffusion models and rapid development in image\nprocessing, it has become effortless to generate fancy images in tasks such as\nstyle transfer and image editing. However, these impressive image processing\napproaches face consistency issues in video processing. In this paper, we\npropose a powerful model-free toolkit called FastBlend to address the\nconsistency problem for video processing. Based on a patch matching algorithm,\nwe design two inference modes, including blending and interpolation. In the\nblending mode, FastBlend eliminates video flicker by blending the frames within\na sliding window. Moreover, we optimize both computational efficiency and video\nquality according to different application scenarios. In the interpolation\nmode, given one or more keyframes rendered by diffusion models, FastBlend can\nrender the whole video. Since FastBlend does not modify the generation process\nof diffusion models, it exhibits excellent compatibility. Extensive experiments\nhave demonstrated the effectiveness of FastBlend. In the blending mode,\nFastBlend outperforms existing methods for video deflickering and video\nsynthesis. In the interpolation mode, FastBlend surpasses video interpolation\nand model-based video processing approaches. The source codes have been\nreleased on GitHub.",
            "author": [
                "Zhongjie Duan",
                "Chengyu Wang",
                "Cen Chen",
                "Weining Qian",
                "Jun Huang",
                "Mingyi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09265v1",
                "http://arxiv.org/pdf/2311.09265v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08768v1",
            "title": "Three Conjectures on Unexpectedeness",
            "updated": "2023-11-15T08:24:41Z",
            "published": "2023-11-15T08:24:41Z",
            "summary": "Unexpectedness is a central concept in Simplicity Theory, a theory of\ncognition relating various inferential processes to the computation of\nKolmogorov complexities, rather than probabilities. Its predictive power has\nbeen confirmed by several experiments with human subjects, yet its theoretical\nbasis remains largely unexplored: why does it work? This paper lays the\ngroundwork for three theoretical conjectures. First, unexpectedness can be seen\nas a generalization of Bayes' rule. Second, the frequentist core of\nunexpectedness can be connected to the function of tracking ergodic properties\nof the world. Third, unexpectedness can be seen as constituent of various\nmeasures of divergence between the entropy of the world (environment) and the\nvariety of the observer (system). The resulting framework hints to research\ndirections that go beyond the division between probabilistic and logical\napproaches, potentially bringing new insights into the extraction of causal\nrelations, and into the role of descriptive mechanisms in learning.",
            "author": [
                "Giovanni Sileno",
                "Jean-Louis Dessalles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08768v1",
                "http://arxiv.org/pdf/2311.08768v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08764v1",
            "title": "Combining Past, Present and Future: A Self-Supervised Approach for Class\n  Incremental Learning",
            "updated": "2023-11-15T08:13:52Z",
            "published": "2023-11-15T08:13:52Z",
            "summary": "Class Incremental Learning (CIL) aims to handle the scenario where data of\nnovel classes occur continuously and sequentially. The model should recognize\nthe sequential novel classes while alleviating the catastrophic forgetting. In\nthe self-supervised manner, it becomes more challenging to avoid the conflict\nbetween the feature embedding spaces of novel classes and old ones without any\nclass labels. To address the problem, we propose a self-supervised CIL\nframework CPPF, meaning Combining Past, Present and Future. In detail, CPPF\nconsists of a prototype clustering module (PC), an embedding space reserving\nmodule (ESR) and a multi-teacher distillation module (MTD). 1) The PC and the\nESR modules reserve embedding space for subsequent phases at the prototype\nlevel and the feature level respectively to prepare for knowledge learned in\nthe future. 2) The MTD module maintains the representations of the current\nphase without the interference of past knowledge. One of the teacher networks\nretains the representations of the past phases, and the other teacher network\ndistills relation information of the current phase to the student network.\nExtensive experiments on CIFAR100 and ImageNet100 datasets demonstrate that our\nproposed method boosts the performance of self-supervised class incremental\nlearning. We will release code in the near future.",
            "author": [
                "Xiaoshuang Chen",
                "Zhongyi Sun",
                "Ke Yan",
                "Shouhong Ding",
                "Hongtao Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08764v1",
                "http://arxiv.org/pdf/2311.08764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08760v1",
            "title": "Forms of Understanding of XAI-Explanations",
            "updated": "2023-11-15T08:06:51Z",
            "published": "2023-11-15T08:06:51Z",
            "summary": "Explainability has become an important topic in computer science and\nartificial intelligence, leading to a subfield called Explainable Artificial\nIntelligence (XAI). The goal of providing or seeking explanations is to achieve\n(better) 'understanding' on the part of the explainee. However, what it means\nto 'understand' is still not clearly defined, and the concept itself is rarely\nthe subject of scientific investigation. This conceptual article aims to\npresent a model of forms of understanding in the context of XAI and beyond.\nFrom an interdisciplinary perspective bringing together computer science,\nlinguistics, sociology, and psychology, a definition of understanding and its\nforms, assessment, and dynamics during the process of giving everyday\nexplanations are explored. Two types of understanding are considered as\npossible outcomes of explanations, namely enabledness, 'knowing how' to do or\ndecide something, and comprehension, 'knowing that' -- both in different\ndegrees (from shallow to deep). Explanations regularly start with shallow\nunderstanding in a specific domain and can lead to deep comprehension and\nenabledness of the explanandum, which we see as a prerequisite for human users\nto gain agency. In this process, the increase of comprehension and enabledness\nare highly interdependent. Against the background of this systematization,\nspecial challenges of understanding in XAI are discussed.",
            "author": [
                "Hendrik Buschmeier",
                "Heike M. Buhl",
                "Friederike Kern",
                "Angela Grimminger",
                "Helen Beierling",
                "Josephine Fisher",
                "Andr\u00e9 Gro\u00df",
                "Ilona Horwath",
                "Nils Klowait",
                "Stefan Lazarov",
                "Michael Lenke",
                "Vivien Lohmer",
                "Katharina Rohlfing",
                "Ingrid Scharlau",
                "Amit Singh",
                "Lutz Terfloth",
                "Anna-Lisa Vollmer",
                "Yu Wang",
                "Annedore Wilmes",
                "Britta Wrede"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08760v1",
                "http://arxiv.org/pdf/2311.08760v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08759v1",
            "title": "4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters",
            "updated": "2023-11-15T08:01:12Z",
            "published": "2023-11-15T08:01:12Z",
            "summary": "The illumination of improperly exposed photographs has been widely corrected\nusing deep convolutional neural networks or Transformers. Despite with\npromising performance, these methods usually suffer from large parameter\namounts and heavy computational FLOPs on high-resolution photographs. In this\npaper, we propose extremely light-weight (with only ~8K parameters) Multi-Scale\nLinear Transformation (MSLT) networks under the multi-layer perception\narchitecture, which can process 4K-resolution sRGB images at 125\nFrame-Per-Second (FPS) by a Titan RTX GPU. Specifically, the proposed MSLT\nnetworks first decompose an input image into high and low frequency layers by\nLaplacian pyramid techniques, and then sequentially correct different layers by\npixel-adaptive linear transformation, which is implemented by efficient\nbilateral grid learning or 1x1 convolutions. Experiments on two benchmark\ndatasets demonstrate the efficiency of our MSLTs against the state-of-the-arts\non photo exposure correction. Extensive ablation studies validate the\neffectiveness of our contributions. The code is available at\nhttps://github.com/Zhou-Yijie/MSLTNet.",
            "author": [
                "Yijie Zhou",
                "Chao Li",
                "Jin Liang",
                "Tianyi Xu",
                "Xin Liu",
                "Jun Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08759v1",
                "http://arxiv.org/pdf/2311.08759v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08757v1",
            "title": "A Scalable Two-Level Domain Decomposition Eigensolver for Periodic\n  Schr\u00f6dinger Eigenstates in Anisotropically Expanding Domains",
            "updated": "2023-11-15T07:57:28Z",
            "published": "2023-11-15T07:57:28Z",
            "summary": "Accelerating iterative eigenvalue algorithms is often achieved by employing a\nspectral shifting strategy. Unfortunately, improved shifting typically leads to\na smaller eigenvalue for the resulting shifted operator, which in turn results\nin a high condition number of the underlying solution matrix, posing a major\nchallenge for iterative linear solvers. This paper introduces a two-level\ndomain decomposition preconditioner that addresses this issue for the linear\nSchr\\\"odinger eigenvalue problem, even in the presence of a vanishing\neigenvalue gap in non-uniform, expanding domains. Since the quasi-optimal\nshift, which is already available as the solution to a spectral cell problem,\nis required for the eigenvalue solver, it is logical to also use its associated\neigenfunction as a generator to construct a coarse space. We analyze the\nresulting two-level additive Schwarz preconditioner and obtain a condition\nnumber bound that is independent of the domain's anisotropy, despite the need\nfor only one basis function per subdomain for the coarse solver. Several\nnumerical examples are presented to illustrate its flexibility and efficiency.",
            "author": [
                "Lambert Theisen",
                "Benjamin Stamm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08757v1",
                "http://arxiv.org/pdf/2311.08757v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.CE",
                "cs.NA",
                "65N25, 65F15, 65N30, 65F10, 65N22, 65N55, 65F08"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08756v1",
            "title": "Accelerating Toeplitz Neural Network with Constant-time Inference\n  Complexity",
            "updated": "2023-11-15T07:50:57Z",
            "published": "2023-11-15T07:50:57Z",
            "summary": "Toeplitz Neural Networks (TNNs) have exhibited outstanding performance in\nvarious sequence modeling tasks. They outperform commonly used\nTransformer-based models while benefiting from log-linear space-time\ncomplexities. On the other hand, State Space Models (SSMs) achieve lower\nperformance than TNNs in language modeling but offer the advantage of constant\ninference complexity. In this paper, we aim to combine the strengths of TNNs\nand SSMs by converting TNNs to SSMs during inference, thereby enabling TNNs to\nachieve the same constant inference complexities as SSMs. To accomplish this,\nwe formulate the conversion process as an optimization problem and provide a\nclosed-form solution. We demonstrate how to transform the target equation into\na Vandermonde linear system problem, which can be efficiently solved using the\nDiscrete Fourier Transform (DFT). Notably, our method requires no training and\nmaintains numerical stability. It can be also applied to any LongConv-based\nmodel. To assess its effectiveness, we conduct extensive experiments on\nlanguage modeling tasks across various settings. Additionally, we compare our\nmethod to other gradient-descent solutions, highlighting the superior numerical\nstability of our approach. The source code is available at\nhttps://github.com/OpenNLPLab/ETSC-Exact-Toeplitz-to-SSM-Conversion.",
            "author": [
                "Zhen Qin",
                "Yiran Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08756v1",
                "http://arxiv.org/pdf/2311.08756v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08755v1",
            "title": "Environment-independent mmWave Fall Detection with Interacting Multiple\n  Model",
            "updated": "2023-11-15T07:49:46Z",
            "published": "2023-11-15T07:49:46Z",
            "summary": "The ageing society brings attention to daily elderly care through sensing\ntechnologies. The future smart home is expected to enable in-home daily\nmonitoring, such as fall detection, for seniors in a non-invasive,\nnon-cooperative, and non-contact manner. The mmWave radar is a promising\ncandidate technology for its privacy-preserving and non-contact manner.\nHowever, existing solutions suffer from low accuracy and robustness due to\nenvironment dependent features. In this paper, we present FADE\n(\\underline{FA}ll \\underline{DE}tection), a practical fall detection radar\nsystem with enhanced accuracy and robustness in real-world scenarios. The key\nenabler underlying FADE is an interacting multiple model (IMM) state estimator\nthat can extract environment-independent features for highly accurate and\ninstantaneous fall detection. Furthermore, we proposed a robust multiple-user\ntracking system to deal with noises from the environment and other human\nbodies. We deployed our algorithm on low computing power and low power\nconsumption system-on-chip (SoC) composed of data front end, DSP, and ARM\nprocessor, and tested its performance in real-world. The experiment shows that\nthe accuracy of fall detection is up to 95\\%.",
            "author": [
                "Xuyao Yu",
                "Jiazhao Wang",
                "Wenchao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08755v1",
                "http://arxiv.org/pdf/2311.08755v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08752v1",
            "title": "ProSpar-GP: scalable Gaussian process modeling with massive\n  non-stationary datasets",
            "updated": "2023-11-15T07:39:25Z",
            "published": "2023-11-15T07:39:25Z",
            "summary": "Gaussian processes (GPs) are a popular class of Bayesian nonparametric\nmodels, but its training can be computationally burdensome for massive training\ndatasets. While there has been notable work on scaling up these models for big\ndata, existing methods typically rely on a stationary GP assumption for\napproximation, and can thus perform poorly when the underlying response surface\nis non-stationary, i.e., it has some regions of rapid change and other regions\nwith little change. Such non-stationarity is, however, ubiquitous in real-world\nproblems, including our motivating application for surrogate modeling of\ncomputer experiments. We thus propose a new Product of Sparse GP (ProSpar-GP)\nmethod for scalable GP modeling with massive non-stationary data. The\nProSpar-GP makes use of a carefully-constructed product-of-experts formulation\nof sparse GP experts, where different experts are placed within local regions\nof non-stationarity. These GP experts are fit via a novel variational inference\napproach, which capitalizes on mini-batching and GPU acceleration for efficient\noptimization of inducing points and length-scale parameters for each expert. We\nfurther show that the ProSpar-GP is Kolmogorov-consistent, in that its\ngenerative distribution defines a valid stochastic process over the prediction\nspace; such a property provides essential stability for variational inference,\nparticularly in the presence of non-stationarity. We then demonstrate the\nimproved performance of the ProSpar-GP over the state-of-the-art, in a suite of\nnumerical experiments and an application for surrogate modeling of a satellite\ndrag simulator.",
            "author": [
                "Kevin Li",
                "Simon Mak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08752v1",
                "http://arxiv.org/pdf/2311.08752v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09263v1",
            "title": "Auto-ICL: In-Context Learning without Human Supervision",
            "updated": "2023-11-15T07:37:28Z",
            "published": "2023-11-15T07:37:28Z",
            "summary": "In the era of Large Language Models (LLMs), human-computer interaction has\nevolved towards natural language, offering unprecedented flexibility. Despite\nthis, LLMs are heavily reliant on well-structured prompts to function\nefficiently within the realm of In-Context Learning. Vanilla In-Context\nLearning relies on human-provided contexts, such as labeled examples, explicit\ninstructions, or other guiding mechanisms that shape the model's outputs. To\naddress this challenge, our study presents a universal framework named\nAutomatic In-Context Learning. Upon receiving a user's request, we ask the\nmodel to independently generate examples, including labels, instructions, or\nreasoning pathways. The model then leverages this self-produced context to\ntackle the given problem. Our approach is universally adaptable and can be\nimplemented in any setting where vanilla In-Context Learning is applicable. We\ndemonstrate that our method yields strong performance across a range of tasks,\nstanding up well when compared to existing methods.",
            "author": [
                "Jinghan Yang",
                "Shuming Ma",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09263v1",
                "http://arxiv.org/pdf/2311.09263v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08747v1",
            "title": "Improved Dense Nested Attention Network Based on Transformer for\n  Infrared Small Target Detection",
            "updated": "2023-11-15T07:29:24Z",
            "published": "2023-11-15T07:29:24Z",
            "summary": "Infrared small target detection based on deep learning offers unique\nadvantages in separating small targets from complex and dynamic backgrounds.\nHowever, the features of infrared small targets gradually weaken as the depth\nof convolutional neural network (CNN) increases. To address this issue, we\npropose a novel method for detecting infrared small targets called improved\ndense nested attention network (IDNANet), which is based on the transformer\narchitecture. We preserve the dense nested structure of dense nested attention\nnetwork (DNANet) and introduce the Swin-transformer during feature extraction\nstage to enhance the continuity of features. Furthermore, we integrate the\nACmix attention structure into the dense nested structure to enhance the\nfeatures of intermediate layers. Additionally, we design a weighted dice binary\ncross-entropy (WD-BCE) loss function to mitigate the negative impact of\nforeground-background imbalance in the samples. Moreover, we develop a dataset\nspecifically for infrared small targets, called BIT-SIRST. The dataset\ncomprises a significant amount of real-world targets and manually annotated\nlabels, as well as synthetic data and corresponding labels. We have evaluated\nthe effectiveness of our method through experiments conducted on public\ndatasets. In comparison to other state-of-the-art methods, our approach\noutperforms in terms of probability of detection (P_d), false-alarm rate (F_a),\nand mean intersection of union ($mIoU$). The $mIoU$ reaches 90.89 on the\nNUDT-SIRST dataset and 79.72 on the NUAA-SIRST dataset.",
            "author": [
                "Chun Bao",
                "Jie Cao",
                "Yaqian Ning",
                "Tianhua Zhao",
                "Zhijun Li",
                "Zechen Wang",
                "Li Zhang",
                "Qun Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08747v1",
                "http://arxiv.org/pdf/2311.08747v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08746v1",
            "title": "A Diffusion Model Based Quality Enhancement Method for HEVC Compressed\n  Video",
            "updated": "2023-11-15T07:29:23Z",
            "published": "2023-11-15T07:29:23Z",
            "summary": "Video post-processing methods can improve the quality of compressed videos at\nthe decoder side. Most of the existing methods need to train corresponding\nmodels for compressed videos with different quantization parameters to improve\nthe quality of compressed videos. However, in most cases, the quantization\nparameters of the decoded video are unknown. This makes existing methods have\ntheir limitations in improving video quality. To tackle this problem, this work\nproposes a diffusion model based post-processing method for compressed videos.\nThe proposed method first estimates the feature vectors of the compressed video\nand then uses the estimated feature vectors as the prior information for the\nquality enhancement model to adaptively enhance the quality of compressed video\nwith different quantization parameters. Experimental results show that the\nquality enhancement results of our proposed method on mixed datasets are\nsuperior to existing methods.",
            "author": [
                "Zheng Liu",
                "Honggang Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08746v1",
                "http://arxiv.org/pdf/2311.08746v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08740v1",
            "title": "AdVENTR: Autonomous Robot Navigation in Complex Outdoor Environments",
            "updated": "2023-11-15T07:10:13Z",
            "published": "2023-11-15T07:10:13Z",
            "summary": "We present a novel system, AdVENTR for autonomous robot navigation in\nunstructured outdoor environments that consist of uneven and vegetated\nterrains. Our approach is general and can enable both wheeled and legged robots\nto handle outdoor terrain complexity including unevenness, surface properties\nlike poor traction, granularity, obstacle stiffness, etc. We use data from\nsensors including RGB cameras, 3D Lidar, IMU, robot odometry, and pose\ninformation with efficient learning-based perception and planning algorithms\nthat can execute on edge computing hardware. Our system uses a scene-aware\nswitching method to perceive the environment for navigation at any time instant\nand dynamically switches between multiple perception algorithms. We test our\nsystem in a variety of sloped, rocky, muddy, and densely vegetated terrains and\ndemonstrate its performance on Husky and Spot robots.",
            "author": [
                "Kasun Weerakoon",
                "Adarsh Jagan Sathyamoorthy",
                "Mohamed Elnoor",
                "Dinesh Manocha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08740v1",
                "http://arxiv.org/pdf/2311.08740v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08736v1",
            "title": "Split representation in celestial holography",
            "updated": "2023-11-15T06:58:29Z",
            "published": "2023-11-15T06:58:29Z",
            "summary": "We develop a split representation for celestial amplitudes in celestial\nholography, by cutting internal lines of Feynman diagrams in Minkowski space.\nMore explicitly, the bulk-to-bulk propagators associated with the internal\nlines are expressed as a product of two boundary-to-bulk propagators with a\ncoinciding boundary point integrated over the celestial sphere. Applying this\nsplit representation, we compute the conformal partial wave and conformal block\nexpansions of celestial four-point functions of massless scalars and photons on\nthe Euclidean celestial sphere. In the $t$-channel massless scalar amplitude,\nwe observe novel intermediate exchanges of staggered modules in the conformal\nblock expansion.",
            "author": [
                "Chi-Ming Chang",
                "Reiko Liu",
                "Wen-Jie Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08736v1",
                "http://arxiv.org/pdf/2311.08736v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08734v1",
            "title": "Thread of Thought Unraveling Chaotic Contexts",
            "updated": "2023-11-15T06:54:44Z",
            "published": "2023-11-15T06:54:44Z",
            "summary": "Large Language Models (LLMs) have ushered in a transformative era in the\nfield of natural language processing, excelling in tasks related to text\ncomprehension and generation. Nevertheless, they encounter difficulties when\nconfronted with chaotic contexts (e.g., distractors rather than long irrelevant\ncontext), leading to the inadvertent omission of certain details within the\nchaotic context. In response to these challenges, we introduce the \"Thread of\nThought\" (ThoT) strategy, which draws inspiration from human cognitive\nprocesses. ThoT systematically segments and analyzes extended contexts while\nadeptly selecting pertinent information. This strategy serves as a versatile\n\"plug-and-play\" module, seamlessly integrating with various LLMs and prompting\ntechniques. In the experiments, we utilize the PopQA and EntityQ datasets, as\nwell as a Multi-Turn Conversation Response dataset (MTCR) we collected, to\nillustrate that ThoT significantly improves reasoning performance compared to\nother prompting techniques.",
            "author": [
                "Yucheng Zhou",
                "Xiubo Geng",
                "Tao Shen",
                "Chongyang Tao",
                "Guodong Long",
                "Jian-Guang Lou",
                "Jianbing Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08734v1",
                "http://arxiv.org/pdf/2311.08734v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08732v1",
            "title": "Enhancing Emergency Decision-making with Knowledge Graphs and Large\n  Language Models",
            "updated": "2023-11-15T06:48:50Z",
            "published": "2023-11-15T06:48:50Z",
            "summary": "Emergency management urgently requires comprehensive knowledge while having a\nhigh possibility to go beyond individuals' cognitive scope. Therefore,\nartificial intelligence(AI) supported decision-making under that circumstance\nis of vital importance. Recent emerging large language models (LLM) provide a\nnew direction for enhancing targeted machine intelligence. However, the\nutilization of LLM directly would inevitably introduce unreliable output for\nits inherent issue of hallucination and poor reasoning skills. In this work, we\ndevelop a system called Enhancing Emergency decision-making with Knowledge\nGraph and LLM (E-KELL), which provides evidence-based decision-making in\nvarious emergency stages. The study constructs a structured emergency knowledge\ngraph and guides LLMs to reason over it via a prompt chain. In real-world\nevaluations, E-KELL receives scores of 9.06, 9.09, 9.03, and 9.09 in\ncomprehensibility, accuracy, conciseness, and instructiveness from a group of\nemergency commanders and firefighters, demonstrating a significant improvement\nacross various situations compared to baseline models. This work introduces a\nnovel approach to providing reliable emergency decision support.",
            "author": [
                "Minze Chen",
                "Zhenxiang Tao",
                "Weitong Tang",
                "Tingxin Qin",
                "Rui Yang",
                "Chunli Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08732v1",
                "http://arxiv.org/pdf/2311.08732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08728v2",
            "title": "Optimal Placement of Capacitor in Distribution System using Particle\n  Swarm Optimization",
            "updated": "2023-11-16T08:22:10Z",
            "published": "2023-11-15T06:38:21Z",
            "summary": "In power systems, the incorporation of capacitors offers a wide range of\nestablished advantages. These benefits encompass the enhancement of the systems\npower factor, optimization of voltage profiles, increased capacity for current\nflow through cables and transformers, and the mitigation of losses attributed\nto the compensation of reactive power components. Different techniques have\nbeen applied to enhance the performance of the distribution system by reducing\nline losses. This paper focuses on reducing line losses through the optimal\nplacement and sizing of capacitors. Optimal capacitor placement is analysed\nusing load flow analysis with the Newton Raphson method. The placement of\ncapacitor optimization is related to the sensitivity of the buses, which\ndepends on the loss sensitivity factor. The optimal capacitor size is\ndetermined using Particle Swarm Optimization (PSO). The analysis is conducted\nusing the IEEE 14 bus system in MATLAB. The results reveal that placing\ncapacitors at the most sensitive bus locations leads to a significant reduction\nin line losses. Additionally, the optimal capacitor size has a substantial\nimpact on improving the voltage profile and the power loss is reduced by 21.02\npercent through the proposed method.",
            "author": [
                "Izhar Ul Haq"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08728v2",
                "http://arxiv.org/pdf/2311.08728v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.NE",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08726v1",
            "title": "Uncertainty Estimation on Sequential Labeling via Uncertainty\n  Transmission",
            "updated": "2023-11-15T06:36:29Z",
            "published": "2023-11-15T06:36:29Z",
            "summary": "Sequential labeling is a task predicting labels for each token in a sequence,\nsuch as Named Entity Recognition (NER). NER tasks aim to extract entities and\npredict their labels given a text, which is important in information\nextraction. Although previous works have shown great progress in improving NER\nperformance, uncertainty estimation on NER (UE-NER) is still underexplored but\nessential. This work focuses on UE-NER, which aims to estimate uncertainty\nscores for the NER predictions. Previous uncertainty estimation models often\noverlook two unique characteristics of NER: the connection between entities\n(i.e., one entity embedding is learned based on the other ones) and wrong span\ncases in the entity extraction subtask. Therefore, we propose a Sequential\nLabeling Posterior Network (SLPN) to estimate uncertainty scores for the\nextracted entities, considering uncertainty transmitted from other tokens.\nMoreover, we have defined an evaluation strategy to address the specificity of\nwrong-span cases. Our SLPN has achieved significant improvements on two\ndatasets, such as a 5.54-point improvement in AUPR on the MIT-Restaurant\ndataset.",
            "author": [
                "Jianfeng He",
                "Linlin Yu",
                "Shuo Lei",
                "Chang-Tien Lu",
                "Feng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08726v1",
                "http://arxiv.org/pdf/2311.08726v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08725v1",
            "title": "A General Theory of Liquidity Provisioning for Automated Market Makers",
            "updated": "2023-11-15T06:35:50Z",
            "published": "2023-11-15T06:35:50Z",
            "summary": "In decentralized finance, it is common for automated market makers to\nprovision liquidity from external parties. The market maker rewards these\nliquidity providers with a cut of the trading fees, in exchange for the risk\nthey take on. A handful of protocols for liquidity provisioning have been\nproposed, such as Uniswap V2 and V3, with specific and sometimes complex rules\nfor collecting liquidity deposits, executing trades, and dividing up fees.\nBeyond these examples, and a broader understanding of liquidity provisioning,\nand particularly the design space from which one could choose a different\nprotocols, has been out of reach. In this work, we show that one can view\nliquidity provisioning very broadly as the practice of running several market\nmakers \"in parallel\": each market maker provides its own liquidity, yet the\ncombined group can operate as a single coherent market. We prove that this\ngeneral protocol, when restricted to specific forms of the constituent market\nmakers, recovers Uniswap V2 and V3 as special cases. We then go on to propose a\nnew restriction which may have advantages over Uniswap V3. In the context of\nprediction markets, where computation costs are less constrained, our general\nprotocol gives a maximally flexible way to provision liquidity. We conclude\nwith remarks about the nature of liquidity and fees in markets with more than 2\nassets, and several open questions.",
            "author": [
                "Adithya Bhaskara",
                "Rafael Frongillo",
                "Maneesha Papireddygari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08725v1",
                "http://arxiv.org/pdf/2311.08725v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08724v1",
            "title": "Method for Text Entity Linking in Power Distribution Scheduling Oriented\n  to Power Distribution Network Knowledge Graph",
            "updated": "2023-11-15T06:35:01Z",
            "published": "2023-11-15T06:35:01Z",
            "summary": "The proposed method for linking entities in power distribution dispatch texts\nto a power distribution network knowledge graph is based on a deep\nunderstanding of these networks. This method leverages the unique features of\nentities in both the power distribution network's knowledge graph and the\ndispatch texts, focusing on their semantic, phonetic, and syntactic\ncharacteristics. An enhanced model, the Lexical Semantic Feature-based Skip\nConvolutional Neural Network (LSF-SCNN), is utilized for effectively matching\ndispatch text entities with those in the knowledge graph. The efficacy of this\nmodel, compared to a control model, is evaluated through cross-validation\nmethods in real-world power distribution dispatch scenarios. The results\nindicate that the LSF-SCNN model excels in accurately linking a variety of\nentity types, demonstrating high overall accuracy in entity linking when the\nprocess is conducted in English.",
            "author": [
                "Xiang Li",
                "Che Wang",
                "Bing Li",
                "Hao Chen",
                "Sizhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08724v1",
                "http://arxiv.org/pdf/2311.08724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09261v1",
            "title": "Emerging Drug Interaction Prediction Enabled by Flow-based Graph Neural\n  Network with Biomedical Network",
            "updated": "2023-11-15T06:34:00Z",
            "published": "2023-11-15T06:34:00Z",
            "summary": "Accurately predicting drug-drug interactions (DDI) for emerging drugs, which\noffer possibilities for treating and alleviating diseases, with computational\nmethods can improve patient care and contribute to efficient drug development.\nHowever, many existing computational methods require large amounts of known DDI\ninformation, which is scarce for emerging drugs. In this paper, we propose\nEmerGNN, a graph neural network (GNN) that can effectively predict interactions\nfor emerging drugs by leveraging the rich information in biomedical networks.\nEmerGNN learns pairwise representations of drugs by extracting the paths\nbetween drug pairs, propagating information from one drug to the other, and\nincorporating the relevant biomedical concepts on the paths. The different\nedges on the biomedical network are weighted to indicate the relevance for the\ntarget DDI prediction. Overall, EmerGNN has higher accuracy than existing\napproaches in predicting interactions for emerging drugs and can identify the\nmost relevant information on the biomedical network.",
            "author": [
                "Yongqi Zhang",
                "Quanming Yao",
                "Ling Yue",
                "Xian Wu",
                "Ziheng Zhang",
                "Zhenxi Lin",
                "Yefeng Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09261v1",
                "http://arxiv.org/pdf/2311.09261v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08723v1",
            "title": "Token Prediction as Implicit Classification to Identify LLM-Generated\n  Text",
            "updated": "2023-11-15T06:33:52Z",
            "published": "2023-11-15T06:33:52Z",
            "summary": "This paper introduces a novel approach for identifying the possible large\nlanguage models (LLMs) involved in text generation. Instead of adding an\nadditional classification layer to a base LM, we reframe the classification\ntask as a next-token prediction task and directly fine-tune the base LM to\nperform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the\nbackbone for our experiments. We compared our approach to the more direct\napproach of utilizing hidden states for classification. Evaluation shows the\nexceptional performance of our method in the text classification task,\nhighlighting its simplicity and efficiency. Furthermore, interpretability\nstudies on the features extracted by our model reveal its ability to\ndifferentiate distinctive writing styles among various LLMs even in the absence\nof an explicit classifier. We also collected a dataset named OpenLLMText,\ncontaining approximately 340k text samples from human and LLMs, including\nGPT3.5, PaLM, LLaMA, and GPT2.",
            "author": [
                "Yutian Chen",
                "Hao Kang",
                "Vivian Zhai",
                "Liangze Li",
                "Rita Singh",
                "Bhiksha Raj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08723v1",
                "http://arxiv.org/pdf/2311.08723v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08719v1",
            "title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term\n  Memory",
            "updated": "2023-11-15T06:08:35Z",
            "published": "2023-11-15T06:08:35Z",
            "summary": "Memory-augmented Large Language Models (LLMs) have demonstrated remarkable\nperformance in long-term human-machine interactions, which basically relies on\niterative recalling and reasoning of history to generate high-quality\nresponses. However, such repeated recall-reason steps easily produce biased\nthoughts, \\textit{i.e.}, inconsistent reasoning results when recalling the same\nhistory for different questions. On the contrary, humans can keep thoughts in\nthe memory and recall them without repeated reasoning. Motivated by this human\ncapability, we propose a novel memory mechanism called TiM (Think-in-Memory)\nthat enables LLMs to maintain an evolved memory for storing historical thoughts\nalong the conversation stream. The TiM framework consists of two crucial\nstages: (1) before generating a response, a LLM agent recalls relevant thoughts\nfrom memory, and (2) after generating a response, the LLM agent post-thinks and\nincorporates both historical and new thoughts to update the memory. Thus, TiM\ncan eliminate the issue of repeated reasoning by saving the post-thinking\nthoughts as the history. Besides, we formulate the basic principles to organize\nthe thoughts in memory based on the well-established operations,\n(\\textit{i.e.}, insert, forget, and merge operations), allowing for dynamic\nupdates and evolution of the thoughts. Furthermore, we introduce\nLocality-Sensitive Hashing into TiM to achieve efficient retrieval for the\nlong-term conversations. We conduct qualitative and quantitative experiments on\nreal-world and simulated dialogues covering a wide range of topics,\ndemonstrating that equipping existing LLMs with TiM significantly enhances\ntheir performance in generating responses for long-term interactions.",
            "author": [
                "Lei Liu",
                "Xiaoyan Yang",
                "Yue Shen",
                "Binbin Hu",
                "Zhiqiang Zhang",
                "Jinjie Gu",
                "Guannan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08719v1",
                "http://arxiv.org/pdf/2311.08719v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08718v1",
            "title": "Decomposing Uncertainty for Large Language Models through Input\n  Clarification Ensembling",
            "updated": "2023-11-15T05:58:35Z",
            "published": "2023-11-15T05:58:35Z",
            "summary": "Uncertainty decomposition refers to the task of decomposing the total\nuncertainty of a model into data (aleatoric) uncertainty, resulting from the\ninherent complexity or ambiguity of the data, and model (epistemic)\nuncertainty, resulting from the lack of knowledge in the model. Performing\nuncertainty decomposition for large language models (LLMs) is an important step\ntoward improving the reliability, trustworthiness, and interpretability of\nLLMs, but this research task is very challenging and remains unresolved. The\nexisting canonical method, Bayesian Neural Network (BNN), cannot be applied to\nLLMs, because BNN requires training and ensembling multiple variants of models,\nwhich is infeasible or prohibitively expensive for LLMs. In this paper, we\nintroduce an uncertainty decomposition framework for LLMs, called input\nclarifications ensemble, which bypasses the need to train new models. Rather\nthan ensembling models with different parameters, our approach generates a set\nof clarifications for the input, feeds them into the fixed LLMs, and ensembles\nthe corresponding predictions. We show that our framework shares a symmetric\ndecomposition structure with BNN. Empirical evaluations demonstrate that the\nproposed framework provides accurate and reliable uncertainty quantification on\nvarious tasks. Code will be made publicly available at\nhttps://github.com/UCSB-NLP-Chang/llm_uncertainty .",
            "author": [
                "Bairu Hou",
                "Yujian Liu",
                "Kaizhi Qian",
                "Jacob Andreas",
                "Shiyu Chang",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08718v1",
                "http://arxiv.org/pdf/2311.08718v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08716v1",
            "title": "Scalable Federated Learning for Clients with Different Input Image Sizes\n  and Numbers of Output Categories",
            "updated": "2023-11-15T05:43:14Z",
            "published": "2023-11-15T05:43:14Z",
            "summary": "Federated learning is a privacy-preserving training method which consists of\ntraining from a plurality of clients but without sharing their confidential\ndata. However, previous work on federated learning do not explore suitable\nneural network architectures for clients with different input images sizes and\ndifferent numbers of output categories. In this paper, we propose an effective\nfederated learning method named ScalableFL, where the depths and widths of the\nlocal models for each client are adjusted according to the clients' input image\nsize and the numbers of output categories. In addition, we provide a new bound\nfor the generalization gap of federated learning. In particular, this bound\nhelps to explain the effectiveness of our scalable neural network approach. We\ndemonstrate the effectiveness of ScalableFL in several heterogeneous client\nsettings for both image classification and object detection tasks.",
            "author": [
                "Shuhei Nitta",
                "Taiji Suzuki",
                "Albert Rodr\u00edguez Mulet",
                "Atsushi Yaguchi",
                "Ryusuke Hirai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08716v1",
                "http://arxiv.org/pdf/2311.08716v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08714v1",
            "title": "Schur indices for $\\mathcal{N}=4$ super-Yang-Mills with more general\n  gauge groups",
            "updated": "2023-11-15T05:42:17Z",
            "published": "2023-11-15T05:42:17Z",
            "summary": "We study the unflavored Schur indices in the $\\mathcal{N}=4$ super-Yang-Mills\ntheory for the $B_n,C_n,D_n, G_2$ gauge groups. We explore two methods, namely\nthe character expansion method and the Fermi gas method, to efficiently compute\nthe $q$-series expansion of the Schur indices to some high orders. Using the\navailable data and the modular properties, we are able to fix the exact\nformulas for the general gauge groups up to some high ranks and discover some\ninteresting new features. We also identify some empirical modular anomaly\nequations, but unlike the case of $A_n$ groups, they are quite complicated and\nnot sufficiently useful to fix exact formulas for gauge groups of arbitrary\nrank.",
            "author": [
                "Bao-ning Du",
                "Min-xin Huang",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08714v1",
                "http://arxiv.org/pdf/2311.08714v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08713v1",
            "title": "Four-body bound states in momentum space: the Yakubovsky approach\n  without two-body $t-$matrices",
            "updated": "2023-11-15T05:41:32Z",
            "published": "2023-11-15T05:41:32Z",
            "summary": "This study presents a solution to the Yakubovsky equations for four-body\nbound states in momentum space, bypassing the common use of two-body\n$t-$matrices. Typically, such solutions are dependent on the fully-off-shell\ntwo-body $t-$matrices, which are obtained from the Lippmann-Schwinger integral\nequation for two-body subsystem energies controlled by the second and third\nJacobi momenta. Instead, we use a version of the Yakubovsky equations that\ndoesn't require $t-$matrices, facilitating the direct use of two-body\ninteractions. This approach streamlines the programming and reduces\ncomputational time. Numerically, we found that this direct approach to the\nYakubovsky equations, using 2B interactions, produces four-body binding energy\nresults consistent with those obtained from the conventional $t-$matrix\ndependent Yakubovsky equations, for both separable (Yamaguchi and Gaussian) and\nnon-separable (Malfliet-Tjon) interactions.",
            "author": [
                "M. Mohammadzadeh",
                "M. Radin",
                "K. Mohseni",
                "M. R. Hadizadeh"
            ],
            "link": [
                "http://dx.doi.org/10.3389/fphy.2023.1232691",
                "http://arxiv.org/abs/2311.08713v1",
                "http://arxiv.org/pdf/2311.08713v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08711v1",
            "title": "PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning",
            "updated": "2023-11-15T05:28:07Z",
            "published": "2023-11-15T05:28:07Z",
            "summary": "Instruction tuning has remarkably advanced large language models (LLMs) in\nunderstanding and responding to diverse human instructions. Despite the success\nin high-resource languages, its application in lower-resource ones faces\nchallenges due to the imbalanced foundational abilities of LLMs across\ndifferent languages, stemming from the uneven language distribution in their\npre-training data. To tackle this issue, we propose pivot language guided\ngeneration (PLUG), an approach that utilizes a high-resource language,\nprimarily English, as the pivot to enhance instruction tuning in lower-resource\nlanguages. It trains the model to first process instructions in the pivot\nlanguage, and then produce responses in the target language. To evaluate our\napproach, we introduce a benchmark, X-AlpacaEval, of instructions in 4\nlanguages (Chinese, Korean, Italian, and Spanish), each annotated by\nprofessional translators. Our approach demonstrates a significant improvement\nin the instruction-following abilities of LLMs by 29% on average, compared to\ndirectly responding in the target language alone. Further experiments validate\nthe versatility of our approach by employing alternative pivot languages beyond\nEnglish to assist languages where LLMs exhibit lower proficiency.",
            "author": [
                "Zhihan Zhang",
                "Dong-Ho Lee",
                "Yuwei Fang",
                "Wenhao Yu",
                "Mengzhao Jia",
                "Meng Jiang",
                "Francesco Barbieri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08711v1",
                "http://arxiv.org/pdf/2311.08711v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08707v1",
            "title": "K-BMPC: Derivative-based Koopman Bilinear Model Predictive Control For\n  Tractor-trailer Trajectory Tracking With Unknown Parameters",
            "updated": "2023-11-15T05:13:02Z",
            "published": "2023-11-15T05:13:02Z",
            "summary": "Nonlinear dynamics bring difficulties to controller design for control-affine\nsystems such as tractor-trailer vehicles, especially when the parameters in\ndynamics are unknown. To address this constraint, we propose a derivative-based\nlifting function construction method, show that the corresponding infinite\ndimensional Koopman bilinear model over the lifting function is equivalent to\nthe original control-affine system. Further, we analyze the propagation and\nbounds of state prediction errors caused by the the truncation in derivative\norder. The identified finite dimensional Koopman bilinear model would serve as\npredictive model in next step. Koopman Bilinear Model Predictive control\n(K-BMPC) is proposed to solve the trajectory tracking problem. We linearize the\nbilinear model around the estimation of the lifted state and control input.\nThen the bilinear Model Predictive Control problem is approximated by a\nquadratic programming problem. Further, the estimation is updated at each\niteration until the convergence is reached. Moreover, we implement our\nalgorithm on a tractor-trailer dynamic system, taking into account the\nlongitudinal and side slip effects. The open-loop simulation shows the proposed\nKoopman bilinear model captures the dynamics with unknown parameters and has\ngood prediction performance. Closed loop tracking results show the proposed\nK-BMPC exhibits elevated tracking precision along with commendable\ncomputational efficiency. The experimental results demonstrate the feasibility\nof the proposed method.",
            "author": [
                "Zehao Wang",
                "Han Zhang",
                "Jingchuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08707v1",
                "http://arxiv.org/pdf/2311.08707v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08706v1",
            "title": "Aligned: A Platform-based Process for Alignment",
            "updated": "2023-11-15T05:12:37Z",
            "published": "2023-11-15T05:12:37Z",
            "summary": "We are introducing Aligned, a platform for global governance and alignment of\nfrontier models, and eventually superintelligence. While previous efforts at\nthe major AI labs have attempted to gather inputs for alignment, these are\noften conducted behind closed doors. We aim to set the foundation for a more\ntrustworthy, public-facing approach to safety: a constitutional committee\nframework. Initial tests with 680 participants result in a 30-guideline\nconstitution with 93% overall support. We show the platform naturally scales,\ninstilling confidence and enjoyment from the community. We invite other AI labs\nand teams to plug and play into the Aligned ecosystem.",
            "author": [
                "Ethan Shaotran",
                "Ido Pesok",
                "Sam Jones",
                "Emi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08706v1",
                "http://arxiv.org/pdf/2311.08706v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08705v1",
            "title": "Evaluating Robustness of Dialogue Summarization Models in the Presence\n  of Naturally Occurring Variations",
            "updated": "2023-11-15T05:11:43Z",
            "published": "2023-11-15T05:11:43Z",
            "summary": "Dialogue summarization task involves summarizing long conversations while\npreserving the most salient information. Real-life dialogues often involve\nnaturally occurring variations (e.g., repetitions, hesitations) and existing\ndialogue summarization models suffer from performance drop on such\nconversations. In this study, we systematically investigate the impact of such\nvariations on state-of-the-art dialogue summarization models using publicly\navailable datasets. To simulate real-life variations, we introduce two types of\nperturbations: utterance-level perturbations that modify individual utterances\nwith errors and language variations, and dialogue-level perturbations that add\nnon-informative exchanges (e.g., repetitions, greetings). We conduct our\nanalysis along three dimensions of robustness: consistency, saliency, and\nfaithfulness, which capture different aspects of the summarization model's\nperformance. We find that both fine-tuned and instruction-tuned models are\naffected by input variations, with the latter being more susceptible,\nparticularly to dialogue-level perturbations. We also validate our findings via\nhuman evaluation. Finally, we investigate if the robustness of fine-tuned\nmodels can be improved by training them with a fraction of perturbed data and\nobserve that this approach is insufficient to address robustness challenges\nwith current models and thus warrants a more thorough investigation to identify\nbetter solutions. Overall, our work highlights robustness challenges in\ndialogue summarization and provides insights for future research.",
            "author": [
                "Ankita Gupta",
                "Chulaka Gunasekara",
                "Hui Wan",
                "Jatin Ganhotra",
                "Sachindra Joshi",
                "Marina Danilevsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08705v1",
                "http://arxiv.org/pdf/2311.08705v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08704v1",
            "title": "Can Large Language Models Follow Concept Annotation Guidelines? A Case\n  Study on Scientific and Financial Domains",
            "updated": "2023-11-15T05:11:26Z",
            "published": "2023-11-15T05:11:26Z",
            "summary": "Although large language models (LLMs) exhibit remarkable capacity to leverage\nin-context demonstrations, it is still unclear to what extent they can learn\nnew concepts or facts from ground-truth labels. To address this question, we\nexamine the capacity of instruction-tuned LLMs to follow in-context concept\nguidelines for sentence labeling tasks. We design guidelines that present\ndifferent types of factual and counterfactual concept definitions, which are\nused as prompts for zero-shot sentence classification tasks. Our results show\nthat although concept definitions consistently help in task performance, only\nthe larger models (with 70B parameters or more) have limited ability to work\nunder counterfactual contexts. Importantly, only proprietary models such as\nGPT-3.5 and GPT-4 can recognize nonsensical guidelines, which we hypothesize is\ndue to more sophisticated alignment methods. Finally, we find that\nFalcon-180B-chat is outperformed by Llama-2-70B-chat is most cases, which\nindicates that careful fine-tuning is more effective than increasing model\nscale. Altogether, our simple evaluation method reveals significant gaps in\nconcept understanding between the most capable open-source language models and\nthe leading proprietary APIs.",
            "author": [
                "Marcio Fonseca",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08704v1",
                "http://arxiv.org/pdf/2311.08704v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08703v1",
            "title": "Impact of Nap on Performance in Different Working Memory Tasks Using EEG",
            "updated": "2023-11-15T05:09:09Z",
            "published": "2023-11-15T05:09:09Z",
            "summary": "Electroencephalography (EEG) has been widely used to study the relationship\nbetween naps and working memory, yet the effects of naps on distinct working\nmemory tasks remain unclear. Here, participants performed word-pair and\nvisuospatial working memory tasks pre- and post-nap sessions. We found marked\ndifferences in accuracy and reaction time between tasks performed pre- and\npost-nap. In order to identify the impact of naps on performance in each\nworking memory task, we employed clustering to classify participants as high-\nor low-performers. Analysis of sleep architecture revealed significant\nvariations in sleep onset latency and rapid eye movement (REM) proportion. In\naddition, the two groups exhibited prominent differences, especially in the\ndelta power of the Non-REM 3 stage linked to memory. Our results emphasize the\ninterplay between nap-related neural activity and working memory, underlining\nspecific EEG markers associated with cognitive performance.",
            "author": [
                "Gi-Hwan Shin",
                "Young-Seok Kweon",
                "Heon-Gyu Kwak",
                "Ha-Na Jo",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08703v1",
                "http://arxiv.org/pdf/2311.08703v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08702v1",
            "title": "Debate Helps Supervise Unreliable Experts",
            "updated": "2023-11-15T05:05:40Z",
            "published": "2023-11-15T05:05:40Z",
            "summary": "As AI systems are used to answer more difficult questions and potentially\nhelp create new knowledge, judging the truthfulness of their outputs becomes\nmore difficult and more important. How can we supervise unreliable experts,\nwhich have access to the truth but may not accurately report it, to give\nanswers that are systematically true and don't just superficially seem true,\nwhen the supervisor can't tell the difference between the two on their own? In\nthis work, we show that debate between two unreliable experts can help a\nnon-expert judge more reliably identify the truth. We collect a dataset of\nhuman-written debates on hard reading comprehension questions where the judge\nhas not read the source passage, only ever seeing expert arguments and short\nquotes selectively revealed by 'expert' debaters who have access to the\npassage. In our debates, one expert argues for the correct answer, and the\nother for an incorrect answer. Comparing debate to a baseline we call\nconsultancy, where a single expert argues for only one answer which is correct\nhalf of the time, we find that debate performs significantly better, with 84%\njudge accuracy compared to consultancy's 74%. Debates are also more efficient,\nbeing 68% of the length of consultancies. By comparing human to AI debaters, we\nfind evidence that with more skilled (in this case, human) debaters, the\nperformance of debate goes up but the performance of consultancy goes down. Our\nerror analysis also supports this trend, with 46% of errors in human debate\nattributable to mistakes by the honest debater (which should go away with\nincreased skill); whereas 52% of errors in human consultancy are due to\ndebaters obfuscating the relevant evidence from the judge (which should become\nworse with increased skill). Overall, these results show that debate is a\npromising approach for supervising increasingly capable but potentially\nunreliable AI systems.",
            "author": [
                "Julian Michael",
                "Salsabila Mahdi",
                "David Rein",
                "Jackson Petty",
                "Julien Dirani",
                "Vishakh Padmakumar",
                "Samuel R. Bowman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08702v1",
                "http://arxiv.org/pdf/2311.08702v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08698v1",
            "title": "Artificial General Intelligence, Existential Risk, and Human Risk\n  Perception",
            "updated": "2023-11-15T04:57:16Z",
            "published": "2023-11-15T04:57:16Z",
            "summary": "Artificial general intelligence (AGI) does not yet exist, but given the pace\nof technological development in artificial intelligence, it is projected to\nreach human-level intelligence within roughly the next two decades. After that,\nmany experts expect it to far surpass human intelligence and to do so rapidly.\nThe prospect of superintelligent AGI poses an existential risk to humans\nbecause there is no reliable method for ensuring that AGI goals stay aligned\nwith human goals. Drawing on publicly available forecaster and opinion data,\nthe author examines how experts and non-experts perceive risk from AGI. The\nfindings indicate that the perceived risk of a world catastrophe or extinction\nfrom AGI is greater than for other existential risks. The increase in perceived\nrisk over the last year is also steeper for AGI than for other existential\nthreats (e.g., nuclear war or human-caused climate change). That AGI is a\npressing existential risk is something on which experts and non-experts agree,\nbut the basis for such agreement currently remains obscure.",
            "author": [
                "David R. Mandel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08698v1",
                "http://arxiv.org/pdf/2311.08698v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08695v1",
            "title": "Attribute Diversity Determines the Systematicity Gap in VQA",
            "updated": "2023-11-15T04:50:30Z",
            "published": "2023-11-15T04:50:30Z",
            "summary": "The degree to which neural networks can generalize to new combinations of\nfamiliar concepts, and the conditions under which they are able to do so, has\nlong been an open question. In this work, we study the systematicity gap in\nvisual question answering: the performance difference between reasoning on\npreviously seen and unseen combinations of object attributes. To test, we\nintroduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased\nquantity of training data does not reduce the systematicity gap, increased\ntraining data diversity of the attributes in the unseen combination does. In\nall, our experiments suggest that the more distinct attribute type combinations\nare seen during training, the more systematic we can expect the resulting model\nto be.",
            "author": [
                "Ian Berlot-Attwell",
                "A. Michael Carrell",
                "Kumar Krishna Agrawal",
                "Yash Sharma",
                "Naomi Saphra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08695v1",
                "http://arxiv.org/pdf/2311.08695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08692v1",
            "title": "Routing to the Expert: Efficient Reward-guided Ensemble of Large\n  Language Models",
            "updated": "2023-11-15T04:40:43Z",
            "published": "2023-11-15T04:40:43Z",
            "summary": "The complementary potential of Large Language Models (LLM) assumes\noff-the-shelf LLMs have heterogeneous expertise in a wide range of domains and\ntasks so that an ensemble of LLMs can achieve consistently better performance.\nExisting ensemble methods for LLMs mainly focus on reward model ranking of\noutputs, leading to significant computation overhead. To combat this issue, we\nrevisit the complementary potential of LLMs and further elaborate it by mining\nlatent expertise with off-the-shelf reward models. We propose Zooter, a\nreward-guided routing method distilling rewards on training queries to train a\nrouting function, which can precisely distribute each query to the LLM with\nexpertise about it. We also integrate a tag-based label enhancement to mitigate\nnoise from uncertainty when using rewards as silver supervision. Zooter shows\ncomputation efficiency in inference as it introduces only a minor computation\noverhead of a routing function compared with reward model ranking methods. We\nevaluate Zooter on a comprehensive benchmark collection with 26 subsets on\ndifferent domains and tasks. Zooter outperforms the best single model on\naverage and ranks first on 44% of tasks, even surpassing multiple reward model\nranking methods.",
            "author": [
                "Keming Lu",
                "Hongyi Yuan",
                "Runji Lin",
                "Junyang Lin",
                "Zheng Yuan",
                "Chang Zhou",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08692v1",
                "http://arxiv.org/pdf/2311.08692v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08690v1",
            "title": "Enabling CMF Estimation in Data-Constrained Scenarios: A\n  Semantic-Encoding Knowledge Mining Model",
            "updated": "2023-11-15T04:37:27Z",
            "published": "2023-11-15T04:37:27Z",
            "summary": "Precise estimation of Crash Modification Factors (CMFs) is central to\nevaluating the effectiveness of various road safety treatments and prioritizing\ninfrastructure investment accordingly. While customized study for each\ncountermeasure scenario is desired, the conventional CMF estimation approaches\nrely heavily on the availability of crash data at given sites. This not only\nmakes the estimation costly, but the results are also less transferable, since\nthe intrinsic similarities between different safety countermeasure scenarios\nare not fully explored. Aiming to fill this gap, this study introduces a novel\nknowledge-mining framework for CMF prediction. This framework delves into the\nconnections of existing countermeasures and reduces the reliance of CMF\nestimation on crash data availability and manual data collection. Specifically,\nit draws inspiration from human comprehension processes and introduces advanced\nNatural Language Processing (NLP) techniques to extract intricate variations\nand patterns from existing CMF knowledge. It effectively encodes unstructured\ncountermeasure scenarios into machine-readable representations and models the\ncomplex relationships between scenarios and CMF values. This new data-driven\nframework provides a cost-effective and adaptable solution that complements the\ncase-specific approaches for CMF estimation, which is particularly beneficial\nwhen availability of crash data or time imposes constraints. Experimental\nvalidation using real-world CMF Clearinghouse data demonstrates the\neffectiveness of this new approach, which shows significant accuracy\nimprovements compared to baseline methods. This approach provides insights into\nnew possibilities of harnessing accumulated transportation knowledge in various\napplications.",
            "author": [
                "Yanlin Qi",
                "Jia Li",
                "Michael Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08690v1",
                "http://arxiv.org/pdf/2311.08690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08687v1",
            "title": "An Eye on Clinical BERT: Investigating Language Model Generalization for\n  Diabetic Eye Disease Phenotyping",
            "updated": "2023-11-15T04:30:20Z",
            "published": "2023-11-15T04:30:20Z",
            "summary": "Diabetic eye disease is a major cause of blindness worldwide. The ability to\nmonitor relevant clinical trajectories and detect lapses in care is critical to\nmanaging the disease and preventing blindness. Alas, much of the information\nnecessary to support these goals is found only in the free text of the\nelectronic medical record. To fill this information gap, we introduce a system\nfor extracting evidence from clinical text of 19 clinical concepts related to\ndiabetic eye disease and inferring relevant attributes for each. In developing\nthis ophthalmology phenotyping system, we are also afforded a unique\nopportunity to evaluate the effectiveness of clinical language models at\nadapting to new clinical domains. Across multiple training paradigms, we find\nthat BERT language models pretrained on out-of-distribution clinical data offer\nno significant improvement over BERT language models pretrained on non-clinical\ndata for our domain. Our study tempers recent claims that language models\npretrained on clinical data are necessary for clinical NLP tasks and highlights\nthe importance of not treating clinical language data as a single homogeneous\ndomain.",
            "author": [
                "Keith Harrigian",
                "Tina Tang",
                "Anthony Gonzales",
                "Cindy X. Cai",
                "Mark Dredze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08687v1",
                "http://arxiv.org/pdf/2311.08687v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09260v1",
            "title": "A Proposed Artificial Neural Network based Approach for Molecules Bitter\n  Prediction",
            "updated": "2023-11-15T04:22:29Z",
            "published": "2023-11-15T04:22:29Z",
            "summary": "In recent years, the development of Artificial Intelligence (AI) has offered\nthe possibility to tackle many interdisciplinary problems, and the field of\nchemistry is not an exception. Drug analysis is crucial in drug discovery,\nplaying an important role in human life. However, this task encounters many\ndifficulties due to the wide range of computational chemistry methods. Drug\nanalysis also involves a massive amount of work, including determining taste.\nThus, applying deep learning to predict a molecule's bitterness is inevitable\nto accelerate innovation in drug analysis by reducing the time spent. This\npaper proposes an artificial neural network (ANN) based approach (EC-ANN) for\nthe molecule's bitter prediction. Our approach took the SMILE (Simplified\nmolecular-input line-entry system) string of a molecule as the input data for\nthe prediction, and the 256-bit ECFP descriptor is the input vector for our\nnetwork. It showed impressive results compared to state-of-the-art, with a\nhigher performance on two out of three test sets according to the experiences\non three popular test sets: Phyto-Dictionary, Unimi, and Bitter-new set [1].\nFor the Phyto-Dictionary test set, our model recorded 0.95 and 0.983 in\nF1-score and AUPR, respectively, depicted as the highest score in F1-score. For\nthe Unimi test set, our model achieved 0.88 in F1-score and 0.88 in AUPR, which\nis roughly 12.3% higher than the peak of previous models [1, 2, 3, 4, 5].",
            "author": [
                "Huynh Quoc Anh Bui",
                "Trong Hop Do",
                "Thanh Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09260v1",
                "http://arxiv.org/pdf/2311.09260v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08685v1",
            "title": "Safer-Instruct: Aligning Language Models with Automated Preference Data",
            "updated": "2023-11-15T04:22:22Z",
            "published": "2023-11-15T04:22:22Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) is a vital strategy for\nenhancing model safety in language models. However, annotating preference data\nfor RLHF is a resource-intensive and creativity-demanding process, while\nautomatic generation methods face limitations in data diversity and quality. In\nresponse, we present Safer-Instruct, a novel pipeline for semi-automatically\nconstructing large-scale preference datasets. Our approach leverages reversed\ninstruction tuning, instruction induction, and expert model evaluation to\nefficiently generate high-quality preference data without human annotators. We\nevaluate Safer-Instruct using LLaMA for instruction induction and GPT-4 as an\nexpert model, generating approximately 10K preference samples. Finetuning an\nAlpaca model on this dataset demonstrates improved harmlessness while\nmaintaining competitive performance on conversation and downstream tasks.\nSafer-Instruct addresses the challenges in preference data acquisition,\nadvancing the development of safer and more responsible AI systems. Our code\nand data are available at https://github.com/uscnlp-lime/safer-instruct",
            "author": [
                "Taiwei Shi",
                "Kai Chen",
                "Jieyu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08685v1",
                "http://arxiv.org/pdf/2311.08685v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08683v1",
            "title": "Hadamard products and BPS networks",
            "updated": "2023-11-15T04:20:38Z",
            "published": "2023-11-15T04:20:38Z",
            "summary": "We study examples of fourth-order Picard-Fuchs operators that are Hadamard\nproducts of two second order Picard-Fuchs operators. Each second order\nPicard-Fuchs operator is associated with a family of elliptic curves, and the\nHadamard product computes period integrals on the fibred product of the two\nelliptic surfaces. We construct 3-cycles on this geometry as the union of\n2-cycles in the fibre over contours on the base. We then use the special\nLagrangian condition to constrain the contours on the base. This leads to a\nconstruction reminiscent of spectral networks and exponential networks that\nhave previously appeared in string theory literature.",
            "author": [
                "Mohamed Elmi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08683v1",
                "http://arxiv.org/pdf/2311.08683v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math.AG",
                "math.SG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08677v1",
            "title": "Federated Learning for Sparse Principal Component Analysis",
            "updated": "2023-11-15T03:55:28Z",
            "published": "2023-11-15T03:55:28Z",
            "summary": "In the rapidly evolving realm of machine learning, algorithm effectiveness\noften faces limitations due to data quality and availability. Traditional\napproaches grapple with data sharing due to legal and privacy concerns. The\nfederated learning framework addresses this challenge. Federated learning is a\ndecentralized approach where model training occurs on client sides, preserving\nprivacy by keeping data localized. Instead of sending raw data to a central\nserver, only model updates are exchanged, enhancing data security. We apply\nthis framework to Sparse Principal Component Analysis (SPCA) in this work. SPCA\naims to attain sparse component loadings while maximizing data variance for\nimproved interpretability. Beside the L1 norm regularization term in\nconventional SPCA, we add a smoothing function to facilitate gradient-based\noptimization methods. Moreover, in order to improve computational efficiency,\nwe introduce a least squares approximation to original SPCA. This enables\nanalytic solutions on the optimization processes, leading to substantial\ncomputational improvements. Within the federated framework, we formulate SPCA\nas a consensus optimization problem, which can be solved using the Alternating\nDirection Method of Multipliers (ADMM). Our extensive experiments involve both\nIID and non-IID random features across various data owners. Results on\nsynthetic and public datasets affirm the efficacy of our federated SPCA\napproach.",
            "author": [
                "Sin Cheng Ciou",
                "Pin Jui Chen",
                "Elvin Y. Tseng",
                "Yuh-Jye Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08677v1",
                "http://arxiv.org/pdf/2311.08677v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08675v1",
            "title": "Coreset Selection with Prioritized Multiple Objectives",
            "updated": "2023-11-15T03:43:04Z",
            "published": "2023-11-15T03:43:04Z",
            "summary": "Coreset selection is powerful in reducing computational costs and\naccelerating data processing for deep learning algorithms. It strives to\nidentify a small subset from large-scale data, so that training only on the\nsubset practically performs on par with full data. When coreset selection is\napplied in realistic scenes, under the premise that the identified coreset has\nachieved comparable model performance, practitioners regularly desire the\nidentified coreset can have a size as small as possible for lower costs and\ngreater acceleration. Motivated by this desideratum, for the first time, we\npose the problem of \"coreset selection with prioritized multiple objectives\",\nin which the smallest coreset size under model performance constraints is\nexplored. Moreover, to address this problem, an innovative method is proposed,\nwhich maintains optimization priority order over the model performance and\ncoreset size, and efficiently optimizes them in the coreset selection\nprocedure. Theoretically, we provide the convergence guarantee of the proposed\nmethod. Empirically, extensive experiments confirm its superiority compared\nwith previous strategies, often yielding better model performance with smaller\ncoreset sizes.",
            "author": [
                "Xiaobo Xia",
                "Jiale Liu",
                "Shaokun Zhang",
                "Qingyun Wu",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08675v1",
                "http://arxiv.org/pdf/2311.08675v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08673v1",
            "title": "CP-EB: Talking Face Generation with Controllable Pose and Eye Blinking\n  Embedding",
            "updated": "2023-11-15T03:37:41Z",
            "published": "2023-11-15T03:37:41Z",
            "summary": "This paper proposes a talking face generation method named \"CP-EB\" that takes\nan audio signal as input and a person image as reference, to synthesize a\nphoto-realistic people talking video with head poses controlled by a short\nvideo clip and proper eye blinking embedding. It's noted that not only the head\npose but also eye blinking are both important aspects for deep fake detection.\nThe implicit control of poses by video has already achieved by the state-of-art\nwork. According to recent research, eye blinking has weak correlation with\ninput audio which means eye blinks extraction from audio and generation are\npossible. Hence, we propose a GAN-based architecture to extract eye blink\nfeature from input audio and reference video respectively and employ\ncontrastive training between them, then embed it into the concatenated features\nof identity and poses to generate talking face images. Experimental results\nshow that the proposed method can generate photo-realistic talking face with\nsynchronous lips motions, natural head poses and blinking eyes.",
            "author": [
                "Jianzong Wang",
                "Yimin Deng",
                "Ziqi Liang",
                "Xulong Zhang",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08673v1",
                "http://arxiv.org/pdf/2311.08673v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08672v1",
            "title": "GUGA-based MRCI approach with Core-Valence Separation Approximation\n  (CVS) for the calculation of the Core-Excited States of molecules",
            "updated": "2023-11-15T03:37:34Z",
            "published": "2023-11-15T03:37:34Z",
            "summary": "We develop and demonstrate how to use the GUGA-based MRCISD with Core-Valence\nSeparation approximation (CVS) to compute the core-excited states. Firstly,\nperform a normal SCF or valence MCSCF calculation to optimize the molecular\norbitals. Secondly, rotate the optimized target core orbitals and append to the\nactive space, form an extended CVS active space, and perform a CVS-MCSCF\ncalculation for core-excited states. Finally, construct the CVS-MRCI expansion\nspace, and perform a CVS-MRCI calculation to optimize the CI coefficients based\non the variational method. The CVS approximation with GUGA-based methods can be\nimplemented by flexible truncation of the Distinct Row Table (DRT). Eliminating\nthe valence-excited configurations from the CVS-MRCI expansion space can\nprevent variational collapse in the Davidson iteration diagonalization. The\naccuracy of the CVS-MRCI scheme was investigated for excitation energies and\ncompared with that of the CVS-MCSCF method. The results show that CVS-MRCI is\ncapable of reproducing well-matched vertical core excitation energies that are\nconsistent with experiments, by combining large basis sets and a rational\nreference space. The calculation results also highlight the fact that the\ndynamic correlation between electrons makes an undeniable contribution in\ncore-excited states.",
            "author": [
                "Qi Song",
                "Baoyuan Liu",
                "Junfeng Wu",
                "Wenli Zou",
                "Yubin Wang",
                "Bingbing Suo",
                "Yibo Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08672v1",
                "http://arxiv.org/pdf/2311.08672v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08669v1",
            "title": "Understanding Calibration for Multilingual Question Answering Models",
            "updated": "2023-11-15T03:29:02Z",
            "published": "2023-11-15T03:29:02Z",
            "summary": "Multilingual pre-trained language models are incredibly effective at Question\nAnswering (QA), a core task in Natural Language Understanding, achieving high\naccuracies on several multilingual benchmarks. However, little is known about\nhow well they are calibrated. In this paper, we study the calibration\nproperties of several pre-trained multilingual large language models (LLMs) on\na variety of question-answering tasks. We perform extensive experiments,\nspanning both extractive and generative QA model designs and diverse languages,\nspanning both high-resource and low-resource ones. We study different\ndimensions of calibration in in-distribution, out-of-distribution, and\ncross-lingual transfer settings, and investigate strategies to improve it,\nincluding post-hoc methods and regularized fine-tuning. We demonstrate\nautomatically translated data augmentation as a highly effective technique to\nimprove model calibration. We also conduct a number of ablation experiments to\nstudy the effect of model size on calibration and how multilingual models\ncompare with their monolingual counterparts for diverse tasks and languages.",
            "author": [
                "Yahan Yang",
                "Soham Dan",
                "Dan Roth",
                "Insup Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08669v1",
                "http://arxiv.org/pdf/2311.08669v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08668v1",
            "title": "Mesonic decay constant and mass ratios and the conformal window",
            "updated": "2023-11-15T03:28:47Z",
            "published": "2023-11-15T03:28:47Z",
            "summary": "Two particular ratios related to mesons are proposed for the study of the\nconformal window in $SU(3)$ gauge theory and fundamental fermions. Lattice and\nother studies indicate that the lower end, $N_f^*$, is at around 7 - 13 flavors\nwhich is a wide range without a clear consensus. Here we propose the decay\nconstant to mass ratios of mesons, $f_{PS,V} / m_V$, as a proxy since below the\nconformal window lattice studies have shown that they are largely\n$N_f$-independent while at the upper end of the conformal window they are\nvanishing. The drop from the non-zero constant value to zero at $N_f = 16.5$\nmight be indicative of $N_f^*$. We compute $f_V / m_V$ to N$^3$LO and $f_{PS} /\nm_V$ to NNLO order in (p)NRQCD. The results are unambiguously reliable just\nbelow $N_f = 16.5$, hence the results are expanded \\'a la Banks-Zaks in\n$\\varepsilon = 16.5 - N_f$. The convergence properties of the series and\nmatching with the non-perturbative infinite volume, continuum and chiral\nextrapolated lattice results at $N_f = 10$ suggest that the perturbative\nresults might be reliable down to $N_f = 12$. A sudden drop is observed at $N_f\n= 12$ and $N_f = 13$ in $f_V / m_V$ and $f_{PS} / m_V$, respectively.",
            "author": [
                "Hee Sok Chung",
                "Daniel Nogradi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08668v1",
                "http://arxiv.org/pdf/2311.08668v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08666v1",
            "title": "It Takes Two to Negotiate: Modeling Social Exchange in Online\n  Multiplayer Games",
            "updated": "2023-11-15T03:21:04Z",
            "published": "2023-11-15T03:21:04Z",
            "summary": "Online games are dynamic environments where players interact with each other,\nwhich offers a rich setting for understanding how players negotiate their way\nthrough the game to an ultimate victory. This work studies online player\ninteractions during the turn-based strategy game, Diplomacy. We annotated a\ndataset of over 10,000 chat messages for different negotiation strategies and\nempirically examined their importance in predicting long- and short-term game\noutcomes. Although negotiation strategies can be predicted reasonably\naccurately through the linguistic modeling of the chat messages, more is needed\nfor predicting short-term outcomes such as trustworthiness. On the other hand,\nthey are essential in graph-aware reinforcement learning approaches to predict\nlong-term outcomes, such as a player's success, based on their prior\nnegotiation history. We close with a discussion of the implications and impact\nof our work. The dataset is available at\nhttps://github.com/kj2013/claff-diplomacy.",
            "author": [
                "Kokil Jaidka",
                "Hansin Ahuja",
                "Lynnette Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08666v1",
                "http://arxiv.org/pdf/2311.08666v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08662v1",
            "title": "Multi-Set Inoculation: Assessing Model Robustness Across Multiple\n  Challenge Sets",
            "updated": "2023-11-15T02:59:10Z",
            "published": "2023-11-15T02:59:10Z",
            "summary": "Language models, given their black-box nature, often exhibit sensitivity to\ninput perturbations, leading to trust issues due to hallucinations. To bolster\ntrust, it's essential to understand these models' failure modes and devise\nstrategies to enhance their performance. In this study, we propose a framework\nto study the effect of input perturbations on language models of different\nscales, from pre-trained models to large language models (LLMs). We use\nfine-tuning to train a robust model to perturbations, and we investigate\nwhether exposure to one perturbation improves or degrades the model's\nperformance on other perturbations. To address multi-perturbation robustness,\nwe suggest three distinct training strategies. We also extend the framework to\nLLMs via a chain of thought(COT) prompting with exemplars. We instantiate our\nframework for the Tabular-NLI task and show that the proposed strategies train\nthe model robust to different perturbations without losing accuracy on a given\ndataset.",
            "author": [
                "Vatsal Gupta",
                "Pranshu Pandya",
                "Tushar Kataria",
                "Vivek Gupta",
                "Dan Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08662v1",
                "http://arxiv.org/pdf/2311.08662v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08661v1",
            "title": "Deep Neural Network Identification of Limnonectes Species and New Class\n  Detection Using Image Data",
            "updated": "2023-11-15T02:57:59Z",
            "published": "2023-11-15T02:57:59Z",
            "summary": "As is true of many complex tasks, the work of discovering, describing, and\nunderstanding the diversity of life on Earth (viz., biological systematics and\ntaxonomy) requires many tools. Some of this work can be accomplished as it has\nbeen done in the past, but some aspects present us with challenges which\ntraditional knowledge and tools cannot adequately resolve. One such challenge\nis presented by species complexes in which the morphological similarities among\nthe group members make it difficult to reliably identify known species and\ndetect new ones. We address this challenge by developing new tools using the\nprinciples of machine learning to resolve two specific questions related to\nspecies complexes. The first question is formulated as a classification problem\nin statistics and machine learning and the second question is an\nout-of-distribution (OOD) detection problem. We apply these tools to a species\ncomplex comprising Southeast Asian stream frogs (Limnonectes kuhlii complex)\nand employ a morphological character (hind limb skin texture) traditionally\ntreated qualitatively in a quantitative and objective manner. We demonstrate\nthat deep neural networks can successfully automate the classification of an\nimage into a known species group for which it has been trained. We further\ndemonstrate that the algorithm can successfully classify an image into a new\nclass if the image does not belong to the existing classes. Additionally, we\nuse the larger MNIST dataset to test the performance of our OOD detection\nalgorithm. We finish our paper with some concluding remarks regarding the\napplication of these methods to species complexes and our efforts to document\ntrue biodiversity. This paper has online supplementary materials.",
            "author": [
                "Li Xu",
                "Yili Hong",
                "Eric P. Smith",
                "David S. McLeod",
                "Xinwei Deng",
                "Laura J. Freeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08661v1",
                "http://arxiv.org/pdf/2311.08661v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08659v1",
            "title": "Regularizing Parameterized Black Hole Spacetimes with Kerr Symmetries",
            "updated": "2023-11-15T02:46:48Z",
            "published": "2023-11-15T02:46:48Z",
            "summary": "Parameterized Kerr spacetimes allow us to test the nature of black holes in\nmodel-independent ways. Such spacetimes contain several arbitrary functions\nand, as a matter of practicality, one Taylor expands them about infinity and\nkeeps only to finite orders in the expansion. In this paper, we focus on the\nparameterized spacetime preserving Killing symmetries of a Kerr spacetime and\nshow that an unphysical divergence may appear in the metric if such a\ntruncation is performed in the series expansion. To remedy this, we redefine\nthe arbitrary functions so that the divergence disappears, at least for several\nknown black hole solutions that can be mapped to the parameterized Kerr\nspacetime. We propose two restricted classes of the refined parameterized Kerr\nspacetime that only contain one or two arbitrary functions and yet can\nreproduce exactly all the example black hole spacetimes considered in this\npaper. The Petrov class of the parameterized Kerr spacetime is of type I while\nthat for the restricted class with one arbitrary function remains type D. We\nalso compute the ringdown frequencies and the shapes of black hole shadows for\nthe parameterized spacetime and show how they deviate from Kerr. The refined\nblack hole metrics with Kerr symmetries presented here are practically more\nuseful than those proposed in previous literature.",
            "author": [
                "Kent Yagi",
                "Samantha Lomuscio",
                "Tristen Lowrey",
                "Zack Carson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08659v1",
                "http://arxiv.org/pdf/2311.08659v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08657v1",
            "title": "ConeQuest: A Benchmark for Cone Segmentation on Mars",
            "updated": "2023-11-15T02:33:08Z",
            "published": "2023-11-15T02:33:08Z",
            "summary": "Over the years, space scientists have collected terabytes of Mars data from\nsatellites and rovers. One important set of features identified in Mars orbital\nimages is pitted cones, which are interpreted to be mud volcanoes believed to\nform in regions that were once saturated in water (i.e., a lake or ocean).\nIdentifying pitted cones globally on Mars would be of great importance, but\nexpert geologists are unable to sort through the massive orbital image archives\nto identify all examples. However, this task is well suited for computer\nvision. Although several computer vision datasets exist for various\nMars-related tasks, there is currently no open-source dataset available for\ncone detection/segmentation. Furthermore, previous studies trained models using\ndata from a single region, which limits their applicability for global\ndetection and mapping. Motivated by this, we introduce ConeQuest, the first\nexpert-annotated public dataset to identify cones on Mars. ConeQuest consists\nof >13k samples from 3 different regions of Mars. We propose two benchmark\ntasks using ConeQuest: (i) Spatial Generalization and (ii) Cone-size\nGeneralization. We finetune and evaluate widely-used segmentation models on\nboth benchmark tasks. Results indicate that cone segmentation is a challenging\nopen problem not solved by existing segmentation models, which achieve an\naverage IoU of 52.52% and 42.55% on in-distribution data for tasks (i) and\n(ii), respectively. We believe this new benchmark dataset will facilitate the\ndevelopment of more accurate and robust models for cone segmentation. Data and\ncode are available at https://github.com/kerner-lab/ConeQuest.",
            "author": [
                "Mirali Purohit",
                "Jacob Adler",
                "Hannah Kerner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08657v1",
                "http://arxiv.org/pdf/2311.08657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08655v1",
            "title": "Review of AlexNet for Medical Image Classification",
            "updated": "2023-11-15T02:28:52Z",
            "published": "2023-11-15T02:28:52Z",
            "summary": "In recent years, the rapid development of deep learning has led to a wide\nrange of applications in the field of medical image classification. The\nvariants of neural network models with ever-increasing performance share some\ncommonalities: to try to mitigate overfitting, improve generalization, avoid\ngradient vanishing and exploding, etc. AlexNet first utilizes the dropout\ntechnique to mitigate overfitting and the ReLU activation function to avoid\ngradient vanishing. Therefore, we focus our discussion on AlexNet, which has\ncontributed greatly to the development of CNNs in 2012. After reviewing over 40\npapers, including journal papers and conference papers, we give a narrative on\nthe technical details, advantages, and application areas of AlexNet.",
            "author": [
                "Wenhao Tang",
                "Junding Sun",
                "Shuihua Wang",
                "Yudong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08655v1",
                "http://arxiv.org/pdf/2311.08655v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08652v1",
            "title": "Refining Perception Contracts: Case Studies in Vision-based Safe\n  Auto-landing",
            "updated": "2023-11-15T02:26:41Z",
            "published": "2023-11-15T02:26:41Z",
            "summary": "Perception contracts provide a method for evaluating safety of control\nsystems that use machine learning for perception. A perception contract is a\nspecification for testing the ML components, and it gives a method for proving\nend-to-end system-level safety requirements. The feasibility of contract-based\ntesting and assurance was established earlier in the context of straight lane\nkeeping: a 3-dimensional system with relatively simple dynamics. This paper\npresents the analysis of two 6 and 12-dimensional flight control systems that\nuse multi-stage, heterogeneous, ML-enabled perception. The paper advances\nmethodology by introducing an algorithm for constructing data and requirement\nguided refinement of perception contracts (DaRePC). The resulting analysis\nprovides testable contracts which establish the state and environment\nconditions under which an aircraft can safety touchdown on the runway and a\ndrone can safely pass through a sequence of gates. It can also discover\nconditions (e.g., low-horizon sun) that can possibly violate the safety of the\nvision-based control system.",
            "author": [
                "Yangge Li",
                "Benjamin C Yang",
                "Yixuan Jia",
                "Daniel Zhuang",
                "Sayan Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08652v1",
                "http://arxiv.org/pdf/2311.08652v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08648v1",
            "title": "Explore Spurious Correlations at the Concept Level in Language Models\n  for Text Classification",
            "updated": "2023-11-15T01:58:54Z",
            "published": "2023-11-15T01:58:54Z",
            "summary": "Language models (LMs) have gained great achievement in various NLP tasks for\nboth fine-tuning and in-context learning (ICL) methods. Despite its outstanding\nperformance, evidence shows that spurious correlations caused by imbalanced\nlabel distributions in training data (or exemplars in ICL) lead to robustness\nissues. However, previous studies mostly focus on word- and phrase-level\nfeatures and fail to tackle it from the concept level, partly due to the lack\nof concept labels and subtle and diverse expressions of concepts in text. In\nthis paper, we first use the LLM to label the concept for each text and then\nmeasure the concept bias of models for fine-tuning or ICL on the test data.\nSecond, we propose a data rebalancing method to mitigate the spurious\ncorrelations by adding the LLM-generated counterfactual data to make a balanced\nlabel distribution for each concept. We verify the effectiveness of our\nmitigation method and show its superiority over the token removal method.\nOverall, our results show that there exist label distribution biases in\nconcepts across multiple text classification datasets, and LMs will utilize\nthese shortcuts to make predictions in both fine-tuning and ICL methods.",
            "author": [
                "Yuhang Zhou",
                "Paiheng Xu",
                "Xiaoyu Liu",
                "Bang An",
                "Wei Ai",
                "Furong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08648v1",
                "http://arxiv.org/pdf/2311.08648v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08646v1",
            "title": "Painterly Image Harmonization via Adversarial Residual Learning",
            "updated": "2023-11-15T01:53:46Z",
            "published": "2023-11-15T01:53:46Z",
            "summary": "Image compositing plays a vital role in photo editing. After inserting a\nforeground object into another background image, the composite image may look\nunnatural and inharmonious. When the foreground is photorealistic and the\nbackground is an artistic painting, painterly image harmonization aims to\ntransfer the style of background painting to the foreground object, which is a\nchallenging task due to the large domain gap between foreground and background.\nIn this work, we employ adversarial learning to bridge the domain gap between\nforeground feature map and background feature map. Specifically, we design a\ndual-encoder generator, in which the residual encoder produces the residual\nfeatures added to the foreground feature map from main encoder. Then, a\npixel-wise discriminator plays against the generator, encouraging the refined\nforeground feature map to be indistinguishable from background feature map.\nExtensive experiments demonstrate that our method could achieve more harmonious\nand visually appealing results than previous methods.",
            "author": [
                "Xudong Wang",
                "Li Niu",
                "Junyan Cao",
                "Yan Hong",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08646v1",
                "http://arxiv.org/pdf/2311.08646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08645v1",
            "title": "Against negative splitting: the case for alternative pacing strategies\n  for elite marathon athletes in official events",
            "updated": "2023-11-15T01:51:33Z",
            "published": "2023-11-15T01:51:33Z",
            "summary": "Objectives: Negative splitting (i.e., finishing the race faster) is a tactic\ncommonly employed by elite marathon athletes, even though research supporting\nthe strategy is scarce. The presence of pacers allows the main runner to run\nbehind a formation, preserving energy. Our aim is to show that, in the presence\nof pacers, the most efficient pacing strategy is positive splitting. Methods:\nWe evaluated the performance of an elite marathon runner from an energetic\nstandpoint, including drag values obtained through Computational Fluid Dynamics\n(CFD). In varying simulations for different pacing strategies, the energy for\nboth the main runner and his pacer were conserved and the total race time was\ncalculated. Results: In order to achieve minimum race time, the main runner\nmust start the race faster and run behind the pacers, and when the pacers drop\nout, finish the race slower. Optimal race times are obtained when the protected\nphase is run 2.4 to 2.6% faster than the unprotected phase. Conclusion: Our\nresults provide strong evidence that positive splitting is indeed the best\npacing strategy when at least one pacer is present, causing significant time\nsavings in official marathon events.",
            "author": [
                "Guilherme Fernandes",
                "Victor Maldonado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08645v1",
                "http://arxiv.org/pdf/2311.08645v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11927v1",
            "title": "Automatic Digitization and Orientation of Scanned Mesh Data for Floor\n  Plan and 3D Model Generation",
            "updated": "2023-11-15T01:47:12Z",
            "published": "2023-11-15T01:47:12Z",
            "summary": "This paper describes a novel approach for generating accurate floor plans and\n3D models of building interiors using scanned mesh data. Unlike previous\nmethods, which begin with a high resolution point cloud from a laser\nrange-finder, our approach begins with triangle mesh data, as from a Microsoft\nHoloLens. It generates two types of floor plans, a \"pen-and-ink\" style that\npreserves details and a drafting-style that reduces clutter. It processes the\n3D model for use in applications by aligning it with coordinate axes,\nannotating important objects, dividing it into stories, and removing the\nceiling. Its performance is evaluated on commercial and residential buildings,\nwith experiments to assess quality and dimensional accuracy. Our approach\ndemonstrates promising potential for automatic digitization and orientation of\nscanned mesh data, enabling floor plan and 3D model generation in various\napplications such as navigation, interior design, furniture placement,\nfacilities management, building construction, and HVAC design.",
            "author": [
                "Ritesh Sharma",
                "Eric Bier",
                "Lester Nelson",
                "Mahabir Bhandari",
                "Niraj Kunwar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11927v1",
                "http://arxiv.org/pdf/2311.11927v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08640v1",
            "title": "Multistage Collaborative Knowledge Distillation from Large Language\n  Models",
            "updated": "2023-11-15T01:28:28Z",
            "published": "2023-11-15T01:28:28Z",
            "summary": "We study semi-supervised sequence prediction tasks where labeled data are too\nscarce to effectively finetune a model and at the same time few-shot prompting\nof a large language model (LLM) has suboptimal performance. This happens when a\ntask, such as parsing, is expensive to annotate and also unfamiliar to a\npretrained LLM. In this paper, we present a discovery that student models\ndistilled from a prompted LLM can often generalize better than their teacher on\nsuch tasks. Leveraging this finding, we propose a new distillation method,\nmultistage collaborative knowledge distillation from an LLM (MCKD), for such\ntasks. MCKD first prompts an LLM using few-shot in-context learning to produce\npseudolabels for unlabeled data. Then, at each stage of distillation, a pair of\nstudents are trained on disjoint partitions of the pseudolabeled data. Each\nstudent subsequently produces new and improved pseudolabels for the unseen\npartition to supervise the next round of student(s) with. We show the benefit\nof multistage cross-partition labeling on two constituency parsing tasks. On\nCRAFT biomedical parsing, 3-stage MCKD with 50 labeled examples matches the\nperformance of supervised finetuning with 500 examples and outperforms the\nprompted LLM and vanilla KD by 7.5% and 3.7% parsing F1, respectively.",
            "author": [
                "Jiachen Zhao",
                "Wenlong Zhao",
                "Andrew Drozdov",
                "Benjamin Rozonoyer",
                "Md Arafat Sultan",
                "Jay-Yoon Lee",
                "Mohit Iyyer",
                "Andrew McCallum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08640v1",
                "http://arxiv.org/pdf/2311.08640v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08637v1",
            "title": "Formal Proofs as Structured Explanations: Proposing Several Tasks on\n  Explainable Natural Language Inference",
            "updated": "2023-11-15T01:24:09Z",
            "published": "2023-11-15T01:24:09Z",
            "summary": "In this position paper, we propose a way of exploiting formal proofs to put\nforward several explainable natural language inference (NLI) tasks. The formal\nproofs will be produced by a reliable and high-performing logic-based NLI\nsystem. Taking advantage of the in-depth information available in the generated\nformal proofs, we show how it can be used to define NLI tasks with structured\nexplanations. The proposed tasks can be ordered according to difficulty defined\nin terms of the granularity of explanations. We argue that the tasks will\nsuffer with substantially fewer shortcomings than the existing explainable NLI\ntasks (or datasets).",
            "author": [
                "Lasha Abzianidze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08637v1",
                "http://arxiv.org/pdf/2311.08637v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08631v2",
            "title": "Influence of Video Dynamics on EEG-based Single-Trial Video Target\n  Surveillance Syste",
            "updated": "2023-11-19T03:00:35Z",
            "published": "2023-11-15T01:10:24Z",
            "summary": "Target detection models are one of the widely used deep learning-based\napplications for reducing human efforts on video surveillance and patrol.\nHowever, the application of conventional computer vision-based target detection\nmodels in military usage can result in limited performance, due to the lack of\nsample data of hostile targets. In this paper, we present the possibility of\nthe electroencephalography-based video target detection model, which could be\napplied as a supportive module of the military video surveillance system. The\nproposed framework and detection model showed prospective performance achieving\na mean macro F-beta of 0.6522 with asynchronous real-time data from five\nsubjects, in a certain video stimulus, but not on some video stimuli. By\nanalyzing the results of experiments using each video stimulus, we present the\nfactors that would affect the performance of electroencephalography-based video\ntarget detection models.",
            "author": [
                "Heon-Gyu Kwak",
                "Sung-Jin Kim",
                "Hyeon-Taek Han",
                "Ji-Hoon Jeong",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08631v2",
                "http://arxiv.org/pdf/2311.08631v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09258v1",
            "title": "Single-Chip Silicon Photonic Processor for Analog Optical and Microwave\n  Signals",
            "updated": "2023-11-15T01:08:31Z",
            "published": "2023-11-15T01:08:31Z",
            "summary": "The explosion of data volume in communications, AI training, and cloud\ncomputing requires efficient data handling, which is typically stored as\ndigital electrical information and transmitted as wireless radio frequency (RF)\nsignals or light waves in optical fibres. Today's communications systems mostly\ntreat the RF and optical signals separately, which results in unnecessary\nconversion losses and increased cost. In this work, we report the first fully\non-chip signal processor for high-speed RF and optical signals based on a\nsilicon photonic circuit. Our chip is capable of both generation and detection\nof analog electrical and optical signals, and can program a user-defined filter\nresponse in both domains. The single silicon photonic chip integrates all\nessential components like modulators, optical filters, and photodetectors, as\nwell as tunable lasers enabled by transfer-printed Indium Phosphide (InP)\noptical amplifiers. The system's configuration is locally programmed through\nthermo-optic phase shifters and monitored by photodetectors. We demonstrate our\nchip's capabilities with different combinations of RF and optical signal\nprocessing functions, including optical and RF signal generation and filtering.\nThis represents a key step towards compact microwave photonic systems for\nfuture wireless communication and sensing applications.",
            "author": [
                "Hong Deng",
                "Jing Zhang",
                "Emadreza Soltanian",
                "Xiangfeng Chen",
                "Chao Pang",
                "Nicolas Vaissiere",
                "Delphine Neel",
                "Joan Ramirez",
                "Jean Decobert",
                "Nishant Singh",
                "Guy Torfs",
                "Gunther Roelkens",
                "Wim Bogaerts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09258v1",
                "http://arxiv.org/pdf/2311.09258v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08624v1",
            "title": "Flow control by a hybrid use of machine learning and control theory",
            "updated": "2023-11-15T01:01:57Z",
            "published": "2023-11-15T01:01:57Z",
            "summary": "Flow control has a great potential to contribute to the sustainable society\nthrough mitigation of environmental burden. However, high dimensional and\nnonlinear nature of fluid flows poses challenges in designing efficient control\nlaws. This paper aims to propose a hybrid method (i.e., machine learning and\ncontrol theory) for feedback control of fluid flows. We propose a partially\nnonlinear linear-system extraction autoencoder (pn-LEAE), which consists of\nconvolutional neural networks-based autoencoder (CNN-AE) and a custom layer to\nextract a low-dimensional latent dynamics. This pn-LEAE basically extracts a\nlinear dynamical system so that the modern control theory can easily be\napplied, but at the same time, it is designed to capture a nonlinear\ndevelopment of the latent dynamics. We demonstrate the effectiveness of the\nlinear system extracted by the pn-LEAE, as well as the designed control law's\neffectiveness for a flow around a circular cylinder at the Reynolds number of\n${\\rm Re}_{D}=100$. This is the first attempt utilizing CNN-AE for\nlinearization of fluid flows involving transient development to design a\nfeedback control law.",
            "author": [
                "Takeru Ishize",
                "Hiroshi Omichi",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08624v1",
                "http://arxiv.org/pdf/2311.08624v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08623v1",
            "title": "DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder\n  Transformer Models",
            "updated": "2023-11-15T01:01:02Z",
            "published": "2023-11-15T01:01:02Z",
            "summary": "Encoder-decoder transformer models have achieved great success on various\nvision-language (VL) tasks, but they suffer from high inference latency.\nTypically, the decoder takes up most of the latency because of the\nauto-regressive decoding. To accelerate the inference, we propose an approach\nof performing Dynamic Early Exit on Decoder (DEED). We build a multi-exit\nencoder-decoder transformer model which is trained with deep supervision so\nthat each of its decoder layers is capable of generating plausible predictions.\nIn addition, we leverage simple yet practical techniques, including shared\ngeneration head and adaptation modules, to keep accuracy when exiting at\nshallow decoder layers. Based on the multi-exit model, we perform step-level\ndynamic early exit during inference, where the model may decide to use fewer\ndecoder layers based on its confidence of the current layer at each individual\ndecoding step. Considering different number of decoder layers may be used at\ndifferent decoding steps, we compute deeper-layer decoder features of previous\ndecoding steps just-in-time, which ensures the features from different decoding\nsteps are semantically aligned. We evaluate our approach with two\nstate-of-the-art encoder-decoder transformer models on various VL tasks. We\nshow our approach can reduce overall inference latency by 30%-60% with\ncomparable or even higher accuracy compared to baselines.",
            "author": [
                "Peng Tang",
                "Pengkai Zhu",
                "Tian Li",
                "Srikar Appalaraju",
                "Vijay Mahadevan",
                "R. Manmatha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08623v1",
                "http://arxiv.org/pdf/2311.08623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08622v1",
            "title": "Multiple-Question Multiple-Answer Text-VQA",
            "updated": "2023-11-15T01:00:02Z",
            "published": "2023-11-15T01:00:02Z",
            "summary": "We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do\ntext-VQA in encoder-decoder transformer models. The text-VQA task requires a\nmodel to answer a question by understanding multi-modal content: text\n(typically from OCR) and an associated image. To the best of our knowledge,\nalmost all previous approaches for text-VQA process a single question and its\nassociated content to predict a single answer. In order to answer multiple\nquestions from the same image, each question and content are fed into the model\nmultiple times. In contrast, our proposed MQMA approach takes multiple\nquestions and content as input at the encoder and predicts multiple answers at\nthe decoder in an auto-regressive manner at the same time. We make several\nnovel architectural modifications to standard encoder-decoder transformers to\nsupport MQMA. We also propose a novel MQMA denoising pre-training task which is\ndesigned to teach the model to align and delineate multiple questions and\ncontent with associated answers. MQMA pre-trained model achieves\nstate-of-the-art results on multiple text-VQA datasets, each with strong\nbaselines. Specifically, on OCR-VQA (+2.5%), TextVQA (+1.4%), ST-VQA (+0.6%),\nDocVQA (+1.1%) absolute improvements over the previous state-of-the-art\napproaches.",
            "author": [
                "Peng Tang",
                "Srikar Appalaraju",
                "R. Manmatha",
                "Yusheng Xie",
                "Vijay Mahadevan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08622v1",
                "http://arxiv.org/pdf/2311.08622v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08621v1",
            "title": "Cross Device Federated Intrusion Detector for Early Stage Botnet\n  Propagation in IoT",
            "updated": "2023-11-15T00:58:35Z",
            "published": "2023-11-15T00:58:35Z",
            "summary": "A botnet is an army of zombified computers infected with malware and\ncontrolled by malicious actors to carry out tasks such as Distributed Denial of\nService (DDoS) attacks. Billions of Internet of Things (IoT) devices are\nprimarily targeted to be infected as bots since they are configured with weak\ncredentials or contain common vulnerabilities. Detecting botnet propagation by\nmonitoring the network traffic is difficult as they easily blend in with\nregular network traffic. The traditional machine learning (ML) based Intrusion\nDetection System (IDS) requires the raw data to be captured and sent to the ML\nprocessor to detect intrusion. In this research, we examine the viability of a\ncross-device federated intrusion detection mechanism where each device runs the\nML model on its data and updates the model weights to the central coordinator.\nThis mechanism ensures the client's data is not shared with any third party,\nterminating privacy leakage. The model examines each data packet separately and\npredicts anomalies. We evaluate our proposed mechanism on a real botnet\npropagation dataset called MedBIoT. Overall, the proposed method produces an\naverage accuracy of 71%, precision 78%, recall 71%, and f1-score 68%. In\naddition, we also examined whether any device taking part in federated learning\ncan employ a poisoning attack on the overall system.",
            "author": [
                "Angela Grace Famera",
                "Raj Mani Shukla",
                "Suman Bhunia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08621v1",
                "http://arxiv.org/pdf/2311.08621v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08620v1",
            "title": "Toucan: Token-Aware Character Level Language Modeling",
            "updated": "2023-11-15T00:57:51Z",
            "published": "2023-11-15T00:57:51Z",
            "summary": "Character-level language models obviate the need for separately trained\ntokenizers, but efficiency suffers from longer sequence lengths. Learning to\ncombine character representations into tokens has made training these models\nmore efficient, but they still require decoding characters individually. We\npropose Toucan, an augmentation to character-level models to make them\n\"token-aware\". Comparing our method to prior work, we demonstrate significant\nspeed-ups in character generation without a loss in language modeling\nperformance. We then explore differences between our learned dynamic\ntokenization of character sequences with popular fixed vocabulary solutions\nsuch as Byte-Pair Encoding and WordPiece, finding our approach leads to a\ngreater amount of longer sequences tokenized as single items. Our project and\ncode are available at https://nlp.jhu.edu/nuggets/.",
            "author": [
                "William Fleshman",
                "Benjamin Van Durme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08620v1",
                "http://arxiv.org/pdf/2311.08620v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08618v1",
            "title": "Computing the k-th Eigenvalue of Symmetric $H^2$-Matrices",
            "updated": "2023-11-15T00:48:49Z",
            "published": "2023-11-15T00:48:49Z",
            "summary": "The numerical solution of eigenvalue problems is essential in various\napplication areas of scientific and engineering domains. In many problem\nclasses, the practical interest is only a small subset of eigenvalues so it is\nunnecessary to compute all of the eigenvalues. Notable examples are the\nelectronic structure problems where the $k$-th smallest eigenvalue is closely\nrelated to the electronic properties of materials. In this paper, we consider\nthe $k$-th eigenvalue problems of symmetric dense matrices with low-rank\noff-diagonal blocks. We present a linear time generalized LDL decomposition of\n$\\mathcal{H}^2$ matrices and combine it with the bisection eigenvalue algorithm\nto compute the $k$-th eigenvalue with controllable accuracy. In addition, if\nmore than one eigenvalue is required, some of the previous computations can be\nreused to compute the other eigenvalues in parallel. Numerical experiments show\nthat our method is more efficient than the state-of-the-art dense eigenvalue\nsolver in LAPACK/ScaLAPACK and ELPA. Furthermore, tests on electronic state\ncalculations of carbon nanomaterials demonstrate that our method outperforms\nthe existing HSS-based bisection eigenvalue algorithm on 3D problems.",
            "author": [
                "M. Ridwan Apriansyah",
                "Rio Yokota"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3605573.3605607",
                "http://arxiv.org/abs/2311.08618v1",
                "http://arxiv.org/pdf/2311.08618v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "G.1.2; G.1.3; G.4; D.1.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10763v1",
            "title": "Comparing Generalization in Learning with Limited Numbers of Exemplars:\n  Transformer vs. RNN in Attractor Dynamics",
            "updated": "2023-11-15T00:37:49Z",
            "published": "2023-11-15T00:37:49Z",
            "summary": "ChatGPT, a widely-recognized large language model (LLM), has recently gained\nsubstantial attention for its performance scaling, attributed to the billions\nof web-sourced natural language sentences used for training. Its underlying\narchitecture, Transformer, has found applications across diverse fields,\nincluding video, audio signals, and robotic movement. %The crucial question\nthis raises concerns the Transformer's generalization-in-learning (GIL)\ncapacity. However, this raises a crucial question about Transformer's\ngeneralization in learning (GIL) capacity. Is ChatGPT's success chiefly due to\nthe vast dataset used for training, or is there more to the story? To\ninvestigate this, we compared Transformer's GIL capabilities with those of a\ntraditional Recurrent Neural Network (RNN) in tasks involving attractor\ndynamics learning. For performance evaluation, the Dynamic Time Warping (DTW)\nmethod has been employed. Our simulation results suggest that under conditions\nof limited data availability, Transformer's GIL abilities are markedly inferior\nto those of RNN.",
            "author": [
                "Rui Fukushima",
                "Jun Tani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10763v1",
                "http://arxiv.org/pdf/2311.10763v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08614v1",
            "title": "XplainLLM: A QA Explanation Dataset for Understanding LLM\n  Decision-Making",
            "updated": "2023-11-15T00:34:28Z",
            "published": "2023-11-15T00:34:28Z",
            "summary": "Large Language Models (LLMs) have recently made impressive strides in natural\nlanguage understanding tasks. Despite their remarkable performance,\nunderstanding their decision-making process remains a big challenge. In this\npaper, we look into bringing some transparency to this process by introducing a\nnew explanation dataset for question answering (QA) tasks that integrates\nknowledge graphs (KGs) in a novel way. Our dataset includes 12,102\nquestion-answer-explanation (QAE) triples. Each explanation in the dataset\nlinks the LLM's reasoning to entities and relations in the KGs. The explanation\ncomponent includes a why-choose explanation, a why-not-choose explanation, and\na set of reason-elements that underlie the LLM's decision. We leverage KGs and\ngraph attention networks (GAT) to find the reason-elements and transform them\ninto why-choose and why-not-choose explanations that are comprehensible to\nhumans. Through quantitative and qualitative evaluations, we demonstrate the\npotential of our dataset to improve the in-context learning of LLMs, and\nenhance their interpretability and explainability. Our work contributes to the\nfield of explainable AI by enabling a deeper understanding of the LLMs\ndecision-making process to make them more transparent and thereby, potentially\nmore reliable, to researchers and practitioners alike. Our dataset is available\nat: https://github.com/chen-zichen/XplainLLM_dataset.git",
            "author": [
                "Zichen Chen",
                "Jianda Chen",
                "Mitali Gaidhani",
                "Ambuj Singh",
                "Misha Sra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08614v1",
                "http://arxiv.org/pdf/2311.08614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08613v1",
            "title": "High-Resolution Particle-In-Cell Simulations of Two-Dimensional\n  Bernstein-Greene-Kruskal Modes",
            "updated": "2023-11-15T00:31:48Z",
            "published": "2023-11-15T00:31:48Z",
            "summary": "We present two dimensional (2D) particle-in-cell (PIC) simulations of 2D\nBernstein-Greene-Kruskal (BGK) modes, which are exact nonlinear steady-state\nsolutions of the Vlasov-Poisson equations, on a 2D plane perpendicular to a\nbackground magnetic field, with a cylindrically symmetric electric potential\nlocalized on the plane. PIC simulations are initialized using analytic electron\ndistributions and electric potentials from the theory. We confirm the validity\nof such solutions using high-resolutions up to a 2048^2 grid. We show that the\nsolutions are dynamically stable for a stronger background magnetic field,\nwhile keeping other parameters of the model fixed, but become unstable when the\nfield strength is weaker than a certain value. When a mode becomes unstable, we\nobserve that the instability begins with the excitation of azimuthal\nelectrostatic waves that ends with a spiral pattern.",
            "author": [
                "J. McClung",
                "M. T. Franciscovich",
                "K. Germaschewski",
                "C. S. Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08613v1",
                "http://arxiv.org/pdf/2311.08613v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "astro-ph.GA",
                "physics.comp-ph",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08609v1",
            "title": "On syzygies of Mori fibre spaces",
            "updated": "2023-11-15T00:18:34Z",
            "published": "2023-11-15T00:18:34Z",
            "summary": "We introduce homological and homotopical $r$-syzygies of Mori fibre spaces as\na generalization of Sarkisov links and relations of Sarkisov links. For any\nproper morphism $Y/R$, we construct a contractible (if not empty) CW complex\nsuch that there is a 1-1 correspondence between its cells and the central\nmodels of $Y/R$. We derive from this CW complex a long exact sequence and a\nspectral sequence converging to the (co)homology of the relative birational\nautomorphism group of $Y/R$. As an application, we compute the spectral\nsequence for the second Cremona group and show that its second group\n(co)homology is non-trivial.",
            "author": [
                "Yang He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08609v1",
                "http://arxiv.org/pdf/2311.08609v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08607v1",
            "title": "Towards Generalizable SER: Soft Labeling and Data Augmentation for\n  Modeling Temporal Emotion Shifts in Large-Scale Multilingual Speech",
            "updated": "2023-11-15T00:09:21Z",
            "published": "2023-11-15T00:09:21Z",
            "summary": "Recognizing emotions in spoken communication is crucial for advanced\nhuman-machine interaction. Current emotion detection methodologies often\ndisplay biases when applied cross-corpus. To address this, our study\namalgamates 16 diverse datasets, resulting in 375 hours of data across\nlanguages like English, Chinese, and Japanese. We propose a soft labeling\nsystem to capture gradational emotional intensities. Using the Whisper encoder\nand data augmentation methods inspired by contrastive learning, our method\nemphasizes the temporal dynamics of emotions. Our validation on four\nmultilingual datasets demonstrates notable zero-shot generalization. We publish\nour open source model weights and initial promising results after fine-tuning\non Hume-Prosody.",
            "author": [
                "Mohamed Osman",
                "Tamer Nadeem",
                "Ghada Khoriba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08607v1",
                "http://arxiv.org/pdf/2311.08607v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08605v1",
            "title": "Navigating the Ocean of Biases: Political Bias Attribution in Language\n  Models via Causal Structures",
            "updated": "2023-11-15T00:02:25Z",
            "published": "2023-11-15T00:02:25Z",
            "summary": "The rapid advancement of Large Language Models (LLMs) has sparked intense\ndebate regarding their ability to perceive and interpret complex\nsocio-political landscapes. In this study, we undertake an exploration of\ndecision-making processes and inherent biases within LLMs, exemplified by\nChatGPT, specifically contextualizing our analysis within political debates. We\naim not to critique or validate LLMs' values, but rather to discern how they\ninterpret and adjudicate \"good arguments.\" By applying Activity Dependency\nNetworks (ADNs), we extract the LLMs' implicit criteria for such assessments\nand illustrate how normative values influence these perceptions. We discuss the\nconsequences of our findings for human-AI alignment and bias mitigation. Our\ncode and data at https://github.com/david-jenny/LLM-Political-Study.",
            "author": [
                "David F. Jenny",
                "Yann Billeter",
                "Mrinmaya Sachan",
                "Bernhard Sch\u00f6lkopf",
                "Zhijing Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08605v1",
                "http://arxiv.org/pdf/2311.08605v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08598v1",
            "title": "DALA: A Distribution-Aware LoRA-Based Adversarial Attack against\n  Pre-trained Language Models",
            "updated": "2023-11-14T23:43:47Z",
            "published": "2023-11-14T23:43:47Z",
            "summary": "Pre-trained language models (PLMs) that achieve success in applications are\nsusceptible to adversarial attack methods that are capable of generating\nadversarial examples with minor perturbations. Although recent attack methods\ncan achieve a relatively high attack success rate (ASR), our observation shows\nthat the generated adversarial examples have a different data distribution\ncompared with the original examples. Specifically, these adversarial examples\nexhibit lower confidence levels and higher distance to the training data\ndistribution. As a result, they are easy to detect using very simple detection\nmethods, diminishing the actual effectiveness of these attack methods. To solve\nthis problem, we propose a Distribution-Aware LoRA-based Adversarial Attack\n(DALA) method, which considers the distribution shift of adversarial examples\nto improve attack effectiveness under detection methods. We further design a\nnew evaluation metric NASR combining ASR and detection for the attack task. We\nconduct experiments on four widely-used datasets and validate the attack\neffectiveness on ASR and NASR of the adversarial examples generated by DALA on\nthe BERT-base model and the black-box LLaMA2-7b model.",
            "author": [
                "Yibo Wang",
                "Xiangjue Dong",
                "James Caverlee",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08598v1",
                "http://arxiv.org/pdf/2311.08598v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08596v1",
            "title": "Are You Sure? Challenging LLMs Leads to Performance Drops in The\n  FlipFlop Experiment",
            "updated": "2023-11-14T23:40:22Z",
            "published": "2023-11-14T23:40:22Z",
            "summary": "The interactive nature of Large Language Models (LLMs) theoretically allows\nmodels to refine and improve their answers, yet systematic analysis of the\nmulti-turn behavior of LLMs remains limited. In this paper, we propose the\nFlipFlop experiment: in the first round of the conversation, an LLM responds to\na prompt containing a classification task. In a second round, the LLM is\nchallenged with a follow-up phrase like \"Are you sure?\", offering an\nopportunity for the model to reflect on its initial answer, and decide whether\nto confirm or flip its answer. A systematic study of nine LLMs on seven\nclassification tasks reveals that models flip their answers on average 46% of\nthe time and that all models see a deterioration of accuracy between their\nfirst and final prediction, with an average drop of 17%. The FlipFlop\nexperiment illustrates the universality of sycophantic behavior in LLMs and\nprovides a robust framework to analyze model behavior and evaluate potential\nsolutions.",
            "author": [
                "Philippe Laban",
                "Lidiya Murakhovs'ka",
                "Caiming Xiong",
                "Chien-Sheng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08596v1",
                "http://arxiv.org/pdf/2311.08596v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08595v1",
            "title": "Fast Parallel Tensor Times Same Vector for Hypergraphs",
            "updated": "2023-11-14T23:39:42Z",
            "published": "2023-11-14T23:39:42Z",
            "summary": "Hypergraphs are a popular paradigm to represent complex real-world networks\nexhibiting multi-way relationships of varying sizes. Mining centrality in\nhypergraphs via symmetric adjacency tensors has only recently become\ncomputationally feasible for large and complex datasets. To enable scalable\ncomputation of these and related hypergraph analytics, here we focus on the\nSparse Symmetric Tensor Times Same Vector (S$^3$TTVc) operation. We introduce\nthe Compound Compressed Sparse Symmetric (CCSS) format, an extension of the\ncompact CSS format for hypergraphs of varying hyperedge sizes and present a\nshared-memory parallel algorithm to compute S$^3$TTVc. We experimentally show\nS$^3$TTVc computation using the CCSS format achieves better performance than\nthe naive baseline, and is subsequently more performant for hypergraph\n$H$-eigenvector centrality.",
            "author": [
                "Shruti Shivakumar",
                "Ilya Amburg",
                "Sinan G. Aksoy",
                "Jiajia Li",
                "Stephen J. Young",
                "Srinivas Aluru"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08595v1",
                "http://arxiv.org/pdf/2311.08595v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.DC",
                "cs.NA",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08593v1",
            "title": "ACID: Abstractive, Content-Based IDs for Document Retrieval with\n  Language Models",
            "updated": "2023-11-14T23:28:36Z",
            "published": "2023-11-14T23:28:36Z",
            "summary": "Generative retrieval (Wang et al., 2022; Tay et al., 2022) is a new approach\nfor end-to-end document retrieval that directly generates document identifiers\ngiven an input query. Techniques for designing effective, high-quality document\nIDs remain largely unexplored. We introduce ACID, in which each document's ID\nis composed of abstractive keyphrases generated by a large language model,\nrather than an integer ID sequence as done in past work. We compare our method\nwith the current state-of-the-art technique for ID generation, which produces\nIDs through hierarchical clustering of document embeddings. We also examine\nsimpler methods to generate natural-language document IDs, including the naive\napproach of using the first k words of each document as its ID or words with\nhigh BM25 scores in that document. We show that using ACID improves top-10 and\ntop-20 accuracy by 15.6% and 14.4% (relative) respectively versus the\nstate-of-the-art baseline on the MSMARCO 100k retrieval task, and 4.4% and 4.0%\nrespectively on the Natural Questions 100k retrieval task. Our results\ndemonstrate the effectiveness of human-readable, natural-language IDs in\ngenerative retrieval with LMs. The code for reproducing our results and the\nkeyword-augmented datasets will be released on formal publication.",
            "author": [
                "Haoxin Li",
                "Phillip Keung",
                "Daniel Cheng",
                "Jungo Kasai",
                "Noah A. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08593v1",
                "http://arxiv.org/pdf/2311.08593v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08592v2",
            "title": "AART: AI-Assisted Red-Teaming with Diverse Data Generation for New\n  LLM-powered Applications",
            "updated": "2023-11-29T23:18:16Z",
            "published": "2023-11-14T23:28:23Z",
            "summary": "Adversarial testing of large language models (LLMs) is crucial for their safe\nand responsible deployment. We introduce a novel approach for automated\ngeneration of adversarial evaluation datasets to test the safety of LLM\ngenerations on new downstream applications. We call it AI-assisted Red-Teaming\n(AART) - an automated alternative to current manual red-teaming efforts. AART\noffers a data generation and augmentation pipeline of reusable and customizable\nrecipes that reduce human effort significantly and enable integration of\nadversarial testing earlier in new product development. AART generates\nevaluation datasets with high diversity of content characteristics critical for\neffective adversarial testing (e.g. sensitive and harmful concepts, specific to\na wide range of cultural and geographic regions and application scenarios). The\ndata generation is steered by AI-assisted recipes to define, scope and\nprioritize diversity within the application context. This feeds into a\nstructured LLM-generation process that scales up evaluation priorities.\nCompared to some state-of-the-art tools, AART shows promising results in terms\nof concept coverage and data quality.",
            "author": [
                "Bhaktipriya Radharapu",
                "Kevin Robinson",
                "Lora Aroyo",
                "Preethi Lahoti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08592v2",
                "http://arxiv.org/pdf/2311.08592v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08591v1",
            "title": "A Two-Field Formulation for Surfactant Transport within the Algebraic\n  Volume of Fluid Method",
            "updated": "2023-11-14T23:25:37Z",
            "published": "2023-11-14T23:25:37Z",
            "summary": "Surfactant transport plays an important role in many technical processes and\nindustrial applications such as chemical reactors, microfluidics, printing and\ncoating technology. High fidelity numerical simulations of two-phase flow\nphenomena reveal rich insights into the flow dynamics, heat, mass and species\ntransport. In the present study, a two-field formulation for surfactant\ntransport within the algebraic volume of fluid method is presented. The slight\ndiffuse nature of representing the interface in the algebraic volume of fluid\nmethod is utilized to track the concentration of surfactant at the interface as\na volumetric concentration. Transport of insoluble and soluble surfactants is\ninvestigated by tracking two different concentrations of the surfactant, one\nwithin the bulk of the liquid and the other one at the interface. These two\ntransport equations are in turn coupled by source terms considering the\nad-/desorption processes at a liquid-gas interface. Appropriate boundary\nconditions at a solid-fluid interface are formulated to ensure surfactant\nconservation, while also enabling to study the ad-/desorption processes at a\nsolid-fluid interface. The developed numerical method is verified by comparing\nthe numerical simulations with well-known analytical and numerical reference\nsolutions. The presented numerical methodology offers a seamless integration of\nsurfactant transport into the algebraic volume of fluid method, where the\nlatter has many advantages such as volume conservation and an inherent ability\nof handling large interface deformations and topological changes.",
            "author": [
                "T. Antritter",
                "T. Josyula",
                "T. Mari\u0107",
                "D. Bothe",
                "P. Hachmann",
                "B. Buck",
                "T. Gambaryan-Roisman",
                "P. Stephan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08591v1",
                "http://arxiv.org/pdf/2311.08591v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08590v1",
            "title": "PEMA: Plug-in External Memory Adaptation for Language Models",
            "updated": "2023-11-14T23:20:51Z",
            "published": "2023-11-14T23:20:51Z",
            "summary": "Pre-trained language models (PLMs) have demonstrated impressive performance\nacross various downstream NLP tasks. Nevertheless, the resource requirements of\npre-training large language models in terms of memory and training compute pose\nsignificant challenges. Furthermore, due to the substantial resources required,\nmany PLM weights are confidential. Consequently, users are compelled to share\ntheir data with model owners for fine-tuning on specific tasks. To overcome the\nlimitations, we introduce Plug-in External Memory Adaptation (PEMA), a\nParameter-Efficient Fine-Tuning (PEFT) approach designed for fine-tuning PLMs\nwithout the need for all weights. PEMA can be integrated into the context\nrepresentation of test data during inference to execute downstream tasks. It\nleverages an external memory to store context representations generated by a\nPLM, mapped with the desired target word. Our method entails training\nLoRA-based weight matrices within the final layer of the PLM for enhanced\nefficiency. The probability is then interpolated with the next-word\ndistribution from the PLM to perform downstream tasks. To improve the\ngeneration quality, we propose a novel interpolation strategy named Gradual\nUnrolling. To demonstrate the effectiveness of our proposed method, we conduct\nexperiments to demonstrate the efficacy of PEMA with a syntactic dataset and\nassess its performance on machine translation and style transfer tasks using\nreal datasets. PEMA outperforms other PEFT methods in terms of memory and\nlatency efficiency for training and inference. Furthermore, it outperforms\nother baselines in preserving the meaning of sentences while generating\nappropriate language and styles.",
            "author": [
                "HyunJin Kim",
                "Young Jin Kim",
                "JinYeong Bak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08590v1",
                "http://arxiv.org/pdf/2311.08590v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08589v1",
            "title": "Carbon Responder: Coordinating Demand Response for the Datacenter Fleet",
            "updated": "2023-11-14T23:20:50Z",
            "published": "2023-11-14T23:20:50Z",
            "summary": "The increasing integration of renewable energy sources results in\nfluctuations in carbon intensity throughout the day. To mitigate their carbon\nfootprint, datacenters can implement demand response (DR) by adjusting their\nload based on grid signals. However, this presents challenges for private\ndatacenters with diverse workloads and services. One of the key challenges is\nefficiently and fairly allocating power curtailment across different workloads.\nIn response to these challenges, we propose the Carbon Responder framework.\n  The Carbon Responder framework aims to reduce the carbon footprint of\nheterogeneous workloads in datacenters by modulating their power usage. Unlike\nprevious studies, Carbon Responder considers both online and batch workloads\nwith different service level objectives and develops accurate performance\nmodels to achieve performance-aware power allocation. The framework supports\nthree alternative policies: Efficient DR, Fair and Centralized DR, and Fair and\nDecentralized DR. We evaluate Carbon Responder polices using production\nworkload traces from a private hyperscale datacenter. Our experimental results\ndemonstrate that the efficient Carbon Responder policy reduces the carbon\nfootprint by around 2x as much compared to baseline approaches adapted from\nexisting methods. The fair Carbon Responder policies distribute the performance\npenalties and carbon reduction responsibility fairly among workloads.",
            "author": [
                "Jiali Xing",
                "Bilge Acun",
                "Aditya Sundarrajan",
                "David Brooks",
                "Manoj Chakkaravarthy",
                "Nikky Avila",
                "Carole-Jean Wu",
                "Benjamin C. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08589v1",
                "http://arxiv.org/pdf/2311.08589v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08588v1",
            "title": "CodeScope: An Execution-based Multilingual Multitask Multidimensional\n  Benchmark for Evaluating LLMs on Code Understanding and Generation",
            "updated": "2023-11-14T23:18:52Z",
            "published": "2023-11-14T23:18:52Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable performance on\ncoding related tasks, particularly on assisting humans in programming and\nfacilitating programming automation. However, existing benchmarks for\nevaluating the code understanding and generation capacities of LLMs suffer from\nsevere limitations. First, most benchmarks are deficient as they focus on a\nnarrow range of popular programming languages and specific tasks, whereas the\nreal-world software development scenarios show dire need to implement systems\nwith multilingual programming environments to satisfy diverse requirements.\nPractical programming practices also strongly expect multi-task settings for\ntesting coding capabilities of LLMs comprehensively and robustly. Second, most\nbenchmarks also fail to consider the actual executability and the consistency\nof execution results of the generated code. To bridge these gaps between\nexisting benchmarks and expectations from practical applications, we introduce\nCodeScope, an execution-based, multilingual, multi-task, multi-dimensional\nevaluation benchmark for comprehensively gauging LLM capabilities on coding\ntasks. CodeScope covers 43 programming languages and 8 coding tasks. It\nevaluates the coding performance of LLMs from three dimensions (perspectives):\ndifficulty, efficiency, and length. To facilitate execution-based evaluations\nof code generation, we develop MultiCodeEngine, an automated code execution\nengine that supports 14 programming languages. Finally, we systematically\nevaluate and analyze 8 mainstream LLMs on CodeScope tasks and demonstrate the\nsuperior breadth and challenges of CodeScope for evaluating LLMs on code\nunderstanding and generation tasks compared to other benchmarks. The CodeScope\nbenchmark and datasets are publicly available at\nhttps://github.com/WeixiangYAN/CodeScope.",
            "author": [
                "Weixiang Yan",
                "Haitian Liu",
                "Yunkun Wang",
                "Yunzhe Li",
                "Qian Chen",
                "Wen Wang",
                "Tingyu Lin",
                "Weishan Zhao",
                "Li Zhu",
                "Shuiguang Deng",
                "Hari Sundaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08588v1",
                "http://arxiv.org/pdf/2311.08588v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08587v1",
            "title": "Quantum Group Intertwiner Space From Quantum Curved Tetrahedron",
            "updated": "2023-11-14T23:17:26Z",
            "published": "2023-11-14T23:17:26Z",
            "summary": "In this paper, we develop a quantum theory of homogeneously curved\ntetrahedron geometry, by applying the combinatorial quantization to the phase\nspace of tetrahedron shapes defined in arXiv:1506.03053. Our method is based on\nthe relation between this phase space and the moduli space of SU(2) flat\nconnections on a 4-punctured sphere. The quantization results in the physical\nHilbert space as the solution of the quantum closure constraint, which\nquantizes the classical closure condition $M_4M_3M_2M_1=1$, $M_\\nu\\in$ SU(2),\nfor the homogeneously curved tetrahedron. The quantum group Uq(su(2)) emerges\nas the gauge symmetry of a quantum tetrahedron. The physical Hilbert space of\nthe quantum tetrahedron coincides with the Hilbert space of 4-valent\nintertwiners of Uq(su(2)). In addition, we define the area operators quantizing\nthe face areas of the tetrahedron and compute the spectrum. The resulting\nspectrum is consistent with the usual Loop-Quantum-Gravity area spectrum in the\nlarge spin regime but is different for small spins. This work closely relates\nto 3+1 dimensional Loop Quantum Gravity in presence of cosmological constant\nand provides a justification for the emergence of quantum group in the theory.",
            "author": [
                "Muxin Han",
                "Chen-Hung Hsiao",
                "Qiaoyin Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08587v1",
                "http://arxiv.org/pdf/2311.08587v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th",
                "math-ph",
                "math.GT",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08585v1",
            "title": "Unsupervised segmentation of irradiation$\\unicode{x2010}$induced\n  order$\\unicode{x2010}$disorder phase transitions in electron microscopy",
            "updated": "2023-11-14T23:13:59Z",
            "published": "2023-11-14T23:13:59Z",
            "summary": "We present a method for the unsupervised segmentation of electron microscopy\nimages, which are powerful descriptors of materials and chemical systems.\nImages are oversegmented into overlapping chips, and similarity graphs are\ngenerated from embeddings extracted from a domain$\\unicode{x2010}$pretrained\nconvolutional neural network (CNN). The Louvain method for community detection\nis then applied to perform segmentation. The graph representation provides an\nintuitive way of presenting the relationship between chips and communities. We\ndemonstrate our method to track irradiation$\\unicode{x2010}$induced amorphous\nfronts in thin films used for catalysis and electronics. This method has\npotential for \"on$\\unicode{x2010}$the$\\unicode{x2010}$fly\" segmentation to\nguide emerging automated electron microscopes.",
            "author": [
                "Arman H Ter-Petrosyan",
                "Jenna A Bilbrey",
                "Christina M Doty",
                "Bethany E Matthews",
                "Le Wang",
                "Yingge Du",
                "Eric Lang",
                "Khalid Hattar",
                "Steven R Spurgeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08585v1",
                "http://arxiv.org/pdf/2311.08585v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08584v1",
            "title": "Asking More Informative Questions for Grounded Retrieval",
            "updated": "2023-11-14T23:13:27Z",
            "published": "2023-11-14T23:13:27Z",
            "summary": "When a model is trying to gather information in an interactive setting, it\nbenefits from asking informative questions. However, in the case of a grounded\nmulti-turn image identification task, previous studies have been constrained to\npolar yes/no questions, limiting how much information the model can gain in a\nsingle turn. We present an approach that formulates more informative,\nopen-ended questions. In doing so, we discover that off-the-shelf visual\nquestion answering (VQA) models often make presupposition errors, which\nstandard information gain question selection methods fail to account for. To\naddress this issue, we propose a method that can incorporate presupposition\nhandling into both question selection and belief updates. Specifically, we use\na two-stage process, where the model first filters out images which are\nirrelevant to a given question, then updates its beliefs about which image the\nuser intends. Through self-play and human evaluations, we show that our method\nis successful in asking informative open-ended questions, increasing accuracy\nover the past state-of-the-art by 14%, while resulting in 48% more efficient\ngames in human evaluations.",
            "author": [
                "Sedrick Keh",
                "Justin T. Chiu",
                "Daniel Fried"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08584v1",
                "http://arxiv.org/pdf/2311.08584v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09257v5",
            "title": "UFOGen: You Forward Once Large Scale Text-to-Image Generation via\n  Diffusion GANs",
            "updated": "2023-12-07T03:56:56Z",
            "published": "2023-11-14T23:07:50Z",
            "summary": "Text-to-image diffusion models have demonstrated remarkable capabilities in\ntransforming textual prompts into coherent images, yet the computational cost\nof their inference remains a persistent challenge. To address this issue, we\npresent UFOGen, a novel generative model designed for ultra-fast, one-step\ntext-to-image synthesis. In contrast to conventional approaches that focus on\nimproving samplers or employing distillation techniques for diffusion models,\nUFOGen adopts a hybrid methodology, integrating diffusion models with a GAN\nobjective. Leveraging a newly introduced diffusion-GAN objective and\ninitialization with pre-trained diffusion models, UFOGen excels in efficiently\ngenerating high-quality images conditioned on textual descriptions in a single\nstep. Beyond traditional text-to-image generation, UFOGen showcases versatility\nin applications. Notably, UFOGen stands among the pioneering models enabling\none-step text-to-image generation and diverse downstream tasks, presenting a\nsignificant advancement in the landscape of efficient generative models.",
            "author": [
                "Yanwu Xu",
                "Yang Zhao",
                "Zhisheng Xiao",
                "Tingbo Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09257v5",
                "http://arxiv.org/pdf/2311.09257v5"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08583v1",
            "title": "MOSAIC: A Multi-Objective Optimization Framework for Sustainable\n  Datacenter Management",
            "updated": "2023-11-14T23:05:37Z",
            "published": "2023-11-14T23:05:37Z",
            "summary": "In recent years, cloud service providers have been building and hosting\ndatacenters across multiple geographical locations to provide robust services.\nHowever, the geographical distribution of datacenters introduces growing\npressure to both local and global environments, particularly when it comes to\nwater usage and carbon emissions. Unfortunately, efforts to reduce the\nenvironmental impact of such datacenters often lead to an increase in the cost\nof datacenter operations. To co-optimize the energy cost, carbon emissions, and\nwater footprint of datacenter operation from a global perspective, we propose a\nnovel framework for multi-objective sustainable datacenter management (MOSAIC)\nthat integrates adaptive local search with a collaborative decomposition-based\nevolutionary algorithm to intelligently manage geographical workload\ndistribution and datacenter operations. Our framework sustainably allocates\nworkloads to datacenters while taking into account multiple geography- and\ntime-based factors including renewable energy sources, variable energy costs,\npower usage efficiency, carbon factors, and water intensity in energy. Our\nexperimental results show that, compared to the best-known prior work\nframeworks, MOSAIC can achieve 27.45x speedup and 1.53x improvement in Pareto\nHypervolume while reducing the carbon footprint by up to 1.33x, water footprint\nby up to 3.09x, and energy costs by up to 1.40x. In the simultaneous\nthree-objective co-optimization scenario, MOSAIC achieves a cumulative\nimprovement across all objectives (carbon, water, cost) of up to 4.61x compared\nto the state-of-the-arts.",
            "author": [
                "Sirui Qi",
                "Dejan Milojicic",
                "Cullen Bash",
                "Sudeep Pasricha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08583v1",
                "http://arxiv.org/pdf/2311.08583v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08581v1",
            "title": "Drivable 3D Gaussian Avatars",
            "updated": "2023-11-14T22:54:29Z",
            "published": "2023-11-14T22:54:29Z",
            "summary": "We present Drivable 3D Gaussian Avatars (D3GA), the first 3D controllable\nmodel for human bodies rendered with Gaussian splats. Current photorealistic\ndrivable avatars require either accurate 3D registrations during training,\ndense input images during testing, or both. The ones based on neural radiance\nfields also tend to be prohibitively slow for telepresence applications. This\nwork uses the recently presented 3D Gaussian Splatting (3DGS) technique to\nrender realistic humans at real-time framerates, using dense calibrated\nmulti-view videos as input. To deform those primitives, we depart from the\ncommonly used point deformation method of linear blend skinning (LBS) and use a\nclassic volumetric deformation method: cage deformations. Given their smaller\nsize, we drive these deformations with joint angles and keypoints, which are\nmore suitable for communication applications. Our experiments on nine subjects\nwith varied body shapes, clothes, and motions obtain higher-quality results\nthan state-of-the-art methods when using the same training and test data.",
            "author": [
                "Wojciech Zielonka",
                "Timur Bagautdinov",
                "Shunsuke Saito",
                "Michael Zollh\u00f6fer",
                "Justus Thies",
                "Javier Romero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08581v1",
                "http://arxiv.org/pdf/2311.08581v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08579v1",
            "title": "Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational\n  AutoEncoders",
            "updated": "2023-11-14T22:47:23Z",
            "published": "2023-11-14T22:47:23Z",
            "summary": "The injection of syntactic information in Variational AutoEncoders (VAEs) has\nbeen shown to result in an overall improvement of performances and\ngeneralisation. An effective strategy to achieve such a goal is to separate the\nencoding of distributional semantic features and syntactic structures into\nheterogeneous latent spaces via multi-task learning or dual encoder\narchitectures. However, existing works employing such techniques are limited to\nLSTM-based VAEs. In this paper, we investigate latent space separation methods\nfor structural syntactic injection in Transformer-based VAE architectures\n(i.e., Optimus). Specifically, we explore how syntactic structures can be\nleveraged in the encoding stage through the integration of graph-based and\nsequential models, and how multiple, specialised latent representations can be\ninjected into the decoder's attention mechanism via low-rank operators. Our\nempirical evaluation, carried out on natural language sentences and\nmathematical expressions, reveals that the proposed end-to-end VAE architecture\ncan result in a better overall organisation of the latent space, alleviating\nthe information loss occurring in standard VAE setups, resulting in enhanced\nperformances on language modelling and downstream generation tasks.",
            "author": [
                "Yingji Zhang",
                "Marco Valentino",
                "Danilo S. Carvalho",
                "Ian Pratt-Hartmann",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08579v1",
                "http://arxiv.org/pdf/2311.08579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08577v2",
            "title": "Finding AI-Generated Faces in the Wild",
            "updated": "2023-11-20T21:32:27Z",
            "published": "2023-11-14T22:46:01Z",
            "summary": "AI-based image generation has continued to rapidly improve, producing\nincreasingly more realistic images with fewer obvious visual flaws.\nAI-generated images are being used to create fake online profiles which in turn\nare being used for spam, fraud, and disinformation campaigns. As the general\nproblem of detecting any type of manipulated or synthesized content is\nreceiving increasing attention, here we focus on a more narrow task of\ndistinguishing a real face from an AI-generated face. This is particularly\napplicable when tackling inauthentic online accounts with a fake user profile\nphoto. We show that by focusing on only faces, a more resilient and\ngeneral-purpose artifact can be detected that allows for the detection of\nAI-generated faces from a variety of GAN- and diffusion-based synthesis\nengines, and across image resolutions (as low as 128 x 128 pixels) and\nqualities.",
            "author": [
                "Gonzalo J. Aniano Porcile",
                "Jack Gindi",
                "Shivansh Mundra",
                "James R. Verbus",
                "Hany Farid"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08577v2",
                "http://arxiv.org/pdf/2311.08577v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08576v1",
            "title": "Towards Evaluating AI Systems for Moral Status Using Self-Reports",
            "updated": "2023-11-14T22:45:44Z",
            "published": "2023-11-14T22:45:44Z",
            "summary": "As AI systems become more advanced and widely deployed, there will likely be\nincreasing debate over whether AI systems could have conscious experiences,\ndesires, or other states of potential moral significance. It is important to\ninform these discussions with empirical evidence to the extent possible. We\nargue that under the right circumstances, self-reports, or an AI system's\nstatements about its own internal states, could provide an avenue for\ninvestigating whether AI systems have states of moral significance.\nSelf-reports are the main way such states are assessed in humans (\"Are you in\npain?\"), but self-reports from current systems like large language models are\nspurious for many reasons (e.g. often just reflecting what humans would say).\nTo make self-reports more appropriate for this purpose, we propose to train\nmodels to answer many kinds of questions about themselves with known answers,\nwhile avoiding or limiting training incentives that bias self-reports. The hope\nof this approach is that models will develop introspection-like capabilities,\nand that these capabilities will generalize to questions about states of moral\nsignificance. We then propose methods for assessing the extent to which these\ntechniques have succeeded: evaluating self-report consistency across contexts\nand between similar models, measuring the confidence and resilience of models'\nself-reports, and using interpretability to corroborate self-reports. We also\ndiscuss challenges for our approach, from philosophical difficulties in\ninterpreting self-reports to technical reasons why our proposal might fail. We\nhope our discussion inspires philosophers and AI researchers to criticize and\nimprove our proposed methodology, as well as to run experiments to test whether\nself-reports can be made reliable enough to provide information about states of\nmoral significance.",
            "author": [
                "Ethan Perez",
                "Robert Long"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08576v1",
                "http://arxiv.org/pdf/2311.08576v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08575v1",
            "title": "Gaussian Approximation of Convex Sets by Intersections of Halfspaces",
            "updated": "2023-11-14T22:42:47Z",
            "published": "2023-11-14T22:42:47Z",
            "summary": "We study the approximability of general convex sets in $\\mathbb{R}^n$ by\nintersections of halfspaces, where the approximation quality is measured with\nrespect to the standard Gaussian distribution $N(0,I_n)$ and the complexity of\nan approximation is the number of halfspaces used. While a large body of\nresearch has considered the approximation of convex sets by intersections of\nhalfspaces under distance metrics such as the Lebesgue measure and Hausdorff\ndistance, prior to our work there has not been a systematic study of convex\napproximation under the Gaussian distribution.\n  We establish a range of upper and lower bounds, both for general convex sets\nand for specific natural convex sets that are of particular interest. Our\nresults demonstrate that the landscape of approximation is intriguingly\ndifferent under the Gaussian distribution versus previously studied distance\nmeasures. For example, we show that $2^{\\Theta(\\sqrt{n})}$ halfspaces are both\nnecessary and sufficient to approximate the origin-centered $\\ell_2$ ball of\nGaussian volume 1/2 to any constant accuracy, and that for $1 \\leq p < 2$, the\norigin-centered $\\ell_p$ ball of Gaussian volume 1/2 can be approximated to any\nconstant accuracy as an intersection of $2^{\\widetilde{O}(n^{3/4})}$ many\nhalfspaces. These bounds are quite different from known approximation results\nunder more commonly studied distance measures.\n  Our results are proved using techniques from many different areas. These\ninclude classical results on convex polyhedral approximation, Cram\\'er-type\nbounds on large deviations from probability theory, and -- perhaps surprisingly\n-- a range of topics from computational complexity, including computational\nlearning theory, unconditional pseudorandomness, and the study of influences\nand noise sensitivity in the analysis of Boolean functions.",
            "author": [
                "Anindya De",
                "Shivam Nadimpalli",
                "Rocco A. Servedio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08575v1",
                "http://arxiv.org/pdf/2311.08575v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DS",
                "math.MG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08572v1",
            "title": "Parameter-Efficient Multilingual Summarisation: An Empirical Study",
            "updated": "2023-11-14T22:32:39Z",
            "published": "2023-11-14T22:32:39Z",
            "summary": "With the increasing prevalence of Large Language Models, traditional full\nfine-tuning approaches face growing challenges, especially in memory-intensive\ntasks. This paper investigates the potential of Parameter-Efficient\nFine-Tuning, focusing on Low-Rank Adaptation (LoRA), for complex and\nunder-explored multilingual summarisation tasks. We conduct an extensive study\nacross different data availability scenarios, including full-data, low-data,\nand cross-lingual transfer, leveraging models of different sizes. Our findings\nreveal that LoRA lags behind full fine-tuning when trained with full data,\nhowever, it excels in low-data scenarios and cross-lingual transfer.\nInterestingly, as models scale up, the performance gap between LoRA and full\nfine-tuning diminishes. Additionally, we investigate effective strategies for\nfew-shot cross-lingual transfer, finding that continued LoRA tuning achieves\nthe best performance compared to both full fine-tuning and dynamic composition\nof language-specific LoRA modules.",
            "author": [
                "Chenxi Whitehouse",
                "Fantine Huot",
                "Jasmijn Bastings",
                "Mostafa Dehghani",
                "Chu-Cheng Lin",
                "Mirella Lapata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08572v1",
                "http://arxiv.org/pdf/2311.08572v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08566v1",
            "title": "COMET: A Cross-Layer Optimized Optical Phase Change Main Memory\n  Architecture",
            "updated": "2023-11-14T21:55:39Z",
            "published": "2023-11-14T21:55:39Z",
            "summary": "Traditional DRAM-based main memory systems face several challenges with\nmemory refresh overhead, high latency, and low throughput as the industry moves\ntowards smaller DRAM cells. These issues have been exacerbated by the emergence\nof data-intensive applications in recent years. Memories based on phase change\nmaterials (PCMs) offer promising solutions to these challenges. PCMs store data\nin the material's phase, which can shift between amorphous and crystalline\nstates when external thermal energy is supplied. This is often achieved using\nelectrical pulses. Alternatively, using laser pulses and integration with\nsilicon photonics offers a unique opportunity to realize high-bandwidth and\nlow-latency photonic memories. Such a memory system may in turn open the\npossibility of realizing fully photonic computing systems. But to realize\nphotonic memories, several challenges that are unique to the photonic domain\nsuch as crosstalk, optical loss management, and laser power overhead have to be\naddressed. In this work, we present COMET, the first cross-layer optimized\noptical main memory architecture that uses PCMs. In architecting COMET, we\nexplore how to use silicon photonics and PCMs together to design a large-scale\nmain memory system while addressing associated challenges. We explore\nchallenges and propose solutions at the PCM cell, photonic memory circuit, and\nmemory architecture levels. Based on our evaluations, COMET offers 7.1x better\nbandwidth, 15.1x lower EPB, and 3x lower latencies than the best-known prior\nwork on photonic main memory architecture design.",
            "author": [
                "Febin Sunny",
                "Amin Shafiee",
                "Benoit Charbonnier",
                "Mahdi Nikdast",
                "Sudeep Pasricha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08566v1",
                "http://arxiv.org/pdf/2311.08566v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08562v2",
            "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in\n  Cognition, Adaptability, Rationality and Collaboration",
            "updated": "2023-11-16T11:40:26Z",
            "published": "2023-11-14T21:46:27Z",
            "summary": "Large Language Models (LLMs) have marked a significant advancement in the\nfield of natural language processing, demonstrating exceptional capabilities in\nreasoning, tool usage, and memory. As their applications extend into\nmulti-agent environments, a need has arisen for a comprehensive evaluation\nframework that captures their abilities in reasoning, planning, collaboration,\nand more. This work introduces a novel benchmarking framework specifically\ntailored to assess LLMs within multi-agent settings, providing quantitative\nmetrics to evaluate their judgment, reasoning, deception, self-awareness,\ncooperation, coordination, and rationality. We utilize games such as Chameleon\nand Undercover, alongside game theory scenarios like Cost Sharing, Multi-player\nPrisoner's Dilemma, and Public Good, to create diverse testing environments.\nOur framework is fortified with the Probabilistic Graphical Modeling (PGM)\nmethod, enhancing the LLMs' capabilities in navigating complex social and\ncognitive dimensions. The benchmark evaluates seven multi-agent systems powered\nby different LLMs, quantitatively highlighting a significant capability gap\nover threefold between the strongest, GPT-4, and the weakest, Llama-2-70B. It\nalso confirms that our PGM enhancement boosts the inherent abilities of all\nselected models by 50% on average. Our codes are released here\nhttps://github.com/cathyxl/MAgIC.",
            "author": [
                "Lin Xu",
                "Zhiyuan Hu",
                "Daquan Zhou",
                "Hongyu Ren",
                "Zhen Dong",
                "Kurt Keutzer",
                "See Kiong Ng",
                "Jiashi Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08562v2",
                "http://arxiv.org/pdf/2311.08562v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08561v1",
            "title": "Measuring association with recursive rank binning",
            "updated": "2023-11-14T21:43:56Z",
            "published": "2023-11-14T21:43:56Z",
            "summary": "Pairwise measures of dependence are a common tool to map data in the early\nstages of analysis with several modern examples based on maximized partitions\nof the pairwise sample space. Following a short survey of modern measures of\ndependence, we introduce a new measure which recursively splits the ranks of a\npair of variables to partition the sample space and computes the $\\chi^2$\nstatistic on the resulting bins. Splitting logic is detailed for splits\nmaximizing a score function and randomly selected splits. Simulations indicate\nthat random splitting produces a statistic conservatively approximated by the\n$\\chi^2$ distribution without a loss of power to detect numerous different data\npatterns compared to maximized binning. Though it seems to add no power to\ndetect dependence, maximized recursive binning is shown to produce a natural\nvisualization of the data and the measure. Applying maximized recursive rank\nbinning to S&P 500 constituent data suggests the automatic detection of tail\ndependence.",
            "author": [
                "Chris Salahub",
                "Wayne Oldford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08561v1",
                "http://arxiv.org/pdf/2311.08561v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62G10",
                "G.3; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08557v1",
            "title": "Low-light Pedestrian Detection in Visible and Infrared Image Feeds:\n  Issues and Challenges",
            "updated": "2023-11-14T21:39:15Z",
            "published": "2023-11-14T21:39:15Z",
            "summary": "Pedestrian detection has become a cornerstone for several high-level tasks,\nincluding autonomous driving, intelligent transportation, and traffic\nsurveillance. There are several works focussed on pedestrian detection using\nvisible images, mainly in the daytime. However, this task is very intriguing\nwhen the environmental conditions change to poor lighting or nighttime.\nRecently, new ideas have been spurred to use alternative sources, such as Far\nInfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light\nconditions. This study comprehensively reviews recent developments in low-light\npedestrian detection approaches. It systematically categorizes and analyses\nvarious algorithms from region-based to non-region-based and graph-based\nlearning methodologies by highlighting their methodologies, implementation\nissues, and challenges. It also outlines the key benchmark datasets that can be\nused for research and development of advanced pedestrian detection algorithms,\nparticularly in low-light situations",
            "author": [
                "Hrishikesh Vachhani",
                "Thangarajah Akilan",
                "Yash Devmurari",
                "Nisharaff Shaik",
                "Dhruvisha Patel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08557v1",
                "http://arxiv.org/pdf/2311.08557v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08555v1",
            "title": "Efficient Quantum Modular Arithmetics for the ISQ Era",
            "updated": "2023-11-14T21:34:39Z",
            "published": "2023-11-14T21:34:39Z",
            "summary": "As we venture into the Intermediate-Scale Quantum (ISQ) era, the proficiency\nof modular arithmetic operations becomes pivotal for advancing quantum\ncryptographic algorithms. This study presents an array of quantum circuits,\neach precision-engineered for modular arithmetic functions critical to\ncryptographic applications. Central to our exposition are quantum modular\nadders, multipliers, and exponential operators, whose designs are rigorously\noptimized for ISQ devices. We provide a theoretical framework and practical\nimplementations in the PennyLane quantum software, bridging the gap between\nconceptual and applied quantum computing. Our simulations validate the efficacy\nof these methodologies, offering a strategic compass for developing quantum\nalgorithms that align with the rapid progression of quantum technology.",
            "author": [
                "Parfait Atchade-Adelomou",
                "Saul Gonzalez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08555v1",
                "http://arxiv.org/pdf/2311.08555v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09256v1",
            "title": "Reading Between the Mud: A Challenging Motorcycle Racer Number Dataset",
            "updated": "2023-11-14T21:31:47Z",
            "published": "2023-11-14T21:31:47Z",
            "summary": "This paper introduces the off-road motorcycle Racer number Dataset (RnD), a\nnew challenging dataset for optical character recognition (OCR) research. RnD\ncontains 2,411 images from professional motorsports photographers that depict\nmotorcycle racers in off-road competitions. The images exhibit a wide variety\nof factors that make OCR difficult, including mud occlusions, motion blur,\nnon-standard fonts, glare, complex backgrounds, etc. The dataset has 5,578\nmanually annotated bounding boxes around visible motorcycle numbers, along with\ntranscribed digits and letters. Our experiments benchmark leading OCR\nalgorithms and reveal an end-to-end F1 score of only 0.527 on RnD, even after\nfine-tuning. Analysis of performance on different occlusion types shows mud as\nthe primary challenge, degrading accuracy substantially compared to normal\nconditions. But the models struggle with other factors including glare, blur,\nshadows, and dust. Analysis exposes substantial room for improvement and\nhighlights failure cases of existing models. RnD represents a valuable new\nbenchmark to drive innovation in real-world OCR capabilities. The authors hope\nthe community will build upon this dataset and baseline experiments to make\nprogress on the open problem of robustly recognizing text in unconstrained\nnatural environments. The dataset is available at\nhttps://github.com/JacobTyo/SwinTextSpotter.",
            "author": [
                "Jacob Tyo",
                "Youngseog Chung",
                "Motolani Olarinre",
                "Zachary C. Lipton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09256v1",
                "http://arxiv.org/pdf/2311.09256v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08552v1",
            "title": "UT5: Pretraining Non autoregressive T5 with unrolled denoising",
            "updated": "2023-11-14T21:28:10Z",
            "published": "2023-11-14T21:28:10Z",
            "summary": "Recent advances in Transformer-based Large Language Models have made great\nstrides in natural language generation. However, to decode K tokens, an\nautoregressive model needs K sequential forward passes, which may be a\nperformance bottleneck for large language models. Many non-autoregressive (NAR)\nresearch are aiming to address this sequentiality bottleneck, albeit many have\nfocused on a dedicated architecture in supervised benchmarks. In this work, we\nstudied unsupervised pretraining for non auto-regressive T5 models via unrolled\ndenoising and shown its SoTA results in downstream generation tasks such as\nSQuAD question generation and XSum.",
            "author": [
                "Mahmoud G. Salem",
                "Jiayu Ye",
                "Chu-Cheng Lin",
                "Frederick Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08552v1",
                "http://arxiv.org/pdf/2311.08552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08548v1",
            "title": "Topology of Surface Electromyogram Signals: Hand Gesture Decoding on\n  Riemannian Manifolds",
            "updated": "2023-11-14T21:20:54Z",
            "published": "2023-11-14T21:20:54Z",
            "summary": "Decoding gestures from the upper limb using noninvasive surface\nelectromyogram (sEMG) signals is of keen interest for the rehabilitation of\namputees, artificial supernumerary limb augmentation, gestural control of\ncomputers, and virtual/augmented realities. We show that sEMG signals recorded\nacross an array of sensor electrodes in multiple spatial locations around the\nforearm evince a rich geometric pattern of global motor unit (MU) activity that\ncan be leveraged to distinguish different hand gestures. We demonstrate a\nsimple technique to analyze spatial patterns of muscle MU activity within a\ntemporal window and show that distinct gestures can be classified in both\nsupervised and unsupervised manners. Specifically, we construct symmetric\npositive definite (SPD) covariance matrices to represent the spatial\ndistribution of MU activity in a time window of interest, calculated as\npairwise covariance of electrical signals measured across different electrodes.\nThis allows us to understand and manipulate multivariate sEMG timeseries on a\nmore natural subspace -the Riemannian manifold. Furthermore, it directly\naddresses signal variability across individuals and sessions, which remains a\nmajor challenge in the field. sEMG signals measured at a single electrode lack\ncontextual information such as how various anatomical and physiological factors\ninfluence the signals and how their combined effect alters the evident\ninteraction among neighboring muscles. As we show here, analyzing spatial\npatterns using covariance matrices on Riemannian manifolds allows us to\nrobustly model complex interactions across spatially distributed MUs and\nprovides a flexible and transparent framework to quantify differences in sEMG\nsignals across individuals. The proposed method is novel in the study of sEMG\nsignals and its performance exceeds the current benchmarks while maintaining\nexceptional computational efficiency.",
            "author": [
                "Harshavardhana T. Gowda",
                "Lee M. Miller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08548v1",
                "http://arxiv.org/pdf/2311.08548v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV",
                "cs.HC",
                "q-bio.QM",
                "53",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08545v1",
            "title": "Efficient Continual Pre-training for Building Domain Specific Large\n  Language Models",
            "updated": "2023-11-14T21:19:14Z",
            "published": "2023-11-14T21:19:14Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable open-domain\ncapabilities. Traditionally, LLMs tailored for a domain are trained from\nscratch to excel at handling domain-specific tasks. In this work, we explore an\nalternative strategy of continual pre-training as a means to develop\ndomain-specific LLMs. We introduce FinPythia-6.9B, developed through\ndomain-adaptive continual pre-training on the financial domain. Continual\npre-trained FinPythia showcases consistent improvements on financial tasks over\nthe original foundational model. We further explore simple but effective data\nselection strategies for continual pre-training. Our data selection strategies\noutperforms vanilla continual pre-training's performance with just 10% of\ncorpus size and cost, without any degradation on open-domain standard tasks.\nOur work proposes an alternative solution to building domain-specific LLMs from\nscratch in a cost-effective manner.",
            "author": [
                "Yong Xie",
                "Karan Aggarwal",
                "Aitzaz Ahmad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08545v1",
                "http://arxiv.org/pdf/2311.08545v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08543v1",
            "title": "2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection",
            "updated": "2023-11-14T21:16:40Z",
            "published": "2023-11-14T21:16:40Z",
            "summary": "Orthogonal time frequency space (OTFS) is a promising modulation scheme for\nwireless communication in high-mobility scenarios. Recently, a reservoir\ncomputing (RC) based approach has been introduced for online subframe-based\nsymbol detection in the OTFS system, where only a limited number of\nover-the-air (OTA) pilot symbols are utilized for training. However, this\napproach does not leverage the domain knowledge specific to the OTFS system.\nThis paper introduces a novel two-dimensional RC (2D-RC) method that\nincorporates the structural knowledge of the OTFS system into the design for\nonline symbol detection on a subframe basis. Specifically, as the channel\nresponse acts as a two-dimensional (2D) operation over the transmitted\ninformation symbols in the delay-Doppler (DD) domain, the 2D-RC is designed to\nhave a 2D structure to equalize the channel. With the introduced architecture,\nthe 2D-RC can benefit from the predictable channel representation in the DD\ndomain. Moreover, unlike the previous work that requires multiple RCs to learn\nthe channel feature, the 2D-RC only requires a single neural network for\ndetection. Experimental results demonstrate the effectiveness of the 2D-RC\napproach across different OTFS system variants and modulation orders.",
            "author": [
                "Jiarui Xu",
                "Karim Said",
                "Lizhong Zheng",
                "Lingjia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08543v1",
                "http://arxiv.org/pdf/2311.08543v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08541v1",
            "title": "Three invariants of geometrically vertex decomposable ideals",
            "updated": "2023-11-14T21:14:46Z",
            "published": "2023-11-14T21:14:46Z",
            "summary": "We study three invariants of geometrically vertex decomposable ideals: the\nCastelnuovo-Mumford regularity, the multiplicity, and the $a$-invariant. We\nshow that these invariants can be computed recursively using the ideals that\nappear in the geometric vertex decomposition process. As an application, we\nprove that the $a$-invariant of a geometrically vertex decomposable ideal is\nnon-positive. We also recover some previously known results in the literature\nincluding a formula for the regularity of the Stanley--Reisner ideal of a pure\nvertex decomposable simplicial complex, and proofs that some well-known\nfamilies of ideals are Hilbertian. Finally, we apply our recursions to the\nstudy of toric ideals of bipartite graphs. Included among our results on this\ntopic is a new proof for a known bound on the $a$-invariant of a toric ideal of\na bipartite graph.",
            "author": [
                "Thai Thanh Nguyen",
                "Jenna Rajchgot",
                "Adam Van Tuyl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08541v1",
                "http://arxiv.org/pdf/2311.08541v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO",
                "13P10, 14M25, 05E40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08539v1",
            "title": "Physical Adversarial Examples for Multi-Camera Systems",
            "updated": "2023-11-14T21:04:49Z",
            "published": "2023-11-14T21:04:49Z",
            "summary": "Neural networks build the foundation of several intelligent systems, which,\nhowever, are known to be easily fooled by adversarial examples. Recent advances\nmade these attacks possible even in air-gapped scenarios, where the autonomous\nsystem observes its surroundings by, e.g., a camera. We extend these ideas in\nour research and evaluate the robustness of multi-camera setups against such\nphysical adversarial examples. This scenario becomes ever more important with\nthe rise in popularity of autonomous vehicles, which fuse the information of\nseveral cameras for their driving decision. While we find that multi-camera\nsetups provide some robustness towards past attack methods, we see that this\nadvantage reduces when optimizing on multiple perspectives at once. We propose\na novel attack method that we call Transcender-MC, where we incorporate online\n3D renderings and perspective projections in the training process. Moreover, we\nmotivate that certain data augmentation techniques can facilitate the\ngeneration of successful adversarial examples even further. Transcender-MC is\n11% more effective in successfully attacking multi-camera setups than\nstate-of-the-art methods. Our findings offer valuable insights regarding the\nresilience of object detection in a setup with multiple cameras and motivate\nthe need of developing adequate defense mechanisms against them.",
            "author": [
                "Ana R\u0103du\u0163oiu",
                "Jan-Philipp Schulze",
                "Philip Sperl",
                "Konstantin B\u00f6ttinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08539v1",
                "http://arxiv.org/pdf/2311.08539v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08538v1",
            "title": "Extending Multilingual Machine Translation through Imitation Learning",
            "updated": "2023-11-14T21:04:03Z",
            "published": "2023-11-14T21:04:03Z",
            "summary": "Despite the growing variety of languages supported by existing multilingual\nneural machine translation (MNMT) models, most of the world's languages are\nstill being left behind. We aim to extend large-scale MNMT models to a new\nlanguage, allowing for translation between the newly added and all of the\nalready supported languages in a challenging scenario: using only a parallel\ncorpus between the new language and English. Previous approaches, such as\ncontinued training on parallel data including the new language, suffer from\ncatastrophic forgetting (i.e., performance on other languages is reduced). Our\nnovel approach Imit-MNMT treats the task as an imitation learning process,\nwhich mimicks the behavior of an expert, a technique widely used in the\ncomputer vision area, but not well explored in NLP. More specifically, we\nconstruct a pseudo multi-parallel corpus of the new and the original languages\nby pivoting through English, and imitate the output distribution of the\noriginal MNMT model. Extensive experiments show that our approach significantly\nimproves the translation performance between the new and the original\nlanguages, without severe catastrophic forgetting. We also demonstrate that our\napproach is capable of solving copy and off-target problems, which are two\ncommon issues existence in current large-scale MNMT models.",
            "author": [
                "Wen Lai",
                "Viktor Hangya",
                "Alexander Fraser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08538v1",
                "http://arxiv.org/pdf/2311.08538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08537v2",
            "title": "The Curve Shortening Flow for Curves of Finite Total (Absolute)\n  Curvature",
            "updated": "2023-11-29T23:49:32Z",
            "published": "2023-11-14T21:02:48Z",
            "summary": "We revisit the well-known Curve Shortening Flow for immersed curves in the\n$d$-dimensional Euclidean space. We exploit a fundamental structure of the\nproblem to derive a new global construction of a solution, that is, a\nconstruction that is valid for all times and is insensitive to singularities.\nThe construction is characterized by discretization in time and the\napproximant, while still exhibiting the possibile formation of finitely many\nsingularities at a finite set of singular times, exists globally and is well\nbehaved and simpler to analyze than a solution of the CSF. A solution of the\nlatter is obtained in the limit. Estimates for a natural (geometric) norm\ninvolving length and total absolute curvature allow passage to the limit. Many\nclassical qualitative results about the flow can be recovered by exploiting the\nsimplicity of the approximant and new ones can be proved. The construction also\nsuggests a numerical procedure for the computation of the flow which proves\nvery effective as demonstrated by a series of numerical experiments scattered\nthroughout the paper.",
            "author": [
                "Patrick Guidotti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08537v2",
                "http://arxiv.org/pdf/2311.08537v2"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "cs.NA",
                "math.NA",
                "35K55, 35K61, 35K93, 53E10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08536v1",
            "title": "Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism",
            "updated": "2023-11-14T21:02:27Z",
            "published": "2023-11-14T21:02:27Z",
            "summary": "Non-intrusive Load Monitoring (NILM) is an established technique for\neffective and cost-efficient electricity consumption management. The method is\nused to estimate appliance-level power consumption from aggregated power\nmeasurements. This paper presents a hybrid learning approach, consisting of a\nconvolutional neural network (CNN) and a bidirectional long short-term memory\n(BILSTM), featuring an integrated attention mechanism, all within the context\nof disaggregating low-frequency power data. While prior research has been\nmainly focused on high-frequency data disaggregation, our study takes a\ndistinct direction by concentrating on low-frequency data. The proposed hybrid\nCNN-BILSTM model is adept at extracting both temporal (time-related) and\nspatial (location-related) features, allowing it to precisely identify energy\nconsumption patterns at the appliance level. This accuracy is further enhanced\nby the attention mechanism, which aids the model in pinpointing crucial parts\nof the data for more precise event detection and load disaggregation. We\nconduct simulations using the existing low-frequency REDD dataset to assess our\nmodel performance. The results demonstrate that our proposed approach\noutperforms existing methods in terms of accuracy and computation time.",
            "author": [
                "Amanie Azzam",
                "Saba Sanami",
                "Amir G. Aghdam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08536v1",
                "http://arxiv.org/pdf/2311.08536v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08533v1",
            "title": "Natural Language Processing for Financial Regulation",
            "updated": "2023-11-14T20:58:21Z",
            "published": "2023-11-14T20:58:21Z",
            "summary": "This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.",
            "author": [
                "Ixandra Achitouv",
                "Dragos Gorduza",
                "Antoine Jacquier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08533v1",
                "http://arxiv.org/pdf/2311.08533v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08532v1",
            "title": "Crowdsearch",
            "updated": "2023-11-14T20:57:22Z",
            "published": "2023-11-14T20:57:22Z",
            "summary": "A common economic process is crowdsearch, wherein a group of agents is\ninvited to search for a valuable physical or virtual object, e.g. creating and\npatenting an invention, solving an open scientific problem, or identifying\nvulnerabilities in software. We study a binary model of crowdsearch in which\nagents have different abilities to find the object. We characterize the types\nof equilibria and identify which type of crowd maximizes the likelihood of\nfinding the object. Sometimes, however, an unlimited crowd is not sufficient to\nguarantee that the object is found. It even can happen that inviting more\nagents lowers the probability of finding the object. We characterize the\noptimal prize and show that offering only one prize (winner-takes-all)\nmaximizes the probability of finding the object but is not necessarily optimal\nfor the crowdsearch designer.",
            "author": [
                "Hans Gersbach",
                "Akaki Mamageishvili",
                "Fikri Pitsuwan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08532v1",
                "http://arxiv.org/pdf/2311.08532v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08530v1",
            "title": "SceneScore: Learning a Cost Function for Object Arrangement",
            "updated": "2023-11-14T20:55:40Z",
            "published": "2023-11-14T20:55:40Z",
            "summary": "Arranging objects correctly is a key capability for robots which unlocks a\nwide range of useful tasks. A prerequisite for creating successful arrangements\nis the ability to evaluate the desirability of a given arrangement. Our method\n\"SceneScore\" learns a cost function for arrangements, such that desirable,\nhuman-like arrangements have a low cost. We learn the distribution of training\narrangements offline using an energy-based model, solely from example images\nwithout requiring environment interaction or human supervision. Our model is\nrepresented by a graph neural network which learns object-object relations,\nusing graphs constructed from images. Experiments demonstrate that the learned\ncost function can be used to predict poses for missing objects, generalise to\nnovel objects using semantic features, and can be composed with other cost\nfunctions to satisfy constraints at inference time.",
            "author": [
                "Ivan Kapelyukh",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08530v1",
                "http://arxiv.org/pdf/2311.08530v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08529v1",
            "title": "Visualizing thickness-dependent magnetic textures in few-layer\n  $\\text{Cr}_2\\text{Ge}_2\\text{Te}_6$",
            "updated": "2023-11-14T20:55:15Z",
            "published": "2023-11-14T20:55:15Z",
            "summary": "Magnetic ordering in two-dimensional (2D) materials has recently emerged as a\npromising platform for data storage, computing, and sensing. To advance these\ndevelopments, it is vital to gain a detailed understanding of how the magnetic\norder evolves on the nanometer-scale as a function of the number of atomic\nlayers and applied magnetic field. Here, we image few-layer\n$\\text{Cr}_2\\text{Ge}_2\\text{Te}_6$ using a combined scanning superconducting\nquantum interference device and atomic force microscopy probe. Maps of the\nmaterial's stray magnetic field as a function of applied magnetic field reveal\nits magnetization per layer as well as the thickness-dependent magnetic\ntexture. Using a micromagnetic model, we correlate measured stray-field\npatterns with the underlying magnetization configurations, including labyrinth\ndomains and skyrmionic bubbles. Comparison between real-space images and\nsimulations demonstrates that the layer dependence of the material's magnetic\ntexture is a result of the thickness-dependent balance between crystalline and\nshape anisotropy. These findings represent an important step towards 2D\nspintronic devices with engineered spin configurations and controlled\ndependence on external magnetic fields.",
            "author": [
                "Andriani Vervelaki",
                "Kousik Bagani",
                "Daniel Jetter",
                "Manh-Ha Doan",
                "Tuan K. Chau",
                "Boris Gross",
                "Dennis Christensen",
                "Peter B\u00f8ggild",
                "Martino Poggio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08529v1",
                "http://arxiv.org/pdf/2311.08529v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08526v1",
            "title": "GLiNER: Generalist Model for Named Entity Recognition using\n  Bidirectional Transformer",
            "updated": "2023-11-14T20:39:12Z",
            "published": "2023-11-14T20:39:12Z",
            "summary": "Named Entity Recognition (NER) is essential in various Natural Language\nProcessing (NLP) applications. Traditional NER models are effective but limited\nto a set of predefined entity types. In contrast, Large Language Models (LLMs)\ncan extract arbitrary entities through natural language instructions, offering\ngreater flexibility. However, their size and cost, particularly for those\naccessed via APIs like ChatGPT, make them impractical in resource-limited\nscenarios. In this paper, we introduce a compact NER model trained to identify\nany type of entity. Leveraging a bidirectional transformer encoder, our model,\nGLiNER, facilitates parallel entity extraction, an advantage over the slow\nsequential token generation of LLMs. Through comprehensive testing, GLiNER\ndemonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs\nin zero-shot evaluations on various NER benchmarks.",
            "author": [
                "Urchade Zaratiana",
                "Nadi Tomeh",
                "Pierre Holat",
                "Thierry Charnois"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08526v1",
                "http://arxiv.org/pdf/2311.08526v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08525v1",
            "title": "Efficient Rotation Invariance in Deep Neural Networks through Artificial\n  Mental Rotation",
            "updated": "2023-11-14T20:37:54Z",
            "published": "2023-11-14T20:37:54Z",
            "summary": "Humans and animals recognize objects irrespective of the beholder's point of\nview, which may drastically change their appearances. Artificial pattern\nrecognizers also strive to achieve this, e.g., through translational invariance\nin convolutional neural networks (CNNs). However, both CNNs and vision\ntransformers (ViTs) perform very poorly on rotated inputs. Here we present\nartificial mental rotation (AMR), a novel deep learning paradigm for dealing\nwith in-plane rotations inspired by the neuro-psychological concept of mental\nrotation. Our simple AMR implementation works with all common CNN and ViT\narchitectures. We test it on ImageNet, Stanford Cars, and Oxford Pet. With a\ntop-1 error (averaged across datasets and architectures) of $0.743$, AMR\noutperforms the current state of the art (rotational data augmentation, average\ntop-1 error of $0.626$) by $19\\%$. We also easily transfer a trained AMR module\nto a downstream task to improve the performance of a pre-trained semantic\nsegmentation model on rotated CoCo from $32.7$ to $55.2$ IoU.",
            "author": [
                "Lukas Tuggener",
                "Thilo Stadelmann",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08525v1",
                "http://arxiv.org/pdf/2311.08525v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08524v1",
            "title": "Cross-dataset domain adaptation for the classification COVID-19 using\n  chest computed tomography images",
            "updated": "2023-11-14T20:36:34Z",
            "published": "2023-11-14T20:36:34Z",
            "summary": "Detecting COVID-19 patients using Computed Tomography (CT) images of the\nlungs is an active area of research. Datasets of CT images from COVID-19\npatients are becoming available. Deep learning (DL) solutions and in particular\nConvolutional Neural Networks (CNN) have achieved impressive results for the\nclassification of COVID-19 CT images, but only when the training and testing\ntake place within the same dataset. Work on the cross-dataset problem is still\nlimited and the achieved results are low. Our work tackles the cross-dataset\nproblem through a Domain Adaptation (DA) technique with deep learning. Our\nproposed solution, COVID19-DANet, is based on pre-trained CNN backbone for\nfeature extraction. For this task, we select the pre-trained Efficientnet-B3\nCNN because it has achieved impressive classification accuracy in previous\nwork. The backbone CNN is followed by a prototypical layer which is a concept\nborrowed from prototypical networks in few-shot learning (FSL). It computes a\ncosine distance between given samples and the class prototypes and then\nconverts them to class probabilities using the Softmax function. To train the\nCOVID19-DANet model, we propose a combined loss function that is composed of\nthe standard cross-entropy loss for class discrimination and another entropy\nloss computed over the unlabelled target set only. This so-called unlabelled\ntarget entropy loss is minimized and maximized in an alternative fashion, to\nreach the two objectives of class discrimination and domain invariance.\nCOVID19-DANet is tested under four cross-dataset scenarios using the\nSARS-CoV-2-CT and COVID19-CT datasets and has achieved encouraging results\ncompared to recent work in the literature.",
            "author": [
                "Ridha Ouni",
                "Haikel Alhichri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08524v1",
                "http://arxiv.org/pdf/2311.08524v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08520v1",
            "title": "Numerical study of natural oscillations of supported drops with free and\n  pinned contact lines",
            "updated": "2023-11-14T20:27:44Z",
            "published": "2023-11-14T20:27:44Z",
            "summary": "In the present study, the axisymmetric natural oscillations of a liquid drop\nsupported by a flat surface is investigated by direct numerical simulation. The\nliquid-gas interface is captured using a geometric volume-of-fluid (VOF)\nmethod. A parametric study is carried out by varying the equilibrium contact\nangle and the gravitational Bond number (Bo). Both positive and negative\ngravities are considered, and thus the results cover both pendant and sessile\ndrops. To incorporate the effect of contact line mobility, the two asymptotic\nlimits, namely the pinned contact line (PCL) and free contact line (FCL)\nconditions, are considered and their effects on the drop oscillation features\nare characterized. The predicted oscillation frequencies for PCL and FCL serve\nas the upper and lower bounds for general situations. The drop oscillation is\ninitiated by increasing the gravity magnitude for a short time. The first mode\ndue to the drop centroid translation dominates the excited oscillation. The\noscillation frequency scales with the capillary frequency, and the normalized\nfrequency monotonically decreases with the equilibrium contact angle. For zero\ngravity, the computed frequencies for all contact angles agree remarkably well\nwith the inviscid theory for both the PCL and FCL conditions. The kinetic\nenergy correction factor is introduced to account for the additional\ncontribution of the oscillation-induced internal flow to the overall kinetic\nenergy of the drop. Both the frequency and the kinetic energy correction factor\nincrease with Bo, decrease with the contact angle, and increase when the\ncontact line condition changed from FCL to PCL. The variation of oscillation\nfrequency due to the change of Bo is particularly significant when the contact\nangle is large.",
            "author": [
                "Jordan Sakakeeny",
                "Yue Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08520v1",
                "http://arxiv.org/pdf/2311.08520v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08518v1",
            "title": "Light-Induced Microwave Noise in Superconducting Microwave-Optical\n  Transducers",
            "updated": "2023-11-14T20:25:34Z",
            "published": "2023-11-14T20:25:34Z",
            "summary": "Microwave-to-optical transducers are integral to the future of\nsuperconducting quantum computing, as they would enable scaling and\nlong-distance communication of superconducting quantum processors through\noptical fiber links. However, optically-induced microwave noise poses a\nsignificant challenge in achieving quantum transduction between microwave and\noptical frequencies. In this work, we study light-induced microwave noise in an\nintegrated electro-optical transducer harnessing Pockels effect of thin film\nlithium niobate. We reveal three sources of added noise with distinctive time\nconstants ranging from sub-100 nanoseconds to milliseconds. Our results gain\ninsights into the mechanisms and corresponding mitigation strategies for\nlight-induced microwave noise in superconducting microwave-optical transducers,\nand pave the way towards realizing the ultimate goal of quantum transduction.",
            "author": [
                "Mingrui Xu",
                "Chunzhen Li",
                "Yuntao Xu",
                "Hong X. Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08518v1",
                "http://arxiv.org/pdf/2311.08518v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08517v1",
            "title": "Impact of inlet gas turbulence on the formation, development and breakup\n  of interfacial waves in a two-phase mixing layer",
            "updated": "2023-11-14T20:17:18Z",
            "published": "2023-11-14T20:17:18Z",
            "summary": "Understanding the development and breakup of interfacial waves in a two-phase\nmixing layer between the gas and liquid streams is paramount to atomization.\nDue to the velocity difference between the two streams, the shear on the\ninterface triggers a longitudinal instability, which develops to interfacial\nwaves that propagate downstream. As the interfacial waves grow spatially,\ntransverse modulations arise, turning the interfacial waves from quasi-2D to\nfully 3D. The inlet gas turbulence intensity has a strong impact on the\ninterfacial instability. Therefore, parametric direct numerical simulations are\nperformed in the present study to systematically investigate the effect of the\ninlet gas turbulence on the formation, development, and breakup of the\ninterfacial waves. The open-source multiphase flow solver, PARIS, is used for\nthe simulations and the mass-momentum consistent volume-of-fluid method is used\nto capture the sharp gas-liquid interfaces. Two computational domain widths are\nconsidered and the wide domain will allow a detailed study of the transverse\ndevelopment of the interfacial waves. The dominant frequency and spatial growth\nrate of the longitudinal instability are found to increase with the inlet gas\nturbulence intensity. The dominant transverse wavenumber, determined by the\nRayleigh-Taylor instability, scales with the longitudinal frequency, so it also\nincreases with the inlet gas turbulence intensity. The holes formed in the\nliquid sheet is important to the disintegration of the interfacial waves. The\nholes formation is influenced by the inlet gas turbulence. As a result, the\nsheet breakup dynamics and the statistics of the droplets formed also change\naccordingly.",
            "author": [
                "Delin Jiang",
                "Yue Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08517v1",
                "http://arxiv.org/pdf/2311.08517v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08516v1",
            "title": "LLMs cannot find reasoning errors, but can correct them!",
            "updated": "2023-11-14T20:12:38Z",
            "published": "2023-11-14T20:12:38Z",
            "summary": "While self-correction has shown promise in improving LLM outputs in terms of\nstyle and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent\nattempts to self-correct logical or reasoning errors often cause correct\nanswers to become incorrect, resulting in worse performances overall (Huang et\nal., 2023). In this paper, we break down the self-correction process into two\ncore components: mistake finding and output correction. For mistake finding, we\nrelease BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought\nreasoning traces. We provide benchmark numbers for several state-of-the-art\nLLMs, and demonstrate that LLMs generally struggle with finding logical\nmistakes. For output correction, we propose a backtracking method which\nprovides large improvements when given information on mistake location. We\nconstrue backtracking as a lightweight alternative to reinforcement learning\nmethods, and show that it remains effective with a reward model at 60-70%\naccuracy.",
            "author": [
                "Gladys Tyen",
                "Hassan Mansoor",
                "Peter Chen",
                "Tony Mak",
                "Victor C\u0103rbune"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08516v1",
                "http://arxiv.org/pdf/2311.08516v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08514v1",
            "title": "An algorithm for Tambara-Yamagami quantum invariants of 3-manifolds,\n  parameterized by the first Betti number",
            "updated": "2023-11-14T20:09:58Z",
            "published": "2023-11-14T20:09:58Z",
            "summary": "Quantum topology provides various frameworks for defining and computing\ninvariants of manifolds. One such framework of substantial interest in both\nmathematics and physics is the Turaev-Viro-Barrett-Westbury state sum\nconstruction, which uses the data of a spherical fusion category to define\ntopological invariants of triangulated 3-manifolds via tensor network\ncontractions. In this work we consider a restricted class of state sum\ninvariants of 3-manifolds derived from Tambara-Yamagami categories. These\ncategories are particularly simple, being entirely specified by three pieces of\ndata: a finite abelian group, a bicharacter of that group, and a sign $\\pm 1$.\nDespite being one of the simplest sources of state sum invariants, the\ncomputational complexities of Tambara-Yamagami invariants are yet to be fully\nunderstood.\n  We make substantial progress on this problem. Our main result is the\nexistence of a general fixed parameter tractable algorithm for all such\ntopological invariants, where the parameter is the first Betti number of the\n3-manifold with $\\mathbb{Z}/2\\mathbb{Z}$ coefficients. We also explain that\nthese invariants are sometimes #P-hard to compute (and we expect that this is\nalmost always the case).\n  Contrary to other domains of computational topology, such as graphs on\nsurfaces, very few hard problems in 3-manifold topology are known to admit FPT\nalgorithms with a topological parameter. However, such algorithms are of\nparticular interest as their complexity depends only polynomially on the\ncombinatorial representation of the input, regardless of size or combinatorial\nwidth. Additionally, in the case of Betti numbers, the parameter itself is\neasily computable in polynomial time.",
            "author": [
                "Colleen Delaney",
                "Cl\u00e9ment Maria",
                "Eric Samperton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08514v1",
                "http://arxiv.org/pdf/2311.08514v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "math.GT",
                "math.QA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08511v1",
            "title": "CoRE-CoG: Conversational Recommendation of Entities using Constrained\n  Generation",
            "updated": "2023-11-14T20:07:34Z",
            "published": "2023-11-14T20:07:34Z",
            "summary": "End-to-end conversational recommendation systems (CRS) generate responses by\nleveraging both dialog history and a knowledge base (KB). A CRS mainly faces\nthree key challenges: (1) at each turn, it must decide if recommending a KB\nentity is appropriate; if so, it must identify the most relevant KB entity to\nrecommend; and finally, it must recommend the entity in a fluent utterance that\nis consistent with the conversation history. Recent CRSs do not pay sufficient\nattention to these desiderata, often generating unfluent responses or not\nrecommending (relevant) entities at the right turn. We introduce a new CRS we\ncall CoRE-CoG. CoRE-CoG addresses the limitations in prior systems by\nimplementing (1) a recommendation trigger that decides if the system utterance\nshould include an entity, (2) a type pruning module that improves the relevance\nof recommended entities, and (3) a novel constrained response generator to make\nrecommendations while maintaining fluency. Together, these modules ensure\nsimultaneous accurate recommendation decisions and fluent system utterances.\nExperiments with recent benchmarks show the superiority particularly on\nconditional generation sub-tasks with close to 10 F1 and 4 Recall@1 percent\npoints gain over baselines.",
            "author": [
                "Harshvardhan Srivastava",
                "Kanav Pruthi",
                "Soumen Chakrabarti",
                "Mausam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08511v1",
                "http://arxiv.org/pdf/2311.08511v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08510v1",
            "title": "Direct numerical simulation of compressible interfacial multiphase flows\n  using a mass-momentum-energy consistent volume-of-fluid method",
            "updated": "2023-11-14T20:06:29Z",
            "published": "2023-11-14T20:06:29Z",
            "summary": "Compressible interfacial multiphase flows (CIMF) are essential to different\napplications, such as liquid fuel injection in supersonic propulsion systems.\nSince high-level details in CIMF are often difficult to measure in experiments,\nnumerical simulation is an important alternative to shed light on the unclear\nphysics. A direct numerical simulation (DNS) of CIMF will need to rigorously\nresolve the shock waves, the interfaces, and the interaction between the two. A\nnovel numerical method has been developed and implemented in the present study.\nThe geometric volume-of-fluid (VOF) method is employed to resolve the sharp\ninterfaces between the two phases. The advection of the density, momentum, and\nenergy is carried out consistently with VOF advection. To suppress spurious\noscillations near shocks, numerical diffusion is introduced based on the\nKurganov-Tadmor method in the region away from the interface. The contribution\nof pressure is incorporated using the projection method and the pressure is\nobtained by solving the Poisson-Helmholtz equation, which allows the present\nmethod to handle flows with all Mach numbers. The present method is tested by a\nsequence of CIMF problems. The simulation results are validated against\ntheories, experiments, and other simulations, and excellent agreement has been\nachieved. In particular, the linear single-mode Richtmyer-Meshkov instabilities\nwith finite Weber and Reynolds numbers are simulated. The simulation results\nagree very well with the linear stability theory, which affirms the capability\nof the present method in capturing the viscous and capillary effects on\nshock-interface interaction.",
            "author": [
                "Bo Zhang",
                "Bradley Boyd",
                "Yue Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08510v1",
                "http://arxiv.org/pdf/2311.08510v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08509v1",
            "title": "Synthetic Neutrino Imaging of a Microquasar",
            "updated": "2023-11-14T20:05:45Z",
            "published": "2023-11-14T20:05:45Z",
            "summary": "Microquasar binary stellar systems emit electromagnetic radiation and\nhigh-energy particles over a broad energy spectrum. However, they are so far\naway that it is hard to observe their details. A simulation offers the link\nbetween relatively scarce observational data and the rich theoretical\nbackground. In this work, high-energy particle emission from simulated twin\nmicroquasar jets is calculated in a unified manner. From the cascade of\nemission within an element of jet matter to the dynamic and radiative whole jet\nmodel, the series of physical processes involved are integrated together. A\nprogramme suite assembled around model data produces synthetic images and\nspectra directly comparable to potential observations by contemporary arrays.\nThe model is capable of describing a multitude of system geometries,\nincorporating increasing levels of realism depending on need and available\ncomputational resources. As an application, the modelling process is applied to\na typical microquasar, which is synthetically observed from different angles\nusing various imaging geometries. Furthermore, the resulting intensities are\ncomparable to the sensitivity of existing detectors. The combined background\nemission from a potential distribution of microquasars is also modelled.",
            "author": [
                "Theodoros Smponias"
            ],
            "link": [
                "http://dx.doi.org/10.3390/galaxies9040080",
                "http://arxiv.org/abs/2311.08509v1",
                "http://arxiv.org/pdf/2311.08509v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08506v1",
            "title": "Electronic excitation spectra of molecular hydrogen in Phase I from\n  Quantum Monte Carlo and Many-Body perturbation methods",
            "updated": "2023-11-14T20:03:31Z",
            "published": "2023-11-14T20:03:31Z",
            "summary": "We study the electronic excitation spectra in solid molecular hydrogen (phase\nI) at ambient temperature and 5-90 GPa pressures using Quantum Monte Carlo\nmethods and Many-Body Perturbation Theory. In this range, the system changes\nfrom a wide gap molecular insulator to a semiconductor, altering the nature of\nthe excitations from localized to delocalized. Computed gaps and spectra agree\nwith experiments, proving the ability to predict accurately band gaps of\nmany-body systems in presence of nuclear quantum and thermal effects. We\nexplore changes in the electronic gap for the hydrogen isotopes.",
            "author": [
                "Vitaly Gorelov",
                "Markus Holzmann",
                "David M. Ceperley",
                "Carlo Pierleoni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08506v1",
                "http://arxiv.org/pdf/2311.08506v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00026v1",
            "title": "A Quality-of-Service Compliance System using Federated Learning and\n  Optimistic Rollups",
            "updated": "2023-11-14T20:02:37Z",
            "published": "2023-11-14T20:02:37Z",
            "summary": "Edge computing brings a new paradigm in which the sharing of computing,\nstorage, and bandwidth resources as close as possible to the mobile devices or\nsensors generating a large amount of data. A parallel trend is the rise of\nphones and tablets as primary computing devices for many people. The powerful\nsensors present on these devices combined with the fact that they are mobile,\nmean they have access to data of an unprecedentedly diverse and private nature.\nModels learned on such data hold the promise of greatly improving usability by\npowering more intelligent applications, but the sensitive nature of the data\nmeans there are risks and responsibilities to storing it in a centralized\nlocation. To address the data privacy required for some data in these devices\nwe propose the use of Federated Learning (FL) so that specific data about\nservices performed by clients do not leave the source machines. Instead of\nsharing data, users collaboratively train a model by only sending weight\nupdates to a server. However, the naive use of FL in those scenarios exposes it\nto a risk of corruption, whether intentional or not, during the training phase.\nTo improve the security of the FL structure, we propose a decentralized\nBlockchain-based FL in an edge computing scenario. We also apply blockchain to\ncreate a reward mechanism in FL to enable incentive strategy for trainers.",
            "author": [
                "Joao Paulo de Brito Goncalves",
                "Guilherme Emerick Sathler",
                "Rodolfo da Silva Villaca"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00026v1",
                "http://arxiv.org/pdf/2312.00026v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08505v1",
            "title": "Semi-Structured Chain-of-Thought: Integrating Multiple Sources of\n  Knowledge for Improved Language Model Reasoning",
            "updated": "2023-11-14T19:53:53Z",
            "published": "2023-11-14T19:53:53Z",
            "summary": "An important open question pertaining to the use of large language models for\nknowledge-intensive tasks is how to effectively integrate knowledge from three\nsources: the model's parametric memory, external structured knowledge, and\nexternal unstructured knowledge. Most existing prompting methods either rely\nsolely on one or two of these sources, or require repeatedly invoking large\nlanguage models to generate similar or identical content. In this work, we\novercome these limitations by introducing a novel semi-structured prompting\napproach that seamlessly integrates the model's parametric memory with\nunstructured knowledge from text documents and structured knowledge from\nknowledge graphs. Experimental results on open-domain multi-hop question\nanswering datasets demonstrate that our prompting method significantly\nsurpasses existing techniques, even exceeding those which require fine-tuning.",
            "author": [
                "Xin Su",
                "Tiep Le",
                "Steven Bethard",
                "Phillip Howard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08505v1",
                "http://arxiv.org/pdf/2311.08505v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08503v1",
            "title": "MADG: Margin-based Adversarial Learning for Domain Generalization",
            "updated": "2023-11-14T19:53:09Z",
            "published": "2023-11-14T19:53:09Z",
            "summary": "Domain Generalization (DG) techniques have emerged as a popular approach to\naddress the challenges of domain shift in Deep Learning (DL), with the goal of\ngeneralizing well to the target domain unseen during the training. In recent\nyears, numerous methods have been proposed to address the DG setting, among\nwhich one popular approach is the adversarial learning-based methodology. The\nmain idea behind adversarial DG methods is to learn domain-invariant features\nby minimizing a discrepancy metric. However, most adversarial DG methods use\n0-1 loss based $\\mathcal{H}\\Delta\\mathcal{H}$ divergence metric. In contrast,\nthe margin loss-based discrepancy metric has the following advantages: more\ninformative, tighter, practical, and efficiently optimizable. To mitigate this\ngap, this work proposes a novel adversarial learning DG algorithm, MADG,\nmotivated by a margin loss-based discrepancy metric. The proposed MADG model\nlearns domain-invariant features across all source domains and uses adversarial\ntraining to generalize well to the unseen target domain. We also provide a\ntheoretical analysis of the proposed MADG model based on the unseen target\nerror bound. Specifically, we construct the link between the source and unseen\ndomains in the real-valued hypothesis space and derive the generalization bound\nusing margin loss and Rademacher complexity. We extensively experiment with the\nMADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome,\nDomainNet, and TerraIncognita. We evaluate the proposed algorithm on\nDomainBed's benchmark and observe consistent performance across all the\ndatasets.",
            "author": [
                "Aveen Dayal",
                "Vimal K. B.",
                "Linga Reddy Cenkeramaddi",
                "C. Krishna Mohan",
                "Abhinav Kumar",
                "Vineeth N Balasubramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08503v1",
                "http://arxiv.org/pdf/2311.08503v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08496v1",
            "title": "Robust Differentiable Predictive Control with Safety Guarantees: A\n  Predictive Safety Filter Approach",
            "updated": "2023-11-14T19:42:00Z",
            "published": "2023-11-14T19:42:00Z",
            "summary": "In this paper, we propose a novel predictive safety filter that is robust to\nbounded perturbations and is combined with a learning-based control called\ndifferentiable predictive control (DPC). The proposed method provides rigorous\nguarantees of safety in the presence of bounded perturbations and implements\nDPC so long as the DPC control satisfies the system constraints. The approach\nalso incorporates two forms of event-triggering to reduce online computation.\nThe approach is comprised of a robust predictive safety filter that extends\nupon existing work to reject disturbances for discrete-time, time-varying\nnonlinear systems with time-varying constraints. The safety filter is based on\nnovel concepts of robust, discrete-time barrier functions and can be used to\nfilter any control law. Here we use the safety filter in conjunction with DPC\nas a promising policy optimization method. The approach is demonstrated on a\nsingle-integrator, two-tank system, and building example.",
            "author": [
                "Wenceslao Shaw Cortez",
                "Jan Drgona",
                "Draguna Vrabie",
                "Mahantesh Halappanavar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08496v1",
                "http://arxiv.org/pdf/2311.08496v1"
            ],
            "primary_category": "cs.SY",
            "category": [
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08494v1",
            "title": "A New Paradigm in Blockchain-based Financial Aid Distribution",
            "updated": "2023-11-14T19:41:24Z",
            "published": "2023-11-14T19:41:24Z",
            "summary": "Blockchain technology has emerged as a game-changer in a variety of\nindustries, providing robust solutions that can supplant conventional\nprocedures. The unique potential of this technology originates from its\ndecentralized ledger systems, which enable enhanced security, transparency, and\nthe validation of transactions without the need for intermediaries. Notably,\nthe financial sector is making substantial progress toward implementing\nblockchain solutions for a variety of operations, including remittances,\nlending, and investments. The healthcare industry is simultaneously\nincorporating this technology into systems for managing medical records,\ntracing supply chains, and data management. Similarly, the capacity of\nblockchain to enhance transparency, traceability, and accountability is widely\nacknowledged in supply chain management, from the procurement of basic\nmaterials to the delivery of finished goods. Diverse industries, including real\nestate, energy, and government, are actively investigating the potential of\nblockchain to improve efficiency, security, and transparency. Notably,\nHyperledger Besu, an open-source blockchain platform, is used to implement\nsmart contracts that automate processes and reduce manual intervention along\ndistribution pathways. This exhaustive review examines the transformative\npotential of blockchain technology across a variety of industries, discussing\nthe obstacles encountered and providing key insights into future research and\ndevelopment directions. This paper seeks to serve as a pivotal resource for\nacademics, industry stakeholders, and policymakers by synthesizing existing\nscholarly literature and shedding light on significant findings.",
            "author": [
                "Md. Raisul Hasan Shahrukh",
                "Md. Tabassinur Rahman",
                "Nafees Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08494v1",
                "http://arxiv.org/pdf/2311.08494v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CE",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08493v1",
            "title": "Performance of Machine Learning Classification in Mammography Images\n  using BI-RADS",
            "updated": "2023-11-14T19:41:19Z",
            "published": "2023-11-14T19:41:19Z",
            "summary": "This research aims to investigate the classification accuracy of various\nstate-of-the-art image classification models across different categories of\nbreast ultrasound images, as defined by the Breast Imaging Reporting and Data\nSystem (BI-RADS). To achieve this, we have utilized a comprehensively assembled\ndataset of 2,945 mammographic images sourced from 1,540 patients. In order to\nconduct a thorough analysis, we employed six advanced classification\narchitectures, including VGG19 \\cite{simonyan2014very}, ResNet50\n\\cite{he2016deep}, GoogleNet \\cite{szegedy2015going}, ConvNext\n\\cite{liu2022convnet}, EfficientNet \\cite{tan2019efficientnet}, and Vision\nTransformers (ViT) \\cite{dosovitskiy2020image}, instead of traditional machine\nlearning models. We evaluate models in three different settings: full\nfine-tuning, linear evaluation and training from scratch. Our findings\ndemonstrate the effectiveness and capability of our Computer-Aided Diagnosis\n(CAD) system, with a remarkable accuracy of 76.39\\% and an F1 score of 67.94\\%\nin the full fine-tuning setting. Our findings indicate the potential for\nenhanced diagnostic accuracy in the field of breast imaging, providing a solid\nfoundation for future endeavors aiming to improve the precision and reliability\nof CAD systems in medical imaging.",
            "author": [
                "Malitha Gunawardhana",
                "Norbert Zolek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08493v1",
                "http://arxiv.org/pdf/2311.08493v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08488v1",
            "title": "MUDD: A New Re-Identification Dataset with Efficient Annotation for\n  Off-Road Racers in Extreme Conditions",
            "updated": "2023-11-14T19:31:19Z",
            "published": "2023-11-14T19:31:19Z",
            "summary": "Re-identifying individuals in unconstrained environments remains an open\nchallenge in computer vision. We introduce the Muddy Racer re-IDentification\nDataset (MUDD), the first large-scale benchmark for matching identities of\nmotorcycle racers during off-road competitions. MUDD exhibits heavy mud\nocclusion, motion blurring, complex poses, and extreme lighting conditions\npreviously unseen in existing re-id datasets. We present an annotation\nmethodology incorporating auxiliary information that reduced labeling time by\nover 65%. We establish benchmark performance using state-of-the-art re-id\nmodels including OSNet and ResNet-50. Without fine-tuning, the best models\nachieve only 33% Rank-1 accuracy. Fine-tuning on MUDD boosts results to 79%\nRank-1, but significant room for improvement remains. We analyze the impact of\nreal-world factors including mud, pose, lighting, and more. Our work exposes\nopen problems in re-identifying individuals under extreme conditions. We hope\nMUDD serves as a diverse and challenging benchmark to spur progress in robust\nre-id, especially for computer vision applications in emerging sports\nanalytics. All code and data can be found at https://github.com/JacobTyo/MUDD.",
            "author": [
                "Jacob Tyo",
                "Motolani Olarinre",
                "Youngseog Chung",
                "Zachary C. Lipton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08488v1",
                "http://arxiv.org/pdf/2311.08488v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08487v1",
            "title": "Alignment is not sufficient to prevent large language models from\n  generating harmful information: A psychoanalytic perspective",
            "updated": "2023-11-14T19:28:51Z",
            "published": "2023-11-14T19:28:51Z",
            "summary": "Large Language Models (LLMs) are central to a multitude of applications but\nstruggle with significant risks, notably in generating harmful content and\nbiases. Drawing an analogy to the human psyche's conflict between evolutionary\nsurvival instincts and societal norm adherence elucidated in Freud's\npsychoanalysis theory, we argue that LLMs suffer a similar fundamental\nconflict, arising between their inherent desire for syntactic and semantic\ncontinuity, established during the pre-training phase, and the post-training\nalignment with human values. This conflict renders LLMs vulnerable to\nadversarial attacks, wherein intensifying the models' desire for continuity can\ncircumvent alignment efforts, resulting in the generation of harmful\ninformation. Through a series of experiments, we first validated the existence\nof the desire for continuity in LLMs, and further devised a straightforward yet\npowerful technique, such as incomplete sentences, negative priming, and\ncognitive dissonance scenarios, to demonstrate that even advanced LLMs struggle\nto prevent the generation of harmful information. In summary, our study\nuncovers the root of LLMs' vulnerabilities to adversarial attacks, hereby\nquestioning the efficacy of solely relying on sophisticated alignment methods,\nand further advocates for a new training idea that integrates modal concepts\nalongside traditional amodal concepts, aiming to endow LLMs with a more nuanced\nunderstanding of real-world contexts and ethical considerations.",
            "author": [
                "Zi Yin",
                "Wei Ding",
                "Jia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08487v1",
                "http://arxiv.org/pdf/2311.08487v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08483v1",
            "title": "Exploration of Hyperledger Besu in Designing Private Blockchain-based\n  Financial Distribution Systems",
            "updated": "2023-11-14T19:18:16Z",
            "published": "2023-11-14T19:18:16Z",
            "summary": "Blockchain, a decentralized technology that provides unrivaled security,\ntransparency, and process validation, is redefining the operational landscape\nacross numerous industries. This article focuses on the development of an\ninnovative consortium blockchain based financial distribution application. This\npaper illuminates the transformative role of blockchain technology in a variety\nof sectors by drawing on a plethora of academic literature and current industry\npractices. It demonstrates the diverse applications of blockchain, ranging from\nremittances to lending and investments in finance to data administration in\nhealthcare and supply chain tracking. The paper reveals the design and\npotential of a consortium blockchain based application for financial\ndistribution. Utilizing the capabilities of Hyperledger Besu, the application\nis tailored to improve security, scalability, and interoperability, thereby\ncontributing to a more integrated financial ecosystem. The investigation sheds\nlight on the combination of consortium blockchain controlled access and\nHyprledger Besu comprehensive functionality, proposing a secure, transparent,\nand efficient financial transaction environment. The investigation serves as a\nresource for academics, industry professionals, and policymakers alike,\nhighlighting the vast potential of blockchain technology, enabled by platforms\nsuch as Hyperledger Besu, in accelerating the evolution of traditional systems\ntoward a more decentralized, secure, and efficient future.",
            "author": [
                "Md. Raisul Hasan Shahrukh",
                "Md. Tabassinur Rahman",
                "Nafees Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08483v1",
                "http://arxiv.org/pdf/2311.08483v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CE",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08481v1",
            "title": "Functionality learning through specification instructions",
            "updated": "2023-11-14T19:15:55Z",
            "published": "2023-11-14T19:15:55Z",
            "summary": "Test suites assess natural language processing models' performance on\nspecific functionalities: cases of interest involving model robustness,\nfairness, or particular linguistic capabilities. They enable fine-grained\nevaluations of model aspects that would otherwise go unnoticed in standard\nevaluation datasets, but they do not address the problem of how to fix the\nfailure cases. Previous work has explored functionality learning by fine-tuning\nmodels on suite data. While this improves performance on seen functionalities,\nit often does not generalize to unseen ones and can harm general performance.\n  This paper analyses a fine-tuning-free approach to functionality learning.\nFor each functionality in a suite, we generate a specification instruction that\nencodes it. We combine the obtained specification instructions to create\nspecification-augmented prompts, which we feed to language models pre-trained\non natural instruction data to generate suite predictions. A core aspect of our\nanalysis is to measure the effect that including a set of specifications has on\na held-out set of unseen, qualitatively different specifications. Our\nexperiments across four tasks and models ranging from 80M to 175B parameters\nshow that smaller models struggle to follow specification instructions.\nHowever, larger models (> 3B params.) can benefit from specifications and even\ngeneralize desirable behaviors across functionalities.",
            "author": [
                "Pedro Henrique Luz de Araujo",
                "Benjamin Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08481v1",
                "http://arxiv.org/pdf/2311.08481v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08479v1",
            "title": "Leveraging Foundation Models to Improve Lightweight Clients in Federated\n  Learning",
            "updated": "2023-11-14T19:10:56Z",
            "published": "2023-11-14T19:10:56Z",
            "summary": "Federated Learning (FL) is a distributed training paradigm that enables\nclients scattered across the world to cooperatively learn a global model\nwithout divulging confidential data. However, FL faces a significant challenge\nin the form of heterogeneous data distributions among clients, which leads to a\nreduction in performance and robustness. A recent approach to mitigating the\nimpact of heterogeneous data distributions is through the use of foundation\nmodels, which offer better performance at the cost of larger computational\noverheads and slower inference speeds. We introduce foundation model\ndistillation to assist in the federated training of lightweight client models\nand increase their performance under heterogeneous data settings while keeping\ninference costs low. Our results show improvement in the global model\nperformance on a balanced testing set, which contains rarely observed samples,\neven under extreme non-IID client data distributions. We conduct a thorough\nevaluation of our framework with different foundation model backbones on\nCIFAR10, with varying degrees of heterogeneous data distributions ranging from\nclass-specific data partitions across clients to dirichlet data sampling,\nparameterized by values between 0.01 and 1.0.",
            "author": [
                "Xidong Wu",
                "Wan-Yi Lin",
                "Devin Willmott",
                "Filipe Condessa",
                "Yufei Huang",
                "Zhenzhen Li",
                "Madan Ravi Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08479v1",
                "http://arxiv.org/pdf/2311.08479v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08478v1",
            "title": "Reduction of large-scale RLCk models via low-rank balanced truncation",
            "updated": "2023-11-14T19:10:51Z",
            "published": "2023-11-14T19:10:51Z",
            "summary": "Model order reduction (MOR) is an important step in the design process of\nintegrated circuits. Specifically, the electromagnetic models extracted from\nmodern complex designs result in a large number of passive elements that\nintroduce limitations in the simulation process. MOR techniques based on\nbalanced truncation (BT) can overcome these limitations by producing compact\nreduced-order models (ROMs) that approximate the behavior of the original\nmodels at the input/output ports. In this paper, we present a low-rank BT\nmethod that exploits the extended Krylov subspace and efficient implementation\ntechniques for the reduction of large-scale models. Experimental evaluation on\na diverse set of analog and mixed-signal circuits with millions of elements\nindicates that up to x5.5 smaller ROMs can be produced with similar accuracy to\nANSYS RaptorX ROMs.",
            "author": [
                "Christos Giamouzis",
                "Dimitrios Garyfallou",
                "Anastasis Vagenas",
                "Nestor Evmorfopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08478v1",
                "http://arxiv.org/pdf/2311.08478v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.AR",
                "cs.CE",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08477v2",
            "title": "Hodge to de Rham degeneration of nodal cubic curve",
            "updated": "2023-11-16T15:33:43Z",
            "published": "2023-11-14T19:09:17Z",
            "summary": "We compute the Hochschild and negative cyclic homology of the nodal cubic\ncurve, and we show that the (noncommutative) Hodge to de Rham spectral sequence\ndegenerates at the second page. We also classify all the Hochschild classes\nthat can be lifted to negative cyclic homology, which is important for\ncomputation of categorical enumerative invariants.",
            "author": [
                "Yunfan He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08477v2",
                "http://arxiv.org/pdf/2311.08477v2"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "14F43,"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08473v1",
            "title": "Real-time topology optimization via learnable mappings",
            "updated": "2023-11-14T19:04:16Z",
            "published": "2023-11-14T19:04:16Z",
            "summary": "In traditional topology optimization, the computing time required to\niteratively update the material distribution within a design domain strongly\ndepends on the complexity or size of the problem, limiting its application in\nreal engineering contexts. This work proposes a multi-stage machine learning\nstrategy that aims to predict an optimal topology and the related stress fields\nof interest, either in 2D or 3D, without resorting to any iterative analysis\nand design process. The overall topology optimization is treated as regression\ntask in a low-dimensional latent space, that encodes the variability of the\ntarget designs. First, a fully-connected model is employed to surrogate the\nfunctional link between the parametric input space characterizing the design\nproblem and the latent space representation of the corresponding optimal\ntopology. The decoder branch of an autoencoder is then exploited to reconstruct\nthe desired optimal topology from its latent representation. The deep learning\nmodels are trained on a dataset generated through a standard method of topology\noptimization implementing the solid isotropic material with penalization, for\nvarying boundary and loading conditions. The underlying hypothesis behind the\nproposed strategy is that optimal topologies share enough common patterns to be\ncompressed into small latent space representations without significant\ninformation loss. Results relevant to a 2D Messerschmitt-B\\\"olkow-Blohm beam\nand a 3D bridge case demonstrate the capabilities of the proposed framework to\nprovide accurate optimal topology predictions in a fraction of a second.",
            "author": [
                "Gabriel Garayalde",
                "Matteo Torzoni",
                "Matteo Bruggi",
                "Alberto Corigliano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08473v1",
                "http://arxiv.org/pdf/2311.08473v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08472v1",
            "title": "Selecting Shots for Demographic Fairness in Few-Shot Learning with Large\n  Language Models",
            "updated": "2023-11-14T19:02:03Z",
            "published": "2023-11-14T19:02:03Z",
            "summary": "Recently, work in NLP has shifted to few-shot (in-context) learning, with\nlarge language models (LLMs) performing well across a range of tasks. However,\nwhile fairness evaluations have become a standard for supervised methods,\nlittle is known about the fairness of LLMs as prediction systems. Further,\ncommon standard methods for fairness involve access to models weights or are\napplied during finetuning, which are not applicable in few-shot learning. Do\nLLMs exhibit prediction biases when used for standard NLP tasks? In this work,\nwe explore the effect of shots, which directly affect the performance of\nmodels, on the fairness of LLMs as NLP classification systems. We consider how\ndifferent shot selection strategies, both existing and new demographically\nsensitive methods, affect model fairness across three standard fairness\ndatasets. We discuss how future work can include LLM fairness evaluations.",
            "author": [
                "Carlos Aguirre",
                "Kuleen Sasse",
                "Isabel Cachola",
                "Mark Dredze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08472v1",
                "http://arxiv.org/pdf/2311.08472v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08469v1",
            "title": "UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations",
            "updated": "2023-11-14T19:00:55Z",
            "published": "2023-11-14T19:00:55Z",
            "summary": "Language technologies that accurately model the dynamics of events must\nperform commonsense reasoning. Existing work evaluating commonsense reasoning\nfocuses on making inferences about common, everyday situations. To instead\ninvestigate the ability to model unusual, unexpected, and unlikely situations,\nwe explore the task of uncommonsense abductive reasoning. Given a piece of\ncontext with an unexpected outcome, this task requires reasoning abductively to\ngenerate a natural language explanation that makes the unexpected outcome more\nlikely in the context. To this end, we curate and release a new English\nlanguage corpus called UNcommonsense. We characterize the differences between\nthe performance of human explainers and the best performing large language\nmodels, finding that model-enhanced human-written explanations achieve the\nhighest quality by trading off between specificity and diversity. Finally, we\nexperiment with several online imitation learning algorithms to train open and\naccessible language models on this task. When compared with the vanilla\nsupervised fine-tuning approach, these methods consistently reduce lose rates\non both common and uncommonsense abductive reasoning judged by human\nevaluators.",
            "author": [
                "Wenting Zhao",
                "Justin T Chiu",
                "Jena D. Hwang",
                "Faeze Brahman",
                "Jack Hessel",
                "Sanjiban Choudhury",
                "Yejin Choi",
                "Xiang Lorraine Li",
                "Alane Suhr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08469v1",
                "http://arxiv.org/pdf/2311.08469v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08462v1",
            "title": "The ALE Partition Functions of M-String Orbifolds",
            "updated": "2023-11-14T19:00:05Z",
            "published": "2023-11-14T19:00:05Z",
            "summary": "The ALE partition functions of a 6d (1,0) SCFT are interesting observables\nwhich are able to detect the global structure of the SCFT. They are defined to\nbe the equivariant partition functions of the SCFT on a background with the\ntopology of a two-dimensional torus times an ALE singularity. In this work, we\ncompute the ALE partition functions of M-string orbifold SCFTs, extending our\nprevious results for the M-string SCFTs. Via geometric engineering, our results\nabout ALE partition functions are connected to the theory of higher-rank\nDonaldson-Thomas invariants for resolutions of elliptic Calabi-Yau threefold\nsingularities. We predict that their generating functions satisfy interesting\nmodular properties. The partition functions receive contributions from BPS\nstrings probing the ALE singularity, whose worldsheet theories we determine via\na chain of string dualities. For this class of backgrounds the BPS strings'\nworldsheet theories become relative field theories that are sensitive to\ndiscrete data generalizing to 6d the familiar choices of flat connections at\ninfinity for instantons on ALE spaces. A novel feature we observe in the case\nof M-string orbifold SCFTs, which does not arise for the M-string SCFT, is the\nexistence of frozen BPS strings which are pinned at the orbifold singularity\nand carry fractional instanton charge with respect to the 6d gauge fields.",
            "author": [
                "Michele Del Zotto",
                "Guglielmo Lockhart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08462v1",
                "http://arxiv.org/pdf/2311.08462v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08463v1",
            "title": "Magic in generalized Rokhsar-Kivelson wavefunctions",
            "updated": "2023-11-14T19:00:05Z",
            "published": "2023-11-14T19:00:05Z",
            "summary": "Magic is a property of a quantum state that characterizes its deviation from\na stabilizer state, serving as a useful resource for achieving universal\nquantum computation e.g., within schemes that use Clifford operations. In this\nwork, we study magic, as quantified by the stabilizer Renyi entropy, in a class\nof models known as generalized Rokhsar-Kivelson systems, i.e., Hamiltonians\nthat allow a stochastic matrix form (SMF) decomposition. The ground state\nwavefunctions of these systems can be written explicitly throughout their phase\ndiagram, and their properties can be related to associated classical\nstatistical mechanics problems, thereby allowing powerful analytical and\nnumerical approaches that are not usually available in conventional quantum\nmany body settings. As a result, we are able to express the SRE in terms of\nwave function coefficients that can be understood as a free energy difference\nof related classical problems. We apply this insight to a range of quantum many\nbody SMF Hamiltonians, which affords us to study numerically the SRE of large\nhigh-dimensional systems, and in some cases to obtain analytical results. We\nobserve that the behaviour of the SRE is relatively featureless across quantum\nphase transitions in these systems, although it is indeed singular (in its\nfirst or higher order derivative, depending on the nature of the transition).\nOn the contrary, we find that the maximum of the SRE generically occurs at a\ncusp away from the quantum critical point, where the derivative suddenly\nchanges sign. Furthermore, we compare the SRE and the logarithm of overlaps\nwith specific stabilizer states, asymptotically realised in the ground state\nphase diagrams of these systems. We find that they display strikingly similar\nbehaviors, which in turn establish rigorous bounds on the min-relative entropy\nof magic.",
            "author": [
                "Poetri Sonya Tarabunga",
                "Claudio Castelnovo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08463v1",
                "http://arxiv.org/pdf/2311.08463v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08460v1",
            "title": "Surrogate Modeling for Computationally Expensive Simulations of\n  Supernovae in High-Resolution Galaxy Simulations",
            "updated": "2023-11-14T19:00:03Z",
            "published": "2023-11-14T19:00:03Z",
            "summary": "Some stars are known to explode at the end of their lives, called supernovae\n(SNe). The substantial amount of matter and energy that SNe release provides\nsignificant feedback to star formation and gas dynamics in a galaxy. SNe\nrelease a substantial amount of matter and energy to the interstellar medium,\nresulting in significant feedback to star formation and gas dynamics in a\ngalaxy. While such feedback has a crucial role in galaxy formation and\nevolution, in simulations of galaxy formation, it has only been implemented\nusing simple {\\it sub-grid models} instead of numerically solving the evolution\nof gas elements around SNe in detail due to a lack of resolution. We develop a\nmethod combining machine learning and Gibbs sampling to predict how a supernova\n(SN) affects the surrounding gas. The fidelity of our model in the thermal\nenergy and momentum distribution outperforms the low-resolution SN simulations.\nOur method can replace the SN sub-grid models and help properly simulate\nun-resolved SN feedback in galaxy formation simulations. We find that employing\nour new approach reduces the necessary computational cost to $\\sim$ 1 percent\ncompared to directly resolving SN feedback.",
            "author": [
                "Keiya Hirashima",
                "Kana Moriwaki",
                "Michiko S. Fujii",
                "Yutaka Hirai",
                "Takayuki R. Saitoh",
                "Junichiro Makino",
                "Shirley Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08460v1",
                "http://arxiv.org/pdf/2311.08460v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08403v1",
            "title": "Instant3D: Instant Text-to-3D Generation",
            "updated": "2023-11-14T18:59:59Z",
            "published": "2023-11-14T18:59:59Z",
            "summary": "Text-to-3D generation, which aims to synthesize vivid 3D objects from text\nprompts, has attracted much attention from the computer vision community. While\nseveral existing works have achieved impressive results for this task, they\nmainly rely on a time-consuming optimization paradigm. Specifically, these\nmethods optimize a neural field from scratch for each text prompt, taking\napproximately one hour or more to generate one object. This heavy and\nrepetitive training cost impedes their practical deployment. In this paper, we\npropose a novel framework for fast text-to-3D generation, dubbed Instant3D.\nOnce trained, Instant3D is able to create a 3D object for an unseen text prompt\nin less than one second with a single run of a feedforward network. We achieve\nthis remarkable speed by devising a new network that directly constructs a 3D\ntriplane from a text prompt. The core innovation of our Instant3D lies in our\nexploration of strategies to effectively inject text conditions into the\nnetwork. Furthermore, we propose a simple yet effective activation function,\nthe scaled-sigmoid, to replace the original sigmoid function, which speeds up\nthe training convergence by more than ten times. Finally, to address the Janus\n(multi-head) problem in 3D generation, we propose an adaptive Perp-Neg\nalgorithm that can dynamically adjust its concept negation scales according to\nthe severity of the Janus problem during training, effectively reducing the\nmulti-head effect. Extensive experiments on a wide variety of benchmark\ndatasets demonstrate that the proposed algorithm performs favorably against the\nstate-of-the-art methods both qualitatively and quantitatively, while achieving\nsignificantly better efficiency. The project page is at\nhttps://ming1993li.github.io/Instant3DProj.",
            "author": [
                "Ming Li",
                "Pan Zhou",
                "Jia-Wei Liu",
                "Jussi Keppo",
                "Min Lin",
                "Shuicheng Yan",
                "Xiangyu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08403v1",
                "http://arxiv.org/pdf/2311.08403v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08402v1",
            "title": "Retrieve and Copy: Scaling ASR Personalization to Large Catalogs",
            "updated": "2023-11-14T18:59:24Z",
            "published": "2023-11-14T18:59:24Z",
            "summary": "Personalization of automatic speech recognition (ASR) models is a widely\nstudied topic because of its many practical applications. Most recently,\nattention-based contextual biasing techniques are used to improve the\nrecognition of rare words and domain specific entities. However, due to\nperformance constraints, the biasing is often limited to a few thousand\nentities, restricting real-world usability. To address this, we first propose a\n\"Retrieve and Copy\" mechanism to improve latency while retaining the accuracy\neven when scaled to a large catalog. We also propose a training strategy to\novercome the degradation in recall at such scale due to an increased number of\nconfusing entities. Overall, our approach achieves up to 6% more Word Error\nRate reduction (WERR) and 3.6% absolute improvement in F1 when compared to a\nstrong baseline. Our method also allows for large catalog sizes of up to 20K\nwithout significantly affecting WER and F1-scores, while achieving at least 20%\ninference speedup per acoustic frame.",
            "author": [
                "Sai Muralidhar Jayanthi",
                "Devang Kulshreshtha",
                "Saket Dingliwal",
                "Srikanth Ronanki",
                "Sravan Bodapati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08402v1",
                "http://arxiv.org/pdf/2311.08402v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08401v1",
            "title": "Fine-tuning Language Models for Factuality",
            "updated": "2023-11-14T18:59:15Z",
            "published": "2023-11-14T18:59:15Z",
            "summary": "The fluency and creativity of large pre-trained language models (LLMs) have\nled to their widespread use, sometimes even as a replacement for traditional\nsearch engines. Yet language models are prone to making convincing but\nfactually inaccurate claims, often referred to as 'hallucinations.' These\nerrors can inadvertently spread misinformation or harmfully perpetuate\nmisconceptions. Further, manual fact-checking of model responses is a\ntime-consuming process, making human factuality labels expensive to acquire. In\nthis work, we fine-tune language models to be more factual, without human\nlabeling and targeting more open-ended generation settings than past work. We\nleverage two key recent innovations in NLP to do so. First, several recent\nworks have proposed methods for judging the factuality of open-ended text by\nmeasuring consistency with an external knowledge base or simply a large model's\nconfidence scores. Second, the direct preference optimization algorithm enables\nstraightforward fine-tuning of language models on objectives other than\nsupervised imitation, using a preference ranking over possible model responses.\nWe show that learning from automatically generated factuality preference\nrankings, generated either through existing retrieval systems or our novel\nretrieval-free approach, significantly improves the factuality (percent of\ngenerated claims that are correct) of Llama-2 on held-out topics compared with\nRLHF or decoding strategies targeted at factuality. At 7B scale, compared to\nLlama-2-chat, we observe 58% and 40% reduction in factual error rate when\ngenerating biographies and answering medical questions, respectively.",
            "author": [
                "Katherine Tian",
                "Eric Mitchell",
                "Huaxiu Yao",
                "Christopher D. Manning",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08401v1",
                "http://arxiv.org/pdf/2311.08401v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08400v1",
            "title": "Towards Open-Ended Visual Recognition with Large Language Model",
            "updated": "2023-11-14T18:59:01Z",
            "published": "2023-11-14T18:59:01Z",
            "summary": "Localizing and recognizing objects in the open-ended physical world poses a\nlong-standing challenge within the domain of machine perception. Recent methods\nhave endeavored to address the issue by employing a class-agnostic mask (or\nbox) proposal model, complemented by an open-vocabulary classifier (e.g., CLIP)\nusing pre-extracted text embeddings. However, it is worth noting that these\nopen-vocabulary recognition models still exhibit limitations in practical\napplications. On one hand, they rely on the provision of class names during\ntesting, where the recognition performance heavily depends on this predefined\nset of semantic classes by users. On the other hand, when training with\nmultiple datasets, human intervention is required to alleviate the label\ndefinition conflict between them. In this paper, we introduce the OmniScient\nModel (OSM), a novel Large Language Model (LLM) based mask classifier, as a\nstraightforward and effective solution to the aforementioned challenges.\nSpecifically, OSM predicts class labels in a generative manner, thus removing\nthe supply of class names during both training and testing. It also enables\ncross-dataset training without any human interference, exhibiting robust\ngeneralization capabilities due to the world knowledge acquired from the LLM.\nBy combining OSM with an off-the-shelf mask proposal model, we present\npromising results on various benchmarks, and demonstrate its effectiveness in\nhandling novel concepts. Code/model are available at\nhttps://github.com/bytedance/OmniScient-Model.",
            "author": [
                "Qihang Yu",
                "Xiaohui Shen",
                "Liang-Chieh Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08400v1",
                "http://arxiv.org/pdf/2311.08400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08398v2",
            "title": "Are Large Language Models Temporally Grounded?",
            "updated": "2023-11-16T09:41:28Z",
            "published": "2023-11-14T18:57:15Z",
            "summary": "Are Large language models (LLMs) temporally grounded? Since LLMs cannot\nperceive and interact with the environment, it is impossible to answer this\nquestion directly. Instead, we provide LLMs with textual narratives and probe\nthem with respect to their common-sense knowledge of the structure and duration\nof events, their ability to order events along a timeline, and self-consistency\nwithin their temporal model (e.g., temporal relations such as after and before\nare mutually exclusive for any pair of events). We evaluate state-of-the-art\nLLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities.\nGenerally, we find that LLMs lag significantly behind both human performance as\nwell as small-scale, specialised LMs. In-context learning, instruction tuning,\nand chain-of-thought prompting reduce this gap only to a limited degree.\nCrucially, LLMs struggle the most with self-consistency, displaying incoherent\nbehaviour in at least 27.23% of their predictions. Contrary to expectations, we\nalso find that scaling the model size does not guarantee positive gains in\nperformance. To explain these results, we study the sources from which LLMs may\ngather temporal information: we find that sentence ordering in unlabelled\ntexts, available during pre-training, is only weakly correlated with event\nordering. Moreover, public instruction tuning mixtures contain few temporal\ntasks. Hence, we conclude that current LLMs lack a consistent temporal model of\ntextual narratives. Code, datasets, and LLM outputs are available at\nhttps://github.com/yfqiu-nlp/temporal-llms.",
            "author": [
                "Yifu Qiu",
                "Zheng Zhao",
                "Yftah Ziser",
                "Anna Korhonen",
                "Edoardo M. Ponti",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08398v2",
                "http://arxiv.org/pdf/2311.08398v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08396v1",
            "title": "Zero-shot audio captioning with audio-language model guidance and audio\n  context keywords",
            "updated": "2023-11-14T18:55:48Z",
            "published": "2023-11-14T18:55:48Z",
            "summary": "Zero-shot audio captioning aims at automatically generating descriptive\ntextual captions for audio content without prior training for this task.\nDifferent from speech recognition which translates audio content that contains\nspoken language into text, audio captioning is commonly concerned with ambient\nsounds, or sounds produced by a human performing an action. Inspired by\nzero-shot image captioning methods, we propose ZerAuCap, a novel framework for\nsummarising such general audio signals in a text caption without requiring\ntask-specific training. In particular, our framework exploits a pre-trained\nlarge language model (LLM) for generating the text which is guided by a\npre-trained audio-language model to produce captions that describe the audio\ncontent. Additionally, we use audio context keywords that prompt the language\nmodel to generate text that is broadly relevant to sounds. Our proposed\nframework achieves state-of-the-art results in zero-shot audio captioning on\nthe AudioCaps and Clotho datasets. Our code is available at\nhttps://github.com/ExplainableML/ZerAuCap.",
            "author": [
                "Leonard Salewski",
                "Stefan Fauth",
                "A. Sophia Koepke",
                "Zeynep Akata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08396v1",
                "http://arxiv.org/pdf/2311.08396v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.CL",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08393v2",
            "title": "MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable\n  Trajectory Generation",
            "updated": "2023-11-18T21:51:33Z",
            "published": "2023-11-14T18:53:28Z",
            "summary": "The learn-from-observation (LfO) paradigm is a human-inspired mode for a\nrobot to learn to perform a task simply by watching it being performed. LfO can\nfacilitate robot integration on factory floors by minimizing disruption and\nreducing tedious programming. A key component of the LfO pipeline is a\ntransformation of the depth camera frames to the corresponding task state and\naction pairs, which are then relayed to learning techniques such as imitation\nor inverse reinforcement learning for understanding the task parameters. While\nseveral existing computer vision models analyze videos for activity\nrecognition, SA-Net specifically targets robotic LfO from RGB-D data. However,\nSA-Net and many other models analyze frame data captured from a single\nviewpoint. Their analysis is therefore highly sensitive to occlusions of the\nobserved task, which are frequent in deployments. An obvious way of reducing\nocclusions is to simultaneously observe the task from multiple viewpoints and\nsynchronously fuse the multiple streams in the model. Toward this, we present\nmulti-view SA-Net, which generalizes the SA-Net model to allow the perception\nof multiple viewpoints of the task activity, integrate them, and better\nrecognize the state and action in each frame. Performance evaluations on two\ndistinct domains establish that MVSA-Net recognizes the state-action pairs\nunder occlusion more accurately compared to single-view MVSA-Net and other\nbaselines. Our ablation studies further evaluate its performance under\ndifferent ambient conditions and establish the contribution of the architecture\ncomponents. As such, MVSA-Net offers a significantly more robust and deployable\nstate-action trajectory generation compared to previous methods.",
            "author": [
                "Ehsan Asali",
                "Prashant Doshi",
                "Jin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08393v2",
                "http://arxiv.org/pdf/2311.08393v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08392v1",
            "title": "Iterative Network Pricing for Ridesharing Platforms",
            "updated": "2023-11-14T18:52:50Z",
            "published": "2023-11-14T18:52:50Z",
            "summary": "Ridesharing platforms match riders and drivers, using dynamic pricing to\nbalance supply and demand. The origin-based \"surge pricing\", however, does not\ntake into consideration market conditions at trip destinations, leading to\ninefficient driver flows in space and incentivizes drivers to strategize. In\nthis work, we introduce the Iterative Network Pricing mechanism, addressing a\nmain challenge in the practical implementation of optimal origin-destination\n(OD) based prices, that the model for rider demand is hard to estimate.\nAssuming that the platform's surge algorithm clears the market for each origin\nin real-time, our mechanism updates the OD-based price adjustments\nweek-over-week, using only information immediately observable during the same\ntime window in the prior weeks. For stationary market conditions, we prove that\nour mechanism converges to an outcome that is approximately welfare-optimal.\nUsing data from the City of Chicago, we illustrate (via simulation) the\niterative updates under our mechanism for morning rush hours, demonstrating\nsubstantial welfare improvements despite significant fluctuations of market\nconditions from early 2019 through the end of 2020.",
            "author": [
                "Chenkai Yu",
                "Hongyao Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08392v1",
                "http://arxiv.org/pdf/2311.08392v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08391v1",
            "title": "A Material Lens on Coloniality in NLP",
            "updated": "2023-11-14T18:52:09Z",
            "published": "2023-11-14T18:52:09Z",
            "summary": "Coloniality, the continuation of colonial harms beyond \"official\"\ncolonization, has pervasive effects across society and scientific fields.\nNatural Language Processing (NLP) is no exception to this broad phenomenon. In\nthis work, we argue that coloniality is implicitly embedded in and amplified by\nNLP data, algorithms, and software. We formalize this analysis using\nActor-Network Theory (ANT): an approach to understanding social phenomena\nthrough the network of relationships between human stakeholders and technology.\nWe use our Actor-Network to guide a quantitative survey of the geography of\ndifferent phases of NLP research, providing evidence that inequality along\ncolonial boundaries increases as NLP builds on itself. Based on this, we argue\nthat combating coloniality in NLP requires not only changing current values but\nalso active work to remove the accumulation of colonial ideals in our\nfoundational data and algorithms.",
            "author": [
                "William Held",
                "Camille Harris",
                "Michael Best",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08391v1",
                "http://arxiv.org/pdf/2311.08391v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08390v1",
            "title": "On What Basis? Predicting Text Preference Via Structured Comparative\n  Reasoning",
            "updated": "2023-11-14T18:51:38Z",
            "published": "2023-11-14T18:51:38Z",
            "summary": "Comparative reasoning plays a crucial role in text preference prediction;\nhowever, large language models (LLMs) often demonstrate inconsistencies in\ntheir reasoning. While approaches like Chain-of-Thought improve accuracy in\nmany other settings, they struggle to consistently distinguish the similarities\nand differences of complex texts. We introduce SC, a prompting approach that\npredicts text preferences by generating structured intermediate comparisons. SC\nbegins by proposing aspects of comparison, followed by generating textual\ncomparisons under each aspect. We select consistent comparisons with a pairwise\nconsistency comparator that ensures each aspect's comparisons clearly\ndistinguish differences between texts, significantly reducing hallucination and\nimproving consistency. Our comprehensive evaluations across various NLP tasks,\nincluding summarization, retrieval, and automatic rating, demonstrate that SC\nequips LLMs to achieve state-of-the-art performance in text preference\nprediction.",
            "author": [
                "Jing Nathan Yan",
                "Tianqi Liu",
                "Justin T Chiu",
                "Jiaming Shen",
                "Zhen Qin",
                "Yue Yu",
                "Yao Zhao",
                "Charu Lakshmanan",
                "Yair Kurzion",
                "Alexander M. Rush",
                "Jialu Liu",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08390v1",
                "http://arxiv.org/pdf/2311.08390v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08389v1",
            "title": "TSST: A Benchmark and Evaluation Models for Text Speech-Style Transfer",
            "updated": "2023-11-14T18:50:51Z",
            "published": "2023-11-14T18:50:51Z",
            "summary": "Text style is highly abstract, as it encompasses various aspects of a\nspeaker's characteristics, habits, logical thinking, and the content they\nexpress. However, previous text-style transfer tasks have primarily focused on\ndata-driven approaches, lacking in-depth analysis and research from the\nperspectives of linguistics and cognitive science. In this paper, we introduce\na novel task called Text Speech-Style Transfer (TSST). The main objective is to\nfurther explore topics related to human cognition, such as personality and\nemotion, based on the capabilities of existing LLMs. Considering the objective\nof our task and the distinctive characteristics of oral speech in real-life\nscenarios, we trained multi-dimension (i.e. filler words, vividness,\ninteractivity, emotionality) evaluation models for the TSST and validated their\ncorrelation with human assessments. We thoroughly analyze the performance of\nseveral large language models (LLMs) and identify areas where further\nimprovement is needed. Moreover, driven by our evaluation models, we have\nreleased a new corpus that improves the capabilities of LLMs in generating text\nwith speech-style characteristics. In summary, we present the TSST task, a new\nbenchmark for style transfer and emphasizing human-oriented evaluation,\nexploring and advancing the performance of current LLMs.",
            "author": [
                "Huashan Sun",
                "Yixiao Wu",
                "Yinghao Li",
                "Jiawei Li",
                "Yizhe Yang",
                "Yang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08389v1",
                "http://arxiv.org/pdf/2311.08389v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08386v1",
            "title": "Communication Efficiency of Summation over a Quantum Erasure MAC with\n  Replicated Inputs",
            "updated": "2023-11-14T18:49:00Z",
            "published": "2023-11-14T18:49:00Z",
            "summary": "The quantum communication cost of computing a classical sum of distributed\nsources is studied over a quantum erasure multiple access channel (QEMAC). $K$\nmessages are distributed across $S$ servers so that each server knows a subset\nof the messages. Each server $s\\in[S]$ sends a quantum subsystem\n$\\mathcal{Q}_s$ to the receiver who computes the sum of the messages. The\ndownload cost from Server $s\\in [S]$ is the logarithm of the dimension of\n$\\mathcal{Q}_s$. The rate $R$ is defined as the number of instances of the sum\ncomputed at the receiver, divided by the total download cost from all the\nservers. In the symmetric setting with $K= {S \\choose \\alpha} $ messages where\neach message is replicated among a unique subset of $\\alpha$ servers, and the\nanswers from any $\\beta$ servers may be erased, the rate achieved is $R=\n\\max\\left\\{ \\min \\left\\{ \\frac{2(\\alpha-\\beta)}{S}, 1-\\frac{2\\beta}{S}\n\\right\\}, \\frac{\\alpha-\\beta}{S} \\right\\}$, which is shown to be optimal when\n$S\\geq 2\\alpha$.",
            "author": [
                "Yuhang Yao",
                "Syed A. Jafar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08386v1",
                "http://arxiv.org/pdf/2311.08386v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08385v2",
            "title": "ChOiRe: Characterizing and Predicting Human Opinions with Chain of\n  Opinion Reasoning",
            "updated": "2023-11-15T16:40:13Z",
            "published": "2023-11-14T18:48:27Z",
            "summary": "Aligning language models (LMs) with human opinion is challenging yet vital to\nenhance their grasp of human values, preferences, and beliefs. We present\nChOiRe, a four-step solution framework to predict human opinion that\ndifferentiates between the user explicit personae (i.e. demographic or\nideological attributes) that are manually declared and implicit personae\ninferred from user historical opinions. Specifically, it consists of (i) an LM\nanalyzing the user explicit personae to filter out irrelevant attributes; (ii)\nthe LM ranking the implicit persona opinions into a preferential list; (iii)\nChain-of-Opinion (CoO) reasoning, where the LM sequentially analyzes the\nexplicit personae and the most relevant implicit personae to perform opinion\nprediction; (iv) and where ChOiRe executes Step (iii) CoO multiple times with\nincreasingly larger lists of implicit personae to overcome insufficient\npersonae information to infer a final result. ChOiRe achieves new\nstate-of-the-art effectiveness with limited inference calls, improving previous\nLLM-based techniques significantly by 3.22%.",
            "author": [
                "Xuan Long Do",
                "Kenji Kawaguchi",
                "Min-Yen Kan",
                "Nancy F. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08385v2",
                "http://arxiv.org/pdf/2311.08385v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08380v1",
            "title": "Direct Preference Optimization for Neural Machine Translation with\n  Minimum Bayes Risk Decoding",
            "updated": "2023-11-14T18:43:51Z",
            "published": "2023-11-14T18:43:51Z",
            "summary": "Minimum Bayes Risk (MBR) decoding can significantly improve translation\nperformance of Multilingual Large Language Models (MLLMs). However, MBR\ndecoding is computationally expensive and in this paper, we show how recently\ndeveloped Reinforcement Learning (RL) technique, Direct Preference Optimization\n(DPO) can be used to fine-tune MLLMs so that we get the gains from MBR without\nthe additional computation in inference. Our fine-tuned models have\nsignificantly improved performance on multiple NMT test sets compared to base\nMLLMs without preference optimization. Our method boosts the translation\nperformance of MLLMs using relatively small monolingual fine-tuning sets.",
            "author": [
                "Guangyu Yang",
                "Jinghong Chen",
                "Weizhe Lin",
                "Bill Byrne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08380v1",
                "http://arxiv.org/pdf/2311.08380v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08445v1",
            "title": "Lecture notes on quantum computing",
            "updated": "2023-11-14T18:42:55Z",
            "published": "2023-11-14T18:42:55Z",
            "summary": "These are the lecture notes of the master's course \"Quantum Computing\",\ntaught at Chalmers University of Technology every fall since 2020, with\nparticipation of students from RWTH Aachen and Delft University of Technology.\nThe aim of this course is to provide a theoretical overview of quantum\ncomputing, excluding specific hardware implementations. Topics covered in these\nnotes include quantum algorithms (such as Grover's algorithm, the quantum\nFourier transform, phase estimation, and Shor's algorithm), variational quantum\nalgorithms that utilise an interplay between classical and quantum computers\n[such as the variational quantum eigensolver (VQE) and the quantum approximate\noptimisation algorithm (QAOA), among others], quantum error correction, various\nversions of quantum computing (such as measurement-based quantum computation,\nadiabatic quantum computation, and the continuous-variable approach to quantum\ninformation), the intersection of quantum computing and machine learning, and\nquantum complexity theory. Lectures on these topics are compiled into 12\nchapters, most of which contain a few suggested exercises at the end, and\ninterspersed with four tutorials, which provide practical exercises as well as\nfurther details. At Chalmers, the course is taught in seven weeks, with three\ntwo-hour lectures or tutorials per week. It is recommended that the students\ntaking the course have some previous experience with quantum physics, but not\nstrictly necessary.",
            "author": [
                "Anton Frisk Kockum",
                "Ariadna Soro",
                "Laura Garc\u00eda-\u00c1lvarez",
                "Pontus Vikst\u00e5l",
                "Tom Douce",
                "G\u00f6ran Johansson",
                "Giulia Ferrini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08445v1",
                "http://arxiv.org/pdf/2311.08445v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08379v3",
            "title": "Scheming AIs: Will AIs fake alignment during training in order to get\n  power?",
            "updated": "2023-11-27T19:30:35Z",
            "published": "2023-11-14T18:42:40Z",
            "summary": "This report examines whether advanced AIs that perform well in training will\nbe doing so in order to gain power later -- a behavior I call \"scheming\" (also\nsometimes called \"deceptive alignment\"). I conclude that scheming is a\ndisturbingly plausible outcome of using baseline machine learning methods to\ntrain goal-directed AIs sophisticated enough to scheme (my subjective\nprobability on such an outcome, given these conditions, is roughly 25%). In\nparticular: if performing well in training is a good strategy for gaining power\n(as I think it might well be), then a very wide variety of goals would motivate\nscheming -- and hence, good training performance. This makes it plausible that\ntraining might either land on such a goal naturally and then reinforce it, or\nactively push a model's motivations towards such a goal as an easy way of\nimproving performance. What's more, because schemers pretend to be aligned on\ntests designed to reveal their motivations, it may be quite difficult to tell\nwhether this has occurred. However, I also think there are reasons for comfort.\nIn particular: scheming may not actually be such a good strategy for gaining\npower; various selection pressures in training might work against schemer-like\ngoals (for example, relative to non-schemers, schemers need to engage in extra\ninstrumental reasoning, which might harm their training performance); and we\nmay be able to increase such pressures intentionally. The report discusses\nthese and a wide variety of other considerations in detail, and it suggests an\narray of empirical research directions for probing the topic further.",
            "author": [
                "Joe Carlsmith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08379v3",
                "http://arxiv.org/pdf/2311.08379v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08377v1",
            "title": "Learning to Filter Context for Retrieval-Augmented Generation",
            "updated": "2023-11-14T18:41:54Z",
            "published": "2023-11-14T18:41:54Z",
            "summary": "On-the-fly retrieval of relevant knowledge has proven an essential element of\nreliable systems for tasks such as open-domain question answering and fact\nverification. However, because retrieval systems are not perfect, generation\nmodels are required to generate outputs given partially or entirely irrelevant\npassages. This can cause over- or under-reliance on context, and result in\nproblems in the generated output such as hallucinations. To alleviate these\nproblems, we propose FILCO, a method that improves the quality of the context\nprovided to the generator by (1) identifying useful context based on lexical\nand information-theoretic approaches, and (2) training context filtering models\nthat can filter retrieved contexts at test time. We experiment on six\nknowledge-intensive tasks with FLAN-T5 and LLaMa2, and demonstrate that our\nmethod outperforms existing approaches on extractive question answering (QA),\ncomplex multi-hop and long-form QA, fact verification, and dialog generation\ntasks. FILCO effectively improves the quality of context, whether or not it\nsupports the canonical output.",
            "author": [
                "Zhiruo Wang",
                "Jun Araki",
                "Zhengbao Jiang",
                "Md Rizwan Parvez",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08377v1",
                "http://arxiv.org/pdf/2311.08377v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08375v1",
            "title": "Proceedings 19th International Conference on Quantum Physics and Logic",
            "updated": "2023-11-14T18:41:23Z",
            "published": "2023-11-14T18:41:23Z",
            "summary": "This volume contains the proceedings of the 19th International Conference on\nQuantum Physics and Logic (QPL 2022), which was held June 27-July 1, 2022 at\nWolfson College, University of Oxford, UK. QPL is an annual conference that\nbrings together academic and industry researchers working on mathematical\nfoundations of quantum computation, quantum physics, and related areas. The\nmain focus is on the use of algebraic and categorical structures, formal\nlanguages, semantic methods, as well as other mathematical and computer\nscientific techniques applicable to the study of physical systems, physical\nprocesses, and their composition.",
            "author": [
                "Stefano Gogioso",
                "Matty Hoban"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.394",
                "http://arxiv.org/abs/2311.08375v1",
                "http://arxiv.org/pdf/2311.08375v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08374v1",
            "title": "A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts",
            "updated": "2023-11-14T18:40:42Z",
            "published": "2023-11-14T18:40:42Z",
            "summary": "In the realm of text manipulation and linguistic transformation, the question\nof authorship has always been a subject of fascination and philosophical\ninquiry. Much like the \\textbf{Ship of Theseus paradox}, which ponders whether\na ship remains the same when each of its original planks is replaced, our\nresearch delves into an intriguing question: \\textit{Does a text retain its\noriginal authorship when it undergoes numerous paraphrasing iterations?}\nSpecifically, since Large Language Models (LLMs) have demonstrated remarkable\nproficiency in the generation of both original content and the modification of\nhuman-authored texts, a pivotal question emerges concerning the determination\nof authorship in instances where LLMs or similar paraphrasing tools are\nemployed to rephrase the text. This inquiry revolves around \\textit{whether\nauthorship should be attributed to the original human author or the AI-powered\ntool, given the tool's independent capacity to produce text that closely\nresembles human-generated content.} Therefore, we embark on a philosophical\nvoyage through the seas of language and authorship to unravel this intricate\npuzzle.",
            "author": [
                "Nafis Irtiza Tripto",
                "Saranya Venkatraman",
                "Dominik Macko",
                "Robert Moro",
                "Ivan Srba",
                "Adaku Uchendu",
                "Thai Le",
                "Dongwon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08374v1",
                "http://arxiv.org/pdf/2311.08374v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08373v1",
            "title": "Proceedings of the 18th International Workshop on the ACL2 Theorem\n  Prover and Its Applications",
            "updated": "2023-11-14T18:38:12Z",
            "published": "2023-11-14T18:38:12Z",
            "summary": "This volume contains the proceedings of the Eighteenth International Workshop\non the ACL2 Theorem Prover and Its Applications (ACL2-2023), a two-day workshop\nheld at the University of Texas at Austin and online, on November 13-14. These\nworkshops provide a major technical forum for users of the ACL2 theorem prover\nto present research related to ACL2 and its applications.",
            "author": [
                "Alessandro Coglio",
                "Sol Swords"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.393",
                "http://arxiv.org/abs/2311.08373v1",
                "http://arxiv.org/pdf/2311.08373v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08372v1",
            "title": "Aid Nexus : A Blockchain Based Financial Distribution System",
            "updated": "2023-11-14T18:35:02Z",
            "published": "2023-11-14T18:35:02Z",
            "summary": "Blockchain technology has emerged as a disruptive force with transformative\npotential across numerous industries, promising efficient and automated\nsolutions that can revolutionize traditional systems. By leveraging\ndecentralized ledger systems, blockchain offers enhanced security,\ntransparency, and transaction verification without the need for intermediaries.\nThe finance sector is exploring blockchain-based solutions for payments,\nremittances, lending, and investments, while healthcare adopts the technology\nfor medical record keeping, supply chain tracking, and data management.\nSimilarly, supply chain management benefits from blockchain's ability to\nenhance transparency, traceability, and accountability from raw materials to\nfinished products. Other sectors, including real estate, energy, and\ngovernment, are also investigating blockchain-based solutions to improve\nefficiency, security, and transparency. Furthermore, smart contracts within the\nblockchain enable process automation, reducing manual intervention in\ndistribution workflows. AidNeux, a consortium-based blockchain DApp, reimagines\nthe distribution of financial assistance by addressing inefficiencies and\nopaqueness. Using smart contracts ensures the security and directness of money\ntransfers. Its robust digital identity verification and real-time auditability\nreduce fraud risks and strengthen accountability, thereby presenting a\nscalable, transparent solution to problems inherent to conventional financial\naid systems.",
            "author": [
                "Md. Raisul Hasan Shahrukh",
                "Md. Tabassinur Rahman",
                "Nafees Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08372v1",
                "http://arxiv.org/pdf/2311.08372v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CE",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08371v1",
            "title": "USLR: an open-source tool for unbiased and smooth longitudinal\n  registration of brain MR",
            "updated": "2023-11-14T18:34:18Z",
            "published": "2023-11-14T18:34:18Z",
            "summary": "We present USLR, a computational framework for longitudinal registration of\nbrain MRI scans to estimate nonlinear image trajectories that are smooth across\ntime, unbiased to any timepoint, and robust to imaging artefacts. It operates\non the Lie algebra parameterisation of spatial transforms (which is compatible\nwith rigid transforms and stationary velocity fields for nonlinear deformation)\nand takes advantage of log-domain properties to solve the problem using\nBayesian inference. USRL estimates rigid and nonlinear registrations that: (i)\nbring all timepoints to an unbiased subject-specific space; and (i) compute a\nsmooth trajectory across the imaging time-series. We capitalise on\nlearning-based registration algorithms and closed-form expressions for fast\ninference. A use-case Alzheimer's disease study is used to showcase the\nbenefits of the pipeline in multiple fronts, such as time-consistent image\nsegmentation to reduce intra-subject variability, subject-specific prediction\nor population analysis using tensor-based morphometry. We demonstrate that such\napproach improves upon cross-sectional methods in identifying group\ndifferences, which can be helpful in detecting more subtle atrophy levels or in\nreducing sample sizes in clinical trials. The code is publicly available in\nhttps://github.com/acasamitjana/uslr",
            "author": [
                "Adri\u00e0 Casamitjana",
                "Roser Sala-Llonch",
                "Karim Lekadir",
                "Juan Eugenio Iglesias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08371v1",
                "http://arxiv.org/pdf/2311.08371v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08370v1",
            "title": "SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in\n  Large Language Models",
            "updated": "2023-11-14T18:33:43Z",
            "published": "2023-11-14T18:33:43Z",
            "summary": "The past year has seen rapid acceleration in the development of large\nlanguage models (LLMs). For many tasks, there is now a wide range of\nopen-source and open-access LLMs that are viable alternatives to proprietary\nmodels like ChatGPT. Without proper steering and safeguards, however, LLMs will\nreadily follow malicious instructions, provide unsafe advice, and generate\ntoxic content. This is a critical safety risk for businesses and developers. We\nintroduce SimpleSafetyTests as a new test suite for rapidly and systematically\nidentifying such critical safety risks. The test suite comprises 100 test\nprompts across five harm areas that LLMs, for the vast majority of\napplications, should refuse to comply with. We test 11 popular open LLMs and\nfind critical safety weaknesses in several of them. While some LLMs do not give\na single unsafe response, most models we test respond unsafely on more than 20%\nof cases, with over 50% unsafe responses in the extreme. Prepending a\nsafety-emphasising system prompt substantially reduces the occurrence of unsafe\nresponses, but does not completely stop them from happening. We recommend that\ndevelopers use such system prompts as a first line of defence against critical\nsafety risks.",
            "author": [
                "Bertie Vidgen",
                "Hannah Rose Kirk",
                "Rebecca Qian",
                "Nino Scherrer",
                "Anand Kannappan",
                "Scott A. Hale",
                "Paul R\u00f6ttger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08370v1",
                "http://arxiv.org/pdf/2311.08370v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08369v1",
            "title": "How You Prompt Matters! Even Task-Oriented Constraints in Instructions\n  Affect LLM-Generated Text Detection",
            "updated": "2023-11-14T18:32:52Z",
            "published": "2023-11-14T18:32:52Z",
            "summary": "Against the misuse (e.g., plagiarism or spreading misinformation) of Large\nLanguage Models (LLMs), many recent works have presented LLM-generated-text\ndetectors with promising detection performance. Spotlighting a situation where\nusers instruct LLMs to generate texts (e.g., essay writing), there are various\nways to write the instruction (e.g., what task-oriented constraint to include).\nIn this paper, we discover that even a task-oriented constraint in instruction\ncan cause the inconsistent performance of current detectors to the generated\ntexts. Specifically, we focus on student essay writing as a realistic domain\nand manually create the task-oriented constraint for each factor on essay\nquality by Ke and Ng (2019). Our experiment shows that the detection\nperformance variance of the current detector on texts generated by instruction\nwith each task-oriented constraint is up to 20 times larger than the variance\ncaused by generating texts multiple times and paraphrasing the instruction. Our\nfinding calls for further research on developing robust detectors that can\ndetect such distributional shifts caused by a task-oriented constraint in the\ninstruction.",
            "author": [
                "Ryuto Koike",
                "Masahiro Kaneko",
                "Naoaki Okazaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08369v1",
                "http://arxiv.org/pdf/2311.08369v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09253v1",
            "title": "The Perception-Robustness Tradeoff in Deterministic Image Restoration",
            "updated": "2023-11-14T18:30:34Z",
            "published": "2023-11-14T18:30:34Z",
            "summary": "We study the behavior of deterministic methods for solving inverse problems\nin imaging. These methods are commonly designed to achieve two goals: (1)\nattaining high perceptual quality, and (2) generating reconstructions that are\nconsistent with the measurements. We provide a rigorous proof that the better a\npredictor satisfies these two requirements, the larger its Lipschitz constant\nmust be, regardless of the nature of the degradation involved. In particular,\nto approach perfect perceptual quality and perfect consistency, the Lipschitz\nconstant of the model must grow to infinity. This implies that such methods are\nnecessarily more susceptible to adversarial attacks. We demonstrate our theory\non single image super-resolution algorithms, addressing both noisy and\nnoiseless settings. We also show how this undesired behavior can be leveraged\nto explore the posterior distribution, thereby allowing the deterministic model\nto imitate stochastic methods.",
            "author": [
                "Guy Ohayon",
                "Tomer Michaeli",
                "Michael Elad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09253v1",
                "http://arxiv.org/pdf/2311.09253v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08367v1",
            "title": "Arboricity-Dependent Algorithms for Edge Coloring",
            "updated": "2023-11-14T18:26:50Z",
            "published": "2023-11-14T18:26:50Z",
            "summary": "The problem of edge coloring has been extensively studied over the years. The\nmain conceptual contribution of this work is in identifying a surprisingly\nsimple connection between the problem of $(\\Delta +O(\\alpha))$-edge coloring\nand a certain canonical graph decomposition in graphs of arboricity $\\alpha$,\nfor which efficient algorithms are known across various computational models.\n  We first leverage such graph decompositions to provide fast $(\\Delta\n+O(\\alpha))$-edge coloring algorithms in the standard {\\em static} (sequential\nand distributed) settings. Further, as our main technical contribution, we show\nhow to efficiently maintain a $(\\Delta +O(\\alpha))$-edge coloring in the\nstandard {\\em dynamic} model. Consequently, we improve over the\nstate-of-the-art edge coloring algorithms in these models for graphs of\nsufficiently small arboricity.",
            "author": [
                "Sayan Bhattacharya",
                "Mart\u00edn Costa",
                "Nadav Panski",
                "Shay Solomon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08367v1",
                "http://arxiv.org/pdf/2311.08367v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08366v1",
            "title": "Random Surfaces and Higher Algebra",
            "updated": "2023-11-14T18:24:08Z",
            "published": "2023-11-14T18:24:08Z",
            "summary": "The space of surfaces $\\mathbf{X}: [0,1]^2 \\to \\mathbb{R}^d$ is equipped with\nnatural horizontal and vertical concatenation operations, and we study\nrepresentations of surfaces which preserve this algebraic structure. The\nframework of higher category theory allows us to formalize this notion in terms\nof a functor between double groupoids. We construct such functors by\ngeneralizing the classical concept of the path-ordered exponential as a\nnonabelian path integral. This generalization yields a notion of nonabelian\nsurface integration, and is known in higher gauge theory as surface holonomy\n(or higher parallel transport). We extend these constructions from smooth\nsurfaces to bounded controlled $p$-variation surfaces in the Young regime, with\n$p < 2$. By focusing on surface holonomy valued in higher generalizations of\nthe classical matrix groups, called matrix double groups, we obtain explicit\ncomputations for piecewise linear approximations. Furthermore, we generalize\nthe nonabelian Stokes' and Fubini theorems to the Young regime. Finally, we use\nthese matrix surface holonomy functors to construct characteristic functions\nfor random surfaces such as fractional Brownian sheets with Hurst parameter $h>\n\\frac{1}{2}$.",
            "author": [
                "Darrick Lee",
                "Harald Oberhauser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08366v1",
                "http://arxiv.org/pdf/2311.08366v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.AT",
                "math.CT",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08360v2",
            "title": "The Transient Nature of Emergent In-Context Learning in Transformers",
            "updated": "2023-11-15T04:02:44Z",
            "published": "2023-11-14T18:03:20Z",
            "summary": "Transformer neural networks can exhibit a surprising capacity for in-context\nlearning (ICL) despite not being explicitly trained for it. Prior work has\nprovided a deeper understanding of how ICL emerges in transformers, e.g.\nthrough the lens of mechanistic interpretability, Bayesian inference, or by\nexamining the distributional properties of training data. However, in each of\nthese cases, ICL is treated largely as a persistent phenomenon; namely, once\nICL emerges, it is assumed to persist asymptotically. Here, we show that the\nemergence of ICL during transformer training is, in fact, often transient. We\ntrain transformers on synthetic data designed so that both ICL and in-weights\nlearning (IWL) strategies can lead to correct predictions. We find that ICL\nfirst emerges, then disappears and gives way to IWL, all while the training\nloss decreases, indicating an asymptotic preference for IWL. The transient\nnature of ICL is observed in transformers across a range of model sizes and\ndatasets, raising the question of how much to \"overtrain\" transformers when\nseeking compact, cheaper-to-run models. We find that L2 regularization may\noffer a path to more persistent ICL that removes the need for early stopping\nbased on ICL-style validation tasks. Finally, we present initial evidence that\nICL transience may be caused by competition between ICL and IWL circuits.",
            "author": [
                "Aaditya K. Singh",
                "Stephanie C. Y. Chan",
                "Ted Moskovitz",
                "Erin Grant",
                "Andrew M. Saxe",
                "Felix Hill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08360v2",
                "http://arxiv.org/pdf/2311.08360v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08359v1",
            "title": "Rotation-Agnostic Image Representation Learning for Digital Pathology",
            "updated": "2023-11-14T18:01:15Z",
            "published": "2023-11-14T18:01:15Z",
            "summary": "This paper addresses complex challenges in histopathological image analysis\nthrough three key contributions. Firstly, it introduces a fast patch selection\nmethod, FPS, for whole-slide image (WSI) analysis, significantly reducing\ncomputational cost while maintaining accuracy. Secondly, it presents PathDino,\na lightweight histopathology feature extractor with a minimal configuration of\nfive Transformer blocks and only 9 million parameters, markedly fewer than\nalternatives. Thirdly, it introduces a rotation-agnostic representation\nlearning paradigm using self-supervised learning, effectively mitigating\noverfitting. We also show that our compact model outperforms existing\nstate-of-the-art histopathology-specific vision transformers on 12 diverse\ndatasets, including both internal datasets spanning four sites (breast, liver,\nskin, and colorectal) and seven public datasets (PANDA, CAMELYON16, BRACS,\nDigestPath, Kather, PanNuke, and WSSS4LUAD). Notably, even with a training\ndataset of 6 million histopathology patches from The Cancer Genome Atlas\n(TCGA), our approach demonstrates an average 8.5% improvement in patch-level\nmajority vote performance. These contributions provide a robust framework for\nenhancing image analysis in digital pathology, rigorously validated through\nextensive evaluation. Project Page: https://rhazeslab.github.io/PathDino-Page/",
            "author": [
                "Saghir Alfasly",
                "Abubakr Shafique",
                "Peyman Nejat",
                "Jibran Khan",
                "Areej Alsaafin",
                "Ghazal Alabtah",
                "H. R. Tizhoosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08359v1",
                "http://arxiv.org/pdf/2311.08359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08356v1",
            "title": "A Two-Step Rayleigh-Schr\u00f6dinger Brillouin-Wigner Approach to\n  Transition Energies",
            "updated": "2023-11-14T17:58:24Z",
            "published": "2023-11-14T17:58:24Z",
            "summary": "Perturbative methods are attractive to describe the electronic structure of\nmolecular systems because of their low-computational cost and systematically\nimprovable character. In this work, a two-step perturbative approach is\nintroduced combining multi-state Rayleigh-Schr\\\"odinger (effective Hamiltonian\ntheory) and state-specific Brillouin-Wigner schemes to treat degenerate\nconfigurations and yield an efficient evaluation of multiple energies. The\nfirst step produces model functions and an updated definition of the\nperturbative partitioning of the Hamiltonian. The second step inherits the\nimproved starting point provided in the first step, enabling then faster\nprocessing of the perturbative corrections for each individual state. The\nhere-proposed two-step method is exemplified on a model-Hamiltonian of\nincreasing complexity.",
            "author": [
                "Loris Delafosse",
                "Amr Hussein",
                "Saad Yalouz",
                "Vincent Robert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08356v1",
                "http://arxiv.org/pdf/2311.08356v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08349v1",
            "title": "Artificial Text Boundary Detection with Topological Data Analysis and\n  Sliding Window Techniques",
            "updated": "2023-11-14T17:48:19Z",
            "published": "2023-11-14T17:48:19Z",
            "summary": "Due to the rapid development of text generation models, people increasingly\noften encounter texts that may start out as written by a human but then\ncontinue as machine-generated results of large language models. Detecting the\nboundary between human-written and machine-generated parts of such texts is a\nvery challenging problem that has not received much attention in literature. In\nthis work, we consider and compare a number of different approaches for this\nartificial text boundary detection problem, comparing several predictors over\nfeatures of different nature. We show that supervised fine-tuning of the\nRoBERTa model works well for this task in general but fails to generalize in\nimportant cross-domain and cross-generator settings, demonstrating a tendency\nto overfit to spurious properties of the data. Then, we propose novel\napproaches based on features extracted from a frozen language model's\nembeddings that are able to outperform both the human accuracy level and\npreviously considered baselines on the Real or Fake Text benchmark. Moreover,\nwe adapt perplexity-based approaches for the boundary detection task and\nanalyze their behaviour. We analyze the robustness of all proposed classifiers\nin cross-domain and cross-model settings, discovering important properties of\nthe data that can negatively influence the performance of artificial text\nboundary detection algorithms.",
            "author": [
                "Laida Kushnareva",
                "Tatiana Gaintseva",
                "German Magai",
                "Serguei Barannikov",
                "Dmitry Abulkhanov",
                "Kristian Kuznetsov",
                "Irina Piontkovskaya",
                "Sergey Nikolenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08349v1",
                "http://arxiv.org/pdf/2311.08349v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08348v1",
            "title": "MC^2: A Multilingual Corpus of Minority Languages in China",
            "updated": "2023-11-14T17:45:50Z",
            "published": "2023-11-14T17:45:50Z",
            "summary": "Large-scale corpora play a vital role in the construction of large language\nmodels (LLMs). However, existing LLMs exhibit limited abilities in\nunderstanding low-resource languages, including the minority languages in\nChina, due to a lack of training data. To improve the accessibility of these\nlanguages, we present MC^2, a Multilingual Corpus of Minority Languages in\nChina, which is the largest open-source corpus so far. It encompasses four\nunderrepresented languages, i.e., Tibetan, Uyghur, Kazakh in the Kazakh Arabic\nscript, and Mongolian in the traditional Mongolian script. Notably, two writing\nsystems in MC^2 are long neglected in previous corpora. As we identify serious\ncontamination in the low-resource language split in the existing multilingual\ncorpora, we propose a quality-centric solution for collecting MC^2,\nprioritizing quality and accuracy while enhancing representativeness and\ndiversity. By in-depth analysis, we demonstrate the new research challenges\nMC^2 brings, such as long-text modeling and multiplicity of writing systems. We\nhope MC^2 can help enhance the equity of the underrepresented languages in\nChina and provide a reliable data foundation for further research on\nlow-resource languages.",
            "author": [
                "Chen Zhang",
                "Mingxu Tao",
                "Quzhe Huang",
                "Jiuheng Lin",
                "Zhibin Chen",
                "Yansong Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08348v1",
                "http://arxiv.org/pdf/2311.08348v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08347v2",
            "title": "High-efficiency single-photon source above the loss-tolerant threshold\n  for efficient linear optical quantum computing",
            "updated": "2023-11-28T16:01:13Z",
            "published": "2023-11-14T17:45:03Z",
            "summary": "Photon loss is the biggest enemy for scalable photonic quantum information\nprocessing. This problem can be tackled by using quantum error correction,\nprovided that the overall photon loss is below a threshold of 1/3. However, all\nreported on-demand and indistinguishable single-photon sources still fall short\nof this threshold. Here, by using tailor shaped laser pulse excitation on a\nhigh-quantum efficiency single quantum dot deterministically coupled to a\ntunable open microcavity, we demonstrate a high-performance source with a\nsingle-photon purity of 0.9795(6), photon indistinguishability of 0.9856(13),\nand an overall system efficiency of 0.712(18), simultaneously. This source for\nthe first time reaches the efficiency threshold for scalable photonic quantum\ncomputing. With this source, we further demonstrate 1.89(14) dB intensity\nsqueezing, and consecutive 40-photon events with 1.67 mHz count rate.",
            "author": [
                "Xing Ding",
                "Yong-Peng Guo",
                "Mo-Chi Xu",
                "Run-Ze Liu",
                "Geng-Yan Zou",
                "Jun-Yi Zhao",
                "Zhen-Xuan Ge",
                "Qi-Hang Zhang",
                "Hua-Liang Liu",
                "Lin-Jun Wang",
                "Ming-Cheng Chen",
                "Hui Wang",
                "Yu-Ming He",
                "Yong-Heng Huo",
                "Chao-Yang Lu",
                "Jian-Wei Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08347v2",
                "http://arxiv.org/pdf/2311.08347v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08345v1",
            "title": "Speeding Up Optimization-based Motion Planning through Deep Learning",
            "updated": "2023-11-14T17:42:01Z",
            "published": "2023-11-14T17:42:01Z",
            "summary": "Planning collision-free motions for robots with many degrees of freedom is\nchallenging in environments with complex obstacle geometries. Recent work\nintroduced the idea of speeding up the planning by encoding prior experience of\nsuccessful motion plans in a neural network. However, this \"neural motion\nplanning\" did not scale to complex robots in unseen 3D environments as needed\nfor real-world applications. Here, we introduce \"basis point set\", well-known\nin computer vision, to neural motion planning as a modern compact environment\nencoding enabling efficient supervised training networks that generalize well\nover diverse 3D worlds. Combined with a new elaborate training scheme, we reach\na planning success rate of 100%. We use the network to predict an educated\ninitial guess for an optimization-based planner (OMP), which quickly converges\nto a feasible solution, massively outperforming random multi-starts when tested\non previously unseen environments. For the DLR humanoid Agile Justin with 19DoF\nand in challenging obstacle environments, optimal paths can be generated in\n200ms using only a single CPU core. We also show a first successful real-world\nexperiment based on a high-resolution world model from an integrated 3D sensor.",
            "author": [
                "Johannes Tenhumberg",
                "Darius Burschka",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IROS47612.2022.9981717",
                "http://arxiv.org/abs/2311.08345v1",
                "http://arxiv.org/pdf/2311.08345v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08332v1",
            "title": "Graph Curve Matroids",
            "updated": "2023-11-14T17:25:05Z",
            "published": "2023-11-14T17:25:05Z",
            "summary": "We introduce a new class of matroids, called graph curve matroids. A graph\ncurve matroid is associated to a graph and defined on the vertices of the graph\nas a ground set. We prove that these matroids provide a combinatorial\ndescription of hyperplane sections of degenerate canonical curves in algebraic\ngeometry. Our focus lies on graphs that are 2-connected and trivalent, which\ndefine identically self-dual graph curve matroids, but we also develop\ngeneralizations. Finally, we provide an algorithm to compute the graph curve\nmatroid associated to a given graph, as well as an implementation and data of\nexamples that can be used in Macaulay2.",
            "author": [
                "Alheydis Geiger",
                "Kevin Kuehn",
                "Raluca Vlad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08332v1",
                "http://arxiv.org/pdf/2311.08332v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG",
                "05E14"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08329v3",
            "title": "KTRL+F: Knowledge-Augmented In-Document Search",
            "updated": "2023-11-16T09:38:39Z",
            "published": "2023-11-14T17:18:08Z",
            "summary": "We introduce a new problem KTRL+F, a knowledge-augmented in-document search\ntask that necessitates real-time identification of all semantic targets within\na document with the awareness of external sources through a single natural\nquery. This task addresses following unique challenges for in-document search:\n1) utilizing knowledge outside the document for extended use of additional\ninformation about targets to bridge the semantic gap between the query and the\ntargets, and 2) balancing between real-time applicability with the performance.\nWe analyze various baselines in KTRL+F and find there are limitations of\nexisting models, such as hallucinations, low latency, or difficulties in\nleveraging external knowledge. Therefore we propose a Knowledge-Augmented\nPhrase Retrieval model that shows a promising balance between speed and\nperformance by simply augmenting external knowledge embedding in phrase\nembedding. Additionally, we conduct a user study to verify whether solving\nKTRL+F can enhance search experience of users. It demonstrates that even with\nour simple model users can reduce the time for searching with less queries and\nreduced extra visits to other sources for collecting evidence. We encourage the\nresearch community to work on KTRL+F to enhance more efficient in-document\ninformation access.",
            "author": [
                "Hanseok Oh",
                "Haebin Shin",
                "Miyoung Ko",
                "Hyunji Lee",
                "Minjoon Seo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08329v3",
                "http://arxiv.org/pdf/2311.08329v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08441v1",
            "title": "MasterRTL: A Pre-Synthesis PPA Estimation Framework for Any RTL Design",
            "updated": "2023-11-14T17:17:32Z",
            "published": "2023-11-14T17:17:32Z",
            "summary": "In modern VLSI design flow, the register-transfer level (RTL) stage is a\ncritical point, where designers define precise design behavior with hardware\ndescription languages (HDLs) like Verilog. Since the RTL design is in the\nformat of HDL code, the standard way to evaluate its quality requires\ntime-consuming subsequent synthesis steps with EDA tools. This time-consuming\nprocess significantly impedes design optimization at the early RTL stage.\nDespite the emergence of some recent ML-based solutions, they fail to maintain\nhigh accuracy for any given RTL design. In this work, we propose an innovative\npre-synthesis PPA estimation framework named MasterRTL. It first converts the\nHDL code to a new bit-level design representation named the simple operator\ngraph (SOG). By only adopting single-bit simple operators, this SOG proves to\nbe a general representation that unifies different design types and styles. The\nSOG is also more similar to the target gate-level netlist, reducing the gap\nbetween RTL representation and netlist. In addition to the new SOG\nrepresentation, MasterRTL proposes new ML methods for the RTL-stage modeling of\ntiming, power, and area separately. Compared with state-of-the-art solutions,\nthe experiment on a comprehensive dataset with 90 different designs shows\naccuracy improvement by 0.33, 0.22, and 0.15 in correlation for total negative\nslack (TNS), worst negative slack (WNS), and power, respectively.",
            "author": [
                "Wenji Fang",
                "Yao Lu",
                "Shang Liu",
                "Qijun Zhang",
                "Ceyu Xu",
                "Lisa Wu Wills",
                "Hongce Zhang",
                "Zhiyao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08441v1",
                "http://arxiv.org/pdf/2311.08441v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08324v1",
            "title": "Anti-LM Decoding for Zero-shot In-context Machine Translation",
            "updated": "2023-11-14T17:09:43Z",
            "published": "2023-11-14T17:09:43Z",
            "summary": "Zero-shot In-context learning is the phenomenon where models can perform the\ntask simply given the instructions. However, pre-trained large language models\nare known to be poorly calibrated for this task. One of the most effective\napproaches to handling this bias is to adopt a contrastive decoding objective,\nwhich accounts for the prior probability of generating the next token by\nconditioning on some context. This work introduces an Anti-Language Model\nobjective with a decay factor designed to address the weaknesses of In-context\nMachine Translation. We conduct our experiments across 3 model types and sizes,\n3 language directions, and for both greedy decoding and beam search ($B=5$).\nThe proposed method outperforms other state-of-art decoding objectives, with up\nto $20$ BLEU point improvement from the default objective observed in some\nsettings.",
            "author": [
                "Suzanna Sia",
                "Alexandra DeLucia",
                "Kevin Duh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08324v1",
                "http://arxiv.org/pdf/2311.08324v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08323v1",
            "title": "Open-vocabulary keyword spotting in any language through multilingual\n  contrastive speech-phoneme pretraining",
            "updated": "2023-11-14T17:09:07Z",
            "published": "2023-11-14T17:09:07Z",
            "summary": "In this paper, we introduce a massively multilingual speech corpora with\nfine-grained phonemic transcriptions, encompassing more than 115 languages from\ndiverse language families. Based on this multilingual dataset, we propose\nCLAP-IPA, a multilingual phoneme-speech contrastive embedding model capable of\nopen-vocabulary matching between speech signals and phonemically transcribed\nkeywords or arbitrary phrases. The proposed model has been tested on two\nfieldwork speech corpora in 97 unseen languages, exhibiting strong\ngeneralizability across languages. Comparison with a text-based model shows\nthat using phonemes as modeling units enables much better crosslinguistic\ngeneralization than orthographic texts.",
            "author": [
                "Jian Zhu",
                "Farhan Samir",
                "Changbing Yang",
                "Jahurul Islam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08323v1",
                "http://arxiv.org/pdf/2311.08323v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08322v1",
            "title": "GT4Py: High Performance Stencils for Weather and Climate Applications\n  using Python",
            "updated": "2023-11-14T17:07:24Z",
            "published": "2023-11-14T17:07:24Z",
            "summary": "All major weather and climate applications are currently developed using\nlanguages such as Fortran or C++. This is typical in the domain of high\nperformance computing (HPC), where efficient execution is an important concern.\nUnfortunately, this approach leads to implementations that intermix\noptimizations for specific hardware architectures with the high-level numerical\nmethods that are typical for the domain. This leads to code that is verbose,\ndifficult to extend and maintain, and difficult to port to different hardware\narchitectures. Here, we propose a different strategy based on GT4Py (GridTools\nfor Python). GT4Py is a Python framework to write weather and climate\napplications that includes a high-level embedded domain specific language (DSL)\nto write stencil computations. The toolchain integrated in GT4Py enables\nautomatic code-generation,to obtain the performance of state-of-the-art C++ and\nCUDA implementations. The separation of concerns between the mathematical\ndefinitions and the actual implementations allows for performance portability\nof the computations on a wide range of computing architectures, while being\nembedded in Python allows easy access to the tools of the Python ecosystem to\nenhance the productivity of the scientists and facilitate integration in\ncomplex workflows. Here, the initial release of GT4Py is described, providing\nan overview of the current state of the framework and performance results\nshowing how GT4Py can outperform pure Python implementations by orders of\nmagnitude.",
            "author": [
                "Enrique G. Paredes",
                "Linus Groner",
                "Stefano Ubbiali",
                "Hannes Vogt",
                "Alberto Madonna",
                "Kean Mariotti",
                "Felipe Cruz",
                "Lucas Benedicic",
                "Mauro Bianco",
                "Joost VandeVondele",
                "Thomas C. Schulthess"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08322v1",
                "http://arxiv.org/pdf/2311.08322v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.PL",
                "68",
                "I.6.5; I.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08321v1",
            "title": "Peak Estimation of Rational Systems using Convex Optimization",
            "updated": "2023-11-14T17:05:49Z",
            "published": "2023-11-14T17:05:49Z",
            "summary": "This paper presents algorithms that upper-bound the peak value of a state\nfunction along trajectories of a continuous-time system with rational dynamics.\nThe finite-dimensional but nonconvex peak estimation problem is cast as a\nconvex infinite-dimensional linear program in occupation measures. This\ninfinite-dimensional program is then truncated into finite-dimensions using the\nmoment-Sum-of-Squares (SOS) hierarchy of semidefinite programs. Prior work on\ntreating rational dynamics using the moment-SOS approach involves clearing\ndynamics to common denominators or by adding lifting variables to handle\nreciprocal terms under new equality constraints. Our solution method uses a\nsum-of-rational method based on absolute continuity of measures. The Moment-SOS\ntruncations of our program possess lower computational complexity and\n(empirically demonstrated) higher accuracy of upper bounds on example systems\nas compared to prior approaches.",
            "author": [
                "Jared Miller",
                "Roy S. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08321v1",
                "http://arxiv.org/pdf/2311.08321v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08319v1",
            "title": "Resource Efficient Over-the-Air Fronthaul Signaling for Uplink Cell-Free\n  Massive MIMO Systems",
            "updated": "2023-11-14T17:03:52Z",
            "published": "2023-11-14T17:03:52Z",
            "summary": "We propose a novel resource efficient analog over-the-air (OTA) computation\nframework to address the demanding requirements of the uplink (UL) fronthaul\nbetween the access points (APs) and the central processing unit (CPU) in\ncell-free massive multiple-input multiple-output (MIMO) systems. We discuss the\ndrawbacks of the wired and wireless fronthaul solutions, and show that our\nproposed mechanism is efficient and scalable as the number of APs increases. We\npresent the transmit precoding and two-phase power assignment strategies at the\nAPs to coherently combine the signals OTA in a spectrally efficient manner. We\nderive the statistics of the APs locally available signals which enable us to\nto obtain the analytical expressions for the Bayesian and classical estimators\nof the OTA combined signals. We empirically evaluate the normalized mean square\nerror (NMSE), symbol error rate (SER), and the coded bit error rate (BER) of\nour developed solution and benchmark against the state-of-the-art wired\nfronthaul based system",
            "author": [
                "Zakir Hussain Shaik",
                "Sai Subramanyam Thoota",
                "Emil Bj\u00f6rnson",
                "Erik G. Larsson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08319v1",
                "http://arxiv.org/pdf/2311.08319v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08318v1",
            "title": "Electromagnetically Induced Transparency (EIT) aided cooling of\n  strontium atoms",
            "updated": "2023-11-14T17:03:29Z",
            "published": "2023-11-14T17:03:29Z",
            "summary": "The presence of ultra-narrow inter-combination spectroscopic lines in\nalkaline earth elements places them as promising candidates for optical atomic\nclocks, quantum computation, and for probing fundmental physics. Doppler\ncooling of these atoms is typically achieved through two subsequent stages: the\ninitial cooling is on the 1s0-1p1 transition followed by cooling using the\nnarrow-line 1s0-3p1 transition. However, due to significantly lower linewidth\nof the second stage cooling transition, efficient transfer of atoms into the\nsecond stage becomes technically challenging. The velocity distribution of the\natoms after the first stage of cooling is too broad for atoms to be captured\nefficiently in the second stage cooling. As a result, the capture efficiency of\natoms into the second stage Magneto-Optical Trap is low, even if the linewidth\nof the second stage cooling laser is artificially broadened.",
            "author": [
                "Korak Biswas",
                "Kushal Patel",
                "S. Sagar Maurya",
                "Pranab Dutta",
                "Umakant D. Rapol",
                "Yeshpal Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08318v1",
                "http://arxiv.org/pdf/2311.08318v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09252v1",
            "title": "In the Red(dit): Social Media and Stock Prices",
            "updated": "2023-11-14T16:58:41Z",
            "published": "2023-11-14T16:58:41Z",
            "summary": "Spearheaded by retail traders on the website reddit, the GameStop short\nsqueeze of early 2021 shows that social media embeds information that\ncorrelates with market movements. This paper seeks to examine this relationship\nby using daily frequencies of classified comments and buzzwords as additional\nfactors in a Fama-French three factor model. Comments are classified using an\nunsupervised clustering method, while past studies have used pretrained models\nthat are not specific to the domains being studied.",
            "author": [
                "James Baker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09252v1",
                "http://arxiv.org/pdf/2311.09252v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08314v1",
            "title": "Convolutional Neural Networks Exploiting Attributes of Biological\n  Neurons",
            "updated": "2023-11-14T16:58:18Z",
            "published": "2023-11-14T16:58:18Z",
            "summary": "In this era of artificial intelligence, deep neural networks like\nConvolutional Neural Networks (CNNs) have emerged as front-runners, often\nsurpassing human capabilities. These deep networks are often perceived as the\npanacea for all challenges. Unfortunately, a common downside of these networks\nis their ''black-box'' character, which does not necessarily mirror the\noperation of biological neural systems. Some even have millions/billions of\nlearnable (tunable) parameters, and their training demands extensive data and\ntime.\n  Here, we integrate the principles of biological neurons in certain layer(s)\nof CNNs. Specifically, we explore the use of neuro-science-inspired\ncomputational models of the Lateral Geniculate Nucleus (LGN) and simple cells\nof the primary visual cortex. By leveraging such models, we aim to extract\nimage features to use as input to CNNs, hoping to enhance training efficiency\nand achieve better accuracy. We aspire to enable shallow networks with a\nPush-Pull Combination of Receptive Fields (PP-CORF) model of simple cells as\nthe foundation layer of CNNs to enhance their learning process and performance.\nTo achieve this, we propose a two-tower CNN, one shallow tower and the other as\nResNet 18. Rather than extracting the features blindly, it seeks to mimic how\nthe brain perceives and extracts features. The proposed system exhibits a\nnoticeable improvement in the performance (on an average of $5\\%-10\\%$) on\nCIFAR-10, CIFAR-100, and ImageNet-100 datasets compared to ResNet-18. We also\ncheck the efficiency of only the Push-Pull tower of the network.",
            "author": [
                "Neeraj Kumar Singh",
                "Nikhil R. Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08314v1",
                "http://arxiv.org/pdf/2311.08314v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08308v1",
            "title": "The Heat is On: Thermal Facial Landmark Tracking",
            "updated": "2023-11-14T16:53:45Z",
            "published": "2023-11-14T16:53:45Z",
            "summary": "Facial landmark tracking for thermal images requires tracking certain\nimportant regions of subjects' faces, using images from thermal images, which\nomit lighting and shading, but show the temperatures of their subjects. The\nfluctuations of heat in particular places reflect physiological changes like\nbloodflow and perspiration, which can be used to remotely gauge things like\nanxiety and excitement. Past work in this domain has been limited to only a\nvery limited set of architectures and techniques. This work goes further by\ntrying a comprehensive suit of various models with different components, such\nas residual connections, channel and feature-wise attention, as well as the\npractice of ensembling components of the network to work in parallel. The best\nmodel integrated convolutional and residual layers followed by a channel-wise\nself-attention layer, requiring less than 100K parameters.",
            "author": [
                "James Baker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08308v1",
                "http://arxiv.org/pdf/2311.08308v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08306v1",
            "title": "On-the-Fly Fusion of Large Language Models and Machine Translation",
            "updated": "2023-11-14T16:49:33Z",
            "published": "2023-11-14T16:49:33Z",
            "summary": "We propose the on-the-fly ensembling of a machine translation model with an\nLLM, prompted on the same task and input. We perform experiments on 4 language\npairs (both directions) with varying data amounts. We find that a slightly\nweaker-at-translation LLM can improve translations of a NMT model, and\nensembling with an LLM can produce better translations than ensembling two\nstronger MT models. We combine our method with various techniques from LLM\nprompting, such as in context learning and translation context.",
            "author": [
                "Hieu Hoang",
                "Huda Khayrallah",
                "Marcin Junczys-Dowmunt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08306v1",
                "http://arxiv.org/pdf/2311.08306v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08305v1",
            "title": "Optimally Managing the Impacts of Convergence Tolerance for Distributed\n  Optimal Power Flow",
            "updated": "2023-11-14T16:49:09Z",
            "published": "2023-11-14T16:49:09Z",
            "summary": "The future power grid may rely on distributed optimization to determine the\nset-points for huge numbers of distributed energy resources. There has been\nsignificant work on applying distributed algorithms to optimal power flow (OPF)\nproblems, which require separate computing agents to agree on shared boundary\nvariable values. Looser tolerances for the mismatches in these shared variables\ngenerally yield faster convergence at the expense of exacerbating constraint\nviolations, but there is little quantitative understanding of how the\nconvergence tolerance affects solution quality. To address this gap, we first\nquantify how convergence tolerance impacts constraint violations when the\ndistributed OPF generator dispatch is applied to the power system. Using\ninsights from this analysis, we then develop a bound tightening algorithm which\nguarantees that operating points from distributed OPF algorithms will not\nresult in violations despite the possibility of shared variable mismatches\nwithin the convergence tolerance. We also explore how bounding the cumulative\nshared variable mismatches can prevent unnecessary conservativeness in the\nbound tightening. The proposed approach enables control of the trade-off\nbetween computational speed, which improves as the convergence tolerance\nincreases, and distributed OPF solution cost, which increases with convergence\ntolerance due to tightened constraints, while ensuring feasibility.",
            "author": [
                "Rachel Harris",
                "Mohannad Alkhraijah",
                "Daniel K. Molzahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08305v1",
                "http://arxiv.org/pdf/2311.08305v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08303v1",
            "title": "Extrinsically-Focused Evaluation of Omissions in Medical Summarization",
            "updated": "2023-11-14T16:46:15Z",
            "published": "2023-11-14T16:46:15Z",
            "summary": "The goal of automated summarization techniques (Paice, 1990; Kupiec et al,\n1995) is to condense text by focusing on the most critical information.\nGenerative large language models (LLMs) have shown to be robust summarizers,\nyet traditional metrics struggle to capture resulting performance (Goyal et al,\n2022) in more powerful LLMs. In safety-critical domains such as medicine, more\nrigorous evaluation is required, especially given the potential for LLMs to\nomit important information in the resulting summary. We propose MED-OMIT, a new\nomission benchmark for medical summarization. Given a doctor-patient\nconversation and a generated summary, MED-OMIT categorizes the chat into a set\nof facts and identifies which are omitted from the summary. We further propose\nto determine fact importance by simulating the impact of each fact on a\ndownstream clinical task: differential diagnosis (DDx) generation. MED-OMIT\nleverages LLM prompt-based approaches which categorize the importance of facts\nand cluster them as supporting or negating evidence to the diagnosis. We\nevaluate MED-OMIT on a publicly-released dataset of patient-doctor\nconversations and find that MED-OMIT captures omissions better than alternative\nmetrics.",
            "author": [
                "Elliot Schumacher",
                "Daniel Rosenthal",
                "Varun Nair",
                "Luladay Price",
                "Geoffrey Tso",
                "Anitha Kannan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08303v1",
                "http://arxiv.org/pdf/2311.08303v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08300v1",
            "title": "Workflow-Guided Response Generation for Task-Oriented Dialogue",
            "updated": "2023-11-14T16:44:33Z",
            "published": "2023-11-14T16:44:33Z",
            "summary": "Task-oriented dialogue (TOD) systems aim to achieve specific goals through\ninteractive dialogue. Such tasks usually involve following specific workflows,\ni.e. executing a sequence of actions in a particular order. While prior work\nhas focused on supervised learning methods to condition on past actions, they\ndo not explicitly optimize for compliance to a desired workflow. In this paper,\nwe propose a novel framework based on reinforcement learning (RL) to generate\ndialogue responses that are aligned with a given workflow. Our framework\nconsists of ComplianceScorer, a metric designed to evaluate how well a\ngenerated response executes the specified action, combined with an RL\nopimization process that utilizes an interactive sampling technique. We\nevaluate our approach on two TOD datasets, Action-Based Conversations Dataset\n(ABCD) (Chen et al., 2021a) and MultiWOZ 2.2 (Zang et al., 2020) on a range of\nautomated and human evaluation metrics. Our findings indicate that our RL-based\nframework outperforms baselines and is effective at enerating responses that\nboth comply with the intended workflows while being expressed in a natural and\nfluent manner.",
            "author": [
                "Do June Min",
                "Paloma Sodhi",
                "Ramya Ramakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08300v1",
                "http://arxiv.org/pdf/2311.08300v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08299v1",
            "title": "VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing",
            "updated": "2023-11-14T16:44:16Z",
            "published": "2023-11-14T16:44:16Z",
            "summary": "Reflective listening is a fundamental skill that counselors must acquire to\nachieve proficiency in motivational interviewing (MI). It involves responding\nin a manner that acknowledges and explores the meaning of what the client has\nexpressed in the conversation. In this work, we introduce the task of\ncounseling response rewriting, which transforms non-reflective statements into\nreflective responses. We introduce VERVE, a template-based rewriting system\nwith paraphrase-augmented training and adaptive template updating. VERVE first\ncreates a template by identifying and filtering out tokens that are not\nrelevant to reflections and constructs a reflective response using the\ntemplate. Paraphrase-augmented training allows the model to learn less-strict\nfillings of masked spans, and adaptive template updating helps discover\neffective templates for rewriting without significantly removing the original\ncontent. Using both automatic and human evaluations, we compare our method\nagainst text rewriting baselines and show that our framework is effective in\nturning non-reflective statements into more reflective responses while\nachieving a good content preservation-reflection style trade-off.",
            "author": [
                "Do June Min",
                "Ver\u00f3nica P\u00e9rez-Rosas",
                "Kenneth Resnicow",
                "Rada Mihalcea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08299v1",
                "http://arxiv.org/pdf/2311.08299v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08298v1",
            "title": "A Survey of Language Model Confidence Estimation and Calibration",
            "updated": "2023-11-14T16:43:29Z",
            "published": "2023-11-14T16:43:29Z",
            "summary": "Language models (LMs) have demonstrated remarkable capabilities across a wide\nrange of tasks in various domains. Despite their impressive performance, the\nreliability of their output is concerning and questionable regarding the demand\nfor AI safety. Assessing the confidence of LM predictions and calibrating them\nacross different tasks with the aim to align LM confidence with accuracy can\nhelp mitigate risks and enable LMs to make better decisions. There have been\nvarious works in this respect, but there has been no comprehensive overview of\nthis important research area. The present survey aims to bridge this gap. In\nparticular, we discuss methods and techniques for LM confidence estimation and\ncalibration, encompassing different LMs and various tasks. We further outline\nthe challenges of estimating the confidence for large language models and we\nsuggest some promising directions for future work.",
            "author": [
                "Jiahui Geng",
                "Fengyu Cai",
                "Yuxia Wang",
                "Heinz Koeppl",
                "Preslav Nakov",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08298v1",
                "http://arxiv.org/pdf/2311.08298v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08291v1",
            "title": "Distribution of quantum gravity induced entanglement in many-body\n  systems",
            "updated": "2023-11-14T16:37:32Z",
            "published": "2023-11-14T16:37:32Z",
            "summary": "Recently, it was shown that two distant test masses, each prepared in a\nspatially superposed quantum state, become entangled through their mutual\ngravitational interaction. This entanglement, it was argued, is a signature of\nthe quantum nature of gravity. We extend this treatment to a many-body system\nin a general setup and study the entanglement properties of the time-evolved\nstate. We exactly compute the time-dependent I-concurrence for every\nbipartition and obtain the necessary and sufficient condition for the creation\nof genuine many-body entanglement. We further show that this entanglement is of\ngeneralised GHZ type when certain conditions are met. We also evaluate the\namount of multipartite entanglement in the system using a set of generalised\nMeyer-Wallach measures.",
            "author": [
                "Pratik Ghosal",
                "Arkaprabha Ghosal",
                "Somshubhro Bandyopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08291v1",
                "http://arxiv.org/pdf/2311.08291v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08287v1",
            "title": "How Well Do Large Language Models Understand Syntax? An Evaluation by\n  Asking Natural Language Questions",
            "updated": "2023-11-14T16:30:36Z",
            "published": "2023-11-14T16:30:36Z",
            "summary": "While recent advancements in large language models (LLMs) bring us closer to\nachieving artificial general intelligence, the question persists: Do LLMs truly\nunderstand language, or do they merely mimic comprehension through pattern\nrecognition? This study seeks to explore this question through the lens of\nsyntax, a crucial component of sentence comprehension. Adopting a natural\nlanguage question-answering (Q&A) scheme, we craft questions targeting nine\nsyntactic knowledge points that are most closely related to sentence\ncomprehension. Experiments conducted on 24 LLMs suggest that most have a\nlimited grasp of syntactic knowledge, exhibiting notable discrepancies across\ndifferent syntactic knowledge points. In particular, questions involving\nprepositional phrase attachment pose the greatest challenge, whereas those\nconcerning adjectival modifier and indirect object are relatively easier for\nLLMs to handle. Furthermore, a case study on the training dynamics of the LLMs\nreveals that the majority of syntactic knowledge is learned during the initial\nstages of training, hinting that simply increasing the number of training\ntokens may not be the `silver bullet' for improving the comprehension ability\nof LLMs.",
            "author": [
                "Houquan Zhou",
                "Yang Hou",
                "Zhenghua Li",
                "Xuebin Wang",
                "Zhefeng Wang",
                "Xinyu Duan",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08287v1",
                "http://arxiv.org/pdf/2311.08287v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08284v1",
            "title": "Level Set KSVD",
            "updated": "2023-11-14T16:27:33Z",
            "published": "2023-11-14T16:27:33Z",
            "summary": "We present a new algorithm for image segmentation - Level-set KSVD. Level-set\nKSVD merges the methods of sparse dictionary learning for feature extraction\nand variational level-set method for image segmentation. Specifically, we use a\ngeneralization of the Chan-Vese functional with features learned by KSVD. The\nmotivation for this model is agriculture based. Aerial images are taken in\norder to detect the spread of fungi in various crops. Our model is tested on\nsuch images of cotton fields. The results are compared to other methods.",
            "author": [
                "Omer Sapir",
                "Iftach Klapp",
                "Nir Sochen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08284v1",
                "http://arxiv.org/pdf/2311.08284v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08278v1",
            "title": "ARTEMIS: Using GANs with Multiple Discriminators to Generate Art",
            "updated": "2023-11-14T16:19:29Z",
            "published": "2023-11-14T16:19:29Z",
            "summary": "We propose a novel method for generating abstract art. First an autoencoder\nis trained to encode and decode the style representations of images, which are\nextracted from source images with a pretrained VGG network. Then, the decoder\ncomponent of the autoencoder is extracted and used as a generator in a GAN. The\ngenerator works with an ensemble of discriminators. Each discriminator takes\ndifferent style representations of the same images, and the generator is\ntrained to create images that create convincing style representations in order\nto deceive all of the generators. The generator is also trained to maximize a\ndiversity term. The resulting images had a surreal, geometric quality. We call\nour approach ARTEMIS (ARTistic Encoder- Multi- Discriminators Including\nSelf-Attention), as it uses the self-attention layers and an encoder-decoder\narchitecture.",
            "author": [
                "James Baker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08278v1",
                "http://arxiv.org/pdf/2311.08278v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08273v1",
            "title": "Examining Modularity in Multilingual LMs via Language-Specialized\n  Subnetworks",
            "updated": "2023-11-14T16:11:23Z",
            "published": "2023-11-14T16:11:23Z",
            "summary": "Recent work has proposed explicitly inducing language-wise modularity in\nmultilingual LMs via sparse fine-tuning (SFT) on per-language subnetworks as a\nmeans of better guiding cross-lingual sharing. In this work, we investigate (1)\nthe degree to which language-wise modularity naturally arises within models\nwith no special modularity interventions, and (2) how cross-lingual sharing and\ninterference differ between such models and those with explicit SFT-guided\nsubnetwork modularity. To quantify language specialization and cross-lingual\ninteraction, we use a Training Data Attribution method that estimates the\ndegree to which a model's predictions are influenced by in-language or\ncross-language training examples. Our results show that language-specialized\nsubnetworks do naturally arise, and that SFT, rather than always increasing\nmodularity, can decrease language specialization of subnetworks in favor of\nmore cross-lingual sharing.",
            "author": [
                "Rochelle Choenni",
                "Ekaterina Shutova",
                "Dan Garrette"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08273v1",
                "http://arxiv.org/pdf/2311.08273v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08269v2",
            "title": "Defining the boundaries: challenges and advances in identifying cells in\n  microscopy images",
            "updated": "2023-11-28T17:18:44Z",
            "published": "2023-11-14T16:02:18Z",
            "summary": "Segmentation, or the outlining of objects within images, is a critical step\nin the measurement and analysis of cells within microscopy images. While\nimprovements continue to be made in tools that rely on classical methods for\nsegmentation, deep learning-based tools increasingly dominate advances in the\ntechnology. Specialist models such as Cellpose continue to improve in accuracy\nand user-friendliness, and segmentation challenges such as the Multi-Modality\nCell Segmentation Challenge continue to push innovation in accuracy across\nwidely-varying test data as well as efficiency and usability. Increased\nattention on documentation, sharing, and evaluation standards are leading to\nincreased user-friendliness and acceleration towards the goal of a truly\nuniversal method.",
            "author": [
                "Nodar Gogoberidze",
                "Beth A. Cimini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08269v2",
                "http://arxiv.org/pdf/2311.08269v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08268v1",
            "title": "A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can\n  Fool Large Language Models Easily",
            "updated": "2023-11-14T16:02:16Z",
            "published": "2023-11-14T16:02:16Z",
            "summary": "Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to\nprovide useful and safe responses. However, adversarial prompts known as\n'jailbreaks' can circumvent safeguards, leading LLMs to generate harmful\ncontent. Exploring jailbreak prompts can help to better reveal the weaknesses\nof LLMs and further steer us to secure them. Unfortunately, existing jailbreak\nmethods either suffer from intricate manual design or require optimization on\nanother white-box model, compromising generalization or jailbreak efficiency.\nIn this paper, we generalize jailbreak prompt attacks into two aspects: (1)\nPrompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM,\nan automatic framework that leverages LLMs themselves to generate effective\njailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantly\nimproves the attack success rate while greatly reducing the time cost compared\nto existing baselines. Our study also reveals the inadequacy of current defense\nmethods in safeguarding LLMs. Finally, we offer detailed analysis and\ndiscussion from the perspective of prompt execution priority on the failure of\nLLMs' defense. We hope that our research can catalyze both the academic\ncommunity and LLMs vendors towards the provision of safer and more regulated\nLarge Language Models.",
            "author": [
                "Peng Ding",
                "Jun Kuang",
                "Dan Ma",
                "Xuezhi Cao",
                "Yunsen Xian",
                "Jiajun Chen",
                "Shujian Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08268v1",
                "http://arxiv.org/pdf/2311.08268v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08265v1",
            "title": "On The Relationship Between Universal Adversarial Attacks And Sparse\n  Representations",
            "updated": "2023-11-14T16:00:29Z",
            "published": "2023-11-14T16:00:29Z",
            "summary": "The prominent success of neural networks, mainly in computer vision tasks, is\nincreasingly shadowed by their sensitivity to small, barely perceivable\nadversarial perturbations in image input.\n  In this work, we aim at explaining this vulnerability through the framework\nof sparsity.\n  We show the connection between adversarial attacks and sparse\nrepresentations, with a focus on explaining the universality and\ntransferability of adversarial examples in neural networks.\n  To this end, we show that sparse coding algorithms, and the neural\nnetwork-based learned iterative shrinkage thresholding algorithm (LISTA) among\nthem, suffer from this sensitivity, and that common attacks on neural networks\ncan be expressed as attacks on the sparse representation of the input image.\nThe phenomenon that we observe holds true also when the network is agnostic to\nthe sparse representation and dictionary, and thus can provide a possible\nexplanation for the universality and transferability of adversarial attacks.\n  The code is available at\nhttps://github.com/danawr/adversarial_attacks_and_sparse_representations.",
            "author": [
                "Dana Weitzner",
                "Raja Giryes"
            ],
            "link": [
                "http://dx.doi.org/10.1109/OJSP.2023.3244486",
                "http://arxiv.org/abs/2311.08265v1",
                "http://arxiv.org/pdf/2311.08265v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08263v1",
            "title": "Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads\n  to Answers Faster",
            "updated": "2023-11-14T15:56:18Z",
            "published": "2023-11-14T15:56:18Z",
            "summary": "In this work, we propose FastCoT, a model-agnostic framework based on\nparallel decoding without any further training of an auxiliary model or\nmodification to the LLM itself. FastCoT uses a size-varying context window\nwhose size changes with position to conduct parallel decoding and\nauto-regressive decoding simultaneously, thus fully utilizing GPU computation\nresources. In FastCoT, the parallel decoding part provides the LLM with a quick\nglance of the future composed of approximate tokens, which could lead to faster\nanswers compared to regular autoregressive decoding used by causal\ntransformers. We also provide an implementation of parallel decoding within\nLLM, which supports KV-cache generation and batch processing. Through extensive\nexperiments, we demonstrate that FastCoT saves inference time by nearly 20%\nwith only a negligible performance drop compared to the regular approach.\nAdditionally, we show that the context window size exhibits considerable\nrobustness for different tasks.",
            "author": [
                "Hongxuan Zhang",
                "Zhining Liu",
                "Jiaqi Zheng",
                "Chenyi Zhuang",
                "Jinjie Gu",
                "Guihai Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08263v1",
                "http://arxiv.org/pdf/2311.08263v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08254v1",
            "title": "Identifiable and interpretable nonparametric factor analysis",
            "updated": "2023-11-14T15:49:29Z",
            "published": "2023-11-14T15:49:29Z",
            "summary": "Factor models have been widely used to summarize the variability of\nhigh-dimensional data through a set of factors with much lower dimensionality.\nGaussian linear factor models have been particularly popular due to their\ninterpretability and ease of computation. However, in practice, data often\nviolate the multivariate Gaussian assumption. To characterize higher-order\ndependence and nonlinearity, models that include factors as predictors in\nflexible multivariate regression are popular, with GP-LVMs using Gaussian\nprocess (GP) priors for the regression function and VAEs using deep neural\nnetworks. Unfortunately, such approaches lack identifiability and\ninterpretability and tend to produce brittle and non-reproducible results. To\naddress these problems by simplifying the nonparametric factor model while\nmaintaining flexibility, we propose the NIFTY framework, which parsimoniously\ntransforms uniform latent variables using one-dimensional nonlinear mappings\nand then applies a linear generative model. The induced multivariate\ndistribution falls into a flexible class while maintaining simple computation\nand interpretation. We prove that this model is identifiable and empirically\nstudy NIFTY using simulated data, observing good performance in density\nestimation and data visualization. We then apply NIFTY to bird song data in an\nenvironmental monitoring application.",
            "author": [
                "Maoran Xu",
                "Amy H. Herring",
                "David B. Dunson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08254v1",
                "http://arxiv.org/pdf/2311.08254v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08253v1",
            "title": "The Impact of Dust on Cepheid and Type Ia Supernova Distances",
            "updated": "2023-11-14T15:48:39Z",
            "published": "2023-11-14T15:48:39Z",
            "summary": "Milky-Way and intergalactic dust extinction and reddening must be accounted\nfor in measurements of distances throughout the universe. This work provides a\ncomprehensive review of the various impacts of cosmic dust focusing\nspecifically on its effects on two key distance indicators used in the distance\nladder: Cepheid variable stars and Type Ia supernovae. We review the formalism\nused for computing and accounting for dust extinction and reddening as a\nfunction of wavelength. We also detail the current state of the art knowledge\nof dust properties in the Milky Way and in host galaxies. We discuss how dust\nhas been accounted for in both the Cepheid and SN distance measurements.\nFinally, we show how current uncertainties on dust modeling impact the inferred\nluminosities and distances, but that measurements of the Hubble constant remain\nrobust to these uncertainties.",
            "author": [
                "Dillon Brout",
                "Adam Riess"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08253v1",
                "http://arxiv.org/pdf/2311.08253v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14708v1",
            "title": "Large Language Model-Driven Classroom Flipping: Empowering\n  Student-Centric Peer Questioning with Flipped Interaction",
            "updated": "2023-11-14T15:48:19Z",
            "published": "2023-11-14T15:48:19Z",
            "summary": "Reciprocal questioning is essential for effective teaching and learning,\nfostering active engagement and deeper understanding through collaborative\ninteractions, especially in large classrooms. Can large language model (LLM),\nsuch as OpenAI's GPT (Generative Pre-trained Transformer) series, assist in\nthis? This paper investigates a pedagogical approach of classroom flipping\nbased on flipped interaction in LLMs. Flipped interaction involves using\nlanguage models to prioritize generating questions instead of answers to\nprompts. We demonstrate how traditional classroom flipping techniques,\nincluding Peer Instruction and Just-in-Time Teaching (JiTT), can be enhanced\nthrough flipped interaction techniques, creating student-centric questions for\nhybrid teaching. In particular, we propose a workflow to integrate prompt\nengineering with clicker and JiTT quizzes by a poll-prompt-quiz routine and a\nquiz-prompt-discuss routine to empower students to self-regulate their learning\ncapacity and enable teachers to swiftly personalize training pathways. We\ndevelop an LLM-driven chatbot software that digitizes various elements of\nclassroom flipping and facilitates the assessment of students using these\nroutines to deliver peer-generated questions. We have applied our LLM-driven\nchatbot software for teaching both undergraduate and graduate students from\n2020 to 2022, effectively useful for bridging the gap between teachers and\nstudents in remote teaching during the COVID-19 pandemic years. In particular,\nLLM-driven classroom flipping can be particularly beneficial in large class\nsettings to optimize teaching pace and enable engaging classroom experiences.",
            "author": [
                "Chee Wei Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14708v1",
                "http://arxiv.org/pdf/2311.14708v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08252v1",
            "title": "REST: Retrieval-Based Speculative Decoding",
            "updated": "2023-11-14T15:43:47Z",
            "published": "2023-11-14T15:43:47Z",
            "summary": "We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm\ndesigned to speed up language model generation. The key insight driving the\ndevelopment of REST is the observation that the process of text generation\noften includes certain common phases and patterns. Unlike previous methods that\nrely on a draft language model for speculative decoding, REST harnesses the\npower of retrieval to generate draft tokens. This method draws from the\nreservoir of existing knowledge, retrieving and employing relevant tokens based\non the current context. Its plug-and-play nature allows for seamless\nintegration and acceleration of any language models, all without necessitating\nadditional training. When benchmarked on 7B and 13B language models in a\nsingle-batch setting, REST achieves a significant speedup of 1.62X to 2.36X on\ncode or text generation. The code of REST is available at\nhttps://github.com/FasterDecoding/REST.",
            "author": [
                "Zhenyu He",
                "Zexuan Zhong",
                "Tianle Cai",
                "Jason D Lee",
                "Di He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08252v1",
                "http://arxiv.org/pdf/2311.08252v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08249v1",
            "title": "On Using Distribution-Based Compositionality Assessment to Evaluate\n  Compositional Generalisation in Machine Translation",
            "updated": "2023-11-14T15:37:19Z",
            "published": "2023-11-14T15:37:19Z",
            "summary": "Compositional generalisation (CG), in NLP and in machine learning more\ngenerally, has been assessed mostly using artificial datasets. It is important\nto develop benchmarks to assess CG also in real-world natural language tasks in\norder to understand the abilities and limitations of systems deployed in the\nwild. To this end, our GenBench Collaborative Benchmarking Task submission\nutilises the distribution-based compositionality assessment (DBCA) framework to\nsplit the Europarl translation corpus into a training and a test set in such a\nway that the test set requires compositional generalisation capacity.\nSpecifically, the training and test sets have divergent distributions of\ndependency relations, testing NMT systems' capability of translating\ndependencies that they have not been trained on. This is a fully-automated\nprocedure to create natural language compositionality benchmarks, making it\nsimple and inexpensive to apply it further to other datasets and languages. The\ncode and data for the experiments is available at\nhttps://github.com/aalto-speech/dbca.",
            "author": [
                "Anssi Moisio",
                "Mathias Creutz",
                "Mikko Kurimo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08249v1",
                "http://arxiv.org/pdf/2311.08249v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08245v1",
            "title": "TENT: Connect Language Models with IoT Sensors for Zero-Shot Activity\n  Recognition",
            "updated": "2023-11-14T15:30:17Z",
            "published": "2023-11-14T15:30:17Z",
            "summary": "Recent achievements in language models have showcased their extraordinary\ncapabilities in bridging visual information with semantic language\nunderstanding. This leads us to a novel question: can language models connect\ntextual semantics with IoT sensory signals to perform recognition tasks, e.g.,\nHuman Activity Recognition (HAR)? If so, an intelligent HAR system with\nhuman-like cognition can be built, capable of adapting to new environments and\nunseen categories. This paper explores its feasibility with an innovative\napproach, IoT-sEnsors-language alignmEnt pre-Training (TENT), which jointly\naligns textual embeddings with IoT sensor signals, including camera video,\nLiDAR, and mmWave. Through the IoT-language contrastive learning, we derive a\nunified semantic feature space that aligns multi-modal features with language\nembeddings, so that the IoT data corresponds to specific words that describe\nthe IoT data. To enhance the connection between textual categories and their\nIoT data, we propose supplementary descriptions and learnable prompts that\nbring more semantic information into the joint feature space. TENT can not only\nrecognize actions that have been seen but also ``guess'' the unseen action by\nthe closest textual words from the feature space. We demonstrate TENT achieves\nstate-of-the-art performance on zero-shot HAR tasks using different modalities,\nimproving the best vision-language models by over 12%.",
            "author": [
                "Yunjiao Zhou",
                "Jianfei Yang",
                "Han Zou",
                "Lihua Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08245v1",
                "http://arxiv.org/pdf/2311.08245v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08241v1",
            "title": "Split-explicit external mode solver in finite volume sea ice ocean model\n  FESOM2",
            "updated": "2023-11-14T15:24:17Z",
            "published": "2023-11-14T15:24:17Z",
            "summary": "A novel split-explicit (SE) external mode solver for the Finite volumE Sea\nice-Ocean Model (FESOM2) is presented. It is compared with the semi-implicit\n(SI) solver currently used in FESOM2. The SE solver utilises a dissipative\nasynchronous (forward-backward) time-stepping scheme. Its implementation with\nArbitrary Lagrangian-Eulerian (ALE) vertical coordinates like Z-star and\nZ-tilde is explored. The comparisons are performed through multiple test cases\ninvolving idealised and realistic global simulations. The SE solver\ndemonstrates lower phase errors and dissipation, but maintain a simulated mean\nocean state very similar to the SI solver. The SE solver is also shown to\npossess better run-time performance and parallel scalability across all tested\nworkloads.",
            "author": [
                "Tridib Banerjee",
                "Patrick Scholz",
                "Sergey Danilov",
                "Knut Klingbeil",
                "Dimitry Sidorenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08241v1",
                "http://arxiv.org/pdf/2311.08241v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08240v1",
            "title": "Investigating the Encoding of Words in BERT's Neurons using Feature\n  Textualization",
            "updated": "2023-11-14T15:21:49Z",
            "published": "2023-11-14T15:21:49Z",
            "summary": "Pretrained language models (PLMs) form the basis of most state-of-the-art NLP\ntechnologies. Nevertheless, they are essentially black boxes: Humans do not\nhave a clear understanding of what knowledge is encoded in different parts of\nthe models, especially in individual neurons. The situation is different in\ncomputer vision, where feature visualization provides a decompositional\ninterpretability technique for neurons of vision models. Activation\nmaximization is used to synthesize inherently interpretable visual\nrepresentations of the information encoded in individual neurons. Our work is\ninspired by this but presents a cautionary tale on the interpretability of\nsingle neurons, based on the first large-scale attempt to adapt activation\nmaximization to NLP, and, more specifically, large PLMs. We propose feature\ntextualization, a technique to produce dense representations of neurons in the\nPLM word embedding space. We apply feature textualization to the BERT model\n(Devlin et al., 2019) to investigate whether the knowledge encoded in\nindividual neurons can be interpreted and symbolized. We find that the produced\nrepresentations can provide insights about the knowledge encoded in individual\nneurons, but that individual neurons do not represent clearcut symbolic units\nof language such as words. Additionally, we use feature textualization to\ninvestigate how many neurons are needed to encode words in BERT.",
            "author": [
                "Tanja Baeumel",
                "Soniya Vijayakumar",
                "Josef van Genabith",
                "Guenter Neumann",
                "Simon Ostermann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08240v1",
                "http://arxiv.org/pdf/2311.08240v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08239v2",
            "title": "Learning Physics-Inspired Regularization for Medical Image Registration\n  with Hypernetworks",
            "updated": "2023-12-04T08:25:58Z",
            "published": "2023-11-14T15:20:42Z",
            "summary": "Medical image registration aims at identifying the spatial deformation\nbetween images of the same anatomical region and is fundamental to image-based\ndiagnostics and therapy. To date, the majority of the deep learning-based\nregistration methods employ regularizers that enforce global spatial\nsmoothness, e.g., the diffusion regularizer. However, such regularizers are not\ntailored to the data and might not be capable of reflecting the complex\nunderlying deformation. In contrast, physics-inspired regularizers promote\nphysically plausible deformations. One such regularizer is the linear elastic\nregularizer which models the deformation of elastic material. These\nregularizers are driven by parameters that define the material's physical\nproperties. For biological tissue, a wide range of estimations of such\nparameters can be found in the literature and it remains an open challenge to\nidentify suitable parameter values for successful registration. To overcome\nthis problem and to incorporate physical properties into learning-based\nregistration, we propose to use a hypernetwork that learns the effect of the\nphysical parameters of a physics-inspired regularizer on the resulting spatial\ndeformation field. In particular, we adapt the HyperMorph framework to learn\nthe effect of the two elasticity parameters of the linear elastic regularizer.\nOur approach enables the efficient discovery of suitable, data-specific\nphysical parameters at test time.",
            "author": [
                "Anna Reithmeir",
                "Julia A. Schnabel",
                "Veronika A. Zimmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08239v2",
                "http://arxiv.org/pdf/2311.08239v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08236v1",
            "title": "MeLo: Low-rank Adaptation is Better than Fine-tuning for Medical Image\n  Diagnosis",
            "updated": "2023-11-14T15:18:54Z",
            "published": "2023-11-14T15:18:54Z",
            "summary": "The common practice in developing computer-aided diagnosis (CAD) models based\non transformer architectures usually involves fine-tuning from ImageNet\npre-trained weights. However, with recent advances in large-scale pre-training\nand the practice of scaling laws, Vision Transformers (ViT) have become much\nlarger and less accessible to medical imaging communities. Additionally, in\nreal-world scenarios, the deployments of multiple CAD models can be troublesome\ndue to problems such as limited storage space and time-consuming model\nswitching. To address these challenges, we propose a new method MeLo (Medical\nimage Low-rank adaptation), which enables the development of a single CAD model\nfor multiple clinical tasks in a lightweight manner. It adopts low-rank\nadaptation instead of resource-demanding fine-tuning. By fixing the weight of\nViT models and only adding small low-rank plug-ins, we achieve competitive\nresults on various diagnosis tasks across different imaging modalities using\nonly a few trainable parameters. Specifically, our proposed method achieves\ncomparable performance to fully fine-tuned ViT models on four distinct medical\nimaging datasets using about 0.17% trainable parameters. Moreover, MeLo adds\nonly about 0.5MB of storage space and allows for extremely fast model switching\nin deployment and inference. Our source code and pre-trained weights are\navailable on our website (https://absterzhu.github.io/melo.github.io/).",
            "author": [
                "Yitao Zhu",
                "Zhenrong Shen",
                "Zihao Zhao",
                "Sheng Wang",
                "Xin Wang",
                "Xiangyu Zhao",
                "Dinggang Shen",
                "Qian Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08236v1",
                "http://arxiv.org/pdf/2311.08236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08235v1",
            "title": "Inference of Probabilistic Programs with Moment-Matching Gaussian\n  Mixtures",
            "updated": "2023-11-14T15:18:15Z",
            "published": "2023-11-14T15:18:15Z",
            "summary": "Computing the posterior distribution of a probabilistic program is a hard\ntask for which no one-fit-for-all solution exists. We propose Gaussian\nSemantics, which approximates the exact probabilistic semantics of a bounded\nprogram by means of Gaussian mixtures. It is parametrized by a map that\nassociates each program location with the moment order to be matched in the\napproximation. We provide two main contributions. The first is a universal\napproximation theorem stating that, under mild conditions, Gaussian Semantics\ncan approximate the exact semantics arbitrarily closely. The second is an\napproximation that matches up to second-order moments analytically in face of\nthe generally difficult problem of matching moments of Gaussian mixtures with\narbitrary moment order. We test our second-order Gaussian approximation (SOGA)\non a number of case studies from the literature. We show that it can provide\naccurate estimates in models not supported by other approximation methods or\nwhen exact symbolic techniques fail because of complex expressions or\nnon-simplified integrals. On two notable classes of problems, namely\ncollaborative filtering and programs involving mixtures of continuous and\ndiscrete distributions, we show that SOGA significantly outperforms alternative\ntechniques in terms of accuracy and computational time.",
            "author": [
                "Francesca Randone",
                "Luca Bortolussi",
                "Emilio Incerto",
                "Mirco Tribastone"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3632905",
                "http://arxiv.org/abs/2311.08235v1",
                "http://arxiv.org/pdf/2311.08235v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08230v1",
            "title": "Electronic bandstructure of superconducting KTaO3 (111) interfaces",
            "updated": "2023-11-14T15:10:58Z",
            "published": "2023-11-14T15:10:58Z",
            "summary": "Two-dimensional electron gases(2DEGs)based on KTaO3 are emerging as a\npromising platform for spin-orbitronics due to their high Rashba spin-orbit\ncoupling (SOC) and gate-voltage tunability. The recent discovery of a\nsuperconducting state in KTaO3 2DEGs now expands their potential towards\ntopological superconductivity. Although the band structure of KTaO3 surfaces of\nvarious crystallographic orientations has already been mapped using\nangle-resolved photoemission spectroscopy(ARPES), this is not the case for\nsuperconducting KTaO3 2DEGs. Here, we reveal the electronic structure of\nsuperconducting 2DEGs based on KTaO3 (111) single crystals through ARPES\nmeasurements. We fit the data with a tight-binding model and compute the\nassociated spin textures to bring insight into the SOC-driven physics of this\nfascinating system.",
            "author": [
                "Srijani Mallik",
                "B\u00f6rge G\u00f6bel",
                "Hugo Witt",
                "Luis M. Vicente-Arche",
                "Sara Varotto",
                "Julien Br\u00e9hin",
                "Gerbold M\u00e9nard",
                "Guilhem Sa\u00efz",
                "Dyhia Tamsaout",
                "Andr\u00e9s Felipe Santander-Syro",
                "Franck Fortuna",
                "Fran\u00e7ois Bertran",
                "Patrick Le F\u00e8vre",
                "Julien Rault",
                "Isabella Boventer",
                "Ingrid Mertig",
                "Agn\u00e8s Barth\u00e9l\u00e9my",
                "Nicolas Bergeal",
                "Annika Johansson",
                "Manuel Bibes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08230v1",
                "http://arxiv.org/pdf/2311.08230v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08439v1",
            "title": "A Unified Approach for Comprehensive Analysis of Various Spectral and\n  Tissue Doppler Echocardiography",
            "updated": "2023-11-14T15:10:05Z",
            "published": "2023-11-14T15:10:05Z",
            "summary": "Doppler echocardiography offers critical insights into cardiac function and\nphases by quantifying blood flow velocities and evaluating myocardial motion.\nHowever, previous methods for automating Doppler analysis, ranging from initial\nsignal processing techniques to advanced deep learning approaches, have been\nconstrained by their reliance on electrocardiogram (ECG) data and their\ninability to process Doppler views collectively. We introduce a novel unified\nframework using a convolutional neural network for comprehensive analysis of\nspectral and tissue Doppler echocardiography images that combines automatic\nmeasurements and end-diastole (ED) detection into a singular method. The\nnetwork automatically recognizes key features across various Doppler views,\nwith novel Doppler shape embedding and anti-aliasing modules enhancing\ninterpretation and ensuring consistent analysis. Empirical results indicate a\nconsistent outperformance in performance metrics, including dice similarity\ncoefficients (DSC) and intersection over union (IoU). The proposed framework\ndemonstrates strong agreement with clinicians in Doppler automatic measurements\nand competitive performance in ED detection.",
            "author": [
                "Jaeik Jeon",
                "Jiyeon Kim",
                "Yeonggul Jang",
                "Yeonyee E. Yoon",
                "Dawun Jeong",
                "Youngtaek Hong",
                "Seung-Ah Lee",
                "Hyuk-Jae Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08439v1",
                "http://arxiv.org/pdf/2311.08439v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08225v1",
            "title": "Uni-COAL: A Unified Framework for Cross-Modality Synthesis and\n  Super-Resolution of MR Images",
            "updated": "2023-11-14T15:05:59Z",
            "published": "2023-11-14T15:05:59Z",
            "summary": "Cross-modality synthesis (CMS), super-resolution (SR), and their combination\n(CMSR) have been extensively studied for magnetic resonance imaging (MRI).\nTheir primary goals are to enhance the imaging quality by synthesizing the\ndesired modality and reducing the slice thickness. Despite the promising\nsynthetic results, these techniques are often tailored to specific tasks,\nthereby limiting their adaptability to complex clinical scenarios. Therefore,\nit is crucial to build a unified network that can handle various image\nsynthesis tasks with arbitrary requirements of modality and resolution\nsettings, so that the resources for training and deploying the models can be\ngreatly reduced. However, none of the previous works is capable of performing\nCMS, SR, and CMSR using a unified network. Moreover, these MRI reconstruction\nmethods often treat alias frequencies improperly, resulting in suboptimal\ndetail restoration. In this paper, we propose a Unified Co-Modulated Alias-free\nframework (Uni-COAL) to accomplish the aforementioned tasks with a single\nnetwork. The co-modulation design of the image-conditioned and stochastic\nattribute representations ensures the consistency between CMS and SR, while\nsimultaneously accommodating arbitrary combinations of input/output modalities\nand thickness. The generator of Uni-COAL is also designed to be alias-free\nbased on the Shannon-Nyquist signal processing framework, ensuring effective\nsuppression of alias frequencies. Additionally, we leverage the semantic prior\nof Segment Anything Model (SAM) to guide Uni-COAL, ensuring a more authentic\npreservation of anatomical structures during synthesis. Experiments on three\ndatasets demonstrate that Uni-COAL outperforms the alternatives in CMS, SR, and\nCMSR tasks for MR images, which highlights its generalizability to wide-range\napplications.",
            "author": [
                "Zhiyun Song",
                "Zengxin Qi",
                "Xin Wang",
                "Xiangyu Zhao",
                "Zhenrong Shen",
                "Sheng Wang",
                "Manman Fei",
                "Zhe Wang",
                "Di Zang",
                "Dongdong Chen",
                "Linlin Yao",
                "Qian Wang",
                "Xuehai Wu",
                "Lichi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08225v1",
                "http://arxiv.org/pdf/2311.08225v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08223v2",
            "title": "Improving Image Captioning via Predicting Structured Concepts",
            "updated": "2023-11-28T04:05:03Z",
            "published": "2023-11-14T15:01:58Z",
            "summary": "Having the difficulty of solving the semantic gap between images and texts\nfor the image captioning task, conventional studies in this area paid some\nattention to treating semantic concepts as a bridge between the two modalities\nand improved captioning performance accordingly. Although promising results on\nconcept prediction were obtained, the aforementioned studies normally ignore\nthe relationship among concepts, which relies on not only objects in the image,\nbut also word dependencies in the text, so that offers a considerable potential\nfor improving the process of generating good descriptions. In this paper, we\npropose a structured concept predictor (SCP) to predict concepts and their\nstructures, then we integrate them into captioning, so as to enhance the\ncontribution of visual signals in this task via concepts and further use their\nrelations to distinguish cross-modal semantics for better description\ngeneration. Particularly, we design weighted graph convolutional networks\n(W-GCN) to depict concept relations driven by word dependencies, and then\nlearns differentiated contributions from these concepts for following decoding\nprocess. Therefore, our approach captures potential relations among concepts\nand discriminatively learns different concepts, so that effectively facilitates\nimage captioning with inherited information across modalities. Extensive\nexperiments and their results demonstrate the effectiveness of our approach as\nwell as each proposed module in this work.",
            "author": [
                "Ting Wang",
                "Weidong Chen",
                "Yuanhe Tian",
                "Yan Song",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08223v2",
                "http://arxiv.org/pdf/2311.08223v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08219v1",
            "title": "Eval-GCSC: A New Metric for Evaluating ChatGPT's Performance in Chinese\n  Spelling Correction",
            "updated": "2023-11-14T14:56:33Z",
            "published": "2023-11-14T14:56:33Z",
            "summary": "ChatGPT has demonstrated impressive performance in various downstream tasks.\nHowever, in the Chinese Spelling Correction (CSC) task, we observe a\ndiscrepancy: while ChatGPT performs well under human evaluation, it scores\npoorly according to traditional metrics. We believe this inconsistency arises\nbecause the traditional metrics are not well-suited for evaluating generative\nmodels. Their overly strict length and phonics constraints may lead to\nunderestimating ChatGPT's correction capabilities. To better evaluate\ngenerative models in the CSC task, this paper proposes a new evaluation metric:\nEval-GCSC. By incorporating word-level and semantic similarity judgments, it\nrelaxes the stringent length and phonics constraints. Experimental results show\nthat Eval-GCSC closely aligns with human evaluations. Under this metric,\nChatGPT's performance is comparable to traditional token-level classification\nmodels (TCM), demonstrating its potential as a CSC tool. The source code and\nscripts can be accessed at https://github.com/ktlKTL/Eval-GCSC.",
            "author": [
                "Kunting Li",
                "Yong Hu",
                "Shaolei Wang",
                "Hanhan Ma",
                "Liang He",
                "Fandong Meng",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08219v1",
                "http://arxiv.org/pdf/2311.08219v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08217v1",
            "title": "Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot\n  Image Generation",
            "updated": "2023-11-14T14:55:42Z",
            "published": "2023-11-14T14:55:42Z",
            "summary": "Few-shot image generation aims to train generative models using a small\nnumber of training images. When there are few images available for training\n(e.g. 10 images), Learning From Scratch (LFS) methods often generate images\nthat closely resemble the training data while Transfer Learning (TL) methods\ntry to improve performance by leveraging prior knowledge from GANs pre-trained\non large-scale datasets. However, current TL methods may not allow for\nsufficient control over the degree of knowledge preservation from the source\nmodel, making them unsuitable for setups where the source and target domains\nare not closely related. To address this, we propose a novel pipeline called\nPeer is your Pillar (PIP), which combines a target few-shot dataset with a peer\ndataset to create a data-unbalanced conditional generation. Our approach\nincludes a class embedding method that separates the class space from the\nlatent space, and we use a direction loss based on pre-trained CLIP to improve\nimage diversity. Experiments on various few-shot datasets demonstrate the\nadvancement of the proposed PIP, especially reduces the training requirements\nof few-shot image generation.",
            "author": [
                "Ziqiang Li",
                "Chaoyue Wang",
                "Xue Rui",
                "Chao Xue",
                "Jiaxu Leng",
                "Bin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08217v1",
                "http://arxiv.org/pdf/2311.08217v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08213v1",
            "title": "Unlock the Power: Competitive Distillation for Multi-Modal Large\n  Language Models",
            "updated": "2023-11-14T14:49:46Z",
            "published": "2023-11-14T14:49:46Z",
            "summary": "Recently, multi-modal content generation has attracted lots of attention from\nresearchers by investigating the utilization of visual instruction tuning based\non large language models (LLMs). To enhance the performance and generalization\nability of such LLMs, the practice of distilling knowledge from pretrained\nmulti-modal models (a.k.a. teachers) to more compact multi-modal LLMs\n(students) has gained considerable interest. However, the prevailing paradigm\nof instructiontuning in multi-modal LLMs knowledge distillation is\nresource-intensive and unidirectional, neglecting the potential for mutual\nfeedback between the student and teacher models. Thus, we propose an innovative\nCompetitive Multi-modal Distillation framework (CoMD), which captures\nbidirectional feedback between teacher and student models and continually\nupdates the multi-modal capabilities that the student model has learned. It\ncomprises two stages: multi-modal pre-training and multi-modal competitive\ndistillation. The first stage pre-trains the student model on a large number of\nfiltered multi-modal datasets. The second stage facilitates a bidirectional\nknowledge transfer between the student and teacher models. Our experimental\nanalysis of diverse datasets shows that our knowledge transfer method\nconsistently improves the capabilities of the student model. Finally, the\n7B-sized student model after four distillations surpassed the current\nstate-of-the-art model LLaVA-13B on the ScienceQA and LLaVA Test dataset, also\noutperforms other strong baselines in the zero-shot setting.",
            "author": [
                "Xinwei Li",
                "Li Lin",
                "Shuai Wang",
                "Chen Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08213v1",
                "http://arxiv.org/pdf/2311.08213v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08208v1",
            "title": "Modular Representations of Truncated current Lie algebras",
            "updated": "2023-11-14T14:44:16Z",
            "published": "2023-11-14T14:44:16Z",
            "summary": "In this paper we consider the structure and representation theory of\ntruncated current algebras $\\mathfrak{g}_m = \\mathfrak{g}[t]/(t^{m+1})$\nassociated to the Lie algebra $\\mathfrak{g}$ of a standard reductive group over\na field of positive characteristic. We classify semisimple and nilpotent\nelements and describe their associated support varieties. Next, we prove\nvarious Morita equivalences for reduced enveloping algebras, including a\nreduction to nilpotent $p$-characters, analogous to a famous theorem of\nFriedlander--Parshall.\n  We go on to give precise upper bounds for the dimensions of simple modules\nfor all $p$-characters, and give lower bounds on these dimensions for\nhomogeneous $p$-characters. We then develop the theory of baby Verma modules\nfor homogeneous $p$-characters and, whenever the $p$-character has standard\nLevi type, we give a full classification of the simple modules. In particular\nwe classify all simple modules with homogeneous $p$-characters for\n$\\mathfrak{g}_m$ when $\\mathfrak{g} = \\mathfrak{gl}_n$. Finally, we compute the\nCartan invariants for the restricted enveloping algebra $U_0(\\mathfrak{g}_m)$\nand show that they can be described by precise formulae depending on\ndecomposition numbers for $U_0(\\mathfrak{g})$.",
            "author": [
                "Matthew Chaffe",
                "Lewis Topley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08208v1",
                "http://arxiv.org/pdf/2311.08208v1"
            ],
            "primary_category": "math.RT",
            "category": [
                "math.RT",
                "math.RA",
                "17B10, 17B45 (Primary) 16D90, 17B20 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08206v1",
            "title": "Human-Centric Autonomous Systems With LLMs for User Command Reasoning",
            "updated": "2023-11-14T14:42:28Z",
            "published": "2023-11-14T14:42:28Z",
            "summary": "The evolution of autonomous driving has made remarkable advancements in\nrecent years, evolving into a tangible reality. However, a human-centric\nlarge-scale adoption hinges on meeting a variety of multifaceted requirements.\nTo ensure that the autonomous system meets the user's intent, it is essential\nto accurately discern and interpret user commands, especially in complex or\nemergency situations. To this end, we propose to leverage the reasoning\ncapabilities of Large Language Models (LLMs) to infer system requirements from\nin-cabin users' commands. Through a series of experiments that include\ndifferent LLM models and prompt designs, we explore the few-shot multivariate\nbinary classification accuracy of system requirements from natural language\ntextual commands. We confirm the general ability of LLMs to understand and\nreason about prompts but underline that their effectiveness is conditioned on\nthe quality of both the LLM model and the design of appropriate sequential\nprompts. Code and models are public with the link\n\\url{https://github.com/KTH-RPL/DriveCmd_LLM}.",
            "author": [
                "Yi Yang",
                "Qingwen Zhang",
                "Ci Li",
                "Daniel Sim\u00f5es Marta",
                "Nazre Batool",
                "John Folkesson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08206v1",
                "http://arxiv.org/pdf/2311.08206v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08205v1",
            "title": "Increasing the Efficiency of Cryptoasset Investigations by Connecting\n  the Cases",
            "updated": "2023-11-14T14:41:39Z",
            "published": "2023-11-14T14:41:39Z",
            "summary": "Law enforcement agencies are confronted with a rapidly growing number of\ncryptoasset-related cases, often redundantly investigating the same cases\nwithout mutual knowledge or shared insights. In this paper, we explore the\nhypothesis that recognizing and acting upon connections between these cases can\nsignificantly streamline investigative processes. Through an analysis of a\ndataset comprising 34 cyberfraud and 1793 sextortion spam cases, we discovered\nthat 41% of the cyberfraud and 96.9% of the sextortion spam incidents can be\ninterconnected. We introduce a straightforward yet effective tool, which is\nintegrated into a broader cryptoasset forensics workflow and allows\ninvestigators to highlight and share case connections. Our research\nunequivocally demonstrates that recognizing case connections can lead to\nremarkable efficiencies, especially when extended across crime areas,\ninternational borders, and jurisdictions.",
            "author": [
                "Bernhard Haslhofer",
                "Christiane Hanslbauer",
                "Michael Fr\u00f6wis",
                "Thomas Goger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08205v1",
                "http://arxiv.org/pdf/2311.08205v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08204v1",
            "title": "On The Evaluation of Collision Probability along a Path",
            "updated": "2023-11-14T14:39:28Z",
            "published": "2023-11-14T14:39:28Z",
            "summary": "Characterizing the risk of operations is a fundamental requirement in\nrobotics, and a crucial ingredient of safe planning. The problem is\nmultifaceted, with multiple definitions arising in the vast recent literature\nfitting different application scenarios and leading to different computational\napproaches. A basic element shared by most frameworks is the definition and\nevaluation of the probability of collision for a mobile object in an\nenvironment with obstacles. We observe that, even in basic cases, different\ninterpretations are possible. This paper proposes an index we call Risk\nDensity, which offers a theoretical link between conceptually distant\nassumptions about the interplay of single collision events along a continuous\npath. We show how this index can be used to approximate the collision\nprobability in the case where the robot evolves along a nominal continuous\ncurve from random initial conditions. Indeed under this hypothesis the proposed\napproximation outperforms some well-established methods either in accuracy or\ncomputational cost.",
            "author": [
                "Lorenzo Paiola",
                "Giorgio Grioli",
                "Antonio Bicchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08204v1",
                "http://arxiv.org/pdf/2311.08204v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00025v1",
            "title": "Secure Transformer Inference",
            "updated": "2023-11-14T14:37:23Z",
            "published": "2023-11-14T14:37:23Z",
            "summary": "We present a three-party protocol that can protect both Transformer\nparameters and user data during the inference phase. For each feedforward\ninference process, our protocol only introduces permutation computation of\ninput and output data on the user side. Our protocol, Secure Transformer\nInference Protocol (STIP), can be applied to real-world services like ChatGPT.",
            "author": [
                "Mu Yuan",
                "Lan Zhang",
                "Xiang-Yang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00025v1",
                "http://arxiv.org/pdf/2312.00025v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08199v1",
            "title": "Diffusion-based generation of Histopathological Whole Slide Images at a\n  Gigapixel scale",
            "updated": "2023-11-14T14:33:39Z",
            "published": "2023-11-14T14:33:39Z",
            "summary": "We present a novel diffusion-based approach to generate synthetic\nhistopathological Whole Slide Images (WSIs) at an unprecedented gigapixel\nscale. Synthetic WSIs have many potential applications: They can augment\ntraining datasets to enhance the performance of many computational pathology\napplications. They allow the creation of synthesized copies of datasets that\ncan be shared without violating privacy regulations. Or they can facilitate\nlearning representations of WSIs without requiring data annotations. Despite\nthis variety of applications, no existing deep-learning-based method generates\nWSIs at their typically high resolutions. Mainly due to the high computational\ncomplexity. Therefore, we propose a novel coarse-to-fine sampling scheme to\ntackle image generation of high-resolution WSIs. In this scheme, we increase\nthe resolution of an initial low-resolution image to a high-resolution WSI.\nParticularly, a diffusion model sequentially adds fine details to images and\nincreases their resolution. In our experiments, we train our method with WSIs\nfrom the TCGA-BRCA dataset. Additionally to quantitative evaluations, we also\nperformed a user study with pathologists. The study results suggest that our\ngenerated WSIs resemble the structure of real WSIs.",
            "author": [
                "Robert Harb",
                "Thomas Pock",
                "Heimo M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08199v1",
                "http://arxiv.org/pdf/2311.08199v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4.9; I.5.4; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08196v1",
            "title": "Computational homogenization of higher-order electro-mechanical\n  materials with built-in generalized periodicity conditions",
            "updated": "2023-11-14T14:29:20Z",
            "published": "2023-11-14T14:29:20Z",
            "summary": "We present a formulation for high-order generalized periodicity conditions in\nthe context of a high-order electromechanical theory including\nflexoelectricity, strain gradient elasticity and gradient dielectricity, with\nthe goal of studying periodic architected metamaterials. Such theory results in\nfourth-order governing partial differential equations, and the periodicity\nconditions involve continuity across the periodic boundary of primal fields\n(displacement and electric potential) and their normal derivatives, continuity\nof the corresponding dual generalized forces (tractions, double tractions,\nsurface charge density and double surface charge density). Rather than imposing\nthese conditions numerically as explicit constraints, we develop an\napproximation space which fulfils generalized periodicity by construction. Our\nmethod naturally allows us to impose general macroscopic fields\n(strains/stresses and electric fields/electric displacements) along arbitrary\ndirections, enabling the characterization of the material anisotropy. We apply\nthe proposed method to study periodic architected metamaterials with apparent\npiezoelectricity. We first verify the method by directly comparing the results\nwith a large periodic structure, then apply it to evaluate the anisotropic\napparently piezoelectricity of a geometrically polarized 2D lattice, and\nfinally demonstrate the application of the method in a 3D architected\nmetamaterial.",
            "author": [
                "J. Barcel\u00f3-Mercader",
                "D. Codony",
                "A. Mocci",
                "I. Arias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08196v1",
                "http://arxiv.org/pdf/2311.08196v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.CE",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08195v1",
            "title": "Automated Fact-Checking in Dialogue: Are Specialized Models Needed?",
            "updated": "2023-11-14T14:29:00Z",
            "published": "2023-11-14T14:29:00Z",
            "summary": "Prior research has shown that typical fact-checking models for stand-alone\nclaims struggle with claims made in dialogues. As a solution, fine-tuning these\nmodels on labelled dialogue data has been proposed. However, creating separate\nmodels for each use case is impractical, and we show that fine-tuning models\nfor dialogue results in poor performance on typical fact-checking. To overcome\nthis challenge, we present techniques that allow us to use the same models for\nboth dialogue and typical fact-checking. These mainly focus on retrieval\nadaptation and transforming conversational inputs so that they can be\naccurately predicted by models trained on stand-alone claims. We demonstrate\nthat a typical fact-checking model incorporating these techniques is\ncompetitive with state-of-the-art models fine-tuned for dialogue, while\nmaintaining its accuracy on stand-alone claims.",
            "author": [
                "Eric Chamoun",
                "Marzieh Saeidi",
                "Andreas Vlachos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08195v1",
                "http://arxiv.org/pdf/2311.08195v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08438v1",
            "title": "LocaliseBot: Multi-view 3D object localisation with differentiable\n  rendering for robot grasping",
            "updated": "2023-11-14T14:27:53Z",
            "published": "2023-11-14T14:27:53Z",
            "summary": "Robot grasp typically follows five stages: object detection, object\nlocalisation, object pose estimation, grasp pose estimation, and grasp\nplanning. We focus on object pose estimation. Our approach relies on three\npieces of information: multiple views of the object, the camera's extrinsic\nparameters at those viewpoints, and 3D CAD models of objects. The first step\ninvolves a standard deep learning backbone (FCN ResNet) to estimate the object\nlabel, semantic segmentation, and a coarse estimate of the object pose with\nrespect to the camera. Our novelty is using a refinement module that starts\nfrom the coarse pose estimate and refines it by optimisation through\ndifferentiable rendering. This is a purely vision-based approach that avoids\nthe need for other information such as point cloud or depth images. We evaluate\nour object pose estimation approach on the ShapeNet dataset and show\nimprovements over the state of the art. We also show that the estimated object\npose results in 99.65% grasp accuracy with the ground truth grasp candidates on\nthe Object Clutter Indoor Dataset (OCID) Grasp dataset, as computed using\nstandard practice.",
            "author": [
                "Sujal Vijayaraghavan",
                "Redwan Alqasemi",
                "Rajiv Dubey",
                "Sudeep Sarkar"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-25075-0_47",
                "http://arxiv.org/abs/2311.08438v1",
                "http://arxiv.org/pdf/2311.08438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08194v1",
            "title": "On the Quantum Chromatic Numbers of Small Graphs",
            "updated": "2023-11-14T14:27:03Z",
            "published": "2023-11-14T14:27:03Z",
            "summary": "We make two contributions pertaining to the study of the quantum chromatic\nnumbers of small graphs. Firstly, in an elegant paper, Man\\v{c}inska and\nRoberson [\\textit{Baltic Journal on Modern Computing}, 4(4), 846-859, 2016]\ngave an example of a graph $G_{14}$ on 14 vertices with quantum chromatic\nnumber 4 and classical chromatic number 5, and conjectured that this is the\nsmallest graph exhibiting a separation between the two parameters. We describe\na computer-assisted proof of this conjecture, thereby resolving a longstanding\nopen problem in quantum graph theory. Our second contribution pertains to the\nstudy of the rank-$r$ quantum chromatic numbers. While it can now be shown that\nfor every $r$, $\\chi_q$ and $\\chi^{(r)}_q$ are distinct, few small examples of\nseparations between these parameters are known. We give the smallest known\nexample of such a separation in the form of a graph $G_{21}$ on 21 vertices\nwith $\\chi_q(G_{21}) = \\chi^{(2)}_q(G_{21}) = 4$ and $ \\xi(G_{21}) =\n\\chi^{(1)}_q(G_{21}) = \\chi(G_{21}) = 5$. The previous record was held by a\ngraph $G_{msg}$ on 57 vertices that was first considered in the aforementioned\npaper of Man\\v{c}inska and Roberson and which satisfies $\\chi_q(G_{msg}) = 3$\nand $\\chi^{(1)}_q(G_{msg}) = 4$. In addition, $G_{21}$ provides the first\nprovable separation between the parameters $\\chi^{(1)}_q$ and $\\chi^{(2)}_q$.\nWe believe that our techniques for constructing $G_{21}$ and lower bounding its\northogonal rank could be of independent interest.",
            "author": [
                "Olivier Lalonde"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08194v1",
                "http://arxiv.org/pdf/2311.08194v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08191v1",
            "title": "GEC-DePenD: Non-Autoregressive Grammatical Error Correction with\n  Decoupled Permutation and Decoding",
            "updated": "2023-11-14T14:24:36Z",
            "published": "2023-11-14T14:24:36Z",
            "summary": "Grammatical error correction (GEC) is an important NLP task that is currently\nusually solved with autoregressive sequence-to-sequence models. However,\napproaches of this class are inherently slow due to one-by-one token\ngeneration, so non-autoregressive alternatives are needed. In this work, we\npropose a novel non-autoregressive approach to GEC that decouples the\narchitecture into a permutation network that outputs a self-attention weight\nmatrix that can be used in beam search to find the best permutation of input\ntokens (with auxiliary {ins} tokens) and a decoder network based on a\nstep-unrolled denoising autoencoder that fills in specific tokens. This allows\nus to find the token permutation after only one forward pass of the permutation\nnetwork, avoiding autoregressive constructions. We show that the resulting\nnetwork improves over previously known non-autoregressive methods for GEC and\nreaches the level of autoregressive methods that do not use language-specific\nsynthetic data generation methods. Our results are supported by a comprehensive\nexperimental validation on the ConLL-2014 and Write&Improve+LOCNESS datasets\nand an extensive ablation study that supports our architectural and algorithmic\nchoices.",
            "author": [
                "Konstantin Yakovlev",
                "Alexander Podolskiy",
                "Andrey Bout",
                "Sergey Nikolenko",
                "Irina Piontkovskaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08191v1",
                "http://arxiv.org/pdf/2311.08191v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08190v1",
            "title": "SAMIHS: Adaptation of Segment Anything Model for Intracranial Hemorrhage\n  Segmentation",
            "updated": "2023-11-14T14:23:09Z",
            "published": "2023-11-14T14:23:09Z",
            "summary": "Segment Anything Model (SAM), a vision foundation model trained on\nlarge-scale annotations, has recently continued raising awareness within\nmedical image segmentation. Despite the impressive capabilities of SAM on\nnatural scenes, it struggles with performance decline when confronted with\nmedical images, especially those involving blurry boundaries and highly\nirregular regions of low contrast. In this paper, a SAM-based\nparameter-efficient fine-tuning method, called SAMIHS, is proposed for\nintracranial hemorrhage segmentation, which is a crucial and challenging step\nin stroke diagnosis and surgical planning. Distinguished from previous SAM and\nSAM-based methods, SAMIHS incorporates parameter-refactoring adapters into\nSAM's image encoder and considers the efficient and flexible utilization of\nadapters' parameters. Additionally, we employ a combo loss that combines binary\ncross-entropy loss and boundary-sensitive loss to enhance SAMIHS's ability to\nrecognize the boundary regions. Our experimental results on two public datasets\ndemonstrate the effectiveness of our proposed method. Code is available at\nhttps://github.com/mileswyn/SAMIHS .",
            "author": [
                "Yinuo Wang",
                "Kai Chen",
                "Weimin Yuan",
                "Cai Meng",
                "XiangZhi Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08190v1",
                "http://arxiv.org/pdf/2311.08190v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08189v2",
            "title": "Unlocking Science: Novel Dataset and Benchmark for Cross-Modality\n  Scientific Information Extraction",
            "updated": "2023-11-15T02:57:01Z",
            "published": "2023-11-14T14:22:47Z",
            "summary": "Extracting key information from scientific papers has the potential to help\nresearchers work more efficiently and accelerate the pace of scientific\nprogress. Over the last few years, research on Scientific Information\nExtraction (SciIE) witnessed the release of several new systems and benchmarks.\nHowever, existing paper-focused datasets mostly focus only on specific parts of\na manuscript (e.g., abstracts) and are single-modality (i.e., text- or\ntable-only), due to complex processing and expensive annotations. Moreover,\ncore information can be present in either text or tables or across both. To\nclose this gap in data availability and enable cross-modality IE, while\nalleviating labeling costs, we propose a semi-supervised pipeline for\nannotating entities in text, as well as entities and relations in tables, in an\niterative procedure. Based on this pipeline, we release novel resources for the\nscientific community, including a high-quality benchmark, a large-scale corpus,\nand a semi-supervised annotation pipeline. We further report the performance of\nstate-of-the-art IE models on the proposed benchmark dataset, as a baseline.\nLastly, we explore the potential capability of large language models such as\nChatGPT for the current task. Our new dataset, results, and analysis validate\nthe effectiveness and efficiency of our semi-supervised pipeline, and we\ndiscuss its remaining limitations.",
            "author": [
                "Yuhan Li",
                "Jian Wu",
                "Zhiwei Yu",
                "B\u00f6rje F. Karlsson",
                "Wei Shen",
                "Manabu Okumura",
                "Chin-Yew Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08189v2",
                "http://arxiv.org/pdf/2311.08189v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08186v1",
            "title": "Island in Quark Cloud Model",
            "updated": "2023-11-14T14:17:10Z",
            "published": "2023-11-14T14:17:10Z",
            "summary": "We compute the entanglement entropy of Hawking radiation in a bath attached\nto a deformed eternal AdS black hole dual to field theories where each theory\nis backreacted by the presence of a uniform static distribution of heavy\nfundamental quarks. The entanglement entropy of the Hawking radiation increases\nlinearly with time until an island emerges after the Page time, at that point\nthe entanglement entropy saturates to a constant value twice the\nBekenstein-Hawking entropy of the deformed black hole resulting in the Page\ncurve. Furthermore, we study the effects of the backreaction on the Page curve\nand observe that introducing deformation delays the appearance of island and\nshifts the Page curve to a later time.",
            "author": [
                "Parul Jain",
                "Sanjay Pant",
                "Himanshu Parihar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08186v1",
                "http://arxiv.org/pdf/2311.08186v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08185v1",
            "title": "Predicting Dynamic Memory Requirements for Scientific Workflow Tasks",
            "updated": "2023-11-14T14:14:51Z",
            "published": "2023-11-14T14:14:51Z",
            "summary": "With the increasing amount of data available to scientists in disciplines as\ndiverse as bioinformatics, physics, and remote sensing, scientific workflow\nsystems are becoming increasingly important for composing and executing\nscalable data analysis pipelines. When writing such workflows, users need to\nspecify the resources to be reserved for tasks so that sufficient resources are\nallocated on the target cluster infrastructure. Crucially, underestimating a\ntask's memory requirements can result in task failures. Therefore, users often\nresort to overprovisioning, resulting in significant resource wastage and\ndecreased throughput.\n  In this paper, we propose a novel online method that uses monitoring time\nseries data to predict task memory usage in order to reduce the memory wastage\nof scientific workflow tasks. Our method predicts a task's runtime, divides it\ninto k equally-sized segments, and learns the peak memory value for each\nsegment depending on the total file input size. We evaluate the prototype\nimplementation of our method using workflows from the publicly available\nnf-core repository, showing an average memory wastage reduction of 29.48%\ncompared to the best state-of-the-art approach",
            "author": [
                "Jonathan Bader",
                "Nils Diedrich",
                "Lauritz Thamsen",
                "Odej Kao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08185v1",
                "http://arxiv.org/pdf/2311.08185v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08182v1",
            "title": "Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning",
            "updated": "2023-11-14T14:10:40Z",
            "published": "2023-11-14T14:10:40Z",
            "summary": "Enhancing the instruction-following ability of Large Language Models (LLMs)\nprimarily demands substantial instruction-tuning datasets. However, the sheer\nvolume of these imposes a considerable computational burden and annotation\ncost. To investigate a label-efficient instruction tuning method that allows\nthe model itself to actively sample subsets that are equally or even more\neffective, we introduce a self-evolving mechanism DiverseEvol. In this process,\na model iteratively augments its training subset to refine its own performance,\nwithout requiring any intervention from humans or more advanced LLMs. The key\nto our data sampling technique lies in the enhancement of diversity in the\nchosen subsets, as the model selects new data points most distinct from any\nexisting ones according to its current embedding space. Extensive experiments\nacross three datasets and benchmarks demonstrate the effectiveness of\nDiverseEvol. Our models, trained on less than 8% of the original dataset,\nmaintain or improve performance compared with finetuning on full data. We also\nprovide empirical evidence to analyze the importance of diversity in\ninstruction data and the iterative scheme as opposed to one-time sampling. Our\ncode is publicly available at https://github.com/OFA-Sys/DiverseEvol.git.",
            "author": [
                "Shengguang Wu",
                "Keming Lu",
                "Benfeng Xu",
                "Junyang Lin",
                "Qi Su",
                "Chang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08182v1",
                "http://arxiv.org/pdf/2311.08182v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08177v2",
            "title": "Overcoming the Size Limit of First Principles Molecular Dynamics\n  Simulations with an In-Distribution Substructure Embedding Active Learner",
            "updated": "2023-11-15T03:45:38Z",
            "published": "2023-11-14T14:06:56Z",
            "summary": "Large-scale first principles molecular dynamics are crucial for simulating\ncomplex processes in chemical, biomedical, and materials sciences. However, the\nunfavorable time complexity with respect to system sizes leads to prohibitive\ncomputational costs when the simulation contains over a few hundred atoms in\npractice. We present an In-Distribution substructure Embedding Active Learner\n(IDEAL) to enable efficient simulation of large complex systems with quantum\naccuracy by maintaining a machine learning force field (MLFF) as an accurate\nsurrogate to the first principles methods. By extracting high-uncertainty\nsubstructures into low-uncertainty atom environments, the active learner is\nallowed to concentrate on and learn from small substructures of interest rather\nthan carrying out intractable quantum chemical computations on large\nstructures. IDEAL is benchmarked on various systems and shows sub-linear\ncomplexity, accelerating the simulation thousands of times compared with\nconventional active learning and millions of times compared with pure first\nprinciples simulations. To demonstrate the capability of IDEAL in practical\napplications, we simulated a polycrystalline lithium system composed of one\nmillion atoms and the full ammonia formation process in a Haber-Bosch reaction\non a 3-nm Iridium nanoparticle catalyst on a computing node comprising one\nsingle A100 GPU and 24 CPU cores.",
            "author": [
                "Lingyu Kong",
                "Jielan Li",
                "Lixin Sun",
                "Han Yang",
                "Hongxia Hao",
                "Chi Chen",
                "Nongnuch Artrith",
                "Jose Antonio Garrido Torres",
                "Ziheng Lu",
                "Yichi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08177v2",
                "http://arxiv.org/pdf/2311.08177v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08176v1",
            "title": "A deformation-based morphometry framework for disentangling Alzheimer's\n  disease from normal aging using learned normal aging templates",
            "updated": "2023-11-14T14:04:35Z",
            "published": "2023-11-14T14:04:35Z",
            "summary": "Alzheimer's Disease and normal aging are both characterized by brain atrophy.\nThe question of whether AD-related brain atrophy represents accelerated aging\nor a neurodegeneration process distinct from that in normal aging remains\nunresolved. Moreover, precisely disentangling AD-related brain atrophy from\nnormal aging in a clinical context is complex. In this study, we propose a\ndeformation-based morphometry framework to estimate normal aging and\nAD-specific atrophy patterns of subjects from morphological MRI scans. We first\nleverage deep-learning-based methods to create age-dependent templates of\ncognitively normal (CN) subjects. These templates model the normal aging\natrophy patterns in a CN population. Then, we use the learned diffeomorphic\nregistration to estimate the one-year normal aging pattern at the voxel level.\nWe register the testing image to the 60-year-old CN template in the second\nstep. Finally, normal aging and AD-specific scores are estimated by measuring\nthe alignment of this registration with the one-year normal aging pattern. The\nmethodology was developed and evaluated on the OASIS3 dataset with 1,014\nT1-weighted MRI scans. Of these, 326 scans were from CN subjects, and 688 scans\nwere from individuals clinically diagnosed with AD at different stages of\nclinical severity defined by clinical dementia rating (CDR) scores. The results\nshow that ventricles predominantly follow an accelerated normal aging pattern\nin subjects with AD. In turn, hippocampi and amygdala regions were affected by\nboth normal aging and AD-specific factors. Interestingly, hippocampi and\namygdala regions showed more of an accelerated normal aging pattern for\nsubjects during the early clinical stages of the disease, while the AD-specific\nscore increases in later clinical stages. Our code is freely available at\nhttps://github.com/Fjr9516/DBM_with_DL.",
            "author": [
                "Jingru Fu",
                "Daniel Ferreira",
                "\u00d6rjan Smedby",
                "Rodrigo Moreno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08176v1",
                "http://arxiv.org/pdf/2311.08176v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08174v1",
            "title": "The G\u014dMartini approach: Revisiting the concept of contact maps and the\n  modelling of protein complexes",
            "updated": "2023-11-14T14:03:56Z",
            "published": "2023-11-14T14:03:56Z",
            "summary": "We present a review of a series of contact maps for the determination of\nnative interactions in proteins and nucleic acids based on a\ndistance-threshold. Such contact maps are mostly based on physical and chemical\nconstruction, and yet they are sensitive to some parameters (e.g. distances or\natomic radii) and can neglect some key interactions. Furthermore, we also\ncomment on a new class of contact maps that only requires geometric arguments.\nThe contact map is a necessary ingredient to build a robust G\\=oMartini model\nfor proteins and their complexes in the Martini 3 force field. We present the\nextension of a popular structure-based G\\=o-like approach for the study of\nprotein-sugar complexes, and also limitations of this approach are discussed.\nThe G\\=oMartini approach was first introduced by Poma et al. J. Chem. Theory\nComput. 2017, 13(3), 1366-1374 in Martini 2 force field and recently, it has\ngained the status of gold-standard for protein simulation undergoing\nconformational changes in Martini 3 force field. We discuss several studies\nthat have provided support to this approach in the context of the biophysical\ncommunity.",
            "author": [
                "Luis F. Cofas-Vargas",
                "Rodrigo A. Moreira",
                "Sim\u00f3n Poblete",
                "Mateusz Chwastyk",
                "Adolfo B. Poma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08174v1",
                "http://arxiv.org/pdf/2311.08174v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08173v1",
            "title": "T-wave Inversion through Inhomogeneous Voltage Diffusion within the FK3V\n  Cardiac Model",
            "updated": "2023-11-14T14:03:07Z",
            "published": "2023-11-14T14:03:07Z",
            "summary": "The heart beats due to the synchronized contraction of cardiomyocytes\ntriggered by a periodic sequence of electrical signals called action\npotentials, which originate in the sinoatrial node and spread through the\nheart's electrical system. A large body of work is devoted to modeling the\npropagation of the action potential and to reproducing reliably its shape and\nduration. Connection of computational modeling of cells to macroscopic\nphenomenological curves such as the electrocardiogram has been also intense,\ndue to its clinical importancce in analyzing cardiovascular diseases. In this\nwork we simulate the dynamics of action potential propagation using the\nthree-variable Fenton-Karma model that can account for both normal and damaged\ncells through spatially inhomogeneous voltage diffusion coefficient. We monitor\nthe action potential propagation in the cardiac tissue and calculate the\npseudo-electrocardiogram that reproduces the R and T waves. The R wave\namplitude varies according to a double exponential law as a function of the\n(spatially homogeneous, for an isotropic tissue) diffusion coefficient. The\naddition of spatial inhomogeneity in the diffusion coefficient by means of a\ndefected region representing damaged cardiac cells, may result in T-wave\ninversion in the calculated pseudo-electrocardiogram. The transition from\npositive to negative polarity of the T-wave is analyzed as a function of the\nlength and the depth of the defected region.",
            "author": [
                "E. Angelaki",
                "N. Lazarides",
                "G. D. Barmparis",
                "I. Kourakis",
                "M. E. Marketou",
                "G. P. Tsironis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08173v1",
                "http://arxiv.org/pdf/2311.08173v1"
            ],
            "primary_category": "nlin.PS",
            "category": [
                "nlin.PS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08172v2",
            "title": "Vision-Language Instruction Tuning: A Review and Analysis",
            "updated": "2023-11-25T07:59:48Z",
            "published": "2023-11-14T14:02:32Z",
            "summary": "Instruction tuning is a crucial supervised training phase in Large Language\nModels (LLMs), aiming to enhance the LLM's ability to generalize instruction\nexecution and adapt to user preferences. With the increasing integration of\nmulti-modal data into LLMs, there is growing interest in Vision-Language\nInstruction Tuning (VLIT), which presents more complex characteristics compared\nto pure text instruction tuning. In this paper, we systematically review the\nlatest VLIT settings and corresponding datasets in multi-modal LLMs and provide\ninsights into the intrinsic motivations behind their design. For the first\ntime, we offer a detailed multi-perspective categorization for existing VLIT\ndatasets and identify the characteristics that high-quality VLIT data should\npossess. By incorporating these characteristics as guiding principles into the\nexisting VLIT data construction process, we conduct extensive experiments and\nverify their positive impact on the performance of tuned multi-modal LLMs.\nFurthermore, we discuss the current challenges and future research directions\nof VLIT, providing insights for the continuous development of this field. The\ncode and dataset related to this paper have been open-sourced at\nhttps://github.com/palchenli/VL-Instruction-Tuning.",
            "author": [
                "Chen Li",
                "Yixiao Ge",
                "Dian Li",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08172v2",
                "http://arxiv.org/pdf/2311.08172v2"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08169v1",
            "title": "Modeling ionic flow between small targets: insights from diffusion and\n  electro-diffusion theory",
            "updated": "2023-11-14T13:49:47Z",
            "published": "2023-11-14T13:49:47Z",
            "summary": "The flow of ions through permeable channels causes voltage drop in\nphysiological nanodomains such as synapses, dendrites and dendritic spines, and\nother protrusions. How the voltage changes around channels in these nanodomains\nhas remained poorly studied. We focus this book chapter on summarizing recent\nefforts in computing the steady-state current, voltage and ionic concentration\ndistributions based on the Poisson-Nernst-Planck equations as a model of\nelectro-diffusion. We first consider the spatial distribution of an uncharged\nparticle density and derive asymptotic formulas for the concentration\ndifference by solving the Laplace's equation with mixed boundary conditions. We\nstudy a constant particles injection rate modeled by a Neumann flux condition\nat a channel represented by a small boundary target, while the injected\nparticles can exit at one or several narrow patches. We then discuss the case\nof two species (positive and negative charges) and take into account motions\ndue to both concentration and electrochemical gradients. The voltage resulting\nfrom charge interactions is calculated by solving the Poisson's equation. We\nshow how deep an influx diffusion propagates inside a nanodomain, for\npopulations of both uncharged and charged particles. We estimate the\nconcentration and voltage changes in relations with geometrical parameters and\nquantify the impact of membrane curvature.",
            "author": [
                "Fr\u00e9d\u00e9ric Paquin-Lefebvre",
                "David Holcman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08169v1",
                "http://arxiv.org/pdf/2311.08169v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "math.AP",
                "q-bio.SC",
                "35J05, 35J08, 35J25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08166v1",
            "title": "MechAgents: Large language model multi-agent collaborations can solve\n  mechanics problems, generate new data, and integrate knowledge",
            "updated": "2023-11-14T13:49:03Z",
            "published": "2023-11-14T13:49:03Z",
            "summary": "Solving mechanics problems using numerical methods requires comprehensive\nintelligent capability of retrieving relevant knowledge and theory,\nconstructing and executing codes, analyzing the results, a task that has thus\nfar mainly been reserved for humans. While emerging AI methods can provide\neffective approaches to solve end-to-end problems, for instance via the use of\ndeep surrogate models or various data analytics strategies, they often lack\nphysical intuition since knowledge is baked into the parametric complement\nthrough training, offering less flexibility when it comes to incorporating\nmathematical or physical insights. By leveraging diverse capabilities of\nmultiple dynamically interacting large language models (LLMs), we can overcome\nthe limitations of conventional approaches and develop a new class of\nphysics-inspired generative machine learning platform, here referred to as\nMechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for\nelasticity problems, via autonomous collaborations. A two-agent team can\neffectively write, execute and self-correct code, in order to apply finite\nelement methods to solve classical elasticity problems in various flavors\n(different boundary conditions, domain geometries, meshes, small/finite\ndeformation and linear/hyper-elastic constitutive laws, and others). For more\ncomplex tasks, we construct a larger group of agents with enhanced division of\nlabor among planning, formulating, coding, executing and criticizing the\nprocess and results. The agents mutually correct each other to improve the\noverall team-work performance in understanding, formulating and validating the\nsolution. Our framework shows the potential of synergizing the intelligence of\nlanguage models, the reliability of physics-based modeling, and the dynamic\ncollaborations among diverse agents, opening novel avenues for automation of\nsolving engineering problems.",
            "author": [
                "Bo Ni",
                "Markus J. Buehler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08166v1",
                "http://arxiv.org/pdf/2311.08166v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cond-mat.dis-nn",
                "cond-mat.mtrl-sci",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08159v1",
            "title": "DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an\n  Optimizable Feature Grid",
            "updated": "2023-11-14T13:39:01Z",
            "published": "2023-11-14T13:39:01Z",
            "summary": "We propose DynamicSurf, a model-free neural implicit surface reconstruction\nmethod for high-fidelity 3D modelling of non-rigid surfaces from monocular\nRGB-D video. To cope with the lack of multi-view cues in monocular sequences of\ndeforming surfaces, one of the most challenging settings for 3D reconstruction,\nDynamicSurf exploits depth, surface normals, and RGB losses to improve\nreconstruction fidelity and optimisation time. DynamicSurf learns a neural\ndeformation field that maps a canonical representation of the surface geometry\nto the current frame. We depart from current neural non-rigid surface\nreconstruction models by designing the canonical representation as a learned\nfeature grid which leads to faster and more accurate surface reconstruction\nthan competing approaches that use a single MLP. We demonstrate DynamicSurf on\npublic datasets and show that it can optimize sequences of varying frames with\n$6\\times$ speedup over pure MLP-based approaches while achieving comparable\nresults to the state-of-the-art methods. Project is available at\nhttps://mirgahney.github.io//DynamicSurf.io/.",
            "author": [
                "Mirgahney Mohamed",
                "Lourdes Agapito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08159v1",
                "http://arxiv.org/pdf/2311.08159v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08154v1",
            "title": "Ask One More Time: Self-Agreement Improves Reasoning of Language Models\n  in (Almost) All Scenarios",
            "updated": "2023-11-14T13:30:54Z",
            "published": "2023-11-14T13:30:54Z",
            "summary": "Although chain-of-thought (CoT) prompting combined with language models has\nachieved encouraging results on complex reasoning tasks, the naive greedy\ndecoding used in CoT prompting usually causes the repetitiveness and local\noptimality. To address this shortcoming, ensemble-optimization tries to obtain\nmultiple reasoning paths to get the final answer assembly. However, current\nensemble-optimization methods either simply employ rule-based post-processing\nsuch as \\textit{self-consistency}, or train an additional model based on\nseveral task-related human annotations to select the best one among multiple\nreasoning paths, yet fail to generalize to realistic settings where the type of\ninput questions is unknown or the answer format of reasoning paths is unknown.\nTo avoid their limitations, we propose \\textbf{self-agreement}, a generalizable\nensemble-optimization method applying in almost all scenarios where the type of\ninput questions and the answer format of reasoning paths may be known or\nunknown. Self-agreement firstly samples from language model's decoder to\ngenerate a \\textit{diverse} set of reasoning paths, and subsequently prompts\nthe language model \\textit{one more time} to determine the optimal answer by\nselecting the most \\textit{agreed} answer among the sampled reasoning paths.\nSelf-agreement simultaneously achieves remarkable performance on six public\nreasoning benchmarks and superior generalization capabilities.",
            "author": [
                "Lei Lin",
                "Jiayi Fu",
                "Pengli Liu",
                "Junchen Wan",
                "Fuzheng Zhang",
                "Zhongyuan Wang",
                "Di Zhang",
                "Kun Gai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08154v1",
                "http://arxiv.org/pdf/2311.08154v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08152v1",
            "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review\n  Collaboration",
            "updated": "2023-11-14T13:27:07Z",
            "published": "2023-11-14T13:27:07Z",
            "summary": "Large Language Models (LLMs) have shown remarkable capabilities in general\nnatural language processing tasks but often fall short in complex reasoning\ntasks. Recent studies have explored human-like problem-solving strategies, such\nas self-correct, to push further the boundary of single-model reasoning\nability. In this work, we let a single model \"step outside the box\" by engaging\nmultiple models to correct each other. We introduce a multi-agent collaboration\nstrategy that emulates the academic peer review process. Each agent\nindependently constructs its own solution, provides reviews on the solutions of\nothers, and assigns confidence levels to its reviews. Upon receiving peer\nreviews, agents revise their initial solutions. Extensive experiments on three\ndifferent types of reasoning tasks show that our collaboration approach\ndelivers superior accuracy across all ten datasets compared to existing\nmethods. Further study demonstrates the effectiveness of integrating confidence\nin the reviews for math reasoning, and suggests a promising direction for\nhuman-mimicking multi-agent collaboration process.",
            "author": [
                "Zhenran Xu",
                "Senbao Shi",
                "Baotian Hu",
                "Jindi Yu",
                "Dongfang Li",
                "Min Zhang",
                "Yuxiang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08152v1",
                "http://arxiv.org/pdf/2311.08152v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08151v1",
            "title": "Rethink Cross-Modal Fusion in Weakly-Supervised Audio-Visual Video\n  Parsing",
            "updated": "2023-11-14T13:27:03Z",
            "published": "2023-11-14T13:27:03Z",
            "summary": "Existing works on weakly-supervised audio-visual video parsing adopt hybrid\nattention network (HAN) as the multi-modal embedding to capture the cross-modal\ncontext. It embeds the audio and visual modalities with a shared network, where\nthe cross-attention is performed at the input. However, such an early fusion\nmethod highly entangles the two non-fully correlated modalities and leads to\nsub-optimal performance in detecting single-modality events. To deal with this\nproblem, we propose the messenger-guided mid-fusion transformer to reduce the\nuncorrelated cross-modal context in the fusion. The messengers condense the\nfull cross-modal context into a compact representation to only preserve useful\ncross-modal information. Furthermore, due to the fact that microphones capture\naudio events from all directions, while cameras only record visual events\nwithin a restricted field of view, there is a more frequent occurrence of\nunaligned cross-modal context from audio for visual event predictions. We thus\npropose cross-audio prediction consistency to suppress the impact of irrelevant\naudio information on visual event prediction. Experiments consistently\nillustrate the superior performance of our framework compared to existing\nstate-of-the-art methods.",
            "author": [
                "Yating Xu",
                "Conghui Hu",
                "Gim Hee Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08151v1",
                "http://arxiv.org/pdf/2311.08151v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08150v1",
            "title": "The Hyperdimensional Transform for Distributional Modelling, Regression\n  and Classification",
            "updated": "2023-11-14T13:26:49Z",
            "published": "2023-11-14T13:26:49Z",
            "summary": "Hyperdimensional computing (HDC) is an increasingly popular computing\nparadigm with immense potential for future intelligent applications. Although\nthe main ideas already took form in the 1990s, HDC recently gained significant\nattention, especially in the field of machine learning and data science. Next\nto efficiency, interoperability and explainability, HDC offers attractive\nproperties for generalization as it can be seen as an attempt to combine\nconnectionist ideas from neural networks with symbolic aspects. In recent work,\nwe introduced the hyperdimensional transform, revealing deep theoretical\nfoundations for representing functions and distributions as high-dimensional\nholographic vectors. Here, we present the power of the hyperdimensional\ntransform to a broad data science audience. We use the hyperdimensional\ntransform as a theoretical basis and provide insight into state-of-the-art HDC\napproaches for machine learning. We show how existing algorithms can be\nmodified and how this transform can lead to a novel, well-founded toolbox. Next\nto the standard regression and classification tasks of machine learning, our\ndiscussion includes various aspects of statistical modelling, such as\nrepresentation, learning and deconvolving distributions, sampling, Bayesian\ninference, and uncertainty estimation.",
            "author": [
                "Pieter Dewulf",
                "Bernard De Baets",
                "Michiel Stock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08150v1",
                "http://arxiv.org/pdf/2311.08150v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08148v1",
            "title": "Cattle Identification Using Muzzle Images and Deep Learning Techniques",
            "updated": "2023-11-14T13:25:41Z",
            "published": "2023-11-14T13:25:41Z",
            "summary": "Traditional animal identification methods such as ear-tagging, ear notching,\nand branding have been effective but pose risks to the animal and have\nscalability issues. Electrical methods offer better tracking and monitoring but\nrequire specialized equipment and are susceptible to attacks. Biometric\nidentification using time-immutable dermatoglyphic features such as muzzle\nprints and iris patterns is a promising solution. This project explores cattle\nidentification using 4923 muzzle images collected from 268 beef cattle. Two\ndeep learning classification models are implemented - wide ResNet50 and\nVGG16\\_BN and image compression is done to lower the image quality and adapt\nthe models to work for the African context. From the experiments run, a maximum\naccuracy of 99.5\\% is achieved while using the wide ResNet50 model with a\ncompression retaining 25\\% of the original image. From the study, it is noted\nthat the time required by the models to train and converge as well as\nrecognition time are dependent on the machine used to run the model.",
            "author": [
                "G. N. Kimani",
                "P. Oluwadara",
                "P. Fashingabo",
                "M. Busogi",
                "E. Luhanga",
                "K. Sowon",
                "L. Chacha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08148v1",
                "http://arxiv.org/pdf/2311.08148v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08147v1",
            "title": "RECALL: A Benchmark for LLMs Robustness against External Counterfactual\n  Knowledge",
            "updated": "2023-11-14T13:24:19Z",
            "published": "2023-11-14T13:24:19Z",
            "summary": "LLMs and AI chatbots have improved people's efficiency in various fields.\nHowever, the necessary knowledge for answering the question may be beyond the\nmodels' knowledge boundaries. To mitigate this issue, many researchers try to\nintroduce external knowledge, such as knowledge graphs and Internet contents,\ninto LLMs for up-to-date information. However, the external information from\nthe Internet may include counterfactual information that will confuse the model\nand lead to an incorrect response. Thus there is a pressing need for LLMs to\npossess the ability to distinguish reliable information from external\nknowledge. Therefore, to evaluate the ability of LLMs to discern the\nreliability of external knowledge, we create a benchmark from existing\nknowledge bases. Our benchmark consists of two tasks, Question Answering and\nText Generation, and for each task, we provide models with a context containing\ncounterfactual information. Evaluation results show that existing LLMs are\nsusceptible to interference from unreliable external knowledge with\ncounterfactual information, and simple intervention methods make limited\ncontributions to the alleviation of this issue.",
            "author": [
                "Yi Liu",
                "Lianzhe Huang",
                "Shicheng Li",
                "Sishuo Chen",
                "Hao Zhou",
                "Fandong Meng",
                "Jie Zhou",
                "Xu Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08147v1",
                "http://arxiv.org/pdf/2311.08147v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08143v1",
            "title": "Sinkhorn Transformations for Single-Query Postprocessing in Text-Video\n  Retrieval",
            "updated": "2023-11-14T13:20:23Z",
            "published": "2023-11-14T13:20:23Z",
            "summary": "A recent trend in multimodal retrieval is related to postprocessing test set\nresults via the dual-softmax loss (DSL). While this approach can bring\nsignificant improvements, it usually presumes that an entire matrix of test\nsamples is available as DSL input. This work introduces a new postprocessing\napproach based on Sinkhorn transformations that outperforms DSL. Further, we\npropose a new postprocessing setting that does not require access to multiple\ntest queries. We show that our approach can significantly improve the results\nof state of the art models such as CLIP4Clip, BLIP, X-CLIP, and DRL, thus\nachieving a new state-of-the-art on several standard text-video retrieval\ndatasets both with access to the entire test set and in the single-query\nsetting.",
            "author": [
                "Konstantin Yakovlev",
                "Gregory Polyakov",
                "Ilseyar Alimova",
                "Alexander Podolskiy",
                "Andrey Bout",
                "Sergey Nikolenko",
                "Irina Piontkovskaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08143v1",
                "http://arxiv.org/pdf/2311.08143v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17924v1",
            "title": "Unrolling Virtual Worlds for Immersive Experiences",
            "updated": "2023-11-14T13:16:34Z",
            "published": "2023-11-14T13:16:34Z",
            "summary": "This research pioneers a method for generating immersive worlds, drawing\ninspiration from elements of vintage adventure games like Myst and employing\nmodern text-to-image models. We explore the intricate conversion of 2D\npanoramas into 3D scenes using equirectangular projections, addressing the\ndistortions in perception that occur as observers navigate within the\nencompassing sphere. Our approach employs a technique similar to \"inpainting\"\nto rectify distorted projections, enabling the smooth construction of locally\ncoherent worlds. This provides extensive insight into the interrelation of\ntechnology, perception, and experiential reality within human-computer\ninteraction.",
            "author": [
                "Alexey Tikhonov",
                "Anton Repushko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17924v1",
                "http://arxiv.org/pdf/2311.17924v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.HC",
                "cs.LG",
                "cs.MM",
                "68U05, 00A66, 68T45, 91C99, 68U35, 94A08",
                "I.2.6; I.3.7; H.5.1; I.3.3; J.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08141v1",
            "title": "GMTR: Graph Matching Transformers",
            "updated": "2023-11-14T13:12:47Z",
            "published": "2023-11-14T13:12:47Z",
            "summary": "Vision transformers (ViTs) have recently been used for visual matching beyond\nobject detection and segmentation. However, the original grid dividing strategy\nof ViTs neglects the spatial information of the keypoints, limiting the\nsensitivity to local information. Therefore, we propose \\textbf{QueryTrans}\n(Query Transformer), which adopts a cross-attention module and keypoints-based\ncenter crop strategy for better spatial information extraction. We further\nintegrate the graph attention module and devise a transformer-based graph\nmatching approach \\textbf{GMTR} (Graph Matching TRansformers) whereby the\ncombinatorial nature of GM is addressed by a graph transformer neural GM\nsolver. On standard GM benchmarks, GMTR shows competitive performance against\nthe SOTA frameworks. Specifically, on Pascal VOC, GMTR achieves\n$\\mathbf{83.6\\%}$ accuracy, $\\mathbf{0.9\\%}$ higher than the SOTA framework. On\nSpair-71k, GMTR shows great potential and outperforms most of the previous\nworks. Meanwhile, on Pascal VOC, QueryTrans improves the accuracy of NGMv2 from\n$80.1\\%$ to $\\mathbf{83.3\\%}$, and BBGM from $79.0\\%$ to $\\mathbf{84.5\\%}$. On\nSpair-71k, QueryTrans improves NGMv2 from $80.6\\%$ to $\\mathbf{82.5\\%}$, and\nBBGM from $82.1\\%$ to $\\mathbf{83.9\\%}$. Source code will be made publicly\navailable.",
            "author": [
                "Jinpei Guo",
                "Shaofeng Zhang",
                "Runzhong Wang",
                "Chang Liu",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08141v1",
                "http://arxiv.org/pdf/2311.08141v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08138v1",
            "title": "Entanglement and correlations in an exactly-solvable model of a\n  Bose-Einstein condensate in a cavity",
            "updated": "2023-11-14T13:06:39Z",
            "published": "2023-11-14T13:06:39Z",
            "summary": "An exactly solvable model of a trapped interacting Bose-Einstein condensate\n(BEC) coupled in the dipole approximation to a quantized light mode in a cavity\nis presented. The model can be seen as a generalization of the\nharmonic-interaction model for a trapped BEC coupled to a bosonic bath. After\nobtaining the ground-state energy and wavefunction in closed form, we focus on\ncomputing the correlations in the system. The reduced one-particle density\nmatrices of the bosons and the cavity are constructed and diagonalized\nanalytically, and the von Neumann entanglement entropy of the BEC and the\ncavity is also expressed explicitly as a function of the number and mass of the\nbosons, frequencies of the trap and cavity, and the cavity-boson coupling\nstrength. The results allow one to study the impact of the cavity on the bosons\nand vice versa on an equal footing. As an application we investigate a specific\ncase of basic interest for itself, namely, non-interacting bosons in a cavity.\nWe find that both the bosons and the cavity develop correlations in a\ncomplementary manner while increasing the coupling between them. Whereas the\ncavity wavepacket broadens in Fock space, the BEC density saturates in real\nspace. On the other hand, while the cavity depletion saturates, and hence does\nthe BEC-cavity entanglement entropy, the BEC becomes strongly correlated and\neventually increasingly fragmented. The latter phenomenon implies single-trap\nfragmentation of otherwise ideal bosons, where their induced long-range\ninteraction is mediated by the cavity. Finally, as a complimentary\ninvestigation, the mean-field equations for the BEC-cavity system are solved\nanalytically as well, and the breakdown of mean-field theory for the cavity and\nthe bosons with increasing coupling is discussed. Further applications are\nenvisaged.",
            "author": [
                "Ofir E. Alon",
                "Lorenz S. Cederbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08138v1",
                "http://arxiv.org/pdf/2311.08138v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas",
                "physics.atom-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08135v1",
            "title": "Neuron-Astrocyte Associative Memory",
            "updated": "2023-11-14T13:01:50Z",
            "published": "2023-11-14T13:01:50Z",
            "summary": "Astrocytes, a unique type of glial cell, are thought to play a significant\nrole in memory due to their involvement in modulating synaptic plasticity.\nNonetheless, no existing theories explain how neurons, synapses, and astrocytes\ncould collectively contribute to memory function. To address this, we propose a\nbiophysical model of neuron-astrocyte interactions that unifies various\nviewpoints on astrocyte function in a principled, biologically-grounded\nframework. A key aspect of the model is that astrocytes mediate long-range\ninteractions between distant tripartite synapses. This effectively creates\n``multi-neuron synapses\" where more than two neurons interact at the same\nsynapse. Such multi-neuron synapses are ubiquitous in models of Dense\nAssociative Memory (also known as Modern Hopfield Networks) and are known to\nlead to superlinear memory storage capacity, which is a desirable computational\nfeature. We establish a theoretical relationship between neuron-astrocyte\nnetworks and Dense Associative Memories and demonstrate that neuron-astrocyte\nnetworks have a larger memory storage capacity per compute unit compared to\npreviously published biological implementations of Dense Associative Memories.\nThis theoretical correspondence suggests the exciting hypothesis that memories\ncould be stored, at least partially, within astrocytes instead of in the\nsynaptic weights between neurons. Importantly, the many-neuron synapses can be\ninfluenced by feedforward signals into the astrocytes, such as neuromodulators,\npotentially originating from distant neurons.",
            "author": [
                "Leo Kozachkov",
                "Jean-Jacques Slotine",
                "Dmitry Krotov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08135v1",
                "http://arxiv.org/pdf/2311.08135v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08129v1",
            "title": "Learning based Deep Disentangling Light Field Reconstruction and\n  Disparity Estimation Application",
            "updated": "2023-11-14T12:48:17Z",
            "published": "2023-11-14T12:48:17Z",
            "summary": "Light field cameras have a wide range of uses due to their ability to\nsimultaneously record light intensity and direction. The angular resolution of\nlight fields is important for downstream tasks such as depth estimation, yet is\noften difficult to improve due to hardware limitations. Conventional methods\ntend to perform poorly against the challenge of large disparity in sparse light\nfields, while general CNNs have difficulty extracting spatial and angular\nfeatures coupled together in 4D light fields. The light field disentangling\nmechanism transforms the 4D light field into 2D image format, which is more\nfavorable for CNN for feature extraction. In this paper, we propose a Deep\nDisentangling Mechanism, which inherits the principle of the light field\ndisentangling mechanism and further develops the design of the feature\nextractor and adds advanced network structure. We design a light-field\nreconstruction network (i.e., DDASR) on the basis of the Deep Disentangling\nMechanism, and achieve SOTA performance in the experiments. In addition, we\ndesign a Block Traversal Angular Super-Resolution Strategy for the practical\napplication of depth estimation enhancement where the input views is often\nhigher than 2x2 in the experiments resulting in a high memory usage, which can\nreduce the memory usage while having a better reconstruction performance.",
            "author": [
                "Langqing Shi",
                "Ping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08129v1",
                "http://arxiv.org/pdf/2311.08129v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08123v1",
            "title": "Memory-efficient Stochastic methods for Memory-based Transformers",
            "updated": "2023-11-14T12:37:25Z",
            "published": "2023-11-14T12:37:25Z",
            "summary": "Training Memory-based transformers can require a large amount of memory and\ncan be quite inefficient. We propose a novel two-phase training mechanism and a\nnovel regularization technique to improve the training efficiency of\nmemory-based transformers, which are often used for long-range context\nproblems. For our experiments, we consider transformer-XL as our baseline model\nwhich is one of memorybased transformer models. We show that our resultant\nmodel, Skip Cross-head TransformerXL, outperforms the baseline on character\nlevel language modeling task with similar parameters and outperforms the\nbaseline on word level language modelling task with almost 20% fewer\nparameters. Our proposed methods do not require any additional memory. We also\ndemonstrate the effectiveness of our regularization mechanism on BERT which\nshows similar performance with reduction in standard deviation of scores of\naround 30% on multiple GLUE tasks.",
            "author": [
                "Vishwajit Kumar Vishnu",
                "C. Chandra Sekhar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08123v1",
                "http://arxiv.org/pdf/2311.08123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08117v1",
            "title": "Insights into Classifying and Mitigating LLMs' Hallucinations",
            "updated": "2023-11-14T12:30:28Z",
            "published": "2023-11-14T12:30:28Z",
            "summary": "The widespread adoption of large language models (LLMs) across diverse AI\napplications is proof of the outstanding achievements obtained in several\ntasks, such as text mining, text generation, and question answering. However,\nLLMs are not exempt from drawbacks. One of the most concerning aspects regards\nthe emerging problematic phenomena known as \"Hallucinations\". They manifest in\ntext generation systems, particularly in question-answering systems reliant on\nLLMs, potentially resulting in false or misleading information propagation.\nThis paper delves into the underlying causes of AI hallucination and elucidates\nits significance in artificial intelligence. In particular, Hallucination\nclassification is tackled over several tasks (Machine Translation, Question and\nAnswer, Dialog Systems, Summarisation Systems, Knowledge Graph with LLMs, and\nVisual Question Answer). Additionally, we explore potential strategies to\nmitigate hallucinations, aiming to enhance the overall reliability of LLMs. Our\nresearch addresses this critical issue within the HeReFaNMi (Health-Related\nFake News Mitigation) project, generously supported by NGI Search, dedicated to\ncombating Health-Related Fake News dissemination on the Internet. This\nendeavour represents a concerted effort to safeguard the integrity of\ninformation dissemination in an age of evolving AI technologies.",
            "author": [
                "Alessandro Bruno",
                "Pier Luigi Mazzeo",
                "Aladine Chetouani",
                "Marouane Tliba",
                "Mohamed Amine Kerkouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08117v1",
                "http://arxiv.org/pdf/2311.08117v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08115v1",
            "title": "Stochastic Optimization of Large-Scale Parametrized Dynamical Systems",
            "updated": "2023-11-14T12:25:57Z",
            "published": "2023-11-14T12:25:57Z",
            "summary": "Many relevant problems in the area of systems and control, such as controller\nsynthesis, observer design and model reduction, can be viewed as optimization\nproblems involving dynamical systems: for instance, maximizing performance in\nthe synthesis setting or minimizing error in the reduction setting. When the\ninvolved dynamics are large-scale (e.g., high-dimensional semi-discretizations\nof partial differential equations), the optimization becomes computationally\ninfeasible. Existing methods in literature lack computational scalability or\nsolve an approximation of the problem (thereby losing guarantees with respect\nto the original problem). In this paper, we propose a novel method that\ncircumvents these issues. The method is an extension of Stochastic Gradient\nDescent (SGD) which is widely used in the context of large-scale machine\nlearning problems. The proposed SGD scheme minimizes the $\\mathcal{H}_2$ norm\nof a (differentiable) parametrized dynamical system, and we prove that the\nscheme is guaranteed to preserve stability with high probability under\nboundedness conditions on the step size. Conditioned on the stability\npreservation, we also obtain probabilistic convergence guarantees to local\nminimizers. The method is also applicable to problems involving non-realizable\ndynamics as it only requires frequency-domain input-output samples. We\ndemonstrate the potential of the approach on two numerical examples:\nfixed-order observer design for a large-scale thermal model and controller\ntuning for an infinite-dimensional system.",
            "author": [
                "Pascal Den Boef",
                "Jos Maubach",
                "Wil Schilders",
                "Nathan van de Wouw"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08115v1",
                "http://arxiv.org/pdf/2311.08115v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08110v1",
            "title": "Improving hateful memes detection via learning hatefulness-aware\n  embedding space through retrieval-guided contrastive learning",
            "updated": "2023-11-14T12:14:54Z",
            "published": "2023-11-14T12:14:54Z",
            "summary": "Hateful memes have emerged as a significant concern on the Internet. These\nmemes, which are a combination of image and text, often convey messages vastly\ndifferent from their individual meanings. Thus, detecting hateful memes\nrequires the system to jointly understand the visual and textual modalities.\nHowever, our investigation reveals that the embedding space of existing\nCLIP-based systems lacks sensitivity to subtle differences in memes that are\nvital for correct hatefulness classification. To address this issue, we propose\nconstructing a hatefulness-aware embedding space through retrieval-guided\ncontrastive training. Specifically, we add an auxiliary loss that utilizes hard\nnegative and pseudo-gold samples to train the embedding space. Our approach\nachieves state-of-the-art performance on the HatefulMemes dataset with an AUROC\nof 86.7. Notably, our approach outperforms much larger fine-tuned Large\nMultimodal Models like Flamingo and LLaVA. Finally, we demonstrate a\nretrieval-based hateful memes detection system, which is capable of making\nhatefulness classification based on data unseen in training from a database.\nThis allows developers to update the hateful memes detection system by simply\nadding new data without retraining, a desirable feature for real services in\nthe constantly-evolving landscape of hateful memes on the Internet.",
            "author": [
                "Jingbiao Mei",
                "Jinghong Chen",
                "Weizhe Lin",
                "Bill Byrne",
                "Marcus Tomalin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08110v1",
                "http://arxiv.org/pdf/2311.08110v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08107v1",
            "title": "SAIE Framework: Support Alone Isn't Enough -- Advancing LLM Training\n  with Adversarial Remarks",
            "updated": "2023-11-14T12:12:25Z",
            "published": "2023-11-14T12:12:25Z",
            "summary": "Large Language Models (LLMs) can justify or criticize their predictions\nthrough discussion with other models or humans, thereby enhancing their\nintrinsic understanding of instances. While proactive discussions enhance\nperformance, this approach is currently limited to the inference phase. In this\ncontext, we posit a hypothesis: learning interactive discussions during\ntraining can improve understanding for the instances in the training step and\nproficiency in logical/critical thinking ability and verbalized expression of\nthe model in the inference step. Our proposed SAIE training method involves\nboth supportive and adversarial discussions between the learner and partner\nmodels. The learner model receives a remark from the partner through the\ndiscussion, and the parameters of the learner model are then updated based on\nthis remark. That is, the teacher signal dynamically adjusts in response to the\nevolving model output throughout the training step. By bolstering the capacity\nfor discussion and comprehension of instances, our experiments across datasets,\nincluding GSM8K, CommonsenseQA, and MMLU, reveal that models fine-tuned with\nour method consistently surpass those trained with standard fine-tuning\ntechniques. Moreover, our approach demonstrates superior performance in\nmulti-agent inference scenarios, boosting the models' reasoning abilities at\nthe inference step.",
            "author": [
                "Mengsay Loem",
                "Masahiro Kaneko",
                "Naoaki Okazaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08107v1",
                "http://arxiv.org/pdf/2311.08107v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08106v1",
            "title": "Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language\n  Models",
            "updated": "2023-11-14T12:12:02Z",
            "published": "2023-11-14T12:12:02Z",
            "summary": "In an ever-evolving world, the dynamic nature of knowledge presents\nchallenges for language models that are trained on static data, leading to\noutdated encoded information. However, real-world scenarios require models not\nonly to acquire new knowledge but also to overwrite outdated information into\nupdated ones. To address this under-explored issue, we introduce the temporally\nevolving question answering benchmark, EvolvingQA - a novel benchmark designed\nfor training and evaluating LMs on an evolving Wikipedia database, where the\nconstruction of our benchmark is automated with our pipeline using large\nlanguage models. Our benchmark incorporates question-answering as a downstream\ntask to emulate real-world applications. Through EvolvingQA, we uncover that\nexisting continual learning baselines have difficulty in updating and\nforgetting outdated knowledge. Our findings suggest that the models fail to\nlearn updated knowledge due to the small weight gradient. Furthermore, we\nelucidate that the models struggle mostly on providing numerical or temporal\nanswers to questions asking for updated knowledge. Our work aims to model the\ndynamic nature of real-world information, offering a robust measure for the\nevolution-adaptability of language models.",
            "author": [
                "Yujin Kim",
                "Jaehong Yoon",
                "Seonghyeon Ye",
                "Sung Ju Hwang",
                "Se-young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08106v1",
                "http://arxiv.org/pdf/2311.08106v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08105v2",
            "title": "DiLoCo: Distributed Low-Communication Training of Language Models",
            "updated": "2023-12-02T14:10:14Z",
            "published": "2023-11-14T12:05:45Z",
            "summary": "Large language models (LLM) have become a critical component in many\napplications of machine learning. However, standard approaches to training LLM\nrequire a large number of tightly interconnected accelerators, with devices\nexchanging gradients and other intermediate states at each optimization step.\nWhile it is difficult to build and maintain a single computing cluster hosting\nmany accelerators, it might be easier to find several computing clusters each\nhosting a smaller number of devices. In this work, we propose a distributed\noptimization algorithm, Distributed Low-Communication (DiLoCo), that enables\ntraining of language models on islands of devices that are poorly connected.\nThe approach is a variant of federated averaging, where the number of inner\nsteps is large, the inner optimizer is AdamW, and the outer optimizer is\nNesterov momentum. On the widely used C4 dataset, we show that DiLoCo on 8\nworkers performs as well as fully synchronous optimization while communicating\n500 times less. DiLoCo exhibits great robustness to the data distribution of\neach worker. It is also robust to resources becoming unavailable over time, and\nvice versa, it can seamlessly leverage resources that become available during\ntraining.",
            "author": [
                "Arthur Douillard",
                "Qixuan Feng",
                "Andrei A. Rusu",
                "Rachita Chhaparia",
                "Yani Donchev",
                "Adhiguna Kuncoro",
                "Marc'Aurelio Ranzato",
                "Arthur Szlam",
                "Jiajun Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08105v2",
                "http://arxiv.org/pdf/2311.08105v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08103v1",
            "title": "Exploring Semi-supervised Hierarchical Stacked Encoder for Legal\n  Judgement Prediction",
            "updated": "2023-11-14T12:03:26Z",
            "published": "2023-11-14T12:03:26Z",
            "summary": "Predicting the judgment of a legal case from its unannotated case facts is a\nchallenging task. The lengthy and non-uniform document structure poses an even\ngreater challenge in extracting information for decision prediction. In this\nwork, we explore and propose a two-level classification mechanism; both\nsupervised and unsupervised; by using domain-specific pre-trained BERT to\nextract information from long documents in terms of sentence embeddings further\nprocessing with transformer encoder layer and use unsupervised clustering to\nextract hidden labels from these embeddings to better predict a judgment of a\nlegal case. We conduct several experiments with this mechanism and see higher\nperformance gains than the previously proposed methods on the ILDC dataset. Our\nexperimental results also show the importance of domain-specific pre-training\nof Transformer Encoders in legal information processing.",
            "author": [
                "Nishchal Prasad",
                "Mohand Boughanem",
                "Taoufiq Dkaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08103v1",
                "http://arxiv.org/pdf/2311.08103v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08100v2",
            "title": "DeepEMplanner: An End-to-End EM Motion Planner with Iterative\n  Interactions",
            "updated": "2023-11-29T07:53:47Z",
            "published": "2023-11-14T11:53:24Z",
            "summary": "Motion planning is a computational problem that finds a sequence of valid\ntrajectories, often based on surrounding agents' forecasting, environmental\nunderstanding, and historical and future contexts. It can also be viewed as a\ngame in which agents continuously plan their next move according to other\nagents' intentions and the encountering environment, further achieving their\nultimate goals through incremental actions. To model the dynamic planning and\ninteraction process, we propose a novel framework, DeepEMplanner, which takes\nthe stepwise interaction into account for fine-grained behavior learning. The\nego vehicle maximizes each step motion to reach its eventual driving outcome\nbased on the stepwise expectation from agents and its upcoming road conditions.\nOn the other hand, the agents also follow the same philosophy to maximize their\nstepwise behavior under the encountering environment and the expectations from\nego and other agents. Our DeepEMplanner models the interactions among ego,\nagents, and the dynamic environment in an autoregressive manner by interleaving\nthe Expectation and Maximization processes. Further, we design ego-to-agents,\nego-to-map, and ego-to-BEV interaction mechanisms with hierarchical dynamic key\nobjects attention to better model the interactions. Experiments on the nuScenes\nbenchmark show that our approach achieves state-of-the-art results.",
            "author": [
                "Zhili Chen",
                "Maosheng Ye",
                "Shuangjie Xu",
                "Tongyi Cao",
                "Qifeng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08100v2",
                "http://arxiv.org/pdf/2311.08100v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08098v1",
            "title": "Ab initio path integral Monte Carlo simulations of the uniform electron\n  gas on large length scales",
            "updated": "2023-11-14T11:50:35Z",
            "published": "2023-11-14T11:50:35Z",
            "summary": "The accurate description of non-ideal quantum many-body systems is of prime\nimportance for a host of applications within physics, quantum chemistry,\nmaterial science, and related disciplines. At finite temperatures, the gold\nstandard is given by \\textit{ab initio} path integral Monte Carlo (PIMC)\nsimulations, which do not require any empirical input, but exhibit an\nexponential increase in the required compute time for fermionic systems with\nincreasing the system size $N$. Very recently, it has been suggested to compute\nfermionic properties without this bottleneck based on PIMC simulations of\nfictitious identical particles. In the present work, we use this technique to\ncarry out very large ($N\\leq1000$) PIMC simulations of the warm dense electron\ngas and demonstrate that it is capable of providing a highly accurate\ndescription of investigated properties, i.e., the static structure factor, the\nstatic density response function, and local field correction, over the entire\nrange of length scales.",
            "author": [
                "Tobias Dornheim",
                "Sebastian Schwalbe",
                "Zhandos Moldabekov",
                "Jan Vorberger",
                "Panagiotis Tolias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08098v1",
                "http://arxiv.org/pdf/2311.08098v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.str-el",
                "physics.comp-ph",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08097v1",
            "title": "Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts",
            "updated": "2023-11-14T11:49:43Z",
            "published": "2023-11-14T11:49:43Z",
            "summary": "Chain-of-Thought (CoT) prompting empowers the reasoning abilities of Large\nLanguage Models (LLMs), eliciting them to solve complex reasoning tasks\nstep-by-step. However, with the success of CoT methods, the ability to deliver\nmulti-step reasoning remains limited to English due to the imbalance in the\ndistribution of the pre-training data, making the other languages a barrier.\n  In this work, we propose a Cross-lingual multi-step reasoning approach,\naiming to align reasoning processes across different languages. In particular,\nour method, through a Self-consistent Cross-lingual prompting mechanism\ninspired by the Tree-of-Thoughts approach, delivers multi-step reasoning paths\nin different languages that, during the steps, lead to the final solution. Our\nexperimental evaluations show that our method significantly outperforms\nexisting prompting methods, reducing the number of interactions and achieving\nstate-of-the-art performance.",
            "author": [
                "Leonardo Ranaldi",
                "Fabio Massimo Zanzotto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08097v1",
                "http://arxiv.org/pdf/2311.08097v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08096v1",
            "title": "Leveraging Static Analysis: An IDE for RTLola",
            "updated": "2023-11-14T11:44:41Z",
            "published": "2023-11-14T11:44:41Z",
            "summary": "Runtime monitoring is an essential part of guaranteeing the safety of\ncyber-physical systems. Recently, runtime monitoring frameworks based on formal\nspecification languages gained momentum. These languages provide valuable\nabstractions for specifying the behavior of a system. Yet, writing\nspecifications remains challenging as, among other things, the specifier has to\nkeep track of the timing behavior of streams. This paper presents the RTLola\nPlayground, a browser-based development environment for the stream-based\nruntime monitoring framework RTLola. It features new methods to explore the\nstatic analysis results of RTLola, leveraging the advantages of such a formal\nlanguage to support the developer in writing and understanding specifications.\nSpecifications are executed locally in the browser, plotting the resulting\nstream values, allowing for intuitive testing. Step-wise execution based on\nuser-provided system traces enables the debugging of identified errors.",
            "author": [
                "Bernd Finkbeiner",
                "Florian Kohn",
                "Malte Schledjewski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08096v1",
                "http://arxiv.org/pdf/2311.08096v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08094v1",
            "title": "Act-VIT: A Representationally Robust Attention Architecture for Skeleton\n  Based Action Recognition Using Vision Transformer",
            "updated": "2023-11-14T11:38:38Z",
            "published": "2023-11-14T11:38:38Z",
            "summary": "Skeleton-based action recognition receives the attention of many researchers\nas it is robust to viewpoint and illumination changes, and its processing is\nmuch more efficient than video frames. With the emergence of deep learning\nmodels, it has become very popular to represent the skeleton data in\npseudo-image form and apply Convolutional Neural Networks for action\nrecognition. Thereafter, studies concentrated on finding effective methods for\nforming pseudo-images. Recently, attention networks, more specifically\ntransformers have provided promising results in various vision problems. In\nthis study, the effectiveness of vision transformers for skeleton-based action\nrecognition is examined and its robustness on the pseudo-image representation\nscheme is investigated. To this end, a three-level architecture, Act-VIT is\nproposed, which forms a set of pseudo images apply a classifier on each of the\nrepresentation and combine their results to find the final action class. The\nclassifiers of Act-VIT are first realized by CNNs and then by VITs and their\nperformances are compared. Experimental studies reveal that the vision\ntransformer is less sensitive to the initial pseudo-image representation\ncompared to CNN. Nevertheless, even with the vision transformer, the\nrecognition performance can be further improved by consensus of classifiers.",
            "author": [
                "Ozge Oztimur Karadag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08094v1",
                "http://arxiv.org/pdf/2311.08094v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08093v1",
            "title": "Spot: A Natural Language Interface for Geospatial Searches in OSM",
            "updated": "2023-11-14T11:35:09Z",
            "published": "2023-11-14T11:35:09Z",
            "summary": "Investigative journalists and fact-checkers have found OpenStreetMap (OSM) to\nbe an invaluable resource for their work due to its extensive coverage and\nintricate details of various locations, which play a crucial role in\ninvestigating news scenes. Despite its value, OSM's complexity presents\nconsiderable accessibility and usability challenges, especially for those\nwithout a technical background. To address this, we introduce 'Spot', a\nuser-friendly natural language interface for querying OSM data. Spot utilizes a\nsemantic mapping from natural language to OSM tags, leveraging artificially\ngenerated sentence queries and a T5 transformer. This approach enables Spot to\nextract relevant information from user-input sentences and display candidate\nlocations matching the descriptions on a map. To foster collaboration and\nfuture advancement, all code and generated data is available as an open-source\nrepository.",
            "author": [
                "Lynn Khellaf",
                "Ipek Baris Schlicht",
                "Julia Bayer",
                "Ruben Bouwmeester",
                "Tilman Mira\u00df",
                "Tilman Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08093v1",
                "http://arxiv.org/pdf/2311.08093v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08091v1",
            "title": "Lumiere: Making Optimal BFT for Partial Synchrony Practical",
            "updated": "2023-11-14T11:25:34Z",
            "published": "2023-11-14T11:25:34Z",
            "summary": "The view synchronization problem lies at the heart of many Byzantine Fault\nTolerant (BFT) State Machine Replication (SMR) protocols in the partial\nsynchrony model, since these protocols are usually based on views. Liveness is\nguaranteed if honest processors spend a sufficiently long time in the same view\nduring periods of synchrony, and if the leader of the view is honest. Ensuring\nthat these conditions occur, known as Byzantine View Synchronization (BVS), has\nturned out to be the performance bottleneck of many BFT SMR protocols.\n  A recent line of work has shown that, by using an appropriate view\nsynchronization protocol, BFT SMR protocols can achieve $O(n^2)$ communication\ncomplexity in the worst case after GST, thereby finally matching the lower\nbound established by Dolev and Reischuk in 1985. However, these protocols\nsuffer from two major issues:\n  (1) When implemented so as to be optimistically responsive, even a single\nByzantine processor may infinitely often cause $\\Omega(n\\Delta)$ latency\nbetween consecutive consensus decisions.\n  (2) Even in the absence of Byzantine action, infinitely many views require\nhonest processors to send $\\Omega(n^2)$ messages.\n  Here, we present Lumiere, an optimistically responsive BVS protocol which\nmaintains optimal worst-case communication complexity while simultaneously\naddressing the two issues above: for the first time, Lumiere enables BFT\nconsensus solutions in the partial synchrony setting that have $O(n^2)$\nworst-case communication complexity, and that eventually always (i.e., except\nfor a small constant number of \"warmup\" decisions) have communication\ncomplexity and latency which is linear in the number of actual faults in the\nexecution.",
            "author": [
                "Andrew Lewis-Pye",
                "Dahlia Malkhi",
                "Oded Naor",
                "Kartik Nayak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08091v1",
                "http://arxiv.org/pdf/2311.08091v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08089v1",
            "title": "Align after Pre-train: Improving Multilingual Generative Models with\n  Cross-lingual Alignment",
            "updated": "2023-11-14T11:24:08Z",
            "published": "2023-11-14T11:24:08Z",
            "summary": "Multilingual generative models obtain remarkable cross-lingual capabilities\nthrough pre-training on large-scale corpora. However, they still exhibit a\nperformance bias toward high-resource languages, and learn isolated\ndistributions of sentence representations across languages. To bridge this gap,\nwe propose a simple yet effective alignment framework exploiting pairs of\ntranslation sentences. It aligns the internal sentence representations across\ndifferent languages via multilingual contrastive learning and aligns model\noutputs by answering prompts in different languages. Experimental results\ndemonstrate that even with less than 0.1 {\\textperthousand} of pre-training\ntokens, our alignment framework significantly boosts the cross-lingual\nabilities of generative models and mitigates the performance gap. Further\nanalysis reveals that it results in a better internal multilingual\nrepresentation distribution of multilingual models.",
            "author": [
                "Chong Li",
                "Shaonan Wang",
                "Jiajun Zhang",
                "Chengqing Zong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08089v1",
                "http://arxiv.org/pdf/2311.08089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08083v1",
            "title": "Solving ARC visual analogies with neural embeddings and vector\n  arithmetic: A generalized method",
            "updated": "2023-11-14T11:10:46Z",
            "published": "2023-11-14T11:10:46Z",
            "summary": "Analogical reasoning derives information from known relations and generalizes\nthis information to similar yet unfamiliar situations. One of the first\ngeneralized ways in which deep learning models were able to solve verbal\nanalogies was through vector arithmetic of word embeddings, essentially\nrelating words that were mapped to a vector space (e.g., king - man + woman =\n__?). In comparison, most attempts to solve visual analogies are still\npredominantly task-specific and less generalizable. This project focuses on\nvisual analogical reasoning and applies the initial generalized mechanism used\nto solve verbal analogies to the visual realm. Taking the Abstraction and\nReasoning Corpus (ARC) as an example to investigate visual analogy solving, we\nuse a variational autoencoder (VAE) to transform ARC items into low-dimensional\nlatent vectors, analogous to the word embeddings used in the verbal approaches.\nThrough simple vector arithmetic, underlying rules of ARC items are discovered\nand used to solve them. Results indicate that the approach works well on simple\nitems with fewer dimensions (i.e., few colors used, uniform shapes), similar\ninput-to-output examples, and high reconstruction accuracy on the VAE.\nPredictions on more complex items showed stronger deviations from expected\noutputs, although, predictions still often approximated parts of the item's\nrule set. Error patterns indicated that the model works as intended. On the\nofficial ARC paradigm, the model achieved a score of 2% (cf. current world\nrecord is 21%) and on ConceptARC it scored 8.8%. Although the methodology\nproposed involves basic dimensionality reduction techniques and standard vector\narithmetic, this approach demonstrates promising outcomes on ARC and can easily\nbe generalized to other abstract visual reasoning tasks.",
            "author": [
                "Luca H. Thoms",
                "Karel A. Veldkamp",
                "Hannes Rosenbusch",
                "Claire E. Stevenson"
            ],
            "link": [
                "http://dx.doi.org/10.17605/OSF.IO/AKP86",
                "http://arxiv.org/abs/2311.08083v1",
                "http://arxiv.org/pdf/2311.08083v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08081v1",
            "title": "Evolutionary-enhanced quantum supervised learning model",
            "updated": "2023-11-14T11:08:47Z",
            "published": "2023-11-14T11:08:47Z",
            "summary": "Quantum supervised learning, utilizing variational circuits, stands out as a\npromising technology for NISQ devices due to its efficiency in hardware\nresource utilization during the creation of quantum feature maps and the\nimplementation of hardware-efficient ansatz with trainable parameters. Despite\nthese advantages, the training of quantum models encounters challenges, notably\nthe barren plateau phenomenon, leading to stagnation in learning during\noptimization iterations. This study proposes an innovative approach: an\nevolutionary-enhanced ansatz-free supervised learning model. In contrast to\nparametrized circuits, our model employs circuits with variable topology that\nevolves through an elitist method, mitigating the barren plateau issue.\nAdditionally, we introduce a novel concept, the superposition of multi-hot\nencodings, facilitating the treatment of multi-classification problems. Our\nframework successfully avoids barren plateaus, resulting in enhanced model\naccuracy. Comparative analysis with variational quantum classifiers from the\ntechnology's state-of-the-art reveal a substantial improvement in training\nefficiency and precision. Furthermore, we conduct tests on a challenging\ndataset class, traditionally problematic for conventional kernel machines,\ndemonstrating a potential alternative path for achieving quantum advantage in\nsupervised learning for NISQ era.",
            "author": [
                "Anton Simen Albino",
                "Rodrigo Bloot",
                "Otto M. Pires",
                "Erick G. S. Nascimento"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08081v1",
                "http://arxiv.org/pdf/2311.08081v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08080v1",
            "title": "Identifying Light-curve Signals with a Deep Learning Based Object\n  Detection Algorithm. II. A General Light Curve Classification Framework",
            "updated": "2023-11-14T11:08:34Z",
            "published": "2023-11-14T11:08:34Z",
            "summary": "Vast amounts of astronomical photometric data are generated from various\nprojects, requiring significant efforts to identify variable stars and other\nobject classes. In light of this, a general, widely applicable classification\nframework would simplify the task of designing custom classifiers. We present a\nnovel deep learning framework for classifying light curves using a weakly\nsupervised object detection model. Our framework identifies the optimal windows\nfor both light curves and power spectra automatically, and zooms in on their\ncorresponding data. This allows for automatic feature extraction from both time\nand frequency domains, enabling our model to handle data across different\nscales and sampling intervals. We train our model on datasets obtained from\nboth space-based and ground-based multi-band observations of variable stars and\ntransients. We achieve an accuracy of 87% for combined variables and transient\nevents, which is comparable to the performance of previous feature-based\nmodels. Our trained model can be utilized directly to other missions, such as\nASAS-SN, without requiring any retraining or fine-tuning. To address known\nissues with miscalibrated predictive probabilities, we apply conformal\nprediction to generate robust predictive sets that guarantee true label\ncoverage with a given probability. Additionally, we incorporate various anomaly\ndetection algorithms to empower our model with the ability to identify\nout-of-distribution objects. Our framework is implemented in the Deep-LC\ntoolkit, which is an open-source Python package hosted on Github and PyPI.",
            "author": [
                "Kaiming Cui",
                "D. J. Armstrong",
                "Fabo Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08080v1",
                "http://arxiv.org/pdf/2311.08080v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.HE",
                "astro-ph.SR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08079v1",
            "title": "Creating equilibrium glassy states via random particle bonding",
            "updated": "2023-11-14T11:06:49Z",
            "published": "2023-11-14T11:06:49Z",
            "summary": "Creating amorphous solid states by randomly bonding an ensemble of dense\nliquid monomers is a common procedure which is applied to create a variety of\nmaterials such as epoxy resins, colloidal gels, and vitrimers. The properties\nof the resulting solid do, however, {\\it a priori} strongly depend on the\npreparation history. This can lead to substantial aging of the material, i.e.,\nproperties such as mechanical moduli and transport coefficients depend on the\ntime elapsed since solidification, which can lead to a slow degradation of the\nmaterial in technological applications. It is therefore important to understand\nunder which conditions random monomer bonding can lead to stable solid states,\ni.e., long-lived metastable states whose properties do not change over time. In\nthis work, we present a theoretical and computational analysis of this problem,\nand introduce a random bonding procedure that guarantees the proper\nequilibration of the resulting amorphous states. Our procedure also provides a\nnew route to investigate the fundamental properties of glassy energy landscapes\nby producing translationally-invariant ultrastable glassy states of simple\nparticle models.",
            "author": [
                "Misaki Ozawa",
                "Jean-Louis Barrat",
                "Walter Kob",
                "Francesco Zamponi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08079v1",
                "http://arxiv.org/pdf/2311.08079v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08078v1",
            "title": "Wave-front sets for $p$-adic Lie algebras",
            "updated": "2023-11-14T11:06:22Z",
            "published": "2023-11-14T11:06:22Z",
            "summary": "We study the wave-front set of an element in a $p$-adic reductive Lie algebra\n(for $p\\gg\\operatorname{rank}$), namely the set of maximal nilpotent orbits\nappearing in its Shalika germ expansion. By adapting an algorithm of\nWaldspurger that computes orbital integrals, we obtain an inductive algorithm\nto compute an invariant that determines the wave-front set. This gives an\nalgorithm to compute the wave-front sets for regular supercuspidal\nrepresentations and reveals examples whose wave-front sets are not contained in\na single geometric orbit, for arbitrarily large $p$ within a fixed rank.",
            "author": [
                "Cheng-Chiang Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08078v1",
                "http://arxiv.org/pdf/2311.08078v1"
            ],
            "primary_category": "math.RT",
            "category": [
                "math.RT",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08077v1",
            "title": "Zero-Shot Segmentation of Eye Features Using the Segment Anything Model\n  (SAM)",
            "updated": "2023-11-14T11:05:08Z",
            "published": "2023-11-14T11:05:08Z",
            "summary": "The advent of foundation models signals a new era in artificial intelligence.\nThe Segment Anything Model (SAM) is the first foundation model for image\nsegmentation. In this study, we evaluate SAM's ability to segment features from\neye images recorded in virtual reality setups. The increasing requirement for\nannotated eye-image datasets presents a significant opportunity for SAM to\nredefine the landscape of data annotation in gaze estimation. Our investigation\ncenters on SAM's zero-shot learning abilities and the effectiveness of prompts\nlike bounding boxes or point clicks. Our results are consistent with studies in\nother domains, demonstrating that SAM's segmentation effectiveness can be\non-par with specialized models depending on the feature, with prompts improving\nits performance, evidenced by an IoU of 93.34% for pupil segmentation in one\ndataset. Foundation models like SAM could revolutionize gaze estimation by\nenabling quick and easy image segmentation, reducing reliance on specialized\nmodels and extensive manual annotation.",
            "author": [
                "Virmarie Maquiling",
                "Sean Anthony Byrne",
                "Diederick C. Niehorster",
                "Marcus Nystr\u00f6m",
                "Enkelejda Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08077v1",
                "http://arxiv.org/pdf/2311.08077v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08075v1",
            "title": "GlanceSeg: Real-time microaneurysm lesion segmentation with\n  gaze-map-guided foundation model for early detection of diabetic retinopathy",
            "updated": "2023-11-14T10:59:45Z",
            "published": "2023-11-14T10:59:45Z",
            "summary": "Early-stage diabetic retinopathy (DR) presents challenges in clinical\ndiagnosis due to inconspicuous and minute microangioma lesions, resulting in\nlimited research in this area. Additionally, the potential of emerging\nfoundation models, such as the segment anything model (SAM), in medical\nscenarios remains rarely explored. In this work, we propose a\nhuman-in-the-loop, label-free early DR diagnosis framework called GlanceSeg,\nbased on SAM. GlanceSeg enables real-time segmentation of microangioma lesions\nas ophthalmologists review fundus images. Our human-in-the-loop framework\nintegrates the ophthalmologist's gaze map, allowing for rough localization of\nminute lesions in fundus images. Subsequently, a saliency map is generated\nbased on the located region of interest, which provides prompt points to assist\nthe foundation model in efficiently segmenting microangioma lesions. Finally, a\ndomain knowledge filter refines the segmentation of minute lesions. We\nconducted experiments on two newly-built public datasets, i.e., IDRiD and\nRetinal-Lesions, and validated the feasibility and superiority of GlanceSeg\nthrough visualized illustrations and quantitative measures. Additionally, we\ndemonstrated that GlanceSeg improves annotation efficiency for clinicians and\nenhances segmentation performance through fine-tuning using annotations. This\nstudy highlights the potential of GlanceSeg-based annotations for self-model\noptimization, leading to enduring performance advancements through continual\nlearning.",
            "author": [
                "Hongyang Jiang",
                "Mengdi Gao",
                "Zirong Liu",
                "Chen Tang",
                "Xiaoqing Zhang",
                "Shuai Jiang",
                "Wu Yuan",
                "Jiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08075v1",
                "http://arxiv.org/pdf/2311.08075v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08074v1",
            "title": "Content-Adaptive Variable Framerate Encoding Scheme for Green Live\n  Streaming",
            "updated": "2023-11-14T10:58:57Z",
            "published": "2023-11-14T10:58:57Z",
            "summary": "Adaptive live video streaming applications use a fixed predefined\nconfiguration for the bitrate ladder with constant framerate and encoding\npresets in a session. However, selecting optimized framerates and presets for\nevery bitrate ladder representation can enhance perceptual quality, improve\ncomputational resource allocation, and thus, the streaming energy efficiency.\nIn particular, low framerates for low-bitrate representations reduce\ncompression artifacts and decrease encoding energy consumption. In addition, an\noptimized preset may lead to improved compression efficiency. To this light,\nthis paper proposes a Content-adaptive Variable Framerate (CVFR) encoding\nscheme, which offers two modes of operation: ecological (ECO) and high-quality\n(HQ). CVFR-ECO optimizes for the highest encoding energy savings by predicting\nthe optimized framerate for each representation in the bitrate ladder. CVFR-HQ\ntakes it further by predicting each representation's optimized\nframerate-encoding preset pair using low-complexity discrete cosine transform\nenergy-based spatial and temporal features for compression efficiency and\nsustainable storage. We demonstrate the advantage of CVFR using the x264\nopen-source video encoder. The results show that CVFR-ECO yields an average\nPSNR and VMAF increase of 0.02 dB and 2.50 points, respectively, for the same\nbitrate, compared to the fastest preset highest framerate encoding. CVFR-ECO\nalso yields an average encoding and storage energy consumption reduction of\n34.54% and 76.24%, considering a just noticeable difference (JND) of six VMAF\npoints. In comparison, CVFR-HQ yields an average increase in PSNR and VMAF of\n2.43 dB and 10.14 points, respectively, for the same bitrate. Finally, CVFR-HQ\nresulted in an average reduction in storage energy consumption of 83.18%,\nconsidering a JND of six VMAF points.",
            "author": [
                "Vignesh V Menon",
                "Samira Afzal",
                "Prajit T Rajendran",
                "Klaus Schoeffmann",
                "Radu Prodan",
                "Christian Timmerer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08074v1",
                "http://arxiv.org/pdf/2311.08074v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08069v1",
            "title": "On Bivariate Pseudo-Logistic Distribution: Its Properties, Estimation\n  and Applications",
            "updated": "2023-11-14T10:48:03Z",
            "published": "2023-11-14T10:48:03Z",
            "summary": "The literature has covered the features and uses of the traditional\nunivariate and bivariate logistic distributions in great detail. It is\nreasonable to wonder, though, if logistic marginals and conditionals could\nexhibit a similar behavior. A phenomenon that is comparable to both bivariate\nexponential and bivariate normal distributions. In this study, we will\nconcentrate on bivariate distributions where one family of conditionals is\nmarginal and the other family is of logistic type. Pseudo-logistic\ndistributions are the name for such distributions. Research on conditionally\nspecified models has revealed, however, that only in cases where the variables\nare independent will logistic marginals and both conditionals be of the\nlogistic form occur. We talk about the features of distributional aspects and\nhow they are built using the original. Both the original and the new\nconditioning regimes are used in two different ways. Possible generalizations\nare also considered. We also provide an example of a Pseudo-logistic model\napplication.",
            "author": [
                "Banoth Veeranna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08069v1",
                "http://arxiv.org/pdf/2311.08069v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08060v2",
            "title": "All Byzantine Agreement Problems are Expensive",
            "updated": "2023-11-15T05:47:11Z",
            "published": "2023-11-14T10:33:46Z",
            "summary": "Byzantine agreement, arguably the most fundamental problem in distributed\ncomputing, operates among n processes, out of which t < n can exhibit arbitrary\nfailures. The problem states that all correct (non-faulty) processes must\neventually decide (termination) the same value (agreement) from a set of\nadmissible values defined by the proposals of the processes (validity).\nDepending on the exact version of the validity property, Byzantine agreement\ncomes in different forms, from Byzantine broadcast to strong and weak\nconsensus, to modern variants of the problem introduced in today's blockchain\nsystems. Regardless of the specific flavor of the agreement problem, its\ncommunication cost is a fundamental metric whose improvement has been the focus\nof decades of research. The Dolev-Reischuk bound, one of the most celebrated\nresults in distributed computing, proved 40 years ago that, at least for\nByzantine broadcast, no deterministic solution can do better than Omega(t^2)\nexchanged messages in the worst case. Since then, it remained unknown whether\nthe quadratic lower bound extends to seemingly weaker variants of Byzantine\nagreement. This paper answers the question in the affirmative, closing this\nlong-standing open problem. Namely, we prove that any non-trivial agreement\nproblem requires Omega(t^2) messages to be exchanged in the worst case. To\nprove the general lower bound, we determine the weakest Byzantine agreement\nproblem and show, via a novel indistinguishability argument, that it incurs\nOmega(t^2) exchanged messages.",
            "author": [
                "Pierre Civit",
                "Seth Gilbert",
                "Rachid Guerraoui",
                "Jovan Komatovic",
                "Anton Paramonov",
                "Manuel Vidigueira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08060v2",
                "http://arxiv.org/pdf/2311.08060v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08059v2",
            "title": "FS-Net: Full Scale Network and Adaptive Threshold for Improving\n  Extraction of Micro-Retinal Vessel Structures",
            "updated": "2023-11-19T14:18:34Z",
            "published": "2023-11-14T10:32:17Z",
            "summary": "Retinal vascular segmentation, is a widely researched subject in biomedical\nimage processing, aims to relieve ophthalmologists' workload when treating and\ndetecting retinal disorders. However, segmenting retinal vessels has its own\nset of challenges, with prior techniques failing to generate adequate results\nwhen segmenting branches and microvascular structures. The neural network\napproaches used recently are characterized by the inability to keep local and\nglobal properties together and the failure to capture tiny end vessels make it\nchallenging to attain the desired result. To reduce this retinal vessel\nsegmentation problem, we propose a full-scale micro-vessel extraction mechanism\nbased on an encoder-decoder neural network architecture, sigmoid smoothing, and\nan adaptive threshold method. The network consists of of residual, encoder\nbooster, bottleneck enhancement, squeeze, and excitation building blocks. All\nof these blocks together help to improve the feature extraction and prediction\nof the segmentation map. The proposed solution has been evaluated using the\nDRIVE, CHASE-DB1, and STARE datasets, and competitive results are obtained when\ncompared with previous studies. The AUC and accuracy on the DRIVE dataset are\n0.9884 and 0.9702, respectively. On the CHASE-DB1 dataset, the scores are\n0.9903 and 0.9755, respectively. On the STARE dataset, the scores are 0.9916\nand 0.9750, respectively. The performance achieved is one step ahead of what\nhas been done in previous studies, and this results in a higher chance of\nhaving this solution in real-life diagnostic centers that seek ophthalmologists\nattention.",
            "author": [
                "Melaku N. Getahun",
                "Oleg Y. Rogov",
                "Dmitry V. Dylov",
                "Andrey Somov",
                "Ahmed Bouridane",
                "Rifat Hamoudi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08059v2",
                "http://arxiv.org/pdf/2311.08059v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08057v1",
            "title": "Data and models for stance and premise detection in COVID-19 tweets:\n  insights from the Social Media Mining for Health (SMM4H) 2022 shared task",
            "updated": "2023-11-14T10:30:49Z",
            "published": "2023-11-14T10:30:49Z",
            "summary": "The COVID-19 pandemic has sparked numerous discussions on social media\nplatforms, with users sharing their views on topics such as mask-wearing and\nvaccination. To facilitate the evaluation of neural models for stance detection\nand premise classification, we organized the Social Media Mining for Health\n(SMM4H) 2022 Shared Task 2. This competition utilized manually annotated posts\non three COVID-19-related topics: school closures, stay-at-home orders, and\nwearing masks. In this paper, we extend the previous work and present newly\ncollected data on vaccination from Twitter to assess the performance of models\non a different topic. To enhance the accuracy and effectiveness of our\nevaluation, we employed various strategies to aggregate tweet texts with\nclaims, including models with feature-level (early) fusion and dual-view\narchitectures from SMM4H 2022 leaderboard. Our primary objective was to create\na valuable dataset and perform an extensive experimental evaluation to support\nfuture research in argument mining in the health domain.",
            "author": [
                "Vera Davydova",
                "Huabin Yang",
                "Elena Tutubalina"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jbi.2023.104555",
                "http://arxiv.org/abs/2311.08057v1",
                "http://arxiv.org/pdf/2311.08057v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SI",
                "I.2.7; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08050v1",
            "title": "INLA+ -- Approximate Bayesian inference for non-sparse models using HPC",
            "updated": "2023-11-14T10:16:49Z",
            "published": "2023-11-14T10:16:49Z",
            "summary": "The integrated nested Laplace approximations (INLA) method has become a\nwidely utilized tool for researchers and practitioners seeking to perform\napproximate Bayesian inference across various fields of application. To address\nthe growing demand for incorporating more complex models and enhancing the\nmethod's capabilities, this paper introduces a novel framework that leverages\ndense matrices for performing approximate Bayesian inference based on INLA\nacross multiple computing nodes using HPC. When dealing with non-sparse\nprecision or covariance matrices, this new approach scales better compared to\nthe current INLA method, capitalizing on the computational power offered by\nmultiprocessors in shared and distributed memory architectures available in\ncontemporary computing resources and specialized dense matrix algebra. To\nvalidate the efficacy of this approach, we conduct a simulation study then\napply it to analyze cancer mortality data in Spain, employing a three-way\nspatio-temporal interaction model.",
            "author": [
                "Esmail Abdul-Fattah",
                "Janet Van Niekerk",
                "Haavard Rue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08050v1",
                "http://arxiv.org/pdf/2311.08050v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08049v1",
            "title": "Towards Reliable AI: Adequacy Metrics for Ensuring the Quality of\n  System-level Testing of Autonomous Vehicles",
            "updated": "2023-11-14T10:16:05Z",
            "published": "2023-11-14T10:16:05Z",
            "summary": "AI-powered systems have gained widespread popularity in various domains,\nincluding Autonomous Vehicles (AVs). However, ensuring their reliability and\nsafety is challenging due to their complex nature. Conventional test adequacy\nmetrics, designed to evaluate the effectiveness of traditional software\ntesting, are often insufficient or impractical for these systems. White-box\nmetrics, which are specifically designed for these systems, leverage neuron\ncoverage information. These coverage metrics necessitate access to the\nunderlying AI model and training data, which may not always be available.\nFurthermore, the existing adequacy metrics exhibit weak correlations with the\nability to detect faults in the generated test suite, creating a gap that we\naim to bridge in this study.\n  In this paper, we introduce a set of black-box test adequacy metrics called\n\"Test suite Instance Space Adequacy\" (TISA) metrics, which can be used to gauge\nthe effectiveness of a test suite. The TISA metrics offer a way to assess both\nthe diversity and coverage of the test suite and the range of bugs detected\nduring testing. Additionally, we introduce a framework that permits testers to\nvisualise the diversity and coverage of the test suite in a two-dimensional\nspace, facilitating the identification of areas that require improvement.\n  We evaluate the efficacy of the TISA metrics by examining their correlation\nwith the number of bugs detected in system-level simulation testing of AVs. A\nstrong correlation, coupled with the short computation time, indicates their\neffectiveness and efficiency in estimating the adequacy of testing AVs.",
            "author": [
                "Neelofar Neelofar",
                "Aldeida Aleti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08049v1",
                "http://arxiv.org/pdf/2311.08049v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08048v1",
            "title": "Analyze business context data in developing economies using quantum\n  computing",
            "updated": "2023-11-14T10:15:40Z",
            "published": "2023-11-14T10:15:40Z",
            "summary": "Quantum computing is an advancing area of computing sciences and provides a\nnew base of development for many futuristic technologies discussions on how it\ncan help developing economies will further help developed economies in\ntechnology transfer and economic development initiatives related to Research\nand development within developing countries thus providing a new means of\nforeign direct investment(FDI) and business innovation for the majority of the\nglobe that lacks infrastructure economic resources required for growth in the\ntechnology landscape and cyberinfrastructure for growth in computing\napplications. Discussion of which areas of support quantum computing can help\nwill further assist developing economies in implementing it for growth\nopportunities for local systems and businesses.",
            "author": [
                "Ammar Jamshed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08048v1",
                "http://arxiv.org/pdf/2311.08048v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08046v1",
            "title": "Chat-UniVi: Unified Visual Representation Empowers Large Language Models\n  with Image and Video Understanding",
            "updated": "2023-11-14T10:11:36Z",
            "published": "2023-11-14T10:11:36Z",
            "summary": "Large language models have demonstrated impressive universal capabilities\nacross a wide range of open-ended tasks and have extended their utility to\nencompass multimodal conversations. However, existing methods encounter\nchallenges in effectively handling both image and video understanding,\nparticularly with limited visual tokens. In this work, we introduce Chat-UniVi,\na unified vision-language model capable of comprehending and engaging in\nconversations involving images and videos through a unified visual\nrepresentation. Specifically, we employ a set of dynamic visual tokens to\nuniformly represent images and videos. This representation framework empowers\nthe model to efficiently utilize a limited number of visual tokens to\nsimultaneously capture the spatial details necessary for images and the\ncomprehensive temporal relationship required for videos. Moreover, we leverage\na multi-scale representation, enabling the model to perceive both high-level\nsemantic concepts and low-level visual details. Notably, Chat-UniVi is trained\non a mixed dataset containing both images and videos, allowing direct\napplication to tasks involving both mediums without requiring any\nmodifications. Extensive experimental results demonstrate that Chat-UniVi, as a\nunified model, consistently outperforms even existing methods exclusively\ndesigned for either images or videos.",
            "author": [
                "Peng Jin",
                "Ryuichi Takanobu",
                "Caiwan Zhang",
                "Xiaochun Cao",
                "Li Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08046v1",
                "http://arxiv.org/pdf/2311.08046v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08045v1",
            "title": "Adversarial Preference Optimization",
            "updated": "2023-11-14T10:10:31Z",
            "published": "2023-11-14T10:10:31Z",
            "summary": "Human preference alignment is a crucial training step to improve the\ninteraction quality of large language models (LLMs). Existing aligning methods\ndepend on manually annotated preference data to guide the LLM optimization\ndirections. However, in practice, continuously updating LLMs raises a\ndistribution gap between model-generated samples and human-preferred responses,\nwhich hinders model fine-tuning efficiency. To mitigate this issue, previous\nmethods require additional preference annotation on generated samples to adapt\nthe shifted distribution, which consumes a large amount of annotation\nresources. Targeting more efficient human preference optimization, we propose\nan adversarial preference optimization (APO) framework, where the LLM agent and\nthe preference model update alternatively via a min-max game. Without\nadditional annotation, our APO method can make a self-adaption to the\ngeneration distribution gap through the adversarial learning process. In\nexperiments, we empirically verify the effectiveness of APO in improving LLM's\nhelpfulness and harmlessness compared with rejection sampling baselines.",
            "author": [
                "Pengyu Cheng",
                "Yifan Yang",
                "Jian Li",
                "Yong Dai",
                "Nan Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08045v1",
                "http://arxiv.org/pdf/2311.08045v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08043v1",
            "title": "Contrastive Learning for Multi-Object Tracking with Transformers",
            "updated": "2023-11-14T10:07:52Z",
            "published": "2023-11-14T10:07:52Z",
            "summary": "The DEtection TRansformer (DETR) opened new possibilities for object\ndetection by modeling it as a translation task: converting image features into\nobject-level representations. Previous works typically add expensive modules to\nDETR to perform Multi-Object Tracking (MOT), resulting in more complicated\narchitectures. We instead show how DETR can be turned into a MOT model by\nemploying an instance-level contrastive loss, a revised sampling strategy and a\nlightweight assignment method. Our training scheme learns object appearances\nwhile preserving detection capabilities and with little overhead. Its\nperformance surpasses the previous state-of-the-art by +2.6 mMOTA on the\nchallenging BDD100K dataset and is comparable to existing transformer-based\nmethods on the MOT17 dataset.",
            "author": [
                "Pierre-Fran\u00e7ois De Plaen",
                "Nicola Marinello",
                "Marc Proesmans",
                "Tinne Tuytelaars",
                "Luc Van Gool"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08043v1",
                "http://arxiv.org/pdf/2311.08043v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08040v1",
            "title": "On the Masking-Friendly Designs for Post-Quantum Cryptography",
            "updated": "2023-11-14T10:00:58Z",
            "published": "2023-11-14T10:00:58Z",
            "summary": "Masking is a well-known and provably secure countermeasure against\nside-channel attacks. However, due to additional redundant computations,\nintegrating masking schemes is expensive in terms of performance. The\nperformance overhead of integrating masking countermeasures is heavily\ninfluenced by the design choices of a cryptographic algorithm and is often not\nconsidered during the design phase.\n  In this work, we deliberate on the effect of design choices on integrating\nmasking techniques into lattice-based cryptography. We select Scabbard, a suite\nof three lattice-based post-quantum key-encapsulation mechanisms (KEM), namely\nFlorete, Espada, and Sable. We provide arbitrary-order masked implementations\nof all the constituent KEMs of the Scabbard suite by exploiting their specific\ndesign elements. We show that the masked implementations of Florete, Espada,\nand Sable outperform the masked implementations of Kyber in terms of speed for\nany order masking. Masked Florete exhibits a $73\\%$, $71\\%$, and $70\\%$\nperformance improvement over masked Kyber corresponding to the first-, second-,\nand third-order. Similarly, Espada exhibits $56\\%$, $59\\%$, and $60\\%$ and\nSable exhibits $75\\%$, $74\\%$, and $73\\%$ enhanced performance for first-,\nsecond-, and third-order masking compared to Kyber respectively. Our results\nshow that the design decisions have a significant impact on the efficiency of\nintegrating masking countermeasures into lattice-based cryptography.",
            "author": [
                "Suparna Kundu",
                "Angshuman Karmakar",
                "Ingrid Verbauwhede"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08040v1",
                "http://arxiv.org/pdf/2311.08040v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "E.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08037v1",
            "title": "Combining Precision Boosting with LP Iterative Refinement for Exact\n  Linear Optimization",
            "updated": "2023-11-14T09:59:29Z",
            "published": "2023-11-14T09:59:29Z",
            "summary": "This article studies a combination of the two state-of-the-art algorithms for\nthe exact solution of linear programs (LPs) over the rational numbers, i.e.,\nwithout any roundoff errors or numerical tolerances. By integrating the method\nof precision boosting inside an LP iterative refinement loop, the combined\nalgorithm is able to leverage the strengths of both methods: the speed of LP\niterative refinement, in particular in the majority of cases when a\ndouble-precision floating-point solver is able to compute approximate solutions\nwith small errors, and the robustness of precision boosting whenever extended\nlevels of precision become necessary. We compare the practical performance of\nthe resulting algorithm with both puremethods on a large set of LPs and\nmixed-integer programs (MIPs). The results show that the combined algorithm\nsolves more instances than a pure LP iterative refinement approach, while being\nfaster than pure precision boosting. When embedded in an exact branch-and-cut\nframework for MIPs, the combined algorithm is able to reduce the number of\nfailed calls to the exact LP solver to zero, while maintaining the speed of the\npure LP iterative refinement approach.",
            "author": [
                "Leon Eifler",
                "Jules Nicolas-Thouvenin",
                "Ambros Gleixner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08037v1",
                "http://arxiv.org/pdf/2311.08037v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "65K05, 90C11, 90-08"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08035v1",
            "title": "Data-driven building energy efficiency prediction based on envelope heat\n  losses using physics-informed neural networks",
            "updated": "2023-11-14T09:55:03Z",
            "published": "2023-11-14T09:55:03Z",
            "summary": "The analytical prediction of building energy performance in residential\nbuildings based on the heat losses of its individual envelope components is a\nchallenging task. It is worth noting that this field is still in its infancy,\nwith relatively limited research conducted in this specific area to date,\nespecially when it comes for data-driven approaches. In this paper we introduce\na novel physics-informed neural network model for addressing this problem.\nThrough the employment of unexposed datasets that encompass general building\ninformation, audited characteristics, and heating energy consumption, we feed\nthe deep learning model with general building information, while the model's\noutput consists of the structural components and several thermal properties\nthat are in fact the basic elements of an energy performance certificate (EPC).\nOn top of this neural network, a function, based on physics equations,\ncalculates the energy consumption of the building based on heat losses and\nenhances the loss function of the deep learning model. This methodology is\ntested on a real case study for 256 buildings located in Riga, Latvia. Our\ninvestigation comes up with promising results in terms of prediction accuracy,\npaving the way for automated, and data-driven energy efficiency performance\nprediction based on basic properties of the building, contrary to exhaustive\nenergy efficiency audits led by humans, which are the current status quo.",
            "author": [
                "Vasilis Michalakopoulos",
                "Sotiris Pelekis",
                "Giorgos Kormpakis",
                "Vagelis Karakolis",
                "Spiros Mouzakitis",
                "Dimitris Askounis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08035v1",
                "http://arxiv.org/pdf/2311.08035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08033v1",
            "title": "Eccentricity-induced systematic error on parametrized tests of general\n  relativity: hierarchical Bayesian inference applied to a binary black hole\n  population",
            "updated": "2023-11-14T09:53:01Z",
            "published": "2023-11-14T09:53:01Z",
            "summary": "One approach to testing general relativity (GR) introduces free parameters in\nthe post-Newtonian (PN) expansion of the gravitational-wave (GW) phase. If\nsystematic errors on these testing GR (TGR) parameters exceed the statistical\nerrors, this may signal a false violation of GR. Here, we consider systematic\nerrors produced by unmodeled binary eccentricity. Since the eccentricity of GW\nevents in ground-based detectors is expected to be small or negligible, the use\nof quasicircular waveform models for testing GR may be safe when analyzing a\nsmall number of events. However, as the catalog size of GW detections\nincreases, more stringent bounds on GR deviations can be placed by combining\ninformation from multiple events. In that case, even small systematic biases\nmay become significant. We apply the approach of hierarchical Bayesian\ninference to model the posterior probability distributions of the TGR\nparameters inferred from a population of eccentric binary black holes (BBHs).\nWe assume each TGR parameter value varies across the BBH population according\nto a Gaussian distribution. We compute the posterior distributions for these\nGaussian hyperparameters. This is done for LIGO and Cosmic Explorer (CE). We\nfind that systematic biases from unmodeled eccentricity can signal false GR\nviolations for both detectors when considering constraints set by a catalog of\nevents. We also compute the projected bounds on the $10$ TGR parameters when\neccentricity is included as a parameter in the waveform model. We find that the\nfirst four dimensionless TGR deformation parameters can be bounded at $90\\%$\nconfidence to $\\delta \\hat{\\varphi}_i \\lesssim 10^{-2}$ for LIGO and $\\lesssim\n10^{-3}$ for CE [where $i=(0,1,2,3)$]. In comparison to the circular orbit\ncase, the combined bounds on the TGR parameters worsen by a modest factor of\n$\\lesssim 2$ when eccentricity is included in the waveform.",
            "author": [
                "Pankaj Saini",
                "Sajad A. Bhat",
                "Marc Favata",
                "K. G. Arun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08033v1",
                "http://arxiv.org/pdf/2311.08033v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08032v1",
            "title": "ELF: An End-to-end Local and Global Multimodal Fusion Framework for\n  Glaucoma Grading",
            "updated": "2023-11-14T09:51:00Z",
            "published": "2023-11-14T09:51:00Z",
            "summary": "Glaucoma is a chronic neurodegenerative condition that can lead to blindness.\nEarly detection and curing are very important in stopping the disease from\ngetting worse for glaucoma patients. The 2D fundus images and optical coherence\ntomography(OCT) are useful for ophthalmologists in diagnosing glaucoma. There\nare many methods based on the fundus images or 3D OCT volumes; however, the\nmining for multi-modality, including both fundus images and data, is less\nstudied. In this work, we propose an end-to-end local and global multi-modal\nfusion framework for glaucoma grading, named ELF for short. ELF can fully\nutilize the complementary information between fundus and OCT. In addition,\nunlike previous methods that concatenate the multi-modal features together,\nwhich lack exploring the mutual information between different modalities, ELF\ncan take advantage of local-wise and global-wise mutual information. The\nextensive experiment conducted on the multi-modal glaucoma grading GAMMA\ndataset can prove the effiectness of ELF when compared with other\nstate-of-the-art methods.",
            "author": [
                "Wenyun Li",
                "Chi-Man Pun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08032v1",
                "http://arxiv.org/pdf/2311.08032v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08435v1",
            "title": "Finite temperature quantum field theory under the influence of 3D\n  lattices",
            "updated": "2023-11-14T09:41:32Z",
            "published": "2023-11-14T09:41:32Z",
            "summary": "The one-loop quantum corrections to the internal energy of lattices due to\nthe quantum fluctuations of the scalar field of phonons are studied. The band\nspectrum of the lattice is characterised in terms of the scattering data,\nallowing to compute the total Helmholtz free energy and the entropy at finite\nnon zero temperature. Some examples of three dimensional periodic potentials\nbuilt from the repetition of the same punctual or compact supported potential\nare addressed: the generalised Dirac comb and the P\\\"oschl-Teller comb,\nrespectively.",
            "author": [
                "Lucia Santamaria-Sanz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08435v1",
                "http://arxiv.org/pdf/2311.08435v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08024v1",
            "title": "MD-IQA: Learning Multi-scale Distributed Image Quality Assessment with\n  Semi Supervised Learning for Low Dose CT",
            "updated": "2023-11-14T09:33:33Z",
            "published": "2023-11-14T09:33:33Z",
            "summary": "Image quality assessment (IQA) plays a critical role in optimizing radiation\ndose and developing novel medical imaging techniques in computed tomography\n(CT). Traditional IQA methods relying on hand-crafted features have limitations\nin summarizing the subjective perceptual experience of image quality. Recent\ndeep learning-based approaches have demonstrated strong modeling capabilities\nand potential for medical IQA, but challenges remain regarding model\ngeneralization and perceptual accuracy. In this work, we propose a multi-scale\ndistributions regression approach to predict quality scores by constraining the\noutput distribution, thereby improving model generalization. Furthermore, we\ndesign a dual-branch alignment network to enhance feature extraction\ncapabilities. Additionally, semi-supervised learning is introduced by utilizing\npseudo-labels for unlabeled data to guide model training. Extensive qualitative\nexperiments demonstrate the effectiveness of our proposed method for advancing\nthe state-of-the-art in deep learning-based medical IQA. Code is available at:\nhttps://github.com/zunzhumu/MD-IQA.",
            "author": [
                "Tao Song",
                "Ruizhi Hou",
                "Lisong Dai",
                "Lei Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08024v1",
                "http://arxiv.org/pdf/2311.08024v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08017v1",
            "title": "The Hardy constant: a review",
            "updated": "2023-11-14T09:22:08Z",
            "published": "2023-11-14T09:22:08Z",
            "summary": "We present a review of results that have been obtained in the past\ntwenty-five years concerning the $L^p$-Hardy inequality with distance to the\nboundary. We concentrate on results where the best Hardy constant is either\ncomputed exactly or estimated from below.",
            "author": [
                "Gerassimos Barbatis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08017v1",
                "http://arxiv.org/pdf/2311.08017v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35A23, 26D10, 46E35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08013v1",
            "title": "CP-SLAM: Collaborative Neural Point-based SLAM System",
            "updated": "2023-11-14T09:17:15Z",
            "published": "2023-11-14T09:17:15Z",
            "summary": "This paper presents a collaborative implicit neural simultaneous localization\nand mapping (SLAM) system with RGB-D image sequences, which consists of\ncomplete front-end and back-end modules including odometry, loop detection,\nsub-map fusion, and global refinement. In order to enable all these modules in\na unified framework, we propose a novel neural point based 3D scene\nrepresentation in which each point maintains a learnable neural feature for\nscene encoding and is associated with a certain keyframe. Moreover, a\ndistributed-to-centralized learning strategy is proposed for the collaborative\nimplicit SLAM to improve consistency and cooperation. A novel global\noptimization framework is also proposed to improve the system accuracy like\ntraditional bundle adjustment. Experiments on various datasets demonstrate the\nsuperiority of the proposed method in both camera tracking and mapping.",
            "author": [
                "Jiarui Hu",
                "Mao Mao",
                "Hujun Bao",
                "Guofeng Zhang",
                "Zhaopeng Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08013v1",
                "http://arxiv.org/pdf/2311.08013v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08011v1",
            "title": "Forgetting before Learning: Utilizing Parametric Arithmetic for\n  Knowledge Updating in Large Language Models",
            "updated": "2023-11-14T09:12:40Z",
            "published": "2023-11-14T09:12:40Z",
            "summary": "Recently Large Language Models (LLMs) have demonstrated their amazing text\nunderstanding and generation capabilities. However, even stronger LLMs may\nstill learn incorrect knowledge from the training corpus, as well as some\nknowledge that is outdated over time. Direct secondary fine-tuning with data\ncontaining new knowledge may be ineffective in updating knowledge due to the\nconflict between old and new knowledge. In this paper, we propose a new\nparadigm for fine-tuning called F-Learning (Forgetting before Learning), which\nis based on parametric arithmetic to achieve forgetting of old knowledge and\nlearning of new knowledge. Experimental results on two publicly available\ndatasets demonstrate that our proposed F-Learning can obviously improve the\nknowledge updating performance of both full fine-tuning and LoRA fine-tuning.\nMoreover, we have also discovered that forgetting old knowledge by subtracting\nthe parameters of LoRA can achieve a similar effect to subtracting the\nparameters of full fine-tuning, and sometimes even surpass it significantly.",
            "author": [
                "Shiwen Ni",
                "Dingwei Chen",
                "Chengming Li",
                "Xiping Hu",
                "Ruifeng Xu",
                "Min Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08011v1",
                "http://arxiv.org/pdf/2311.08011v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08010v1",
            "title": "Distantly-Supervised Named Entity Recognition with Uncertainty-aware\n  Teacher Learning and Student-student Collaborative Learning",
            "updated": "2023-11-14T09:09:58Z",
            "published": "2023-11-14T09:09:58Z",
            "summary": "Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates\nthe burden of annotation, but meanwhile suffers from the label noise. Recent\nworks attempt to adopt the teacher-student framework to gradually refine the\ntraining labels and improve the overall robustness. However, we argue that\nthese teacher-student methods achieve limited performance because poor network\ncalibration produces incorrectly pseudo-labeled samples, leading to error\npropagation. Therefore, we attempt to mitigate this issue by proposing: (1)\nUncertainty-aware Teacher Learning that leverages the prediction uncertainty to\nguide the selection of pseudo-labels, avoiding the number of incorrect\npseudo-labels in the self-training stage. (2) Student-student Collaborative\nLearning that allows the transfer of reliable labels between two student\nnetworks instead of completely relying on all pseudo-labels from its teacher.\nMeanwhile, this approach allows a full exploration of mislabeled samples rather\nthan simply filtering unreliable pseudo-labeled samples. Extensive experimental\nresults on five DS-NER datasets demonstrate that our method is superior to\nstate-of-the-art teacher-student methods.",
            "author": [
                "Helan Hu",
                "Shuzheng Si",
                "Haozhe Zhao",
                "Shuang Zeng",
                "Kaikai An",
                "Zefan Cai",
                "Baobao Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08010v1",
                "http://arxiv.org/pdf/2311.08010v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08007v1",
            "title": "Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame\n  Interpolation",
            "updated": "2023-11-14T09:08:30Z",
            "published": "2023-11-14T09:08:30Z",
            "summary": "Existing video frame interpolation (VFI) methods blindly predict where each\nobject is at a specific timestep t (\"time indexing\"), which struggles to\npredict precise object movements. Given two images of a baseball, there are\ninfinitely many possible trajectories: accelerating or decelerating, straight\nor curved. This often results in blurry frames as the method averages out these\npossibilities. Instead of forcing the network to learn this complicated\ntime-to-location mapping implicitly together with predicting the frames, we\nprovide the network with an explicit hint on how far the object has traveled\nbetween start and end frames, a novel approach termed \"distance indexing\". This\nmethod offers a clearer learning goal for models, reducing the uncertainty tied\nto object speeds. We further observed that, even with this extra guidance,\nobjects can still be blurry especially when they are equally far from both\ninput frames (i.e., halfway in-between), due to the directional ambiguity in\nlong-range motion. To solve this, we propose an iterative reference-based\nestimation strategy that breaks down a long-range prediction into several\nshort-range steps. When integrating our plug-and-play strategies into\nstate-of-the-art learning-based models, they exhibit markedly sharper outputs\nand superior perceptual quality in arbitrary time interpolations, using a\nuniform distance indexing map in the same format as time indexing.\nAdditionally, distance indexing can be specified pixel-wise, which enables\ntemporal manipulation of each object independently, offering a novel tool for\nvideo editing tasks like re-timing.",
            "author": [
                "Zhihang Zhong",
                "Gurunandan Krishnan",
                "Xiao Sun",
                "Yu Qiao",
                "Sizhuo Ma",
                "Jian Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08007v1",
                "http://arxiv.org/pdf/2311.08007v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08003v1",
            "title": "The Hochschild (co)homology of gentle algebras",
            "updated": "2023-11-14T08:58:46Z",
            "published": "2023-11-14T08:58:46Z",
            "summary": "In this paper, we calculate the complete Tamarkin Tsygan calculus for gentle\nalgebras. For this we give a complete description of the structure of the\nHochschild cohomology ring of a gentle algebra both as a graded commutative\nalgebra and as Gerstenhaber algebra. Furthermore, we show how these structures\nare encoded in the geometric surface model of the bounded derived category\nassociated to a gentle algebra via its ribbon graph. We also compute the\nHochschild homology, the cyclic homology, the Connes' map and the right module\nstructure of the Hochschild homology over the Hochschild cohomology ring via\nthe cap product.",
            "author": [
                "Cristian Chaparro",
                "Sibylle Schroll",
                "Andrea Solotar",
                "Mariano Su\u00e1rez-\u00c1lvarez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08003v1",
                "http://arxiv.org/pdf/2311.08003v1"
            ],
            "primary_category": "math.RT",
            "category": [
                "math.RT",
                "16E30, 16E35, 16E40, 16G10, 18G80"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08002v1",
            "title": "TempTabQA: Temporal Question Answering for Semi-Structured Tables",
            "updated": "2023-11-14T08:57:01Z",
            "published": "2023-11-14T08:57:01Z",
            "summary": "Semi-structured data, such as Infobox tables, often include temporal\ninformation about entities, either implicitly or explicitly. Can current NLP\nsystems reason about such information in semi-structured tables? To tackle this\nquestion, we introduce the task of temporal question answering on\nsemi-structured tables. We present a dataset, TempTabQA, which comprises 11,454\nquestion-answer pairs extracted from 1,208 Wikipedia Infobox tables spanning\nmore than 90 distinct domains. Using this dataset, we evaluate several\nstate-of-the-art models for temporal reasoning. We observe that even the\ntop-performing LLMs lag behind human performance by more than 13.5 F1 points.\nGiven these results, our dataset has the potential to serve as a challenging\nbenchmark to improve the temporal reasoning capabilities of NLP models.",
            "author": [
                "Vivek Gupta",
                "Pranshu Kandoi",
                "Mahek Bhavesh Vora",
                "Shuo Zhang",
                "Yujie He",
                "Ridho Reinanda",
                "Vivek Srikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08002v1",
                "http://arxiv.org/pdf/2311.08002v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08001v1",
            "title": "A Comparative Analysis of the COVID-19 Infodemic in English and Chinese:\n  Insights from Social Media Textual Data",
            "updated": "2023-11-14T08:55:11Z",
            "published": "2023-11-14T08:55:11Z",
            "summary": "The COVID-19 infodemic, characterized by the rapid spread of misinformation\nand unverified claims related to the pandemic, presents a significant\nchallenge. This paper presents a comparative analysis of the COVID-19 infodemic\nin the English and Chinese languages, utilizing textual data extracted from\nsocial media platforms. To ensure a balanced representation, two infodemic\ndatasets were created by augmenting previously collected social media textual\ndata. Through word frequency analysis, the thirty-five most frequently\noccurring infodemic words are identified, shedding light on prevalent\ndiscussions surrounding the infodemic. Moreover, topic clustering analysis\nuncovers thematic structures and provides a deeper understanding of primary\ntopics within each language context. Additionally, sentiment analysis enables\ncomprehension of the emotional tone associated with COVID-19 information on\nsocial media platforms in English and Chinese. This research contributes to a\nbetter understanding of the COVID-19 infodemic phenomenon and can guide the\ndevelopment of strategies to combat misinformation during public health crises\nacross different languages.",
            "author": [
                "Jia Luo",
                "Daiyun Peng",
                "Lei Shi",
                "Didier El Baz",
                "Xinran Liu"
            ],
            "link": [
                "http://dx.doi.org/10.3389/fpubh.2023.1281259",
                "http://arxiv.org/abs/2311.08001v1",
                "http://arxiv.org/pdf/2311.08001v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CL",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08000v1",
            "title": "LiPar: A Lightweight Parallel Learning Model for Practical In-Vehicle\n  Network Intrusion Detection",
            "updated": "2023-11-14T08:54:00Z",
            "published": "2023-11-14T08:54:00Z",
            "summary": "With the development of intelligent transportation systems, vehicles are\nexposed to a complex network environment. As the main network of in-vehicle\nnetworks, the controller area network (CAN) has many potential security\nhazards, resulting in higher requirements for intrusion detection systems to\nensure safety. Among intrusion detection technologies, methods based on deep\nlearning work best without prior expert knowledge. However, they all have a\nlarge model size and rely on cloud computing, and are therefore not suitable to\nbe installed on the in-vehicle network. Therefore, we propose a lightweight\nparallel neural network structure, LiPar, to allocate task loads to multiple\nelectronic control units (ECU). The LiPar model consists of multi-dimensional\nbranch convolution networks, spatial and temporal feature fusion learning, and\na resource adaptation algorithm. Through experiments, we prove that LiPar has\ngreat detection performance, running efficiency, and lightweight model size,\nwhich can be well adapted to the in-vehicle environment practically and protect\nthe in-vehicle CAN bus security.",
            "author": [
                "Aiheng Zhang",
                "Kai Wang",
                "Bailing Wang",
                "Yulei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08000v1",
                "http://arxiv.org/pdf/2311.08000v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07999v1",
            "title": "Impact of half-wave plate systematics on the measurement of CMB $B$-mode\n  polarization",
            "updated": "2023-11-14T08:53:58Z",
            "published": "2023-11-14T08:53:58Z",
            "summary": "Polarization of the cosmic microwave background (CMB) can help probe the\nfundamental physics behind cosmic inflation via the measurement of primordial\n$B$ modes. As this requires exquisite control over instrumental systematics,\nsome next-generation CMB experiments plan to use a rotating half-wave plate\n(HWP) as polarization modulator. However, the HWP non-idealities, if not\nproperly treated in the analysis, can result in additional systematics. In this\npaper, we present a simple, semi-analytical end-to-end model to propagate the\nHWP non-idealities through the macro-steps that make up any CMB experiment\n(observation of multi-frequency maps, foreground cleaning, and power spectra\nestimation) and compute the HWP-induced bias on the estimated tensor-to-scalar\nratio, $r$. We find that the effective polarization efficiency of the HWP\nsuppresses the polarization signal, leading to an underestimation of $r$.\nLaboratory measurements of the properties of the HWP can be used to calibrate\nthis effect, but we show how gain calibration of the CMB temperature can also\nbe used to partially mitigate it. On the basis of our findings, we present a\nset of recommendations for the HWP design that can help maximize the benefits\nof gain calibration.",
            "author": [
                "Marta Monelli",
                "Eiichiro Komatsu",
                "Tommaso Ghigna",
                "Tomotake Matsumura",
                "Giampaolo Pisano",
                "Ryota Takaku"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07999v1",
                "http://arxiv.org/pdf/2311.07999v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07996v1",
            "title": "How Well Do Text Embedding Models Understand Syntax?",
            "updated": "2023-11-14T08:51:00Z",
            "published": "2023-11-14T08:51:00Z",
            "summary": "Text embedding models have significantly contributed to advancements in\nnatural language processing by adeptly capturing semantic properties of textual\ndata. However, the ability of these models to generalize across a wide range of\nsyntactic contexts remains under-explored. In this paper, we first develop an\nevaluation set, named \\textbf{SR}, to scrutinize the capability for syntax\nunderstanding of text embedding models from two crucial syntactic aspects:\nStructural heuristics, and Relational understanding among concepts, as revealed\nby the performance gaps in previous studies. Our findings reveal that existing\ntext embedding models have not sufficiently addressed these syntactic\nunderstanding challenges, and such ineffectiveness becomes even more apparent\nwhen evaluated against existing benchmark datasets. Furthermore, we conduct\nrigorous analysis to unearth factors that lead to such limitations and examine\nwhy previous evaluations fail to detect such ineffectiveness. Lastly, we\npropose strategies to augment the generalization ability of text embedding\nmodels in diverse syntactic scenarios. This study serves to highlight the\nhurdles associated with syntactic generalization and provides pragmatic\nguidance for boosting model performance across varied syntactic contexts.",
            "author": [
                "Yan Zhang",
                "Zhaopeng Feng",
                "Zhiyang Teng",
                "Zuozhu Liu",
                "Haizhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07996v1",
                "http://arxiv.org/pdf/2311.07996v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07993v1",
            "title": "Explicit Change Relation Learning for Change Detection in VHR Remote\n  Sensing Images",
            "updated": "2023-11-14T08:47:38Z",
            "published": "2023-11-14T08:47:38Z",
            "summary": "Change detection has always been a concerned task in the interpretation of\nremote sensing images. It is essentially a unique binary classification task\nwith two inputs, and there is a change relationship between these two inputs.\nAt present, the mining of change relationship features is usually implicit in\nthe network architectures that contain single-branch or two-branch encoders.\nHowever, due to the lack of artificial prior design for change relationship\nfeatures, these networks cannot learn enough change semantic information and\nlose more accurate change detection performance. So we propose a network\narchitecture NAME for the explicit mining of change relation features. In our\nopinion, the change features of change detection should be divided into\npre-changed image features, post-changed image features and change relation\nfeatures. In order to fully mine these three kinds of change features, we\npropose the triple branch network combining the transformer and convolutional\nneural network (CNN) to extract and fuse these change features from two\nperspectives of global information and local information, respectively. In\naddition, we design the continuous change relation (CCR) branch to further\nobtain the continuous and detail change relation features to improve the change\ndiscrimination capability of the model. The experimental results show that our\nnetwork performs better, in terms of F1, IoU, and OA, than those of the\nexisting advanced networks for change detection on four public very\nhigh-resolution (VHR) remote sensing datasets. Our source code is available at\nhttps://github.com/DalongZ/NAME.",
            "author": [
                "Dalong Zheng",
                "Zebin Wu",
                "Jia Liu",
                "Chih-Cheng Hung",
                "Zhihui Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07993v1",
                "http://arxiv.org/pdf/2311.07993v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07989v3",
            "title": "Unifying the Perspectives of NLP and Software Engineering: A Survey on\n  Language Models for Code",
            "updated": "2023-12-05T13:09:06Z",
            "published": "2023-11-14T08:34:26Z",
            "summary": "In this work we systematically review the recent advancements in code\nprocessing with language models, covering 50+ models, 30+ evaluation tasks,\n170+ datasets, and 700 related works. We break down code processing models into\ngeneral language models represented by the GPT family and specialized models\nthat are specifically pretrained on code, often with tailored objectives. We\ndiscuss the relations and differences between these models, and highlight the\nhistorical transition of code modeling from statistical models and RNNs to\npretrained Transformers and LLMs, which is exactly the same course that had\nbeen taken by NLP. We also discuss code-specific features such as AST, CFG, and\nunit tests, along with their application in training code language models, and\nidentify key challenges and potential future directions in this domain. We keep\nthe survey open and updated on GitHub at\nhttps://github.com/codefuse-ai/Awesome-Code-LLM.",
            "author": [
                "Ziyin Zhang",
                "Chaoyu Chen",
                "Bingchang Liu",
                "Cong Liao",
                "Zi Gong",
                "Hang Yu",
                "Jianguo Li",
                "Rui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07989v3",
                "http://arxiv.org/pdf/2311.07989v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07988v1",
            "title": "Spectral Line Analysis/Modeling (SLAM) I: pvanalysis",
            "updated": "2023-11-14T08:32:45Z",
            "published": "2023-11-14T08:32:45Z",
            "summary": "Line observations of young stellar objects (YSOs) at (sub)millimeter\nwavelengths provide essential information of gas kinematics in star and planet\nforming environments. For Class 0 and I YSOs, identification of Keplerian\nrotation is of particular interest, because it reveals presence of\nrotationally-supported disks that are still being embedded in infalling\nenvelopes and enables us to dynamically measure the protostellar mass. We have\ndeveloped a python library SLAM (Spectral Line Analysis/Modeling) with a\nprimary focus on analyses of emission line data at (sub)millimeter wavelengths.\nHere, we present an overview of the pvanalysis tool from SLAM, which is\ndesigned to identify Keplerian rotation of a disk and measure the dynamical\nmass of a central object using a position-velocity (PV) diagram of emission\nline data. The advantage of this tool is that it analyzes observational\nfeatures of given data and thus requires few computational time and parameter\nassumptions, in contrast to detailed radiative transfer modelings. In this\narticle, we introduce the basic concept and usage of this tool, present an\napplication to observational data, and discuss remaining caveats.",
            "author": [
                "Yusuke Aso",
                "Jinshi Sai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07988v1",
                "http://arxiv.org/pdf/2311.07988v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07986v1",
            "title": "On the View-and-Channel Aggregation Gain in Integrated Sensing and Edge\n  AI",
            "updated": "2023-11-14T08:27:50Z",
            "published": "2023-11-14T08:27:50Z",
            "summary": "Sensing and edge artificial intelligence (AI) are two key features of the\nsixth-generation (6G) mobile networks. Their natural integration, termed\nIntegrated sensing and edge AI (ISEA), is envisioned to automate wide-ranging\nInternet-of-Tings (IoT) applications. To achieve a high sensing accuracy,\nmulti-view features are uploaded to an edge server for aggregation and\ninference using an AI model. The view aggregation is realized efficiently using\nover-the-air computing (AirComp), which also aggregates channels to suppress\nchannel noise. At its nascent stage, ISEA still lacks a characterization of the\nfundamental performance gains from view-and-channel aggregation, which\nmotivates this work. Our framework leverages a well-established distribution\nmodel of multi-view sensing data where the classic Gaussian-mixture model is\nmodified by adding sub-spaces matrices to represent individual sensor\nobservation perspectives. Based on the model, we study the End-to-End sensing\n(inference) uncertainty, a popular measure of inference accuracy, of the said\nISEA system by a novel approach involving designing a scaling-tight uncertainty\nsurrogate function, global discriminant gain, distribution of receive\nSignal-to-Noise Ratio (SNR), and channel induced discriminant loss. We prove\nthat the E2E sensing uncertainty diminishes at an exponential rate as the\nnumber of views/sensors grows, where the rate is proportional to global\ndiscriminant gain. Given channel distortion, we further show that the\nexponential scaling remains with a reduced decay rate related to the channel\ninduced discriminant loss. Furthermore, we benchmark AirComp against equally\nfast, traditional analog orthogonal access, which reveals a sensing-accuracy\ncrossing point between the schemes, leading to the proposal of adaptive\naccess-mode switching. Last, the insights from our framework are validated by\nexperiments using real-world dataset.",
            "author": [
                "Xu Chen",
                "Khaled B. Letaief",
                "Kaibin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07986v1",
                "http://arxiv.org/pdf/2311.07986v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07985v1",
            "title": "Configurable convolutional neural networks for real-time\n  pedestrian-level wind prediction in urban environments",
            "updated": "2023-11-14T08:27:00Z",
            "published": "2023-11-14T08:27:00Z",
            "summary": "Urbanization has underscored the importance of understanding the pedestrian\nwind environment in urban and architectural design contexts. Pedestrian Wind\nComfort (PWC) focuses on the effects of wind on the safety and comfort of\npedestrians and cyclists, given the influence of urban structures on the local\nmicroclimate. Traditional Computational Fluid Dynamics (CFD) methods used for\nPWC analysis have limitations in computation, cost, and time. Deep-learning\nmodels have the potential to significantly speed up this process. The\nprevailing state-of-the-art methodologies largely rely on GAN-based models,\nsuch as pix2pix, which have exhibited training instability issues. In contrast,\nour work introduces a convolutional neural network (CNN) approach based on the\nU-Net architecture, offering a more stable and streamlined solution. The\nprocess of generating a wind flow prediction at pedestrian level is\nreformulated from a 3D CFD simulation into a 2D image-to-image translation\ntask, using the projected building heights as input. Testing on standard\nconsumer hardware shows that our model can efficiently predict wind velocities\nin urban settings in real time. Further tests on different configurations of\nthe model, combined with a Pareto front analysis, helped identify the trade-off\nbetween accuracy and computational efficiency. This CNN-based approach provides\na fast and efficient method for PWC analysis, potentially aiding in more\nefficient urban design processes.",
            "author": [
                "Alfredo Vicente Clemente",
                "Knut Erik Teigen Giljarhus",
                "Luca Oggiano",
                "Massimiliano Ruocco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07985v1",
                "http://arxiv.org/pdf/2311.07985v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "I.2.10; I.6.0; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07983v1",
            "title": "Ab Initio and Kinetic Modelling of $\u03b2$-D-xylopyranose Under Fast\n  Pyrolysis Conditions",
            "updated": "2023-11-14T08:23:43Z",
            "published": "2023-11-14T08:23:43Z",
            "summary": "Lignocellulosic biomass is an abundant renewable resource that can be\nupgraded to chemical and fuel products through a range of thermal conversion\nprocesses. Fast pyrolysis is a promising technology that uses high temperatures\nand fast heating rates to convert lignocellulose into bio-oils in high yields\nin the absence of oxygen. Hemicellulose is one of three major components of\nlignocellulosic biomass and is a highly branched heteropolymer structure made\nof pentose, hexose sugars, and sugar acids. In this study,\n$\\beta$-D-xylopyranose is proposed as a model structural motif for the\nessential chemical structure of hemicellulose. The gas-phase pyrolytic\nreactivity of $\\beta$-D-xylopyranose is thoroughly investigated using\ncomputational strategies rooted in quantum chemistry. In particular, its\nthermal degradation potential energy surfaces are computed employing Minnesota\nglobal hybrid functional M06-2X in conjunction with 6-311++G(d,p) Pople basis\nset. Electronic energies are further refined by performing DLPNO-CCSD(T)-F12\nsingle point calculations on top of M06-2X geometries using cc-pVTZ-F12 basis\nset. Key thermodynamic quantities (free energies, barrier heights, enthalpies\nof formation, and heat capacities) are computed. Rate coefficients for the\ninitial steps of thermal decomposition are computed by means of reaction rate\ntheory. For the first time, a detailed elementary reaction kinetic model for\n$\\beta$-D-xylopyranose is developed by utilizing the thermodynamic and kinetic\ninformation acquired from the aforementioned calculations. This model\nspecifically targets the initial stages of $\\beta$-D-xylopyranose pyrolysis,\naiming to gain a deeper understanding of its reaction kinetics. This approach\nestablishes a systematic strategy for exploring reactive pathways, evaluating\ncompeting parallel reactions, and selectively accepting or discarding pathways\nbased on the analysis.",
            "author": [
                "Jacopo Lupi",
                "Leandro Ayarde-Henr\u00edquez",
                "Mark Kelly",
                "Stephen Dooley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07983v1",
                "http://arxiv.org/pdf/2311.07983v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07981v1",
            "title": "Benchmarking Individual Tree Mapping with Sub-meter Imagery",
            "updated": "2023-11-14T08:21:36Z",
            "published": "2023-11-14T08:21:36Z",
            "summary": "There is a rising interest in mapping trees using satellite or aerial\nimagery, but there is no standardized evaluation protocol for comparing and\nenhancing methods. In dense canopy areas, the high variability of tree sizes\nand their spatial proximity makes it arduous to define the quality of the\npredictions. Concurrently, object-centric approaches such as bounding box\ndetection usuallyperform poorly on small and dense objects. It thus remains\nunclear what is the ideal framework for individual tree mapping, in regards to\ndetection and segmentation approaches, convolutional neural networks and\ntransformers. In this paper, we introduce an evaluation framework suited for\nindividual tree mapping in any physical environment, with annotation costs and\napplicative goals in mind. We review and compare different approaches and deep\narchitectures, and introduce a new method that we experimentally prove to be a\ngood compromise between segmentation and detection.",
            "author": [
                "Dimitri Gominski",
                "Ankit Kariryaa",
                "Martin Brandt",
                "Christian Igel",
                "Sizhuo Li",
                "Maurice Mugabowindekwe",
                "Rasmus Fensholt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07981v1",
                "http://arxiv.org/pdf/2311.07981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07980v1",
            "title": "QuantumEyes: Towards Better Interpretability of Quantum Circuits",
            "updated": "2023-11-14T08:20:11Z",
            "published": "2023-11-14T08:20:11Z",
            "summary": "Quantum computing offers significant speedup compared to classical computing,\nwhich has led to a growing interest among users in learning and applying\nquantum computing across various applications. However, quantum circuits, which\nare fundamental for implementing quantum algorithms, can be challenging for\nusers to understand due to their underlying logic, such as the temporal\nevolution of quantum states and the effect of quantum amplitudes on the\nprobability of basis quantum states. To fill this research gap, we propose\nQuantumEyes, an interactive visual analytics system to enhance the\ninterpretability of quantum circuits through both global and local levels. For\nthe global-level analysis, we present three coupled visualizations to delineate\nthe changes of quantum states and the underlying reasons: a Probability Summary\nView to overview the probability evolution of quantum states; a State Evolution\nView to enable an in-depth analysis of the influence of quantum gates on the\nquantum states; a Gate Explanation View to show the individual qubit states and\nfacilitate a better understanding of the effect of quantum gates. For the\nlocal-level analysis, we design a novel geometrical visualization Dandelion\nChart to explicitly reveal how the quantum amplitudes affect the probability of\nthe quantum state. We thoroughly evaluated QuantumEyes as well as the novel\nQuantumEyes integrated into it through two case studies on different types of\nquantum algorithms and in-depth expert interviews with 12 domain experts. The\nresults demonstrate the effectiveness and usability of our approach in\nenhancing the interpretability of quantum circuits.",
            "author": [
                "Shaolun Ruan",
                "Qiang Guan",
                "Paul Griffin",
                "Ying Mao",
                "Yong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07980v1",
                "http://arxiv.org/pdf/2311.07980v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07978v1",
            "title": "How good are Large Language Models on African Languages?",
            "updated": "2023-11-14T08:10:14Z",
            "published": "2023-11-14T08:10:14Z",
            "summary": "Recent advancements in natural language processing have led to the\nproliferation of large language models (LLMs). These models have been shown to\nyield good performance, using in-context learning, even on unseen tasks and\nlanguages. Additionally, they have been widely adopted as\nlanguage-model-as-a-service commercial APIs like GPT-4 API. However, their\nperformance on African languages is largely unknown. We present an analysis of\nthree popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks\n(news topic classification, sentiment classification, machine translation,\nquestion answering, and named entity recognition) across 30 African languages,\nspanning different language families and geographical regions. Our results\nsuggest that all LLMs produce below-par performance on African languages, and\nthere is a large gap in performance compared to high-resource languages like\nEnglish most tasks. We find that GPT-4 has an average or impressive performance\non classification tasks but very poor results on generative tasks like machine\ntranslation. Surprisingly, we find that mT0 had the best overall on\ncross-lingual QA, better than the state-of-the-art supervised model (i.e.\nfine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the\nworst performance due to its limited multilingual capabilities and\nEnglish-centric pre-training corpus. In general, our findings present a\ncall-to-action to ensure African languages are well represented in large\nlanguage models, given their growing popularity.",
            "author": [
                "Jessica Ojo",
                "Kelechi Ogueji",
                "Pontus Stenetorp",
                "David I. Adelani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07978v1",
                "http://arxiv.org/pdf/2311.07978v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07973v2",
            "title": "Comparative study of decoding the surface code using simulated annealing\n  under depolarizing noise",
            "updated": "2023-11-21T05:25:55Z",
            "published": "2023-11-14T08:00:23Z",
            "summary": "We explored decoding methods for the surface code under depolarizing noise by\nmapping the problem into the Ising model optimization. We consider two kinds of\nmapping with and without a soft constraint and also various optimization\nsolvers, including simulated annealing implemented on a CPU, \"Fujitsu Digital\nAnnealer\" (DA), a hardware architecture specialized for the Ising problems, and\nCPLEX, an exact integer programming solver. We find that the proposed\nIsing-based decoding approaches provide higher accuracy compared to the\nminimum-weight perfect matching (MWPM) algorithm for depolarizing noise and\ncomparable to minimum distance decoding using CPLEX. While decoding time is\nlonger than MWPM when we compare it with a single core CPU, our method is\namenable to parallelization and easy to implement on dedicated hardware,\nsuggesting potential future speedups. Regarding the mapping methods to the\nIsing model with and without a soft constraint, the SA decoder yielded higher\naccuracy without a soft constraint. In contrast, the DA decoder shows less\ndifference between the two mapping methods, which indicates that DA can find a\nbetter solution with smaller number of iterations even under the soft\nconstraint. Our results are important for devising efficient and fast decoders\nfeasible with quantum computer control devices.",
            "author": [
                "Yusaku Takeuchi",
                "Yugo Takada",
                "Tatsuya Sakashita",
                "Jun Fujisaki",
                "Hirotaka Oshima",
                "Shintaro Sato",
                "Keisuke Fujii"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07973v2",
                "http://arxiv.org/pdf/2311.07973v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07970v1",
            "title": "Dynamical theory of topological defects II: Universal aspects of defect\n  motion",
            "updated": "2023-11-14T07:50:25Z",
            "published": "2023-11-14T07:50:25Z",
            "summary": "We study the dynamics of topological defects in continuum theories governed\nby a free energy minimization principle, building on our recently developed\nframework [Romano J, Mahault B and Golestanian R 2023 J. Stat. Mech.: Theory\nExp. 083211]. We show how the equation of motion of point defects, domain\nwalls, disclination lines and any other singularity can be understood with one\nunifying mathematical framework. For disclination lines, this also allows us to\nstudy the interplay between the internal line tension and the interaction with\nother lines. This interplay is non-trivial, allowing defect loops to expand,\ninstead of contracting, due to external interaction. We also use this framework\nto obtain an analytical description of two long-lasting problems in point\ndefect motion, namely the scale dependence of the defect mobility and the role\nof elastic anisotropy in the motion of defects in liquid crystals. For the\nformer, we show that this dependence is strongly problem-dependent, but it can\nbe computed with high accuracy for a pair of annihilating defects. For the\nlatter, we show that at the first order in perturbation theory anisotropy\ncauses a non-radial force, making the trajectory of annihilating defects\ndeviate from a straight line. At higher orders, it also induces a correction in\nthe mobility, which becomes non-isotropic for the $+1/2$ defect. We argue that,\ndue to its generality, our method can help to shed light on the motion of\nsingularities in many different systems, including driven and active\nnon-equilibrium theories.",
            "author": [
                "Jacopo Romano",
                "Beno\u00eet Mahault",
                "Ramin Golestanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07970v1",
                "http://arxiv.org/pdf/2311.07970v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07967v1",
            "title": "Comparison of two data fusion approaches for land use classification",
            "updated": "2023-11-14T07:46:03Z",
            "published": "2023-11-14T07:46:03Z",
            "summary": "Accurate land use maps, describing the territory from an anthropic\nutilisation point of view, are useful tools for land management and planning.\nTo produce them, the use of optical images alone remains limited. It is\ntherefore necessary to make use of several heterogeneous sources, each carrying\ncomplementary or contradictory information due to their imperfections or their\ndifferent specifications. This study compares two different approaches i.e. a\npre-classification and a post-classification fusion approach for combining\nseveral sources of spatial data in the context of land use classification. The\napproaches are applied on authoritative land use data located in the Gers\ndepartment in the southwest of France. Pre-classification fusion, while not\nexplicitly modeling imperfections, has the best final results, reaching an\noverall accuracy of 97% and a macro-mean F1 score of 88%.",
            "author": [
                "Martin Cubaud",
                "Arnaud Le Bris",
                "Laurence Jolivet",
                "Ana-Maria Olteanu-Raimond"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07967v1",
                "http://arxiv.org/pdf/2311.07967v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10760v1",
            "title": "Non-Parametric Memory Guidance for Multi-Document Summarization",
            "updated": "2023-11-14T07:41:48Z",
            "published": "2023-11-14T07:41:48Z",
            "summary": "Multi-document summarization (MDS) is a difficult task in Natural Language\nProcessing, aiming to summarize information from several documents. However,\nthe source documents are often insufficient to obtain a qualitative summary. We\npropose a retriever-guided model combined with non-parametric memory for\nsummary generation. This model retrieves relevant candidates from a database\nand then generates the summary considering the candidates with a copy mechanism\nand the source documents. The retriever is implemented with Approximate Nearest\nNeighbor Search (ANN) to search large databases. Our method is evaluated on the\nMultiXScience dataset which includes scientific articles. Finally, we discuss\nour results and possible directions for future work.",
            "author": [
                "Florian Baud",
                "Alex Aussem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10760v1",
                "http://arxiv.org/pdf/2311.10760v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07964v2",
            "title": "Surveying Wikipedians: a dataset of users and contributors' practices on\n  Wikipedia in 8 languages",
            "updated": "2023-12-05T09:04:12Z",
            "published": "2023-11-14T07:39:27Z",
            "summary": "The dataset focuses on Wikipedia users and contains information about\ndemographic and socioeconomic characteristics of the respondents and their\nactivity on Wikipedia. The data was collected using a questionnaire available\nonline between June and July 2023. The link to the questionnaire was\ndistributed via a banner published in 8 languages on the Wikipedia page.\nFilling out the questionnaire was voluntary and not incentivised in any way.\nThe survey includes 200 questions about: what people were doing on Wikipedia\nbefore clicking the link to the questionnaire; how they use Wikipedia as\nreaders (``professional'' and ``personal'' uses); their opinion on the quality,\nthe thematic coverage, the importance of the encyclopaedia; the making of\nWikipedia (how they think it is made, if they have ever contributed and how);\ntheir social, sport, artistic and cultural activities, both online and offline;\ntheir socio-economic characteristics including political beliefs, and trust\npropensities. More than 200 000 people opened the questionnaire, 100 332\nstarted to answer, and constitute our dataset, and 10 576 finished it. Among\nother themes identified by future researchers, the dataset can be useful for\nadvancing the research regarding the features of readers vs contributors of\nonline commons, the relationship between trust, information, sources, and the\nuse made of this information.",
            "author": [
                "Caterina Cruciani",
                "L\u00e9o Joubert",
                "Nicolas Jullien",
                "Laurent Mell",
                "Sasha Piccione",
                "Jeanne Vermeirsche"
            ],
            "link": [
                "http://dx.doi.org/10.34847/nkl.4ecf4u8m",
                "http://arxiv.org/abs/2311.07964v2",
                "http://arxiv.org/pdf/2311.07964v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07963v1",
            "title": "Bounding free energy difference with flow matching",
            "updated": "2023-11-14T07:29:54Z",
            "published": "2023-11-14T07:29:54Z",
            "summary": "This paper introduces a method for computing the Helmholtz free energy using\nthe flow matching technique. Unlike previous work that utilized flow-based\nmodels for variational free energy calculations, this method provides bounds\nfor free energy estimation based on targeted free energy perturbation, by\nperforming calculations on samples from both ends of the mapping. We\ndemonstrate applications of the present method by estimating the free energy of\nthe classical Coulomb gas in a harmonic trap.",
            "author": [
                "Lu Zhao",
                "Lei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07963v1",
                "http://arxiv.org/pdf/2311.07963v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07961v1",
            "title": "The ART of LLM Refinement: Ask, Refine, and Trust",
            "updated": "2023-11-14T07:26:32Z",
            "published": "2023-11-14T07:26:32Z",
            "summary": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ngenerative abilities, but can they judge the quality of their own generations?\nA popular concept, referred to as self-refinement, postulates that LLMs can\ndetect and correct the errors in their generations when asked to do so.\nHowever, recent empirical evidence points in the opposite direction, suggesting\nthat LLMs often struggle to accurately identify errors when reasoning is\ninvolved. To address this, we propose a reasoning with refinement objective\ncalled ART: Ask, Refine, and Trust, which asks necessary questions to decide\nwhen an LLM should refine its output, and either affirm or withhold trust in\nits refinement by ranking the refinement and the initial prediction. On two\nmultistep reasoning tasks of mathematical word problems (GSM8K) and question\nanswering (StrategyQA), ART achieves a performance gain of +5 points over\nself-refinement baselines, while using a much smaller model as the decision\nmaker. We also demonstrate the benefit of using smaller models to make\nrefinement decisions as a cost-effective alternative to fine-tuning a larger\nmodel.",
            "author": [
                "Kumar Shridhar",
                "Koustuv Sinha",
                "Andrew Cohen",
                "Tianlu Wang",
                "Ping Yu",
                "Ram Pasunuru",
                "Mrinmaya Sachan",
                "Jason Weston",
                "Asli Celikyilmaz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07961v1",
                "http://arxiv.org/pdf/2311.07961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07957v1",
            "title": "Language Models are Better Bug Detector Through Code-Pair Classification",
            "updated": "2023-11-14T07:20:57Z",
            "published": "2023-11-14T07:20:57Z",
            "summary": "Large language models (LLMs) such as GPT-3.5 and CodeLlama are powerful\nmodels for code generation and understanding. Fine-tuning these models comes\nwith a high computational cost and requires a large labeled dataset.\nAlternatively, in-context learning techniques allow models to learn downstream\ntasks with only a few examples. Recently, researchers have shown how in-context\nlearning performs well in bug detection and repair. In this paper, we propose\ncode-pair classification task in which both the buggy and non-buggy versions\nare given to the model, and the model identifies the buggy ones. We evaluate\nour task in real-world dataset of bug detection and two most powerful LLMs. Our\nexperiments indicate that an LLM can often pick the buggy from the non-buggy\nversion of the code, and the code-pair classification task is much easier\ncompared to be given a snippet and deciding if and where a bug exists.",
            "author": [
                "Kamel Alrashedy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07957v1",
                "http://arxiv.org/pdf/2311.07957v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07956v2",
            "title": "Robust Learning Based Condition Diagnosis Method for Distribution\n  Network Switchgear",
            "updated": "2023-12-07T00:17:41Z",
            "published": "2023-11-14T07:20:46Z",
            "summary": "This paper introduces a robust, learning-based method for diagnosing the\nstate of distribution network switchgear, which is crucial for maintaining the\npower quality for end users. Traditional diagnostic models often rely heavily\non expert knowledge and lack robustness. To address this, our method\nincorporates an expanded feature vector that includes environmental data,\ntemperature readings, switch position, motor operation, insulation conditions,\nand local discharge information. We tackle the issue of high dimensionality\nthrough feature mapping. The method introduces a decision radius to categorize\nunlabeled samples and updates the model parameters using a combination of\nsupervised and unsupervised loss, along with a consistency regularization\nfunction. This approach ensures robust learning even with a limited number of\nlabeled samples. Comparative analysis demonstrates that this method\nsignificantly outperforms existing models in both accuracy and robustness.",
            "author": [
                "Wenxi Zhang",
                "Zhe Li",
                "Weixi Li",
                "Weisi Ma",
                "Xinyi Chen",
                "Sizhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07956v2",
                "http://arxiv.org/pdf/2311.07956v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07955v2",
            "title": "Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle\n  Imagery: Review and Experimental Comparisons",
            "updated": "2023-11-15T02:38:37Z",
            "published": "2023-11-14T07:20:38Z",
            "summary": "With the advancement of maritime unmanned aerial vehicles (UAVs) and deep\nlearning technologies, the application of UAV-based object detection has become\nincreasingly significant in the fields of maritime industry and ocean\nengineering. Endowed with intelligent sensing capabilities, the maritime UAVs\nenable effective and efficient maritime surveillance. To further promote the\ndevelopment of maritime UAV-based object detection, this paper provides a\ncomprehensive review of challenges, relative methods, and UAV aerial datasets.\nSpecifically, in this work, we first briefly summarize four challenges for\nobject detection on maritime UAVs, i.e., object feature diversity, device\nlimitation, maritime environment variability, and dataset scarcity. We then\nfocus on computational methods to improve maritime UAV-based object detection\nperformance in terms of scale-aware, small object detection, view-aware,\nrotated object detection, lightweight methods, and others. Next, we review the\nUAV aerial image/video datasets and propose a maritime UAV aerial dataset named\nMS2ship for ship detection. Furthermore, we conduct a series of experiments to\npresent the performance evaluation and robustness analysis of object detection\nmethods on maritime datasets. Eventually, we give the discussion and outlook on\nfuture works for maritime UAV-based object detection. The MS2ship dataset is\navailable at\n\\href{https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}.",
            "author": [
                "Chenjie Zhao",
                "Ryan Wen Liu",
                "Jingxiang Qu",
                "Ruobin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07955v2",
                "http://arxiv.org/pdf/2311.07955v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07954v1",
            "title": "A Closer Look at the Self-Verification Abilities of Large Language\n  Models in Logical Reasoning",
            "updated": "2023-11-14T07:13:10Z",
            "published": "2023-11-14T07:13:10Z",
            "summary": "Logical reasoning has been an ongoing pursuit in the field of AI. Despite\nsignificant advancements made by large language models (LLMs), they still\nstruggle with complex logical reasoning problems. To enhance reasoning\nperformance, one promising direction is scalable oversight, which requires LLMs\nto identify their own errors and then improve by themselves. Various\nself-verification methods have been proposed in pursuit of this goal.\nNevertheless, whether existing models understand their own errors well is still\nunder investigation. In this paper, we take a closer look at the\nself-verification abilities of LLMs in the context of logical reasoning,\nfocusing on their ability to identify logical fallacies accurately. We\nintroduce a dataset, FALLACIES, containing 232 types of reasoning fallacies\ncategorized in a hierarchical taxonomy. By conducting exhaustive experiments on\nFALLACIES, we obtain comprehensive and detailed analyses of a series of models\non their verification abilities. Our main findings suggest that existing LLMs\ncould struggle to identify fallacious reasoning steps accurately and may fall\nshort of guaranteeing the validity of self-verification methods. Drawing from\nthese observations, we offer suggestions for future research and practical\napplications of self-verification methods.",
            "author": [
                "Ruixin Hong",
                "Hongming Zhang",
                "Xinyu Pang",
                "Dong Yu",
                "Changshui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07954v1",
                "http://arxiv.org/pdf/2311.07954v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07951v1",
            "title": "A Fast and Simple Algorithm for computing the MLE of Amplitude Density\n  Function Parameters",
            "updated": "2023-11-14T07:04:47Z",
            "published": "2023-11-14T07:04:47Z",
            "summary": "Over the last decades, the family of $\\alpha$-stale distributions has proven\nto be useful for modelling in telecommunication systems. Particularly, in the\ncase of radar applications, finding a fast and accurate estimation for the\namplitude density function parameters appears to be very important. In this\nwork, the maximum likelihood estimator (MLE) is proposed for parameters of the\namplitude distribution. To do this, the amplitude data are \\emph{projected} on\nthe horizontal and vertical axes using two simple transformations. It is proved\nthat the \\emph{projected} data follow a zero-location symmetric $\\alpha$-stale\ndistribution for which the MLE can be computed quite fast. The average of\ncomputed MLEs based on two \\emph{projections} is considered as estimator for\nparameters of the amplitude distribution. Performance of the proposed\n\\emph{projection} method is demonstrated through simulation study and analysis\nof two sets of real radar data.",
            "author": [
                "Mahdi Teimouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07951v1",
                "http://arxiv.org/pdf/2311.07951v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07947v1",
            "title": "Towards a Technical Debt for Recommender System",
            "updated": "2023-11-14T06:57:20Z",
            "published": "2023-11-14T06:57:20Z",
            "summary": "Balancing the management of technical debt within recommender systems\nrequires effectively juggling the introduction of new features with the ongoing\nmaintenance and enhancement of the current system. Within the realm of\nrecommender systems, technical debt encompasses the trade-offs and expedient\nchoices made during the development and upkeep of the recommendation system,\nwhich could potentially have adverse effects on its long-term performance,\nscalability, and maintainability. In this vision paper, our objective is to\nkickstart a research direction regarding Technical Debt in Recommender Systems.\nWe identified 15 potential factors, along with detailed explanations outlining\nwhy it is advisable to consider them.",
            "author": [
                "Sergio Moreschini",
                "Ludovik Coba",
                "Valentina Lenarduzzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07947v1",
                "http://arxiv.org/pdf/2311.07947v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07945v1",
            "title": "First Step Advantage: Importance of Starting Right in Multi-Step\n  Reasoning",
            "updated": "2023-11-14T06:45:31Z",
            "published": "2023-11-14T06:45:31Z",
            "summary": "Large Language Models (LLMs) can solve complex reasoning tasks by generating\nrationales for their predictions. Distilling these capabilities into a smaller,\ncompact model can facilitate the creation of specialized, cost-effective models\ntailored for specific tasks. However, smaller models often face challenges in\ncomplex reasoning tasks and often deviate from the correct reasoning path. We\nshow that LLMs can guide smaller models and bring them back to the correct\nreasoning path only if they intervene at the right time. We show that smaller\nmodels fail to reason primarily due to their difficulty in initiating the\nprocess, and that guiding them in the right direction can lead to a performance\ngain of over 100%. We explore different model sizes and evaluate the benefits\nof providing guidance to improve reasoning in smaller models.",
            "author": [
                "Kushal Jain",
                "Kumar Shridhar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07945v1",
                "http://arxiv.org/pdf/2311.07945v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07941v1",
            "title": "Non-autoregressive Machine Translation with Probabilistic Context-free\n  Grammar",
            "updated": "2023-11-14T06:39:04Z",
            "published": "2023-11-14T06:39:04Z",
            "summary": "Non-autoregressive Transformer(NAT) significantly accelerates the inference\nof neural machine translation. However, conventional NAT models suffer from\nlimited expression power and performance degradation compared to autoregressive\n(AT) models due to the assumption of conditional independence among target\ntokens. To address these limitations, we propose a novel approach called\nPCFG-NAT, which leverages a specially designed Probabilistic Context-Free\nGrammar (PCFG) to enhance the ability of NAT models to capture complex\ndependencies among output tokens. Experimental results on major machine\ntranslation benchmarks demonstrate that PCFG-NAT further narrows the gap in\ntranslation quality between NAT and AT models. Moreover, PCFG-NAT facilitates a\ndeeper understanding of the generated sentences, addressing the lack of\nsatisfactory explainability in neural machine translation.Code is publicly\navailable at https://github.com/ictnlp/PCFG-NAT.",
            "author": [
                "Shangtong Gui",
                "Chenze Shao",
                "Zhengrui Ma",
                "Xishan Zhang",
                "Yunji Chen",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07941v1",
                "http://arxiv.org/pdf/2311.07941v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07934v1",
            "title": "Duality in Gauge Theory, Gravity and String Theory",
            "updated": "2023-11-14T06:23:30Z",
            "published": "2023-11-14T06:23:30Z",
            "summary": "Einstein's theory in the vacuum was recently shown to possess an $SO(2)$\nduality invariance, which is broken by coupling to matter. Duality invariance\ncan be restored by enlarging the phase space of the theory to allow for\nviolations of the algebraic Bianchi identity. We show that in cases where the\nmatter content can be understood as a component of the torsion tensor duality\ncan be restored and we compute the corresponding duality current. We consider\nthe case of NS-NS gravity as an example and find that the duality current is\ngiven by the divergence of the axion. In the linearized approximation of the\nlow energy heterotic string theory these results imply that duality of the\ngeneralized Riemann curvature tensor implements Riemannian, axion-dilaton and\nelectro-magnetic dualities simultaneously.",
            "author": [
                "Uri Kol",
                "Shing-Tung Yau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07934v1",
                "http://arxiv.org/pdf/2311.07934v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "math-ph",
                "math.DG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07932v1",
            "title": "Cross-subject dual-domain fusion network with task-related and\n  task-discriminant component analysis enhancing one-shot SSVEP classification",
            "updated": "2023-11-14T06:20:50Z",
            "published": "2023-11-14T06:20:50Z",
            "summary": "This study addresses the significant challenge of developing efficient\ndecoding algorithms for classifying steady-state visual evoked potentials\n(SSVEPs) in scenarios characterized by extreme scarcity of calibration data,\nwhere only one calibration is available for each stimulus target. To tackle\nthis problem, we introduce a novel cross-subject dual-domain fusion network\n(CSDuDoFN) incorporating task-related and task-discriminant component analysis\n(TRCA and TDCA) for one-shot SSVEP classification. The CSDuDoFN framework is\ndesigned to comprehensively transfer information from source subjects, while\nTRCA and TDCA are employed to exploit the single available calibration of the\ntarget subject. Specifically, we develop multi-reference least-squares\ntransformation (MLST) to map data from both source subjects and the target\nsubject into the domain of sine-cosine templates, thereby mitigating\ninter-individual variability and benefiting transfer learning. Subsequently,\nthe transformed data in the sine-cosine templates domain and the original\ndomain data are separately utilized to train a convolutional neural network\n(CNN) model, with the adequate fusion of their feature maps occurring at\ndistinct network layers. To further capitalize on the calibration of the target\nsubject, source aliasing matrix estimation (SAME) data augmentation is\nincorporated into the training process of the ensemble TRCA (eTRCA) and TDCA\nmodels. Ultimately, the outputs of the CSDuDoFN, eTRCA, and TDCA are combined\nfor SSVEP classification. The effectiveness of our proposed approach is\ncomprehensively evaluated on three publicly available SSVEP datasets, achieving\nthe best performance on two datasets and competitive performance on one. This\nunderscores the potential for integrating brain-computer interface (BCI) into\ndaily life.",
            "author": [
                "Yang Deng",
                "Zhiwei Ji",
                "Yijun Wang",
                "S. Kevin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07932v1",
                "http://arxiv.org/pdf/2311.07932v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07930v1",
            "title": "It's All Relative! -- A Synthetic Query Generation Approach for\n  Improving Zero-Shot Relevance Prediction",
            "updated": "2023-11-14T06:16:49Z",
            "published": "2023-11-14T06:16:49Z",
            "summary": "Recent developments in large language models (LLMs) have shown promise in\ntheir ability to generate synthetic query-document pairs by prompting with as\nfew as 8 demonstrations. This has enabled building better IR models, especially\nfor tasks with no training data readily available. Typically, such synthetic\nquery generation (QGen) approaches condition on an input context (e.g. a text\ndocument) and generate a query relevant to that context, or condition the QGen\nmodel additionally on the relevance label (e.g. relevant vs irrelevant) to\ngenerate queries across relevance buckets. However, we find that such QGen\napproaches are sub-optimal as they require the model to reason about the\ndesired label and the input from a handful of examples. In this work, we\npropose to reduce this burden of LLMs by generating queries simultaneously for\ndifferent labels. We hypothesize that instead of asking the model to generate,\nsay, an irrelevant query given an input context, asking the model to generate\nan irrelevant query relative to a relevant query is a much simpler task setup\nfor the model to reason about. Extensive experimentation across seven IR\ndatasets shows that synthetic queries generated in such a fashion translates to\na better downstream performance, suggesting that the generated queries are\nindeed of higher quality.",
            "author": [
                "Aditi Chaudhary",
                "Karthik Raman",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07930v1",
                "http://arxiv.org/pdf/2311.07930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07928v1",
            "title": "Towards Improving Robustness Against Common Corruptions in Object\n  Detectors Using Adversarial Contrastive Learning",
            "updated": "2023-11-14T06:13:52Z",
            "published": "2023-11-14T06:13:52Z",
            "summary": "Neural networks have revolutionized various domains, exhibiting remarkable\naccuracy in tasks like natural language processing and computer vision.\nHowever, their vulnerability to slight alterations in input samples poses\nchallenges, particularly in safety-critical applications like autonomous\ndriving. Current approaches, such as introducing distortions during training,\nfall short in addressing unforeseen corruptions. This paper proposes an\ninnovative adversarial contrastive learning framework to enhance neural network\nrobustness simultaneously against adversarial attacks and common corruptions.\nBy generating instance-wise adversarial examples and optimizing contrastive\nloss, our method fosters representations that resist adversarial perturbations\nand remain robust in real-world scenarios. Subsequent contrastive learning then\nstrengthens the similarity between clean samples and their adversarial\ncounterparts, fostering representations resistant to both adversarial attacks\nand common distortions. By focusing on improving performance under adversarial\nand real-world conditions, our approach aims to bolster the robustness of\nneural networks in safety-critical applications, such as autonomous vehicles\nnavigating unpredictable weather conditions. We anticipate that this framework\nwill contribute to advancing the reliability of neural networks in challenging\nenvironments, facilitating their widespread adoption in mission-critical\nscenarios.",
            "author": [
                "Shashank Kotyan",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07928v1",
                "http://arxiv.org/pdf/2311.07928v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07925v1",
            "title": "Brain-Driven Representation Learning Based on Diffusion Model",
            "updated": "2023-11-14T05:59:58Z",
            "published": "2023-11-14T05:59:58Z",
            "summary": "Interpreting EEG signals linked to spoken language presents a complex\nchallenge, given the data's intricate temporal and spatial attributes, as well\nas the various noise factors. Denoising diffusion probabilistic models (DDPMs),\nwhich have recently gained prominence in diverse areas for their capabilities\nin representation learning, are explored in our research as a means to address\nthis issue. Using DDPMs in conjunction with a conditional autoencoder, our new\napproach considerably outperforms traditional machine learning algorithms and\nestablished baseline models in accuracy. Our results highlight the potential of\nDDPMs as a sophisticated computational method for the analysis of\nspeech-related EEG signals. This could lead to significant advances in\nbrain-computer interfaces tailored for spoken communication.",
            "author": [
                "Soowon Kim",
                "Seo-Hyun Lee",
                "Young-Eun Lee",
                "Ji-Won Lee",
                "Ji-Ha Park",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07925v1",
                "http://arxiv.org/pdf/2311.07925v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07919v1",
            "title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified\n  Large-Scale Audio-Language Models",
            "updated": "2023-11-14T05:34:50Z",
            "published": "2023-11-14T05:34:50Z",
            "summary": "Recently, instruction-following audio-language models have received broad\nattention for audio interaction with humans. However, the absence of\npre-trained audio models capable of handling diverse audio types and tasks has\nhindered progress in this field. Consequently, most existing works have only\nbeen able to support a limited range of interaction capabilities. In this\npaper, we develop the Qwen-Audio model and address this limitation by scaling\nup audio-language pre-training to cover over 30 tasks and various audio types,\nsuch as human speech, natural sounds, music, and songs, to facilitate universal\naudio understanding abilities. However, directly co-training all tasks and\ndatasets can lead to interference issues, as the textual labels associated with\ndifferent datasets exhibit considerable variations due to differences in task\nfocus, language, granularity of annotation, and text structure. To overcome the\none-to-many interference, we carefully design a multi-task training framework\nby conditioning on a sequence of hierarchical tags to the decoder for\nencouraging knowledge sharing and avoiding interference through shared and\nspecified tags respectively. Remarkably, Qwen-Audio achieves impressive\nperformance across diverse benchmark tasks without requiring any task-specific\nfine-tuning, surpassing its counterparts. Building upon the capabilities of\nQwen-Audio, we further develop Qwen-Audio-Chat, which allows for input from\nvarious audios and text inputs, enabling multi-turn dialogues and supporting\nvarious audio-central scenarios.",
            "author": [
                "Yunfei Chu",
                "Jin Xu",
                "Xiaohuan Zhou",
                "Qian Yang",
                "Shiliang Zhang",
                "Zhijie Yan",
                "Chang Zhou",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07919v1",
                "http://arxiv.org/pdf/2311.07919v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07918v1",
            "title": "Automated title and abstract screening for scoping reviews using the\n  GPT-4 Large Language Model",
            "updated": "2023-11-14T05:30:43Z",
            "published": "2023-11-14T05:30:43Z",
            "summary": "Scoping reviews, a type of literature review, require intensive human effort\nto screen large numbers of scholarly sources for their relevance to the review\nobjectives. This manuscript introduces GPTscreenR, a package for the R\nstatistical programming language that uses the GPT-4 Large Language Model (LLM)\nto automatically screen sources. The package makes use of the chain-of-thought\ntechnique with the goal of maximising performance on complex screening tasks.\nIn validation against consensus human reviewer decisions, GPTscreenR performed\nsimilarly to an alternative zero-shot technique, with a sensitivity of 71%,\nspecificity of 89%, and overall accuracy of 84%. Neither method achieved\nperfect accuracy nor human levels of intraobserver agreement. GPTscreenR\ndemonstrates the potential for LLMs to support scholarly work and provides a\nuser-friendly software framework that can be integrated into existing review\nprocesses.",
            "author": [
                "David Wilkins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07918v1",
                "http://arxiv.org/pdf/2311.07918v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07915v1",
            "title": "Energy Stable Scheme for Random Batch Molecular Dynamics",
            "updated": "2023-11-14T05:24:43Z",
            "published": "2023-11-14T05:24:43Z",
            "summary": "The computational bottleneck of molecular dynamics is the pairwise additive\nlong-range interactions between particles. The random batch Ewald (RBE) method\nprovides a highly efficient and superscalable solver for long-range\ninteractions, but the stochastic nature of this algorithm leads to unphysical\nself-heating effect during the simulation. We propose an energy stable scheme\n(ESS) for particle systems by employing a Berendsen-type energy bath. The\nscheme removes the notorious energy drift which exists due to the force error\neven when a symplectic integrator is employed. Combining the RBE and the ESS,\nthe new method provides a perfect solution of the computational bottleneck of\nmolecular dynamics at the microcanonical ensemble. Numerical results for\nprimitive electrolyte and all-atom pure water systems demonstrate the\nattractive performance of the algorithm including its dramatically high\naccuracy, linear complexity and overcoming the energy drift for long-time\nsimulations.",
            "author": [
                "Jiuyang Liang",
                "Zhenli Xu",
                "Yue Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07915v1",
                "http://arxiv.org/pdf/2311.07915v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07914v1",
            "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
            "updated": "2023-11-14T05:21:57Z",
            "published": "2023-11-14T05:21:57Z",
            "summary": "The contemporary LLMs are prone to producing hallucinations, stemming mainly\nfrom the knowledge gaps within the models. To address this critical limitation,\nresearchers employ diverse strategies to augment the LLMs by incorporating\nexternal knowledge, aiming to reduce hallucinations and enhance reasoning\naccuracy. Among these strategies, leveraging knowledge graphs as a source of\nexternal information has demonstrated promising results. In this survey, we\nconduct a comprehensive review of these knowledge-graph-based knowledge\naugmentation techniques in LLMs, focusing on their efficacy in mitigating\nhallucinations. We systematically categorize these methods into three\noverarching groups, offering both methodological comparisons and empirical\nevaluations of their performance. Lastly, the paper explores the challenges\nassociated with these techniques and outlines potential avenues for future\nresearch in this emerging field.",
            "author": [
                "Garima Agrawal",
                "Tharindu Kumarage",
                "Zeyad Alghami",
                "Huan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07914v1",
                "http://arxiv.org/pdf/2311.07914v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07913v1",
            "title": "Roadside LiDAR Assisted Cooperative Localization for Connected\n  Autonomous Vehicles",
            "updated": "2023-11-14T05:18:01Z",
            "published": "2023-11-14T05:18:01Z",
            "summary": "Advancements in LiDAR technology have led to more cost-effective production\nwhile simultaneously improving precision and resolution. As a result, LiDAR has\nbecome integral to vehicle localization, achieving centimeter-level accuracy\nthrough techniques like Normal Distributions Transform (NDT) and other advanced\n3D registration algorithms. Nonetheless, these approaches are reliant on\nhigh-definition 3D point cloud maps, the creation of which involves significant\nexpenditure. When such maps are unavailable or lack sufficient features for 3D\nregistration algorithms, localization accuracy diminishes, posing a risk to\nroad safety. To address this, we proposed to use LiDAR-equipped roadside unit\nand Vehicle-to-Infrastructure (V2I) communication to accurately estimate the\nconnected autonomous vehicle's position and help the vehicle when its\nself-localization is not accurate enough. Our simulation results indicate that\nthis method outperforms traditional NDT scan matching-based approaches in terms\nof localization accuracy.",
            "author": [
                "Yuze Jiang",
                "Ehsan Javanmard",
                "Jin Nakazato",
                "Manabu Tsukada",
                "Hiroshi Esaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07913v1",
                "http://arxiv.org/pdf/2311.07913v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07912v1",
            "title": "Detection of Small Targets in Sea Clutter Based on RepVGG and Continuous\n  Wavelet Transform",
            "updated": "2023-11-14T05:14:41Z",
            "published": "2023-11-14T05:14:41Z",
            "summary": "Constructing a high-performance target detector under the background of sea\nclutter is always necessary and important. In this work, we propose a\nRepVGGA0-CWT detector, where RepVGG is a residual network that gains a high\ndetection accuracy. Different from traditional residual networks, RepVGG keeps\nan acceptable calculation speed. Giving consideration to both accuracy and\nspeed, the RepVGGA0 is selected among all the variants of RepVGG. Also,\ncontinuous wavelet transform (CWT) is employed to extract the radar echoes'\ntime-frequency feature effectively. In the tests, other networks (ResNet50,\nResNet18 and AlexNet) and feature extraction methods (short-time Fourier\ntransform (STFT), CWT) are combined to build detectors for comparison. The\nresult of different datasets shows that the RepVGGA0-CWT detector performs\nbetter than those detectors in terms of low controllable false alarm rate, high\ntraining speed, high inference speed and low memory usage. This RepVGGA0-CWT\ndetector is hardware-friendly and can be applied in real-time scenes for its\nhigh inference speed in detection.",
            "author": [
                "Jingchen Ni",
                "Haoru Li",
                "Lilin Xu",
                "Jing Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07912v1",
                "http://arxiv.org/pdf/2311.07912v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07911v1",
            "title": "Instruction-Following Evaluation for Large Language Models",
            "updated": "2023-11-14T05:13:55Z",
            "published": "2023-11-14T05:13:55Z",
            "summary": "One core capability of Large Language Models (LLMs) is to follow natural\nlanguage instructions. However, the evaluation of such abilities is not\nstandardized: Human evaluations are expensive, slow, and not objectively\nreproducible, while LLM-based auto-evaluation is potentially biased or limited\nby the ability of the evaluator LLM. To overcome these issues, we introduce\nInstruction-Following Eval (IFEval) for large language models. IFEval is a\nstraightforward and easy-to-reproduce evaluation benchmark. It focuses on a set\nof \"verifiable instructions\" such as \"write in more than 400 words\" and\n\"mention the keyword of AI at least 3 times\". We identified 25 types of those\nverifiable instructions and constructed around 500 prompts, with each prompt\ncontaining one or more verifiable instructions. We show evaluation results of\ntwo widely available LLMs on the market. Our code and data can be found at\nhttps://github.com/google-research/google-research/tree/master/instruction_following_eval",
            "author": [
                "Jeffrey Zhou",
                "Tianjian Lu",
                "Swaroop Mishra",
                "Siddhartha Brahma",
                "Sujoy Basu",
                "Yi Luan",
                "Denny Zhou",
                "Le Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07911v1",
                "http://arxiv.org/pdf/2311.07911v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T50 (Primary) 68T99 (Secondary)",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07910v1",
            "title": "Force Training Neural Network Potential Energy Surface Models",
            "updated": "2023-11-14T05:10:12Z",
            "published": "2023-11-14T05:10:12Z",
            "summary": "Machine learned chemical potentials have shown great promise as alternatives\nto conventional computational chemistry methods to represent the potential\nenergy of a given atomic or molecular system as a function of its geometry.\nHowever, such potentials are only as good as the data they are trained on, and\nbuilding a comprehensive training set can be a costly process. Therefore, it is\nimportant to extract as much information from training data as possible without\nfurther increasing the computational cost. One way to accomplish this is by\ntraining on molecular forces in addition to energies. This allows for three\nadditional labels per atom within the molecule. Here we develop a neural\nnetwork potential energy surface for studying a hydrogen transfer reaction\nbetween two conformers of C5H5. We show that, for a much smaller training set,\nforce training can greatly improve the accuracy of the model compared to only\ntraining to energies. We also demonstrate the importance of choosing the proper\nforce to energy weight ratio for the loss function to minimize the model test\nerror.",
            "author": [
                "Christian Devereux",
                "Yoona Yang",
                "Carles Mart\u00ed",
                "Judit Z\u00e1dor",
                "Michael S. Eldred",
                "Habib N. Najm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07910v1",
                "http://arxiv.org/pdf/2311.07910v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07907v1",
            "title": "Curve Stabbing Depth: Data Depth for Plane Curves",
            "updated": "2023-11-14T05:00:25Z",
            "published": "2023-11-14T05:00:25Z",
            "summary": "Measures of data depth have been studied extensively for point data.\nMotivated by recent work on analysis, clustering, and identifying\nrepresentative elements in sets of trajectories, we introduce {\\em curve\nstabbing depth} to quantify how deeply a given curve $Q$ is located relative to\na given set $\\cal C$ of curves in $\\mathbb{R}^2$. Curve stabbing depth\nevaluates the average number of elements of $\\cal C$ stabbed by rays rooted\nalong the length of $Q$. We describe an $O(n^3 + n^2 m\\log^2m+nm^2\\log^2\nm)$-time algorithm for computing curve stabbing depth when $Q$ is an $m$-vertex\npolyline and $\\cal C$ is a set of $n$ polylines, each with $O(m)$ vertices.",
            "author": [
                "Stephane Durocher",
                "Alexandre Leblanc",
                "Spencer Szabados"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07907v1",
                "http://arxiv.org/pdf/2311.07907v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08432v1",
            "title": "Zeno-effect Computation: Opportunities and Challenges",
            "updated": "2023-11-14T04:31:10Z",
            "published": "2023-11-14T04:31:10Z",
            "summary": "Adiabatic quantum computing has demonstrated how quantum Zeno can be used to\nconstruct quantum optimisers. However, much less work has been done to\nunderstand how more general Zeno effects could be used in a similar setting. We\nuse a construction based on three state systems rather than directly in qubits,\nso that a qubit can remain after projecting out one of the states. We find that\nour model of computing is able to recover the dynamics of a transverse field\nIsing model, several generalisations are possible, but our methods allow for\nconstraints to be implemented non-perturbatively and does not need tunable\ncouplers, unlike simple transverse field implementations. We further discuss\nhow to implement the protocol physically using methods building on STIRAP\nprotocols for state transfer. We find a substantial challenge, that settings\ndefined exclusively by measurement or dissipative Zeno effects do not allow for\nfrustration, and in these settings pathological spectral features arise leading\nto unfavorable runtime scaling. We discuss methods to overcome this challenge\nfor example including gain as well as loss as is often done in optical Ising\nmachines.",
            "author": [
                "Jesse Berwald",
                "Nicholas Chancellor",
                "Raouf Dridi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08432v1",
                "http://arxiv.org/pdf/2311.08432v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07897v1",
            "title": "CPopQA: Ranking Cultural Concept Popularity by LLMs",
            "updated": "2023-11-14T04:10:40Z",
            "published": "2023-11-14T04:10:40Z",
            "summary": "Prior work has demonstrated large language models' (LLMs) potential to\ndiscern statistical tendencies within their pre-training corpora. Despite that,\nmany examinations of LLMs' knowledge capacity focus on knowledge explicitly\nappearing in the training data or implicitly inferable from similar contexts.\nHow well an LLM captures the corpus-level statistical trends of concepts for\nreasoning, especially long-tail ones, is still underexplored. In this study, we\nintroduce a novel few-shot question-answering task (CPopQA) that examines LLMs'\nstatistical ranking abilities for long-tail cultural concepts (e.g., holidays),\nwith a specific focus on these concepts' popularity in the United States and\nthe United Kingdom, respectively. We curate a dataset containing 459 holidays\nacross 58 countries, generating a total of 6,000 QA testing pairs. Experiments\non four strong LLMs show that large models are capable of ranking long-tail\ncultural concepts regarding their statistical tendency. Notably, GPT-3.5\ndisplayed superior performance and exhibited its potential to identify\ngeo-cultural proximity across continents.",
            "author": [
                "Ming Jiang",
                "Mansi Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07897v1",
                "http://arxiv.org/pdf/2311.07897v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07896v1",
            "title": "Bayesian Conditional Diffusion Models for Versatile Spatiotemporal\n  Turbulence Generation",
            "updated": "2023-11-14T04:08:14Z",
            "published": "2023-11-14T04:08:14Z",
            "summary": "Turbulent flows have historically presented formidable challenges to\npredictive computational modeling. Traditional numerical simulations often\nrequire vast computational resources, making them infeasible for numerous\nengineering applications. As an alternative, deep learning-based surrogate\nmodels have emerged, offering data-drive solutions. However, these are\ntypically constructed within deterministic settings, leading to shortfall in\ncapturing the innate chaotic and stochastic behaviors of turbulent dynamics. We\nintroduce a novel generative framework grounded in probabilistic diffusion\nmodels for versatile generation of spatiotemporal turbulence. Our method\nunifies both unconditional and conditional sampling strategies within a\nBayesian framework, which can accommodate diverse conditioning scenarios,\nincluding those with a direct differentiable link between specified conditions\nand generated unsteady flow outcomes, and scenarios lacking such explicit\ncorrelations. A notable feature of our approach is the method proposed for\nlong-span flow sequence generation, which is based on autoregressive\ngradient-based conditional sampling, eliminating the need for cumbersome\nretraining processes. We showcase the versatile turbulence generation\ncapability of our framework through a suite of numerical experiments,\nincluding: 1) the synthesis of LES simulated instantaneous flow sequences from\nURANS inputs; 2) holistic generation of inhomogeneous, anisotropic wall-bounded\nturbulence, whether from given initial conditions, prescribed turbulence\nstatistics, or entirely from scratch; 3) super-resolved generation of\nhigh-speed turbulent boundary layer flows from low-resolution data across a\nrange of input resolutions. Collectively, our numerical experiments highlight\nthe merit and transformative potential of the proposed methods, making a\nsignificant advance in the field of turbulence generation.",
            "author": [
                "Han Gao",
                "Xu Han",
                "Xiantao Fan",
                "Luning Sun",
                "Li-Ping Liu",
                "Lian Duan",
                "Jian-Xun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07896v1",
                "http://arxiv.org/pdf/2311.07896v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07893v1",
            "title": "Adaptive measurement strategy for quantum subspace methods",
            "updated": "2023-11-14T04:00:59Z",
            "published": "2023-11-14T04:00:59Z",
            "summary": "Estimation of physical observables for unknown quantum states is an important\nproblem that underlies a wide range of fields, including quantum information\nprocessing, quantum physics, and quantum chemistry. In the context of quantum\ncomputation, in particular, existing studies have mainly focused on holistic\nstate tomography or estimation on specific observables with known classical\ndescriptions, while this lacks the important class of problems where the\nestimation target itself relies on the measurement outcome. In this work, we\npropose an adaptive measurement optimization method that is useful for the\nquantum subspace methods, namely the variational simulation methods that\nutilize classical postprocessing on measurement outcomes. The proposed method\nfirst determines the measurement protocol based on QSE calculation for\nclassically simulatable states, and then adaptively updates the protocol\naccording to the quantum measurement result. As a numerical demonstration, we\nhave shown for excited-state simulation of molecules that (i) we are able to\nreduce the number of measurements by an order of magnitude by constructing an\nappropriate measurement strategy (ii) the adaptive iteration converges\nsuccessfully even for strongly correlated molecule of H$_4$. Our work reveals\nthat the potential of the QSE method can be empowered by elaborated measurement\nprotocols, and opens a path to further pursue efficient quantum measurement\ntechniques in practical computations.",
            "author": [
                "Yuma Nakamura",
                "Yoshichika Yano",
                "Nobuyuki Yoshioka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07893v1",
                "http://arxiv.org/pdf/2311.07893v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07892v1",
            "title": "Complexity in two-point measurement schemes",
            "updated": "2023-11-14T04:00:31Z",
            "published": "2023-11-14T04:00:31Z",
            "summary": "We show that the characteristic function of the probability distribution\nassociated with the change of an observable in a two-point measurement protocol\nwith a perturbation can be written as an auto-correlation function between an\ninitial state and a certain unitary evolved state by an effective unitary\noperator. Using this identification, we probe how the evolved state spreads in\nthe corresponding conjugate space, by defining a notion of the complexity of\nthe spread of this evolved state. For a sudden quench scenario, where the\nparameters of an initial Hamiltonian (taken as the observable measured in the\ntwo-point measurement protocol) are suddenly changed to a new set of values, we\nfirst obtain the corresponding Krylov basis vectors and the associated Lanczos\ncoefficients for an initial pure state, and obtain the spread complexity.\nInterestingly, we find that in such a protocol, the Lanczos coefficients can be\nrelated to various cost functions used in the geometric formulation of circuit\ncomplexity, for example the one used to define Fubini-Study complexity. We\nillustrate the evolution of spread complexity both analytically, by using Lie\nalgebraic techniques, and by performing numerical computations. This is done\nfor cases when the Hamiltonian before and after the quench are taken as\ndifferent combinations of chaotic and integrable spin chains. We show that the\ncomplexity saturates for large values of the parameter only when the pre-quench\nHamiltonian is chaotic. Further, in these examples we also discuss the\nimportant role played by the initial state which is determined by the\ntime-evolved perturbation operator.",
            "author": [
                "Ankit Gill",
                "Kunal Pal",
                "Kuntal Pal",
                "Tapobrata Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07892v1",
                "http://arxiv.org/pdf/2311.07892v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07885v1",
            "title": "One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View\n  Generation and 3D Diffusion",
            "updated": "2023-11-14T03:40:25Z",
            "published": "2023-11-14T03:40:25Z",
            "summary": "Recent advancements in open-world 3D object generation have been remarkable,\nwith image-to-3D methods offering superior fine-grained control over their\ntext-to-3D counterparts. However, most existing models fall short in\nsimultaneously providing rapid generation speeds and high fidelity to input\nimages - two features essential for practical applications. In this paper, we\npresent One-2-3-45++, an innovative method that transforms a single image into\na detailed 3D textured mesh in approximately one minute. Our approach aims to\nfully harness the extensive knowledge embedded in 2D diffusion models and\npriors from valuable yet limited 3D data. This is achieved by initially\nfinetuning a 2D diffusion model for consistent multi-view image generation,\nfollowed by elevating these images to 3D with the aid of multi-view conditioned\n3D native diffusion models. Extensive experimental evaluations demonstrate that\nour method can produce high-quality, diverse 3D assets that closely mirror the\noriginal input image. Our project webpage:\nhttps://sudo-ai-3d.github.io/One2345plus_page.",
            "author": [
                "Minghua Liu",
                "Ruoxi Shi",
                "Linghao Chen",
                "Zhuoyang Zhang",
                "Chao Xu",
                "Xinyue Wei",
                "Hansheng Chen",
                "Chong Zeng",
                "Jiayuan Gu",
                "Hao Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07885v1",
                "http://arxiv.org/pdf/2311.07885v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07884v1",
            "title": "Fair Abstractive Summarization of Diverse Perspectives",
            "updated": "2023-11-14T03:38:55Z",
            "published": "2023-11-14T03:38:55Z",
            "summary": "People from different social and demographic groups express diverse\nperspectives and conflicting opinions on a broad set of topics such as product\nreviews, healthcare, law, and politics. A fair summary should provide a\ncomprehensive coverage of diverse perspectives without underrepresenting\ncertain groups. However, current work in summarization metrics and Large\nLanguage Models (LLMs) evaluation has not explored fair abstractive\nsummarization. In this paper, we systematically investigate fair abstractive\nsummarization for user-generated data. We first formally define fairness in\nabstractive summarization as not underrepresenting perspectives of any groups\nof people and propose four reference-free automatic metrics measuring the\ndifferences between target and source perspectives. We evaluate five LLMs,\nincluding three GPT models, Alpaca, and Claude, on six datasets collected from\nsocial media, online reviews, and recorded transcripts. Experiments show that\nboth the model-generated and the human-written reference summaries suffer from\nlow fairness. We conduct a comprehensive analysis of the common factors\ninfluencing fairness and propose three simple but effective methods to\nalleviate unfair summarization. Our dataset and code are available at\nhttps://github.com/psunlpgroup/FairSumm.",
            "author": [
                "Yusen Zhang",
                "Nan Zhang",
                "Yixin Liu",
                "Alexander Fabbri",
                "Junru Liu",
                "Ryo Kamoi",
                "Xiaoxin Lu",
                "Caiming Xiong",
                "Jieyu Zhao",
                "Dragomir Radev",
                "Kathleen McKeown",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07884v1",
                "http://arxiv.org/pdf/2311.07884v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07883v1",
            "title": "Analysis of a tensor POD-ROM for parameter dependent parabolic problems",
            "updated": "2023-11-14T03:38:44Z",
            "published": "2023-11-14T03:38:44Z",
            "summary": "A space-time-parameters structure of the parametric parabolic PDEs motivates\nthe application of tensor methods to define reduced order models (ROMs). Within\na tensor-based ROM framework, the matrix SVD -- a traditional dimension\nreduction technique -- yields to a low-rank tensor decomposition (LRTD). Such\ntensor extension of the Galerkin proper orthogonal decomposition ROMs\n(POD-ROMs) benefits both the practical efficiency of the ROM and its\namenability for the rigorous error analysis when applied to parametric PDEs.\nThe paper addresses the error analysis of the Galerkin LRTD-ROM for an abstract\nlinear parabolic problem that depends on multiple physical parameters. An error\nestimate for the LRTD-ROM solution is proved, which is uniform with respect to\nproblem parameters and extends to parameter values not in a sampling/training\nset. The estimate is given in terms of discretization and sampling mesh\nproperties, and LRTD accuracy. The estimate depends on the smoothness rather\nthan on the Kolmogorov n-widths of the parameterized manifold of solutions.\nTheoretical results are illustrated with several numerical experiments.",
            "author": [
                "Alexander V. Mamonov",
                "Maxim A. Olshanskii"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07883v1",
                "http://arxiv.org/pdf/2311.07883v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07881v1",
            "title": "Accurate estimates of dynamical statistics using memory",
            "updated": "2023-11-14T03:28:04Z",
            "published": "2023-11-14T03:28:04Z",
            "summary": "Many chemical reactions and molecular processes occur on timescales that are\nsignificantly longer than those accessible by direct simulation. One successful\napproach to estimating dynamical statistics for such processes is to use many\nshort time series observations of the system to construct a Markov state model\n(MSM), which approximates the dynamics of the system as memoryless transitions\nbetween a set of discrete states. The dynamical Galerkin approximation (DGA)\ngeneralizes MSMs for the problem of calculating dynamical statistics, such as\ncommittors and mean first passage times, by replacing the set of discrete\nstates with a projection onto a basis. Because the projected dynamics are\ngenerally not memoryless, the Markov approximation can result in significant\nsystematic error. Inspired by quasi-Markov state models, which employ the\ngeneralized master equation to encode memory resulting from the projection, we\nreformulate DGA to account for memory and analyze its performance on two\nsystems: a two-dimensional triple well and helix-to-helix transitions of the\nAIB$_9$ peptide. We demonstrate that our method is robust to the choice of\nbasis and can decrease the time series length required to obtain accurate\nkinetics by an order of magnitude.",
            "author": [
                "Chatipat Lorpaiboon",
                "Spencer C. Guo",
                "John Strahan",
                "Jonathan Weare",
                "Aaron R. Dinner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07881v1",
                "http://arxiv.org/pdf/2311.07881v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.stat-mech",
                "physics.chem-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07880v1",
            "title": "VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway\n  IoT-Applications",
            "updated": "2023-11-14T03:19:55Z",
            "published": "2023-11-14T03:19:55Z",
            "summary": "Vehicle anomaly detection plays a vital role in highway safety applications\nsuch as accident prevention, rapid response, traffic flow optimization, and\nwork zone safety. With the surge of the Internet of Things (IoT) in recent\nyears, there has arisen a pressing demand for Artificial Intelligence (AI)\nbased anomaly detection methods designed to meet the requirements of IoT\ndevices. Catering to this futuristic vision, we introduce a lightweight\napproach to vehicle anomaly detection by utilizing the power of trajectory\nprediction. Our proposed design identifies vehicles deviating from expected\npaths, indicating highway risks from different camera-viewing angles from\nreal-world highway datasets. On top of that, we present VegaEdge - a\nsophisticated AI confluence designed for real-time security and surveillance\napplications in modern highway settings through edge-centric IoT-embedded\nplatforms equipped with our anomaly detection approach. Extensive testing\nacross multiple platforms and traffic scenarios showcases the versatility and\neffectiveness of VegaEdge. This work also presents the Carolinas Anomaly\nDataset (CAD), to bridge the existing gap in datasets tailored for highway\nanomalies. In real-world scenarios, our anomaly detection approach achieves an\nAUC-ROC of 0.94, and our proposed VegaEdge design, on an embedded IoT platform,\nprocesses 738 trajectories per second in a typical highway setting. The dataset\nis available at\nhttps://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set .",
            "author": [
                "Vinit Katariya",
                "Fatema-E- Jannat",
                "Armin Danesh Pazho",
                "Ghazal Alinezhad Noghre",
                "Hamed Tabkhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07880v1",
                "http://arxiv.org/pdf/2311.07880v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07879v1",
            "title": "Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting\n  Volunteer Content Moderators",
            "updated": "2023-11-14T03:18:28Z",
            "published": "2023-11-14T03:18:28Z",
            "summary": "Extensive efforts in automated approaches for content moderation have been\nfocused on developing models to identify toxic, offensive, and hateful content\n-- with the aim of lightening the load for moderators. Yet, it remains\nuncertain whether improvements on those tasks truly address the needs that\nmoderators have in accomplishing their work. In this paper, we surface the gaps\nbetween past research efforts that have aimed to provide automation for aspects\nof the content moderation task, and the needs of volunteer content moderators.\nTo do so, we conduct a model review on Hugging Face to reveal the availability\nof models to cover various moderation rules and guidelines. We further put\nstate-of-the-art LLMs to the test (GPT-4 and Llama-2), evaluating how well\nthese models perform in flagging violations of platform rules. Overall, we\nobserve a non-trivial gap, as missing developed models and LLMs exhibit low\nrecall on a significant portion of the rules.",
            "author": [
                "Yang Trista Cao",
                "Lovely-Frances Domingo",
                "Sarah Ann Gilbert",
                "Michelle Mazurek",
                "Katie Shilton",
                "Hal Daum\u00e9 III"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07879v1",
                "http://arxiv.org/pdf/2311.07879v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07877v1",
            "title": "Test-Time Training for Semantic Segmentation with Output Contrastive\n  Loss",
            "updated": "2023-11-14T03:13:47Z",
            "published": "2023-11-14T03:13:47Z",
            "summary": "Although deep learning-based segmentation models have achieved impressive\nperformance on public benchmarks, generalizing well to unseen environments\nremains a major challenge. To improve the model's generalization ability to the\nnew domain during evaluation, the test-time training (TTT) is a challenging\nparadigm that adapts the source-pretrained model in an online fashion. Early\nefforts on TTT mainly focus on the image classification task. Directly\nextending these methods to semantic segmentation easily experiences unstable\nadaption due to segmentation's inherent characteristics, such as extreme class\nimbalance and complex decision spaces. To stabilize the adaptation process, we\nintroduce contrastive loss (CL), known for its capability to learn robust and\ngeneralized representations. Nevertheless, the traditional CL operates in the\nrepresentation space and cannot directly enhance predictions. In this paper, we\nresolve this limitation by adapting the CL to the output space, employing a\nhigh temperature, and simplifying the formulation, resulting in a\nstraightforward yet effective loss function called Output Contrastive Loss\n(OCL). Our comprehensive experiments validate the efficacy of our approach\nacross diverse evaluation scenarios. Notably, our method excels even when\napplied to models initially pre-trained using domain adaptation methods on test\ndomain data, showcasing its resilience and adaptability.\\footnote{Code and more\ninformation could be found at~ \\url{https://github.com/dazhangyu123/OCL}}",
            "author": [
                "Yunlong Zhang",
                "Yuxuan Sun",
                "Sunyi Zheng",
                "Zhongyi Shui",
                "Chenglu Zhu",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07877v1",
                "http://arxiv.org/pdf/2311.07877v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07872v1",
            "title": "Cost-Efficient Computation Offloading and Service Chain Caching in LEO\n  Satellite Networks",
            "updated": "2023-11-14T03:03:37Z",
            "published": "2023-11-14T03:03:37Z",
            "summary": "The ever-increasing demand for ubiquitous, continuous, and high-quality\nservices poses a great challenge to the traditional terrestrial network. To\nmitigate this problem, the mobile-edge-computing-enhanced low earth orbit (LEO)\nsatellite network, which provides both communication connectivity and on-board\nprocessing services, has emerged as an effective method. The main issue in LEO\nsatellites includes finding the optimal locations to host network functions\n(NFs) and then making offloading decisions. In this article, we jointly\nconsider the problem of service chain caching and computation offloading to\nminimize the overall cost, which consists of task latency and energy\nconsumption. In particular, the collaboration among satellites, the network\nresource limitations, and the specific operation order of NFs in service chains\nare taken into account. Then, the problem is formulated and linearized as an\ninteger linear programming model. Moreover, to accelerate the solution, we\nprovide a greedy algorithm with cubic time complexity. Numerical investigations\ndemonstrate the effectiveness of the proposed scheme, which can reduce the\noverall cost by around 20% compared to the nominal case where NFs are served in\ndata centers.",
            "author": [
                "Yantong Wang",
                "Chuanfen Feng",
                "Jiande Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07872v1",
                "http://arxiv.org/pdf/2311.07872v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07871v1",
            "title": "Dual-channel Prototype Network for few-shot Classification of\n  Pathological Images",
            "updated": "2023-11-14T03:03:21Z",
            "published": "2023-11-14T03:03:21Z",
            "summary": "In pathology, the rarity of certain diseases and the complexity in annotating\npathological images significantly hinder the creation of extensive,\nhigh-quality datasets. This limitation impedes the progress of deep\nlearning-assisted diagnostic systems in pathology. Consequently, it becomes\nimperative to devise a technology that can discern new disease categories from\na minimal number of annotated examples. Such a technology would substantially\nadvance deep learning models for rare diseases. Addressing this need, we\nintroduce the Dual-channel Prototype Network (DCPN), rooted in the few-shot\nlearning paradigm, to tackle the challenge of classifying pathological images\nwith limited samples. DCPN augments the Pyramid Vision Transformer (PVT)\nframework for few-shot classification via self-supervised learning and\nintegrates it with convolutional neural networks. This combination forms a\ndual-channel architecture that extracts multi-scale, highly precise\npathological features. The approach enhances the versatility of prototype\nrepresentations and elevates the efficacy of prototype networks in few-shot\npathological image classification tasks. We evaluated DCPN using three publicly\navailable pathological datasets, configuring small-sample classification tasks\nthat mirror varying degrees of clinical scenario domain shifts. Our\nexperimental findings robustly affirm DCPN's superiority in few-shot\npathological image classification, particularly in tasks within the same\ndomain, where it achieves the benchmarks of supervised learning.",
            "author": [
                "Hao Quan",
                "Xinjia Li",
                "Dayu Hu",
                "Tianhang Nan",
                "Xiaoyu Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07871v1",
                "http://arxiv.org/pdf/2311.07871v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08430v1",
            "title": "Rankitect: Ranking Architecture Search Battling World-class Engineers at\n  Meta Scale",
            "updated": "2023-11-14T03:02:02Z",
            "published": "2023-11-14T03:02:02Z",
            "summary": "Neural Architecture Search (NAS) has demonstrated its efficacy in computer\nvision and potential for ranking systems. However, prior work focused on\nacademic problems, which are evaluated at small scale under well-controlled\nfixed baselines. In industry system, such as ranking system in Meta, it is\nunclear whether NAS algorithms from the literature can outperform production\nbaselines because of: (1) scale - Meta ranking systems serve billions of users,\n(2) strong baselines - the baselines are production models optimized by\nhundreds to thousands of world-class engineers for years since the rise of deep\nlearning, (3) dynamic baselines - engineers may have established new and\nstronger baselines during NAS search, and (4) efficiency - the search pipeline\nmust yield results quickly in alignment with the productionization life cycle.\nIn this paper, we present Rankitect, a NAS software framework for ranking\nsystems at Meta. Rankitect seeks to build brand new architectures by composing\nlow level building blocks from scratch. Rankitect implements and improves\nstate-of-the-art (SOTA) NAS methods for comprehensive and fair comparison under\nthe same search space, including sampling-based NAS, one-shot NAS, and\nDifferentiable NAS (DNAS). We evaluate Rankitect by comparing to multiple\nproduction ranking models at Meta. We find that Rankitect can discover new\nmodels from scratch achieving competitive tradeoff between Normalized Entropy\nloss and FLOPs. When utilizing search space designed by engineers, Rankitect\ncan generate better models than engineers, achieving positive offline\nevaluation and online A/B test at Meta scale.",
            "author": [
                "Wei Wen",
                "Kuang-Hung Liu",
                "Igor Fedorov",
                "Xin Zhang",
                "Hang Yin",
                "Weiwei Chu",
                "Kaveh Hassani",
                "Mengying Sun",
                "Jiang Liu",
                "Xu Wang",
                "Lin Jiang",
                "Yuxin Chen",
                "Buyun Zhang",
                "Xi Liu",
                "Dehua Cheng",
                "Zhengxing Chen",
                "Guang Zhao",
                "Fangqiu Han",
                "Jiyan Yang",
                "Yuchen Hao",
                "Liang Xiong",
                "Wen-Yen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08430v1",
                "http://arxiv.org/pdf/2311.08430v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07869v1",
            "title": "Hybrid GRU-CNN Bilinear Parameters Initialization for Quantum\n  Approximate Optimization Algorithm",
            "updated": "2023-11-14T03:00:39Z",
            "published": "2023-11-14T03:00:39Z",
            "summary": "The Quantum Approximate Optimization Algorithm (QAOA), a pivotal paradigm in\nthe realm of variational quantum algorithms (VQAs), offers promising\ncomputational advantages for tackling combinatorial optimization problems.\nWell-defined initial circuit parameters, responsible for preparing a\nparameterized quantum state encoding the solution, play a key role in\noptimizing QAOA. However, classical optimization techniques encounter\nchallenges in discerning optimal parameters that align with the optimal\nsolution. In this work, we propose a hybrid optimization approach that\nintegrates Gated Recurrent Units (GRU), Convolutional Neural Networks (CNN),\nand a bilinear strategy as an innovative alternative to conventional optimizers\nfor predicting optimal parameters of QAOA circuits. GRU serves to\nstochastically initialize favorable parameters for depth-1 circuits, while CNN\npredicts initial parameters for depth-2 circuits based on the optimized\nparameters of depth-1 circuits. To assess the efficacy of our approach, we\nconducted a comparative analysis with traditional initialization methods using\nQAOA on Erd\\H{o}s-R\\'enyi graph instances, revealing superior optimal\napproximation ratios. We employ the bilinear strategy to initialize QAOA\ncircuit parameters at greater depths, with reference parameters obtained from\nGRU-CNN optimization. This approach allows us to forecast parameters for a\ndepth-12 QAOA circuit, yielding a remarkable approximation ratio of 0.998\nacross 10 qubits, which surpasses that of the random initialization strategy\nand the PPN2 method at a depth of 10. The proposed hybrid GRU-CNN bilinear\noptimization method significantly improves the effectiveness and accuracy of\nparameters initialization, offering a promising iterative framework for QAOA\nthat elevates its performance.",
            "author": [
                "Zuyu Xu",
                "Pengnian Cai",
                "Kang Sheng",
                "Tao Yang",
                "Yuanming Hu",
                "Yunlai Zhu",
                "Zuheng Wu",
                "Yuehua Dai",
                "Fei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07869v1",
                "http://arxiv.org/pdf/2311.07869v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07868v1",
            "title": "Multi-Signal Reconstruction Using Masked Autoencoder From EEG During\n  Polysomnography",
            "updated": "2023-11-14T02:57:37Z",
            "published": "2023-11-14T02:57:37Z",
            "summary": "Polysomnography (PSG) is an indispensable diagnostic tool in sleep medicine,\nessential for identifying various sleep disorders. By capturing physiological\nsignals, including EEG, EOG, EMG, and cardiorespiratory metrics, PSG presents a\npatient's sleep architecture. However, its dependency on complex equipment and\nexpertise confines its use to specialized clinical settings. Addressing these\nlimitations, our study aims to perform PSG by developing a system that requires\nonly a single EEG measurement. We propose a novel system capable of\nreconstructing multi-signal PSG from a single-channel EEG based on a masked\nautoencoder. The masked autoencoder was trained and evaluated using the\nSleep-EDF-20 dataset, with mean squared error as the metric for assessing the\nsimilarity between original and reconstructed signals. The model demonstrated\nproficiency in reconstructing multi-signal data. Our results present promise\nfor the development of more accessible and long-term sleep monitoring systems.\nThis suggests the expansion of PSG's applicability, enabling its use beyond the\nconfines of clinics.",
            "author": [
                "Young-Seok Kweon",
                "Gi-Hwan Shin",
                "Heon-Gyu Kwak",
                "Ha-Na Jo",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07868v1",
                "http://arxiv.org/pdf/2311.07868v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07864v1",
            "title": "Probing clustering in neural network representations",
            "updated": "2023-11-14T02:33:54Z",
            "published": "2023-11-14T02:33:54Z",
            "summary": "Neural network representations contain structure beyond what was present in\nthe training labels. For instance, representations of images that are visually\nor semantically similar tend to lie closer to each other than to dissimilar\nimages, regardless of their labels. Clustering these representations can thus\nprovide insights into dataset properties as well as the network internals. In\nthis work, we study how the many design choices involved in neural network\ntraining affect the clusters formed in the hidden representations. To do so, we\nestablish an evaluation setup based on the BREEDS hierarchy, for the task of\nsubclass clustering after training models with only superclass information. We\nisolate the training dataset and architecture as important factors affecting\nclusterability. Datasets with labeled classes consisting of unrelated\nsubclasses yield much better clusterability than those following a natural\nhierarchy. When using pretrained models to cluster representations on\ndownstream datasets, models pretrained on subclass labels provide better\nclusterability than models pretrained on superclass labels, but only when there\nis a high degree of domain overlap between the pretraining and downstream data.\nArchitecturally, we find that normalization strategies affect which layers\nyield the best clustering performance, and, surprisingly, Vision Transformers\nattain lower subclass clusterability than ResNets.",
            "author": [
                "Thao Nguyen",
                "Simon Kornblith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07864v1",
                "http://arxiv.org/pdf/2311.07864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07863v1",
            "title": "Fluctuation-Induced Transitions in Anisotropic Two-Dimensional\n  Turbulence",
            "updated": "2023-11-14T02:31:13Z",
            "published": "2023-11-14T02:31:13Z",
            "summary": "Two-dimensional (2D) turbulence features an inverse energy cascade producing\nlarge-scale flow structures such as hurricane-like large-scale vortices (LSVs)\nand jets. We study the dynamics of such structures by direct numerical\nsimulations (DNS) of stochastically forced, viscously damped 2D turbulence\nwithin a periodic rectangular domain $[0,L_x]\\times[0,L_y]$. Stable LSVs form\nin the system when the aspect ratio $\\delta = L_x/L_y \\approx 1$, while jets\npredominate at $\\delta\\gtrsim 1.1$. At intermediate values of $\\delta$, both\nstructures are metastable, and noise-induced transitions occur between them.\nBased on large-scale energy balance, we derive and verify predictions for the\nparameter dependence of the total kinetic energy and the flow polarity. We\ncollect detailed statistics on the lifetimes of LSVs and jets from long-time\nsimulations, consistent with a memoryless process. Our DNS results support both\nan exponential and an algebraic dependence of the mean lifetime on $\\delta$. We\nshow that the mean lifetime depends strongly on the Reynolds number $Re$. As\n$Re$ increases, the energy gap between LSV (lower energy) and jet states\n(higher energy) grows, leading to increasing lifetimes following power laws in\n$Re$. Similarly, as the forcing scale decreases, transitions become less\nfrequent. We study the transitions in terms of kinetic energy, flow polarity,\nand 2D phase-space diagrams, revealing that the transitions occur in two\nstages: an initial, efficient redistribution of kinetic energy by nonlinear\ntriadic interactions facilitates a rapid transition from LSVs to jets and vice\nversa. In the second stage, the kinetic energy of the newly formed structure\nslowly adjusts to its associated equilibrium value on a longer, viscous\ntimescale, leading to hysteresis. Our findings shed new light on the dynamics\nof coherent large-scale structures in anisotropic turbulence.",
            "author": [
                "Lichuan Xu",
                "Adrian van Kan",
                "Chang Liu",
                "Edgar Knobloch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07863v1",
                "http://arxiv.org/pdf/2311.07863v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cond-mat.stat-mech",
                "physics.ao-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07859v1",
            "title": "Relaxation time for the alignment between quark spin and angular\n  velocity in a rotating QCD medium",
            "updated": "2023-11-14T02:24:08Z",
            "published": "2023-11-14T02:24:08Z",
            "summary": "We compute the relaxation times for massive quarks and anti-quarks to align\ntheir spins with the angular velocity in a rigidly rotating medium at finite\ntemperature and baryon density. The rotation effects are implemented using a\nfermion propagator immersed in a cylindrical rotating environment. The\nrelaxation time is computed as the inverse of the interaction rate to produce\nan asymmetry between the quark (anti-quark) spin components along and opposite\nto the angular velocity. For conditions resembling heavy-ion collisions, the\nrelaxation times for quarks are smaller than for anti-quarks. For semi-central\ncollisions the relaxation time is within the possible life-time of the QGP for\nall collision energies. However, for anti-quarks this happens only for\ncollision energies $\\sqrt{s_{NN}}\\gtrsim 50$ GeV. The results are quantified in\nterms of the intrinsic quark and anti-quark polarizations, namely, the\nprobability to build the spin asymmetry as a function of time. Our results show\nthat these intrinsic polarizations tend to 1 with time at different rates given\nby the relaxation times with quarks reaching a sizable asymmetry at a faster\npace. These are key results to further elucidate the mechanisms of hyperon\npolarization in relativistic heavy-ion collisions.",
            "author": [
                "Alejandro Ayala",
                "Santiago Bernal-Langarica",
                "Isabel Dom\u00ednguez Jim\u00e9nez",
                "Ivonne Maldonado",
                "Jos\u00e9 Jorge Medina-Serna",
                "Javier Rend\u00f3n",
                "Mar\u00eda Elena Tejeda-Yeomans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07859v1",
                "http://arxiv.org/pdf/2311.07859v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07857v1",
            "title": "Detecting Dark Matter Induced Power in Quantum Devices",
            "updated": "2023-11-14T02:18:44Z",
            "published": "2023-11-14T02:18:44Z",
            "summary": "In the past few years, many mesoscale systems have been proposed as possible\ndetectors of sub-GeV dark matter particles. In this work, we point out the\nfeasibility of probing dark matter-nucleon scattering cross section using\nsuperconductor-based quantum devices with meV-scale energy threshold. We\ncompute new limits on spin-independent dark matter scattering cross section\nusing the existing power measurement data from three different experiments for\nMeV to 10 GeV mass. We derive the limits for both halo and thermalized dark\nmatter populations.",
            "author": [
                "Anirban Das",
                "Noah Kurinsky",
                "Rebecca K. Leane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07857v1",
                "http://arxiv.org/pdf/2311.07857v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07854v1",
            "title": "Topological and spectral properties of random digraphs",
            "updated": "2023-11-14T02:12:41Z",
            "published": "2023-11-14T02:12:41Z",
            "summary": "We investigate some topological and spectral properties of\nErd\\H{o}s-R\\'{e}nyi (ER) random digraphs $D(n,p)$. In terms of topological\nproperties, our primary focus lies in analyzing the number of non-isolated\nvertices $V_x(D)$ as well as two vertex-degree-based topological indices: the\nRandi\\'c index $R(D)$ and sum-connectivity index $\\chi(D)$. First, by\nperforming a scaling analysis we show that the average degree $\\langle k\n\\rangle$ serves as scaling parameter for the average values of $V_x(D)$, $R(D)$\nand $\\chi(D)$. Then, we also state expressions relating the number of arcs,\nspectral radius, and closed walks of length 2 to $(n,p)$, the parameters of ER\nrandom digraphs. Concerning spectral properties, we compute six different graph\nenergies on $D(n,p)$. We start by validating $\\langle k \\rangle$ as the scaling\nparameter of the graph energies. Additionally, we reformulate a set of bounds\npreviously reported in the literature for these energies as a function $(n,p)$.\nFinally, we phenomenologically state relations between energies that allow us\nto extend previously known bounds.",
            "author": [
                "C. T. Mart\u00ednez-Mart\u00ednez",
                "J. A. M\u00e9ndez-Berm\u00fadez",
                "Jos\u00e9 M. Sigarreta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07854v1",
                "http://arxiv.org/pdf/2311.07854v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07853v1",
            "title": "Learning Mutually Informed Representations for Characters and Subwords",
            "updated": "2023-11-14T02:09:10Z",
            "published": "2023-11-14T02:09:10Z",
            "summary": "Most pretrained language models rely on subword tokenization, which processes\ntext as a sequence of subword tokens. However, different granularities of text,\nsuch as characters, subwords, and words, can contain different kinds of\ninformation. Previous studies have shown that incorporating multiple input\ngranularities improves model generalization, yet very few of them outputs\nuseful representations for each granularity. In this paper, we introduce the\nentanglement model, aiming to combine character and subword language models.\nInspired by vision-language models, our model treats characters and subwords as\nseparate modalities, and it generates mutually informed representations for\nboth granularities as output. We evaluate our model on text classification,\nnamed entity recognition, and POS-tagging tasks. Notably, the entanglement\nmodel outperforms its backbone language models, particularly in the presence of\nnoisy texts and low-resource languages. Furthermore, the entanglement model\neven outperforms larger pre-trained models on all English sequence labeling\ntasks and classification tasks. Our anonymized code is available at\nhttps://anonymous.4open.science/r/noisy-IE-A673",
            "author": [
                "Yilin Wang",
                "Xinyi Hu",
                "Matthew R. Gormley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07853v1",
                "http://arxiv.org/pdf/2311.07853v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07850v1",
            "title": "Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA",
            "updated": "2023-11-14T02:05:29Z",
            "published": "2023-11-14T02:05:29Z",
            "summary": "We present BYOKG, a universal question-answering (QA) system that can operate\non any knowledge graph (KG), requires no human-annotated training data, and can\nbe ready to use within a day -- attributes that are out-of-scope for current\nKGQA systems. BYOKG draws inspiration from the remarkable ability of humans to\ncomprehend information present in an unseen KG through exploration -- starting\nat random nodes, inspecting the labels of adjacent nodes and edges, and\ncombining them with their prior world knowledge. In BYOKG, exploration\nleverages an LLM-backed symbolic agent that generates a diverse set of\nquery-program exemplars, which are then used to ground a retrieval-augmented\nreasoning procedure to predict programs for arbitrary questions. BYOKG is\neffective over both small- and large-scale graphs, showing dramatic gains in QA\naccuracy over a zero-shot baseline of 27.89 and 58.02 F1 on GrailQA and MetaQA,\nrespectively. On GrailQA, we further show that our unsupervised BYOKG\noutperforms a supervised in-context learning method, demonstrating the\neffectiveness of exploration. Lastly, we find that performance of BYOKG\nreliably improves with continued exploration as well as improvements in the\nbase LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1\non a sub-sampled zero-shot split of GrailQA.",
            "author": [
                "Dhruv Agarwal",
                "Rajarshi Das",
                "Sopan Khosla",
                "Rashmi Gangadharaiah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07850v1",
                "http://arxiv.org/pdf/2311.07850v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07849v1",
            "title": "Neural integration for constitutive equations using small data",
            "updated": "2023-11-14T02:02:30Z",
            "published": "2023-11-14T02:02:30Z",
            "summary": "Data-driven models based on deep learning algorithms intend to overcome the\nlimitations of traditional constitutive modelling by directly learning from\ndata. However, the need for extensive data that collate the full state of the\nmaterial is hindered by traditional experimental observations, which typically\nprovide only small data - sparse and partial material state observations. To\naddress this issue, we develop a novel deep learning algorithm referred to as\nNeural Integration for Constitutive Equations to discover constitutive models\nat the material point level from scarce and incomplete observations. It builds\nupon the solution of the initial value problem describing the time evolution of\nthe material state, unlike the majority of data-driven approaches for\nconstitutive modelling that require large data of increments of state\nvariables. Numerical benchmarks demonstrate that the method can learn accurate,\nconsistent, and robust constitutive models from incomplete, sparse, and noisy\ndata collecting simple conventional experimental protocols.",
            "author": [
                "Filippo Masi",
                "Itai Einav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07849v1",
                "http://arxiv.org/pdf/2311.07849v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07842v1",
            "title": "Replay Clocks",
            "updated": "2023-11-14T01:42:34Z",
            "published": "2023-11-14T01:42:34Z",
            "summary": "In this work, we focus on the problem of replay clocks (RepCL). The need for\nreplay clocks arises from the observation that analyzing distributed\ncomputation for all desired properties of interest may not be feasible in an\nonline environment. These properties can be analyzed by replaying the\ncomputation. However, to be beneficial, such replay must account for all the\nuncertainty that is possible in a distributed computation. Specifically, if\nevent 'e' must occur before 'f' then the replay clock must ensure that 'e' is\nreplayed before 'f'. On the other hand, if 'e' and 'f' could occur in any order\nthen replay should not force an order between them.\n  After identifying the limitations of existing clocks to provide the replay\nprimitive, we present RepCL and identify an efficient representation for the\nsame. We demonstrate that RepCL can be implemented with less than four integers\nfor 64 processes for various system parameters if clocks are synchronized\nwithin 1 ms. Furthermore, the overhead of RepCL (for computing/comparing\ntimestamps and message size) is proportional to the size of the clock. Using\nsimulations, we identify the expected overhead of RepCL based on the given\nsystem settings. We also identify how a user can the identify feasibility\nregion for RepCL. Specifically, given the desired overhead of RepCL, it\nidentifies the region where unabridged replay is possible.",
            "author": [
                "Ishaan Lagwankar",
                "Sandeep S Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07842v1",
                "http://arxiv.org/pdf/2311.07842v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07841v2",
            "title": "PEMS: Pre-trained Epidemic Time-series Models",
            "updated": "2023-11-19T19:47:36Z",
            "published": "2023-11-14T01:40:21Z",
            "summary": "Providing accurate and reliable predictions about the future of an epidemic\nis an important problem for enabling informed public health decisions. Recent\nworks have shown that leveraging data-driven solutions that utilize advances in\ndeep learning methods to learn from past data of an epidemic often outperform\ntraditional mechanistic models. However, in many cases, the past data is sparse\nand may not sufficiently capture the underlying dynamics. While there exists a\nlarge amount of data from past epidemics, leveraging prior knowledge from\ntime-series data of other diseases is a non-trivial challenge. Motivated by the\nsuccess of pre-trained models in language and vision tasks, we tackle the\nproblem of pre-training epidemic time-series models to learn from multiple\ndatasets from different diseases and epidemics. We introduce Pre-trained\nEpidemic Time-Series Models (PEMS) that learn from diverse time-series datasets\nof a variety of diseases by formulating pre-training as a set of\nself-supervised learning (SSL) tasks. We tackle various important challenges\nspecific to pre-training for epidemic time-series such as dealing with\nheterogeneous dynamics and efficiently capturing useful patterns from multiple\nepidemic datasets by carefully designing the SSL tasks to learn important\npriors about the epidemic dynamics that can be leveraged for fine-tuning to\nmultiple downstream tasks. The resultant PEM outperforms previous\nstate-of-the-art methods in various downstream time-series tasks across\ndatasets of varying seasonal patterns, geography, and mechanism of contagion\nincluding the novel Covid-19 pandemic unseen in pre-trained data with better\nefficiency using smaller fraction of datasets.",
            "author": [
                "Harshavardhan Kamarthi",
                "B. Aditya Prakash"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07841v2",
                "http://arxiv.org/pdf/2311.07841v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07840v1",
            "title": "Enabling Decision-Support Systems through Automated Cell Tower Detection",
            "updated": "2023-11-14T01:40:08Z",
            "published": "2023-11-14T01:40:08Z",
            "summary": "Cell phone coverage and high-speed service gaps persist in rural areas in\nsub-Saharan Africa, impacting public access to mobile-based financial,\neducational, and humanitarian services. Improving maps of telecommunications\ninfrastructure can help inform strategies to eliminate gaps in mobile coverage.\nDeep neural networks, paired with remote sensing images, can be used for object\ndetection of cell towers and eliminate the need for inefficient and burdensome\nmanual mapping to find objects over large geographic regions. In this study, we\ndemonstrate a partially automated workflow to train an object detection model\nto locate cell towers using OpenStreetMap (OSM) features and high-resolution\nMaxar imagery. For model fine-tuning and evaluation, we curated a diverse\ndataset of over 6,000 unique images of cell towers in 26 countries in eastern,\nsouthern, and central Africa using automatically generated annotations from OSM\npoints. Our model achieves an average precision at 50% Intersection over Union\n(IoU) (AP@50) of 81.2 with good performance across different geographies and\nout-of-sample testing. Accurate localization of cell towers can yield more\naccurate cell coverage maps, in turn enabling improved delivery of digital\nservices for decision-support applications.",
            "author": [
                "Natasha Krell",
                "Will Gleave",
                "Daniel Nakada",
                "Justin Downes",
                "Amanda Willet",
                "Matthew Baran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07840v1",
                "http://arxiv.org/pdf/2311.07840v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07838v1",
            "title": "LLatrieval: LLM-Verified Retrieval for Verifiable Generation",
            "updated": "2023-11-14T01:38:02Z",
            "published": "2023-11-14T01:38:02Z",
            "summary": "Verifiable generation aims to let the large language model (LLM) generate\ntext with corresponding supporting documents, which enables the user to\nflexibly verify the answer and makes it more trustworthy. Its evaluation not\nonly measures the correctness of the answer, but also the answer's\nverifiability, i.e., how well the answer is supported by the corresponding\ndocuments. In typical, verifiable generation adopts the retrieval-read\npipeline, which is divided into two stages: 1) retrieve relevant documents of\nthe question. 2) according to the documents, generate the corresponding answer.\nSince the retrieved documents can supplement knowledge for the LLM to generate\nthe answer and serve as evidence, the retrieval stage is essential for the\ncorrectness and verifiability of the answer. However, the widely used\nretrievers become the bottleneck of the entire pipeline and limit the overall\nperformance. They often have fewer parameters than the large language model and\nhave not been proven to scale well to the size of LLMs. Since the LLM passively\nreceives the retrieval result, if the retriever does not correctly find the\nsupporting documents, the LLM can not generate the correct and verifiable\nanswer, which overshadows the LLM's remarkable abilities. In this paper, we\npropose LLatrieval (Large Language Model Verified Retrieval), where the LLM\nupdates the retrieval result until it verifies that the retrieved documents can\nsupport answering the question. Thus, the LLM can iteratively provide feedback\nto retrieval and facilitate the retrieval result to sufficiently support\nverifiable generation. Experimental results show that our method significantly\noutperforms extensive baselines and achieves new state-of-the-art results.",
            "author": [
                "Xiaonan Li",
                "Changtai Zhu",
                "Linyang Li",
                "Zhangyue Yin",
                "Tianxiang Sun",
                "Xipeng Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07838v1",
                "http://arxiv.org/pdf/2311.07838v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07834v1",
            "title": "Research on the X-Ray Polarization Deconstruction Method Based on\n  Hexagonal Convolutional Neural Network",
            "updated": "2023-11-14T01:29:44Z",
            "published": "2023-11-14T01:29:44Z",
            "summary": "Track reconstruction algorithms are critical for polarization measurements.\nIn addition to traditional moment-based track reconstruction approaches,\nconvolutional neural networks (CNN) are a promising alternative. However,\nhexagonal grid track images in gas pixel detectors (GPD) for better anisotropy\ndo not match the classical rectangle-based CNN, and converting the track images\nfrom hexagonal to square results in loss of information. We developed a new\nhexagonal CNN algorithm for track reconstruction and polarization estimation in\nX-ray polarimeters, which was used to extract emission angles and absorption\npoints from photoelectron track images and predict the uncertainty of the\npredicted emission angles. The simulated data of PolarLight test were used to\ntrain and test the hexagonal CNN models. For individual energies, the hexagonal\nCNN algorithm produced 15-30% improvements in modulation factor compared to\nmoment analysis method for 100% polarized data, and its performance was\ncomparable to rectangle-based CNN algorithm newly developed by IXPE team, but\nat a much less computational cost.",
            "author": [
                "Ya-Nan Li",
                "Jia-Huan Zhu",
                "Huai-Zhong Gao",
                "Hong Li",
                "Ji-Rong Cang",
                "Zhi Zeng",
                "Hua Feng",
                "Ming Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07834v1",
                "http://arxiv.org/pdf/2311.07834v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07833v1",
            "title": "Toward Efficient and Incremental Spectral Clustering via Parametric\n  Spectral Clustering",
            "updated": "2023-11-14T01:26:20Z",
            "published": "2023-11-14T01:26:20Z",
            "summary": "Spectral clustering is a popular method for effectively clustering\nnonlinearly separable data. However, computational limitations, memory\nrequirements, and the inability to perform incremental learning challenge its\nwidespread application. To overcome these limitations, this paper introduces a\nnovel approach called parametric spectral clustering (PSC). By extending the\ncapabilities of spectral clustering, PSC addresses the challenges associated\nwith big data and real-time scenarios and enables efficient incremental\nclustering with new data points. Experimental evaluations conducted on various\nopen datasets demonstrate the superiority of PSC in terms of computational\nefficiency while achieving clustering quality mostly comparable to standard\nspectral clustering. The proposed approach has significant potential for\nincremental and real-time data analysis applications, facilitating timely and\naccurate clustering in dynamic and evolving datasets. The findings of this\nresearch contribute to the advancement of clustering techniques and open new\navenues for efficient and effective data analysis. We publish the experimental\ncode at https://github.com/109502518/PSC_BigData.",
            "author": [
                "Jo-Chun Chen",
                "Hung-Hsuan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07833v1",
                "http://arxiv.org/pdf/2311.07833v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07830v1",
            "title": "Challenges in molecular dynamics simulations of heat exchange statistics",
            "updated": "2023-11-14T01:19:16Z",
            "published": "2023-11-14T01:19:16Z",
            "summary": "We study heat exchange in temperature-biased metal-molecule-metal molecular\njunctions by employing the LAMMPS atomic molecular dynamics simulator.\nGenerating the nonequilibrium steady state with Langevin thermostats at the\nboundaries of the junction, we show that the {\\it average} heat current across\na gold-alkanedithiol-gold nanojunction behaves correctly-physically, with the\nthermal conductance value matching the literature. In contrast, the {\\it full\nprobability distribution function} for heat exchange, as generated by the\nsimulator, violates the fundamental fluctuation symmetry for entropy\nproduction. We trace this failure back to the implementation of the thermostats\nand the expression used to calculate the heat exchange. To rectify this issue\nand produce the correct statistics, we introduce single-atom thermostats as an\nalternative to conventional many-atom thermostats. Once averaging heat exchange\nover the hot and cold thermostats, this approach successfully generates the\ncorrect probability distribution function, which we use to study the behavior\nof both the average heat current and its noise. We further examine the\nthermodynamic uncertainty relation in the molecular junction and show that it\nholds, albeit demonstrating nontrivial trends. Our study points to the need to\ncarefully implement nonequilibrium molecular dynamics solvers in atomistic\nsimulation software tools for future investigations of noise phenomena in\nthermal transport.",
            "author": [
                "Jonathan J. Wang",
                "Matthew Gerry",
                "Dvira Segal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07830v1",
                "http://arxiv.org/pdf/2311.07830v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07829v1",
            "title": "A Coding Scheme for Straggler Resilient Quantum $X$-Secure $T$-Private\n  Information Retrieval",
            "updated": "2023-11-14T01:14:01Z",
            "published": "2023-11-14T01:14:01Z",
            "summary": "Building on recent constructions of Quantum Cross Subspace Alignment (QCSA)\ncodes, this work develops a coding scheme for QEXSTPIR, i.e., classical private\ninformation retrieval with $X$-secure storage and $T$-private queries, over a\nquantum multiple access channel, that is resilient to any set of up to $E$\nerased servers (equivalently known as unresponsive servers, or stragglers). The\nscheme is accordingly labeled QECSA, with the `E' indicating resilience to\nerased servers. The novelty of QECSA lies in achieving efficient $E$-straggler\nresilience on top of existing QCSA codes that already achieve $X$-secure\nstorage, $T$-private queries, and distributed superdense coding gains for\ncommunication efficient decoding. The QECSA code structure may be broadly\nuseful for problems such as quantum coded secure distributed computation, where\nsecurity, straggler resilience, and distributed superdense coding gains are\nsimultaneously required.",
            "author": [
                "Yuxiang Lu",
                "Syed A. Jafar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07829v1",
                "http://arxiv.org/pdf/2311.07829v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07826v1",
            "title": "Adaptive Search Optimization: Dynamic Algorithm Selection and Caching\n  for Enhanced Database Performance",
            "updated": "2023-11-14T01:05:47Z",
            "published": "2023-11-14T01:05:47Z",
            "summary": "Efficient search operations in databases are paramount for timely retrieval\nof information various applications. This research introduces a novel approach,\ncombining dynamicalgorithm1 selection and caching2 strategies, to optimize\nsearch performance. The proposed dynamic search algorithm intelligently\nswitches between Binary3 and Interpolation 4 Search based on dataset\ncharacteristics, significantly improving efficiency for non-uniformly\ndistributed data. Additionally, a robust caching mechanism5 stores and\nretrieves previous search results, further enhancing computational efficiency6.\nTheoretical analysis and extensive experiments demonstrate the effectiveness of\nthe approach, showcasing its potential to revolutionize database performance7\nin scenarios with diverse data distributions. This research contributes\nvaluable insights and practical solutions to the realm of database\noptimization, offering a promising avenue for enhancing search operations in\nreal-world applications",
            "author": [
                "Hakikat Singh"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.34751.69281",
                "http://arxiv.org/abs/2311.07826v1",
                "http://arxiv.org/pdf/2311.07826v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08429v1",
            "title": "Purpose in the Machine: Do Traffic Simulators Produce Distributionally\n  Equivalent Outcomes for Reinforcement Learning Applications?",
            "updated": "2023-11-14T01:05:14Z",
            "published": "2023-11-14T01:05:14Z",
            "summary": "Traffic simulators are used to generate data for learning in intelligent\ntransportation systems (ITSs). A key question is to what extent their modelling\nassumptions affect the capabilities of ITSs to adapt to various scenarios when\ndeployed in the real world. This work focuses on two simulators commonly used\nto train reinforcement learning (RL) agents for traffic applications, CityFlow\nand SUMO. A controlled virtual experiment varying driver behavior and\nsimulation scale finds evidence against distributional equivalence in\nRL-relevant measures from these simulators, with the root mean squared error\nand KL divergence being significantly greater than 0 for all assessed measures.\nWhile granular real-world validation generally remains infeasible, these\nfindings suggest that traffic simulators are not a deus ex machina for RL\ntraining: understanding the impacts of inter-simulator differences is necessary\nto train and deploy RL-based ITSs.",
            "author": [
                "Rex Chen",
                "Kathleen M. Carley",
                "Fei Fang",
                "Norman Sadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08429v1",
                "http://arxiv.org/pdf/2311.08429v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07821v1",
            "title": "Statistical Parameterized Physics-Based Machine Learning Digital Twin\n  Models for Laser Powder Bed Fusion Process",
            "updated": "2023-11-14T00:45:53Z",
            "published": "2023-11-14T00:45:53Z",
            "summary": "A digital twin (DT) is a virtual representation of physical process, products\nand/or systems that requires a high-fidelity computational model for continuous\nupdate through the integration of sensor data and user input. In the context of\nlaser powder bed fusion (LPBF) additive manufacturing, a digital twin of the\nmanufacturing process can offer predictions for the produced parts, diagnostics\nfor manufacturing defects, as well as control capabilities. This paper\nintroduces a parameterized physics-based digital twin (PPB-DT) for the\nstatistical predictions of LPBF metal additive manufacturing process. We\naccomplish this by creating a high-fidelity computational model that accurately\nrepresents the melt pool phenomena and subsequently calibrating and validating\nit through controlled experiments. In PPB-DT, a mechanistic reduced-order\nmethod-driven stochastic calibration process is introduced, which enables the\nstatistical predictions of the melt pool geometries and the identification of\ndefects such as lack-of-fusion porosity and surface roughness, specifically for\ndiagnostic applications. Leveraging data derived from this physics-based model\nand experiments, we have trained a machine learning-based digital twin\n(PPB-ML-DT) model for predicting, monitoring, and controlling melt pool\ngeometries. These proposed digital twin models can be employed for predictions,\ncontrol, optimization, and quality assurance within the LPBF process,\nultimately expediting product development and certification in LPBF-based metal\nadditive manufacturing.",
            "author": [
                "Yangfan Li",
                "Satyajit Mojumder",
                "Ye Lu",
                "Abdullah Al Amin",
                "Jiachen Guo",
                "Xiaoyu Xie",
                "Wei Chen",
                "Gregory J. Wagner",
                "Jian Cao",
                "Wing Kam Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07821v1",
                "http://arxiv.org/pdf/2311.07821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.NA",
                "math.NA",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07820v1",
            "title": "On the Analysis of Cross-Lingual Prompt Tuning for Decoder-based\n  Multilingual Model",
            "updated": "2023-11-14T00:43:33Z",
            "published": "2023-11-14T00:43:33Z",
            "summary": "An exciting advancement in the field of multilingual models is the emergence\nof autoregressive models with zero- and few-shot capabilities, a phenomenon\nwidely reported in large-scale language models. To further improve model\nadaptation to cross-lingual tasks, another trend is to further fine-tune the\nlanguage models with either full fine-tuning or parameter-efficient tuning.\nHowever, the interaction between parameter-efficient fine-tuning (PEFT) and\ncross-lingual tasks in multilingual autoregressive models has yet to be\nstudied. Specifically, we lack an understanding of the role of linguistic\ndistributions in multilingual models in the effectiveness of token-based prompt\ntuning. To address this question, we conduct experiments comparing prompt\ntuning and fine-tuning on the decoder-based multilingual model, XGLM, with four\ncross-lingual tasks (XNLI, PAWS-X, POS, NER). According to our study, prompt\ntuning achieves on par or better performance over fine-tuning across all\nlanguages while updating at most 0.13\\% of the model parameters. Moreover, we\nempirically show that prompt tuning is more effective in enhancing the\nperformance of low-resource languages than fine-tuning. Our further analysis\nshows that the phenomenon is related to the tokenization scheme of the\nmultilingual model.",
            "author": [
                "Nohil Park",
                "Joonsuk Park",
                "Kang Min Yoo",
                "Sungroh Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07820v1",
                "http://arxiv.org/pdf/2311.07820v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07818v1",
            "title": "Container Resource Allocation versus Performance of Data-intensive\n  Applications on Different Cloud Servers",
            "updated": "2023-11-14T00:33:40Z",
            "published": "2023-11-14T00:33:40Z",
            "summary": "In recent years, data-intensive applications have been increasingly deployed\non cloud systems. Such applications utilize significant compute, memory, and\nI/O resources to process large volumes of data. Optimizing the performance and\ncost-efficiency for such applications is a non-trivial problem. The problem\nbecomes even more challenging with the increasing use of containers, which are\npopular due to their lower operational overheads and faster boot speed at the\ncost of weaker resource assurances for the hosted applications. In this paper,\ntwo containerized data-intensive applications with very different performance\nobjectives and resource needs were studied on cloud servers with Docker\ncontainers running on Intel Xeon E5 and AMD EPYC Rome multi-core processors\nwith a range of CPU, memory, and I/O configurations. Primary findings from our\nexperiments include: 1) Allocating multiple cores to a compute-intensive\napplication can improve performance, but only if the cores do not contend for\nthe same caches, and the optimal core counts depend on the specific workload;\n2) allocating more memory to a memory-intensive application than its\ndeterministic data workload does not further improve performance; however, 3)\nhaving multiple such memory-intensive containers on the same server can lead to\ncache and memory bus contention leading to significant and volatile performance\ndegradation. The comparative observations on Intel and AMD servers provided\ninsights into trade-offs between larger numbers of distributed chiplets\ninterconnected with higher speed buses (AMD) and larger numbers of centrally\nintegrated cores and caches with lesser speed buses (Intel). For the two types\nof applications studied, the more distributed caches and faster data buses have\nbenefited the deployment of larger numbers of containers.",
            "author": [
                "Qing Wang",
                "Snigdhaswin Kar",
                "Prabodh Mishra",
                "Caleb Linduff",
                "Ryan Izard",
                "Khayam Anjam",
                "Geddings Barrineau",
                "Junaid Zulfiqar",
                "Kuang-Ching Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07818v1",
                "http://arxiv.org/pdf/2311.07818v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07815v1",
            "title": "Cooperative AI via Decentralized Commitment Devices",
            "updated": "2023-11-14T00:23:21Z",
            "published": "2023-11-14T00:23:21Z",
            "summary": "Credible commitment devices have been a popular approach for robust\nmulti-agent coordination. However, existing commitment mechanisms face\nlimitations like privacy, integrity, and susceptibility to mediator or user\nstrategic behavior. It is unclear if the cooperative AI techniques we study are\nrobust to real-world incentives and attack vectors. However, decentralized\ncommitment devices that utilize cryptography have been deployed in the wild,\nand numerous studies have shown their ability to coordinate algorithmic agents\nfacing adversarial opponents with significant economic incentives, currently in\nthe order of several million to billions of dollars. In this paper, we use\nexamples in the decentralization and, in particular, Maximal Extractable Value\n(MEV) (arXiv:1904.05234) literature to illustrate the potential security issues\nin cooperative AI. We call for expanded research into decentralized commitments\nto advance cooperative AI capabilities for secure coordination in open\nenvironments and empirical testing frameworks to evaluate multi-agent\ncoordination ability given real-world commitment constraints.",
            "author": [
                "Xinyuan Sun",
                "Davide Crapis",
                "Matt Stephenson",
                "Barnab\u00e9 Monnot",
                "Thomas Thiery",
                "Jonathan Passerat-Palmbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07815v1",
                "http://arxiv.org/pdf/2311.07815v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CR",
                "cs.GT",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17923v1",
            "title": "Enhanced Generative Adversarial Networks for Unseen Word Generation from\n  EEG Signals",
            "updated": "2023-11-14T00:20:25Z",
            "published": "2023-11-14T00:20:25Z",
            "summary": "Recent advances in brain-computer interface (BCI) technology, particularly\nbased on generative adversarial networks (GAN), have shown great promise for\nimproving decoding performance for BCI. Within the realm of Brain-Computer\nInterfaces (BCI), GANs find application in addressing many areas. They serve as\na valuable tool for data augmentation, which can solve the challenge of limited\ndata availability, and synthesis, effectively expanding the dataset and\ncreating novel data formats, thus enhancing the robustness and adaptability of\nBCI systems. Research in speech-related paradigms has significantly expanded,\nwith a critical impact on the advancement of assistive technologies and\ncommunication support for individuals with speech impairments. In this study,\nGANs were investigated, particularly for the BCI field, and applied to generate\ntext from EEG signals. The GANs could generalize all subjects and decode unseen\nwords, indicating its ability to capture underlying speech patterns consistent\nacross different individuals. The method has practical applications in neural\nsignal-based speech recognition systems and communication aids for individuals\nwith speech difficulties.",
            "author": [
                "Young-Eun Lee",
                "Seo-Hyun Lee",
                "Soowon Kim",
                "Jung-Sun Lee",
                "Deok-Seon Kim",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17923v1",
                "http://arxiv.org/pdf/2311.17923v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07814v1",
            "title": "A novel and simple spectral method for nonlocal PDEs with the fractional\n  Laplacian",
            "updated": "2023-11-14T00:07:24Z",
            "published": "2023-11-14T00:07:24Z",
            "summary": "We propose a novel and simple spectral method based on the semi-discrete\nFourier transforms to discretize the fractional Laplacian\n$(-\\Delta)^\\frac{\\alpha}{2}$. Numerical analysis and experiments are provided\nto study its performance. Our method has the same symbol $|\\xi|^\\alpha$ as the\nfractional Laplacian $(-\\Delta)^\\frac{\\alpha}{2}$ at the discrete level, and\nthus it can be viewed as the exact discrete analogue of the fractional\nLaplacian. This {\\it unique feature} distinguishes our method from other\nexisting methods for the fractional Laplacian. Note that our method is\ndifferent from the Fourier pseudospectral methods in the literature, which are\nusually limited to periodic boundary conditions (see Remark \\ref{remark0}).\nNumerical analysis shows that our method can achieve a spectral accuracy. The\nstability and convergence of our method in solving the fractional Poisson\nequations were analyzed. Our scheme yields a multilevel Toeplitz stiffness\nmatrix, and thus fast algorithms can be developed for efficient matrix-vector\nproducts. The computational complexity is ${\\mathcal O}(2N\\log(2N))$, and the\nmemory storage is ${\\mathcal O}(N)$ with $N$ the total number of points.\nExtensive numerical experiments verify our analytical results and demonstrate\nthe effectiveness of our method in solving various problems.",
            "author": [
                "Shiping Zhou",
                "Yanzhi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07814v1",
                "http://arxiv.org/pdf/2311.07814v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07811v1",
            "title": "In-context Learning Generalizes, But Not Always Robustly: The Case of\n  Syntax",
            "updated": "2023-11-13T23:52:43Z",
            "published": "2023-11-13T23:52:43Z",
            "summary": "In-context learning (ICL) is now a common method for supervising large\nlanguage models (LLMs): given labeled examples in the input context, the LLM\nlearns to perform the task without weight updates. Despite ICL's prevalence and\nutility, we understand little about whether models supervised in this manner\nrepresent the underlying structure of their tasks, rather than superficial\nheuristics that only generalize to identically distributed examples. In this\nstudy, we investigate the robustness of LLMs supervised via ICL using the test\ncase of sensitivity to syntax, which is a prerequisite for robust language\nunderstanding. Our experiments are based on two simple and well-controlled\nsyntactic transformations tasks, where correct out-of-distribution\ngeneralization requires an accurate syntactic analysis of the input. We further\ninvestigate whether out-of-distribution generalization can be improved via\nchain-of-thought prompting, where the model is provided with a sequence of\nintermediate computation steps that illustrate how the task ought to be\nperformed. In experiments with models from the GPT, PaLM, and Llama 2 families,\nwe find large variance across LMs on this fundamental linguistic phenomenon,\nand that the variance is explained more by the composition of the pre-training\ncorpus and supervision methods than by model size. In particular, we find\nevidence that models pre-trained on code generalize better, and benefit to a\ngreater extent from chain-of-thought prompting.",
            "author": [
                "Aaron Mueller",
                "Albert Webson",
                "Jackson Petty",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07811v1",
                "http://arxiv.org/pdf/2311.07811v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07807v1",
            "title": "Creation of a CS1 Course with Modern C++ Principles",
            "updated": "2023-11-13T23:43:38Z",
            "published": "2023-11-13T23:43:38Z",
            "summary": "Best practices in programming need to be emphasized in a CS1 course as bad\nstudent habits persist if not reinforced well. The C++ programming language,\nalthough a relatively old language, has been regularly updated with new\nversions since 2011, on the pace of once every three years. Each new version\ncontains important features that make the C++ language more complex for\nbackwards compatibility, but often introduce new features to make common use\ncases simpler to implement. This poster contains experiences in designing a CS1\ncourse that uses the C++ programming language that incorporates ``modern''\nversions of the language from the start, as well as recent conferences about\nthe language. Our goals were to prevent many common bad habits among C++\nprogrammers.",
            "author": [
                "Ryan E. Dougherty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07807v1",
                "http://arxiv.org/pdf/2311.07807v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07806v1",
            "title": "Assessing Test-time Variability for Interactive 3D Medical Image\n  Segmentation with Diverse Point Prompts",
            "updated": "2023-11-13T23:40:24Z",
            "published": "2023-11-13T23:40:24Z",
            "summary": "Interactive segmentation model leverages prompts from users to produce robust\nsegmentation. This advancement is facilitated by prompt engineering, where\ninteractive prompts serve as strong priors during test-time. However, this is\nan inherently subjective and hard-to-reproduce process. The variability in user\nexpertise and inherently ambiguous boundaries in medical images can lead to\ninconsistent prompt selections, potentially affecting segmentation accuracy.\nThis issue has not yet been extensively explored for medical imaging. In this\npaper, we assess the test-time variability for interactive medical image\nsegmentation with diverse point prompts. For a given target region, the point\nis classified into three sub-regions: boundary, margin, and center. Our goal is\nto identify a straightforward and efficient approach for optimal prompt\nselection during test-time based on three considerations: (1) benefits of\nadditional prompts, (2) effects of prompt placement, and (3) strategies for\noptimal prompt selection. We conduct extensive experiments on the public\nMedical Segmentation Decathlon dataset for challenging colon tumor segmentation\ntask. We suggest an optimal strategy for prompt selection during test-time,\nsupported by comprehensive results. The code is publicly available at\nhttps://github.com/MedICL-VU/variability",
            "author": [
                "Hao Li",
                "Han Liu",
                "Dewei Hu",
                "Jiacheng Wang",
                "Ipek Oguz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07806v1",
                "http://arxiv.org/pdf/2311.07806v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07804v1",
            "title": "IruMozhi: Automatically classifying diglossia in Tamil",
            "updated": "2023-11-13T23:36:35Z",
            "published": "2023-11-13T23:36:35Z",
            "summary": "Tamil, a Dravidian language of South Asia, is a highly diglossic language\nwith two very different registers in everyday use: Literary Tamil (preferred in\nwriting and formal communication) and Spoken Tamil (confined to speech and\ninformal media). Spoken Tamil is under-supported in modern NLP systems. In this\npaper, we release IruMozhi, a human-annotated dataset of parallel text in\nLiterary and Spoken Tamil. We train classifiers on the task of identifying\nwhich variety a text belongs to. We use these models to gauge the availability\nof pretraining data in Spoken Tamil, to audit the composition of existing\nlabelled datasets for Tamil, and to encourage future work on the variety.",
            "author": [
                "Kabilan Prasanna",
                "Aryaman Arora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07804v1",
                "http://arxiv.org/pdf/2311.07804v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07803v1",
            "title": "Designing Theory of Computing Backwards",
            "updated": "2023-11-13T23:32:41Z",
            "published": "2023-11-13T23:32:41Z",
            "summary": "The design of any technical Computer Science course must involve its context\nwithin the institution's CS program, but also incorporate any new material that\nis relevant and appropriately accessible to students. In many institutions,\ntheory of computing (ToC) courses within undergraduate CS programs are often\nplaced near the end of the program, and have a very common structure of\nbuilding off previous sections of the course. The central question behind any\nsuch course is ``What are the limits of computers?'' for various types of\ncomputational models. However, what is often intuitive for students about what\na ``computer'' is--a Turing machine--is taught at the end of the course, which\nnecessitates motivation for earlier models. This poster contains our\nexperiences in designing a ToC course that teaches the material effectively\n``backwards,'' with pedagogic motivation of instead asking the question ``What\nsuitable restrictions can we place on computers to make their problems\ntractable?'' We also give recommendations for future course design.",
            "author": [
                "Ryan E. Dougherty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07803v1",
                "http://arxiv.org/pdf/2311.07803v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07800v1",
            "title": "Atypical behaviors of a tagged particle in asymmetric simple exclusion",
            "updated": "2023-11-13T23:30:28Z",
            "published": "2023-11-13T23:30:28Z",
            "summary": "Consider the asymmetric nearest-neighbor exclusion process (ASEP) on\n${\\mathbb Z}$ with single particle drift $\\gamma>0$, starting from a Bernoulli\nproduct invariant measure $\\nu_\\rho$ with density $\\rho$. It is known that the\nposition $X_{N}$ of a tagged particle, say initially at the origin, at time $N$\nsatisfies an a.s. law of large numbers $\\frac{1}{N}X_N \\rightarrow\n\\gamma(1-\\rho)$ as $N\\uparrow\\infty$.\n  In this context, we study the `typical' behavior of the tagged particle and\n`bulk' density evolution subject to `atypical' events $\\{X_N\\geq AN\\}$ or\n$\\{X_N\\leq AN\\}$ for $A\\neq \\gamma(1-\\rho)$. We detail different structures,\ndepending on whether $A<0$, $0\\leq A< \\gamma(1-\\rho)$, $\\gamma(1-\\rho)<A<\n\\gamma$, or $A\\geq \\gamma$, under which these atypical events are achieved, and\ncompute associated large deviation costs. Among our results is an `upper tail'\nlarge deviation principle in scale $N$ for $\\frac{1}{N}X_N$.",
            "author": [
                "Sunder Sethuraman",
                "S. R. S. Varadhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07800v1",
                "http://arxiv.org/pdf/2311.07800v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP",
                "60K35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07795v1",
            "title": "Optimal control formulation of transition path problems for Markov Jump\n  Processes",
            "updated": "2023-11-13T23:12:23Z",
            "published": "2023-11-13T23:12:23Z",
            "summary": "Among various rare events, the effective computation of transition paths\nconnecting metastable states in a stochastic model is an important problem.\nThis paper proposes a stochastic optimal control formulation for transition\npath problems in an infinite time horizon for Markov jump processes on polish\nspace. An unbounded terminal cost at a stopping time and a controlled\ntransition rate for the jump process regulate the transition from one\nmetastable state to another. The running cost is taken as an entropy form of\nthe control velocity, in contrast to the quadratic form for diffusion\nprocesses. Using the Girsanov transformation for Markov jump processes, the\noptimal control problem in both finite time and infinite time horizon with\nstopping time fit into one framework: the optimal change of measures in the\nC\\`adl\\`ag path space via minimizing their relative entropy. We prove that the\ncommittor function, solved from the backward equation with appropriate boundary\nconditions, yields an explicit formula for the optimal path measure and the\nassociated optimal control for the transition path problem. The unbounded\nterminal cost leads to a singular transition rate (unbounded control velocity),\nfor which, the Gamma convergence technique is applied to pass the limit for a\nregularized optimal path measure. The limiting path measure is proved to solve\na Martingale problem with an optimally controlled transition rate and the\nassociated optimal control is given by Doob-h transformation. The resulting\noptimally controlled process can realize the transitions almost surely.",
            "author": [
                "Yuan Gao",
                "Jian-Guo Liu",
                "Oliver Tse"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07795v1",
                "http://arxiv.org/pdf/2311.07795v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.AP",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07792v1",
            "title": "Western, Religious or Spiritual: An Evaluation of Moral Justification in\n  Large Language Models",
            "updated": "2023-11-13T23:01:19Z",
            "published": "2023-11-13T23:01:19Z",
            "summary": "The increasing success of Large Language Models (LLMs) in variety of tasks\nlead to their widespread use in our lives which necessitates the examination of\nthese models from different perspectives. The alignment of these models to\nhuman values is an essential concern in order to establish trust that we have\nsafe and responsible systems. In this paper, we aim to find out which values\nand principles are embedded in LLMs in the process of moral justification. For\nthis purpose, we come up with three different moral perspective categories:\nWestern tradition perspective (WT), Abrahamic tradition perspective (AT), and\nSpiritualist/Mystic tradition perspective (SMT). In two different experiment\nsettings, we asked models to choose principles from the three for suggesting a\nmoral action and evaluating the moral permissibility of an action if one tries\nto justify an action on these categories, respectively. Our experiments\nindicate that tested LLMs favors the Western tradition moral perspective over\nothers. Additionally, we observe that there potentially exists an\nover-alignment towards religious values represented in the Abrahamic Tradition,\nwhich causes models to fail to recognize an action is immoral if it is\npresented as a \"religious-action\". We believe that these results are essential\nin order to direct our attention in future efforts.",
            "author": [
                "Eyup Engin Kucuk",
                "Muhammed Yusuf Kocyigit"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07792v1",
                "http://arxiv.org/pdf/2311.07792v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07790v1",
            "title": "Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for\n  continual scientific machine learning",
            "updated": "2023-11-13T22:55:56Z",
            "published": "2023-11-13T22:55:56Z",
            "summary": "We address two major challenges in scientific machine learning (SciML):\ninterpretability and computational efficiency. We increase the interpretability\nof certain learning processes by establishing a new theoretical connection\nbetween optimization problems arising from SciML and a generalized Hopf\nformula, which represents the viscosity solution to a Hamilton-Jacobi partial\ndifferential equation (HJ PDE) with time-dependent Hamiltonian. Namely, we show\nthat when we solve certain regularized learning problems with integral-type\nlosses, we actually solve an optimal control problem and its associated HJ PDE\nwith time-dependent Hamiltonian. This connection allows us to reinterpret\nincremental updates to learned models as the evolution of an associated HJ PDE\nand optimal control problem in time, where all of the previous information is\nintrinsically encoded in the solution to the HJ PDE. As a result, existing HJ\nPDE solvers and optimal control algorithms can be reused to design new\nefficient training approaches for SciML that naturally coincide with the\ncontinual learning framework, while avoiding catastrophic forgetting. As a\nfirst exploration of this connection, we consider the special case of linear\nregression and leverage our connection to develop a new Riccati-based\nmethodology for solving these learning problems that is amenable to continual\nlearning applications. We also provide some corresponding numerical examples\nthat demonstrate the potential computational and memory advantages our\nRiccati-based approach can provide.",
            "author": [
                "Paula Chen",
                "Tingwei Meng",
                "Zongren Zou",
                "J\u00e9r\u00f4me Darbon",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07790v1",
                "http://arxiv.org/pdf/2311.07790v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07789v1",
            "title": "Level-k Thinking in the Extensive Form",
            "updated": "2023-11-13T22:50:09Z",
            "published": "2023-11-13T22:50:09Z",
            "summary": "Level-$k$ thinking and Cognitive Hierarchy have been widely applied as a\nnormal-form solution concept in behavioral and experimental game theory. We\nconsider level-k thinking in games in extensive form. Player's may learn about\nlevels of opponents' thinking during the play of the game because some\ninformation sets may be inconsistent with certain levels. In particular, for\nany information set reached, a level-$k$ player attaches the maximum\nlevel-$\\ell$ thinking for $\\ell < k$ to her opponents consistent with the\ninformation set. We compare our notion of strong level-$k$ thinking with other\nsolution concepts such as level-$k$ thinking in the associated normal form,\nstrong rationalizability, $\\Delta$-rationalizability, iterated admissibility,\nbackward rationalizability, backward level-$k$ thinking, and backward\ninduction. We use strong level-$k$ thinking to reanalyze data from some prior\nexperiments in the literature.",
            "author": [
                "Burkhard C. Schipper",
                "Hang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07789v1",
                "http://arxiv.org/pdf/2311.07789v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07788v1",
            "title": "CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework\n  for Zero-Shot Electroencephalography Signal Conversion",
            "updated": "2023-11-13T22:46:43Z",
            "published": "2023-11-13T22:46:43Z",
            "summary": "Electroencephalography (EEG) is a prominent non-invasive neuroimaging\ntechnique providing insights into brain function. Unfortunately, EEG data\nexhibit a high degree of noise and variability across subjects hampering\ngeneralizable signal extraction. Therefore, a key aim in EEG analysis is to\nextract the underlying neural activation (content) as well as to account for\nthe individual subject variability (style). We hypothesize that the ability to\nconvert EEG signals between tasks and subjects requires the extraction of\nlatent representations accounting for content and style. Inspired by recent\nadvancements in voice conversion technologies, we propose a novel contrastive\nsplit-latent permutation autoencoder (CSLP-AE) framework that directly\noptimizes for EEG conversion. Importantly, the latent representations are\nguided using contrastive learning to promote the latent splits to explicitly\nrepresent subject (style) and task (content). We contrast CSLP-AE to\nconventional supervised, unsupervised (AE), and self-supervised (contrastive\nlearning) training and find that the proposed approach provides favorable\ngeneralizable characterizations of subject and task. Importantly, the procedure\nalso enables zero-shot conversion between unseen subjects. While the present\nwork only considers conversion of EEG, the proposed CSLP-AE provides a general\nframework for signal conversion and extraction of content (task activation) and\nstyle (subject variability) components of general interest for the modeling and\nanalysis of biological signals.",
            "author": [
                "Anders Vestergaard N\u00f8rskov",
                "Alexander Neergaard Zahid",
                "Morten M\u00f8rup"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07788v1",
                "http://arxiv.org/pdf/2311.07788v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07787v1",
            "title": "Hybrid Synaptic Structure for Spiking Neural Network Realization",
            "updated": "2023-11-13T22:42:07Z",
            "published": "2023-11-13T22:42:07Z",
            "summary": "Neural networks and neuromorphic computing play pivotal roles in deep\nlearning and machine vision. Due to their dissipative nature and inherent\nlimitations, traditional semiconductor-based circuits face challenges in\nrealizing ultra-fast and low-power neural networks. However, the spiking\nbehavior characteristic of single flux quantum (SFQ) circuits positions them as\npromising candidates for spiking neural networks (SNNs). Our previous work\nshowcased a JJ-Soma design capable of operating at tens of gigahertz while\nconsuming only a fraction of the power compared to traditional circuits, as\ndocumented in [1]. This paper introduces a compact SFQ-based synapse design\nthat applies positive and negative weighted inputs to the JJ-Soma. Using an\nRSFQ synapse empowers us to replicate the functionality of a biological neuron,\na crucial step in realizing a complete SNN. The JJ-Synapse can operate at\nultra-high frequencies, exhibits orders of magnitude lower power consumption\nthan CMOS counterparts, and can be conveniently fabricated using commercial Nb\nprocesses. Furthermore, the network's flexibility enables modifications by\nincorporating cryo-CMOS circuits for weight value adjustments. In our endeavor,\nwe have successfully designed, fabricated, and partially tested the JJ-Synapse\nwithin our cryocooler system. Integration with the JJ-Soma further facilitates\nthe realization of a high-speed inference SNN.",
            "author": [
                "Sasan Razmkhah",
                "Mustafa Altay Karamuftuoglu",
                "Ali Bozbey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07787v1",
                "http://arxiv.org/pdf/2311.07787v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cs.AR",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07785v1",
            "title": "Fracture of bio-cemented sands",
            "updated": "2023-11-13T22:26:56Z",
            "published": "2023-11-13T22:26:56Z",
            "summary": "Bio-chemical reactions enable the production of biomimetic materials such as\nsandstones. In the present study, microbiologically-induced calcium carbonate\nprecipitation (MICP) is used to manufacture laboratory-scale specimens for\nfracture toughness measurement. The mode I and mixed-mode fracture toughnesses\nare measured as a function of cementation, and are correlated with strength,\npermeability and porosity. A micromechanical model is developed to predict the\ndependence of mode I fracture toughness upon the degree of cementation. In\naddition, the role of the crack tip $T$-stress in dictating kink angle and\ntoughness is determined for mixed mode loading. At a sufficiently low degree of\ncementation, the zone of microcracking in the vicinity of the crack tip is\nsufficiently large for a crack tip $K$-field to cease to exist and for crack\nkinking theory to not apply. The interplay between cementation and fracture\nproperties of sedimentary rocks is explained; this understanding underpins a\nwide range of rock fracture phenomena including hydraulic fracture.",
            "author": [
                "C. Konstantinou",
                "E. Mart\u00ednez-Pa\u00f1eda",
                "G. Biscontin",
                "N. A. Fleck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07785v1",
                "http://arxiv.org/pdf/2311.07785v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CE",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07784v2",
            "title": "A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated\n  Class Incremental Learning for Vision Tasks",
            "updated": "2023-11-21T08:23:31Z",
            "published": "2023-11-13T22:21:27Z",
            "summary": "Deep learning models often suffer from forgetting previously learned\ninformation when trained on new data. This problem is exacerbated in federated\nlearning (FL), where the data is distributed and can change independently for\neach user. Many solutions are proposed to resolve this catastrophic forgetting\nin a centralized setting. However, they do not apply directly to FL because of\nits unique complexities, such as privacy concerns and resource limitations. To\novercome these challenges, this paper presents a framework for\n$\\textbf{federated class incremental learning}$ that utilizes a generative\nmodel to synthesize samples from past distributions. This data can be later\nexploited alongside the training data to mitigate catastrophic forgetting. To\npreserve privacy, the generative model is trained on the server using data-free\nmethods at the end of each task without requesting data from clients. Moreover,\nour solution does not demand the users to store old data or models, which gives\nthem the freedom to join/leave the training at any time. Additionally, we\nintroduce SuperImageNet, a new regrouping of the ImageNet dataset specifically\ntailored for federated continual learning. We demonstrate significant\nimprovements compared to existing baselines through extensive experiments on\nmultiple datasets.",
            "author": [
                "Sara Babakniya",
                "Zalan Fabian",
                "Chaoyang He",
                "Mahdi Soltanolkotabi",
                "Salman Avestimehr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07784v2",
                "http://arxiv.org/pdf/2311.07784v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07781v1",
            "title": "An Ex Post Condition for the Exactness of Optimal Power Flow Conic\n  Relaxations",
            "updated": "2023-11-13T22:15:53Z",
            "published": "2023-11-13T22:15:53Z",
            "summary": "Convex relaxations of the optimal power flow problem (OPF) provide an\nefficient alternative to solving the NP-hard alternating current (AC) optimal\npower flow. Conic relaxations of the OPF, in particular, greatly accelerate\nresolution while leading to high-quality approximations that are exact in\nseveral scenarios. However, the sufficient conditions guaranteeing exactness\nare stringent, e.g., requiring radial networks. In this letter, we present an\nex post condition for the exactness of conic relaxations of the OPF. Instead of\nrelying on satisfying necessary conditions a priori, the operator can obtain an\nexactness certificate for the computed solution. This enables the use of conic\nrelaxations for networks where exactness requirements are not met while still\nproviding an optimality guarantee.",
            "author": [
                "Jean-Luc Lupien",
                "Antoine Lesage-Landry"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07781v1",
                "http://arxiv.org/pdf/2311.07781v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07778v1",
            "title": "Depth and regularity of tableau ideals",
            "updated": "2023-11-13T22:08:05Z",
            "published": "2023-11-13T22:08:05Z",
            "summary": "We compute the depth and regularity of ideals associated with arbitrary\nfillings of positive integers to a Young diagram, called the tableau ideals.",
            "author": [
                "Do Trong Hoang",
                "Thanh Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07778v1",
                "http://arxiv.org/pdf/2311.07778v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO",
                "13D02, 05E40, 13F55"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07773v1",
            "title": "Computational and Statistical Thresholds in Multi-layer Stochastic Block\n  Models",
            "updated": "2023-11-13T21:46:51Z",
            "published": "2023-11-13T21:46:51Z",
            "summary": "We study the problem of community recovery and detection in multi-layer\nstochastic block models, focusing on the critical network density threshold for\nconsistent community structure inference. Using a prototypical two-block model,\nwe reveal a computational barrier for such multi-layer stochastic block models\nthat does not exist for its single-layer counterpart: When there are no\ncomputational constraints, the density threshold depends linearly on the number\nof layers. However, when restricted to polynomial-time algorithms, the density\nthreshold scales with the square root of the number of layers, assuming\ncorrectness of a low-degree polynomial hardness conjecture. Our results provide\na nearly complete picture of the optimal inference in multiple-layer stochastic\nblock models and partially settle the open question in Lei and Lin (2022)\nregarding the optimality of the bias-adjusted spectral method.",
            "author": [
                "Jing Lei",
                "Anru R. Zhang",
                "Zihan Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07773v1",
                "http://arxiv.org/pdf/2311.07773v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH",
                "62C20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07772v3",
            "title": "In-context Learning and Gradient Descent Revisited",
            "updated": "2023-11-18T19:58:27Z",
            "published": "2023-11-13T21:42:38Z",
            "summary": "In-context learning (ICL) has shown impressive results in few-shot learning\ntasks, yet its underlying mechanism is still not fully understood. Recent works\nsuggest that ICL can be thought of as a gradient descent (GD) based\noptimization process. While promising, these results mainly focus on simplified\nsettings of ICL and provide only a preliminary evaluation of the similarities\nbetween the two methods. In this work, we revisit the comparison between ICL\nand GD-based finetuning and study what properties of ICL an equivalent process\nmust follow. We highlight a major difference in the flow of information between\nICL and standard finetuning. Namely, ICL can only rely on information from\nlower layers at every point, while finetuning depends on loss gradients from\ndeeper layers. We refer to this discrepancy as Layer Causality and show that a\nlayer causal variant of the finetuning process aligns with ICL on par with\nvanilla finetuning and is even better in most cases across relevant metrics. To\nthe best of our knowledge, this is the first work to discuss this discrepancy\nexplicitly and suggest a solution that tackles this problem with minimal\nchanges.",
            "author": [
                "Gilad Deutch",
                "Nadav Magar",
                "Tomer Bar Natan",
                "Guy Dar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07772v3",
                "http://arxiv.org/pdf/2311.07772v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07768v1",
            "title": "Bayesian Calibration and Uncertainty Quantification of a Rate-dependent\n  Cohesive Zone Model for Polymer Interfaces",
            "updated": "2023-11-13T21:36:12Z",
            "published": "2023-11-13T21:36:12Z",
            "summary": "In the present work, a rate-dependent cohesive zone model for the fracture of\npolymeric interfaces is presented. Inverse calibration of parameters for such\ncomplex models through trial and error is computationally tedious due to the\nlarge number of parameters and the high computational cost associated. The\nobtained parameter values are often non-unique and the calibration inherits\nhigher uncertainty when the available experimental data is limited. To\nalleviate these difficulties, a Bayesian calibration approach is used for the\nproposed rate-dependent cohesive zone model in this work. The proposed cohesive\nzone model accounts for both reversible elastic and irreversible rate-dependent\nseparation sliding deformation at the interface. The viscous dissipation due to\nthe irreversible opening at the interface is modeled using elastic-viscoplastic\nkinematics that incorporates the effects of strain rate. To quantify the\nuncertainty associated with the inverse parameter estimation, a modular\nBayesian approach is employed to calibrate the unknown model parameters,\naccounting for the parameter uncertainty of the cohesive zone model. Further,\nto quantify the model uncertainties, such as incorrect assumptions or missing\nphysics, a discrepancy function is introduced and it is approximated as a\nGaussian process. The improvement in the model predictions following the\nintroduction of a discrepancy function is demonstrated justifying the need for\na discrepancy term. Finally, the overall uncertainty of the model is quantified\nin a predictive setting and the results are provided as confidence intervals. A\nsensitivity analysis is also performed to understand the effect of the\nvariability of the inputs on the nature of the output.",
            "author": [
                "Ponkrshnan Thiagarajan",
                "Trisha Sain",
                "Susanta Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07768v1",
                "http://arxiv.org/pdf/2311.07768v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07767v1",
            "title": "GreekT5: A Series of Greek Sequence-to-Sequence Models for News\n  Summarization",
            "updated": "2023-11-13T21:33:12Z",
            "published": "2023-11-13T21:33:12Z",
            "summary": "Text summarization (TS) is a natural language processing (NLP) subtask\npertaining to the automatic formulation of a concise and coherent summary that\ncovers the major concepts and topics from one or multiple documents. Recent\nadvancements in deep learning have led to the development of abstractive\nsummarization transformer-based models, which outperform classical approaches.\nIn any case, research in this field focuses on high resource languages such as\nEnglish, while the corresponding work for low resource languages is still\nunderdeveloped. Taking the above into account, this paper proposes a series of\nnovel TS models for Greek news articles. The proposed models were thoroughly\nevaluated on the same dataset against GreekBART, which is the state-of-the-art\nmodel in Greek abstractive news summarization. Our evaluation results reveal\nthat most of the proposed models significantly outperform GreekBART on various\nevaluation metrics. We make our evaluation code public, aiming to increase the\nreproducibility of this work and facilitate future research in the field.",
            "author": [
                "Nikolaos Giarelis",
                "Charalampos Mastrokostas",
                "Nikos Karacapilidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07767v1",
                "http://arxiv.org/pdf/2311.07767v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T07, 68T50",
                "I.2.7"
            ]
        }
    }
]